[
    {
        "table_id":9545,
        "row_id":51285,
        "rank":1,
        "Model":"PEGASUS",
        "mlmodel":{

        },
        "method_short":"PEGASUS",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-02",
        "metrics":{
            "ROUGE-2":"23.2",
            "BLEU score":null,
            "Parameters":"568 M"
        },
        "raw_metrics":{
            "ROUGE-2":23.2,
            "BLEU score":null,
            "Parameters":568.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":741562,
            "title":"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics",
            "url":"\/paper\/the-gem-benchmark-natural-language-generation",
            "published":"2021-02-02T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/the-gem-benchmark-natural-language-generation\/review\/?hl=51285"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":9545,
        "row_id":51283,
        "rank":2,
        "Model":"PaLM (finetuning)-540B",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"finetuning",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-05",
        "metrics":{
            "ROUGE-2":"21.2",
            "BLEU score":null,
            "Parameters":"540 B"
        },
        "raw_metrics":{
            "ROUGE-2":21.2,
            "BLEU score":null,
            "Parameters":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":989558,
            "title":"PaLM: Scaling Language Modeling with Pathways",
            "url":"\/paper\/palm-scaling-language-modeling-with-pathways-1",
            "published":"2022-04-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":9545,
        "row_id":51286,
        "rank":3,
        "Model":"T5-XXL",
        "mlmodel":{

        },
        "method_short":"T5-XXL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-05",
        "metrics":{
            "ROUGE-2":"21.0",
            "BLEU score":null,
            "Parameters":null
        },
        "raw_metrics":{
            "ROUGE-2":21.0,
            "BLEU score":null,
            "Parameters":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":989558,
            "title":"PaLM: Scaling Language Modeling with Pathways",
            "url":"\/paper\/palm-scaling-language-modeling-with-pathways-1",
            "published":"2022-04-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":9545,
        "row_id":51284,
        "rank":4,
        "Model":"PaLM (finetuning)-62B",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"finetuning",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-05",
        "metrics":{
            "ROUGE-2":"18.5",
            "BLEU score":null,
            "Parameters":"62 B"
        },
        "raw_metrics":{
            "ROUGE-2":18.5,
            "BLEU score":null,
            "Parameters":62.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":989558,
            "title":"PaLM: Scaling Language Modeling with Pathways",
            "url":"\/paper\/palm-scaling-language-modeling-with-pathways-1",
            "published":"2022-04-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":9545,
        "row_id":34003,
        "rank":5,
        "Model":"ByT5",
        "mlmodel":{

        },
        "method_short":"ByT5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-28",
        "metrics":{
            "ROUGE-2":null,
            "BLEU score":"15.3",
            "Parameters":null
        },
        "raw_metrics":{
            "ROUGE-2":null,
            "BLEU score":15.3,
            "Parameters":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":807434,
            "title":"ByT5: Towards a token-free future with pre-trained byte-to-byte models",
            "url":"\/paper\/byt5-towards-a-token-free-future-with-pre",
            "published":"2021-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/byt5-towards-a-token-free-future-with-pre\/review\/?hl=34003"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9545,
        "row_id":34005,
        "rank":6,
        "Model":"mT5",
        "mlmodel":{

        },
        "method_short":"mT5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-28",
        "metrics":{
            "ROUGE-2":null,
            "BLEU score":"14.3",
            "Parameters":null
        },
        "raw_metrics":{
            "ROUGE-2":null,
            "BLEU score":14.3,
            "Parameters":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":807434,
            "title":"ByT5: Towards a token-free future with pre-trained byte-to-byte models",
            "url":"\/paper\/byt5-towards-a-token-free-future-with-pre",
            "published":"2021-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/byt5-towards-a-token-free-future-with-pre\/review\/?hl=34005"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]