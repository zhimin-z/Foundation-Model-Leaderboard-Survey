[
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.447",
        "Observed inference time (s)":"0.743",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"796.496",
        "# output tokens":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.429",
        "Observed inference time (s)":"0.55",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"823.277",
        "# output tokens":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.571",
        "Observed inference time (s)":"0.387",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"823.277",
        "# output tokens":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.355",
        "Observed inference time (s)":"0.377",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"823.277",
        "# output tokens":"1"
    },
    {
        "Model":"Mixtral (8x7B 32K seqlen)",
        "EM":"0.578",
        "Observed inference time (s)":"0.346",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"796.496",
        "# output tokens":"1"
    },
    {
        "Model":"Phi-2",
        "EM":"0.426",
        "Observed inference time (s)":"0.31",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"660.72",
        "# output tokens":"1"
    },
    {
        "Model":"Qwen1.5 (14B)",
        "EM":"0.482",
        "Observed inference time (s)":"0.319",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"732.34",
        "# output tokens":"1"
    },
    {
        "Model":"Qwen1.5 (72B)",
        "EM":"0.631",
        "Observed inference time (s)":"0.375",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"732.34",
        "# output tokens":"1"
    },
    {
        "Model":"Qwen1.5 (7B)",
        "EM":"0.457",
        "Observed inference time (s)":"0.293",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"732.34",
        "# output tokens":"1"
    },
    {
        "Model":"Yi (34B)",
        "EM":"0.674",
        "Observed inference time (s)":"0.66",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"771.16",
        "# output tokens":"1"
    },
    {
        "Model":"Yi (6B)",
        "EM":"0.486",
        "Observed inference time (s)":"0.37",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"771.16",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude Instant 1.2",
        "EM":"0.582",
        "Observed inference time (s)":"0.895",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"730.422",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude 2.1",
        "EM":"0.613",
        "Observed inference time (s)":"2.529",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"730.422",
        "# output tokens":"1"
    },
    {
        "Model":"Claude 3 Haiku (20240307)",
        "EM":"0.539",
        "Observed inference time (s)":"0.771",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"665.422",
        "# output tokens":"1"
    },
    {
        "Model":"Claude 3 Sonnet (20240229)",
        "EM":"0.656",
        "Observed inference time (s)":"1.391",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"665.422",
        "# output tokens":"1"
    },
    {
        "Model":"Claude 3 Opus (20240229)",
        "EM":"0.791",
        "Observed inference time (s)":"3.982",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"665.422",
        "# output tokens":"1"
    },
    {
        "Model":"Gemini 1.0 Pro",
        "EM":"0.525",
        "Observed inference time (s)":"0.384",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"747.418",
        "# output tokens":"0"
    },
    {
        "Model":"PaLM-2 (Bison)",
        "EM":"0.578",
        "Observed inference time (s)":"0.812",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"752.83",
        "# output tokens":"1"
    },
    {
        "Model":"PaLM-2 (Unicorn)",
        "EM":"0.706",
        "Observed inference time (s)":"0.978",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"752.83",
        "# output tokens":"0"
    },
    {
        "Model":"GPT-3.5 Turbo (0613)",
        "EM":"0.535",
        "Observed inference time (s)":"0.439",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"651.592",
        "# output tokens":"1"
    },
    {
        "Model":"GPT-4 Turbo (1106 preview)",
        "EM":"0.684",
        "Observed inference time (s)":"0.54",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"651.592",
        "# output tokens":"1"
    },
    {
        "Model":"GPT-4 (0613)",
        "EM":"0.702",
        "Observed inference time (s)":"0.444",
        "# eval":"282",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"651.592",
        "# output tokens":"1"
    }
]