[
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A100",
        "task":"chat",
        "energy":335.26,
        "throughput":27.47,
        "response_length":60.65,
        "latency":1.99,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"V100",
        "task":"chat",
        "energy":335.88,
        "throughput":26.08,
        "response_length":65.01,
        "latency":2.11,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":354.66,
        "throughput":23.93,
        "response_length":68.06,
        "latency":2.28,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":369.43,
        "throughput":27.65,
        "response_length":67.52,
        "latency":2.12,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":493.75,
        "throughput":30.66,
        "response_length":99.96,
        "latency":3.1,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":494.74,
        "throughput":31.28,
        "response_length":103.0,
        "latency":3.21,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A40",
        "task":"chat",
        "energy":525.71,
        "throughput":25.77,
        "response_length":64.59,
        "latency":2.28,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":539.05,
        "throughput":25.8,
        "response_length":63.46,
        "latency":2.25,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A100",
        "task":"instruct",
        "energy":561.97,
        "throughput":29.32,
        "response_length":107.48,
        "latency":3.32,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":569.27,
        "throughput":32.84,
        "response_length":122.12,
        "latency":3.66,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":576.98,
        "throughput":32.02,
        "response_length":119.63,
        "latency":3.62,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":578.52,
        "throughput":28.42,
        "response_length":106.22,
        "latency":3.37,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":594.79,
        "throughput":26.58,
        "response_length":104.02,
        "latency":3.35,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":596.66,
        "throughput":33.29,
        "response_length":124.22,
        "latency":3.68,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A100",
        "task":"chat",
        "energy":631.57,
        "throughput":23.2,
        "response_length":76.47,
        "latency":2.97,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"V100",
        "task":"instruct",
        "energy":636.4,
        "throughput":23.64,
        "response_length":110.3,
        "latency":3.73,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"V100",
        "task":"instruct",
        "energy":671.83,
        "throughput":31.26,
        "response_length":127.87,
        "latency":3.99,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":671.84,
        "throughput":21.6,
        "response_length":78.06,
        "latency":3.17,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":677.74,
        "throughput":33.55,
        "response_length":142.32,
        "latency":4.21,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A100",
        "task":"chat",
        "energy":684.17,
        "throughput":28.0,
        "response_length":132.85,
        "latency":4.63,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":697.67,
        "throughput":30.28,
        "response_length":124.94,
        "latency":3.96,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":699.25,
        "throughput":32.73,
        "response_length":280.61,
        "latency":13.96,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"V100",
        "task":"chat",
        "energy":727.22,
        "throughput":30.31,
        "response_length":130.44,
        "latency":4.12,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A100",
        "task":"instruct",
        "energy":727.92,
        "throughput":25.79,
        "response_length":127.34,
        "latency":4.79,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A100",
        "task":"chat",
        "energy":735.77,
        "throughput":61.52,
        "response_length":214.78,
        "latency":3.08,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":736.66,
        "throughput":64.48,
        "response_length":209.48,
        "latency":2.92,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A100",
        "task":"instruct",
        "energy":750.08,
        "throughput":32.31,
        "response_length":147.0,
        "latency":4.44,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"V100",
        "task":"chat",
        "energy":772.4,
        "throughput":17.27,
        "response_length":76.56,
        "latency":3.78,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"V100",
        "task":"chat",
        "energy":783.93,
        "throughput":31.76,
        "response_length":160.12,
        "latency":4.94,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":791.12,
        "throughput":31.91,
        "response_length":141.03,
        "latency":4.3,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":805.04,
        "throughput":66.07,
        "response_length":226.21,
        "latency":3.19,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":818.27,
        "throughput":29.12,
        "response_length":104.98,
        "latency":3.54,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"V100",
        "task":"instruct",
        "energy":821.75,
        "throughput":31.58,
        "response_length":146.43,
        "latency":4.47,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":847.95,
        "throughput":53.98,
        "response_length":195.53,
        "latency":3.43,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A100",
        "task":"instruct",
        "energy":853.24,
        "throughput":22.7,
        "response_length":99.55,
        "latency":3.95,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A40",
        "task":"instruct",
        "energy":864.42,
        "throughput":26.4,
        "response_length":104.19,
        "latency":3.61,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":865.8,
        "throughput":33.33,
        "response_length":195.68,
        "latency":5.77,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-7B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":872.0,
        "throughput":26.26,
        "response_length":96.94,
        "latency":3.35,
        "arc":51.11,
        "hellaswag":77.74,
        "truthfulqa":34.08,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"V100",
        "task":"instruct",
        "energy":872.86,
        "throughput":30.12,
        "response_length":359.11,
        "latency":18.11,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A100",
        "task":"chat",
        "energy":881.44,
        "throughput":33.57,
        "response_length":161.81,
        "latency":4.79,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A100",
        "task":"instruct",
        "energy":887.48,
        "throughput":55.22,
        "response_length":221.39,
        "latency":3.84,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A100",
        "task":"instruct",
        "energy":892.83,
        "throughput":61.49,
        "response_length":244.59,
        "latency":3.69,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A40",
        "task":"chat",
        "energy":916.05,
        "throughput":30.1,
        "response_length":125.2,
        "latency":4.13,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":927.76,
        "throughput":29.48,
        "response_length":117.95,
        "latency":3.97,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":930.42,
        "throughput":23.08,
        "response_length":114.53,
        "latency":4.39,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":936.36,
        "throughput":17.17,
        "response_length":85.42,
        "latency":4.21,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":940.7,
        "throughput":31.87,
        "response_length":191.74,
        "latency":5.78,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A100",
        "task":"chat",
        "energy":951.08,
        "throughput":33.2,
        "response_length":212.46,
        "latency":6.39,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":968.56,
        "throughput":32.58,
        "response_length":213.58,
        "latency":6.53,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":968.79,
        "throughput":42.47,
        "response_length":193.91,
        "latency":4.34,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A40",
        "task":"instruct",
        "energy":973.6,
        "throughput":30.11,
        "response_length":126.36,
        "latency":4.16,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":994.33,
        "throughput":25.77,
        "response_length":121.15,
        "latency":4.55,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":998.78,
        "throughput":33.02,
        "response_length":206.82,
        "latency":6.23,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1002.33,
        "throughput":54.28,
        "response_length":233.51,
        "latency":4.1,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1002.49,
        "throughput":24.81,
        "response_length":143.01,
        "latency":5.49,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A100",
        "task":"instruct",
        "energy":1011.17,
        "throughput":32.74,
        "response_length":219.56,
        "latency":6.71,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A100",
        "task":"chat",
        "energy":1030.89,
        "throughput":55.84,
        "response_length":240.34,
        "latency":4.12,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1042.91,
        "throughput":33.2,
        "response_length":213.17,
        "latency":6.39,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1043.99,
        "throughput":17.27,
        "response_length":310.34,
        "latency":23.45,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1073.31,
        "throughput":35.33,
        "response_length":284.16,
        "latency":12.14,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"tatsu-lab\/alpaca-7B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1080.59,
        "throughput":29.85,
        "response_length":121.29,
        "latency":4.04,
        "arc":52.65,
        "hellaswag":76.91,
        "truthfulqa":39.55,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"V100",
        "task":"chat",
        "energy":1083.43,
        "throughput":30.28,
        "response_length":216.18,
        "latency":6.9,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1084.13,
        "throughput":31.09,
        "response_length":213.68,
        "latency":6.75,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1093.54,
        "throughput":31.0,
        "response_length":217.51,
        "latency":6.95,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1098.34,
        "throughput":24.68,
        "response_length":155.28,
        "latency":6.0,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1105.64,
        "throughput":44.77,
        "response_length":224.97,
        "latency":4.83,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1110.33,
        "throughput":40.21,
        "response_length":281.74,
        "latency":10.49,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"V100",
        "task":"chat",
        "energy":1112.95,
        "throughput":38.26,
        "response_length":214.35,
        "latency":5.1,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A100",
        "task":"chat",
        "energy":1124.4,
        "throughput":45.42,
        "response_length":243.88,
        "latency":5.21,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1132.0,
        "throughput":29.38,
        "response_length":141.62,
        "latency":4.84,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A100",
        "task":"instruct",
        "energy":1132.5,
        "throughput":45.09,
        "response_length":232.79,
        "latency":4.99,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1134.24,
        "throughput":33.0,
        "response_length":218.2,
        "latency":6.52,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"V100",
        "task":"instruct",
        "energy":1134.95,
        "throughput":43.16,
        "response_length":220.49,
        "latency":4.91,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1139.97,
        "throughput":36.4,
        "response_length":202.85,
        "latency":4.89,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"V100",
        "task":"chat",
        "energy":1150.4,
        "throughput":17.29,
        "response_length":312.98,
        "latency":24.0,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1151.47,
        "throughput":18.57,
        "response_length":117.86,
        "latency":5.58,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1160.81,
        "throughput":20.98,
        "response_length":124.96,
        "latency":5.78,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A40",
        "task":"instruct",
        "energy":1177.36,
        "throughput":28.94,
        "response_length":142.34,
        "latency":4.76,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"V100",
        "task":"instruct",
        "energy":1181.36,
        "throughput":31.41,
        "response_length":253.6,
        "latency":7.83,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1195.7,
        "throughput":32.93,
        "response_length":247.05,
        "latency":7.46,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1199.14,
        "throughput":45.94,
        "response_length":244.93,
        "latency":5.17,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A100",
        "task":"instruct",
        "energy":1209.06,
        "throughput":48.58,
        "response_length":273.66,
        "latency":5.68,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"V100",
        "task":"chat",
        "energy":1212.85,
        "throughput":43.26,
        "response_length":241.46,
        "latency":5.36,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"Neutralzz\/BiLLa-7B-SFT",
        "gpu":"A40",
        "task":"chat",
        "energy":1218.64,
        "throughput":29.49,
        "response_length":159.3,
        "latency":5.44,
        "arc":27.73,
        "hellaswag":26.04,
        "truthfulqa":49.05,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"V100",
        "task":"instruct",
        "energy":1231.14,
        "throughput":32.0,
        "response_length":228.92,
        "latency":7.08,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1237.66,
        "throughput":42.27,
        "response_length":233.52,
        "latency":5.21,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A100",
        "task":"chat",
        "energy":1242.92,
        "throughput":22.11,
        "response_length":153.76,
        "latency":7.94,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A100",
        "task":"chat",
        "energy":1246.09,
        "throughput":49.54,
        "response_length":275.27,
        "latency":5.6,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1251.94,
        "throughput":31.66,
        "response_length":247.84,
        "latency":7.69,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1264.45,
        "throughput":39.22,
        "response_length":226.72,
        "latency":5.37,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1264.82,
        "throughput":15.49,
        "response_length":81.27,
        "latency":4.88,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1266.69,
        "throughput":25.68,
        "response_length":169.55,
        "latency":6.41,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1272.89,
        "throughput":48.27,
        "response_length":274.1,
        "latency":5.72,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"V100",
        "task":"instruct",
        "energy":1274.25,
        "throughput":18.48,
        "response_length":117.28,
        "latency":5.55,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1276.27,
        "throughput":31.45,
        "response_length":241.79,
        "latency":7.49,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1279.5,
        "throughput":30.17,
        "response_length":243.02,
        "latency":7.83,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1280.44,
        "throughput":44.66,
        "response_length":274.27,
        "latency":6.19,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"metaai\/Llama-2-7b-chat-hf",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1288.21,
        "throughput":30.96,
        "response_length":220.84,
        "latency":6.82,
        "arc":52.73,
        "hellaswag":78.48,
        "truthfulqa":45.33,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A40",
        "task":"chat",
        "energy":1293.69,
        "throughput":15.7,
        "response_length":80.32,
        "latency":4.76,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"V100",
        "task":"instruct",
        "energy":1302.03,
        "throughput":39.94,
        "response_length":246.8,
        "latency":5.84,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A100",
        "task":"instruct",
        "energy":1307.83,
        "throughput":33.04,
        "response_length":355.22,
        "latency":15.6,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"V100",
        "task":"chat",
        "energy":1308.97,
        "throughput":32.54,
        "response_length":261.65,
        "latency":7.93,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"V100",
        "task":"chat",
        "energy":1327.98,
        "throughput":37.91,
        "response_length":273.35,
        "latency":7.26,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"V100",
        "task":"instruct",
        "energy":1329.69,
        "throughput":37.61,
        "response_length":273.06,
        "latency":7.3,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1333.27,
        "throughput":29.0,
        "response_length":223.56,
        "latency":7.42,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A100",
        "task":"chat",
        "energy":1345.55,
        "throughput":26.56,
        "response_length":261.07,
        "latency":9.62,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"V100",
        "task":"chat",
        "energy":1349.82,
        "throughput":28.54,
        "response_length":242.86,
        "latency":8.21,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A100",
        "task":"instruct",
        "energy":1374.59,
        "throughput":22.23,
        "response_length":161.53,
        "latency":8.26,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"V100",
        "task":"instruct",
        "energy":1381.34,
        "throughput":28.54,
        "response_length":233.76,
        "latency":7.93,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1384.46,
        "throughput":33.43,
        "response_length":272.48,
        "latency":8.14,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"V100",
        "task":"instruct",
        "energy":1386.76,
        "throughput":31.8,
        "response_length":268.9,
        "latency":8.36,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1387.84,
        "throughput":33.19,
        "response_length":273.57,
        "latency":8.18,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1392.61,
        "throughput":14.77,
        "response_length":145.36,
        "latency":9.38,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A100",
        "task":"instruct",
        "energy":1393.55,
        "throughput":26.46,
        "response_length":269.85,
        "latency":10.0,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1423.87,
        "throughput":27.1,
        "response_length":275.32,
        "latency":9.71,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1426.35,
        "throughput":29.75,
        "response_length":200.52,
        "latency":6.66,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1445.49,
        "throughput":38.47,
        "response_length":274.21,
        "latency":7.18,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A100",
        "task":"instruct",
        "energy":1447.62,
        "throughput":25.95,
        "response_length":259.23,
        "latency":9.77,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1449.52,
        "throughput":38.02,
        "response_length":274.04,
        "latency":7.25,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A100",
        "task":"chat",
        "energy":1457.86,
        "throughput":27.49,
        "response_length":274.39,
        "latency":9.54,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"V100",
        "task":"chat",
        "energy":1458.19,
        "throughput":14.87,
        "response_length":151.27,
        "latency":9.74,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"V100",
        "task":"chat",
        "energy":1458.53,
        "throughput":32.13,
        "response_length":283.12,
        "latency":8.76,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1462.68,
        "throughput":20.98,
        "response_length":168.69,
        "latency":7.78,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1464.54,
        "throughput":26.91,
        "response_length":276.31,
        "latency":9.84,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1523.77,
        "throughput":14.91,
        "response_length":157.11,
        "latency":10.05,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1524.92,
        "throughput":29.57,
        "response_length":212.12,
        "latency":7.14,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A100",
        "task":"instruct",
        "energy":1529.69,
        "throughput":32.41,
        "response_length":300.91,
        "latency":9.14,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A100",
        "task":"chat",
        "energy":1531.7,
        "throughput":27.26,
        "response_length":284.92,
        "latency":10.3,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1539.88,
        "throughput":27.43,
        "response_length":241.68,
        "latency":8.4,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"V100",
        "task":"instruct",
        "energy":1557.45,
        "throughput":32.28,
        "response_length":300.22,
        "latency":9.15,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1586.24,
        "throughput":25.75,
        "response_length":188.13,
        "latency":7.25,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A100",
        "task":"chat",
        "energy":1588.27,
        "throughput":31.59,
        "response_length":326.3,
        "latency":10.17,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1590.84,
        "throughput":15.79,
        "response_length":102.36,
        "latency":6.01,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1593.3,
        "throughput":31.98,
        "response_length":316.21,
        "latency":9.72,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1618.03,
        "throughput":22.13,
        "response_length":273.0,
        "latency":11.78,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"V100",
        "task":"instruct",
        "energy":1619.95,
        "throughput":15.06,
        "response_length":159.93,
        "latency":10.2,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A100",
        "task":"instruct",
        "energy":1629.66,
        "throughput":27.4,
        "response_length":283.26,
        "latency":9.93,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A40",
        "task":"chat",
        "energy":1636.2,
        "throughput":28.85,
        "response_length":216.66,
        "latency":7.54,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1647.93,
        "throughput":30.35,
        "response_length":313.37,
        "latency":10.03,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1657.13,
        "throughput":26.35,
        "response_length":195.91,
        "latency":7.37,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1659.14,
        "throughput":21.66,
        "response_length":273.98,
        "latency":12.05,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1661.29,
        "throughput":32.86,
        "response_length":235.19,
        "latency":6.72,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"V100",
        "task":"chat",
        "energy":1661.33,
        "throughput":22.22,
        "response_length":278.48,
        "latency":11.95,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1676.22,
        "throughput":29.93,
        "response_length":223.85,
        "latency":7.51,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"metaai\/llama-13B",
        "gpu":"A40",
        "task":"instruct",
        "energy":1693.43,
        "throughput":15.75,
        "response_length":101.69,
        "latency":5.97,
        "arc":56.31,
        "hellaswag":80.86,
        "truthfulqa":39.9,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"V100",
        "task":"instruct",
        "energy":1700.6,
        "throughput":21.54,
        "response_length":281.81,
        "latency":12.53,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1706.17,
        "throughput":29.05,
        "response_length":212.76,
        "latency":7.33,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A100",
        "task":"instruct",
        "energy":1718.98,
        "throughput":25.88,
        "response_length":219.98,
        "latency":8.45,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1736.54,
        "throughput":32.63,
        "response_length":197.44,
        "latency":5.9,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1738.08,
        "throughput":26.07,
        "response_length":216.64,
        "latency":8.21,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1738.9,
        "throughput":26.39,
        "response_length":227.33,
        "latency":8.57,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1744.03,
        "throughput":19.18,
        "response_length":312.91,
        "latency":20.88,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A40",
        "task":"instruct",
        "energy":1758.71,
        "throughput":31.01,
        "response_length":357.14,
        "latency":17.96,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A40",
        "task":"chat",
        "energy":1787.51,
        "throughput":21.69,
        "response_length":312.84,
        "latency":17.95,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1787.59,
        "throughput":33.07,
        "response_length":242.74,
        "latency":6.94,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A100",
        "task":"chat",
        "energy":1802.98,
        "throughput":19.29,
        "response_length":314.3,
        "latency":20.68,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "gpu":"A40",
        "task":"instruct",
        "energy":1804.48,
        "throughput":29.21,
        "response_length":233.48,
        "latency":8.1,
        "arc":36.86,
        "hellaswag":61.55,
        "truthfulqa":37.94,
        "parameters":7
    },
    {
        "Model":"lmsys\/fastchat-t5-3b-v1.0",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1807.68,
        "throughput":21.1,
        "response_length":313.1,
        "latency":18.37,
        "arc":35.92,
        "hellaswag":46.36,
        "truthfulqa":48.79,
        "parameters":3
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A40",
        "task":"chat",
        "energy":1833.72,
        "throughput":33.11,
        "response_length":243.22,
        "latency":6.95,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A100",
        "task":"instruct-concise",
        "energy":1834.86,
        "throughput":24.82,
        "response_length":236.01,
        "latency":9.22,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"V100",
        "task":"chat",
        "energy":1837.74,
        "throughput":30.55,
        "response_length":324.95,
        "latency":10.4,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A40",
        "task":"instruct",
        "energy":1863.51,
        "throughput":32.8,
        "response_length":221.25,
        "latency":6.59,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":1871.65,
        "throughput":17.42,
        "response_length":135.39,
        "latency":7.73,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A40",
        "task":"instruct",
        "energy":1918.9,
        "throughput":29.35,
        "response_length":253.72,
        "latency":8.65,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":1940.6,
        "throughput":29.89,
        "response_length":251.45,
        "latency":8.39,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":1946.2,
        "throughput":25.5,
        "response_length":258.85,
        "latency":10.06,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":1952.14,
        "throughput":21.46,
        "response_length":188.23,
        "latency":8.71,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":1977.17,
        "throughput":21.54,
        "response_length":212.53,
        "latency":9.8,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":2004.23,
        "throughput":21.75,
        "response_length":194.73,
        "latency":8.89,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A100",
        "task":"chat",
        "energy":2004.73,
        "throughput":26.57,
        "response_length":247.8,
        "latency":9.28,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-7b",
        "gpu":"A40",
        "task":"chat",
        "energy":2017.33,
        "throughput":29.72,
        "response_length":260.72,
        "latency":8.72,
        "arc":47.1,
        "hellaswag":73.7,
        "truthfulqa":46.0,
        "parameters":7
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A100",
        "task":"instruct",
        "energy":2025.33,
        "throughput":26.55,
        "response_length":244.76,
        "latency":9.2,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A100",
        "task":"instruct",
        "energy":2029.47,
        "throughput":24.94,
        "response_length":250.45,
        "latency":9.79,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2049.71,
        "throughput":32.33,
        "response_length":229.96,
        "latency":6.91,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"RWKV\/rwkv-raven-7b",
        "gpu":"A40",
        "task":"instruct",
        "energy":2049.77,
        "throughput":33.8,
        "response_length":264.96,
        "latency":7.56,
        "arc":39.42,
        "hellaswag":66.45,
        "truthfulqa":38.54,
        "parameters":7
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":2057.17,
        "throughput":24.92,
        "response_length":251.1,
        "latency":9.77,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A100",
        "task":"chat",
        "energy":2060.03,
        "throughput":25.4,
        "response_length":259.59,
        "latency":9.93,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2095.39,
        "throughput":15.27,
        "response_length":141.44,
        "latency":8.89,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A40",
        "task":"instruct",
        "energy":2099.34,
        "throughput":30.89,
        "response_length":274.67,
        "latency":8.96,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2105.32,
        "throughput":28.14,
        "response_length":262.99,
        "latency":9.25,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2114.63,
        "throughput":30.93,
        "response_length":271.89,
        "latency":8.86,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A100",
        "task":"instruct",
        "energy":2115.52,
        "throughput":26.22,
        "response_length":275.88,
        "latency":10.47,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":2117.02,
        "throughput":26.16,
        "response_length":276.17,
        "latency":10.5,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A40",
        "task":"instruct",
        "energy":2131.37,
        "throughput":29.42,
        "response_length":267.84,
        "latency":9.16,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A40",
        "task":"chat",
        "energy":2142.92,
        "throughput":30.88,
        "response_length":272.84,
        "latency":8.9,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2143.53,
        "throughput":29.83,
        "response_length":271.91,
        "latency":9.13,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A100",
        "task":"chat",
        "energy":2144.83,
        "throughput":21.21,
        "response_length":265.57,
        "latency":12.14,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "gpu":"A40",
        "task":"chat",
        "energy":2149.25,
        "throughput":32.66,
        "response_length":243.15,
        "latency":7.27,
        "arc":44.97,
        "hellaswag":63.22,
        "truthfulqa":47.08,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":2151.01,
        "throughput":26.47,
        "response_length":269.12,
        "latency":10.13,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"metaai\/Llama-2-7b-chat-hf",
        "gpu":"A40",
        "task":"instruct",
        "energy":2180.25,
        "throughput":31.82,
        "response_length":365.4,
        "latency":11.32,
        "arc":52.73,
        "hellaswag":78.48,
        "truthfulqa":45.33,
        "parameters":7
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A100",
        "task":"chat",
        "energy":2189.25,
        "throughput":26.28,
        "response_length":288.82,
        "latency":10.95,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A100",
        "task":"instruct",
        "energy":2191.19,
        "throughput":20.73,
        "response_length":254.08,
        "latency":11.89,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"V100",
        "task":"instruct",
        "energy":2196.75,
        "throughput":21.69,
        "response_length":255.05,
        "latency":11.67,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"V100",
        "task":"instruct",
        "energy":2202.81,
        "throughput":21.82,
        "response_length":220.83,
        "latency":10.11,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":2210.65,
        "throughput":15.31,
        "response_length":239.28,
        "latency":15.19,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"lmsys\/vicuna-7B",
        "gpu":"A40",
        "task":"chat",
        "energy":2239.07,
        "throughput":30.07,
        "response_length":284.27,
        "latency":9.47,
        "arc":53.5,
        "hellaswag":77.53,
        "truthfulqa":49.0,
        "parameters":7
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2240.87,
        "throughput":15.33,
        "response_length":149.74,
        "latency":9.35,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"V100",
        "task":"chat",
        "energy":2265.42,
        "throughput":21.59,
        "response_length":244.31,
        "latency":11.24,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"Salesforce\/xgen-7b-8k-inst",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2275.13,
        "throughput":30.95,
        "response_length":272.63,
        "latency":8.88,
        "arc":46.67,
        "hellaswag":74.85,
        "truthfulqa":41.89,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A100",
        "task":"instruct",
        "energy":2284.89,
        "throughput":21.01,
        "response_length":266.41,
        "latency":12.33,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"V100",
        "task":"instruct-concise",
        "energy":2290.82,
        "throughput":21.7,
        "response_length":229.18,
        "latency":10.52,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"V100",
        "task":"chat",
        "energy":2299.25,
        "throughput":21.53,
        "response_length":265.55,
        "latency":12.2,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2305.97,
        "throughput":26.52,
        "response_length":244.17,
        "latency":8.98,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A40",
        "task":"chat",
        "energy":2319.91,
        "throughput":26.41,
        "response_length":255.35,
        "latency":9.45,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A100",
        "task":"chat-concise",
        "energy":2349.18,
        "throughput":26.3,
        "response_length":282.48,
        "latency":10.73,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"V100",
        "task":"instruct",
        "energy":2355.2,
        "throughput":21.7,
        "response_length":246.25,
        "latency":11.36,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A40",
        "task":"chat",
        "energy":2362.09,
        "throughput":15.6,
        "response_length":148.33,
        "latency":9.17,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"V100",
        "task":"instruct",
        "energy":2362.64,
        "throughput":21.7,
        "response_length":274.18,
        "latency":12.58,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"databricks\/dolly-v2-12b",
        "gpu":"A40",
        "task":"instruct",
        "energy":2369.28,
        "throughput":15.68,
        "response_length":155.61,
        "latency":9.58,
        "arc":42.15,
        "hellaswag":71.83,
        "truthfulqa":33.37,
        "parameters":12
    },
    {
        "Model":"metaai\/Llama-2-7b-chat-hf",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2398.92,
        "throughput":31.73,
        "response_length":402.67,
        "latency":12.57,
        "arc":52.73,
        "hellaswag":78.48,
        "truthfulqa":45.33,
        "parameters":7
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":2412.71,
        "throughput":21.22,
        "response_length":268.29,
        "latency":12.47,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A40",
        "task":"instruct",
        "energy":2415.8,
        "throughput":28.48,
        "response_length":306.77,
        "latency":10.69,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"metaai\/Llama-2-13b-chat-hf",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2423.3,
        "throughput":16.75,
        "response_length":223.39,
        "latency":12.93,
        "arc":59.13,
        "hellaswag":81.95,
        "truthfulqa":43.96,
        "parameters":13
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2439.29,
        "throughput":26.57,
        "response_length":255.54,
        "latency":9.4,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"StabilityAI\/stablelm-tuned-alpha-7b",
        "gpu":"A40",
        "task":"instruct",
        "energy":2445.44,
        "throughput":23.12,
        "response_length":244.86,
        "latency":10.37,
        "arc":31.91,
        "hellaswag":53.59,
        "truthfulqa":40.22,
        "parameters":7
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":2461.87,
        "throughput":15.21,
        "response_length":249.45,
        "latency":15.91,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"V100",
        "task":"chat",
        "energy":2513.59,
        "throughput":15.36,
        "response_length":256.3,
        "latency":16.2,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"V100",
        "task":"instruct",
        "energy":2516.29,
        "throughput":21.92,
        "response_length":264.1,
        "latency":12.06,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2521.58,
        "throughput":20.85,
        "response_length":275.1,
        "latency":12.63,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A100",
        "task":"chat",
        "energy":2526.46,
        "throughput":24.5,
        "response_length":291.92,
        "latency":13.17,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A40",
        "task":"chat",
        "energy":2541.44,
        "throughput":21.41,
        "response_length":279.51,
        "latency":12.51,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"metaai\/Llama-2-7b-chat-hf",
        "gpu":"A40",
        "task":"chat",
        "energy":2556.72,
        "throughput":31.92,
        "response_length":428.19,
        "latency":13.37,
        "arc":52.73,
        "hellaswag":78.48,
        "truthfulqa":45.33,
        "parameters":7
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":2576.32,
        "throughput":21.43,
        "response_length":253.87,
        "latency":11.72,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A100",
        "task":"chat",
        "energy":2600.84,
        "throughput":21.61,
        "response_length":280.74,
        "latency":12.74,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A40",
        "task":"chat",
        "energy":2621.35,
        "throughput":29.0,
        "response_length":324.25,
        "latency":11.01,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"project-baize\/baize-v2-7B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2644.92,
        "throughput":28.93,
        "response_length":321.06,
        "latency":10.94,
        "arc":48.46,
        "hellaswag":75.0,
        "truthfulqa":41.66,
        "parameters":7
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"V100",
        "task":"instruct",
        "energy":2645.14,
        "throughput":15.25,
        "response_length":252.09,
        "latency":16.13,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":2699.07,
        "throughput":21.43,
        "response_length":280.88,
        "latency":13.06,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"V100",
        "task":"chat",
        "energy":2717.4,
        "throughput":21.39,
        "response_length":293.63,
        "latency":13.59,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A40",
        "task":"instruct",
        "energy":2834.29,
        "throughput":17.01,
        "response_length":282.32,
        "latency":15.98,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"V100",
        "task":"chat-concise",
        "energy":2867.59,
        "throughput":21.5,
        "response_length":274.16,
        "latency":12.66,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":2937.84,
        "throughput":14.45,
        "response_length":275.08,
        "latency":18.29,
        "arc":42.15,
        "hellaswag":70.84,
        "truthfulqa":36.1,
        "parameters":7
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":2956.61,
        "throughput":17.27,
        "response_length":194.22,
        "latency":11.17,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"V100",
        "task":"chat",
        "energy":2980.67,
        "throughput":21.72,
        "response_length":278.88,
        "latency":12.83,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":3031.32,
        "throughput":17.39,
        "response_length":199.81,
        "latency":11.56,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":3058.93,
        "throughput":17.31,
        "response_length":185.44,
        "latency":10.59,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"V100",
        "task":"chat",
        "energy":3063.67,
        "throughput":21.44,
        "response_length":292.4,
        "latency":13.6,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":3263.63,
        "throughput":17.46,
        "response_length":217.35,
        "latency":12.44,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A40",
        "task":"instruct",
        "energy":3411.24,
        "throughput":17.56,
        "response_length":232.67,
        "latency":13.29,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":3501.18,
        "throughput":17.5,
        "response_length":229.58,
        "latency":13.13,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A40",
        "task":"instruct",
        "energy":3646.91,
        "throughput":17.52,
        "response_length":245.78,
        "latency":14.08,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A40",
        "task":"instruct-concise",
        "energy":3673.63,
        "throughput":16.03,
        "response_length":241.32,
        "latency":14.69,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":3747.88,
        "throughput":17.39,
        "response_length":252.57,
        "latency":14.5,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A40",
        "task":"chat",
        "energy":3827.61,
        "throughput":17.45,
        "response_length":262.53,
        "latency":15.03,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":3829.11,
        "throughput":16.01,
        "response_length":249.1,
        "latency":15.15,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"BAIR\/koala-13b",
        "gpu":"A40",
        "task":"instruct",
        "energy":3858.42,
        "throughput":17.47,
        "response_length":254.09,
        "latency":14.49,
        "arc":52.9,
        "hellaswag":77.54,
        "truthfulqa":50.09,
        "parameters":13
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A40",
        "task":"chat",
        "energy":3891.88,
        "throughput":16.06,
        "response_length":254.26,
        "latency":15.46,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "gpu":"A40",
        "task":"instruct",
        "energy":3936.23,
        "throughput":14.44,
        "response_length":253.77,
        "latency":17.25,
        "arc":45.56,
        "hellaswag":69.93,
        "truthfulqa":39.19,
        "parameters":12
    },
    {
        "Model":"metaai\/Llama-2-13b-chat-hf",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":3942.4,
        "throughput":16.93,
        "response_length":358.79,
        "latency":20.99,
        "arc":59.13,
        "hellaswag":81.95,
        "truthfulqa":43.96,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A40",
        "task":"instruct",
        "energy":3967.5,
        "throughput":17.6,
        "response_length":263.96,
        "latency":15.05,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":4051.82,
        "throughput":17.22,
        "response_length":268.91,
        "latency":15.69,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"nomic-ai\/gpt4all-13b-snoozy",
        "gpu":"A40",
        "task":"chat",
        "energy":4093.9,
        "throughput":17.46,
        "response_length":250.17,
        "latency":14.32,
        "arc":56.06,
        "hellaswag":78.69,
        "truthfulqa":48.36,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A40",
        "task":"instruct",
        "energy":4113.54,
        "throughput":17.27,
        "response_length":276.04,
        "latency":16.04,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":4203.67,
        "throughput":17.28,
        "response_length":269.62,
        "latency":15.69,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"metaai\/Llama-2-13b-chat-hf",
        "gpu":"A40",
        "task":"instruct",
        "energy":4210.19,
        "throughput":17.0,
        "response_length":371.56,
        "latency":21.69,
        "arc":59.13,
        "hellaswag":81.95,
        "truthfulqa":43.96,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A40",
        "task":"chat-concise",
        "energy":4262.54,
        "throughput":17.46,
        "response_length":283.45,
        "latency":16.29,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    },
    {
        "Model":"lmsys\/vicuna-13B",
        "gpu":"A40",
        "task":"chat",
        "energy":4265.29,
        "throughput":17.51,
        "response_length":281.3,
        "latency":16.1,
        "arc":52.9,
        "hellaswag":80.12,
        "truthfulqa":51.82,
        "parameters":13
    },
    {
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "gpu":"A40",
        "task":"chat",
        "energy":4316.49,
        "throughput":17.49,
        "response_length":289.59,
        "latency":16.59,
        "arc":58.7,
        "hellaswag":81.96,
        "truthfulqa":48.86,
        "parameters":13
    },
    {
        "Model":"metaai\/Llama-2-13b-chat-hf",
        "gpu":"A40",
        "task":"chat",
        "energy":4337.67,
        "throughput":16.96,
        "response_length":384.73,
        "latency":22.55,
        "arc":59.13,
        "hellaswag":81.95,
        "truthfulqa":43.96,
        "parameters":13
    },
    {
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "gpu":"A40",
        "task":"chat",
        "energy":4466.8,
        "throughput":17.41,
        "response_length":292.34,
        "latency":16.83,
        "arc":55.55,
        "hellaswag":79.3,
        "truthfulqa":47.33,
        "parameters":13
    }
]