[
    {
        "Date":1701129600000,
        "Model":"GPT-4 (Medprompt)\nMicrosoft\n(Nori et al. 2023)",
        "Code":"",
        "Size":"NA",
        "Accuracy (%)":82.0,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1684195200000,
        "Model":"Med-PaLM 2\nGoogle Research & DeepMind\n(Singhal et al. 2023)",
        "Code":"",
        "Size":"NA",
        "Accuracy (%)":81.8,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1701043200000,
        "Model":"MEDITRON\nEPFL\n(Chen et al. 2023)",
        "Code":"https:\/\/github.com\/epfLLM\/meditron",
        "Size":"70B",
        "Accuracy (%)":81.6,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1688601600000,
        "Model":"Palmyra-Med\nWriter Inc.\n(Kamble et al. 2023)",
        "Code":"",
        "Size":"40B",
        "Accuracy (%)":81.1,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1701388800000,
        "Model":"AntGLM-Med\nAnt Group\n(Li et al. 2023)",
        "Code":"",
        "Size":"10B",
        "Accuracy (%)":80.6,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1681257600000,
        "Model":"GPT-4-base\nMicrosoft & OpenAI\n(Nori et al. 2023)",
        "Code":"",
        "Size":"NA",
        "Accuracy (%)":80.4,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1673395200000,
        "Model":"GPT-3.5 + Z-Code++\nMicrosoft Azure AI\n(He et al. 2022)",
        "Code":"",
        "Size":"175B",
        "Accuracy (%)":79.6,
        "Macro-F1 (%)":"55.8"
    },
    {
        "Date":1672012800000,
        "Model":"Flan-PaLM (3-shot)\nGoogle Research & DeepMind\n(Singhal et al. 2022)",
        "Code":"",
        "Size":"540B",
        "Accuracy (%)":79.0,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1671494400000,
        "Model":"Codex (5-shot)\nTechnical University of Denmark & Copenhagen University Hospital\n(Li\u00e9vin et al. 2022)",
        "Code":"https:\/\/github.com\/vlievin\/medical-reasoning",
        "Size":"175B",
        "Accuracy (%)":78.2,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1568332800000,
        "Model":"Human Performance\nUniversity of Pittsburgh & Carnegie Mellon University\n(Jin et al. 2019)",
        "Code":"https:\/\/github.com\/pubmedqa\/pubmedqa",
        "Size":"NA",
        "Accuracy (%)":78.0,
        "Macro-F1 (%)":"72.2"
    },
    {
        "Date":1668556800000,
        "Model":"Galactica\nMeta AI\n(Taylor et al. 2022)",
        "Code":"",
        "Size":"120B",
        "Accuracy (%)":77.6,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1684713600000,
        "Model":"GatorTronGPT\nUniversity of Florida & NVIDIA\n(Peng et al. 2023)",
        "Code":"",
        "Size":"20B",
        "Accuracy (%)":77.6,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1679270400000,
        "Model":"GPT-4\nMicrosoft & OpenAI\n(Nori et al. 2023)",
        "Code":"",
        "Size":"NA",
        "Accuracy (%)":75.2,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1671062400000,
        "Model":"PubMedGPT\nStanford University\n(Bolton et al. 2022)",
        "Code":"https:\/\/github.com\/stanford-crfm\/pubmedgpt",
        "Size":"2.7B",
        "Accuracy (%)":74.4,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1665964800000,
        "Model":"DRAGON\nStanford University & EPFL\n(Yasunaga et al. 2022)",
        "Code":"https:\/\/github.com\/michiyasunaga\/dragon",
        "Size":"360M",
        "Accuracy (%)":73.4,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1682553600000,
        "Model":"PMC-LLaMA\nShanghai Jiao Tong University\n(Wu et al. 2023)",
        "Code":"https:\/\/github.com\/chaoyi-wu\/PMC-LLaMA",
        "Size":"7B",
        "Accuracy (%)":73.4,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1648512000000,
        "Model":"BioLinkBERT (large)\nStanford University\n(Yasunaga et al. 2022)",
        "Code":"https:\/\/github.com\/michiyasunaga\/LinkBERT",
        "Size":"340M",
        "Accuracy (%)":72.2,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1648512000000,
        "Model":"BioLinkBERT (base)\nStanford University\n(Yasunaga et al. 2022)",
        "Code":"https:\/\/github.com\/michiyasunaga\/LinkBERT",
        "Size":"110M",
        "Accuracy (%)":70.2,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1568332800000,
        "Model":"BioBERT (multi-phase tuning)\nUniversity of Pittsburgh & Carnegie Mellon University\n(Jin et al. 2019)",
        "Code":"https:\/\/github.com\/pubmedqa\/pubmedqa",
        "Size":"110M",
        "Accuracy (%)":68.1,
        "Macro-F1 (%)":"52.7"
    },
    {
        "Date":1622505600000,
        "Model":"BioELECTRA\nSAAMA AI Research Lab\n(Kanakarajan et al. 2019)",
        "Code":"https:\/\/github.com\/kamalkraj\/BioELECTRA",
        "Size":"110M",
        "Accuracy (%)":64.0,
        "Macro-F1 (%)":"NA"
    },
    {
        "Date":1596153600000,
        "Model":"PubMedBERT\nMicrosoft Research\n(Gu et al. 2020)",
        "Code":"https:\/\/huggingface.co\/microsoft\/BiomedNLP-PubMedBERT-base-uncased-abstract",
        "Size":"110M",
        "Accuracy (%)":55.8,
        "Macro-F1 (%)":"NA"
    }
]