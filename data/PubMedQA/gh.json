[
    {
        "Model":"GPT-4 (Medprompt)\nMicrosoft\n(Nori et al. 2023)",
        "Code":null,
        "Size":null,
        "Accuracy (%)":82.0,
        "Macro-F1 (%)":null
    },
    {
        "Model":"Med-PaLM 2\nGoogle Research & DeepMind\n(Singhal et al. 2023)",
        "Code":null,
        "Size":null,
        "Accuracy (%)":81.8,
        "Macro-F1 (%)":null
    },
    {
        "Model":"MEDITRON\nEPFL\n(Chen et al. 2023)",
        "Code":null,
        "Size":"70B",
        "Accuracy (%)":81.6,
        "Macro-F1 (%)":null
    },
    {
        "Model":"Palmyra-Med\nWriter Inc.\n(Kamble et al. 2023)",
        "Code":null,
        "Size":"40B",
        "Accuracy (%)":81.1,
        "Macro-F1 (%)":null
    },
    {
        "Model":"AntGLM-Med\nAnt Group\n(Li et al. 2023)",
        "Code":null,
        "Size":"10B",
        "Accuracy (%)":80.6,
        "Macro-F1 (%)":null
    },
    {
        "Model":"GPT-4-base\nMicrosoft & OpenAI\n(Nori et al. 2023)",
        "Code":null,
        "Size":null,
        "Accuracy (%)":80.4,
        "Macro-F1 (%)":null
    },
    {
        "Model":"GPT-3.5 + Z-Code++\nMicrosoft Azure AI\n(He et al. 2022)",
        "Code":null,
        "Size":"175B",
        "Accuracy (%)":79.6,
        "Macro-F1 (%)":55.8
    },
    {
        "Model":"Flan-PaLM (3-shot)\nGoogle Research & DeepMind\n(Singhal et al. 2022)",
        "Code":null,
        "Size":"540B",
        "Accuracy (%)":79.0,
        "Macro-F1 (%)":null
    },
    {
        "Model":"Codex (5-shot)\nTechnical University of Denmark & Copenhagen University Hospital\n(Li\u00e9vin et al. 2022)",
        "Code":null,
        "Size":"175B",
        "Accuracy (%)":78.2,
        "Macro-F1 (%)":null
    },
    {
        "Model":"Human Performance\nUniversity of Pittsburgh & Carnegie Mellon University\n(Jin et al. 2019)",
        "Code":null,
        "Size":null,
        "Accuracy (%)":78.0,
        "Macro-F1 (%)":72.2
    },
    {
        "Model":"Galactica\nMeta AI\n(Taylor et al. 2022)",
        "Code":null,
        "Size":"120B",
        "Accuracy (%)":77.6,
        "Macro-F1 (%)":null
    },
    {
        "Model":"GatorTronGPT\nUniversity of Florida & NVIDIA\n(Peng et al. 2023)",
        "Code":null,
        "Size":"20B",
        "Accuracy (%)":77.6,
        "Macro-F1 (%)":null
    },
    {
        "Model":"GPT-4\nMicrosoft & OpenAI\n(Nori et al. 2023)",
        "Code":null,
        "Size":null,
        "Accuracy (%)":75.2,
        "Macro-F1 (%)":null
    },
    {
        "Model":"PubMedGPT\nStanford University\n(Bolton et al. 2022)",
        "Code":null,
        "Size":"2.7B",
        "Accuracy (%)":74.4,
        "Macro-F1 (%)":null
    },
    {
        "Model":"DRAGON\nStanford University & EPFL\n(Yasunaga et al. 2022)",
        "Code":null,
        "Size":"360M",
        "Accuracy (%)":73.4,
        "Macro-F1 (%)":null
    },
    {
        "Model":"PMC-LLaMA\nShanghai Jiao Tong University\n(Wu et al. 2023)",
        "Code":null,
        "Size":"7B",
        "Accuracy (%)":73.4,
        "Macro-F1 (%)":null
    },
    {
        "Model":"BioLinkBERT (large)\nStanford University\n(Yasunaga et al. 2022)",
        "Code":null,
        "Size":"340M",
        "Accuracy (%)":72.2,
        "Macro-F1 (%)":null
    },
    {
        "Model":"BioLinkBERT (base)\nStanford University\n(Yasunaga et al. 2022)",
        "Code":null,
        "Size":"110M",
        "Accuracy (%)":70.2,
        "Macro-F1 (%)":null
    },
    {
        "Model":"BioBERT (multi-phase tuning)\nUniversity of Pittsburgh & Carnegie Mellon University\n(Jin et al. 2019)",
        "Code":null,
        "Size":"110M",
        "Accuracy (%)":68.1,
        "Macro-F1 (%)":52.7
    },
    {
        "Model":"BioELECTRA\nSAAMA AI Research Lab\n(Kanakarajan et al. 2019)",
        "Code":null,
        "Size":"110M",
        "Accuracy (%)":64.0,
        "Macro-F1 (%)":null
    },
    {
        "Model":"PubMedBERT\nMicrosoft Research\n(Gu et al. 2020)",
        "Code":null,
        "Size":"110M",
        "Accuracy (%)":55.8,
        "Macro-F1 (%)":null
    }
]