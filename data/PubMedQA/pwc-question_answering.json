[
    {
        "table_id":7316,
        "row_id":112890,
        "rank":1,
        "method":"Meditron-70B (CoT + SC)",
        "mlmodel":{

        },
        "method_short":"Meditron-70B ",
        "method_details":"CoT + SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-12",
        "metrics":{
            "Accuracy":"81.6"
        },
        "raw_metrics":{
            "Accuracy":81.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1327790,
            "title":"MEDITRON-70B: Scaling Medical Pretraining for Large Language Models",
            "url":"\/paper\/meditron-70b-scaling-medical-pretraining-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88932,
        "rank":2,
        "method":"BioGPT-Large(1.5B)",
        "mlmodel":{

        },
        "method_short":"BioGPT-Large",
        "method_details":"1.5B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-11",
        "metrics":{
            "Accuracy":"81.0"
        },
        "raw_metrics":{
            "Accuracy":81.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1096274,
            "title":"BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
            "url":"\/paper\/biogpt-generative-pre-trained-transformer-for",
            "published":"2022-10-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biogpt-generative-pre-trained-transformer-for\/review\/?hl=88932"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":102921,
        "rank":3,
        "method":"Med-PaLM 2 (5-shot)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"5-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"79.2"
        },
        "raw_metrics":{
            "Accuracy":79.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102921"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88397,
        "rank":4,
        "method":"Flan-PaLM (540B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"Flan-PaLM ",
        "method_details":"540B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"79"
        },
        "raw_metrics":{
            "Accuracy":79.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88397"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":87769,
        "rank":5,
        "method":"BioGPT(345M)",
        "mlmodel":{

        },
        "method_short":"BioGPT",
        "method_details":"345M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-19",
        "metrics":{
            "Accuracy":"78.2"
        },
        "raw_metrics":{
            "Accuracy":78.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1096274,
            "title":"BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
            "url":"\/paper\/biogpt-generative-pre-trained-transformer-for",
            "published":"2022-10-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biogpt-generative-pre-trained-transformer-for\/review\/?hl=87769"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88032,
        "rank":6,
        "method":"Codex 5-shot CoT",
        "mlmodel":{

        },
        "method_short":"Codex 5-shot CoT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-17",
        "metrics":{
            "Accuracy":"78.2"
        },
        "raw_metrics":{
            "Accuracy":78.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1044892,
            "title":"Can large language models reason about medical questions?",
            "url":"\/paper\/can-large-language-models-reason-about",
            "published":"2022-07-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/can-large-language-models-reason-about\/review\/?hl=88032"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88933,
        "rank":7,
        "method":"Human Performance (single annotator)",
        "mlmodel":{

        },
        "method_short":"Human Performance ",
        "method_details":"single annotator",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-13",
        "metrics":{
            "Accuracy":"78.0"
        },
        "raw_metrics":{
            "Accuracy":78.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":153577,
            "title":"PubMedQA: A Dataset for Biomedical Research Question Answering",
            "url":"\/paper\/pubmedqa-a-dataset-for-biomedical-research",
            "published":"2019-09-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pubmedqa-a-dataset-for-biomedical-research\/review\/?hl=88933"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":80266,
        "rank":8,
        "method":"GAL 120B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GAL 120B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"77.6"
        },
        "raw_metrics":{
            "Accuracy":77.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80266"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88395,
        "rank":9,
        "method":"Flan-PaLM (62B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"Flan-PaLM ",
        "method_details":"62B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"77.2"
        },
        "raw_metrics":{
            "Accuracy":77.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88395"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":108174,
        "rank":10,
        "method":"BioMedGPT-10B",
        "mlmodel":{

        },
        "method_short":"BioMedGPT-10B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"76.1"
        },
        "raw_metrics":{
            "Accuracy":76.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265550,
            "title":"BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine",
            "url":"\/paper\/biomedgpt-open-multimodal-generative-pre",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biomedgpt-open-multimodal-generative-pre\/review\/?hl=108174"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88401,
        "rank":11,
        "method":"Flan-PaLM (540B, SC)",
        "mlmodel":{

        },
        "method_short":"Flan-PaLM ",
        "method_details":"540B, SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"75.2"
        },
        "raw_metrics":{
            "Accuracy":75.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88401"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":102923,
        "rank":12,
        "method":"Med-PaLM 2 (ER)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"ER",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"75.0"
        },
        "raw_metrics":{
            "Accuracy":75.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102923"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":102922,
        "rank":13,
        "method":"Med-PaLM 2 (CoT + SC)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"CoT + SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"74.0"
        },
        "raw_metrics":{
            "Accuracy":74.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102922"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":85409,
        "rank":14,
        "method":"BLOOM (zero-shot)",
        "mlmodel":{

        },
        "method_short":"BLOOM ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"73.6"
        },
        "raw_metrics":{
            "Accuracy":73.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85409"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":113000,
        "rank":15,
        "method":"CoT-T5-11B (1024 Shot)",
        "mlmodel":{

        },
        "method_short":"CoT-T5-11B ",
        "method_details":"1024 Shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "Accuracy":"73.42"
        },
        "raw_metrics":{
            "Accuracy":73.42
        },
        "uses_additional_data":false,
        "paper":{
            "id":1214294,
            "title":"The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
            "url":"\/paper\/the-cot-collection-improving-zero-shot-and",
            "published":"2023-05-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/the-cot-collection-improving-zero-shot-and\/review\/?hl=113000"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":50812,
        "rank":16,
        "method":"BioLinkBERT (large)",
        "mlmodel":{

        },
        "method_short":"BioLinkBERT ",
        "method_details":"large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-29",
        "metrics":{
            "Accuracy":"72.2"
        },
        "raw_metrics":{
            "Accuracy":72.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":986102,
            "title":"LinkBERT: Pretraining Language Models with Document Links",
            "url":"\/paper\/linkbert-pretraining-language-models-with",
            "published":"2022-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/linkbert-pretraining-language-models-with\/review\/?hl=50812"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":50813,
        "rank":17,
        "method":"BioLinkBERT (base)",
        "mlmodel":{

        },
        "method_short":"BioLinkBERT ",
        "method_details":"base",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-29",
        "metrics":{
            "Accuracy":"70.2"
        },
        "raw_metrics":{
            "Accuracy":70.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":986102,
            "title":"LinkBERT: Pretraining Language Models with Document Links",
            "url":"\/paper\/linkbert-pretraining-language-models-with",
            "published":"2022-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/linkbert-pretraining-language-models-with\/review\/?hl=50813"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":85408,
        "rank":18,
        "method":"OPT (zero-shot)",
        "mlmodel":{

        },
        "method_short":"OPT ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"70.2"
        },
        "raw_metrics":{
            "Accuracy":70.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85408"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88393,
        "rank":19,
        "method":"Flan-PaLM (8B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"Flan-PaLM ",
        "method_details":"8B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"67.6"
        },
        "raw_metrics":{
            "Accuracy":67.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88393"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":36494,
        "rank":20,
        "method":"BioELECTRA uncased",
        "mlmodel":{

        },
        "method_short":"BioELECTRA uncased",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-11",
        "metrics":{
            "Accuracy":"64.2"
        },
        "raw_metrics":{
            "Accuracy":64.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":821040,
            "title":"BioELECTRA:Pretrained Biomedical text Encoder using Discriminators",
            "url":"\/paper\/bioelectra-pretrained-biomedical-text-encoder",
            "published":"2021-06-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88394,
        "rank":21,
        "method":"PaLM (62B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"62B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"57.8"
        },
        "raw_metrics":{
            "Accuracy":57.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88394"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":27970,
        "rank":22,
        "method":"PubMedBERT uncased",
        "mlmodel":{

        },
        "method_short":"PubMedBERT uncased",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-31",
        "metrics":{
            "Accuracy":"55.84"
        },
        "raw_metrics":{
            "Accuracy":55.84
        },
        "uses_additional_data":false,
        "paper":{
            "id":211372,
            "title":"Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing",
            "url":"\/paper\/domain-specific-language-model-pretraining",
            "published":"2020-07-31T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/domain-specific-language-model-pretraining\/review\/?hl=27970"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88396,
        "rank":23,
        "method":"PaLM (540B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"540B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"55"
        },
        "raw_metrics":{
            "Accuracy":55.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88396"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":7316,
        "row_id":88392,
        "rank":24,
        "method":"PaLM (8B, Few-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"8B, Few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"34"
        },
        "raw_metrics":{
            "Accuracy":34.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88392"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]