[
    {
        "table_id":1223,
        "row_id":100259,
        "rank":1,
        "method":"VideoMAE V2-g",
        "mlmodel":{

        },
        "method_short":"VideoMAE V2-g",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-29",
        "metrics":{
            "3-fold Accuracy":"99.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":99.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1182705,
            "title":"VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking",
            "url":"\/paper\/videomae-v2-scaling-video-masked-autoencoders",
            "published":"2023-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/videomae-v2-scaling-video-masked-autoencoders\/review\/?hl=100259"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":112955,
        "rank":2,
        "method":"OmniVec",
        "mlmodel":{

        },
        "method_short":"OmniVec",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-07",
        "metrics":{
            "3-fold Accuracy":"99.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":99.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1319233,
            "title":"OmniVec: Learning robust representations with cross modal sharing",
            "url":"\/paper\/omnivec-learning-robust-representations-with",
            "published":"2023-11-07T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/omnivec-learning-robust-representations-with\/review\/?hl=112955"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":101055,
        "rank":3,
        "method":"BIKE",
        "mlmodel":{

        },
        "method_short":"BIKE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-31",
        "metrics":{
            "3-fold Accuracy":"98.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.9,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1136846,
            "title":"Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models",
            "url":"\/paper\/bidirectional-cross-modal-knowledge",
            "published":"2022-12-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bidirectional-cross-modal-knowledge\/review\/?hl=101055"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":24018,
        "rank":4,
        "method":"SMART",
        "mlmodel":{

        },
        "method_short":"SMART",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-19",
        "metrics":{
            "3-fold Accuracy":"98.64",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.64,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":730142,
            "title":"SMART Frame Selection for Action Recognition",
            "url":"\/paper\/smart-frame-selection-for-action-recognition",
            "published":"2020-12-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/smart-frame-selection-for-action-recognition\/review\/?hl=24018"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":21649,
        "rank":5,
        "method":"OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)",
        "mlmodel":{

        },
        "method_short":"OmniSource ",
        "method_details":"SlowOnly-8x8-R101-RGB + I3D-Flow",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-03-29",
        "metrics":{
            "3-fold Accuracy":"98.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":188764,
            "title":"Omni-sourced Webly-supervised Learning for Video Recognition",
            "url":"\/paper\/omni-sourced-webly-supervised-learning-for",
            "published":"2020-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/omni-sourced-webly-supervised-learning-for\/review\/?hl=21649"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":23855,
        "rank":6,
        "method":"PERF-Net (multi-distilled S3D)",
        "mlmodel":{

        },
        "method_short":"PERF-Net ",
        "method_details":"multi-distilled S3D",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-09-28",
        "metrics":{
            "3-fold Accuracy":"98.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":219654,
            "title":"PERF-Net: Pose Empowered RGB-Flow Net",
            "url":"\/paper\/perf-net-pose-empowered-rgb-flow-net",
            "published":"2020-09-28T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/perf-net-pose-empowered-rgb-flow-net\/review\/?hl=23855"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":109643,
        "rank":7,
        "method":"ZeroI2V ViT-L\/14",
        "mlmodel":{

        },
        "method_short":"ZeroI2V ViT-L\/14",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-02",
        "metrics":{
            "3-fold Accuracy":"98.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1292264,
            "title":"ZeroI2V: Zero-Cost Adaptation of Pre-trained Transformers from Image to Video",
            "url":"\/paper\/zeroi2v-zero-cost-adaptation-of-pre-trained",
            "published":"2023-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/zeroi2v-zero-cost-adaptation-of-pre-trained\/review\/?hl=109643"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12926,
        "rank":8,
        "method":"LGD-3D Two-stream",
        "mlmodel":{

        },
        "method_short":"LGD-3D Two-stream",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "3-fold Accuracy":"98.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":142601,
            "title":"Learning Spatio-Temporal Representation with Local and Global Diffusion",
            "url":"\/paper\/learning-spatio-temporal-representation-with-3",
            "published":"2019-06-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/learning-spatio-temporal-representation-with-3\/review\/?hl=12926"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":83617,
        "rank":9,
        "method":"Text4Vis",
        "mlmodel":{

        },
        "method_short":"Text4Vis",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-04",
        "metrics":{
            "3-fold Accuracy":"98.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1037200,
            "title":"Revisiting Classifier: Transferring Vision-Language Models for Video Recognition",
            "url":"\/paper\/transferring-textual-knowledge-for-visual",
            "published":"2022-07-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/transferring-textual-knowledge-for-visual\/review\/?hl=83617"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27753,
        "rank":10,
        "method":"Two-Stream I3D (Imagenet+Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"Two-Stream I3D ",
        "method_details":"Imagenet+Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"98.0",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":98.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27753"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6673,
        "rank":11,
        "method":"MARS+RGB+Flow (64 frames, Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"MARS+RGB+Flow ",
        "method_details":"64 frames, Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-01",
        "metrics":{
            "3-fold Accuracy":"97.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.8,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":116002,
            "title":"MARS: Motion-Augmented RGB Stream for Action Recognition",
            "url":"\/paper\/mars-motion-augmented-rgb-stream-for-action",
            "published":"2019-06-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12928,
        "rank":12,
        "method":"HATNet (32 frames)",
        "mlmodel":{

        },
        "method_short":"HATNet ",
        "method_details":"32 frames",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-25",
        "metrics":{
            "3-fold Accuracy":"97.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":112715,
            "title":"Large Scale Holistic Video Understanding",
            "url":"\/paper\/holistic-large-scale-video-understanding",
            "published":"2019-04-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/holistic-large-scale-video-understanding\/review\/?hl=12928"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27759,
        "rank":13,
        "method":"Two-Stream I3D (Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"Two-Stream I3D ",
        "method_details":"Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"97.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27759"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":25283,
        "rank":14,
        "method":"BubbleNET",
        "mlmodel":{

        },
        "method_short":"BubbleNET",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-30",
        "metrics":{
            "3-fold Accuracy":"97.62",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.62,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":743563,
            "title":"Bubblenet: A Disperse Recurrent Structure To Recognize Activities",
            "url":"\/paper\/bubblenet-a-disperse-recurrent-structure-to",
            "published":"2020-10-30T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27820,
        "rank":15,
        "method":"D3D + D3D",
        "mlmodel":{

        },
        "method_short":"D3D + D3D",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-19",
        "metrics":{
            "3-fold Accuracy":"97.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":65765,
            "title":"D3D: Distilled 3D Networks for Video Action Recognition",
            "url":"\/paper\/d3d-distilled-3d-networks-for-video-action",
            "published":"2018-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/d3d-distilled-3d-networks-for-video-action\/review\/?hl=27820"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":40705,
        "rank":16,
        "method":"BQN",
        "mlmodel":{

        },
        "method_short":"BQN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-29",
        "metrics":{
            "3-fold Accuracy":"97.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":758504,
            "title":"Busy-Quiet Video Disentangling for Video Classification",
            "url":"\/paper\/video-classification-with-finecoarse-networks",
            "published":"2021-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/video-classification-with-finecoarse-networks\/review\/?hl=40705"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6689,
        "rank":17,
        "method":"CCS + TSN (ImageNet+Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"CCS + TSN ",
        "method_details":"ImageNet+Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-27",
        "metrics":{
            "3-fold Accuracy":"97.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.4,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":151253,
            "title":"Cooperative Cross-Stream Network for Discriminative Action Representation",
            "url":"\/paper\/cooperative-cross-stream-network-for",
            "published":"2019-08-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/cooperative-cross-stream-network-for\/review\/?hl=6689"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27740,
        "rank":18,
        "method":"R[2+1]D-TwoStream (Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-TwoStream ",
        "method_details":"Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"97.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.3,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6655,
        "rank":19,
        "method":"Multi-stream I3D ",
        "mlmodel":{

        },
        "method_short":"Multi-stream I3D ",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-03-20",
        "metrics":{
            "3-fold Accuracy":"97.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151908,
            "title":"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition",
            "url":"\/paper\/contextual-action-cues-from-camera-sensor-for",
            "published":"2019-03-20T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":8209,
        "rank":20,
        "method":"Hidden Two-Stream",
        "mlmodel":{

        },
        "method_short":"Hidden Two-Stream",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-04-02",
        "metrics":{
            "3-fold Accuracy":"97.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":15944,
            "title":"Hidden Two-Stream Convolutional Networks for Action Recognition",
            "url":"\/paper\/hidden-two-stream-convolutional-networks-for",
            "published":"2017-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/hidden-two-stream-convolutional-networks-for\/review\/?hl=8209"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27818,
        "rank":21,
        "method":"D3D (Kinetics-600 pretraining)",
        "mlmodel":{

        },
        "method_short":"D3D ",
        "method_details":"Kinetics-600 pretraining",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-19",
        "metrics":{
            "3-fold Accuracy":"97.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.1,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":65765,
            "title":"D3D: Distilled 3D Networks for Video Action Recognition",
            "url":"\/paper\/d3d-distilled-3d-networks-for-video-action",
            "published":"2018-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/d3d-distilled-3d-networks-for-video-action\/review\/?hl=27818"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27816,
        "rank":22,
        "method":"D3D (Kinetics-400 pretraining)",
        "mlmodel":{

        },
        "method_short":"D3D ",
        "method_details":"Kinetics-400 pretraining",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-19",
        "metrics":{
            "3-fold Accuracy":"97",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":65765,
            "title":"D3D: Distilled 3D Networks for Video Action Recognition",
            "url":"\/paper\/d3d-distilled-3d-networks-for-video-action",
            "published":"2018-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/d3d-distilled-3d-networks-for-video-action\/review\/?hl=27816"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27870,
        "rank":23,
        "method":"LGD-3D RGB",
        "mlmodel":{

        },
        "method_short":"LGD-3D RGB",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "3-fold Accuracy":"97",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":142601,
            "title":"Learning Spatio-Temporal Representation with Local and Global Diffusion",
            "url":"\/paper\/learning-spatio-temporal-representation-with-3",
            "published":"2019-06-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/learning-spatio-temporal-representation-with-3\/review\/?hl=27870"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":28822,
        "rank":24,
        "method":"STAM-32 (ImageNet\/Kinetics pretraining)",
        "mlmodel":{

        },
        "method_short":"STAM-32 ",
        "method_details":"ImageNet\/Kinetics pretraining",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-25",
        "metrics":{
            "3-fold Accuracy":"97",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":97.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":757279,
            "title":"An Image is Worth 16x16 Words, What is a Video Worth?",
            "url":"\/paper\/an-image-is-worth-16x16-words-what-is-a-video",
            "published":"2021-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-image-is-worth-16x16-words-what-is-a-video\/review\/?hl=28822"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":28824,
        "rank":25,
        "method":"FASTER32",
        "mlmodel":{

        },
        "method_short":"FASTER32",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-10",
        "metrics":{
            "3-fold Accuracy":"96.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.9,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":142365,
            "title":"FASTER Recurrent Networks for Efficient Video Classification",
            "url":"\/paper\/faster-recurrent-networks-for-video",
            "published":"2019-06-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/faster-recurrent-networks-for-video\/review\/?hl=28824"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27742,
        "rank":26,
        "method":"R[2+1]D-RGB (Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-RGB ",
        "method_details":"Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"96.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.8,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27772,
        "rank":27,
        "method":"S3D-G (ImageNet, Kinetics-400 pretrained)",
        "mlmodel":{

        },
        "method_short":"S3D-G ",
        "method_details":"ImageNet, Kinetics-400 pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-12-13",
        "metrics":{
            "3-fold Accuracy":"96.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.8,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":13041,
            "title":"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification",
            "url":"\/paper\/rethinking-spatiotemporal-feature-learning",
            "published":"2017-12-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/rethinking-spatiotemporal-feature-learning\/review\/?hl=27772"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27872,
        "rank":28,
        "method":"LGD-3D Flow",
        "mlmodel":{

        },
        "method_short":"LGD-3D Flow",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "3-fold Accuracy":"96.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":142601,
            "title":"Learning Spatio-Temporal Representation with Local and Global Diffusion",
            "url":"\/paper\/learning-spatio-temporal-representation-with-3",
            "published":"2019-06-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/learning-spatio-temporal-representation-with-3\/review\/?hl=27872"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27751,
        "rank":29,
        "method":"Flow-I3D (Imagenet+Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"Flow-I3D ",
        "method_details":"Imagenet+Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"96.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.7,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27751"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":31465,
        "rank":30,
        "method":"VidTr-L",
        "mlmodel":{

        },
        "method_short":"VidTr-L",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-23",
        "metrics":{
            "3-fold Accuracy":"96.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":787687,
            "title":"VidTr: Video Transformer Without Convolutions",
            "url":"\/paper\/vidtr-video-transformer-without-convolutions",
            "published":"2021-04-23T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/vidtr-video-transformer-without-convolutions\/review\/?hl=31465"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6670,
        "rank":31,
        "method":"CMA iter1-S",
        "mlmodel":{

        },
        "method_short":"CMA iter1-S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-01",
        "metrics":{
            "3-fold Accuracy":"96.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":148881,
            "title":"Two-Stream Video Classification with Cross-Modality Attention",
            "url":"\/paper\/two-stream-video-classification-with-cross",
            "published":"2019-08-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/two-stream-video-classification-with-cross\/review\/?hl=6670"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27757,
        "rank":32,
        "method":"Flow-I3D (Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"Flow-I3D ",
        "method_details":"Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"96.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.5,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27757"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":49530,
        "rank":33,
        "method":"I3D RGB + DMC-Net (I3D)",
        "mlmodel":{

        },
        "method_short":"I3D RGB + DMC-Net ",
        "method_details":"I3D",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-11",
        "metrics":{
            "3-fold Accuracy":"96.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":87278,
            "title":"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition",
            "url":"\/paper\/dmc-net-generating-discriminative-motion-cues",
            "published":"2019-01-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/dmc-net-generating-discriminative-motion-cues\/review\/?hl=49530"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27792,
        "rank":34,
        "method":"A2-Net (ResNet-50)",
        "mlmodel":{

        },
        "method_short":"A2-Net ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-10-27",
        "metrics":{
            "3-fold Accuracy":"96.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":60633,
            "title":"$A^2$-Nets: Double Attention Networks",
            "url":"\/paper\/a2-nets-double-attention-networks",
            "published":"2018-10-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/a2-nets-double-attention-networks\/review\/?hl=27792"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":10924,
        "rank":35,
        "method":"MF-Net, RGB only (ImageNet+Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"MF-Net, RGB only ",
        "method_details":"ImageNet+Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-07-30",
        "metrics":{
            "3-fold Accuracy":"96.0",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":53819,
            "title":"Multi-Fiber Networks for Video Recognition",
            "url":"\/paper\/multi-fiber-networks-for-video-recognition",
            "published":"2018-07-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/multi-fiber-networks-for-video-recognition\/review\/?hl=10924"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12929,
        "rank":36,
        "method":"Optical Flow Guided Feature",
        "mlmodel":{

        },
        "method_short":"Optical Flow Guided Feature",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-29",
        "metrics":{
            "3-fold Accuracy":"96",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":96.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":13814,
            "title":"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition",
            "url":"\/paper\/optical-flow-guided-feature-a-fast-and-robust",
            "published":"2017-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/optical-flow-guided-feature-a-fast-and-robust\/review\/?hl=12929"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6674,
        "rank":37,
        "method":"MARS+RGB+Flow (16 frames)",
        "mlmodel":{

        },
        "method_short":"MARS+RGB+Flow ",
        "method_details":"16 frames",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-01",
        "metrics":{
            "3-fold Accuracy":"95.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":116002,
            "title":"MARS: Motion-Augmented RGB Stream for Action Recognition",
            "url":"\/paper\/mars-motion-augmented-rgb-stream-for-action",
            "published":"2019-06-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6587,
        "rank":38,
        "method":"Prob-Distill",
        "mlmodel":{

        },
        "method_short":"Prob-Distill",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-05",
        "metrics":{
            "3-fold Accuracy":"95.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":111002,
            "title":"Attention Distillation for Learning Video Representations",
            "url":"\/paper\/paying-more-attention-to-motion-attention",
            "published":"2019-04-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/paying-more-attention-to-motion-attention\/review\/?hl=6587"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27749,
        "rank":39,
        "method":"RGB-I3D (Imagenet+Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"RGB-I3D ",
        "method_details":"Imagenet+Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"95.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27749"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27741,
        "rank":40,
        "method":"R[2+1]D-Flow (Kinetics pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-Flow ",
        "method_details":"Kinetics pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"95.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.5,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27832,
        "rank":41,
        "method":"TVNet+IDT",
        "mlmodel":{

        },
        "method_short":"TVNet+IDT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-04-02",
        "metrics":{
            "3-fold Accuracy":"95.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":6928,
            "title":"End-to-End Learning of Motion Representation for Video Understanding",
            "url":"\/paper\/end-to-end-learning-of-motion-representation",
            "published":"2018-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/end-to-end-learning-of-motion-representation\/review\/?hl=27832"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":18464,
        "rank":42,
        "method":"TesNet (ImageNet pretrained)",
        "mlmodel":{

        },
        "method_short":"TesNet ",
        "method_details":"ImageNet pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-11",
        "metrics":{
            "3-fold Accuracy":"95.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.2,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":183114,
            "title":"Learning spatio-temporal representations with temporal squeeze pooling",
            "url":"\/paper\/learning-spatio-temporal-representations-with",
            "published":"2020-02-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/learning-spatio-temporal-representations-with\/review\/?hl=18464"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6538,
        "rank":43,
        "method":"I3D-LSTM",
        "mlmodel":{

        },
        "method_short":"I3D-LSTM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-09",
        "metrics":{
            "3-fold Accuracy":"95.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151892,
            "title":"I3D-LSTM: A New Model for Human Action Recognition",
            "url":"\/paper\/i3d-lstm-a-new-model-for-human-action",
            "published":"2019-08-09T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27755,
        "rank":44,
        "method":"RGB-I3D (Kinetics pre-training)",
        "mlmodel":{

        },
        "method_short":"RGB-I3D ",
        "method_details":"Kinetics pre-training",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"95.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.1,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=27755"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27737,
        "rank":45,
        "method":"R[2+1]D-TwoStream (Sports-1M pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-TwoStream ",
        "method_details":"Sports-1M pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"95",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":95.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":38834,
        "rank":46,
        "method":"X3D MobileNet-V3 LGD-GC",
        "mlmodel":{

        },
        "method_short":"X3D MobileNet-V3 LGD-GC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-08-30",
        "metrics":{
            "3-fold Accuracy":"94.85",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.85,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":858450,
            "title":"LIGAR: Lightweight General-purpose Action Recognition",
            "url":"\/paper\/ligar-lightweight-general-purpose-action",
            "published":"2021-08-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27766,
        "rank":47,
        "method":"ST-ResNet + IDT",
        "mlmodel":{

        },
        "method_short":"ST-ResNet + IDT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-11-07",
        "metrics":{
            "3-fold Accuracy":"94.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":28966,
            "title":"Spatiotemporal Residual Networks for Video Action Recognition",
            "url":"\/paper\/spatiotemporal-residual-networks-for-video",
            "published":"2016-11-07T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6535,
        "rank":48,
        "method":"ResNeXt-101 (64f)",
        "mlmodel":{

        },
        "method_short":"ResNeXt-101 ",
        "method_details":"64f",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-27",
        "metrics":{
            "3-fold Accuracy":"94.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":6944,
            "title":"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?",
            "url":"\/paper\/can-spatiotemporal-3d-cnns-retrace-the",
            "published":"2017-11-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/can-spatiotemporal-3d-cnns-retrace-the\/review\/?hl=6535"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6654,
        "rank":49,
        "method":"R-STAN-101",
        "mlmodel":{

        },
        "method_short":"R-STAN-101",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-19",
        "metrics":{
            "3-fold Accuracy":"94.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151907,
            "title":"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition",
            "url":"\/paper\/r-stan-residual-spatial-temporal-attention",
            "published":"2019-06-19T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":7135,
        "rank":50,
        "method":"TSN+TSM",
        "mlmodel":{

        },
        "method_short":"TSN+TSM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-09-11",
        "metrics":{
            "3-fold Accuracy":"94.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":56869,
            "title":"Temporal-Spatial Mapping for Action Recognition",
            "url":"\/paper\/temporal-spatial-mapping-for-action",
            "published":"2018-09-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/temporal-spatial-mapping-for-action\/review\/?hl=7135"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27778,
        "rank":51,
        "method":"ARTNet w\/ TSN",
        "mlmodel":{

        },
        "method_short":"ARTNet w\/ TSN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-24",
        "metrics":{
            "3-fold Accuracy":"94.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":4408,
            "title":"Appearance-and-Relation Networks for Video Classification",
            "url":"\/paper\/appearance-and-relation-networks-for-video",
            "published":"2017-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/appearance-and-relation-networks-for-video\/review\/?hl=27778"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27764,
        "rank":52,
        "method":"Temporal Segment Networks",
        "mlmodel":{

        },
        "method_short":"Temporal Segment Networks",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-08-02",
        "metrics":{
            "3-fold Accuracy":"94.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":31692,
            "title":"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition",
            "url":"\/paper\/temporal-segment-networks-towards-good",
            "published":"2016-08-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/temporal-segment-networks-towards-good\/review\/?hl=27764"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12930,
        "rank":53,
        "method":"TS-LSTM",
        "mlmodel":{

        },
        "method_short":"TS-LSTM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-03-30",
        "metrics":{
            "3-fold Accuracy":"94.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":94.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":24666,
            "title":"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition",
            "url":"\/paper\/ts-lstm-and-temporal-inception-exploiting",
            "published":"2017-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ts-lstm-and-temporal-inception-exploiting\/review\/?hl=12930"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":89414,
        "rank":54,
        "method":"SVT (finetune)",
        "mlmodel":{

        },
        "method_short":"SVT ",
        "method_details":"finetune",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-02",
        "metrics":{
            "3-fold Accuracy":"93.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":93.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":924698,
            "title":"Self-supervised Video Transformer",
            "url":"\/paper\/self-supervised-video-transformer",
            "published":"2021-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-video-transformer\/review\/?hl=89414"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27739,
        "rank":55,
        "method":"R[2+1]D-RGB (Sports-1M pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-RGB ",
        "method_details":"Sports-1M pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"93.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":93.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6537,
        "rank":56,
        "method":"Two-stream I3D",
        "mlmodel":{

        },
        "method_short":"Two-stream I3D",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-22",
        "metrics":{
            "3-fold Accuracy":"93.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":93.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10430,
            "title":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
            "url":"\/paper\/quo-vadis-action-recognition-a-new-model-and",
            "published":"2017-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/quo-vadis-action-recognition-a-new-model-and\/review\/?hl=6537"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27738,
        "rank":57,
        "method":"R[2+1]D-Flow (Sports-1M pretrained)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D-Flow ",
        "method_details":"Sports-1M pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-30",
        "metrics":{
            "3-fold Accuracy":"93.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":93.3,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":6204,
            "title":"A Closer Look at Spatiotemporal Convolutions for Action Recognition",
            "url":"\/paper\/a-closer-look-at-spatiotemporal-convolutions",
            "published":"2017-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":35420,
        "rank":58,
        "method":"VIMPAC",
        "mlmodel":{

        },
        "method_short":"VIMPAC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-21",
        "metrics":{
            "3-fold Accuracy":"92.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":92.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":821705,
            "title":"VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning",
            "url":"\/paper\/vimpac-video-pre-training-via-masked-token",
            "published":"2021-06-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vimpac-video-pre-training-via-masked-token\/review\/?hl=35420"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12931,
        "rank":59,
        "method":"S:VGG-16, T:VGG-16 (ImageNet pretrain)",
        "mlmodel":{

        },
        "method_short":"S:VGG-16, T:VGG-16 ",
        "method_details":"ImageNet pretrain",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-04-22",
        "metrics":{
            "3-fold Accuracy":"92.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":92.5,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":30270,
            "title":"Convolutional Two-Stream Network Fusion for Video Action Recognition",
            "url":"\/paper\/convolutional-two-stream-network-fusion-for",
            "published":"2016-04-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/convolutional-two-stream-network-fusion-for\/review\/?hl=12931"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":49529,
        "rank":60,
        "method":"DMC-Net (I3D)",
        "mlmodel":{

        },
        "method_short":"DMC-Net ",
        "method_details":"I3D",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-11",
        "metrics":{
            "3-fold Accuracy":"92.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":92.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":87278,
            "title":"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition",
            "url":"\/paper\/dmc-net-generating-discriminative-motion-cues",
            "published":"2019-01-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/dmc-net-generating-discriminative-motion-cues\/review\/?hl=49529"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12932,
        "rank":61,
        "method":"two-in-one two stream",
        "mlmodel":{

        },
        "method_short":"two-in-one two stream",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-01",
        "metrics":{
            "3-fold Accuracy":"92",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":92.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":110055,
            "title":"Dance with Flow: Two-in-One Stream Action Detection",
            "url":"\/paper\/dance-with-flow-two-in-one-stream-action",
            "published":"2019-04-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12933,
        "rank":62,
        "method":"LTC",
        "mlmodel":{

        },
        "method_short":"LTC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-04-15",
        "metrics":{
            "3-fold Accuracy":"91.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":22103,
            "title":"Long-term Temporal Convolutions for Action Recognition",
            "url":"\/paper\/long-term-temporal-convolutions-for-action",
            "published":"2016-04-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/long-term-temporal-convolutions-for-action\/review\/?hl=12933"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6653,
        "rank":63,
        "method":"R-STAN-50",
        "mlmodel":{

        },
        "method_short":"R-STAN-50",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-19",
        "metrics":{
            "3-fold Accuracy":"91.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151907,
            "title":"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition",
            "url":"\/paper\/r-stan-residual-spatial-temporal-attention",
            "published":"2019-06-19T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27762,
        "rank":64,
        "method":"TDD + IDT",
        "mlmodel":{

        },
        "method_short":"TDD + IDT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-05-19",
        "metrics":{
            "3-fold Accuracy":"91.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":40603,
            "title":"Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors",
            "url":"\/paper\/action-recognition-with-trajectory-pooled",
            "published":"2015-05-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/action-recognition-with-trajectory-pooled\/review\/?hl=27762"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12934,
        "rank":65,
        "method":"Very deep two-stream ConvNet",
        "mlmodel":{

        },
        "method_short":"Very deep two-stream ConvNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-07-08",
        "metrics":{
            "3-fold Accuracy":"91.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":39721,
            "title":"Towards Good Practices for Very Deep Two-Stream ConvNets",
            "url":"\/paper\/towards-good-practices-for-very-deep-two",
            "published":"2015-07-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/towards-good-practices-for-very-deep-two\/review\/?hl=12934"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":39194,
        "rank":66,
        "method":"3D ResNeXt-101 + Confidence Distillation",
        "mlmodel":{

        },
        "method_short":"3D ResNeXt-101 + Confidence Distillation",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-05",
        "metrics":{
            "3-fold Accuracy":"91.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":861909,
            "title":"Efficient Action Recognition Using Confidence Distillation",
            "url":"\/paper\/efficient-action-recognition-using-confidence",
            "published":"2021-09-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/efficient-action-recognition-using-confidence\/review\/?hl=39194"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6548,
        "rank":67,
        "method":"MR Two-Sream R-CNN",
        "mlmodel":{

        },
        "method_short":"MR Two-Sream R-CNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-09-17",
        "metrics":{
            "3-fold Accuracy":"91.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":91.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151894,
            "title":"Multi-region two-stream R-CNN for action detection",
            "url":"\/paper\/multi-region-two-stream-r-cnn-for-action",
            "published":"2016-09-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":89413,
        "rank":68,
        "method":"SVT (linear)",
        "mlmodel":{

        },
        "method_short":"SVT ",
        "method_details":"linear",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-02",
        "metrics":{
            "3-fold Accuracy":"90.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":90.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":924698,
            "title":"Self-supervised Video Transformer",
            "url":"\/paper\/self-supervised-video-transformer",
            "published":"2021-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-video-transformer\/review\/?hl=89413"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27760,
        "rank":69,
        "method":"Dynamic Image Networks + IDT",
        "mlmodel":{

        },
        "method_short":"Dynamic Image Networks + IDT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-06-01",
        "metrics":{
            "3-fold Accuracy":"89.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":89.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":90406,
            "title":"Dynamic Image Networks for Action Recognition",
            "url":"\/paper\/dynamic-image-networks-for-action-recognition",
            "published":"2016-06-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12935,
        "rank":70,
        "method":"Two-stream+LSTM",
        "mlmodel":{

        },
        "method_short":"Two-stream+LSTM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-03-31",
        "metrics":{
            "3-fold Accuracy":"88.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":88.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":41259,
            "title":"Beyond Short Snippets: Deep Networks for Video Classification",
            "url":"\/paper\/beyond-short-snippets-deep-networks-for-video",
            "published":"2015-03-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/beyond-short-snippets-deep-networks-for-video\/review\/?hl=12935"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12936,
        "rank":71,
        "method":"P3D (ImageNet + Sports1M)",
        "mlmodel":{

        },
        "method_short":"P3D ",
        "method_details":"ImageNet + Sports1M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-28",
        "metrics":{
            "3-fold Accuracy":"88.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":88.6,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":13943,
            "title":"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks",
            "url":"\/paper\/learning-spatio-temporal-representation-with",
            "published":"2017-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-spatio-temporal-representation-with\/review\/?hl=12936"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12937,
        "rank":72,
        "method":"Two-Stream (ImageNet pretrained)",
        "mlmodel":{

        },
        "method_short":"Two-Stream ",
        "method_details":"ImageNet pretrained",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-06-09",
        "metrics":{
            "3-fold Accuracy":"88.0",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":88.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":43357,
            "title":"Two-Stream Convolutional Networks for Action Recognition in Videos",
            "url":"\/paper\/two-stream-convolutional-networks-for-action",
            "published":"2014-06-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/two-stream-convolutional-networks-for-action\/review\/?hl=12937"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27831,
        "rank":73,
        "method":"MV-CNN",
        "mlmodel":{

        },
        "method_short":"MV-CNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-04-26",
        "metrics":{
            "3-fold Accuracy":"86.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":86.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":34371,
            "title":"Real-time Action Recognition with Enhanced Motion Vector CNNs",
            "url":"\/paper\/real-time-action-recognition-with-enhanced",
            "published":"2016-04-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/real-time-action-recognition-with-enhanced\/review\/?hl=27831"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":108643,
        "rank":74,
        "method":"Dynamics 2 for DenseNet-201 Transformer",
        "mlmodel":{

        },
        "method_short":"Dynamics 2 for DenseNet-201 Transformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-17",
        "metrics":{
            "3-fold Accuracy":"86.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":86.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1160382,
            "title":"Video Action Recognition Collaborative Learning with Dynamics via PSO-ConvNet Transformer",
            "url":"\/paper\/video-action-recognition-collaborative",
            "published":"2023-02-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/video-action-recognition-collaborative\/review\/?hl=108643"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6610,
        "rank":75,
        "method":"R(2+1)D-18 (DistInit pretraining)",
        "mlmodel":{

        },
        "method_short":"R",
        "method_details":"2+1",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-26",
        "metrics":{
            "3-fold Accuracy":"85.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":85.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88322,
            "title":"DistInit: Learning Video Representations Without a Single Labeled Video",
            "url":"\/paper\/distinit-learning-video-representations",
            "published":"2019-01-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/distinit-learning-video-representations\/review\/?hl=6610"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27776,
        "rank":76,
        "method":"Res3D",
        "mlmodel":{

        },
        "method_short":"Res3D",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-08-16",
        "metrics":{
            "3-fold Accuracy":"85.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":85.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":18716,
            "title":"ConvNet Architecture Search for Spatiotemporal Feature Learning",
            "url":"\/paper\/convnet-architecture-search-for",
            "published":"2017-08-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27829,
        "rank":77,
        "method":"ActionFlowNet",
        "mlmodel":{

        },
        "method_short":"ActionFlowNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-12-09",
        "metrics":{
            "3-fold Accuracy":"83.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":83.9,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10070,
            "title":"ActionFlowNet: Learning Motion Representation for Action Recognition",
            "url":"\/paper\/actionflownet-learning-motion-representation",
            "published":"2016-12-09T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/actionflownet-learning-motion-representation\/review\/?hl=27829"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":12939,
        "rank":78,
        "method":"C3D",
        "mlmodel":{

        },
        "method_short":"C3D",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-02",
        "metrics":{
            "3-fold Accuracy":"82.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":82.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":38344,
            "title":"Learning Spatiotemporal Features with 3D Convolutional Networks",
            "url":"\/paper\/learning-spatiotemporal-features-with-3d",
            "published":"2014-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-spatiotemporal-features-with-3d\/review\/?hl=12939"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":29330,
        "rank":79,
        "method":"HalluciNet (ResNet-50)",
        "mlmodel":{

        },
        "method_short":"HalluciNet ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-10",
        "metrics":{
            "3-fold Accuracy":"79.83",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":79.83,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":176246,
            "title":"HalluciNet-ing Spatiotemporal Representations Using a 2D-CNN",
            "url":"\/paper\/hallucinet-ing-spatiotemporal-representations",
            "published":"2019-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/hallucinet-ing-spatiotemporal-representations\/review\/?hl=29330"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27943,
        "rank":80,
        "method":"R[2+1]D (VideoMoCo)",
        "mlmodel":{

        },
        "method_short":"R[2+1]D ",
        "method_details":"VideoMoCo",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-10",
        "metrics":{
            "3-fold Accuracy":"78.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":78.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":752909,
            "title":"VideoMoCo: Contrastive Video Representation Learning with Temporally Adversarial Examples",
            "url":"\/paper\/videomoco-contrastive-video-representation",
            "published":"2021-03-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/videomoco-contrastive-video-representation\/review\/?hl=27943"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":27941,
        "rank":81,
        "method":"3D-ResNet-18 (VideoMoCo)",
        "mlmodel":{

        },
        "method_short":"3D-ResNet-18 ",
        "method_details":"VideoMoCo",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-10",
        "metrics":{
            "3-fold Accuracy":"74.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":74.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":752909,
            "title":"VideoMoCo: Contrastive Video Representation Learning with Temporally Adversarial Examples",
            "url":"\/paper\/videomoco-contrastive-video-representation",
            "published":"2021-03-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/videomoco-contrastive-video-representation\/review\/?hl=27941"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6533,
        "rank":82,
        "method":"Slow Fusion + Finetune top 3 layers",
        "mlmodel":{

        },
        "method_short":"Slow Fusion + Finetune top 3 layers",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-06-23",
        "metrics":{
            "3-fold Accuracy":"65.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":65.4,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":151891,
            "title":"Large-Scale Video Classification with Convolutional Neural Networks",
            "url":"\/paper\/large-scale-video-classification-with-1",
            "published":"2014-06-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":8162,
        "rank":83,
        "method":"MLGCN",
        "mlmodel":{

        },
        "method_short":"MLGCN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-11",
        "metrics":{
            "3-fold Accuracy":"63.27",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":63.27,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":157084,
            "title":"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition",
            "url":"\/paper\/mlgcn-multi-laplacian-graph-convolutional",
            "published":"2019-09-11T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":27,
                "name":"GCN",
                "color":"#aaa018"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6632,
        "rank":84,
        "method":"CD-UAR",
        "mlmodel":{

        },
        "method_short":"CD-UAR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-03-22",
        "metrics":{
            "3-fold Accuracy":"42.5",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":42.5,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":7719,
            "title":"Towards Universal Representation for Unseen Action Recognition",
            "url":"\/paper\/towards-universal-representation-for-unseen",
            "published":"2018-03-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-universal-representation-for-unseen\/review\/?hl=6632"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":30139,
        "rank":85,
        "method":"SL",
        "mlmodel":{

        },
        "method_short":"SL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "3-fold Accuracy":"35.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":35.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":6534,
        "rank":86,
        "method":"I3D + PoTion",
        "mlmodel":{

        },
        "method_short":"I3D + PoTion",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-06-01",
        "metrics":{
            "3-fold Accuracy":"29.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "3-fold Accuracy":29.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":81725,
            "title":"PoTion: Pose MoTion Representation for Action Recognition",
            "url":"\/paper\/potion-pose-motion-representation-for-action",
            "published":"2018-06-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1223,
        "row_id":80694,
        "rank":87,
        "method":"R3D-18",
        "mlmodel":{

        },
        "method_short":"R3D-18",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-05",
        "metrics":{
            "3-fold Accuracy":null,
            "Accuracy":"73.16"
        },
        "raw_metrics":{
            "3-fold Accuracy":null,
            "Accuracy":73.16
        },
        "uses_additional_data":false,
        "paper":{
            "id":1038170,
            "title":"Federated Self-supervised Learning for Video Understanding",
            "url":"\/paper\/federated-self-supervised-learning-for-video",
            "published":"2022-07-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/federated-self-supervised-learning-for-video\/review\/?hl=80694"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]