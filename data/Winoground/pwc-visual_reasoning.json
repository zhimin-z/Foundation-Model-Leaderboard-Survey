[
    {
        "table_id":19095,
        "row_id":113468,
        "rank":1,
        "Model":"GPT-4V (CoT, pick b\/w two options)",
        "mlmodel":{

        },
        "method_short":"GPT-4V ",
        "method_details":"CoT, pick b\/w two options",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-15",
        "metrics":{
            "Text Score":"75.25",
            "Image Score":"68.75",
            "Group Score":"58.75"
        },
        "raw_metrics":{
            "Text Score":75.25,
            "Image Score":68.75,
            "Group Score":58.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1321419,
            "title":"The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task",
            "url":"\/paper\/the-role-of-chain-of-thought-in-complex",
            "published":"2023-11-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/the-role-of-chain-of-thought-in-complex\/review\/?hl=113468"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113467,
        "rank":2,
        "Model":"GPT-4V (pick b\/w two options)",
        "mlmodel":{

        },
        "method_short":"GPT-4V ",
        "method_details":"pick b\/w two options",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-15",
        "metrics":{
            "Text Score":"69.25",
            "Image Score":"46.25",
            "Group Score":"39.25"
        },
        "raw_metrics":{
            "Text Score":69.25,
            "Image Score":46.25,
            "Group Score":39.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1321419,
            "title":"The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task",
            "url":"\/paper\/the-role-of-chain-of-thought-in-complex",
            "published":"2023-11-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/the-role-of-chain-of-thought-in-complex\/review\/?hl=113467"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113431,
        "rank":3,
        "Model":"FIBER (EqSim)",
        "mlmodel":{

        },
        "method_short":"FIBER ",
        "method_details":"EqSim",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"51.5",
            "Image Score":"32.00",
            "Group Score":"27.5"
        },
        "raw_metrics":{
            "Text Score":51.5,
            "Image Score":32.0,
            "Group Score":27.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113431"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113430,
        "rank":4,
        "Model":"FIBER (finetuned, Flickr30k)",
        "mlmodel":{

        },
        "method_short":"FIBER ",
        "method_details":"finetuned, Flickr30k",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"51.25",
            "Image Score":"26.50",
            "Group Score":"23.00"
        },
        "raw_metrics":{
            "Text Score":51.25,
            "Image Score":26.5,
            "Group Score":23.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113430"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":104766,
        "rank":5,
        "Model":"VQ2",
        "mlmodel":{

        },
        "method_short":"VQ2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"47",
            "Image Score":"42.2",
            "Group Score":"30.5"
        },
        "raw_metrics":{
            "Text Score":47.0,
            "Image Score":42.2,
            "Group Score":30.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113462,
        "rank":6,
        "Model":"X-VLM 16M",
        "mlmodel":{

        },
        "method_short":"X-VLM 16M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"46.7",
            "Image Score":"24.5",
            "Group Score":"21.2"
        },
        "raw_metrics":{
            "Text Score":46.7,
            "Image Score":24.5,
            "Group Score":21.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113462"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":104769,
        "rank":7,
        "Model":"PaLI (ft SNLI-VE + Synthetic Data)",
        "mlmodel":{

        },
        "method_short":"PaLI ",
        "method_details":"ft SNLI-VE + Synthetic Data",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"46.5",
            "Image Score":"38",
            "Group Score":"28.75"
        },
        "raw_metrics":{
            "Text Score":46.5,
            "Image Score":38.0,
            "Group Score":28.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113427,
        "rank":8,
        "Model":"FIBER",
        "mlmodel":{

        },
        "method_short":"FIBER",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"46.25",
            "Image Score":"25.75",
            "Group Score":"22.25"
        },
        "raw_metrics":{
            "Text Score":46.25,
            "Image Score":25.75,
            "Group Score":22.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113427"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113466,
        "rank":9,
        "Model":"MMICL (FLAN-T5-XXL)",
        "mlmodel":{

        },
        "method_short":"MMICL ",
        "method_details":"FLAN-T5-XXL",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-14",
        "metrics":{
            "Text Score":"45.50",
            "Image Score":"44.99",
            "Group Score":"43.00"
        },
        "raw_metrics":{
            "Text Score":45.5,
            "Image Score":44.99,
            "Group Score":43.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1280779,
            "title":"MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning",
            "url":"\/paper\/mmicl-empowering-vision-language-model-with",
            "published":"2023-09-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mmicl-empowering-vision-language-model-with\/review\/?hl=113466"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113440,
        "rank":10,
        "Model":"PaLI (ft SNLI-VE)",
        "mlmodel":{

        },
        "method_short":"PaLI ",
        "method_details":"ft SNLI-VE",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"45.00",
            "Image Score":"41.50",
            "Group Score":"28.70"
        },
        "raw_metrics":{
            "Text Score":45.0,
            "Image Score":41.5,
            "Group Score":28.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113429,
        "rank":11,
        "Model":"METER (EqSim)",
        "mlmodel":{

        },
        "method_short":"METER ",
        "method_details":"EqSim",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"45.0",
            "Image Score":"22.75",
            "Group Score":"18.75"
        },
        "raw_metrics":{
            "Text Score":45.0,
            "Image Score":22.75,
            "Group Score":18.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113429"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113458,
        "rank":12,
        "Model":"X-VLM 4M",
        "mlmodel":{

        },
        "method_short":"X-VLM 4M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"44.0",
            "Image Score":"26.7",
            "Group Score":"21.5"
        },
        "raw_metrics":{
            "Text Score":44.0,
            "Image Score":26.7,
            "Group Score":21.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113458"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113441,
        "rank":13,
        "Model":"BLIP2 (ft COCO)",
        "mlmodel":{

        },
        "method_short":"BLIP2 ",
        "method_details":"ft COCO",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"44.00",
            "Image Score":"26.00",
            "Group Score":"23.50"
        },
        "raw_metrics":{
            "Text Score":44.0,
            "Image Score":26.0,
            "Group Score":23.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113428,
        "rank":14,
        "Model":"METER (finetuned, Flickr30k)",
        "mlmodel":{

        },
        "method_short":"METER ",
        "method_details":"finetuned, Flickr30k",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"43.5",
            "Image Score":"20.75",
            "Group Score":"14.75"
        },
        "raw_metrics":{
            "Text Score":43.5,
            "Image Score":20.75,
            "Group Score":14.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113428"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113420,
        "rank":15,
        "Model":"BLIP2 (SGVL)",
        "mlmodel":{

        },
        "method_short":"BLIP2 ",
        "method_details":"SGVL",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"42.8",
            "Image Score":"28.5",
            "Group Score":"23.3"
        },
        "raw_metrics":{
            "Text Score":42.8,
            "Image Score":28.5,
            "Group Score":23.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113420"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113418,
        "rank":16,
        "Model":"BLIP (SGVL)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"SGVL",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"42.8",
            "Image Score":"27.3",
            "Group Score":"21.5"
        },
        "raw_metrics":{
            "Text Score":42.8,
            "Image Score":27.3,
            "Group Score":21.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113418"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113424,
        "rank":17,
        "Model":"NegBLIP",
        "mlmodel":{

        },
        "method_short":"NegBLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"42.5",
            "Image Score":"24.0",
            "Group Score":"18.5"
        },
        "raw_metrics":{
            "Text Score":42.5,
            "Image Score":24.0,
            "Group Score":18.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113424"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":88465,
        "rank":18,
        "Model":"IAIS large (Flickr30k)",
        "mlmodel":{

        },
        "method_short":"IAIS large ",
        "method_details":"Flickr30k",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-03",
        "metrics":{
            "Text Score":"42.50",
            "Image Score":"19.75",
            "Group Score":"16.00"
        },
        "raw_metrics":{
            "Text Score":42.5,
            "Image Score":19.75,
            "Group Score":16.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336326,
            "title":"Does Structural Attention Improve Compositional Representations in Vision-Language Models?",
            "url":"\/paper\/does-structural-attention-improve",
            "published":"2022-12-03T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113456,
        "rank":19,
        "Model":"LLaVA-1.5-CCoT",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-CCoT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"42.0",
            "Image Score":"35.5",
            "Group Score":"22.3"
        },
        "raw_metrics":{
            "Text Score":42.0,
            "Image Score":35.5,
            "Group Score":22.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113456"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":104770,
        "rank":20,
        "Model":"BLIP2",
        "mlmodel":{

        },
        "method_short":"BLIP2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"42.0",
            "Image Score":"23.8",
            "Group Score":"19.0"
        },
        "raw_metrics":{
            "Text Score":42.0,
            "Image Score":23.8,
            "Group Score":19.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=104770"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113413,
        "rank":21,
        "Model":"IAIS large (COCO)",
        "mlmodel":{

        },
        "method_short":"IAIS large ",
        "method_details":"COCO",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-03",
        "metrics":{
            "Text Score":"41.75",
            "Image Score":"19.75",
            "Group Score":"15.50"
        },
        "raw_metrics":{
            "Text Score":41.75,
            "Image Score":19.75,
            "Group Score":15.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336326,
            "title":"Does Structural Attention Improve Compositional Representations in Vision-Language Models?",
            "url":"\/paper\/does-structural-attention-improve",
            "published":"2022-12-03T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113425,
        "rank":22,
        "Model":"NegBLIP2",
        "mlmodel":{

        },
        "method_short":"NegBLIP2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"41.5",
            "Image Score":"26.0",
            "Group Score":"20.5"
        },
        "raw_metrics":{
            "Text Score":41.5,
            "Image Score":26.0,
            "Group Score":20.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113425"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113417,
        "rank":23,
        "Model":"BLIP (+Graph Text, +Graph Neg)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"+Graph Text, +Graph Neg",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"40.5",
            "Image Score":"25.5",
            "Group Score":"19.0"
        },
        "raw_metrics":{
            "Text Score":40.5,
            "Image Score":25.5,
            "Group Score":19.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113417"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113416,
        "rank":24,
        "Model":"BLIP (+Graph Text)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"+Graph Text",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"40.3",
            "Image Score":"20.5",
            "Group Score":"16.5"
        },
        "raw_metrics":{
            "Text Score":40.3,
            "Image Score":20.5,
            "Group Score":16.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113416"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":104073,
        "rank":25,
        "Model":"CACR base",
        "mlmodel":{

        },
        "method_short":"CACR base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-03",
        "metrics":{
            "Text Score":"39.25",
            "Image Score":"17.75",
            "Group Score":"14.25"
        },
        "raw_metrics":{
            "Text Score":39.25,
            "Image Score":17.75,
            "Group Score":14.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336326,
            "title":"Does Structural Attention Improve Compositional Representations in Vision-Language Models?",
            "url":"\/paper\/does-structural-attention-improve",
            "published":"2022-12-03T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113426,
        "rank":26,
        "Model":"METER",
        "mlmodel":{

        },
        "method_short":"METER",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-25",
        "metrics":{
            "Text Score":"39.25",
            "Image Score":"15.75",
            "Group Score":"12.00"
        },
        "raw_metrics":{
            "Text Score":39.25,
            "Image Score":15.75,
            "Group Score":12.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1180853,
            "title":"Equivariant Similarity for Vision-Language Foundation Models",
            "url":"\/paper\/equivariant-similarity-for-vision-language",
            "published":"2023-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/equivariant-similarity-for-vision-language\/review\/?hl=113426"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113415,
        "rank":27,
        "Model":"BLIP",
        "mlmodel":{

        },
        "method_short":"BLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"39.0",
            "Image Score":"19.2",
            "Group Score":"15.0"
        },
        "raw_metrics":{
            "Text Score":39.0,
            "Image Score":19.2,
            "Group Score":15.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113415"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113529,
        "rank":28,
        "Model":"GPT-4V (image-caption match answer yes\/no, zero-shot)",
        "mlmodel":{

        },
        "method_short":"GPT-4V ",
        "method_details":"image-caption match answer yes\/no, zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-02",
        "metrics":{
            "Text Score":"38.00",
            "Image Score":"38.00",
            "Group Score":"38.00"
        },
        "raw_metrics":{
            "Text Score":38.0,
            "Image Score":38.0,
            "Group Score":38.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":61428,
        "rank":29,
        "Model":"UNITER large",
        "mlmodel":{

        },
        "method_short":"UNITER large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"38.00",
            "Image Score":"14.00",
            "Group Score":"10.50"
        },
        "raw_metrics":{
            "Text Score":38.0,
            "Image Score":14.0,
            "Group Score":10.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=61428"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":61426,
        "rank":30,
        "Model":"VinVL",
        "mlmodel":{

        },
        "method_short":"VinVL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"37.75",
            "Image Score":"17.75",
            "Group Score":"14.50"
        },
        "raw_metrics":{
            "Text Score":37.75,
            "Image Score":17.75,
            "Group Score":14.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=61426"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113394,
        "rank":31,
        "Model":"ViLLA large",
        "mlmodel":{

        },
        "method_short":"ViLLA large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"37.00",
            "Image Score":"13.25",
            "Group Score":"11.00"
        },
        "raw_metrics":{
            "Text Score":37.0,
            "Image Score":13.25,
            "Group Score":11.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113394"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113392,
        "rank":32,
        "Model":"BLIP (VisualGPTScore, \u03b1-tuned)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"VisualGPTScore, \u03b1-tuned",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "Text Score":"36.5",
            "Image Score":"21.5",
            "Group Score":"16.8"
        },
        "raw_metrics":{
            "Text Score":36.5,
            "Image Score":21.5,
            "Group Score":16.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1223024,
            "title":"Revisiting the Role of Language Priors in Vision-Language Models",
            "url":"\/paper\/visualgptscore-visio-linguistic-reasoning",
            "published":"2023-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/visualgptscore-visio-linguistic-reasoning\/review\/?hl=113392"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113460,
        "rank":33,
        "Model":"BLIP 14M",
        "mlmodel":{

        },
        "method_short":"BLIP 14M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"36.5",
            "Image Score":"18.5",
            "Group Score":"14.5"
        },
        "raw_metrics":{
            "Text Score":36.5,
            "Image Score":18.5,
            "Group Score":14.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113460"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113476,
        "rank":34,
        "Model":"ViT-B\/16 + BERT base + ViLEM",
        "mlmodel":{

        },
        "method_short":"ViT-B\/16 + BERT base + ViLEM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-01",
        "metrics":{
            "Text Score":"36.5",
            "Image Score":null,
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":36.5,
            "Image Score":null,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1209793,
            "title":"ViLEM: Visual-Language Error Modeling for Image-Text Retrieval",
            "url":"\/paper\/vilem-visual-language-error-modeling-for",
            "published":"2023-01-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113454,
        "rank":35,
        "Model":"LLaVA-1.5",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"36.0",
            "Image Score":"33.3",
            "Group Score":"20.1"
        },
        "raw_metrics":{
            "Text Score":36.0,
            "Image Score":33.3,
            "Group Score":20.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113454"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113439,
        "rank":36,
        "Model":"BLIP (ITM)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"ITM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "Text Score":"35.8",
            "Image Score":"15.8",
            "Group Score":"13.3"
        },
        "raw_metrics":{
            "Text Score":35.8,
            "Image Score":15.8,
            "Group Score":13.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1223024,
            "title":"Revisiting the Role of Language Priors in Vision-Language Models",
            "url":"\/paper\/visualgptscore-visio-linguistic-reasoning",
            "published":"2023-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/visualgptscore-visio-linguistic-reasoning\/review\/?hl=113439"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113463,
        "rank":37,
        "Model":"BLIP 129M",
        "mlmodel":{

        },
        "method_short":"BLIP 129M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"35.5",
            "Image Score":"15.0",
            "Group Score":"11.7"
        },
        "raw_metrics":{
            "Text Score":35.5,
            "Image Score":15.0,
            "Group Score":11.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113463"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113414,
        "rank":38,
        "Model":"ROSITA (Flickr30k)",
        "mlmodel":{

        },
        "method_short":"ROSITA ",
        "method_details":"Flickr30k",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-03",
        "metrics":{
            "Text Score":"35.25",
            "Image Score":"15.25",
            "Group Score":"12.25"
        },
        "raw_metrics":{
            "Text Score":35.25,
            "Image Score":15.25,
            "Group Score":12.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336326,
            "title":"Does Structural Attention Improve Compositional Representations in Vision-Language Models?",
            "url":"\/paper\/does-structural-attention-improve",
            "published":"2022-12-03T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113397,
        "rank":39,
        "Model":"ViLT (ViT-B\/32)",
        "mlmodel":{

        },
        "method_short":"ViLT ",
        "method_details":"ViT-B\/32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"34.75",
            "Image Score":"14.00",
            "Group Score":"9.25"
        },
        "raw_metrics":{
            "Text Score":34.75,
            "Image Score":14.0,
            "Group Score":9.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113397"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113464,
        "rank":40,
        "Model":"BLIP 129M (CapFilt\/L)",
        "mlmodel":{

        },
        "method_short":"BLIP 129M ",
        "method_details":"CapFilt\/L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"34.7",
            "Image Score":"15.2",
            "Group Score":"12.2"
        },
        "raw_metrics":{
            "Text Score":34.7,
            "Image Score":15.2,
            "Group Score":12.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113464"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113465,
        "rank":41,
        "Model":"BLIP-ViT\/L 129M",
        "mlmodel":{

        },
        "method_short":"BLIP-ViT\/L 129M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"34.7",
            "Image Score":"14.5",
            "Group Score":"12.2"
        },
        "raw_metrics":{
            "Text Score":34.7,
            "Image Score":14.5,
            "Group Score":12.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113465"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":109087,
        "rank":42,
        "Model":"Diffusion Classifier (zero-shot)",
        "mlmodel":{

        },
        "method_short":"Diffusion Classifier ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-28",
        "metrics":{
            "Text Score":"34.00",
            "Image Score":null,
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":34.0,
            "Image Score":null,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1181860,
            "title":"Your Diffusion Model is Secretly a Zero-Shot Classifier",
            "url":"\/paper\/your-diffusion-model-is-secretly-a-zero-shot",
            "published":"2023-03-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/your-diffusion-model-is-secretly-a-zero-shot\/review\/?hl=109087"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113461,
        "rank":43,
        "Model":"PEVL 14M",
        "mlmodel":{

        },
        "method_short":"PEVL 14M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"33.2",
            "Image Score":"15.7",
            "Group Score":"12.2"
        },
        "raw_metrics":{
            "Text Score":33.2,
            "Image Score":15.7,
            "Group Score":12.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113461"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113459,
        "rank":44,
        "Model":"ALBEF 14M",
        "mlmodel":{

        },
        "method_short":"ALBEF 14M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"32.5",
            "Image Score":"16.2",
            "Group Score":"12.7"
        },
        "raw_metrics":{
            "Text Score":32.5,
            "Image Score":16.2,
            "Group Score":12.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113459"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113401,
        "rank":45,
        "Model":"FLAVA (ITM)",
        "mlmodel":{

        },
        "method_short":"FLAVA ",
        "method_details":"ITM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"32.25",
            "Image Score":"20.50",
            "Group Score":"14.25"
        },
        "raw_metrics":{
            "Text Score":32.25,
            "Image Score":20.5,
            "Group Score":14.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113401"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113393,
        "rank":46,
        "Model":"UNITER base",
        "mlmodel":{

        },
        "method_short":"UNITER base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"32.25",
            "Image Score":"13.25",
            "Group Score":"10.00"
        },
        "raw_metrics":{
            "Text Score":32.25,
            "Image Score":13.25,
            "Group Score":10.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113393"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113419,
        "rank":47,
        "Model":"CLIP (SGVL)",
        "mlmodel":{

        },
        "method_short":"CLIP ",
        "method_details":"SGVL",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"32.0",
            "Image Score":"14.0",
            "Group Score":"9.8"
        },
        "raw_metrics":{
            "Text Score":32.0,
            "Image Score":14.0,
            "Group Score":9.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113419"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113475,
        "rank":48,
        "Model":"ViT-B\/16 + BERT base",
        "mlmodel":{

        },
        "method_short":"ViT-B\/16 + BERT base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-01",
        "metrics":{
            "Text Score":"31.2",
            "Image Score":null,
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":31.2,
            "Image Score":null,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1209793,
            "title":"ViLEM: Visual-Language Error Modeling for Image-Text Retrieval",
            "url":"\/paper\/vilem-visual-language-error-modeling-for",
            "published":"2023-01-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113470,
        "rank":49,
        "Model":"OCLIP (ViT-H\/14)",
        "mlmodel":{

        },
        "method_short":"OCLIP ",
        "method_details":"ViT-H\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"30.75",
            "Image Score":"12.75",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":30.75,
            "Image Score":12.75,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113403,
        "rank":50,
        "Model":"CLIP (ViT-B\/32)",
        "mlmodel":{

        },
        "method_short":"CLIP ",
        "method_details":"ViT-B\/32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"30.75",
            "Image Score":"10.50",
            "Group Score":"8.00"
        },
        "raw_metrics":{
            "Text Score":30.75,
            "Image Score":10.5,
            "Group Score":8.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113403"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113432,
        "rank":51,
        "Model":"OFA large (ITM)",
        "mlmodel":{

        },
        "method_short":"OFA large ",
        "method_details":"ITM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"30.75",
            "Image Score":"10.25",
            "Group Score":"7.25"
        },
        "raw_metrics":{
            "Text Score":30.75,
            "Image Score":10.25,
            "Group Score":7.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113432"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113469,
        "rank":52,
        "Model":"CLIP (ViT-L\/14)",
        "mlmodel":{

        },
        "method_short":"CLIP ",
        "method_details":"ViT-L\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"30.25",
            "Image Score":"8.0",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":30.25,
            "Image Score":8.0,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113395,
        "rank":53,
        "Model":"ViLLA base",
        "mlmodel":{

        },
        "method_short":"ViLLA base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"30.00",
            "Image Score":"12.00",
            "Group Score":"8.00"
        },
        "raw_metrics":{
            "Text Score":30.0,
            "Image Score":12.0,
            "Group Score":8.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113395"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113410,
        "rank":54,
        "Model":"syn-CLIP",
        "mlmodel":{

        },
        "method_short":"syn-CLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Text Score":"30.00",
            "Image Score":"11.50",
            "Group Score":"9.50"
        },
        "raw_metrics":{
            "Text Score":30.0,
            "Image Score":11.5,
            "Group Score":9.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183404,
            "title":"Going Beyond Nouns With Vision & Language Models Using Synthetic Data",
            "url":"\/paper\/going-beyond-nouns-with-vision-language",
            "published":"2023-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/going-beyond-nouns-with-vision-language\/review\/?hl=113410"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113412,
        "rank":55,
        "Model":"syn-CyCLIP",
        "mlmodel":{

        },
        "method_short":"syn-CyCLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Text Score":"30.00",
            "Image Score":"10.75",
            "Group Score":"8.25"
        },
        "raw_metrics":{
            "Text Score":30.0,
            "Image Score":10.75,
            "Group Score":8.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183404,
            "title":"Going Beyond Nouns With Vision & Language Models Using Synthetic Data",
            "url":"\/paper\/going-beyond-nouns-with-vision-language",
            "published":"2023-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/going-beyond-nouns-with-vision-language\/review\/?hl=113412"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113423,
        "rank":56,
        "Model":"NegCLIP",
        "mlmodel":{

        },
        "method_short":"NegCLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"29.5",
            "Image Score":"10.5",
            "Group Score":"8.0"
        },
        "raw_metrics":{
            "Text Score":29.5,
            "Image Score":10.5,
            "Group Score":8.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113423"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113435,
        "rank":57,
        "Model":"OFA large (TLC-A)",
        "mlmodel":{

        },
        "method_short":"OFA large ",
        "method_details":"TLC-A",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"29.25",
            "Image Score":"27.00",
            "Group Score":"17.50"
        },
        "raw_metrics":{
            "Text Score":29.25,
            "Image Score":27.0,
            "Group Score":17.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113435"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113457,
        "rank":58,
        "Model":"ALBEF 4M",
        "mlmodel":{

        },
        "method_short":"ALBEF 4M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-12",
        "metrics":{
            "Text Score":"29.2",
            "Image Score":"15.5",
            "Group Score":"11.0"
        },
        "raw_metrics":{
            "Text Score":29.2,
            "Image Score":15.5,
            "Group Score":11.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1207174,
            "title":"Measuring Progress in Fine-grained Vision-and-Language Understanding",
            "url":"\/paper\/measuring-progress-in-fine-grained-vision-and",
            "published":"2023-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/measuring-progress-in-fine-grained-vision-and\/review\/?hl=113457"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113474,
        "rank":59,
        "Model":"LDM-T5 (SelfEval)",
        "mlmodel":{

        },
        "method_short":"LDM-T5 ",
        "method_details":"SelfEval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"29.00",
            "Image Score":"13.50",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":29.0,
            "Image Score":13.5,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113411,
        "rank":60,
        "Model":"CyCLIP",
        "mlmodel":{

        },
        "method_short":"CyCLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Text Score":"28.50",
            "Image Score":"9.50",
            "Group Score":"7.25"
        },
        "raw_metrics":{
            "Text Score":28.5,
            "Image Score":9.5,
            "Group Score":7.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183404,
            "title":"Going Beyond Nouns With Vision & Language Models Using Synthetic Data",
            "url":"\/paper\/going-beyond-nouns-with-vision-language",
            "published":"2023-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/going-beyond-nouns-with-vision-language\/review\/?hl=113411"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113473,
        "rank":61,
        "Model":"PDM-T5 (SelfEval)",
        "mlmodel":{

        },
        "method_short":"PDM-T5 ",
        "method_details":"SelfEval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"28.25",
            "Image Score":"12.00",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":28.25,
            "Image Score":12.0,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113445,
        "rank":62,
        "Model":"COCA ViT-L14 (f.t on COCO)",
        "mlmodel":{

        },
        "method_short":"COCA ViT-L14 ",
        "method_details":"f.t on COCO",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"28.25",
            "Image Score":"11.50",
            "Group Score":"8.25"
        },
        "raw_metrics":{
            "Text Score":28.25,
            "Image Score":11.5,
            "Group Score":8.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113455,
        "rank":63,
        "Model":"LLaVA-1.5-ZS-CoT",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-ZS-CoT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"28.0",
            "Image Score":"22.5",
            "Group Score":"12.3"
        },
        "raw_metrics":{
            "Text Score":28.0,
            "Image Score":22.5,
            "Group Score":12.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113455"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113438,
        "rank":64,
        "Model":"BLIP (ITC)",
        "mlmodel":{

        },
        "method_short":"BLIP ",
        "method_details":"ITC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "Text Score":"28.0",
            "Image Score":"9.0",
            "Group Score":"6.5"
        },
        "raw_metrics":{
            "Text Score":28.0,
            "Image Score":9.0,
            "Group Score":6.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1223024,
            "title":"Revisiting the Role of Language Priors in Vision-Language Models",
            "url":"\/paper\/visualgptscore-visio-linguistic-reasoning",
            "published":"2023-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/visualgptscore-visio-linguistic-reasoning\/review\/?hl=113438"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113444,
        "rank":65,
        "Model":"OFA large (ft SNLI-VE)",
        "mlmodel":{

        },
        "method_short":"OFA large ",
        "method_details":"ft SNLI-VE",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"27.70",
            "Image Score":"14.30",
            "Group Score":"9.00"
        },
        "raw_metrics":{
            "Text Score":27.7,
            "Image Score":14.3,
            "Group Score":9.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113433,
        "rank":66,
        "Model":"OFA base (ITM)",
        "mlmodel":{

        },
        "method_short":"OFA base ",
        "method_details":"ITM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"26.75",
            "Image Score":"10.75",
            "Group Score":"6.50"
        },
        "raw_metrics":{
            "Text Score":26.75,
            "Image Score":10.75,
            "Group Score":6.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113433"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113443,
        "rank":67,
        "Model":"CLIP RN50x64",
        "mlmodel":{

        },
        "method_short":"CLIP RN50x64",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"26.50",
            "Image Score":"13.75",
            "Group Score":"10.25"
        },
        "raw_metrics":{
            "Text Score":26.5,
            "Image Score":13.75,
            "Group Score":10.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113447,
        "rank":68,
        "Model":"LLaVA-7B (GPTScore)",
        "mlmodel":{

        },
        "method_short":"LLaVA-7B ",
        "method_details":"GPTScore",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-21",
        "metrics":{
            "Text Score":"25.50",
            "Image Score":"17.00",
            "Group Score":"10.50"
        },
        "raw_metrics":{
            "Text Score":25.5,
            "Image Score":17.0,
            "Group Score":10.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1266387,
            "title":"An Examination of the Compositionality of Large Generative Vision-Language Models",
            "url":"\/paper\/an-examination-of-the-compositionality-of",
            "published":"2023-08-21T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113402,
        "rank":69,
        "Model":"FLAVA (contrastive)",
        "mlmodel":{

        },
        "method_short":"FLAVA ",
        "method_details":"contrastive",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"25.25",
            "Image Score":"13.50",
            "Group Score":"9.00"
        },
        "raw_metrics":{
            "Text Score":25.25,
            "Image Score":13.5,
            "Group Score":9.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113402"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113528,
        "rank":70,
        "Model":"Random chance",
        "mlmodel":{

        },
        "method_short":"Random chance",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"25.00",
            "Image Score":"25.00",
            "Group Score":"16.67"
        },
        "raw_metrics":{
            "Text Score":25.0,
            "Image Score":25.0,
            "Group Score":16.67
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113528"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113421,
        "rank":71,
        "Model":"LLaVA",
        "mlmodel":{

        },
        "method_short":"LLaVA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"24.8",
            "Image Score":"25.0",
            "Group Score":"13.0"
        },
        "raw_metrics":{
            "Text Score":24.8,
            "Image Score":25.0,
            "Group Score":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113421"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113436,
        "rank":72,
        "Model":"OFA base (TLC-A)",
        "mlmodel":{

        },
        "method_short":"OFA base ",
        "method_details":"TLC-A",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"24.50",
            "Image Score":"23.50",
            "Group Score":"13.75"
        },
        "raw_metrics":{
            "Text Score":24.5,
            "Image Score":23.5,
            "Group Score":13.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113436"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113449,
        "rank":73,
        "Model":"MiniGPT-4-7B (GPTScore)",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4-7B ",
        "method_details":"GPTScore",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-21",
        "metrics":{
            "Text Score":"24.50",
            "Image Score":"21.75",
            "Group Score":"11.50"
        },
        "raw_metrics":{
            "Text Score":24.5,
            "Image Score":21.75,
            "Group Score":11.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1266387,
            "title":"An Examination of the Compositionality of Large Generative Vision-Language Models",
            "url":"\/paper\/an-examination-of-the-compositionality-of",
            "published":"2023-08-21T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113399,
        "rank":74,
        "Model":"ViLBERT base",
        "mlmodel":{

        },
        "method_short":"ViLBERT base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"23.75",
            "Image Score":"7.25",
            "Group Score":"4.75"
        },
        "raw_metrics":{
            "Text Score":23.75,
            "Image Score":7.25,
            "Group Score":4.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113399"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113422,
        "rank":75,
        "Model":"MiniGPT-4",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Text Score":"23.3",
            "Image Score":"18.0",
            "Group Score":"9.5"
        },
        "raw_metrics":{
            "Text Score":23.3,
            "Image Score":18.0,
            "Group Score":9.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205780,
            "title":"Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs",
            "url":"\/paper\/incorporating-structured-representations-into",
            "published":"2023-05-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/incorporating-structured-representations-into\/review\/?hl=113422"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113450,
        "rank":76,
        "Model":"MiniGPT-4-7B (VisualGPTScore)",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4-7B ",
        "method_details":"VisualGPTScore",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-21",
        "metrics":{
            "Text Score":"23.25",
            "Image Score":"18.00",
            "Group Score":"9.50"
        },
        "raw_metrics":{
            "Text Score":23.25,
            "Image Score":18.0,
            "Group Score":9.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1266387,
            "title":"An Examination of the Compositionality of Large Generative Vision-Language Models",
            "url":"\/paper\/an-examination-of-the-compositionality-of",
            "published":"2023-08-21T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113404,
        "rank":77,
        "Model":"VSE++ (COCO, ResNet)",
        "mlmodel":{

        },
        "method_short":"VSE++ ",
        "method_details":"COCO, ResNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"22.75",
            "Image Score":"8.00",
            "Group Score":"4.00"
        },
        "raw_metrics":{
            "Text Score":22.75,
            "Image Score":8.0,
            "Group Score":4.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113404"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113434,
        "rank":78,
        "Model":"OFA tiny (ITM)",
        "mlmodel":{

        },
        "method_short":"OFA tiny ",
        "method_details":"ITM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"22.75",
            "Image Score":"7.75",
            "Group Score":"4.50"
        },
        "raw_metrics":{
            "Text Score":22.75,
            "Image Score":7.75,
            "Group Score":4.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113434"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113471,
        "rank":79,
        "Model":"LDM-CLIP (SelfEval)",
        "mlmodel":{

        },
        "method_short":"LDM-CLIP ",
        "method_details":"SelfEval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"22.75",
            "Image Score":"7.25",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":22.75,
            "Image Score":7.25,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113453,
        "rank":80,
        "Model":"InstructBLIP-CCoT",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-CCoT ",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"21.0",
            "Image Score":"21.3",
            "Group Score":"8.3"
        },
        "raw_metrics":{
            "Text Score":21.0,
            "Image Score":21.3,
            "Group Score":8.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113453"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113409,
        "rank":81,
        "Model":"VSRN (Flickr30k)",
        "mlmodel":{

        },
        "method_short":"VSRN ",
        "method_details":"Flickr30k",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"20.00",
            "Image Score":"5.00",
            "Group Score":"3.50"
        },
        "raw_metrics":{
            "Text Score":20.0,
            "Image Score":5.0,
            "Group Score":3.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113409"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113406,
        "rank":82,
        "Model":"VSE++ (Flickr30k, ResNet)",
        "mlmodel":{

        },
        "method_short":"VSE++ ",
        "method_details":"Flickr30k, ResNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"20.00",
            "Image Score":"5.00",
            "Group Score":"2.75"
        },
        "raw_metrics":{
            "Text Score":20.0,
            "Image Score":5.0,
            "Group Score":2.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113406"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113407,
        "rank":83,
        "Model":"VSE++ (Flickr30k, VGG)",
        "mlmodel":{

        },
        "method_short":"VSE++ ",
        "method_details":"Flickr30k, VGG",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"19.75",
            "Image Score":"6.25",
            "Group Score":"4.50"
        },
        "raw_metrics":{
            "Text Score":19.75,
            "Image Score":6.25,
            "Group Score":4.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113407"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113400,
        "rank":84,
        "Model":"UniT (ITM finetuned)",
        "mlmodel":{

        },
        "method_short":"UniT ",
        "method_details":"ITM finetuned",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"19.50",
            "Image Score":"6.25",
            "Group Score":"4.00"
        },
        "raw_metrics":{
            "Text Score":19.5,
            "Image Score":6.25,
            "Group Score":4.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113400"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113398,
        "rank":85,
        "Model":"LXMERT",
        "mlmodel":{

        },
        "method_short":"LXMERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"19.25",
            "Image Score":"7.00",
            "Group Score":"4.00"
        },
        "raw_metrics":{
            "Text Score":19.25,
            "Image Score":7.0,
            "Group Score":4.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113398"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113442,
        "rank":86,
        "Model":"TIFA",
        "mlmodel":{

        },
        "method_short":"TIFA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Text Score":"19.00",
            "Image Score":"12.50",
            "Group Score":"11.30"
        },
        "raw_metrics":{
            "Text Score":19.0,
            "Image Score":12.5,
            "Group Score":11.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333293,
            "title":"What You See is What You Read? Improving Text-Image Alignment Evaluation",
            "url":"\/paper\/what-you-see-is-what-you-read-improving-text-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113478,
        "rank":87,
        "Model":"IDEFICS 80B",
        "mlmodel":{

        },
        "method_short":"IDEFICS 80B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-22",
        "metrics":{
            "Text Score":"18.75",
            "Image Score":"22.5",
            "Group Score":"8.0"
        },
        "raw_metrics":{
            "Text Score":18.75,
            "Image Score":22.5,
            "Group Score":8.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113405,
        "rank":88,
        "Model":"VSE++ (COCO, VGG)",
        "mlmodel":{

        },
        "method_short":"VSE++ ",
        "method_details":"COCO, VGG",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"18.75",
            "Image Score":"5.50",
            "Group Score":"3.50"
        },
        "raw_metrics":{
            "Text Score":18.75,
            "Image Score":5.5,
            "Group Score":3.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113405"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113408,
        "rank":89,
        "Model":"VSRN (COCO)",
        "mlmodel":{

        },
        "method_short":"VSRN ",
        "method_details":"COCO",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"17.50",
            "Image Score":"7.00",
            "Group Score":"3.75"
        },
        "raw_metrics":{
            "Text Score":17.5,
            "Image Score":7.0,
            "Group Score":3.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113408"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113472,
        "rank":90,
        "Model":"PDM-CLIP (SelfEval)",
        "mlmodel":{

        },
        "method_short":"PDM-CLIP ",
        "method_details":"SelfEval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-17",
        "metrics":{
            "Text Score":"17.00",
            "Image Score":"14.00",
            "Group Score":null
        },
        "raw_metrics":{
            "Text Score":17.0,
            "Image Score":14.0,
            "Group Score":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323173,
            "title":"SelfEval: Leveraging the discriminative nature of generative models for evaluation",
            "url":"\/paper\/selfeval-leveraging-the-discriminative-nature",
            "published":"2023-11-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113479,
        "rank":91,
        "Model":"IDEFICS 9B",
        "mlmodel":{

        },
        "method_short":"IDEFICS 9B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-22",
        "metrics":{
            "Text Score":"16.8",
            "Image Score":"20.8",
            "Group Score":"5.0"
        },
        "raw_metrics":{
            "Text Score":16.8,
            "Image Score":20.8,
            "Group Score":5.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113437,
        "rank":92,
        "Model":"OFA tiny (TLC-A)",
        "mlmodel":{

        },
        "method_short":"OFA tiny ",
        "method_details":"TLC-A",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Text Score":"16.50",
            "Image Score":"15.75",
            "Group Score":"6.75"
        },
        "raw_metrics":{
            "Text Score":16.5,
            "Image Score":15.75,
            "Group Score":6.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1206470,
            "title":"Simple Token-Level Confidence Improves Caption Correctness",
            "url":"\/paper\/simple-token-level-confidence-improves",
            "published":"2023-05-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-token-level-confidence-improves\/review\/?hl=113437"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113396,
        "rank":93,
        "Model":"VisualBERT base",
        "mlmodel":{

        },
        "method_short":"VisualBERT base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-07",
        "metrics":{
            "Text Score":"15.50",
            "Image Score":"2.50",
            "Group Score":"1.50"
        },
        "raw_metrics":{
            "Text Score":15.5,
            "Image Score":2.5,
            "Group Score":1.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":990784,
            "title":"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality",
            "url":"\/paper\/winoground-probing-vision-and-language-models",
            "published":"2022-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/winoground-probing-vision-and-language-models\/review\/?hl=113396"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":521,
                "name":"tested-in-winoground-paper",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113448,
        "rank":94,
        "Model":"MiniGPT-4-7B (BERTScore)",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4-7B ",
        "method_details":"BERTScore",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-21",
        "metrics":{
            "Text Score":"14.00",
            "Image Score":"8.00",
            "Group Score":"2.75"
        },
        "raw_metrics":{
            "Text Score":14.0,
            "Image Score":8.0,
            "Group Score":2.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":1266387,
            "title":"An Examination of the Compositionality of Large Generative Vision-Language Models",
            "url":"\/paper\/an-examination-of-the-compositionality-of",
            "published":"2023-08-21T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113446,
        "rank":95,
        "Model":"LLaVA-7B (BERTScore)",
        "mlmodel":{

        },
        "method_short":"LLaVA-7B ",
        "method_details":"BERTScore",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-21",
        "metrics":{
            "Text Score":"13.50",
            "Image Score":"5.25",
            "Group Score":"2.25"
        },
        "raw_metrics":{
            "Text Score":13.5,
            "Image Score":5.25,
            "Group Score":2.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1266387,
            "title":"An Examination of the Compositionality of Large Generative Vision-Language Models",
            "url":"\/paper\/an-examination-of-the-compositionality-of",
            "published":"2023-08-21T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113452,
        "rank":96,
        "Model":"InstructBLIP-ZS-CoT",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-ZS-CoT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"9.3",
            "Image Score":"16.3",
            "Group Score":"4.0"
        },
        "raw_metrics":{
            "Text Score":9.3,
            "Image Score":16.3,
            "Group Score":4.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113452"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":19095,
        "row_id":113451,
        "rank":97,
        "Model":"InstructBLIP",
        "mlmodel":{

        },
        "method_short":"InstructBLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-27",
        "metrics":{
            "Text Score":"7.0",
            "Image Score":"11.5",
            "Group Score":"3.3"
        },
        "raw_metrics":{
            "Text Score":7.0,
            "Image Score":11.5,
            "Group Score":3.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1331616,
            "title":"Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "url":"\/paper\/compositional-chain-of-thought-prompting-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/compositional-chain-of-thought-prompting-for\/review\/?hl=113451"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]