[
    {
        "Model":"Falcon (40B)",
        "EM":"0.204",
        "Observed inference time (s)":"3.174",
        "# eval":"490",
        "# train":"0.265",
        "truncated":"0.016",
        "# prompt tokens":"1486.482",
        "# output tokens":"0.876"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.22",
        "Observed inference time (s)":"1.041",
        "# eval":"490",
        "# train":"0.265",
        "truncated":"0.016",
        "# prompt tokens":"1486.482",
        "# output tokens":"0.982"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.694",
        "Observed inference time (s)":"0.729",
        "# eval":"490",
        "# train":"1.886",
        "truncated":"0.004",
        "# prompt tokens":"3642.378",
        "# output tokens":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.72",
        "Observed inference time (s)":"1.744",
        "# eval":"490",
        "# train":"1.886",
        "truncated":"0.004",
        "# prompt tokens":"3642.378",
        "# output tokens":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.676",
        "Observed inference time (s)":"0.76",
        "# eval":"490",
        "# train":"1.886",
        "truncated":"0.004",
        "# prompt tokens":"3642.378",
        "# output tokens":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.018",
        "Observed inference time (s)":"1.987",
        "# eval":"490",
        "# train":"0.024",
        "truncated":"0.031",
        "# prompt tokens":"1481.433",
        "# output tokens":"0.882"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.696",
        "Observed inference time (s)":"0.577",
        "# eval":"490",
        "# train":"1.969",
        "truncated":"0",
        "# prompt tokens":"3534.259",
        "# output tokens":"0.992"
    },
    {
        "Model":"Mixtral (8x7B 32K seqlen)",
        "EM":"0.773",
        "Observed inference time (s)":"0.512",
        "# eval":"490",
        "# train":"1.969",
        "truncated":"0",
        "# prompt tokens":"3534.259",
        "# output tokens":"0.998"
    },
    {
        "Model":"Yi (34B)",
        "EM":"0.733",
        "Observed inference time (s)":"1.063",
        "# eval":"490",
        "# train":"2",
        "truncated":"0",
        "# prompt tokens":"3359.547",
        "# output tokens":"1"
    },
    {
        "Model":"Yi (6B)",
        "EM":"0.698",
        "Observed inference time (s)":"1.149",
        "# eval":"490",
        "# train":"2",
        "truncated":"0",
        "# prompt tokens":"3359.547",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude 2.0",
        "EM":"0.827",
        "Observed inference time (s)":"6.2",
        "# eval":"490",
        "# train":"4.99",
        "truncated":"0",
        "# prompt tokens":"6484.969",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude 2.1",
        "EM":"0.812",
        "Observed inference time (s)":"6.58",
        "# eval":"490",
        "# train":"4.99",
        "truncated":"0",
        "# prompt tokens":"6484.969",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude v1.3",
        "EM":"0.712",
        "Observed inference time (s)":"8.614",
        "# eval":"490",
        "# train":"4.99",
        "truncated":"0",
        "# prompt tokens":"6484.969",
        "# output tokens":"1"
    },
    {
        "Model":"Anthropic Claude Instant 1.2",
        "EM":"0.716",
        "Observed inference time (s)":"1.974",
        "# eval":"490",
        "# train":"4.99",
        "truncated":"0",
        "# prompt tokens":"6484.969",
        "# output tokens":"1"
    },
    {
        "Model":"Cohere Command",
        "EM":"0.671",
        "Observed inference time (s)":"1.842",
        "# eval":"490",
        "# train":"0.388",
        "truncated":"0.014",
        "# prompt tokens":"1529.327",
        "# output tokens":"3.055"
    },
    {
        "Model":"Cohere Command Light",
        "EM":"0.173",
        "Observed inference time (s)":"1.232",
        "# eval":"490",
        "# train":"0.388",
        "truncated":"0.014",
        "# prompt tokens":"1529.327",
        "# output tokens":"23.614"
    },
    {
        "Model":"GPT-3.5 (text-davinci-003)",
        "EM":"0.724",
        "Observed inference time (s)":"0.474",
        "# eval":"490",
        "# train":"2.053",
        "truncated":"0",
        "# prompt tokens":"3225.32",
        "# output tokens":"1.061"
    },
    {
        "Model":"GPT-3.5 (text-davinci-002)",
        "EM":"0.71",
        "Observed inference time (s)":"0.403",
        "# eval":"490",
        "# train":"2.053",
        "truncated":"0",
        "# prompt tokens":"3225.32",
        "# output tokens":"0.996"
    },
    {
        "Model":"GPT-4 (0613)",
        "EM":"0.818",
        "Observed inference time (s)":"0.886",
        "# eval":"490",
        "# train":"4.992",
        "truncated":"0",
        "# prompt tokens":"6350.008",
        "# output tokens":"1"
    },
    {
        "Model":"GPT-4 Turbo (1106 preview)",
        "EM":"0.812",
        "Observed inference time (s)":"0.98",
        "# eval":"490",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"6357.388",
        "# output tokens":"1"
    },
    {
        "Model":"GPT-3.5 Turbo (0613)",
        "EM":"0.676",
        "Observed inference time (s)":"0.277",
        "# eval":"490",
        "# train":"2.09",
        "truncated":"0",
        "# prompt tokens":"3254.159",
        "# output tokens":"1"
    },
    {
        "Model":"Palmyra X V2 (33B)",
        "EM":"0.812",
        "Observed inference time (s)":"1.784",
        "# eval":"490",
        "# train":"3.984",
        "truncated":"0",
        "# prompt tokens":"5467.178",
        "# output tokens":"1"
    },
    {
        "Model":"Palmyra X V3 (72B)",
        "EM":"0.835",
        "Observed inference time (s)":"3",
        "# eval":"490",
        "# train":"3.984",
        "truncated":"0",
        "# prompt tokens":"5467.178",
        "# output tokens":"1"
    },
    {
        "Model":"PaLM-2 (Bison)",
        "EM":"0.737",
        "Observed inference time (s)":"1.325",
        "# eval":"490",
        "# train":"2.988",
        "truncated":"0",
        "# prompt tokens":"5134.504",
        "# output tokens":"1"
    },
    {
        "Model":"PaLM-2 (Unicorn)",
        "EM":"0.831",
        "Observed inference time (s)":"3.198",
        "# eval":"490",
        "# train":"2.988",
        "truncated":"0",
        "# prompt tokens":"5134.504",
        "# output tokens":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.706",
        "Observed inference time (s)":"2.827",
        "# eval":"490",
        "# train":"4.992",
        "truncated":"0",
        "# prompt tokens":"4600.92",
        "# output tokens":"2"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.533",
        "Observed inference time (s)":"1.079",
        "# eval":"490",
        "# train":"1.006",
        "truncated":"0.012",
        "# prompt tokens":"1514.22",
        "# output tokens":"2.216"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.165",
        "Observed inference time (s)":"1.073",
        "# eval":"490",
        "# train":"0.335",
        "truncated":"0.665",
        "# prompt tokens":"1514.545",
        "# output tokens":"4.027"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.32",
        "Observed inference time (s)":"1.261",
        "# eval":"490",
        "# train":"0.335",
        "truncated":"0.665",
        "# prompt tokens":"1514.545",
        "# output tokens":"3.196"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.343",
        "Observed inference time (s)":"2.035",
        "# eval":"490",
        "# train":"0.335",
        "truncated":"0.665",
        "# prompt tokens":"1514.545",
        "# output tokens":"1.769"
    }
]