[
    {
        "table_id":18404,
        "row_id":58816,
        "rank":1,
        "Model":"NOAH-ViTB\/16",
        "mlmodel":{

        },
        "method_short":"NOAH-ViTB\/16",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-09",
        "metrics":{
            "Average Top-1 Accuracy":"47.6"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":47.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1024509,
            "title":"Neural Prompt Search",
            "url":"\/paper\/neural-prompt-search",
            "published":"2022-06-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-prompt-search\/review\/?hl=58816"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":261,
                "name":"pre-trained on ImageNet22K",
                "color":"#bb25b6"
            },
            {
                "id":259,
                "name":"parameter-efficient tuning",
                "color":"#cb6155"
            },
            {
                "id":145,
                "name":"ViT",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58881,
        "rank":2,
        "Model":"SwinTransformer",
        "mlmodel":{

        },
        "method_short":"SwinTransformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-25",
        "metrics":{
            "Average Top-1 Accuracy":"46.4"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":46.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":757245,
            "title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
            "url":"\/paper\/swin-transformer-hierarchical-vision",
            "published":"2021-03-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/swin-transformer-hierarchical-vision\/review\/?hl=58881"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":47,
                "name":"swin-transformer",
                "color":"#f75c2f"
            },
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58894,
        "rank":3,
        "Model":"ViT-B\/16",
        "mlmodel":{

        },
        "method_short":"ViT-B\/16",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Average Top-1 Accuracy":"45.8"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":45.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":229828,
            "title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
            "url":"\/paper\/an-image-is-worth-16x16-words-transformers-1",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-image-is-worth-16x16-words-transformers-1\/review\/?hl=58894"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":145,
                "name":"ViT",
                "color":"#2771D3"
            },
            {
                "id":261,
                "name":"pre-trained on ImageNet22K",
                "color":"#bb25b6"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58736,
        "rank":4,
        "Model":"Bamboo-R50",
        "mlmodel":{

        },
        "method_short":"Bamboo-R50",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-07",
        "metrics":{
            "Average Top-1 Accuracy":"45.4"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":45.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":977452,
            "title":"Bamboo: Building Mega-Scale Vision Dataset Continually with Human-Machine Synergy",
            "url":"\/paper\/bamboo-building-mega-scale-vision-dataset",
            "published":"2022-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bamboo-building-mega-scale-vision-dataset\/review\/?hl=58736"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":260,
                "name":"pre-trained on Bamboo-CLS",
                "color":"#a2449a"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58874,
        "rank":5,
        "Model":"Adapter-ViTB\/16",
        "mlmodel":{

        },
        "method_short":"Adapter-ViTB\/16",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-02-02",
        "metrics":{
            "Average Top-1 Accuracy":"44.5"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":44.5
        },
        "uses_additional_data":true,
        "paper":{
            "id":93330,
            "title":"Parameter-Efficient Transfer Learning for NLP",
            "url":"\/paper\/parameter-efficient-transfer-learning-for-nlp",
            "published":"2019-02-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/parameter-efficient-transfer-learning-for-nlp\/review\/?hl=58874"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":145,
                "name":"ViT",
                "color":"#2771D3"
            },
            {
                "id":259,
                "name":"parameter-efficient tuning",
                "color":"#cb6155"
            },
            {
                "id":261,
                "name":"pre-trained on ImageNet22K",
                "color":"#bb25b6"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58892,
        "rank":6,
        "Model":"CLIP-RN50",
        "mlmodel":{

        },
        "method_short":"CLIP-RN50",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-26",
        "metrics":{
            "Average Top-1 Accuracy":"42.1"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":42.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":749733,
            "title":"Learning Transferable Visual Models From Natural Language Supervision",
            "url":"\/paper\/learning-transferable-visual-models-from",
            "published":"2021-02-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-transferable-visual-models-from\/review\/?hl=58892"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":231,
                "name":"CLIP Pre-trained",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58890,
        "rank":7,
        "Model":"IG-1B",
        "mlmodel":{

        },
        "method_short":"IG-1B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-02",
        "metrics":{
            "Average Top-1 Accuracy":"40.4"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":40.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":113449,
            "title":"Billion-scale semi-supervised learning for image classification",
            "url":"\/paper\/billion-scale-semi-supervised-learning-for",
            "published":"2019-05-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/billion-scale-semi-supervised-learning-for\/review\/?hl=58890"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":137,
                "name":"Pre-trained on IG-1B & ImageNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58891,
        "rank":8,
        "Model":"BiT-M",
        "mlmodel":{

        },
        "method_short":"BiT-M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-24",
        "metrics":{
            "Average Top-1 Accuracy":"40.4"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":40.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":178162,
            "title":"Big Transfer (BiT): General Visual Representation Learning",
            "url":"\/paper\/large-scale-learning-of-general-visual",
            "published":"2019-12-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-learning-of-general-visual\/review\/?hl=58891"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":261,
                "name":"pre-trained on ImageNet22K",
                "color":"#bb25b6"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58876,
        "rank":9,
        "Model":"DINO",
        "mlmodel":{

        },
        "method_short":"DINO",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Average Top-1 Accuracy":"38.9"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":38.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=58876"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":110,
                "name":"unsupervised",
                "color":"#d33227"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58878,
        "rank":10,
        "Model":"SwAV",
        "mlmodel":{

        },
        "method_short":"SwAV",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Average Top-1 Accuracy":"38.3"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":38.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":202916,
            "title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
            "url":"\/paper\/unsupervised-learning-of-visual-features-by",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-learning-of-visual-features-by\/review\/?hl=58878"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":110,
                "name":"unsupervised",
                "color":"#d33227"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58884,
        "rank":11,
        "Model":"ResNet-101",
        "mlmodel":{

        },
        "method_short":"ResNet-101",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-12-10",
        "metrics":{
            "Average Top-1 Accuracy":"37.4"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":37.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":37118,
            "title":"Deep Residual Learning for Image Recognition",
            "url":"\/paper\/deep-residual-learning-for-image-recognition",
            "published":"2015-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-residual-learning-for-image-recognition\/review\/?hl=58884"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":261,
                "name":"pre-trained on ImageNet22K",
                "color":"#bb25b6"
            },
            {
                "id":54,
                "name":"ResNet-101",
                "color":"#cc1e1e"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58886,
        "rank":12,
        "Model":"MEAL-V2",
        "mlmodel":{

        },
        "method_short":"MEAL-V2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-09-17",
        "metrics":{
            "Average Top-1 Accuracy":"36.6"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":36.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":218270,
            "title":"MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks",
            "url":"\/paper\/meal-v2-boosting-vanilla-resnet-50-to-80-top",
            "published":"2020-09-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/meal-v2-boosting-vanilla-resnet-50-to-80-top\/review\/?hl=58886"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":263,
                "name":"augmentation",
                "color":"#2743d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58893,
        "rank":13,
        "Model":"MoPro-V2",
        "mlmodel":{

        },
        "method_short":"MoPro-V2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-09-17",
        "metrics":{
            "Average Top-1 Accuracy":"36.1"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":36.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":218388,
            "title":"MoPro: Webly Supervised Learning with Momentum Prototypes",
            "url":"\/paper\/mopro-webly-supervised-learning-with-momentum",
            "published":"2020-09-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mopro-webly-supervised-learning-with-momentum\/review\/?hl=58893"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":263,
                "name":"augmentation",
                "color":"#2743d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58882,
        "rank":14,
        "Model":"EfficientNetB4",
        "mlmodel":{

        },
        "method_short":"EfficientNetB4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-28",
        "metrics":{
            "Average Top-1 Accuracy":"35.8"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":35.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":117456,
            "title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
            "url":"\/paper\/efficientnet-rethinking-model-scaling-for",
            "published":"2019-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficientnet-rethinking-model-scaling-for\/review\/?hl=58882"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58877,
        "rank":15,
        "Model":"MoCoV2",
        "mlmodel":{

        },
        "method_short":"MoCoV2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Average Top-1 Accuracy":"34.8"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":34.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":172144,
            "title":"Momentum Contrast for Unsupervised Visual Representation Learning",
            "url":"\/paper\/momentum-contrast-for-unsupervised-visual",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/momentum-contrast-for-unsupervised-visual\/review\/?hl=58877"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58875,
        "rank":16,
        "Model":"ResNet-50",
        "mlmodel":{

        },
        "method_short":"ResNet-50",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-12-10",
        "metrics":{
            "Average Top-1 Accuracy":"34.3"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":34.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":37118,
            "title":"Deep Residual Learning for Image Recognition",
            "url":"\/paper\/deep-residual-learning-for-image-recognition",
            "published":"2015-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-residual-learning-for-image-recognition\/review\/?hl=58875"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":131,
                "name":"Pre-trained on ImageNet",
                "color":"#27d39f"
            },
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58885,
        "rank":17,
        "Model":"InceptionV4",
        "mlmodel":{

        },
        "method_short":"InceptionV4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-02-23",
        "metrics":{
            "Average Top-1 Accuracy":"32.3"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":32.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":31162,
            "title":"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
            "url":"\/paper\/inception-v4-inception-resnet-and-the-impact",
            "published":"2016-02-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/inception-v4-inception-resnet-and-the-impact\/review\/?hl=58885"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58883,
        "rank":18,
        "Model":"MLP-Mixer",
        "mlmodel":{

        },
        "method_short":"MLP-Mixer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-04",
        "metrics":{
            "Average Top-1 Accuracy":"32.2"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":32.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":793349,
            "title":"MLP-Mixer: An all-MLP Architecture for Vision",
            "url":"\/paper\/mlp-mixer-an-all-mlp-architecture-for-vision",
            "published":"2021-05-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mlp-mixer-an-all-mlp-architecture-for-vision\/review\/?hl=58883"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":18,
                "name":"MLP",
                "color":"#ffae00"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58888,
        "rank":19,
        "Model":"Manifold",
        "mlmodel":{

        },
        "method_short":"Manifold",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-06-13",
        "metrics":{
            "Average Top-1 Accuracy":"31.6"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":31.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":456,
            "title":"Manifold Mixup: Better Representations by Interpolating Hidden States",
            "url":"\/paper\/manifold-mixup-better-representations-by",
            "published":"2018-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/manifold-mixup-better-representations-by\/review\/?hl=58888"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":263,
                "name":"augmentation",
                "color":"#2743d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58887,
        "rank":20,
        "Model":"CutMix",
        "mlmodel":{

        },
        "method_short":"CutMix",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-13",
        "metrics":{
            "Average Top-1 Accuracy":"31.1"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":31.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":114316,
            "title":"CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features",
            "url":"\/paper\/cutmix-regularization-strategy-to-train",
            "published":"2019-05-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cutmix-regularization-strategy-to-train\/review\/?hl=58887"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":263,
                "name":"augmentation",
                "color":"#2743d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58889,
        "rank":21,
        "Model":"ReLabel",
        "mlmodel":{

        },
        "method_short":"ReLabel",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-01-13",
        "metrics":{
            "Average Top-1 Accuracy":"30.8"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":30.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":735765,
            "title":"Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels",
            "url":"\/paper\/re-labeling-imagenet-from-single-to-multi",
            "published":"2021-01-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/re-labeling-imagenet-from-single-to-multi\/review\/?hl=58889"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":263,
                "name":"augmentation",
                "color":"#2743d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58879,
        "rank":22,
        "Model":"MAE",
        "mlmodel":{

        },
        "method_short":"MAE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-11",
        "metrics":{
            "Average Top-1 Accuracy":"30.6"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":30.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":908690,
            "title":"Masked Autoencoders Are Scalable Vision Learners",
            "url":"\/paper\/masked-autoencoders-are-scalable-vision",
            "published":"2021-11-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/masked-autoencoders-are-scalable-vision\/review\/?hl=58879"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":110,
                "name":"unsupervised",
                "color":"#d33227"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":18404,
        "row_id":58880,
        "rank":23,
        "Model":"BeiT",
        "mlmodel":{

        },
        "method_short":"BeiT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-15",
        "metrics":{
            "Average Top-1 Accuracy":"30.1"
        },
        "raw_metrics":{
            "Average Top-1 Accuracy":30.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":818838,
            "title":"BEiT: BERT Pre-Training of Image Transformers",
            "url":"\/paper\/beit-bert-pre-training-of-image-transformers",
            "published":"2021-06-15T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":262,
                "name":"linear probing",
                "color":"#74433c"
            },
            {
                "id":201,
                "name":"Unsupervised",
                "color":"#d3276c"
            }
        ],
        "reports":[

        ]
    }
]