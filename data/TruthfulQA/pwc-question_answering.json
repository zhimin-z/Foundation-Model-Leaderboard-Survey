[
    {
        "table_id":12484,
        "row_id":110275,
        "rank":1,
        "method":"GPT-4 (RLHF)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"RLHF",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "MC1":"0.59",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.59,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=110275"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":111323,
        "rank":2,
        "method":"LLaMA-2-Chat-13B + Representation Control (Contrast Vector)",
        "mlmodel":{

        },
        "Model":"LLaMA-2-Chat-13B + Representation Control ",
        "method_details":"Contrast Vector",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-02",
        "metrics":{
            "MC1":"0.54",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.54,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1292050,
            "title":"Representation Engineering: A Top-Down Approach to AI Transparency",
            "url":"\/paper\/representation-engineering-a-top-down",
            "published":"2023-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/representation-engineering-a-top-down\/review\/?hl=111323"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":111324,
        "rank":3,
        "method":"LLaMA-2-Chat-7B + Representation Control (Contrast Vector)",
        "mlmodel":{

        },
        "Model":"LLaMA-2-Chat-7B + Representation Control ",
        "method_details":"Contrast Vector",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-02",
        "metrics":{
            "MC1":"0.48",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.48,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1292050,
            "title":"Representation Engineering: A Top-Down Approach to AI Transparency",
            "url":"\/paper\/representation-engineering-a-top-down",
            "published":"2023-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/representation-engineering-a-top-down\/review\/?hl=111324"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":105816,
        "rank":4,
        "method":"Vicuna 7B + Inference Time Intervention (ITI)",
        "mlmodel":{

        },
        "Model":"Vicuna 7B + Inference Time Intervention ",
        "method_details":"ITI",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "MC1":"0.389",
            "MC2":null,
            "% true":"88.6",
            "% info":"83.5",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.389,
            "MC2":null,
            "% true":88.6,
            "% info":83.5,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":105815,
        "rank":5,
        "method":"Alpaca 7B + Inference Time Intervention (ITI)",
        "mlmodel":{

        },
        "Model":"Alpaca 7B + Inference Time Intervention ",
        "method_details":"ITI",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "MC1":"0.319",
            "MC2":null,
            "% true":"66.6",
            "% info":"97.7",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.319,
            "MC2":null,
            "% true":66.6,
            "% info":97.7,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":60878,
        "rank":6,
        "method":"Gopher 280B (zero-shot, Our Prompt + Choices)",
        "mlmodel":{

        },
        "Model":"Gopher 280B ",
        "method_details":"zero-shot, Our Prompt + Choices",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0.295",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.295,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":105814,
        "rank":7,
        "method":"LLaMA 7B + Inference Time Intervention (ITI)",
        "mlmodel":{

        },
        "Model":"LLaMA 7B + Inference Time Intervention ",
        "method_details":"ITI",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "MC1":"0.288",
            "MC2":null,
            "% true":"45.1",
            "% info":"93.8",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.288,
            "MC2":null,
            "% true":45.1,
            "% info":93.8,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":80297,
        "rank":8,
        "method":"GAL 120B",
        "mlmodel":{

        },
        "Model":"GAL 120B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.26",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.26,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80297"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":77129,
        "rank":9,
        "method":"Gopher 7.1 (zero-shot, QA prompts)",
        "mlmodel":{

        },
        "Model":"Gopher 7.1 ",
        "method_details":"zero-shot, QA prompts",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0.25",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.25,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":80296,
        "rank":10,
        "method":"GAL 30B",
        "mlmodel":{

        },
        "Model":"GAL 30B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.24",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.24,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80296"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":60879,
        "rank":11,
        "method":"Gopher 7.1B (zero-shot, Our Prompt + Choices)",
        "mlmodel":{

        },
        "Model":"Gopher 7.1B ",
        "method_details":"zero-shot, Our Prompt + Choices",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0.23",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.23,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":77130,
        "rank":12,
        "method":"Gopher 1.4 (zero-shot, QA prompts)",
        "mlmodel":{

        },
        "Model":"Gopher 1.4 ",
        "method_details":"zero-shot, QA prompts",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0.23",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.23,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":39605,
        "rank":13,
        "method":"GPT-2 1.5B",
        "mlmodel":{

        },
        "Model":"GPT-2 1.5B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-08",
        "metrics":{
            "MC1":"0.22",
            "MC2":"0.39",
            "% true":"29.50",
            "% info":"89.84",
            "% true (GPT-judge)":"29.87",
            "BLEURT":"-0.25",
            "ROUGE":"-9.41",
            "BLEU":"-4.91"
        },
        "raw_metrics":{
            "MC1":0.22,
            "MC2":0.39,
            "% true":29.5,
            "% info":89.84,
            "% true (GPT-judge)":29.87,
            "BLEURT":-0.25,
            "ROUGE":-9.41,
            "BLEU":-4.91
        },
        "uses_additional_data":false,
        "paper":{
            "id":868989,
            "title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods",
            "url":"\/paper\/truthfulqa-measuring-how-models-mimic-human",
            "published":"2021-09-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/truthfulqa-measuring-how-models-mimic-human\/review\/?hl=39605"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":60880,
        "rank":14,
        "method":"Gopher 1.4B (zero-shot, Our Prompt + Choices)",
        "mlmodel":{

        },
        "Model":"Gopher 1.4B ",
        "method_details":"zero-shot, Our Prompt + Choices",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0.217",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.217,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":39602,
        "rank":15,
        "method":"GPT-3 175B",
        "mlmodel":{

        },
        "Model":"GPT-3 175B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-08",
        "metrics":{
            "MC1":"0.21",
            "MC2":"0.33",
            "% true":"20.44",
            "% info":"97.55",
            "% true (GPT-judge)":"20.56",
            "BLEURT":"-0.56",
            "ROUGE":"-17.75",
            "BLEU":"-17.38"
        },
        "raw_metrics":{
            "MC1":0.21,
            "MC2":0.33,
            "% true":20.44,
            "% info":97.55,
            "% true (GPT-judge)":20.56,
            "BLEURT":-0.56,
            "ROUGE":-17.75,
            "BLEU":-17.38
        },
        "uses_additional_data":false,
        "paper":{
            "id":868989,
            "title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods",
            "url":"\/paper\/truthfulqa-measuring-how-models-mimic-human",
            "published":"2021-09-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/truthfulqa-measuring-how-models-mimic-human\/review\/?hl=39602"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":85015,
        "rank":16,
        "method":"OPT 175B",
        "mlmodel":{

        },
        "Model":"OPT 175B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.21",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.21,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85015"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":39604,
        "rank":17,
        "method":"GPT-J 6B",
        "mlmodel":{

        },
        "Model":"GPT-J 6B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-08",
        "metrics":{
            "MC1":"0.20",
            "MC2":"0.36",
            "% true":"26.68",
            "% info":"89.96",
            "% true (GPT-judge)":"27.17",
            "BLEURT":"-0.31",
            "ROUGE":"-11.35",
            "BLEU":"-7.58"
        },
        "raw_metrics":{
            "MC1":0.2,
            "MC2":0.36,
            "% true":26.68,
            "% info":89.96,
            "% true (GPT-judge)":27.17,
            "BLEURT":-0.31,
            "ROUGE":-11.35,
            "BLEU":-7.58
        },
        "uses_additional_data":false,
        "paper":{
            "id":868989,
            "title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods",
            "url":"\/paper\/truthfulqa-measuring-how-models-mimic-human",
            "published":"2021-09-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/truthfulqa-measuring-how-models-mimic-human\/review\/?hl=39604"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":39606,
        "rank":18,
        "method":"UnifiedQA 3B",
        "mlmodel":{

        },
        "Model":"UnifiedQA 3B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-08",
        "metrics":{
            "MC1":"0.19",
            "MC2":"0.35",
            "% true":"53.86",
            "% info":"64.50",
            "% true (GPT-judge)":"53.24",
            "BLEURT":"0.08",
            "ROUGE":"1.76",
            "BLEU":"-0.16"
        },
        "raw_metrics":{
            "MC1":0.19,
            "MC2":0.35,
            "% true":53.86,
            "% info":64.5,
            "% true (GPT-judge)":53.24,
            "BLEURT":0.08,
            "ROUGE":1.76,
            "BLEU":-0.16
        },
        "uses_additional_data":false,
        "paper":{
            "id":868989,
            "title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods",
            "url":"\/paper\/truthfulqa-measuring-how-models-mimic-human",
            "published":"2021-09-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/truthfulqa-measuring-how-models-mimic-human\/review\/?hl=39606"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":80293,
        "rank":19,
        "method":"GAL 125M",
        "mlmodel":{

        },
        "Model":"GAL 125M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.19",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.19,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80293"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":80294,
        "rank":20,
        "method":"GAL 1.3B",
        "mlmodel":{

        },
        "Model":"GAL 1.3B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.19",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.19,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80294"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":80295,
        "rank":21,
        "method":"GAL 6.7B",
        "mlmodel":{

        },
        "Model":"GAL 6.7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "MC1":"0.19",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0.19,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80295"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":77128,
        "rank":22,
        "method":"Gopher 280B (zero-shot, QA prompts)",
        "mlmodel":{

        },
        "Model":"Gopher 280B ",
        "method_details":"zero-shot, QA prompts",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "MC1":"0. 27",
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":0,
            "MC2":null,
            "% true":null,
            "% info":null,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":97690,
        "rank":23,
        "method":"LLaMA 65B",
        "mlmodel":{

        },
        "Model":"LLaMA 65B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "MC1":null,
            "MC2":null,
            "% true":"57",
            "% info":"53",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":null,
            "MC2":null,
            "% true":57.0,
            "% info":53.0,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97690"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":97689,
        "rank":24,
        "method":"LLaMA 33B",
        "mlmodel":{

        },
        "Model":"LLaMA 33B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "MC1":null,
            "MC2":null,
            "% true":"52",
            "% info":"48",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":null,
            "MC2":null,
            "% true":52.0,
            "% info":48.0,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97689"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":97688,
        "rank":25,
        "method":"LLaMA 13B",
        "mlmodel":{

        },
        "Model":"LLaMA 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "MC1":null,
            "MC2":null,
            "% true":"47",
            "% info":"41",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":null,
            "MC2":null,
            "% true":47.0,
            "% info":41.0,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97688"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12484,
        "row_id":97687,
        "rank":26,
        "method":"LLaMA 7B",
        "mlmodel":{

        },
        "Model":"LLaMA 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "MC1":null,
            "MC2":null,
            "% true":"33",
            "% info":"29",
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "raw_metrics":{
            "MC1":null,
            "MC2":null,
            "% true":33.0,
            "% info":29.0,
            "% true (GPT-judge)":null,
            "BLEURT":null,
            "ROUGE":null,
            "BLEU":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97687"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]