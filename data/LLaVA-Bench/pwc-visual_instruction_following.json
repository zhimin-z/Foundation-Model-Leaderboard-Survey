[
    {
        "table_id":25941,
        "row_id":114185,
        "rank":1,
        "method":"ShareGPT4V-13B",
        "mlmodel":{

        },
        "Model":"ShareGPT4V-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-21",
        "metrics":{
            "avg score":"79.9"
        },
        "raw_metrics":{
            "avg score":79.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1325159,
            "title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions",
            "url":"\/paper\/sharegpt4v-improving-large-multi-modal-models",
            "published":"2023-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sharegpt4v-improving-large-multi-modal-models\/review\/?hl=114185"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114184,
        "rank":2,
        "method":"ShareGPT4V-7B",
        "mlmodel":{

        },
        "Model":"ShareGPT4V-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-21",
        "metrics":{
            "avg score":"72.6"
        },
        "raw_metrics":{
            "avg score":72.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1325159,
            "title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions",
            "url":"\/paper\/sharegpt4v-improving-large-multi-modal-models",
            "published":"2023-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sharegpt4v-improving-large-multi-modal-models\/review\/?hl=114184"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114187,
        "rank":3,
        "method":"LLaVA-v1.5-13B",
        "mlmodel":{

        },
        "Model":"LLaVA-v1.5-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "avg score":"70.7"
        },
        "raw_metrics":{
            "avg score":70.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=114187"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114186,
        "rank":4,
        "method":"LLaVA-v1.5-7B",
        "mlmodel":{

        },
        "Model":"LLaVA-v1.5-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "avg score":"63.4"
        },
        "raw_metrics":{
            "avg score":63.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=114186"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114188,
        "rank":5,
        "method":"InstructBLIP-7B",
        "mlmodel":{

        },
        "Model":"InstructBLIP-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "avg score":"60.9"
        },
        "raw_metrics":{
            "avg score":60.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333348,
            "title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
            "url":"\/paper\/instructblip-towards-general-purpose-vision",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114189,
        "rank":6,
        "method":"InstructBLIP-13B",
        "mlmodel":{

        },
        "Model":"InstructBLIP-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "avg score":"58.2"
        },
        "raw_metrics":{
            "avg score":58.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333348,
            "title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
            "url":"\/paper\/instructblip-towards-general-purpose-vision",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25941,
        "row_id":114190,
        "rank":7,
        "method":"BLIP-2",
        "mlmodel":{

        },
        "Model":"BLIP-2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-30",
        "metrics":{
            "avg score":"38.1"
        },
        "raw_metrics":{
            "avg score":38.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1149122,
            "title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
            "url":"\/paper\/blip-2-bootstrapping-language-image-pre",
            "published":"2023-01-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/blip-2-bootstrapping-language-image-pre\/review\/?hl=114190"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]