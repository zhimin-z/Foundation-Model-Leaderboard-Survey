[
    {
        "table_id":386,
        "row_id":97049,
        "rank":1,
        "Model":"Parti Finetuned",
        "mlmodel":{

        },
        "method_short":"Parti Finetuned",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-22",
        "metrics":{
            "FID":"3.22",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":3.22,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1031436,
            "title":"Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
            "url":"\/paper\/scaling-autoregressive-models-for-content",
            "published":"2022-06-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-autoregressive-models-for-content\/review\/?hl=97049"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":485,
                "name":"Autoregressive",
                "color":"#d38327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":108730,
        "rank":2,
        "Model":"CM3Leon-7B",
        "mlmodel":{

        },
        "method_short":"CM3Leon-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-05",
        "metrics":{
            "FID":"4.88",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":4.88,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1274389,
            "title":"Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning",
            "url":"\/paper\/scaling-autoregressive-multi-modal-models",
            "published":"2023-09-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-autoregressive-multi-modal-models\/review\/?hl=108730"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":485,
                "name":"Autoregressive",
                "color":"#d38327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96270,
        "rank":3,
        "Model":"Re-Imagen (Finetuned)",
        "mlmodel":{

        },
        "method_short":"Re-Imagen ",
        "method_details":"Finetuned",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-29",
        "metrics":{
            "FID":"5.25",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":5.25,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1082694,
            "title":"Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
            "url":"\/paper\/re-imagen-retrieval-augmented-text-to-image",
            "published":"2022-09-29T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/re-imagen-retrieval-augmented-text-to-image\/review\/?hl=96270"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":105223,
        "rank":4,
        "Model":"U-ViT-S\/2-Deep",
        "mlmodel":{

        },
        "method_short":"U-ViT-S\/2-Deep",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-25",
        "metrics":{
            "FID":"5.48",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":5.48,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1080097,
            "title":"All are Worth Words: A ViT Backbone for Diffusion Models",
            "url":"\/paper\/all-are-worth-words-a-vit-backbone-for-score",
            "published":"2022-09-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/all-are-worth-words-a-vit-backbone-for-score\/review\/?hl=105223"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":89481,
        "rank":5,
        "Model":"GLIGEN (fine-tuned, Detection + Caption data)",
        "mlmodel":{

        },
        "method_short":"GLIGEN ",
        "method_details":"fine-tuned, Detection + Caption data",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-17",
        "metrics":{
            "FID":"5.61",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":5.61,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1143499,
            "title":"GLIGEN: Open-Set Grounded Text-to-Image Generation",
            "url":"\/paper\/gligen-open-set-grounded-text-to-image",
            "published":"2023-01-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gligen-open-set-grounded-text-to-image\/review\/?hl=89481"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":89480,
        "rank":6,
        "Model":"GLIGEN (fine-tuned, Detection data only)",
        "mlmodel":{

        },
        "method_short":"GLIGEN ",
        "method_details":"fine-tuned, Detection data only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-17",
        "metrics":{
            "FID":"5.82",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":5.82,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1143499,
            "title":"GLIGEN: Open-Set Grounded Text-to-Image Generation",
            "url":"\/paper\/gligen-open-set-grounded-text-to-image",
            "published":"2023-01-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gligen-open-set-grounded-text-to-image\/review\/?hl=89480"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":105224,
        "rank":7,
        "Model":"U-ViT-S\/2",
        "mlmodel":{

        },
        "method_short":"U-ViT-S\/2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-25",
        "metrics":{
            "FID":"5.95",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":5.95,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1080097,
            "title":"All are Worth Words: A ViT Backbone for Diffusion Models",
            "url":"\/paper\/all-are-worth-words-a-vit-backbone-for-score",
            "published":"2022-09-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/all-are-worth-words-a-vit-backbone-for-score\/review\/?hl=105224"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":105173,
        "rank":8,
        "Model":"TLDM",
        "mlmodel":{

        },
        "method_short":"TLDM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-19",
        "metrics":{
            "FID":"6.29",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.29,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":964964,
            "title":"Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders",
            "url":"\/paper\/truncated-diffusion-probabilistic-models",
            "published":"2022-02-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/truncated-diffusion-probabilistic-models\/review\/?hl=105173"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":89482,
        "rank":9,
        "Model":"GLIGEN (fine-tuned, Grounding data)",
        "mlmodel":{

        },
        "method_short":"GLIGEN ",
        "method_details":"fine-tuned, Grounding data",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-17",
        "metrics":{
            "FID":"6.38",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.38,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1143499,
            "title":"GLIGEN: Open-Set Grounded Text-to-Image Generation",
            "url":"\/paper\/gligen-open-set-grounded-text-to-image",
            "published":"2023-01-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gligen-open-set-grounded-text-to-image\/review\/?hl=89482"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":107573,
        "rank":10,
        "Model":"RAPHAEL (zero-shot)",
        "mlmodel":{

        },
        "method_short":"RAPHAEL ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "FID":"6.61",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.61,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1218281,
            "title":"RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths",
            "url":"\/paper\/raphael-text-to-image-generation-via-large",
            "published":"2023-05-29T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":87394,
        "rank":11,
        "Model":"ERNIE-ViLG 2.0 (zero-shot)",
        "mlmodel":{

        },
        "method_short":"ERNIE-ViLG 2.0 ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-27",
        "metrics":{
            "FID":"6.75",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.75,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1100948,
            "title":"ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts",
            "url":"\/paper\/ernie-vilg-2-0-improving-text-to-image",
            "published":"2022-10-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-vilg-2-0-improving-text-to-image\/review\/?hl=87394"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96269,
        "rank":12,
        "Model":"Re-Imagen",
        "mlmodel":{

        },
        "method_short":"Re-Imagen",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-29",
        "metrics":{
            "FID":"6.88",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.88,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1082694,
            "title":"Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
            "url":"\/paper\/re-imagen-retrieval-augmented-text-to-image",
            "published":"2022-09-29T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/re-imagen-retrieval-augmented-text-to-image\/review\/?hl=96269"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":83159,
        "rank":13,
        "Model":"eDiff-I (zero-shot)",
        "mlmodel":{

        },
        "method_short":"eDiff-I ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-02",
        "metrics":{
            "FID":"6.95",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":6.95,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1104639,
            "title":"eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers",
            "url":"\/paper\/ediffi-text-to-image-diffusion-models-with-an",
            "published":"2022-11-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ediffi-text-to-image-diffusion-models-with-an\/review\/?hl=83159"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":79047,
        "rank":14,
        "Model":"Swinv2-Imagen",
        "mlmodel":{

        },
        "method_short":"Swinv2-Imagen",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-18",
        "metrics":{
            "FID":"7.21",
            "Inception score":"31.46",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.21,
            "Inception score":31.46,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1095579,
            "title":"Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for Text-to-Image Generation",
            "url":"\/paper\/swinv2-imagen-hierarchical-vision-transformer",
            "published":"2022-10-18T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/swinv2-imagen-hierarchical-vision-transformer\/review\/?hl=79047"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":75484,
        "rank":15,
        "Model":"Parti",
        "mlmodel":{

        },
        "method_short":"Parti",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-22",
        "metrics":{
            "FID":"7.23",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.23,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1031436,
            "title":"Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
            "url":"\/paper\/scaling-autoregressive-models-for-content",
            "published":"2022-06-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-autoregressive-models-for-content\/review\/?hl=75484"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":485,
                "name":"Autoregressive",
                "color":"#d38327"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55292,
        "rank":16,
        "Model":"Imagen (zero-shot)",
        "mlmodel":{

        },
        "method_short":"Imagen ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-23",
        "metrics":{
            "FID":"7.27",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.27,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1014103,
            "title":"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
            "url":"\/paper\/photorealistic-text-to-image-diffusion-models",
            "published":"2022-05-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":99001,
        "rank":17,
        "Model":"GigaGAN (Zero-shot, 64x64)",
        "mlmodel":{

        },
        "method_short":"GigaGAN ",
        "method_details":"Zero-shot, 64x64",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-09",
        "metrics":{
            "FID":"7.28",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.28,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1171028,
            "title":"Scaling up GANs for Text-to-Image Synthesis",
            "url":"\/paper\/scaling-up-gans-for-text-to-image-synthesis",
            "published":"2023-03-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-up-gans-for-text-to-image-synthesis\/review\/?hl=99001"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":95705,
        "rank":18,
        "Model":"StyleGAN-T (Zero-shot, 64x64)",
        "mlmodel":{

        },
        "method_short":"StyleGAN-T ",
        "method_details":"Zero-shot, 64x64",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-23",
        "metrics":{
            "FID":"7.3",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.3,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1145779,
            "title":"StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis",
            "url":"\/paper\/stylegan-t-unlocking-the-power-of-gans-for",
            "published":"2023-01-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/stylegan-t-unlocking-the-power-of-gans-for\/review\/?hl=95705"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":79045,
        "rank":19,
        "Model":"Make-a-Scene (unfiltered)",
        "mlmodel":{

        },
        "method_short":"Make-a-Scene ",
        "method_details":"unfiltered",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-24",
        "metrics":{
            "FID":"7.55",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.55,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":982815,
            "title":"Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors",
            "url":"\/paper\/make-a-scene-scene-based-text-to-image",
            "published":"2022-03-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/make-a-scene-scene-based-text-to-image\/review\/?hl=79045"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":485,
                "name":"Autoregressive",
                "color":"#d38327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":88680,
        "rank":20,
        "Model":"Muse-3B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"Muse-3B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "FID":"7.88",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":7.88,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136877,
            "title":"Muse: Text-To-Image Generation via Masked Generative Transformers",
            "url":"\/paper\/muse-text-to-image-generation-via-masked",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/muse-text-to-image-generation-via-masked\/review\/?hl=88680"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":484,
                "name":"Mask Prediction",
                "color":"#27d35a"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":109795,
        "rank":21,
        "Model":"Kandinsky",
        "mlmodel":{

        },
        "method_short":"Kandinsky",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "FID":"8.03",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":8.03,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293149,
            "title":"Kandinsky: an Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion",
            "url":"\/paper\/kandinsky-an-improved-text-to-image-synthesis",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/kandinsky-an-improved-text-to-image-synthesis\/review\/?hl=109795"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":43591,
        "rank":22,
        "Model":"Lafite",
        "mlmodel":{

        },
        "method_short":"Lafite",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-27",
        "metrics":{
            "FID":"8.12",
            "Inception score":"32.34",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":"61.09"
        },
        "raw_metrics":{
            "FID":8.12,
            "Inception score":32.34,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":61.09
        },
        "uses_additional_data":false,
        "paper":{
            "id":921956,
            "title":"LAFITE: Towards Language-Free Training for Text-to-Image Generation",
            "url":"\/paper\/lafite-towards-language-free-training-for",
            "published":"2021-11-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/lafite-towards-language-free-training-for\/review\/?hl=43591"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":105567,
        "rank":23,
        "Model":"simple diffusion (U-ViT)",
        "mlmodel":{

        },
        "method_short":"simple diffusion ",
        "method_details":"U-ViT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "FID":"8.3",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":8.3,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1147811,
            "title":"Simple diffusion: End-to-end diffusion for high resolution images",
            "url":"\/paper\/simple-diffusion-end-to-end-diffusion-for",
            "published":"2023-01-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/simple-diffusion-end-to-end-diffusion-for\/review\/?hl=105567"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":99000,
        "rank":24,
        "Model":"GigaGAN (Zero-shot, 256x256)",
        "mlmodel":{

        },
        "method_short":"GigaGAN ",
        "method_details":"Zero-shot, 256x256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-09",
        "metrics":{
            "FID":"9.09",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":9.09,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1171028,
            "title":"Scaling up GANs for Text-to-Image Synthesis",
            "url":"\/paper\/scaling-up-gans-for-text-to-image-synthesis",
            "published":"2023-03-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-up-gans-for-text-to-image-synthesis\/review\/?hl=99000"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96293,
        "rank":25,
        "Model":"XMC-GAN (256 x 256)",
        "mlmodel":{

        },
        "method_short":"XMC-GAN ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":"9.3",
            "Inception score":"30.5",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":9.3,
            "Inception score":30.5,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96293"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55251,
        "rank":26,
        "Model":"XMC-GAN",
        "mlmodel":{

        },
        "method_short":"XMC-GAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-01-12",
        "metrics":{
            "FID":"9.33",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":9.33,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":735749,
            "title":"Cross-Modal Contrastive Learning for Text-to-Image Generation",
            "url":"\/paper\/cross-modal-contrastive-learning-for-text-to",
            "published":"2021-01-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cross-modal-contrastive-learning-for-text-to\/review\/?hl=55251"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55293,
        "rank":27,
        "Model":"DALL-E 2",
        "mlmodel":{

        },
        "method_short":"DALL-E 2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-13",
        "metrics":{
            "FID":"10.39",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":10.39,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":993876,
            "title":"Hierarchical Text-Conditional Image Generation with CLIP Latents",
            "url":"\/paper\/hierarchical-text-conditional-image",
            "published":"2022-04-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/hierarchical-text-conditional-image\/review\/?hl=55293"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96988,
        "rank":28,
        "Model":"Corgi-Semi",
        "mlmodel":{

        },
        "method_short":"Corgi-Semi",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-24",
        "metrics":{
            "FID":"10.6",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":10.6,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1118729,
            "title":"Shifted Diffusion for Text-to-image Generation",
            "url":"\/paper\/shifted-diffusion-for-text-to-image",
            "published":"2022-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/shifted-diffusion-for-text-to-image\/review\/?hl=96988"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":176,
                "name":"semi-supervised",
                "color":"#2771D3"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96880,
        "rank":29,
        "Model":"Corgi",
        "mlmodel":{

        },
        "method_short":"Corgi",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-24",
        "metrics":{
            "FID":"10.88",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":10.88,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1118729,
            "title":"Shifted Diffusion for Text-to-image Generation",
            "url":"\/paper\/shifted-diffusion-for-text-to-image",
            "published":"2022-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/shifted-diffusion-for-text-to-image\/review\/?hl=96880"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":102003,
        "rank":30,
        "Model":"TR0N (StyleGAN-XL, LAION2BCLIP, BLIP-2, zero-shot)",
        "mlmodel":{

        },
        "method_short":"TR0N ",
        "method_details":"StyleGAN-XL, LAION2BCLIP, BLIP-2, zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-26",
        "metrics":{
            "FID":"10.9",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":10.9,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1198699,
            "title":"TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation",
            "url":"\/paper\/tr0n-translator-networks-for-0-shot-plug-and",
            "published":"2023-04-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":79046,
        "rank":31,
        "Model":"Make-a-Scene (unfiltered)",
        "mlmodel":{

        },
        "method_short":"Make-a-Scene ",
        "method_details":"unfiltered",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-24",
        "metrics":{
            "FID":"11.84",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":11.84,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":982815,
            "title":"Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors",
            "url":"\/paper\/make-a-scene-scene-based-text-to-image",
            "published":"2022-03-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/make-a-scene-scene-based-text-to-image\/review\/?hl=79046"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55294,
        "rank":32,
        "Model":"GLIDE (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GLIDE ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-20",
        "metrics":{
            "FID":"12.24",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.24,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":932461,
            "title":"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
            "url":"\/paper\/glide-towards-photorealistic-image-generation",
            "published":"2021-12-20T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96264,
        "rank":33,
        "Model":"KNN-Diffusion",
        "mlmodel":{

        },
        "method_short":"KNN-Diffusion",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-06",
        "metrics":{
            "FID":"12.5",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.5,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":990120,
            "title":"KNN-Diffusion: Image Generation via Large-Scale Retrieval",
            "url":"\/paper\/knn-diffusion-image-generation-via-large",
            "published":"2022-04-06T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/knn-diffusion-image-generation-via-large\/review\/?hl=96264"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":108418,
        "rank":34,
        "Model":"GALIP (CC12m)",
        "mlmodel":{

        },
        "method_short":"GALIP ",
        "method_details":"CC12m",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-30",
        "metrics":{
            "FID":"12.54",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.54,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1148968,
            "title":"GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis",
            "url":"\/paper\/galip-generative-adversarial-clips-for-text",
            "published":"2023-01-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galip-generative-adversarial-clips-for-text\/review\/?hl=108418"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":79044,
        "rank":35,
        "Model":"Latent Diffusion (LDM-KL-8-G)",
        "mlmodel":{

        },
        "method_short":"Latent Diffusion ",
        "method_details":"LDM-KL-8-G",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-20",
        "metrics":{
            "FID":"12.63",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.63,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":932462,
            "title":"High-Resolution Image Synthesis with Latent Diffusion Models",
            "url":"\/paper\/high-resolution-image-synthesis-with-latent",
            "published":"2021-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/high-resolution-image-synthesis-with-latent\/review\/?hl=79044"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96265,
        "rank":36,
        "Model":"Stable Diffusion",
        "mlmodel":{

        },
        "method_short":"Stable Diffusion",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-22",
        "metrics":{
            "FID":"12.63",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.63,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1116351,
            "title":"Retrieval-Augmented Multimodal Language Modeling",
            "url":"\/paper\/retrieval-augmented-multimodal-language",
            "published":"2022-11-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/retrieval-augmented-multimodal-language\/review\/?hl=96265"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96294,
        "rank":37,
        "Model":"N\u00dcWA (256 x 256)",
        "mlmodel":{

        },
        "method_short":"N\u00dcWA ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":"12.9",
            "Inception score":" 27.2",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":12.9,
            "Inception score":27.2,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96294"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":44743,
        "rank":38,
        "Model":"VQ-Diffusion-F",
        "mlmodel":{

        },
        "method_short":"VQ-Diffusion-F",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-29",
        "metrics":{
            "FID":"13.86",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":13.86,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":921851,
            "title":"Vector Quantized Diffusion Model for Text-to-Image Synthesis",
            "url":"\/paper\/vector-quantized-diffusion-model-for-text-to",
            "published":"2021-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vector-quantized-diffusion-model-for-text-to\/review\/?hl=44743"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":95706,
        "rank":39,
        "Model":"StyleGAN-T (Zero-shot, 256x256)",
        "mlmodel":{

        },
        "method_short":"StyleGAN-T ",
        "method_details":"Zero-shot, 256x256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-23",
        "metrics":{
            "FID":"13.9",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":13.9,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1145779,
            "title":"StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis",
            "url":"\/paper\/stylegan-t-unlocking-the-power-of-gans-for",
            "published":"2023-01-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/stylegan-t-unlocking-the-power-of-gans-for\/review\/?hl=95706"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":53810,
        "rank":40,
        "Model":"RAT-GAN",
        "mlmodel":{

        },
        "method_short":"RAT-GAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-22",
        "metrics":{
            "FID":"14.6",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":14.6,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":998395,
            "title":"Recurrent Affine Transformation for Text-to-image Synthesis",
            "url":"\/paper\/recurrent-affine-transformation-for-text-to",
            "published":"2022-04-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/recurrent-affine-transformation-for-text-to\/review\/?hl=53810"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55740,
        "rank":41,
        "Model":"ERNIE-ViLG",
        "mlmodel":{

        },
        "method_short":"ERNIE-ViLG",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-31",
        "metrics":{
            "FID":"14.7",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":14.7,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":934395,
            "title":"ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation",
            "url":"\/paper\/ernie-vilg-unified-generative-pre-training",
            "published":"2021-12-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-vilg-unified-generative-pre-training\/review\/?hl=55740"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96278,
        "rank":42,
        "Model":"RA-CM3 (2.7B)",
        "mlmodel":{

        },
        "method_short":"RA-CM3 ",
        "method_details":"2.7B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-22",
        "metrics":{
            "FID":"15.7",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":15.7,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1116351,
            "title":"Retrieval-Augmented Multimodal Language Modeling",
            "url":"\/paper\/retrieval-augmented-multimodal-language",
            "published":"2022-11-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/retrieval-augmented-multimodal-language\/review\/?hl=96278"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96274,
        "rank":43,
        "Model":"CogView2(6B, Finetuned)",
        "mlmodel":{

        },
        "method_short":"CogView2",
        "method_details":"6B, Finetuned",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-28",
        "metrics":{
            "FID":"17.7",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":17.7,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001909,
            "title":"CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers",
            "url":"\/paper\/cogview2-faster-and-better-text-to-image",
            "published":"2022-04-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cogview2-faster-and-better-text-to-image\/review\/?hl=96274"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55291,
        "rank":44,
        "Model":"DALL-E",
        "mlmodel":{

        },
        "method_short":"DALL-E",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-24",
        "metrics":{
            "FID":"17.89",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":17.89,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":748555,
            "title":"Zero-Shot Text-to-Image Generation",
            "url":"\/paper\/zero-shot-text-to-image-generation",
            "published":"2021-02-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/zero-shot-text-to-image-generation\/review\/?hl=55291"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":44740,
        "rank":45,
        "Model":"VQ-Diffusion-B",
        "mlmodel":{

        },
        "method_short":"VQ-Diffusion-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-29",
        "metrics":{
            "FID":"19.75",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":19.75,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":921851,
            "title":"Vector Quantized Diffusion Model for Text-to-Image Synthesis",
            "url":"\/paper\/vector-quantized-diffusion-model-for-text-to",
            "published":"2021-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vector-quantized-diffusion-model-for-text-to\/review\/?hl=44740"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":246,
                "name":"Diffusion",
                "color":"#e60a57"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":36521,
        "rank":46,
        "Model":"DM-GAN+CL",
        "mlmodel":{

        },
        "method_short":"DM-GAN+CL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-06",
        "metrics":{
            "FID":"20.79",
            "Inception score":"33.34",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":20.79,
            "Inception score":33.34,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831200,
            "title":"Improving Text-to-Image Synthesis Using Contrastive Learning",
            "url":"\/paper\/improving-text-to-image-synthesis-using",
            "published":"2021-07-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-text-to-image-synthesis-using\/review\/?hl=36521"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55295,
        "rank":47,
        "Model":"FuseDream (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"FuseDream ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-02",
        "metrics":{
            "FID":"21.16",
            "Inception score":"34.26",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":21.16,
            "Inception score":34.26,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":925561,
            "title":"FuseDream: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization",
            "url":"\/paper\/fusedream-training-free-text-to-image",
            "published":"2021-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fusedream-training-free-text-to-image\/review\/?hl=55295"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":56120,
        "rank":48,
        "Model":"FuseDream (k=5, 256)",
        "mlmodel":{

        },
        "method_short":"FuseDream ",
        "method_details":"k=5, 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-02",
        "metrics":{
            "FID":"21.16",
            "Inception score":"34.26",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":21.16,
            "Inception score":34.26,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":925561,
            "title":"FuseDream: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization",
            "url":"\/paper\/fusedream-training-free-text-to-image",
            "published":"2021-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fusedream-training-free-text-to-image\/review\/?hl=56120"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":56119,
        "rank":49,
        "Model":"FuseDream (k=10, 256)",
        "mlmodel":{

        },
        "method_short":"FuseDream ",
        "method_details":"k=10, 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-02",
        "metrics":{
            "FID":"21.89",
            "Inception score":"34.67",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":21.89,
            "Inception score":34.67,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":925561,
            "title":"FuseDream: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization",
            "url":"\/paper\/fusedream-training-free-text-to-image",
            "published":"2021-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fusedream-training-free-text-to-image\/review\/?hl=56119"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":36522,
        "rank":50,
        "Model":"AttnGAN+CL",
        "mlmodel":{

        },
        "method_short":"AttnGAN+CL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-06",
        "metrics":{
            "FID":"23.93",
            "Inception score":"25.70",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":23.93,
            "Inception score":25.7,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831200,
            "title":"Improving Text-to-Image Synthesis Using Contrastive Learning",
            "url":"\/paper\/improving-text-to-image-synthesis-using",
            "published":"2021-07-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-text-to-image-synthesis-using\/review\/?hl=36522"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96273,
        "rank":51,
        "Model":"CogView2(6B, Finetuned)",
        "mlmodel":{

        },
        "method_short":"CogView2",
        "method_details":"6B, Finetuned",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-28",
        "metrics":{
            "FID":"24",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":24.0,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001909,
            "title":"CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers",
            "url":"\/paper\/cogview2-faster-and-better-text-to-image",
            "published":"2022-04-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cogview2-faster-and-better-text-to-image\/review\/?hl=96273"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":8684,
        "rank":52,
        "Model":"OP-GAN",
        "mlmodel":{

        },
        "method_short":"OP-GAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-29",
        "metrics":{
            "FID":"24.70",
            "Inception score":"27.88",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":"35.85"
        },
        "raw_metrics":{
            "FID":24.7,
            "Inception score":27.88,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":35.85
        },
        "uses_additional_data":false,
        "paper":{
            "id":167191,
            "title":"Semantic Object Accuracy for Generative Text-to-Image Synthesis",
            "url":"\/paper\/191013321",
            "published":"2019-10-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/191013321\/review\/?hl=8684"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96289,
        "rank":53,
        "Model":"DM-GAN (256 x 256)",
        "mlmodel":{

        },
        "method_short":"DM-GAN ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":" 26.0",
            "Inception score":"32.2",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":26.0,
            "Inception score":32.2,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96289"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55297,
        "rank":54,
        "Model":"Lafite (zero-shot)",
        "mlmodel":{

        },
        "method_short":"Lafite ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-27",
        "metrics":{
            "FID":"26.94",
            "Inception score":"26.02",
            "FID-1":"22.97",
            "FID-2":"18.70",
            "FID-4":"15.72",
            "FID-8":"14.79",
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":26.94,
            "Inception score":26.02,
            "FID-1":22.97,
            "FID-2":18.7,
            "FID-4":15.72,
            "FID-8":14.79,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":921956,
            "title":"LAFITE: Towards Language-Free Training for Text-to-Image Generation",
            "url":"\/paper\/lafite-towards-language-free-training-for",
            "published":"2021-11-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/lafite-towards-language-free-training-for\/review\/?hl=55297"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":55296,
        "rank":55,
        "Model":"CogView",
        "mlmodel":{

        },
        "method_short":"CogView",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-26",
        "metrics":{
            "FID":"27.1",
            "Inception score":"18.2",
            "FID-1":"19.4",
            "FID-2":"13.9",
            "FID-4":"19.4",
            "FID-8":"23.6",
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":27.1,
            "Inception score":18.2,
            "FID-1":19.4,
            "FID-2":13.9,
            "FID-4":19.4,
            "FID-8":23.6,
            "SOA-C":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":806641,
            "title":"CogView: Mastering Text-to-Image Generation via Transformers",
            "url":"\/paper\/cogview-mastering-text-to-image-generation",
            "published":"2021-05-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cogview-mastering-text-to-image-generation\/review\/?hl=55296"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96292,
        "rank":56,
        "Model":"CogView (256 x 256)",
        "mlmodel":{

        },
        "method_short":"CogView ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":" 27.1",
            "Inception score":"18.2",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":27.1,
            "Inception score":18.2,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96292"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96291,
        "rank":57,
        "Model":"DALL-E (256 x 256)",
        "mlmodel":{

        },
        "method_short":"DALL-E ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":"27.5",
            "Inception score":"17.9",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":27.5,
            "Inception score":17.9,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96291"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96271,
        "rank":58,
        "Model":"DALL-E (12B)",
        "mlmodel":{

        },
        "method_short":"DALL-E ",
        "method_details":"12B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-22",
        "metrics":{
            "FID":"28",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":28.0,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1116351,
            "title":"Retrieval-Augmented Multimodal Language Modeling",
            "url":"\/paper\/retrieval-augmented-multimodal-language",
            "published":"2022-11-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/retrieval-augmented-multimodal-language\/review\/?hl=96271"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":29787,
        "rank":59,
        "Model":"AttnGAN + VICTR",
        "mlmodel":{

        },
        "method_short":"AttnGAN + VICTR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-07",
        "metrics":{
            "FID":"29.26",
            "Inception score":"28.18",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":29.26,
            "Inception score":28.18,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":225453,
            "title":"VICTR: Visual Information Captured Text Representation for Text-to-Image Multimodal Tasks",
            "url":"\/paper\/victr-visual-information-captured-text",
            "published":"2020-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/victr-visual-information-captured-text\/review\/?hl=29787"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96277,
        "rank":60,
        "Model":"Vanilla CM3",
        "mlmodel":{

        },
        "method_short":"Vanilla CM3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-22",
        "metrics":{
            "FID":"29.5",
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":29.5,
            "Inception score":null,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1116351,
            "title":"Retrieval-Augmented Multimodal Language Modeling",
            "url":"\/paper\/retrieval-augmented-multimodal-language",
            "published":"2022-11-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/retrieval-augmented-multimodal-language\/review\/?hl=96277"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":29789,
        "rank":61,
        "Model":"DM-GAN + VICTR",
        "mlmodel":{

        },
        "method_short":"DM-GAN + VICTR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-07",
        "metrics":{
            "FID":"32.37",
            "Inception score":"32.37",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":32.37,
            "Inception score":32.37,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":225453,
            "title":"VICTR: Visual Information Captured Text Representation for Text-to-Image Multimodal Tasks",
            "url":"\/paper\/victr-visual-information-captured-text",
            "published":"2020-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/victr-visual-information-captured-text\/review\/?hl=29789"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":12052,
        "rank":62,
        "Model":"DM-GAN",
        "mlmodel":{

        },
        "method_short":"DM-GAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-02",
        "metrics":{
            "FID":"32.64",
            "Inception score":"30.49",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":"33.44"
        },
        "raw_metrics":{
            "FID":32.64,
            "Inception score":30.49,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":33.44
        },
        "uses_additional_data":false,
        "paper":{
            "id":110250,
            "title":"DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis",
            "url":"\/paper\/dm-gan-dynamic-memory-generative-adversarial",
            "published":"2019-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/dm-gan-dynamic-memory-generative-adversarial\/review\/?hl=12052"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":3718,
        "rank":63,
        "Model":"AttnGAN + OP",
        "mlmodel":{

        },
        "method_short":"AttnGAN + OP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-03",
        "metrics":{
            "FID":"33.35",
            "Inception score":"24.76",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":"25.46"
        },
        "raw_metrics":{
            "FID":33.35,
            "Inception score":24.76,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":25.46
        },
        "uses_additional_data":false,
        "paper":{
            "id":86402,
            "title":"Generating Multiple Objects at Spatially Distinct Locations",
            "url":"\/paper\/generating-multiple-objects-at-spatially",
            "published":"2019-01-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/generating-multiple-objects-at-spatially\/review\/?hl=3718"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96288,
        "rank":64,
        "Model":"AttnGAN (256 x 256)",
        "mlmodel":{

        },
        "method_short":"AttnGAN ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":" 35.2",
            "Inception score":"23.3",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":35.2,
            "Inception score":23.3,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96288"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":2774,
        "rank":65,
        "Model":"AttnGAN",
        "mlmodel":{

        },
        "method_short":"AttnGAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-11-28",
        "metrics":{
            "FID":"35.49",
            "Inception score":"25.89",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":"25.88"
        },
        "raw_metrics":{
            "FID":35.49,
            "Inception score":25.89,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":25.88
        },
        "uses_additional_data":true,
        "paper":{
            "id":13914,
            "title":"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks",
            "url":"\/paper\/attngan-fine-grained-text-to-image-generation",
            "published":"2017-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/attngan-fine-grained-text-to-image-generation\/review\/?hl=2774"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":48660,
        "rank":66,
        "Model":"L-Verse-CC",
        "mlmodel":{

        },
        "method_short":"L-Verse-CC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-22",
        "metrics":{
            "FID":"37.2",
            "Inception score":null,
            "FID-1":"31.6",
            "FID-2":"25.7",
            "FID-4":"21.4",
            "FID-8":"21.1",
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":37.2,
            "Inception score":null,
            "FID-1":31.6,
            "FID-2":25.7,
            "FID-4":21.4,
            "FID-8":21.1,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":914416,
            "title":"L-Verse: Bidirectional Generation Between Image and Text",
            "url":"\/paper\/l-verse-bidirectional-generation-between",
            "published":"2021-11-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/l-verse-bidirectional-generation-between\/review\/?hl=48660"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":48654,
        "rank":67,
        "Model":"L-Verse",
        "mlmodel":{

        },
        "method_short":"L-Verse",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-22",
        "metrics":{
            "FID":"45.8",
            "Inception score":null,
            "FID-1":"41.9",
            "FID-2":"35.5",
            "FID-4":"30.2",
            "FID-8":"29.83",
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":45.8,
            "Inception score":null,
            "FID-1":41.9,
            "FID-2":35.5,
            "FID-4":30.2,
            "FID-8":29.83,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":914416,
            "title":"L-Verse: Bidirectional Generation Between Image and Text",
            "url":"\/paper\/l-verse-bidirectional-generation-between",
            "published":"2021-11-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/l-verse-bidirectional-generation-between\/review\/?hl=48654"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":3720,
        "rank":68,
        "Model":"StackGAN + OP",
        "mlmodel":{

        },
        "method_short":"StackGAN + OP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-03",
        "metrics":{
            "FID":"55.30",
            "Inception score":"12.12",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":55.3,
            "Inception score":12.12,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":86402,
            "title":"Generating Multiple Objects at Spatially Distinct Locations",
            "url":"\/paper\/generating-multiple-objects-at-spatially",
            "published":"2019-01-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/generating-multiple-objects-at-spatially\/review\/?hl=3720"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":85800,
        "rank":69,
        "Model":"StackGAN-v1",
        "mlmodel":{

        },
        "method_short":"StackGAN-v1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-10-19",
        "metrics":{
            "FID":"74.05",
            "Inception score":"8.45",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":74.05,
            "Inception score":8.45,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":12544,
            "title":"StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks",
            "url":"\/paper\/stackgan-realistic-image-synthesis-with",
            "published":"2017-10-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/stackgan-realistic-image-synthesis-with\/review\/?hl=85800"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":96290,
        "rank":70,
        "Model":"DF-GAN (256 x 256)",
        "mlmodel":{

        },
        "method_short":"DF-GAN ",
        "method_details":"256 x 256",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-24",
        "metrics":{
            "FID":null,
            "Inception score":"18.7",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":null,
            "Inception score":18.7,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":916177,
            "title":"N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
            "url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural",
            "published":"2021-11-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nuwa-visual-synthesis-pre-training-for-neural\/review\/?hl=96290"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":29788,
        "rank":71,
        "Model":"StackGAN + VICTR",
        "mlmodel":{

        },
        "method_short":"StackGAN + VICTR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-07",
        "metrics":{
            "FID":null,
            "Inception score":"10.38",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":null,
            "Inception score":10.38,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":225453,
            "title":"VICTR: Visual Information Captured Text Representation for Text-to-Image Multimodal Tasks",
            "url":"\/paper\/victr-visual-information-captured-text",
            "published":"2020-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/victr-visual-information-captured-text\/review\/?hl=29788"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":386,
        "row_id":5091,
        "rank":72,
        "Model":"ChatPainter",
        "mlmodel":{

        },
        "method_short":"ChatPainter",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-02-22",
        "metrics":{
            "FID":null,
            "Inception score":"9.74",
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "raw_metrics":{
            "FID":null,
            "Inception score":9.74,
            "FID-1":null,
            "FID-2":null,
            "FID-4":null,
            "FID-8":null,
            "SOA-C":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":9667,
            "title":"ChatPainter: Improving Text to Image Generation using Dialogue",
            "url":"\/paper\/chatpainter-improving-text-to-image",
            "published":"2018-02-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/chatpainter-improving-text-to-image\/review\/?hl=5091"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]