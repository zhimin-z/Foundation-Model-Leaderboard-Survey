[
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.5",
        "Average":70.35,
        "Ko-ARC":76.28,
        "Ko-HellaSwag":80.85,
        "Ko-MMLU":56.09,
        "Ko-TruthfulQA":84.33,
        "Ko-CommonGen V2":54.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-dpo-v5.0",
        "Average":70.3,
        "Ko-ARC":76.19,
        "Ko-HellaSwag":80.96,
        "Ko-MMLU":56.09,
        "Ko-TruthfulQA":84.32,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/SOLAR-10.7B",
        "Average":69.94,
        "Ko-ARC":77.05,
        "Ko-HellaSwag":79.35,
        "Ko-MMLU":55.6,
        "Ko-TruthfulQA":83.3,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-sft-dpo-v1.0",
        "Average":68.93,
        "Ko-ARC":73.81,
        "Ko-HellaSwag":70.87,
        "Ko-MMLU":58.1,
        "Ko-TruthfulQA":78.1,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-dpo-v3.0",
        "Average":68.5,
        "Ko-ARC":75.09,
        "Ko-HellaSwag":74.18,
        "Ko-MMLU":57.7,
        "Ko-TruthfulQA":80.98,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-dpo-v4.0",
        "Average":68.47,
        "Ko-ARC":75.17,
        "Ko-HellaSwag":74.98,
        "Ko-MMLU":57.27,
        "Ko-TruthfulQA":82.29,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chlee10\/T3Q-ko-solar-sft-v3.0",
        "Average":68.46,
        "Ko-ARC":73.81,
        "Ko-HellaSwag":69.17,
        "Ko-MMLU":58.18,
        "Ko-TruthfulQA":76.22,
        "Ko-CommonGen V2":64.94,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/nox_DPOv3",
        "Average":68.38,
        "Ko-ARC":74.57,
        "Ko-HellaSwag":74.6,
        "Ko-MMLU":57.92,
        "Ko-TruthfulQA":81.92,
        "Ko-CommonGen V2":52.89,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-dpo-v1.0",
        "Average":67.92,
        "Ko-ARC":73.89,
        "Ko-HellaSwag":72.46,
        "Ko-MMLU":57.94,
        "Ko-TruthfulQA":79.72,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-ko-solar-dpo-v2.0",
        "Average":67.91,
        "Ko-ARC":73.81,
        "Ko-HellaSwag":72.6,
        "Ko-MMLU":58.18,
        "Ko-TruthfulQA":79.38,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"papercat404\/mergecat_v0.1",
        "Average":67.89,
        "Ko-ARC":74.06,
        "Ko-HellaSwag":72.19,
        "Ko-MMLU":58.05,
        "Ko-TruthfulQA":79.55,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.4",
        "Average":67.86,
        "Ko-ARC":73.89,
        "Ko-HellaSwag":72.23,
        "Ko-MMLU":58.01,
        "Ko-TruthfulQA":79.57,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"hkss\/hk-SOLAR-10.7B-v1.4",
        "Average":67.85,
        "Ko-ARC":73.89,
        "Ko-HellaSwag":72.17,
        "Ko-MMLU":58.04,
        "Ko-TruthfulQA":79.52,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/nox-solar-10.7b-v4",
        "Average":67.77,
        "Ko-ARC":73.55,
        "Ko-HellaSwag":72.07,
        "Ko-MMLU":57.93,
        "Ko-TruthfulQA":79.32,
        "Ko-CommonGen V2":55.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/nox-solar-10.7b-v3",
        "Average":67.73,
        "Ko-ARC":74.57,
        "Ko-HellaSwag":72.21,
        "Ko-MMLU":58.38,
        "Ko-TruthfulQA":76.35,
        "Ko-CommonGen V2":57.14,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JY623\/KoSOLAR-v2.1",
        "Average":66.4,
        "Ko-ARC":75.0,
        "Ko-HellaSwag":67.86,
        "Ko-MMLU":60.12,
        "Ko-TruthfulQA":76.85,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/nox-solar-10.7b-v2",
        "Average":65.38,
        "Ko-ARC":73.46,
        "Ko-HellaSwag":67.32,
        "Ko-MMLU":58.7,
        "Ko-TruthfulQA":71.94,
        "Ko-CommonGen V2":55.49,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JY623\/KoSOLAR-v2.0",
        "Average":65.16,
        "Ko-ARC":74.32,
        "Ko-HellaSwag":62.62,
        "Ko-MMLU":59.23,
        "Ko-TruthfulQA":70.14,
        "Ko-CommonGen V2":59.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/nox-solar-10.7b-v4-kolon-all-5-v2.0",
        "Average":64.8,
        "Ko-ARC":74.32,
        "Ko-HellaSwag":65.8,
        "Ko-MMLU":57.91,
        "Ko-TruthfulQA":72.59,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"tlphams\/solar-10.7b-merged-v0.1",
        "Average":64.5,
        "Ko-ARC":69.71,
        "Ko-HellaSwag":69.73,
        "Ko-MMLU":58.22,
        "Ko-TruthfulQA":75.11,
        "Ko-CommonGen V2":49.7,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/nox-solar-10.7b-v4-kolon-all-5-v3.0",
        "Average":64.33,
        "Ko-ARC":73.55,
        "Ko-HellaSwag":65.23,
        "Ko-MMLU":57.15,
        "Ko-TruthfulQA":72.69,
        "Ko-CommonGen V2":53.01,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-KO-SOLAR-MG-v1.0",
        "Average":64.2,
        "Ko-ARC":73.04,
        "Ko-HellaSwag":61.79,
        "Ko-MMLU":58.57,
        "Ko-TruthfulQA":71.54,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/nox-solar-10.7b-v1",
        "Average":63.63,
        "Ko-ARC":73.04,
        "Ko-HellaSwag":63.4,
        "Ko-MMLU":58.42,
        "Ko-TruthfulQA":70.87,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.7B-v1.0",
        "Average":62.65,
        "Ko-ARC":72.61,
        "Ko-HellaSwag":58.54,
        "Ko-MMLU":56.2,
        "Ko-TruthfulQA":66.5,
        "Ko-CommonGen V2":59.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/nox-solar-10.7b-v4-kolon-all-5",
        "Average":62.5,
        "Ko-ARC":72.1,
        "Ko-HellaSwag":61.89,
        "Ko-MMLU":54.63,
        "Ko-TruthfulQA":72.17,
        "Ko-CommonGen V2":51.71,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-Rev-v3.0.4",
        "Average":62.44,
        "Ko-ARC":72.27,
        "Ko-HellaSwag":57.85,
        "Ko-MMLU":55.94,
        "Ko-TruthfulQA":66.15,
        "Ko-CommonGen V2":59.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/nox-solar-10.7b-v4-kolon-all-10",
        "Average":61.73,
        "Ko-ARC":71.25,
        "Ko-HellaSwag":61.67,
        "Ko-MMLU":53.72,
        "Ko-TruthfulQA":73.25,
        "Ko-CommonGen V2":48.76,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-v2.0.1",
        "Average":61.45,
        "Ko-ARC":72.18,
        "Ko-HellaSwag":57.07,
        "Ko-MMLU":54.12,
        "Ko-TruthfulQA":66.37,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-Rev-v2.0.4",
        "Average":61.25,
        "Ko-ARC":71.59,
        "Ko-HellaSwag":56.91,
        "Ko-MMLU":54.05,
        "Ko-TruthfulQA":65.16,
        "Ko-CommonGen V2":58.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/komt_DPOv3",
        "Average":61.2,
        "Ko-ARC":57.51,
        "Ko-HellaSwag":70.33,
        "Ko-MMLU":53.34,
        "Ko-TruthfulQA":68.49,
        "Ko-CommonGen V2":56.32,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"chihoonlee10\/T3Q-Merge-SOLAR12",
        "Average":60.82,
        "Ko-ARC":56.66,
        "Ko-HellaSwag":67.72,
        "Ko-MMLU":53.57,
        "Ko-TruthfulQA":66.19,
        "Ko-CommonGen V2":59.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freewheelin\/free-solar-slerp-v0.2",
        "Average":60.78,
        "Ko-ARC":56.48,
        "Ko-HellaSwag":67.7,
        "Ko-MMLU":53.67,
        "Ko-TruthfulQA":66.18,
        "Ko-CommonGen V2":59.86,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freewheelin\/free-solar-slerp-v0.3",
        "Average":60.75,
        "Ko-ARC":57.08,
        "Ko-HellaSwag":67.25,
        "Ko-MMLU":53.52,
        "Ko-TruthfulQA":66.04,
        "Ko-CommonGen V2":59.86,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v5",
        "Average":60.59,
        "Ko-ARC":57.08,
        "Ko-HellaSwag":69.62,
        "Ko-MMLU":52.99,
        "Ko-TruthfulQA":67.51,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ONS-AI-RESEARCH\/ONS-SOLAR-10.7B-v1.2",
        "Average":60.51,
        "Ko-ARC":57.68,
        "Ko-HellaSwag":63.45,
        "Ko-MMLU":56.88,
        "Ko-TruthfulQA":67.14,
        "Ko-CommonGen V2":57.38,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/DataVortexS_dpov3",
        "Average":60.18,
        "Ko-ARC":56.23,
        "Ko-HellaSwag":69.15,
        "Ko-MMLU":52.76,
        "Ko-TruthfulQA":67.87,
        "Ko-CommonGen V2":54.9,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"chlee10\/T3Q-Merge-SOLAR",
        "Average":60.08,
        "Ko-ARC":56.14,
        "Ko-HellaSwag":69.01,
        "Ko-MMLU":52.92,
        "Ko-TruthfulQA":67.06,
        "Ko-CommonGen V2":55.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freewheelin\/komt-solar-slerp-v0.1",
        "Average":60.08,
        "Ko-ARC":56.14,
        "Ko-HellaSwag":69.01,
        "Ko-MMLU":52.92,
        "Ko-TruthfulQA":67.06,
        "Ko-CommonGen V2":55.25,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/SOLAR-10.7B-v1.5",
        "Average":59.69,
        "Ko-ARC":57.17,
        "Ko-HellaSwag":62.14,
        "Ko-MMLU":56.96,
        "Ko-TruthfulQA":65.41,
        "Ko-CommonGen V2":56.79,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-SFT-v1.2",
        "Average":59.66,
        "Ko-ARC":56.14,
        "Ko-HellaSwag":68.27,
        "Ko-MMLU":52.78,
        "Ko-TruthfulQA":66.66,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"chlee10\/T3Q-ko-solar-sft-v1.0",
        "Average":59.57,
        "Ko-ARC":71.59,
        "Ko-HellaSwag":59.13,
        "Ko-MMLU":53.12,
        "Ko-TruthfulQA":61.37,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.11",
        "Average":59.56,
        "Ko-ARC":55.97,
        "Ko-HellaSwag":68.68,
        "Ko-MMLU":52.67,
        "Ko-TruthfulQA":66.74,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/deepnoid_DPOv3",
        "Average":59.51,
        "Ko-ARC":70.73,
        "Ko-HellaSwag":54.02,
        "Ko-MMLU":51.96,
        "Ko-TruthfulQA":66.78,
        "Ko-CommonGen V2":54.07,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v3",
        "Average":59.51,
        "Ko-ARC":55.89,
        "Ko-HellaSwag":68.44,
        "Ko-MMLU":52.75,
        "Ko-TruthfulQA":66.65,
        "Ko-CommonGen V2":53.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"chlee10\/T3Q-ko-solar-sft-v2.0",
        "Average":59.49,
        "Ko-ARC":71.93,
        "Ko-HellaSwag":59.36,
        "Ko-MMLU":54.82,
        "Ko-TruthfulQA":64.83,
        "Ko-CommonGen V2":46.52,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"freewheelin\/free-solar-dpo-v0.2",
        "Average":59.44,
        "Ko-ARC":73.55,
        "Ko-HellaSwag":61.95,
        "Ko-MMLU":57.66,
        "Ko-TruthfulQA":62.86,
        "Ko-CommonGen V2":41.2,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-SOLAR-10.7B",
        "Average":59.34,
        "Ko-ARC":55.38,
        "Ko-HellaSwag":65.56,
        "Ko-MMLU":53.38,
        "Ko-TruthfulQA":64.39,
        "Ko-CommonGen V2":57.97,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.6",
        "Average":59.22,
        "Ko-ARC":53.84,
        "Ko-HellaSwag":67.9,
        "Ko-MMLU":52.37,
        "Ko-TruthfulQA":64.6,
        "Ko-CommonGen V2":57.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-v2.0.7",
        "Average":59.11,
        "Ko-ARC":73.04,
        "Ko-HellaSwag":58.25,
        "Ko-MMLU":54.27,
        "Ko-TruthfulQA":62.18,
        "Ko-CommonGen V2":47.82,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.3.0-DPO",
        "Average":59.08,
        "Ko-ARC":54.61,
        "Ko-HellaSwag":63.65,
        "Ko-MMLU":53.38,
        "Ko-TruthfulQA":62.51,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-v3.0",
        "Average":59.06,
        "Ko-ARC":70.05,
        "Ko-HellaSwag":54.0,
        "Ko-MMLU":53.75,
        "Ko-TruthfulQA":68.02,
        "Ko-CommonGen V2":49.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"colable\/LDCC-CCK-slerp",
        "Average":58.89,
        "Ko-ARC":53.92,
        "Ko-HellaSwag":64.35,
        "Ko-MMLU":53.29,
        "Ko-TruthfulQA":63.95,
        "Ko-CommonGen V2":58.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.0.0-DPO",
        "Average":58.6,
        "Ko-ARC":52.47,
        "Ko-HellaSwag":63.25,
        "Ko-MMLU":52.91,
        "Ko-TruthfulQA":63.33,
        "Ko-CommonGen V2":61.04,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/SOLAR-10.7B-merge-dpo_v1",
        "Average":58.41,
        "Ko-ARC":62.71,
        "Ko-HellaSwag":58.72,
        "Ko-MMLU":55.61,
        "Ko-TruthfulQA":65.05,
        "Ko-CommonGen V2":49.94,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Raphael21\/Raphael21-SOLAR-10.7B",
        "Average":58.41,
        "Ko-ARC":54.18,
        "Ko-HellaSwag":67.54,
        "Ko-MMLU":53.05,
        "Ko-TruthfulQA":64.38,
        "Ko-CommonGen V2":52.89,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v4",
        "Average":58.17,
        "Ko-ARC":55.97,
        "Ko-HellaSwag":66.54,
        "Ko-MMLU":53.02,
        "Ko-TruthfulQA":60.87,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.8",
        "Average":58.15,
        "Ko-ARC":52.56,
        "Ko-HellaSwag":66.68,
        "Ko-MMLU":51.21,
        "Ko-TruthfulQA":59.27,
        "Ko-CommonGen V2":61.04,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-v1",
        "Average":58.12,
        "Ko-ARC":54.61,
        "Ko-HellaSwag":63.67,
        "Ko-MMLU":53.28,
        "Ko-TruthfulQA":60.11,
        "Ko-CommonGen V2":58.91,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/SOLAR-10.7B-merge-dpo",
        "Average":58.11,
        "Ko-ARC":66.47,
        "Ko-HellaSwag":49.98,
        "Ko-MMLU":51.45,
        "Ko-TruthfulQA":64.91,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/eeve_dpo-v3",
        "Average":57.97,
        "Ko-ARC":57.51,
        "Ko-HellaSwag":67.01,
        "Ko-MMLU":56.3,
        "Ko-TruthfulQA":54.86,
        "Ko-CommonGen V2":54.19,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.4.0-DPO",
        "Average":57.96,
        "Ko-ARC":52.05,
        "Ko-HellaSwag":62.0,
        "Ko-MMLU":53.28,
        "Ko-TruthfulQA":61.21,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.0",
        "Average":57.92,
        "Ko-ARC":56.91,
        "Ko-HellaSwag":65.81,
        "Ko-MMLU":53.81,
        "Ko-TruthfulQA":58.77,
        "Ko-CommonGen V2":54.31,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"logicker\/SkkuDataScience-DPO-v2-440-ckpt",
        "Average":57.89,
        "Ko-ARC":55.12,
        "Ko-HellaSwag":64.13,
        "Ko-MMLU":54.47,
        "Ko-TruthfulQA":55.29,
        "Ko-CommonGen V2":60.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"kimwooglae\/WebSquareAI-Instruct-KoSOLAR-10.7b-v0.5.34",
        "Average":57.79,
        "Ko-ARC":53.07,
        "Ko-HellaSwag":62.62,
        "Ko-MMLU":55.54,
        "Ko-TruthfulQA":59.64,
        "Ko-CommonGen V2":58.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ONS-AI-RESEARCH\/ONS-SOLAR-10.7B",
        "Average":57.66,
        "Ko-ARC":55.97,
        "Ko-HellaSwag":65.07,
        "Ko-MMLU":55.37,
        "Ko-TruthfulQA":56.03,
        "Ko-CommonGen V2":55.84,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.3",
        "Average":57.65,
        "Ko-ARC":52.99,
        "Ko-HellaSwag":64.8,
        "Ko-MMLU":54.86,
        "Ko-TruthfulQA":53.87,
        "Ko-CommonGen V2":61.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"c1park\/kosolra-kullm-LDCC-merge",
        "Average":57.63,
        "Ko-ARC":53.84,
        "Ko-HellaSwag":64.65,
        "Ko-MMLU":54.26,
        "Ko-TruthfulQA":56.37,
        "Ko-CommonGen V2":59.03,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.12",
        "Average":57.61,
        "Ko-ARC":54.44,
        "Ko-HellaSwag":67.21,
        "Ko-MMLU":54.09,
        "Ko-TruthfulQA":61.88,
        "Ko-CommonGen V2":50.41,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-v2.0.2",
        "Average":57.58,
        "Ko-ARC":70.05,
        "Ko-HellaSwag":52.22,
        "Ko-MMLU":49.82,
        "Ko-TruthfulQA":64.7,
        "Ko-CommonGen V2":51.12,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/mergekit_v2",
        "Average":57.58,
        "Ko-ARC":70.05,
        "Ko-HellaSwag":52.3,
        "Ko-MMLU":49.85,
        "Ko-TruthfulQA":64.68,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.0.1-DPO",
        "Average":57.38,
        "Ko-ARC":54.01,
        "Ko-HellaSwag":63.69,
        "Ko-MMLU":53.06,
        "Ko-TruthfulQA":62.63,
        "Ko-CommonGen V2":53.48,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/SOLAR-10.7B-dpo-v1",
        "Average":57.24,
        "Ko-ARC":51.54,
        "Ko-HellaSwag":60.71,
        "Ko-MMLU":49.86,
        "Ko-TruthfulQA":57.98,
        "Ko-CommonGen V2":66.12,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-v2.0.3",
        "Average":57.19,
        "Ko-ARC":70.14,
        "Ko-HellaSwag":52.17,
        "Ko-MMLU":50.11,
        "Ko-TruthfulQA":64.64,
        "Ko-CommonGen V2":48.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"logicker\/SkkuDataScience-10.7B-v5",
        "Average":57.18,
        "Ko-ARC":49.32,
        "Ko-HellaSwag":60.12,
        "Ko-MMLU":52.9,
        "Ko-TruthfulQA":58.86,
        "Ko-CommonGen V2":64.7,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"megastudyedu\/M-SOLAR-10.7B-v1.3-dpo",
        "Average":57.11,
        "Ko-ARC":51.96,
        "Ko-HellaSwag":62.3,
        "Ko-MMLU":54.99,
        "Ko-TruthfulQA":51.71,
        "Ko-CommonGen V2":64.58,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.1.0-DPO",
        "Average":57.03,
        "Ko-ARC":55.29,
        "Ko-HellaSwag":65.09,
        "Ko-MMLU":53.6,
        "Ko-TruthfulQA":57.55,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.2.0-DPO",
        "Average":57.01,
        "Ko-ARC":54.61,
        "Ko-HellaSwag":65.17,
        "Ko-MMLU":53.46,
        "Ko-TruthfulQA":57.74,
        "Ko-CommonGen V2":54.07,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"SJ-Donald\/SJ-SOLAR-10.7b-DPO",
        "Average":56.93,
        "Ko-ARC":53.67,
        "Ko-HellaSwag":61.99,
        "Ko-MMLU":53.36,
        "Ko-TruthfulQA":57.2,
        "Ko-CommonGen V2":58.44,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"SJ-Donald\/SOLAR-10.7B-slerp",
        "Average":56.93,
        "Ko-ARC":53.58,
        "Ko-HellaSwag":62.03,
        "Ko-MMLU":53.31,
        "Ko-TruthfulQA":57.16,
        "Ko-CommonGen V2":58.56,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"msy127\/ft-240209-sft",
        "Average":56.79,
        "Ko-ARC":48.98,
        "Ko-HellaSwag":60.87,
        "Ko-MMLU":53.52,
        "Ko-TruthfulQA":54.8,
        "Ko-CommonGen V2":65.76,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.1",
        "Average":56.78,
        "Ko-ARC":54.35,
        "Ko-HellaSwag":63.44,
        "Ko-MMLU":51.09,
        "Ko-TruthfulQA":53.85,
        "Ko-CommonGen V2":61.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.0.0-DPOM",
        "Average":56.71,
        "Ko-ARC":48.63,
        "Ko-HellaSwag":57.59,
        "Ko-MMLU":53.5,
        "Ko-TruthfulQA":60.06,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.64
    },
    {
        "T":"\u2b55",
        "Model":"megastudy\/M-SOLAR-10.7B-v1.3",
        "Average":56.64,
        "Ko-ARC":51.37,
        "Ko-HellaSwag":60.93,
        "Ko-MMLU":54.91,
        "Ko-TruthfulQA":48.45,
        "Ko-CommonGen V2":67.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"yanolja\/Bookworm-10.7B-v0.4-DPO",
        "Average":56.62,
        "Ko-ARC":55.63,
        "Ko-HellaSwag":66.12,
        "Ko-MMLU":55.67,
        "Ko-TruthfulQA":48.32,
        "Ko-CommonGen V2":57.38,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.2",
        "Average":56.53,
        "Ko-ARC":52.73,
        "Ko-HellaSwag":64.83,
        "Ko-MMLU":52.99,
        "Ko-TruthfulQA":58.36,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-eeve-v2.0.0",
        "Average":56.5,
        "Ko-ARC":69.03,
        "Ko-HellaSwag":51.82,
        "Ko-MMLU":49.96,
        "Ko-TruthfulQA":63.5,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JONGYUN\/DPO_Test_2",
        "Average":56.36,
        "Ko-ARC":52.56,
        "Ko-HellaSwag":63.56,
        "Ko-MMLU":54.35,
        "Ko-TruthfulQA":49.47,
        "Ko-CommonGen V2":61.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.10",
        "Average":56.32,
        "Ko-ARC":54.27,
        "Ko-HellaSwag":63.16,
        "Ko-MMLU":49.95,
        "Ko-TruthfulQA":55.08,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"logicker\/SkkuDataScience-10.7B-v6",
        "Average":56.29,
        "Ko-ARC":48.46,
        "Ko-HellaSwag":59.69,
        "Ko-MMLU":53.79,
        "Ko-TruthfulQA":55.76,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/SOLAR-10.7B-dpo-v0.1",
        "Average":56.29,
        "Ko-ARC":47.95,
        "Ko-HellaSwag":59.49,
        "Ko-MMLU":51.29,
        "Ko-TruthfulQA":60.97,
        "Ko-CommonGen V2":61.75,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"dddsaty\/KoSOLAR-10.7B_DPO_Adapter_Attach",
        "Average":56.24,
        "Ko-ARC":53.33,
        "Ko-HellaSwag":64.36,
        "Ko-MMLU":55.63,
        "Ko-TruthfulQA":45.42,
        "Ko-CommonGen V2":62.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Jaehyeon222\/M-SOLAR-10.7B-v1.0-DPO",
        "Average":56.17,
        "Ko-ARC":51.19,
        "Ko-HellaSwag":62.0,
        "Ko-MMLU":54.81,
        "Ko-TruthfulQA":52.41,
        "Ko-CommonGen V2":60.45,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"megastudyedu\/M-SOLAR-10.7B-v1.4-dpo",
        "Average":56.17,
        "Ko-ARC":54.61,
        "Ko-HellaSwag":64.45,
        "Ko-MMLU":56.17,
        "Ko-TruthfulQA":54.15,
        "Ko-CommonGen V2":51.48,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.0.0-M",
        "Average":56.17,
        "Ko-ARC":53.07,
        "Ko-HellaSwag":63.38,
        "Ko-MMLU":54.56,
        "Ko-TruthfulQA":52.33,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"logicker\/SkkuDataScience-DPO-v2-90-ckpt",
        "Average":56.16,
        "Ko-ARC":53.33,
        "Ko-HellaSwag":63.37,
        "Ko-MMLU":54.76,
        "Ko-TruthfulQA":51.51,
        "Ko-CommonGen V2":57.85,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"jeonsworld\/CarbonVillain-10.7B-v2",
        "Average":56.15,
        "Ko-ARC":48.46,
        "Ko-HellaSwag":59.78,
        "Ko-MMLU":53.42,
        "Ko-TruthfulQA":55.47,
        "Ko-CommonGen V2":63.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ONS-AI-RESEARCH\/ONS-SOLAR-KOEN-10.7B",
        "Average":56.15,
        "Ko-ARC":52.82,
        "Ko-HellaSwag":60.1,
        "Ko-MMLU":52.29,
        "Ko-TruthfulQA":61.37,
        "Ko-CommonGen V2":54.19,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-v2",
        "Average":56.15,
        "Ko-ARC":49.91,
        "Ko-HellaSwag":61.3,
        "Ko-MMLU":53.25,
        "Ko-TruthfulQA":56.66,
        "Ko-CommonGen V2":59.62,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"hkss\/hk-SOLAR-10.7B-v2.0",
        "Average":56.14,
        "Ko-ARC":53.24,
        "Ko-HellaSwag":64.21,
        "Ko-MMLU":55.56,
        "Ko-TruthfulQA":45.1,
        "Ko-CommonGen V2":62.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v2.0-DPO",
        "Average":56.13,
        "Ko-ARC":51.79,
        "Ko-HellaSwag":63.84,
        "Ko-MMLU":48.04,
        "Ko-TruthfulQA":63.62,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"hkss\/hk-SOLAR-10.7B-v1.1",
        "Average":56.12,
        "Ko-ARC":53.24,
        "Ko-HellaSwag":64.21,
        "Ko-MMLU":55.48,
        "Ko-TruthfulQA":45.08,
        "Ko-CommonGen V2":62.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"jwkweon\/CUBOX-SOLAR-10.7B-DPO-v0.1",
        "Average":56.11,
        "Ko-ARC":55.72,
        "Ko-HellaSwag":64.17,
        "Ko-MMLU":50.47,
        "Ko-TruthfulQA":50.67,
        "Ko-CommonGen V2":59.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"jeonsworld\/CarbonVillain-10.7B-v3",
        "Average":56.09,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":59.77,
        "Ko-MMLU":53.76,
        "Ko-TruthfulQA":55.72,
        "Ko-CommonGen V2":63.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yanolja\/KoSOLAR-10.7B-v0.3",
        "Average":56.09,
        "Ko-ARC":53.16,
        "Ko-HellaSwag":64.2,
        "Ko-MMLU":55.52,
        "Ko-TruthfulQA":45.11,
        "Ko-CommonGen V2":62.46,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v6",
        "Average":56.09,
        "Ko-ARC":49.91,
        "Ko-HellaSwag":64.38,
        "Ko-MMLU":54.01,
        "Ko-TruthfulQA":59.72,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"yanolja\/EEVE-Korean-Instruct-10.8B-v1.0",
        "Average":56.08,
        "Ko-ARC":55.2,
        "Ko-HellaSwag":66.11,
        "Ko-MMLU":56.48,
        "Ko-TruthfulQA":49.14,
        "Ko-CommonGen V2":53.48,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"kekmodel\/StopCarbon-ko-10.7B-v3",
        "Average":56.08,
        "Ko-ARC":47.95,
        "Ko-HellaSwag":59.74,
        "Ko-MMLU":53.74,
        "Ko-TruthfulQA":55.71,
        "Ko-CommonGen V2":63.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"kekmodel\/StopCarbon-ko-10.7B-v2",
        "Average":56.08,
        "Ko-ARC":47.95,
        "Ko-HellaSwag":59.74,
        "Ko-MMLU":53.74,
        "Ko-TruthfulQA":55.71,
        "Ko-CommonGen V2":63.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/SOLAR-10.7B-v1.1",
        "Average":56.07,
        "Ko-ARC":53.67,
        "Ko-HellaSwag":60.87,
        "Ko-MMLU":53.03,
        "Ko-TruthfulQA":56.72,
        "Ko-CommonGen V2":56.08,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"TeamUNIVA\/Komodo_7B_v1.0.0",
        "Average":56.04,
        "Ko-ARC":52.13,
        "Ko-HellaSwag":68.17,
        "Ko-MMLU":45.45,
        "Ko-TruthfulQA":59.53,
        "Ko-CommonGen V2":54.9,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"heavytail\/kullm-solar",
        "Average":55.99,
        "Ko-ARC":68.09,
        "Ko-HellaSwag":40.97,
        "Ko-MMLU":44.69,
        "Ko-TruthfulQA":66.46,
        "Ko-CommonGen V2":59.74,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-eeve-KorSTS",
        "Average":55.98,
        "Ko-ARC":52.73,
        "Ko-HellaSwag":64.09,
        "Ko-MMLU":55.41,
        "Ko-TruthfulQA":43.9,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v2",
        "Average":55.97,
        "Ko-ARC":52.47,
        "Ko-HellaSwag":63.19,
        "Ko-MMLU":55.59,
        "Ko-TruthfulQA":57.0,
        "Ko-CommonGen V2":51.59,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"StatPan\/all-you-need-is",
        "Average":55.93,
        "Ko-ARC":48.98,
        "Ko-HellaSwag":58.59,
        "Ko-MMLU":54.75,
        "Ko-TruthfulQA":54.3,
        "Ko-CommonGen V2":63.05,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-eeve-kullm-v2",
        "Average":55.89,
        "Ko-ARC":52.82,
        "Ko-HellaSwag":63.35,
        "Ko-MMLU":56.11,
        "Ko-TruthfulQA":47.07,
        "Ko-CommonGen V2":60.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ONS-AI-RESEARCH\/ONS-SOLAR-10.7B-v1.1",
        "Average":55.83,
        "Ko-ARC":55.8,
        "Ko-HellaSwag":64.31,
        "Ko-MMLU":56.59,
        "Ko-TruthfulQA":48.98,
        "Ko-CommonGen V2":53.48,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"hkss\/hk-SOLAR-10.7B-v1.2",
        "Average":55.82,
        "Ko-ARC":53.24,
        "Ko-HellaSwag":64.24,
        "Ko-MMLU":55.49,
        "Ko-TruthfulQA":44.73,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.7",
        "Average":55.81,
        "Ko-ARC":55.55,
        "Ko-HellaSwag":63.39,
        "Ko-MMLU":51.57,
        "Ko-TruthfulQA":48.23,
        "Ko-CommonGen V2":60.33,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/KoSoLAR-10.7B-v0.2_1.3_dedup_p",
        "Average":55.78,
        "Ko-ARC":53.07,
        "Ko-HellaSwag":63.06,
        "Ko-MMLU":54.07,
        "Ko-TruthfulQA":46.26,
        "Ko-CommonGen V2":62.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/KoSoLAR-10.7B-v0.2_1.3_dedup",
        "Average":55.78,
        "Ko-ARC":53.07,
        "Ko-HellaSwag":63.06,
        "Ko-MMLU":54.07,
        "Ko-TruthfulQA":46.26,
        "Ko-CommonGen V2":62.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"TeamUNIVA\/Komodo_6B_v3.0.0",
        "Average":55.78,
        "Ko-ARC":49.32,
        "Ko-HellaSwag":63.85,
        "Ko-MMLU":48.39,
        "Ko-TruthfulQA":53.0,
        "Ko-CommonGen V2":64.34,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/KoSOLAR-Platypus-10.7B",
        "Average":55.68,
        "Ko-ARC":52.39,
        "Ko-HellaSwag":61.76,
        "Ko-MMLU":54.71,
        "Ko-TruthfulQA":48.72,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yanolja\/KoSOLAR-10.7B-v0.2",
        "Average":55.62,
        "Ko-ARC":50.51,
        "Ko-HellaSwag":62.29,
        "Ko-MMLU":53.76,
        "Ko-TruthfulQA":47.31,
        "Ko-CommonGen V2":64.23,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/deep-solar-eeve-sentineg",
        "Average":55.53,
        "Ko-ARC":53.58,
        "Ko-HellaSwag":64.88,
        "Ko-MMLU":55.49,
        "Ko-TruthfulQA":42.92,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"heavytail\/kullm-solar-S",
        "Average":55.53,
        "Ko-ARC":70.14,
        "Ko-HellaSwag":43.54,
        "Ko-MMLU":45.9,
        "Ko-TruthfulQA":71.46,
        "Ko-CommonGen V2":46.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/OPEN-SOLAR-KO-10.7B-dpo-v1",
        "Average":55.42,
        "Ko-ARC":52.47,
        "Ko-HellaSwag":60.88,
        "Ko-MMLU":47.45,
        "Ko-TruthfulQA":55.36,
        "Ko-CommonGen V2":60.92,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"DKYoon\/kosolar-hermes-test",
        "Average":55.38,
        "Ko-ARC":52.39,
        "Ko-HellaSwag":62.29,
        "Ko-MMLU":55.66,
        "Ko-TruthfulQA":45.2,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"jeonsworld\/CarbonVillain-10.7B-v1",
        "Average":55.33,
        "Ko-ARC":49.91,
        "Ko-HellaSwag":60.65,
        "Ko-MMLU":55.04,
        "Ko-TruthfulQA":48.22,
        "Ko-CommonGen V2":62.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.5",
        "Average":55.32,
        "Ko-ARC":52.13,
        "Ko-HellaSwag":61.27,
        "Ko-MMLU":53.99,
        "Ko-TruthfulQA":49.71,
        "Ko-CommonGen V2":59.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Megastudy\/M-SOLAR-10.7B-v1.1-beta",
        "Average":55.25,
        "Ko-ARC":51.71,
        "Ko-HellaSwag":60.86,
        "Ko-MMLU":54.24,
        "Ko-TruthfulQA":47.12,
        "Ko-CommonGen V2":62.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.9",
        "Average":55.19,
        "Ko-ARC":53.33,
        "Ko-HellaSwag":62.57,
        "Ko-MMLU":49.55,
        "Ko-TruthfulQA":49.01,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"jjourney1125\/M-SOLAR-10.7B-v1.0",
        "Average":55.15,
        "Ko-ARC":49.57,
        "Ko-HellaSwag":60.12,
        "Ko-MMLU":54.6,
        "Ko-TruthfulQA":49.23,
        "Ko-CommonGen V2":62.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"TeamUNIVA\/Komodo_7B_v1.0.1",
        "Average":55.06,
        "Ko-ARC":51.45,
        "Ko-HellaSwag":66.23,
        "Ko-MMLU":41.85,
        "Ko-TruthfulQA":58.17,
        "Ko-CommonGen V2":57.62,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/SOLAR-10.7B-v1.4",
        "Average":55.05,
        "Ko-ARC":55.2,
        "Ko-HellaSwag":63.2,
        "Ko-MMLU":58.17,
        "Ko-TruthfulQA":46.59,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"fiveflow\/KoSOLAR-10.7B-Instruct-v0.1",
        "Average":55.04,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":62.24,
        "Ko-MMLU":53.81,
        "Ko-TruthfulQA":46.64,
        "Ko-CommonGen V2":61.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"sunburstAI\/solar_ko_v0.1",
        "Average":55.0,
        "Ko-ARC":52.47,
        "Ko-HellaSwag":64.28,
        "Ko-MMLU":55.73,
        "Ko-TruthfulQA":44.87,
        "Ko-CommonGen V2":57.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/SOLAR-10.7B-v1.2",
        "Average":54.97,
        "Ko-ARC":52.05,
        "Ko-HellaSwag":62.01,
        "Ko-MMLU":54.36,
        "Ko-TruthfulQA":46.59,
        "Ko-CommonGen V2":59.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"mightbe\/EEVE-10.8B-Multiturn",
        "Average":54.92,
        "Ko-ARC":53.92,
        "Ko-HellaSwag":63.25,
        "Ko-MMLU":54.83,
        "Ko-TruthfulQA":42.25,
        "Ko-CommonGen V2":60.33,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-SFT-v1.3",
        "Average":54.9,
        "Ko-ARC":52.99,
        "Ko-HellaSwag":63.93,
        "Ko-MMLU":55.25,
        "Ko-TruthfulQA":43.78,
        "Ko-CommonGen V2":58.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"seungduk\/Bookworm-10.7B-v0.3",
        "Average":54.75,
        "Ko-ARC":52.3,
        "Ko-HellaSwag":62.91,
        "Ko-MMLU":54.22,
        "Ko-TruthfulQA":46.72,
        "Ko-CommonGen V2":57.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"kurugai\/Kurugai-EEVE-v1.0",
        "Average":54.72,
        "Ko-ARC":49.66,
        "Ko-HellaSwag":58.91,
        "Ko-MMLU":52.17,
        "Ko-TruthfulQA":50.87,
        "Ko-CommonGen V2":61.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"kurugai\/Kurugai-EEVE-v1.1",
        "Average":54.72,
        "Ko-ARC":49.66,
        "Ko-HellaSwag":58.91,
        "Ko-MMLU":52.17,
        "Ko-TruthfulQA":50.87,
        "Ko-CommonGen V2":61.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"Megastudy\/M-SOLAR-10.7B-v1.2",
        "Average":54.56,
        "Ko-ARC":51.71,
        "Ko-HellaSwag":62.01,
        "Ko-MMLU":54.58,
        "Ko-TruthfulQA":45.1,
        "Ko-CommonGen V2":59.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-solar-10.7b-sft-v1",
        "Average":54.44,
        "Ko-ARC":50.43,
        "Ko-HellaSwag":59.93,
        "Ko-MMLU":56.45,
        "Ko-TruthfulQA":47.9,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-SOLAR-11b-v3.0",
        "Average":54.42,
        "Ko-ARC":51.02,
        "Ko-HellaSwag":61.92,
        "Ko-MMLU":54.25,
        "Ko-TruthfulQA":46.95,
        "Ko-CommonGen V2":57.97,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/SOLAR-10.7B-v1.3",
        "Average":54.41,
        "Ko-ARC":53.33,
        "Ko-HellaSwag":62.94,
        "Ko-MMLU":54.99,
        "Ko-TruthfulQA":49.21,
        "Ko-CommonGen V2":51.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"TeamUNIVA\/Komodo_6B_v2.0.0",
        "Average":54.4,
        "Ko-ARC":48.89,
        "Ko-HellaSwag":62.56,
        "Ko-MMLU":48.81,
        "Ko-TruthfulQA":50.36,
        "Ko-CommonGen V2":61.39,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.3",
        "Average":54.39,
        "Ko-ARC":52.73,
        "Ko-HellaSwag":63.27,
        "Ko-MMLU":55.54,
        "Ko-TruthfulQA":43.36,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/SOLAR_merge_DPOv3",
        "Average":54.35,
        "Ko-ARC":51.19,
        "Ko-HellaSwag":61.39,
        "Ko-MMLU":52.27,
        "Ko-TruthfulQA":58.11,
        "Ko-CommonGen V2":48.76,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.2",
        "Average":54.31,
        "Ko-ARC":52.13,
        "Ko-HellaSwag":63.13,
        "Ko-MMLU":55.47,
        "Ko-TruthfulQA":44.14,
        "Ko-CommonGen V2":56.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.1",
        "Average":54.3,
        "Ko-ARC":52.05,
        "Ko-HellaSwag":63.22,
        "Ko-MMLU":55.41,
        "Ko-TruthfulQA":44.05,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"mohomin123\/M-DIE-M-10.7B",
        "Average":54.29,
        "Ko-ARC":50.51,
        "Ko-HellaSwag":59.88,
        "Ko-MMLU":53.93,
        "Ko-TruthfulQA":47.88,
        "Ko-CommonGen V2":59.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.0.0",
        "Average":54.26,
        "Ko-ARC":52.3,
        "Ko-HellaSwag":62.02,
        "Ko-MMLU":53.34,
        "Ko-TruthfulQA":48.29,
        "Ko-CommonGen V2":55.37,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/OPEN-SOLAR-KO-10.7B-mixed-v15",
        "Average":54.21,
        "Ko-ARC":50.85,
        "Ko-HellaSwag":59.82,
        "Ko-MMLU":50.51,
        "Ko-TruthfulQA":46.1,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-SOLAR-11b-v4.0",
        "Average":54.2,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":62.14,
        "Ko-MMLU":54.25,
        "Ko-TruthfulQA":46.09,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/SOLAR-10.7B-orca-alpaca-gpt4-math",
        "Average":54.17,
        "Ko-ARC":51.11,
        "Ko-HellaSwag":61.69,
        "Ko-MMLU":54.56,
        "Ko-TruthfulQA":45.97,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-v0.4",
        "Average":54.15,
        "Ko-ARC":49.4,
        "Ko-HellaSwag":59.7,
        "Ko-MMLU":54.63,
        "Ko-TruthfulQA":47.5,
        "Ko-CommonGen V2":59.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/kosolra-kullm",
        "Average":54.04,
        "Ko-ARC":49.49,
        "Ko-HellaSwag":61.48,
        "Ko-MMLU":53.63,
        "Ko-TruthfulQA":46.46,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK_Gony_v3",
        "Average":53.98,
        "Ko-ARC":48.55,
        "Ko-HellaSwag":57.92,
        "Ko-MMLU":53.31,
        "Ko-TruthfulQA":57.22,
        "Ko-CommonGen V2":52.89,
        "Type":"instruction-tuned",
        "Precision":"MixtralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":46.7
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"TeamUNIVA\/Komodo_6B_v1.0.0",
        "Average":53.97,
        "Ko-ARC":50.6,
        "Ko-HellaSwag":62.58,
        "Ko-MMLU":48.91,
        "Ko-TruthfulQA":47.9,
        "Ko-CommonGen V2":59.86,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"megastudyedu\/M-SOLAR-10.7B-v1.4",
        "Average":53.95,
        "Ko-ARC":51.62,
        "Ko-HellaSwag":62.5,
        "Ko-MMLU":55.84,
        "Ko-TruthfulQA":49.49,
        "Ko-CommonGen V2":50.3,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Minirecord\/solar_informal_10.7b",
        "Average":53.92,
        "Ko-ARC":51.71,
        "Ko-HellaSwag":60.95,
        "Ko-MMLU":51.71,
        "Ko-TruthfulQA":47.24,
        "Ko-CommonGen V2":57.97,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v1.4",
        "Average":53.81,
        "Ko-ARC":52.05,
        "Ko-HellaSwag":62.93,
        "Ko-MMLU":53.59,
        "Ko-TruthfulQA":50.42,
        "Ko-CommonGen V2":50.06,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.9B-v1.0",
        "Average":53.76,
        "Ko-ARC":49.4,
        "Ko-HellaSwag":60.76,
        "Ko-MMLU":51.85,
        "Ko-TruthfulQA":45.29,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"mumu-97\/SOLAR-KO-various-v0.1",
        "Average":53.74,
        "Ko-ARC":49.74,
        "Ko-HellaSwag":60.59,
        "Ko-MMLU":48.82,
        "Ko-TruthfulQA":45.3,
        "Ko-CommonGen V2":64.23,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.1.0",
        "Average":53.68,
        "Ko-ARC":50.68,
        "Ko-HellaSwag":61.71,
        "Ko-MMLU":53.76,
        "Ko-TruthfulQA":47.69,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Twice-KoSOLAR-16.1B-instruct-test",
        "Average":53.64,
        "Ko-ARC":52.3,
        "Ko-HellaSwag":59.98,
        "Ko-MMLU":53.42,
        "Ko-TruthfulQA":44.07,
        "Ko-CommonGen V2":58.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":16.1
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/SOLAR_KO_1.3_deup",
        "Average":53.63,
        "Ko-ARC":52.65,
        "Ko-HellaSwag":60.92,
        "Ko-MMLU":50.9,
        "Ko-TruthfulQA":45.14,
        "Ko-CommonGen V2":58.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v1.2.0",
        "Average":53.62,
        "Ko-ARC":50.94,
        "Ko-HellaSwag":61.36,
        "Ko-MMLU":53.39,
        "Ko-TruthfulQA":49.26,
        "Ko-CommonGen V2":53.13,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/kosolra_SFT_DPO_v0",
        "Average":53.58,
        "Ko-ARC":52.39,
        "Ko-HellaSwag":62.06,
        "Ko-MMLU":51.19,
        "Ko-TruthfulQA":53.13,
        "Ko-CommonGen V2":49.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"hwkwon\/S-SOLAR-10.7B-v1.0",
        "Average":53.51,
        "Ko-ARC":49.74,
        "Ko-HellaSwag":61.76,
        "Ko-MMLU":54.29,
        "Ko-TruthfulQA":45.32,
        "Ko-CommonGen V2":56.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-dpo-v0.1",
        "Average":53.21,
        "Ko-ARC":47.87,
        "Ko-HellaSwag":57.18,
        "Ko-MMLU":54.82,
        "Ko-TruthfulQA":53.64,
        "Ko-CommonGen V2":52.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"genne\/kiwi_solar_merge_ties",
        "Average":53.03,
        "Ko-ARC":48.81,
        "Ko-HellaSwag":55.96,
        "Ko-MMLU":54.32,
        "Ko-TruthfulQA":49.04,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"genne\/kiwi_solar_merge_slerp",
        "Average":53.03,
        "Ko-ARC":48.81,
        "Ko-HellaSwag":55.95,
        "Ko-MMLU":54.32,
        "Ko-TruthfulQA":49.04,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"logicker\/SkkuDataScience-DPO",
        "Average":52.95,
        "Ko-ARC":48.89,
        "Ko-HellaSwag":59.62,
        "Ko-MMLU":52.19,
        "Ko-TruthfulQA":42.77,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/SOLAR-10.7B-orca-alpaca-gpt4-lora-653",
        "Average":52.9,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":60.81,
        "Ko-MMLU":54.64,
        "Ko-TruthfulQA":46.22,
        "Ko-CommonGen V2":54.78,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/ko_solra_merge",
        "Average":52.88,
        "Ko-ARC":48.81,
        "Ko-HellaSwag":59.53,
        "Ko-MMLU":52.2,
        "Ko-TruthfulQA":42.82,
        "Ko-CommonGen V2":61.04,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"dddsaty\/Open_Ko_SOLAR_DPO_Merge_v0.1",
        "Average":52.83,
        "Ko-ARC":50.0,
        "Ko-HellaSwag":60.55,
        "Ko-MMLU":48.8,
        "Ko-TruthfulQA":43.65,
        "Ko-CommonGen V2":61.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/ko-solra-platusv3-koprompt",
        "Average":52.83,
        "Ko-ARC":50.09,
        "Ko-HellaSwag":60.26,
        "Ko-MMLU":52.75,
        "Ko-TruthfulQA":41.9,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/SOLAR-KO-10.7B",
        "Average":52.72,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":60.39,
        "Ko-MMLU":48.78,
        "Ko-TruthfulQA":43.57,
        "Ko-CommonGen V2":61.04,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/OPEN-SOLAR-KO-10.7B",
        "Average":52.72,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":60.39,
        "Ko-MMLU":48.78,
        "Ko-TruthfulQA":43.57,
        "Ko-CommonGen V2":61.04,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKAL_merged_test-v1-13B",
        "Average":52.72,
        "Ko-ARC":51.45,
        "Ko-HellaSwag":60.55,
        "Ko-MMLU":44.8,
        "Ko-TruthfulQA":49.05,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HumanF-MarkrAI\/COKAL-DPO-13b-v2",
        "Average":52.69,
        "Ko-ARC":54.95,
        "Ko-HellaSwag":63.02,
        "Ko-MMLU":43.98,
        "Ko-TruthfulQA":51.67,
        "Ko-CommonGen V2":49.82,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/COKAL-DPO_test-v2-13b",
        "Average":52.68,
        "Ko-ARC":55.63,
        "Ko-HellaSwag":63.52,
        "Ko-MMLU":43.49,
        "Ko-TruthfulQA":51.5,
        "Ko-CommonGen V2":49.23,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/COKAL-DPO_test-v2",
        "Average":52.67,
        "Ko-ARC":55.63,
        "Ko-HellaSwag":63.5,
        "Ko-MMLU":43.49,
        "Ko-TruthfulQA":51.5,
        "Ko-CommonGen V2":49.23,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/Yi-6b-dpo-v0.2",
        "Average":52.63,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":52.96,
        "Ko-MMLU":46.69,
        "Ko-TruthfulQA":52.38,
        "Ko-CommonGen V2":69.42,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/DND-v0.0-e1",
        "Average":52.48,
        "Ko-ARC":67.58,
        "Ko-HellaSwag":49.13,
        "Ko-MMLU":52.04,
        "Ko-TruthfulQA":61.41,
        "Ko-CommonGen V2":32.23,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"hchung1017\/linear-merge",
        "Average":52.42,
        "Ko-ARC":50.09,
        "Ko-HellaSwag":59.72,
        "Ko-MMLU":47.91,
        "Ko-TruthfulQA":45.12,
        "Ko-CommonGen V2":59.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"daebum\/LoRA-Submit-Test",
        "Average":52.41,
        "Ko-ARC":49.06,
        "Ko-HellaSwag":60.39,
        "Ko-MMLU":49.05,
        "Ko-TruthfulQA":43.32,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"seungduk\/KoSOLAR-10.7B-v0.1",
        "Average":52.4,
        "Ko-ARC":47.18,
        "Ko-HellaSwag":59.54,
        "Ko-MMLU":52.04,
        "Ko-TruthfulQA":41.84,
        "Ko-CommonGen V2":61.39,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"freewheelin\/free-solar-instrunction-v0.1",
        "Average":52.38,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":60.75,
        "Ko-MMLU":49.44,
        "Ko-TruthfulQA":47.68,
        "Ko-CommonGen V2":56.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"testmod\/koen-llama2-13b-dpotrain_testver",
        "Average":52.37,
        "Ko-ARC":50.43,
        "Ko-HellaSwag":57.83,
        "Ko-MMLU":46.75,
        "Ko-TruthfulQA":53.96,
        "Ko-CommonGen V2":52.89,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"Surromind\/Solar_v0.1",
        "Average":52.31,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":59.25,
        "Ko-MMLU":53.98,
        "Ko-TruthfulQA":42.64,
        "Ko-CommonGen V2":54.9,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-Mixtral-8x7B",
        "Average":52.23,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":56.37,
        "Ko-MMLU":53.81,
        "Ko-TruthfulQA":46.84,
        "Ko-CommonGen V2":54.31,
        "Type":"instruction-tuned",
        "Precision":"MixtralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"ifuseok\/ft-solar-10.7b-v2.1-dpo",
        "Average":52.17,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":58.36,
        "Ko-MMLU":52.45,
        "Ko-TruthfulQA":46.74,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/Yi-6b-dpo-v0.3",
        "Average":52.12,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":53.08,
        "Ko-MMLU":45.51,
        "Ko-TruthfulQA":53.03,
        "Ko-CommonGen V2":66.47,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/SOLAR-10.7B-v1.6",
        "Average":52.08,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":63.38,
        "Ko-MMLU":59.23,
        "Ko-TruthfulQA":38.75,
        "Ko-CommonGen V2":49.23,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-10.7B-v0.4",
        "Average":52.05,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":60.15,
        "Ko-MMLU":49.9,
        "Ko-TruthfulQA":45.37,
        "Ko-CommonGen V2":54.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/llama2-13b-dpo-v7",
        "Average":51.91,
        "Ko-ARC":49.66,
        "Ko-HellaSwag":59.33,
        "Ko-MMLU":44.81,
        "Ko-TruthfulQA":50.96,
        "Ko-CommonGen V2":54.78,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/llama2-13b-dpo-v4",
        "Average":51.88,
        "Ko-ARC":48.21,
        "Ko-HellaSwag":60.05,
        "Ko-MMLU":44.84,
        "Ko-TruthfulQA":50.36,
        "Ko-CommonGen V2":55.96,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/Yi-Ko-6B-dpo-v6",
        "Average":51.88,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":57.02,
        "Ko-MMLU":41.6,
        "Ko-TruthfulQA":59.83,
        "Ko-CommonGen V2":55.73,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.7",
        "Average":51.86,
        "Ko-ARC":48.38,
        "Ko-HellaSwag":60.19,
        "Ko-MMLU":44.78,
        "Ko-TruthfulQA":50.33,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/Dear_My_best_Friends-v2-13B",
        "Average":51.85,
        "Ko-ARC":54.44,
        "Ko-HellaSwag":61.73,
        "Ko-MMLU":43.39,
        "Ko-TruthfulQA":47.99,
        "Ko-CommonGen V2":51.71,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"ifuseok\/sft-solar-10.7b-v1.1",
        "Average":51.84,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":58.07,
        "Ko-MMLU":52.21,
        "Ko-TruthfulQA":46.6,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/psm_170k_llama_13b",
        "Average":51.79,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":59.16,
        "Ko-MMLU":44.48,
        "Ko-TruthfulQA":47.79,
        "Ko-CommonGen V2":61.28,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"jeonsworld\/CarbonVillain-13B-v1",
        "Average":51.76,
        "Ko-ARC":48.38,
        "Ko-HellaSwag":60.46,
        "Ko-MMLU":44.69,
        "Ko-TruthfulQA":50.86,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/llama13b_2s_dpo",
        "Average":51.74,
        "Ko-ARC":48.12,
        "Ko-HellaSwag":57.38,
        "Ko-MMLU":43.3,
        "Ko-TruthfulQA":48.39,
        "Ko-CommonGen V2":61.51,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/SOLAR-tail-10.7B-instruct-v1.0",
        "Average":51.7,
        "Ko-ARC":46.93,
        "Ko-HellaSwag":58.19,
        "Ko-MMLU":53.15,
        "Ko-TruthfulQA":46.52,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"ifuseok\/sft-solar-10.7b-v1",
        "Average":51.69,
        "Ko-ARC":47.18,
        "Ko-HellaSwag":56.88,
        "Ko-MMLU":51.72,
        "Ko-TruthfulQA":45.42,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HumanF-MarkrAI\/COKAL-DPO-13b-v3",
        "Average":51.67,
        "Ko-ARC":53.24,
        "Ko-HellaSwag":62.28,
        "Ko-MMLU":43.86,
        "Ko-TruthfulQA":48.65,
        "Ko-CommonGen V2":50.3,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.24",
        "Average":51.61,
        "Ko-ARC":48.81,
        "Ko-HellaSwag":60.42,
        "Ko-MMLU":43.33,
        "Ko-TruthfulQA":50.96,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/SOLAR_C-v2-10.7B",
        "Average":51.59,
        "Ko-ARC":47.27,
        "Ko-HellaSwag":59.31,
        "Ko-MMLU":51.14,
        "Ko-TruthfulQA":46.65,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/SOLAR_D-v2-10.7B",
        "Average":51.57,
        "Ko-ARC":47.53,
        "Ko-HellaSwag":59.38,
        "Ko-MMLU":51.08,
        "Ko-TruthfulQA":46.76,
        "Ko-CommonGen V2":53.13,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/Orca-Platypus-v3-1epoch",
        "Average":51.55,
        "Ko-ARC":47.1,
        "Ko-HellaSwag":60.01,
        "Ko-MMLU":52.79,
        "Ko-TruthfulQA":42.36,
        "Ko-CommonGen V2":55.49,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"ENERGY-DRINK-LOVE\/TQ3_leaderboard_inst_v2",
        "Average":51.54,
        "Ko-ARC":69.88,
        "Ko-HellaSwag":59.41,
        "Ko-MMLU":35.59,
        "Ko-TruthfulQA":56.47,
        "Ko-CommonGen V2":36.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/psm_llama13b",
        "Average":51.54,
        "Ko-ARC":47.44,
        "Ko-HellaSwag":57.87,
        "Ko-MMLU":43.35,
        "Ko-TruthfulQA":46.12,
        "Ko-CommonGen V2":62.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/Yi-6b-dpo-v0.4",
        "Average":51.53,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":53.46,
        "Ko-MMLU":45.09,
        "Ko-TruthfulQA":53.9,
        "Ko-CommonGen V2":62.46,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/Orca-Platypus-kiwi-1epoch",
        "Average":51.53,
        "Ko-ARC":47.1,
        "Ko-HellaSwag":59.96,
        "Ko-MMLU":52.54,
        "Ko-TruthfulQA":39.6,
        "Ko-CommonGen V2":58.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/llama2-13b-dpo-v6",
        "Average":51.48,
        "Ko-ARC":48.55,
        "Ko-HellaSwag":58.29,
        "Ko-MMLU":44.3,
        "Ko-TruthfulQA":49.95,
        "Ko-CommonGen V2":56.32,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"ENERGY-DRINK-LOVE\/eeve_leaderboard_inst_v1.5",
        "Average":51.47,
        "Ko-ARC":49.06,
        "Ko-HellaSwag":61.7,
        "Ko-MMLU":52.24,
        "Ko-TruthfulQA":41.68,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-SOLAR-10.7B_02",
        "Average":51.46,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":59.81,
        "Ko-MMLU":50.83,
        "Ko-TruthfulQA":38.03,
        "Ko-CommonGen V2":57.85,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-Yi-Ko-6B-v5.0",
        "Average":51.43,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":55.49,
        "Ko-MMLU":45.26,
        "Ko-TruthfulQA":52.97,
        "Ko-CommonGen V2":60.92,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-16B",
        "Average":51.39,
        "Ko-ARC":49.23,
        "Ko-HellaSwag":60.41,
        "Ko-MMLU":44.65,
        "Ko-TruthfulQA":51.05,
        "Ko-CommonGen V2":51.59,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/Yi-6b-dpo-v0.1",
        "Average":51.38,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":52.23,
        "Ko-MMLU":45.34,
        "Ko-TruthfulQA":54.03,
        "Ko-CommonGen V2":63.99,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/OPEN-SOLAR-KO-10.7B-v13",
        "Average":51.36,
        "Ko-ARC":50.09,
        "Ko-HellaSwag":60.61,
        "Ko-MMLU":49.04,
        "Ko-TruthfulQA":38.97,
        "Ko-CommonGen V2":58.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"yuntaeyang\/KoSOLAR-10.7B-dpo-v1.0",
        "Average":51.33,
        "Ko-ARC":50.26,
        "Ko-HellaSwag":59.75,
        "Ko-MMLU":50.34,
        "Ko-TruthfulQA":49.58,
        "Ko-CommonGen V2":46.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/llama13b_dpo_loss0_OTL",
        "Average":51.33,
        "Ko-ARC":47.53,
        "Ko-HellaSwag":58.09,
        "Ko-MMLU":44.51,
        "Ko-TruthfulQA":43.86,
        "Ko-CommonGen V2":62.69,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/love_but_hate-10.7B",
        "Average":51.3,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":60.59,
        "Ko-MMLU":50.95,
        "Ko-TruthfulQA":55.13,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.7
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.4",
        "Average":51.28,
        "Ko-ARC":47.78,
        "Ko-HellaSwag":58.35,
        "Ko-MMLU":43.66,
        "Ko-TruthfulQA":52.05,
        "Ko-CommonGen V2":54.55,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/llama2-13b-dpo-v3",
        "Average":51.24,
        "Ko-ARC":49.15,
        "Ko-HellaSwag":59.1,
        "Ko-MMLU":44.35,
        "Ko-TruthfulQA":53.55,
        "Ko-CommonGen V2":50.06,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.25",
        "Average":51.23,
        "Ko-ARC":48.46,
        "Ko-HellaSwag":60.42,
        "Ko-MMLU":44.65,
        "Ko-TruthfulQA":48.68,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-Yi-Ko-6B-v6.0",
        "Average":51.22,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":55.7,
        "Ko-MMLU":45.36,
        "Ko-TruthfulQA":53.77,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"oneonlee\/KoSOLAR-v0.2-gugutypus-10.7B",
        "Average":51.17,
        "Ko-ARC":47.78,
        "Ko-HellaSwag":58.29,
        "Ko-MMLU":47.27,
        "Ko-TruthfulQA":48.31,
        "Ko-CommonGen V2":54.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.22",
        "Average":51.16,
        "Ko-ARC":48.89,
        "Ko-HellaSwag":59.41,
        "Ko-MMLU":43.7,
        "Ko-TruthfulQA":50.07,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/kosolra-wiki-QA",
        "Average":51.06,
        "Ko-ARC":48.89,
        "Ko-HellaSwag":57.68,
        "Ko-MMLU":51.86,
        "Ko-TruthfulQA":39.59,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.23",
        "Average":51.04,
        "Ko-ARC":47.35,
        "Ko-HellaSwag":60.05,
        "Ko-MMLU":44.52,
        "Ko-TruthfulQA":47.41,
        "Ko-CommonGen V2":55.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"daekeun-ml\/Llama-2-ko-DPO-13B",
        "Average":51.03,
        "Ko-ARC":47.53,
        "Ko-HellaSwag":58.28,
        "Ko-MMLU":43.59,
        "Ko-TruthfulQA":51.91,
        "Ko-CommonGen V2":53.84,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"kodonho\/SolarM-SakuraSolar-SLERP",
        "Average":51.02,
        "Ko-ARC":48.12,
        "Ko-HellaSwag":54.0,
        "Ko-MMLU":50.85,
        "Ko-TruthfulQA":53.13,
        "Ko-CommonGen V2":49.0,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Sakura-SOLRCA-Instruct-DPO",
        "Average":51.02,
        "Ko-ARC":48.12,
        "Ko-HellaSwag":54.04,
        "Ko-MMLU":50.64,
        "Ko-TruthfulQA":53.75,
        "Ko-CommonGen V2":48.52,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Sakura-SOLRCA-Math-Instruct-DPO-v1",
        "Average":51.01,
        "Ko-ARC":48.12,
        "Ko-HellaSwag":54.07,
        "Ko-MMLU":50.66,
        "Ko-TruthfulQA":53.76,
        "Ko-CommonGen V2":48.41,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/llama13b_test02",
        "Average":50.99,
        "Ko-ARC":47.1,
        "Ko-HellaSwag":57.93,
        "Ko-MMLU":44.26,
        "Ko-TruthfulQA":43.22,
        "Ko-CommonGen V2":62.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"refarde\/OPEN-SOLAR-KO-10.7B-S-Core",
        "Average":50.95,
        "Ko-ARC":47.44,
        "Ko-HellaSwag":57.62,
        "Ko-MMLU":45.85,
        "Ko-TruthfulQA":47.87,
        "Ko-CommonGen V2":55.96,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Mini_llama13b_test123",
        "Average":50.9,
        "Ko-ARC":48.21,
        "Ko-HellaSwag":58.98,
        "Ko-MMLU":44.51,
        "Ko-TruthfulQA":46.74,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/llama-2-koen-13b-dpo-v3_2",
        "Average":50.79,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":56.81,
        "Ko-MMLU":41.0,
        "Ko-TruthfulQA":45.88,
        "Ko-CommonGen V2":64.7,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"lIlBrother\/llama2-merge-v0.1",
        "Average":50.79,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":59.07,
        "Ko-MMLU":44.69,
        "Ko-TruthfulQA":50.56,
        "Ko-CommonGen V2":53.13,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"42MARU\/GenAI-llama2-ko-en-dpo-13b-test3",
        "Average":50.78,
        "Ko-ARC":45.73,
        "Ko-HellaSwag":58.17,
        "Ko-MMLU":44.13,
        "Ko-TruthfulQA":47.56,
        "Ko-CommonGen V2":58.32,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"lIlBrother\/llama2-merge-v0.2",
        "Average":50.78,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":59.11,
        "Ko-MMLU":44.69,
        "Ko-TruthfulQA":50.57,
        "Ko-CommonGen V2":53.01,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/Yi-9b-v1",
        "Average":50.76,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":52.93,
        "Ko-MMLU":45.66,
        "Ko-TruthfulQA":51.59,
        "Ko-CommonGen V2":63.28,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":8.95
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Sakura-SOLAR-Instruct",
        "Average":50.72,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":53.75,
        "Ko-MMLU":50.64,
        "Ko-TruthfulQA":52.95,
        "Ko-CommonGen V2":48.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-yi-ko-6b-v0.9.28",
        "Average":50.71,
        "Ko-ARC":44.45,
        "Ko-HellaSwag":55.43,
        "Ko-MMLU":46.83,
        "Ko-TruthfulQA":48.17,
        "Ko-CommonGen V2":58.68,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-yi-ko-6b-v0.9.30",
        "Average":50.71,
        "Ko-ARC":43.86,
        "Ko-HellaSwag":55.43,
        "Ko-MMLU":46.6,
        "Ko-TruthfulQA":47.09,
        "Ko-CommonGen V2":60.57,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-yi-ko-6b-v0.9.31",
        "Average":50.7,
        "Ko-ARC":43.86,
        "Ko-HellaSwag":55.42,
        "Ko-MMLU":46.59,
        "Ko-TruthfulQA":47.09,
        "Ko-CommonGen V2":60.57,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Mini_Orca_daekeun_llama13b",
        "Average":50.68,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":57.33,
        "Ko-MMLU":43.44,
        "Ko-TruthfulQA":46.57,
        "Ko-CommonGen V2":59.03,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/KoSoLAR-10.7B-v0.2_1.4_dedup_1",
        "Average":50.67,
        "Ko-ARC":50.43,
        "Ko-HellaSwag":62.0,
        "Ko-MMLU":53.87,
        "Ko-TruthfulQA":38.89,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.81
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"MarkrAI\/DopeorNope-maestro-v4-DPO-13b",
        "Average":50.66,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":57.35,
        "Ko-MMLU":43.49,
        "Ko-TruthfulQA":46.55,
        "Ko-CommonGen V2":58.91,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/LDCC-with-openorca",
        "Average":50.65,
        "Ko-ARC":46.33,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":43.87,
        "Ko-TruthfulQA":44.75,
        "Ko-CommonGen V2":61.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Sakura-SOLAR-Instruct-DPO-v2",
        "Average":50.62,
        "Ko-ARC":47.35,
        "Ko-HellaSwag":53.74,
        "Ko-MMLU":50.78,
        "Ko-TruthfulQA":52.93,
        "Ko-CommonGen V2":48.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/LDCC-with-openorca2",
        "Average":50.6,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":43.89,
        "Ko-TruthfulQA":44.79,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/LDCC-with-openorca-and-korca",
        "Average":50.58,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":56.61,
        "Ko-MMLU":43.66,
        "Ko-TruthfulQA":44.84,
        "Ko-CommonGen V2":62.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"testmod\/koen-llama2-13b-avg_testver",
        "Average":50.56,
        "Ko-ARC":48.38,
        "Ko-HellaSwag":56.33,
        "Ko-MMLU":46.87,
        "Ko-TruthfulQA":49.52,
        "Ko-CommonGen V2":51.71,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"seungduk\/Bookworm-10.7B-v0.2",
        "Average":50.55,
        "Ko-ARC":50.94,
        "Ko-HellaSwag":62.61,
        "Ko-MMLU":34.2,
        "Ko-TruthfulQA":47.49,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v4-13B",
        "Average":50.49,
        "Ko-ARC":45.65,
        "Ko-HellaSwag":57.96,
        "Ko-MMLU":44.03,
        "Ko-TruthfulQA":47.53,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13B-v6",
        "Average":50.47,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":57.34,
        "Ko-MMLU":44.21,
        "Ko-TruthfulQA":47.13,
        "Ko-CommonGen V2":56.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/Mini_DPO_test_01",
        "Average":50.47,
        "Ko-ARC":48.29,
        "Ko-HellaSwag":54.68,
        "Ko-MMLU":46.7,
        "Ko-TruthfulQA":47.78,
        "Ko-CommonGen V2":54.9,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kodonho\/Solar-OrcaDPO-Solar-Instruct-SLERP",
        "Average":50.44,
        "Ko-ARC":46.84,
        "Ko-HellaSwag":53.34,
        "Ko-MMLU":50.34,
        "Ko-TruthfulQA":53.52,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"StatPan\/mistral7b-bartending-recipe-v1",
        "Average":50.41,
        "Ko-ARC":50.0,
        "Ko-HellaSwag":54.93,
        "Ko-MMLU":48.76,
        "Ko-TruthfulQA":52.19,
        "Ko-CommonGen V2":46.16,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Yhyu13\/LMCocktail-10.7B-v1",
        "Average":50.41,
        "Ko-ARC":47.1,
        "Ko-HellaSwag":53.19,
        "Ko-MMLU":50.5,
        "Ko-TruthfulQA":52.49,
        "Ko-CommonGen V2":48.76,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ENERGY-DRINK-LOVE\/leaderboard_inst_v1.3_Open-Hermes_LDCC-SOLAR-10.7B_DPOv3",
        "Average":50.39,
        "Ko-ARC":50.85,
        "Ko-HellaSwag":62.97,
        "Ko-MMLU":51.44,
        "Ko-TruthfulQA":42.75,
        "Ko-CommonGen V2":43.92,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"KT-AI\/midm-bitext-S-7B-inst-v2",
        "Average":50.35,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":58.8,
        "Ko-MMLU":45.66,
        "Ko-TruthfulQA":43.6,
        "Ko-CommonGen V2":58.56,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Puluming\/AISquare-Instruct-llama2-koen-13b-v0.9.20",
        "Average":50.31,
        "Ko-ARC":46.67,
        "Ko-HellaSwag":57.91,
        "Ko-MMLU":43.69,
        "Ko-TruthfulQA":46.01,
        "Ko-CommonGen V2":57.26,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Mini_Synatra_SFT",
        "Average":50.3,
        "Ko-ARC":49.83,
        "Ko-HellaSwag":55.63,
        "Ko-MMLU":47.51,
        "Ko-TruthfulQA":50.82,
        "Ko-CommonGen V2":47.7,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/LDCC-with-korca",
        "Average":50.27,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":56.64,
        "Ko-MMLU":43.6,
        "Ko-TruthfulQA":44.87,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/Yi-Ko-6B-dpo-v4",
        "Average":50.27,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":53.6,
        "Ko-MMLU":46.64,
        "Ko-TruthfulQA":44.54,
        "Ko-CommonGen V2":63.05,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"MarkrAI\/DopeorNope-maestro-v1-DPO-13b",
        "Average":50.25,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":57.65,
        "Ko-MMLU":44.64,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":54.66,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MarkrAI\/DopeorNope-Maestro-v1-13B",
        "Average":50.24,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":57.66,
        "Ko-MMLU":44.64,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":54.66,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"MarkrAI\/DopeorNope-maestro-v1.1-DPO-13b",
        "Average":50.23,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":57.64,
        "Ko-MMLU":44.61,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":54.66,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"inswave\/AISquare-Instruct-yi-ko-6b-v0.9.26",
        "Average":50.21,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":54.43,
        "Ko-MMLU":46.5,
        "Ko-TruthfulQA":46.71,
        "Ko-CommonGen V2":60.33,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PracticeLLM\/Twice-KoSOLAR-16.1B-test",
        "Average":50.2,
        "Ko-ARC":45.65,
        "Ko-HellaSwag":57.14,
        "Ko-MMLU":51.39,
        "Ko-TruthfulQA":42.99,
        "Ko-CommonGen V2":53.84,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":16.1
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKALD-13B-v2",
        "Average":50.19,
        "Ko-ARC":47.78,
        "Ko-HellaSwag":57.41,
        "Ko-MMLU":44.0,
        "Ko-TruthfulQA":47.12,
        "Ko-CommonGen V2":54.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v1",
        "Average":50.19,
        "Ko-ARC":45.99,
        "Ko-HellaSwag":56.93,
        "Ko-MMLU":41.78,
        "Ko-TruthfulQA":41.66,
        "Ko-CommonGen V2":64.58,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Puluming\/AISquare-Instruct-llama2-koen-13b-v0.9.18",
        "Average":50.17,
        "Ko-ARC":45.9,
        "Ko-HellaSwag":57.14,
        "Ko-MMLU":43.22,
        "Ko-TruthfulQA":45.44,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.8",
        "Average":50.15,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":56.71,
        "Ko-MMLU":43.71,
        "Ko-TruthfulQA":45.43,
        "Ko-CommonGen V2":59.74,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"lIlBrother\/llama2-merge-v0.4",
        "Average":50.12,
        "Ko-ARC":47.87,
        "Ko-HellaSwag":58.1,
        "Ko-MMLU":45.28,
        "Ko-TruthfulQA":44.67,
        "Ko-CommonGen V2":54.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"Deepnoid\/OPEN-SOLAR-KO-10.7B-v14",
        "Average":50.11,
        "Ko-ARC":49.57,
        "Ko-HellaSwag":60.17,
        "Ko-MMLU":49.09,
        "Ko-TruthfulQA":39.55,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"AIdenU\/SOLAR-10.7b-ko-Y24_v1.0",
        "Average":50.09,
        "Ko-ARC":48.38,
        "Ko-HellaSwag":58.66,
        "Ko-MMLU":52.91,
        "Ko-TruthfulQA":41.16,
        "Ko-CommonGen V2":49.35,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/minyi_dpo_6b",
        "Average":50.09,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":54.38,
        "Ko-MMLU":46.21,
        "Ko-TruthfulQA":44.32,
        "Ko-CommonGen V2":62.69,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.3",
        "Average":50.09,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":57.49,
        "Ko-MMLU":43.31,
        "Ko-TruthfulQA":43.54,
        "Ko-CommonGen V2":59.86,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/Yi-Ko-6B-dpo-v3",
        "Average":50.09,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":53.77,
        "Ko-MMLU":45.43,
        "Ko-TruthfulQA":45.14,
        "Ko-CommonGen V2":62.57,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"ENERGY-DRINK-LOVE\/leaderboard_inst_v1.3_deup_LDCC-SOLAR-10.7B_SFT",
        "Average":50.04,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":61.04,
        "Ko-MMLU":51.04,
        "Ko-TruthfulQA":37.16,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Ko-PlatYi-6B",
        "Average":49.97,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":53.55,
        "Ko-MMLU":46.5,
        "Ko-TruthfulQA":40.31,
        "Ko-CommonGen V2":66.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v4",
        "Average":49.89,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":57.06,
        "Ko-MMLU":41.83,
        "Ko-TruthfulQA":42.93,
        "Ko-CommonGen V2":62.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Mini_synatra_7b_02",
        "Average":49.88,
        "Ko-ARC":48.46,
        "Ko-HellaSwag":53.82,
        "Ko-MMLU":46.81,
        "Ko-TruthfulQA":47.05,
        "Ko-CommonGen V2":53.25,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"lIlBrother\/llama2-merge-v0.3",
        "Average":49.85,
        "Ko-ARC":42.58,
        "Ko-HellaSwag":58.2,
        "Ko-MMLU":44.92,
        "Ko-TruthfulQA":50.67,
        "Ko-CommonGen V2":52.89,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v8",
        "Average":49.84,
        "Ko-ARC":45.65,
        "Ko-HellaSwag":56.98,
        "Ko-MMLU":41.37,
        "Ko-TruthfulQA":42.52,
        "Ko-CommonGen V2":62.69,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Puluming\/AISquare-Instruct-llama2-koen-13b-v0.9.15",
        "Average":49.84,
        "Ko-ARC":45.39,
        "Ko-HellaSwag":56.88,
        "Ko-MMLU":42.6,
        "Ko-TruthfulQA":46.84,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-llama2-koen-13b-v0.9.19",
        "Average":49.8,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":58.35,
        "Ko-MMLU":42.99,
        "Ko-TruthfulQA":46.25,
        "Ko-CommonGen V2":55.84,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"lcw99\/llama2-ko-chang-13b-instruct-chat",
        "Average":49.79,
        "Ko-ARC":46.67,
        "Ko-HellaSwag":59.84,
        "Ko-MMLU":41.99,
        "Ko-TruthfulQA":49.7,
        "Ko-CommonGen V2":50.77,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/Dear_My_best_Friend-SFT-v2-13B",
        "Average":49.79,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":57.44,
        "Ko-MMLU":44.0,
        "Ko-TruthfulQA":46.24,
        "Ko-CommonGen V2":53.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.2",
        "Average":49.79,
        "Ko-ARC":45.31,
        "Ko-HellaSwag":56.66,
        "Ko-MMLU":43.11,
        "Ko-TruthfulQA":41.9,
        "Ko-CommonGen V2":61.98,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/mistral-7b-v5",
        "Average":49.78,
        "Ko-ARC":47.95,
        "Ko-HellaSwag":54.23,
        "Ko-MMLU":46.99,
        "Ko-TruthfulQA":47.8,
        "Ko-CommonGen V2":51.95,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HumanF-MarkrAI\/Dear_My_best_Friends-v4-13B",
        "Average":49.77,
        "Ko-ARC":47.87,
        "Ko-HellaSwag":57.49,
        "Ko-MMLU":44.49,
        "Ko-TruthfulQA":46.59,
        "Ko-CommonGen V2":52.42,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKAL_pre_DPO_Test_v2-13b",
        "Average":49.77,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":57.59,
        "Ko-MMLU":44.68,
        "Ko-TruthfulQA":46.12,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v2.1",
        "Average":49.76,
        "Ko-ARC":42.24,
        "Ko-HellaSwag":52.71,
        "Ko-MMLU":44.07,
        "Ko-TruthfulQA":44.15,
        "Ko-CommonGen V2":65.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKAL_pre_DPO_Test_v1-13b",
        "Average":49.74,
        "Ko-ARC":47.87,
        "Ko-HellaSwag":57.47,
        "Ko-MMLU":44.46,
        "Ko-TruthfulQA":46.62,
        "Ko-CommonGen V2":52.3,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Mini_synatra_7b_03",
        "Average":49.72,
        "Ko-ARC":46.84,
        "Ko-HellaSwag":53.7,
        "Ko-MMLU":46.17,
        "Ko-TruthfulQA":47.8,
        "Ko-CommonGen V2":54.07,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"wons\/llama2-13b-dpo-test-v0.2",
        "Average":49.7,
        "Ko-ARC":37.97,
        "Ko-HellaSwag":52.36,
        "Ko-MMLU":38.75,
        "Ko-TruthfulQA":54.85,
        "Ko-CommonGen V2":64.58,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Merge_test01",
        "Average":49.68,
        "Ko-ARC":48.21,
        "Ko-HellaSwag":53.76,
        "Ko-MMLU":46.81,
        "Ko-TruthfulQA":51.66,
        "Ko-CommonGen V2":47.93,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/mistral7b-lora-multiturn-v4",
        "Average":49.67,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":53.64,
        "Ko-MMLU":46.57,
        "Ko-TruthfulQA":49.15,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-20B-v1",
        "Average":49.66,
        "Ko-ARC":46.16,
        "Ko-HellaSwag":56.77,
        "Ko-MMLU":43.06,
        "Ko-TruthfulQA":45.87,
        "Ko-CommonGen V2":56.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-yi-ko-6b-v0.9.27",
        "Average":49.66,
        "Ko-ARC":44.28,
        "Ko-HellaSwag":55.56,
        "Ko-MMLU":46.12,
        "Ko-TruthfulQA":46.61,
        "Ko-CommonGen V2":55.73,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKALL-13B-v3",
        "Average":49.66,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":57.05,
        "Ko-MMLU":44.33,
        "Ko-TruthfulQA":42.4,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"daekeun-ml\/Llama-2-ko-instruct-13B",
        "Average":49.52,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":56.9,
        "Ko-MMLU":43.76,
        "Ko-TruthfulQA":42.0,
        "Ko-CommonGen V2":58.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK-v3",
        "Average":49.5,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":56.34,
        "Ko-MMLU":50.87,
        "Ko-TruthfulQA":46.44,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v5",
        "Average":49.5,
        "Ko-ARC":44.88,
        "Ko-HellaSwag":56.74,
        "Ko-MMLU":42.23,
        "Ko-TruthfulQA":42.82,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.6",
        "Average":49.49,
        "Ko-ARC":46.42,
        "Ko-HellaSwag":56.93,
        "Ko-MMLU":43.82,
        "Ko-TruthfulQA":41.97,
        "Ko-CommonGen V2":58.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KOR-Orca-Platypus-13B-v2",
        "Average":49.48,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":54.43,
        "Ko-MMLU":42.23,
        "Ko-TruthfulQA":41.64,
        "Ko-CommonGen V2":65.05,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"oneonlee\/LDCC-SOLAR-gugutypus-10.7B",
        "Average":49.45,
        "Ko-ARC":45.9,
        "Ko-HellaSwag":55.46,
        "Ko-MMLU":47.96,
        "Ko-TruthfulQA":48.93,
        "Ko-CommonGen V2":49.0,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"42MARU\/GenAI-llama2-ko-en-dpo-13b-v2",
        "Average":49.43,
        "Ko-ARC":46.08,
        "Ko-HellaSwag":57.06,
        "Ko-MMLU":41.1,
        "Ko-TruthfulQA":47.44,
        "Ko-CommonGen V2":55.49,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"MarkrAI\/DopeorNope-maestro-v2-DPO-13b",
        "Average":49.42,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":56.69,
        "Ko-MMLU":41.37,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":61.63,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/llama-2-koen-13b-dpo-v3",
        "Average":49.42,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":41.34,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":61.75,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/llama-2-koen-13b-dpo-v2",
        "Average":49.42,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":41.34,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":61.75,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/ko-en-llama2-13b-mixed-v10",
        "Average":49.42,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":41.34,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":61.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.2",
        "Average":49.41,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":55.19,
        "Ko-MMLU":41.9,
        "Ko-TruthfulQA":44.71,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13B-v5",
        "Average":49.4,
        "Ko-ARC":46.76,
        "Ko-HellaSwag":57.13,
        "Ko-MMLU":44.13,
        "Ko-TruthfulQA":42.32,
        "Ko-CommonGen V2":56.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/minyi_6b",
        "Average":49.4,
        "Ko-ARC":42.06,
        "Ko-HellaSwag":54.17,
        "Ko-MMLU":46.26,
        "Ko-TruthfulQA":42.85,
        "Ko-CommonGen V2":61.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/Yi-Ko-6B-dpo-v5",
        "Average":49.4,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":54.01,
        "Ko-MMLU":44.61,
        "Ko-TruthfulQA":53.68,
        "Ko-CommonGen V2":52.18,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKALL-13B-v4",
        "Average":49.37,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":56.98,
        "Ko-MMLU":43.92,
        "Ko-TruthfulQA":42.05,
        "Ko-CommonGen V2":56.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/Mini_synatra_7b_01",
        "Average":49.36,
        "Ko-ARC":47.78,
        "Ko-HellaSwag":53.88,
        "Ko-MMLU":45.97,
        "Ko-TruthfulQA":46.99,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_Orca_16_32",
        "Average":49.36,
        "Ko-ARC":47.78,
        "Ko-HellaSwag":53.86,
        "Ko-MMLU":45.98,
        "Ko-TruthfulQA":46.99,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKALL-13B-v1",
        "Average":49.36,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":56.97,
        "Ko-MMLU":44.03,
        "Ko-TruthfulQA":42.11,
        "Ko-CommonGen V2":56.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"We-Want-GPU\/Yi-Ko-6B-DPO-v2",
        "Average":49.34,
        "Ko-ARC":41.13,
        "Ko-HellaSwag":54.47,
        "Ko-MMLU":43.74,
        "Ko-TruthfulQA":43.99,
        "Ko-CommonGen V2":63.4,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"sunburstAI\/sb_solar_ko_10.7B_v0.2",
        "Average":49.33,
        "Ko-ARC":45.31,
        "Ko-HellaSwag":57.08,
        "Ko-MMLU":44.66,
        "Ko-TruthfulQA":46.13,
        "Ko-CommonGen V2":53.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.0",
        "Average":49.33,
        "Ko-ARC":44.88,
        "Ko-HellaSwag":56.5,
        "Ko-MMLU":44.84,
        "Ko-TruthfulQA":45.98,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/yi-ko-6b-dpo-further",
        "Average":49.32,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":53.38,
        "Ko-MMLU":45.76,
        "Ko-TruthfulQA":44.71,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"42MARU\/GenAI-llama2-ko-en-dpo-13b-v1",
        "Average":49.31,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":56.93,
        "Ko-MMLU":41.11,
        "Ko-TruthfulQA":47.44,
        "Ko-CommonGen V2":55.25,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/llama-2-koen-13b-mixed-v11_2",
        "Average":49.31,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":56.61,
        "Ko-MMLU":41.4,
        "Ko-TruthfulQA":42.56,
        "Ko-CommonGen V2":60.92,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"testmod\/koen-llama2-13b-sft_testver",
        "Average":49.31,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":57.0,
        "Ko-MMLU":42.81,
        "Ko-TruthfulQA":42.84,
        "Ko-CommonGen V2":55.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.3",
        "Average":49.31,
        "Ko-ARC":48.29,
        "Ko-HellaSwag":54.55,
        "Ko-MMLU":48.5,
        "Ko-TruthfulQA":43.83,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.37
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/kosolra-wiki-QA-1epoch",
        "Average":49.3,
        "Ko-ARC":46.93,
        "Ko-HellaSwag":57.89,
        "Ko-MMLU":51.69,
        "Ko-TruthfulQA":37.36,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-platypus-13B",
        "Average":49.3,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":55.25,
        "Ko-MMLU":41.84,
        "Ko-TruthfulQA":44.78,
        "Ko-CommonGen V2":59.39,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/llama-2-koen-13b-mixed-v7",
        "Average":49.29,
        "Ko-ARC":44.8,
        "Ko-HellaSwag":56.64,
        "Ko-MMLU":41.19,
        "Ko-TruthfulQA":42.43,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKALL-13B-v2",
        "Average":49.28,
        "Ko-ARC":46.84,
        "Ko-HellaSwag":56.93,
        "Ko-MMLU":44.26,
        "Ko-TruthfulQA":42.3,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/llama-2-koen-13b-dpo-v1",
        "Average":49.27,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":56.62,
        "Ko-MMLU":41.16,
        "Ko-TruthfulQA":42.44,
        "Ko-CommonGen V2":61.16,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.1-dpo",
        "Average":49.26,
        "Ko-ARC":42.06,
        "Ko-HellaSwag":53.19,
        "Ko-MMLU":44.76,
        "Ko-TruthfulQA":42.52,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-yi-ko-6b-v0.9.29",
        "Average":49.26,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":55.28,
        "Ko-MMLU":45.83,
        "Ko-TruthfulQA":45.63,
        "Ko-CommonGen V2":55.61,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"vitruv\/vitruv_1",
        "Average":49.25,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":58.61,
        "Ko-MMLU":43.97,
        "Ko-TruthfulQA":42.14,
        "Ko-CommonGen V2":53.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"moondriller\/llama2-13B-eugeneparkthebest",
        "Average":49.25,
        "Ko-ARC":43.86,
        "Ko-HellaSwag":57.77,
        "Ko-MMLU":40.7,
        "Ko-TruthfulQA":46.77,
        "Ko-CommonGen V2":57.14,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/Yi-Ko-6B-mixed-v11",
        "Average":49.24,
        "Ko-ARC":42.06,
        "Ko-HellaSwag":53.37,
        "Ko-MMLU":46.88,
        "Ko-TruthfulQA":41.22,
        "Ko-CommonGen V2":62.69,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"zomd\/AISquare-Instruct-llama2-koen-13b-v0.9.17",
        "Average":49.24,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":57.48,
        "Ko-MMLU":40.75,
        "Ko-TruthfulQA":43.91,
        "Ko-CommonGen V2":58.91,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.6",
        "Average":49.23,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":59.33,
        "Ko-MMLU":43.8,
        "Ko-TruthfulQA":46.94,
        "Ko-CommonGen V2":48.05,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.4",
        "Average":49.23,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":55.47,
        "Ko-MMLU":40.89,
        "Ko-TruthfulQA":47.41,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"cong1230\/LDCC_LoRA_NoRemote_full_re",
        "Average":49.2,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":56.3,
        "Ko-MMLU":41.91,
        "Ko-TruthfulQA":45.9,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v3-13B",
        "Average":49.2,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":55.37,
        "Ko-MMLU":44.1,
        "Ko-TruthfulQA":44.87,
        "Ko-CommonGen V2":56.2,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v3-13b",
        "Average":49.2,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":55.37,
        "Ko-MMLU":44.1,
        "Ko-TruthfulQA":44.87,
        "Ko-CommonGen V2":56.2,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-v1",
        "Average":49.2,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":55.45,
        "Ko-MMLU":40.82,
        "Ko-TruthfulQA":47.46,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kfkas\/my_test_LLM",
        "Average":49.17,
        "Ko-ARC":44.37,
        "Ko-HellaSwag":56.55,
        "Ko-MMLU":41.82,
        "Ko-TruthfulQA":45.02,
        "Ko-CommonGen V2":58.09,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"megastudyedu\/ME-dpo-7B-v1.1",
        "Average":49.17,
        "Ko-ARC":48.29,
        "Ko-HellaSwag":54.27,
        "Ko-MMLU":48.52,
        "Ko-TruthfulQA":50.37,
        "Ko-CommonGen V2":44.39,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/Llama-2-kor-13B",
        "Average":49.17,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":56.4,
        "Ko-MMLU":43.58,
        "Ko-TruthfulQA":45.37,
        "Ko-CommonGen V2":54.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"oopsung\/Yi-Ko-ENWdpo-v1",
        "Average":49.15,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":54.44,
        "Ko-MMLU":46.48,
        "Ko-TruthfulQA":41.39,
        "Ko-CommonGen V2":60.68,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-Yi-Ko-6B-v1.1",
        "Average":49.15,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":55.41,
        "Ko-MMLU":45.54,
        "Ko-TruthfulQA":44.21,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v7",
        "Average":49.11,
        "Ko-ARC":45.9,
        "Ko-HellaSwag":56.8,
        "Ko-MMLU":41.92,
        "Ko-TruthfulQA":41.42,
        "Ko-CommonGen V2":59.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-platypus-13B-v2",
        "Average":49.11,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":54.88,
        "Ko-MMLU":41.39,
        "Ko-TruthfulQA":44.69,
        "Ko-CommonGen V2":59.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.1",
        "Average":49.1,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":53.14,
        "Ko-MMLU":44.79,
        "Ko-TruthfulQA":42.51,
        "Ko-CommonGen V2":62.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/Yi-Ko-6B-orca-alpaca-gpt4-math-lora",
        "Average":49.1,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":54.29,
        "Ko-MMLU":43.86,
        "Ko-TruthfulQA":42.03,
        "Ko-CommonGen V2":64.94,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"yuntaeyang\/Llama-2-ko-instruct-13B-kor-orca-lora",
        "Average":49.09,
        "Ko-ARC":47.1,
        "Ko-HellaSwag":56.81,
        "Ko-MMLU":45.27,
        "Ko-TruthfulQA":42.67,
        "Ko-CommonGen V2":53.6,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/Yi-Ko-6B-mixed-v13",
        "Average":49.09,
        "Ko-ARC":42.92,
        "Ko-HellaSwag":53.5,
        "Ko-MMLU":46.72,
        "Ko-TruthfulQA":41.75,
        "Ko-CommonGen V2":60.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"Jaehyeon222\/ME-MOE-7Bx2_test",
        "Average":49.08,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":54.08,
        "Ko-MMLU":48.86,
        "Ko-TruthfulQA":50.73,
        "Ko-CommonGen V2":44.04,
        "Type":"instruction-tuned",
        "Precision":"MixtralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":12.88
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-yi-ko-6b-v0.9.16",
        "Average":49.06,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":54.88,
        "Ko-MMLU":45.79,
        "Ko-TruthfulQA":43.69,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/llama-2-koen-13b-mixed-v9",
        "Average":49.03,
        "Ko-ARC":44.71,
        "Ko-HellaSwag":56.5,
        "Ko-MMLU":41.15,
        "Ko-TruthfulQA":42.08,
        "Ko-CommonGen V2":60.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-Yi-Ko-6B-v4.0",
        "Average":49.02,
        "Ko-ARC":43.77,
        "Ko-HellaSwag":55.0,
        "Ko-MMLU":46.1,
        "Ko-TruthfulQA":44.16,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Ko-PlatYi-6B-O",
        "Average":49.0,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":53.59,
        "Ko-MMLU":47.47,
        "Ko-TruthfulQA":41.01,
        "Ko-CommonGen V2":59.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"ENERGY-DRINK-LOVE\/leaderboard_inst_v1.3_Open-Hermes_LDCC-SOLAR-10.7B_SFT",
        "Average":48.98,
        "Ko-ARC":47.61,
        "Ko-HellaSwag":60.6,
        "Ko-MMLU":51.32,
        "Ko-TruthfulQA":40.37,
        "Ko-CommonGen V2":44.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"jjourney1125\/llama2-13b-v1",
        "Average":48.97,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":54.19,
        "Ko-MMLU":43.01,
        "Ko-TruthfulQA":44.71,
        "Ko-CommonGen V2":59.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/ko-platypus-kiwi-13B",
        "Average":48.97,
        "Ko-ARC":42.41,
        "Ko-HellaSwag":54.29,
        "Ko-MMLU":41.98,
        "Ko-TruthfulQA":40.05,
        "Ko-CommonGen V2":66.12,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"We-Want-GPU\/Yi-Ko-6B-orca-alpaca-gpt4-math-lora-DPO",
        "Average":48.96,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":54.59,
        "Ko-MMLU":44.08,
        "Ko-TruthfulQA":43.1,
        "Ko-CommonGen V2":62.34,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/Yi-Ko-6B-smash-dpo",
        "Average":48.95,
        "Ko-ARC":41.64,
        "Ko-HellaSwag":54.73,
        "Ko-MMLU":44.25,
        "Ko-TruthfulQA":52.08,
        "Ko-CommonGen V2":52.07,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo-3",
        "Average":48.95,
        "Ko-ARC":41.13,
        "Ko-HellaSwag":52.94,
        "Ko-MMLU":42.65,
        "Ko-TruthfulQA":45.47,
        "Ko-CommonGen V2":62.57,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"KT-AI\/midm-bitext-S-7B-inst-v1",
        "Average":48.91,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":55.11,
        "Ko-MMLU":41.25,
        "Ko-TruthfulQA":45.75,
        "Ko-CommonGen V2":59.98,
        "Type":"instruction-tuned",
        "Precision":"MidmLMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":9.16
    },
    {
        "T":"\u2b55",
        "Model":"moondriller\/solar10B-eugeneparkthebestv2",
        "Average":48.91,
        "Ko-ARC":42.92,
        "Ko-HellaSwag":48.41,
        "Ko-MMLU":51.11,
        "Ko-TruthfulQA":46.39,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-ko-Fdpo-v1",
        "Average":48.9,
        "Ko-ARC":42.24,
        "Ko-HellaSwag":54.21,
        "Ko-MMLU":46.47,
        "Ko-TruthfulQA":41.4,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"oopsung\/Yi-Ko-ENCdpo",
        "Average":48.9,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":54.48,
        "Ko-MMLU":46.4,
        "Ko-TruthfulQA":41.47,
        "Ko-CommonGen V2":59.86,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/Dear_My_best_Friends-13B",
        "Average":48.89,
        "Ko-ARC":51.71,
        "Ko-HellaSwag":58.44,
        "Ko-MMLU":41.52,
        "Ko-TruthfulQA":38.8,
        "Ko-CommonGen V2":53.96,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/Yi-Ko-6B-smash",
        "Average":48.88,
        "Ko-ARC":41.38,
        "Ko-HellaSwag":53.47,
        "Ko-MMLU":46.34,
        "Ko-TruthfulQA":41.35,
        "Ko-CommonGen V2":61.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/SOLAR-KOEN-10.8B",
        "Average":48.87,
        "Ko-ARC":44.8,
        "Ko-HellaSwag":57.93,
        "Ko-MMLU":48.98,
        "Ko-TruthfulQA":42.57,
        "Ko-CommonGen V2":50.06,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/OPEN-SOLAR-KO-10.7B-mixed-v15-dedup",
        "Average":48.87,
        "Ko-ARC":41.21,
        "Ko-HellaSwag":53.56,
        "Ko-MMLU":46.67,
        "Ko-TruthfulQA":40.8,
        "Ko-CommonGen V2":62.1,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-ENin-test-v1",
        "Average":48.87,
        "Ko-ARC":40.61,
        "Ko-HellaSwag":53.27,
        "Ko-MMLU":46.19,
        "Ko-TruthfulQA":42.51,
        "Ko-CommonGen V2":61.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v6-13B",
        "Average":48.86,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":56.1,
        "Ko-MMLU":41.22,
        "Ko-TruthfulQA":45.71,
        "Ko-CommonGen V2":56.2,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/llama-2-koen-13b-OKI-v20231124-1e-5",
        "Average":48.86,
        "Ko-ARC":44.8,
        "Ko-HellaSwag":57.29,
        "Ko-MMLU":41.65,
        "Ko-TruthfulQA":44.23,
        "Ko-CommonGen V2":56.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Korean-OpenOrca-v3",
        "Average":48.86,
        "Ko-ARC":43.77,
        "Ko-HellaSwag":54.3,
        "Ko-MMLU":41.79,
        "Ko-TruthfulQA":43.85,
        "Ko-CommonGen V2":60.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-13b-v4",
        "Average":48.85,
        "Ko-ARC":45.39,
        "Ko-HellaSwag":55.72,
        "Ko-MMLU":40.77,
        "Ko-TruthfulQA":47.14,
        "Ko-CommonGen V2":55.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/llama-2-koen-13b-mixed-v11",
        "Average":48.85,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":56.46,
        "Ko-MMLU":41.46,
        "Ko-TruthfulQA":42.23,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/Yi-Ko-6B-mixed-v15",
        "Average":48.85,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":53.42,
        "Ko-MMLU":45.92,
        "Ko-TruthfulQA":42.63,
        "Ko-CommonGen V2":59.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-13b-v5",
        "Average":48.85,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":55.85,
        "Ko-MMLU":40.98,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v2-13b",
        "Average":48.85,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":55.61,
        "Ko-MMLU":44.29,
        "Ko-TruthfulQA":44.23,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-com-test-v1",
        "Average":48.82,
        "Ko-ARC":41.38,
        "Ko-HellaSwag":53.23,
        "Ko-MMLU":46.01,
        "Ko-TruthfulQA":42.06,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-wiki-test-v1",
        "Average":48.81,
        "Ko-ARC":41.21,
        "Ko-HellaSwag":53.5,
        "Ko-MMLU":46.23,
        "Ko-TruthfulQA":41.6,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.3",
        "Average":48.81,
        "Ko-ARC":44.11,
        "Ko-HellaSwag":55.58,
        "Ko-MMLU":44.24,
        "Ko-TruthfulQA":44.15,
        "Ko-CommonGen V2":55.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.1",
        "Average":48.81,
        "Ko-ARC":46.59,
        "Ko-HellaSwag":56.83,
        "Ko-MMLU":43.6,
        "Ko-TruthfulQA":42.12,
        "Ko-CommonGen V2":54.9,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"maywell\/Synatra-7B-v0.3-dpo",
        "Average":48.81,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":53.24,
        "Ko-MMLU":46.2,
        "Ko-TruthfulQA":51.19,
        "Ko-CommonGen V2":46.4,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-orcapus-test-v1",
        "Average":48.8,
        "Ko-ARC":41.81,
        "Ko-HellaSwag":53.24,
        "Ko-MMLU":46.44,
        "Ko-TruthfulQA":41.37,
        "Ko-CommonGen V2":61.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/Yi-Ko-6B",
        "Average":48.79,
        "Ko-ARC":41.04,
        "Ko-HellaSwag":53.39,
        "Ko-MMLU":46.28,
        "Ko-TruthfulQA":41.64,
        "Ko-CommonGen V2":61.63,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Korean-OpenOrca-13B",
        "Average":48.79,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":54.13,
        "Ko-MMLU":40.24,
        "Ko-TruthfulQA":45.22,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/Yi-Ko-6B_mixed_v10",
        "Average":48.79,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":53.8,
        "Ko-MMLU":46.33,
        "Ko-TruthfulQA":41.57,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/yi-ko-6b-instruct-test-v0.2",
        "Average":48.79,
        "Ko-ARC":41.81,
        "Ko-HellaSwag":53.69,
        "Ko-MMLU":46.39,
        "Ko-TruthfulQA":41.59,
        "Ko-CommonGen V2":60.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Minirecord\/minyi_5k_6B",
        "Average":48.79,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":53.62,
        "Ko-MMLU":45.77,
        "Ko-TruthfulQA":42.63,
        "Ko-CommonGen V2":58.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-v3",
        "Average":48.77,
        "Ko-ARC":45.05,
        "Ko-HellaSwag":55.85,
        "Ko-MMLU":41.04,
        "Ko-TruthfulQA":46.19,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Ko-PlatYi-6B-gu",
        "Average":48.76,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":54.0,
        "Ko-MMLU":44.66,
        "Ko-TruthfulQA":41.22,
        "Ko-CommonGen V2":61.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/Yi-6b-v0.3",
        "Average":48.75,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":53.24,
        "Ko-MMLU":47.0,
        "Ko-TruthfulQA":40.48,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"yuntaeyang\/Yi-Ko-6B-lora",
        "Average":48.75,
        "Ko-ARC":41.21,
        "Ko-HellaSwag":51.6,
        "Ko-MMLU":46.22,
        "Ko-TruthfulQA":44.03,
        "Ko-CommonGen V2":60.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Ko-PlatYi-6B-kiwi",
        "Average":48.75,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":53.61,
        "Ko-MMLU":46.1,
        "Ko-TruthfulQA":38.3,
        "Ko-CommonGen V2":63.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"yeheun\/llama-2-koen-13b-v1.2",
        "Average":48.74,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":56.76,
        "Ko-MMLU":40.97,
        "Ko-TruthfulQA":41.01,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/llama-2-koen-13b-v1.2",
        "Average":48.74,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":56.76,
        "Ko-MMLU":40.97,
        "Ko-TruthfulQA":41.01,
        "Ko-CommonGen V2":59.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.12",
        "Average":48.72,
        "Ko-ARC":45.39,
        "Ko-HellaSwag":56.08,
        "Ko-MMLU":41.35,
        "Ko-TruthfulQA":43.73,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Cartinoe5930\/KoRAE-13b-DPO",
        "Average":48.71,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":57.54,
        "Ko-MMLU":42.87,
        "Ko-TruthfulQA":41.28,
        "Ko-CommonGen V2":55.37,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-Exogen-test-v1",
        "Average":48.69,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":53.36,
        "Ko-MMLU":46.13,
        "Ko-TruthfulQA":41.59,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-Exo-test-v1",
        "Average":48.68,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":53.3,
        "Ko-MMLU":46.02,
        "Ko-TruthfulQA":41.69,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-all-test-v1",
        "Average":48.68,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":53.27,
        "Ko-MMLU":46.24,
        "Ko-TruthfulQA":42.25,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/yi-ko-6b-instruct-test-v0.1",
        "Average":48.65,
        "Ko-ARC":42.58,
        "Ko-HellaSwag":53.87,
        "Ko-MMLU":46.02,
        "Ko-TruthfulQA":41.4,
        "Ko-CommonGen V2":59.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v6",
        "Average":48.65,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":64.4,
        "Ko-MMLU":44.34,
        "Ko-TruthfulQA":43.43,
        "Ko-CommonGen V2":48.76,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Cartinoe5930\/KoRAE-13b",
        "Average":48.64,
        "Ko-ARC":46.33,
        "Ko-HellaSwag":57.25,
        "Ko-MMLU":42.8,
        "Ko-TruthfulQA":41.08,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-Instruct-v0.3-pre",
        "Average":48.6,
        "Ko-ARC":47.27,
        "Ko-HellaSwag":52.56,
        "Ko-MMLU":46.98,
        "Ko-TruthfulQA":47.67,
        "Ko-CommonGen V2":48.52,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"genne\/eclectus_1.1_dedup",
        "Average":48.59,
        "Ko-ARC":48.12,
        "Ko-HellaSwag":58.8,
        "Ko-MMLU":45.61,
        "Ko-TruthfulQA":43.1,
        "Ko-CommonGen V2":47.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.21",
        "Average":48.57,
        "Ko-ARC":46.84,
        "Ko-HellaSwag":56.99,
        "Ko-MMLU":42.46,
        "Ko-TruthfulQA":40.6,
        "Ko-CommonGen V2":55.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-13b-n1",
        "Average":48.57,
        "Ko-ARC":44.37,
        "Ko-HellaSwag":55.54,
        "Ko-MMLU":40.88,
        "Ko-TruthfulQA":47.17,
        "Ko-CommonGen V2":54.9,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-N-test-v1",
        "Average":48.57,
        "Ko-ARC":40.61,
        "Ko-HellaSwag":53.28,
        "Ko-MMLU":46.24,
        "Ko-TruthfulQA":41.9,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"seungduk\/Bookworm-10.7B-v0.1",
        "Average":48.55,
        "Ko-ARC":49.4,
        "Ko-HellaSwag":55.53,
        "Ko-MMLU":45.11,
        "Ko-TruthfulQA":45.61,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.11",
        "Average":48.54,
        "Ko-ARC":45.73,
        "Ko-HellaSwag":55.68,
        "Ko-MMLU":42.58,
        "Ko-TruthfulQA":42.42,
        "Ko-CommonGen V2":56.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-13b-v6",
        "Average":48.54,
        "Ko-ARC":45.73,
        "Ko-HellaSwag":55.39,
        "Ko-MMLU":40.86,
        "Ko-TruthfulQA":46.27,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-6B-tech-test-v1",
        "Average":48.53,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":53.16,
        "Ko-MMLU":46.51,
        "Ko-TruthfulQA":40.89,
        "Ko-CommonGen V2":61.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.0
    },
    {
        "T":"\u2b55",
        "Model":"JaeyeonKang\/CCK_gony",
        "Average":48.53,
        "Ko-ARC":48.89,
        "Ko-HellaSwag":54.88,
        "Ko-MMLU":49.43,
        "Ko-TruthfulQA":44.46,
        "Ko-CommonGen V2":44.98,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":46.7
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/Yi-Ko-6B-Instruct-v1.1_",
        "Average":48.53,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":53.68,
        "Ko-MMLU":45.56,
        "Ko-TruthfulQA":41.33,
        "Ko-CommonGen V2":60.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/Yi-Ko-6B-Instruct-v1.1",
        "Average":48.53,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":53.68,
        "Ko-MMLU":45.56,
        "Ko-TruthfulQA":41.33,
        "Ko-CommonGen V2":60.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/OPEN-SOLAR-KO-10.7B-dpo-dedup",
        "Average":48.51,
        "Ko-ARC":40.1,
        "Ko-HellaSwag":54.01,
        "Ko-MMLU":44.17,
        "Ko-TruthfulQA":46.29,
        "Ko-CommonGen V2":57.97,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.13",
        "Average":48.51,
        "Ko-ARC":45.73,
        "Ko-HellaSwag":56.99,
        "Ko-MMLU":43.12,
        "Ko-TruthfulQA":41.45,
        "Ko-CommonGen V2":55.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"Cartinoe5930\/original-KoRAE-13b",
        "Average":48.5,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":57.04,
        "Ko-MMLU":42.2,
        "Ko-TruthfulQA":40.67,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"HY-KDPARK\/llama-2-koen-13b-sft-v0.3",
        "Average":48.48,
        "Ko-ARC":47.27,
        "Ko-HellaSwag":56.68,
        "Ko-MMLU":45.28,
        "Ko-TruthfulQA":44.27,
        "Ko-CommonGen V2":48.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"cong1230\/LDCC_LoRA_full",
        "Average":48.45,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":55.92,
        "Ko-MMLU":42.15,
        "Ko-TruthfulQA":45.34,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Kukedlc\/Triunvirato-7b",
        "Average":48.43,
        "Ko-ARC":42.92,
        "Ko-HellaSwag":51.86,
        "Ko-MMLU":44.76,
        "Ko-TruthfulQA":56.11,
        "Ko-CommonGen V2":46.52,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"maywell\/PiVoT-0.1-early",
        "Average":48.43,
        "Ko-ARC":47.53,
        "Ko-HellaSwag":53.83,
        "Ko-MMLU":46.44,
        "Ko-TruthfulQA":51.4,
        "Ko-CommonGen V2":42.98,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"heavytail\/kullm-mistral-S",
        "Average":48.43,
        "Ko-ARC":60.92,
        "Ko-HellaSwag":35.11,
        "Ko-MMLU":32.77,
        "Ko-TruthfulQA":68.03,
        "Ko-CommonGen V2":45.34,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/kosy-openorca",
        "Average":48.43,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":54.49,
        "Ko-MMLU":39.86,
        "Ko-TruthfulQA":45.3,
        "Ko-CommonGen V2":58.8,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"wons\/llama2-13b-test-v0.1",
        "Average":48.4,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":56.62,
        "Ko-MMLU":42.09,
        "Ko-TruthfulQA":42.33,
        "Ko-CommonGen V2":55.37,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KOR-Orca-Platypus-13B-v3",
        "Average":48.37,
        "Ko-ARC":43.77,
        "Ko-HellaSwag":54.27,
        "Ko-MMLU":42.66,
        "Ko-TruthfulQA":38.58,
        "Ko-CommonGen V2":62.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"AIdenU\/SOLAR-10b-ko-Y24_v0.1",
        "Average":48.36,
        "Ko-ARC":43.86,
        "Ko-HellaSwag":51.95,
        "Ko-MMLU":51.03,
        "Ko-TruthfulQA":40.77,
        "Ko-CommonGen V2":54.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"moondriller\/solar10B-eugeneparkthebest",
        "Average":48.36,
        "Ko-ARC":42.66,
        "Ko-HellaSwag":47.71,
        "Ko-MMLU":50.94,
        "Ko-TruthfulQA":46.05,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/Yi_lee-SFT-v2-6B",
        "Average":48.36,
        "Ko-ARC":40.78,
        "Ko-HellaSwag":52.71,
        "Ko-MMLU":44.84,
        "Ko-TruthfulQA":44.54,
        "Ko-CommonGen V2":58.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-13b-sft-dpo",
        "Average":48.34,
        "Ko-ARC":45.39,
        "Ko-HellaSwag":54.94,
        "Ko-MMLU":43.24,
        "Ko-TruthfulQA":44.98,
        "Ko-CommonGen V2":53.13,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/Yi_lee-v2-DPO-6B",
        "Average":48.33,
        "Ko-ARC":40.78,
        "Ko-HellaSwag":52.72,
        "Ko-MMLU":44.92,
        "Ko-TruthfulQA":44.52,
        "Ko-CommonGen V2":58.68,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/SOLAR-tail-10.7B-Merge-v1.0",
        "Average":48.32,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":50.88,
        "Ko-MMLU":50.84,
        "Ko-TruthfulQA":46.87,
        "Ko-CommonGen V2":50.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"msy127\/mnsim-dpo-peftmerged-2-eos",
        "Average":48.28,
        "Ko-ARC":45.39,
        "Ko-HellaSwag":53.87,
        "Ko-MMLU":43.28,
        "Ko-TruthfulQA":47.26,
        "Ko-CommonGen V2":51.59,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v2",
        "Average":48.28,
        "Ko-ARC":45.73,
        "Ko-HellaSwag":56.97,
        "Ko-MMLU":38.77,
        "Ko-TruthfulQA":38.75,
        "Ko-CommonGen V2":61.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"LDCC\/LDCC-Instruct-Llama-2-ko-13B-v1.5",
        "Average":48.28,
        "Ko-ARC":48.04,
        "Ko-HellaSwag":58.41,
        "Ko-MMLU":43.74,
        "Ko-TruthfulQA":46.08,
        "Ko-CommonGen V2":45.1,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-ENC-v1",
        "Average":48.27,
        "Ko-ARC":40.19,
        "Ko-HellaSwag":53.04,
        "Ko-MMLU":46.18,
        "Ko-TruthfulQA":42.08,
        "Ko-CommonGen V2":59.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v5-13B",
        "Average":48.26,
        "Ko-ARC":43.6,
        "Ko-HellaSwag":55.68,
        "Ko-MMLU":41.57,
        "Ko-TruthfulQA":45.91,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo-2",
        "Average":48.25,
        "Ko-ARC":38.82,
        "Ko-HellaSwag":52.65,
        "Ko-MMLU":42.52,
        "Ko-TruthfulQA":44.23,
        "Ko-CommonGen V2":63.05,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.5",
        "Average":48.24,
        "Ko-ARC":45.9,
        "Ko-HellaSwag":59.59,
        "Ko-MMLU":38.25,
        "Ko-TruthfulQA":45.38,
        "Ko-CommonGen V2":52.07,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Mistral_test04",
        "Average":48.22,
        "Ko-ARC":43.86,
        "Ko-HellaSwag":51.49,
        "Ko-MMLU":43.67,
        "Ko-TruthfulQA":45.99,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Saxo\/yunsung-llama-2-koen-13b-linkbricks-sft-basic-v1",
        "Average":48.2,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":56.18,
        "Ko-MMLU":37.55,
        "Ko-TruthfulQA":42.04,
        "Ko-CommonGen V2":61.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-7B-OP-u1k-ver0.7",
        "Average":48.17,
        "Ko-ARC":40.27,
        "Ko-HellaSwag":49.83,
        "Ko-MMLU":45.92,
        "Ko-TruthfulQA":48.51,
        "Ko-CommonGen V2":56.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Korean-OpenOrca-13B-v2",
        "Average":48.17,
        "Ko-ARC":43.17,
        "Ko-HellaSwag":54.51,
        "Ko-MMLU":42.9,
        "Ko-TruthfulQA":41.82,
        "Ko-CommonGen V2":58.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo",
        "Average":48.17,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":52.64,
        "Ko-MMLU":42.32,
        "Ko-TruthfulQA":43.92,
        "Ko-CommonGen V2":63.4,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"spow12\/KoSOLAR-10.7B_instruct",
        "Average":48.16,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":45.66,
        "Ko-MMLU":49.95,
        "Ko-TruthfulQA":44.84,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"Cartinoe5930\/original-KoRAE-13b-3ep",
        "Average":48.16,
        "Ko-ARC":44.37,
        "Ko-HellaSwag":56.97,
        "Ko-MMLU":43.27,
        "Ko-TruthfulQA":41.75,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.6",
        "Average":48.15,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":52.73,
        "Ko-MMLU":43.0,
        "Ko-TruthfulQA":43.66,
        "Ko-CommonGen V2":61.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"MarkrAI\/DopeorNope-maestro-v3-DPO-13b",
        "Average":48.13,
        "Ko-ARC":44.37,
        "Ko-HellaSwag":56.96,
        "Ko-MMLU":43.16,
        "Ko-TruthfulQA":41.73,
        "Ko-CommonGen V2":54.43,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"Cartinoe5930\/weak-KoRAE-13b",
        "Average":48.1,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":56.79,
        "Ko-MMLU":42.0,
        "Ko-TruthfulQA":40.4,
        "Ko-CommonGen V2":56.08,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama2-ko-en-instruct-v7-13B",
        "Average":48.08,
        "Ko-ARC":45.65,
        "Ko-HellaSwag":55.93,
        "Ko-MMLU":40.51,
        "Ko-TruthfulQA":45.32,
        "Ko-CommonGen V2":53.01,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/Yi-Ko-6B-Instruct-v1.0",
        "Average":48.07,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":53.25,
        "Ko-MMLU":45.6,
        "Ko-TruthfulQA":41.69,
        "Ko-CommonGen V2":58.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v2.0",
        "Average":48.06,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":53.02,
        "Ko-MMLU":45.01,
        "Ko-TruthfulQA":49.7,
        "Ko-CommonGen V2":52.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/llama2_cot-13b-v2",
        "Average":48.06,
        "Ko-ARC":44.54,
        "Ko-HellaSwag":55.86,
        "Ko-MMLU":40.85,
        "Ko-TruthfulQA":46.76,
        "Ko-CommonGen V2":52.3,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/yi-ko-6b-lora-v1",
        "Average":48.04,
        "Ko-ARC":41.38,
        "Ko-HellaSwag":53.77,
        "Ko-MMLU":45.42,
        "Ko-TruthfulQA":43.21,
        "Ko-CommonGen V2":56.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.8",
        "Average":48.04,
        "Ko-ARC":40.19,
        "Ko-HellaSwag":53.1,
        "Ko-MMLU":44.01,
        "Ko-TruthfulQA":42.7,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/llama-2-koen-13b-v1.3",
        "Average":48.04,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":56.34,
        "Ko-MMLU":42.5,
        "Ko-TruthfulQA":42.17,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.5",
        "Average":48.02,
        "Ko-ARC":41.13,
        "Ko-HellaSwag":52.44,
        "Ko-MMLU":43.13,
        "Ko-TruthfulQA":42.6,
        "Ko-CommonGen V2":60.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"F24\/llama-2-koen-13b-slimOrca",
        "Average":48.02,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":56.36,
        "Ko-MMLU":45.17,
        "Ko-TruthfulQA":44.25,
        "Ko-CommonGen V2":48.05,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"wons\/Yi-6b-test-v0.1",
        "Average":48.02,
        "Ko-ARC":41.04,
        "Ko-HellaSwag":52.98,
        "Ko-MMLU":46.65,
        "Ko-TruthfulQA":40.97,
        "Ko-CommonGen V2":58.44,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/mistralopithecus-v1-SFT",
        "Average":47.98,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":53.44,
        "Ko-MMLU":45.95,
        "Ko-TruthfulQA":45.38,
        "Ko-CommonGen V2":47.46,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-v1.2",
        "Average":47.98,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":52.61,
        "Ko-MMLU":42.33,
        "Ko-TruthfulQA":43.87,
        "Ko-CommonGen V2":62.69,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"kfkas\/yi-ko-SFT-LoRA",
        "Average":47.94,
        "Ko-ARC":41.04,
        "Ko-HellaSwag":53.1,
        "Ko-MMLU":44.67,
        "Ko-TruthfulQA":40.81,
        "Ko-CommonGen V2":60.09,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"yuntaeyang\/SOLAR-10.7B-Instructlora_sftt-v1.0",
        "Average":47.94,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":47.41,
        "Ko-MMLU":50.2,
        "Ko-TruthfulQA":51.05,
        "Ko-CommonGen V2":48.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"ifuseok\/yi-ko-playtus-instruct-v0.2",
        "Average":47.93,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":52.95,
        "Ko-MMLU":43.78,
        "Ko-TruthfulQA":41.18,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/yi-ko-6b-it-v1.0.0",
        "Average":47.93,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":56.3,
        "Ko-MMLU":45.92,
        "Ko-TruthfulQA":40.24,
        "Ko-CommonGen V2":54.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/llama2_tmt-13b-v2",
        "Average":47.9,
        "Ko-ARC":43.26,
        "Ko-HellaSwag":55.52,
        "Ko-MMLU":39.95,
        "Ko-TruthfulQA":46.84,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v7.1",
        "Average":47.88,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":57.02,
        "Ko-MMLU":43.65,
        "Ko-TruthfulQA":39.82,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-7B-AO-u0.5-b2-ver0.4",
        "Average":47.88,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":48.81,
        "Ko-MMLU":46.12,
        "Ko-TruthfulQA":47.85,
        "Ko-CommonGen V2":57.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-ko-13b-instruct-v1",
        "Average":47.87,
        "Ko-ARC":44.45,
        "Ko-HellaSwag":54.38,
        "Ko-MMLU":43.22,
        "Ko-TruthfulQA":44.03,
        "Ko-CommonGen V2":53.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-ko-orca-plat-Yi-ko-6b-refine-v1.2",
        "Average":47.86,
        "Ko-ARC":42.06,
        "Ko-HellaSwag":52.72,
        "Ko-MMLU":44.83,
        "Ko-TruthfulQA":42.17,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Mistral_test03",
        "Average":47.84,
        "Ko-ARC":42.41,
        "Ko-HellaSwag":50.68,
        "Ko-MMLU":44.25,
        "Ko-TruthfulQA":45.69,
        "Ko-CommonGen V2":56.2,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.7",
        "Average":47.84,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":52.69,
        "Ko-MMLU":45.06,
        "Ko-TruthfulQA":51.77,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/Yi_lee-v1-6B",
        "Average":47.82,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":53.37,
        "Ko-MMLU":46.73,
        "Ko-TruthfulQA":40.55,
        "Ko-CommonGen V2":57.14,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/Yi_lee-v1-DPO-6B",
        "Average":47.8,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":53.39,
        "Ko-MMLU":46.67,
        "Ko-TruthfulQA":40.53,
        "Ko-CommonGen V2":57.14,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/seal3.1.3_ia3",
        "Average":47.8,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":56.13,
        "Ko-MMLU":39.75,
        "Ko-TruthfulQA":41.24,
        "Ko-CommonGen V2":56.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/seal3.1.6_ia3",
        "Average":47.8,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":56.59,
        "Ko-MMLU":41.14,
        "Ko-TruthfulQA":40.53,
        "Ko-CommonGen V2":55.49,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"megastudyedu\/ME-7B-v1.1",
        "Average":47.78,
        "Ko-ARC":47.18,
        "Ko-HellaSwag":53.27,
        "Ko-MMLU":48.12,
        "Ko-TruthfulQA":46.19,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v6",
        "Average":47.78,
        "Ko-ARC":45.22,
        "Ko-HellaSwag":56.6,
        "Ko-MMLU":42.36,
        "Ko-TruthfulQA":42.31,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.4",
        "Average":47.78,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":53.08,
        "Ko-MMLU":45.18,
        "Ko-TruthfulQA":50.51,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.7.0",
        "Average":47.78,
        "Ko-ARC":38.65,
        "Ko-HellaSwag":50.9,
        "Ko-MMLU":44.45,
        "Ko-TruthfulQA":47.15,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.8",
        "Average":47.74,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":56.46,
        "Ko-MMLU":40.57,
        "Ko-TruthfulQA":42.22,
        "Ko-CommonGen V2":54.31,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/Mistral-7B-OP-u1k-ver0.4",
        "Average":47.73,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":49.48,
        "Ko-MMLU":45.84,
        "Ko-TruthfulQA":48.63,
        "Ko-CommonGen V2":55.37,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/Yi-ko-1.1-dedup",
        "Average":47.73,
        "Ko-ARC":44.45,
        "Ko-HellaSwag":54.88,
        "Ko-MMLU":45.42,
        "Ko-TruthfulQA":41.82,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-Instruct-v0.3-pre2",
        "Average":47.72,
        "Ko-ARC":46.08,
        "Ko-HellaSwag":53.07,
        "Ko-MMLU":46.58,
        "Ko-TruthfulQA":46.35,
        "Ko-CommonGen V2":46.52,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"HY-KDPARK\/llama-2-koen-13b-dpo-v0.4",
        "Average":47.7,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":56.23,
        "Ko-MMLU":39.26,
        "Ko-TruthfulQA":43.14,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.4",
        "Average":47.67,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":56.74,
        "Ko-MMLU":38.71,
        "Ko-TruthfulQA":41.16,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/GenAI-llama-2-ko-en-instruct-v1",
        "Average":47.67,
        "Ko-ARC":44.45,
        "Ko-HellaSwag":55.72,
        "Ko-MMLU":37.63,
        "Ko-TruthfulQA":46.02,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/ko-llama2-v2",
        "Average":47.67,
        "Ko-ARC":40.19,
        "Ko-HellaSwag":52.47,
        "Ko-MMLU":39.83,
        "Ko-TruthfulQA":47.3,
        "Ko-CommonGen V2":58.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-Ko-ENW-v1",
        "Average":47.66,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":53.05,
        "Ko-MMLU":45.69,
        "Ko-TruthfulQA":41.73,
        "Ko-CommonGen V2":58.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/llama-2-koen-13b-mixed-v8",
        "Average":47.64,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":56.22,
        "Ko-MMLU":42.38,
        "Ko-TruthfulQA":40.99,
        "Ko-CommonGen V2":54.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Mistral_test02",
        "Average":47.63,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":51.35,
        "Ko-MMLU":42.95,
        "Ko-TruthfulQA":46.25,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/llama-2-koen-13b",
        "Average":47.63,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":56.23,
        "Ko-MMLU":42.31,
        "Ko-TruthfulQA":40.98,
        "Ko-CommonGen V2":54.66,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.10",
        "Average":47.62,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":57.23,
        "Ko-MMLU":40.35,
        "Ko-TruthfulQA":39.34,
        "Ko-CommonGen V2":55.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"yuntaeyang\/Yi-6B-ko-dpo",
        "Average":47.61,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":53.45,
        "Ko-MMLU":44.14,
        "Ko-TruthfulQA":41.65,
        "Ko-CommonGen V2":56.32,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.9B-v0.5",
        "Average":47.6,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":53.12,
        "Ko-MMLU":41.79,
        "Ko-TruthfulQA":43.94,
        "Ko-CommonGen V2":56.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.7.1",
        "Average":47.58,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":50.88,
        "Ko-MMLU":44.39,
        "Ko-TruthfulQA":46.61,
        "Ko-CommonGen V2":56.43,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.3",
        "Average":47.58,
        "Ko-ARC":44.62,
        "Ko-HellaSwag":56.83,
        "Ko-MMLU":40.86,
        "Ko-TruthfulQA":39.61,
        "Ko-CommonGen V2":55.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-Yi-Ko-6B-v1.11",
        "Average":47.57,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":53.34,
        "Ko-MMLU":43.11,
        "Ko-TruthfulQA":43.96,
        "Ko-CommonGen V2":56.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.6",
        "Average":47.56,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":53.08,
        "Ko-MMLU":45.99,
        "Ko-TruthfulQA":47.74,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"F24\/F23-llama2-13B-x1",
        "Average":47.55,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":56.5,
        "Ko-MMLU":39.66,
        "Ko-TruthfulQA":43.48,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/Yi-ko-F-v1",
        "Average":47.52,
        "Ko-ARC":40.53,
        "Ko-HellaSwag":53.03,
        "Ko-MMLU":45.83,
        "Ko-TruthfulQA":41.08,
        "Ko-CommonGen V2":57.14,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"megastudyedu\/ME-dpo-7B-v1.0",
        "Average":47.48,
        "Ko-ARC":46.76,
        "Ko-HellaSwag":54.25,
        "Ko-MMLU":47.51,
        "Ko-TruthfulQA":50.51,
        "Ko-CommonGen V2":38.37,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-v0.3-QA",
        "Average":47.47,
        "Ko-ARC":46.76,
        "Ko-HellaSwag":53.03,
        "Ko-MMLU":46.06,
        "Ko-TruthfulQA":47.25,
        "Ko-CommonGen V2":44.27,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jaekwanyda\/Yi-Ko-6B_KO_Open-Platypus",
        "Average":47.47,
        "Ko-ARC":40.02,
        "Ko-HellaSwag":53.09,
        "Ko-MMLU":43.61,
        "Ko-TruthfulQA":41.01,
        "Ko-CommonGen V2":59.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"amphora\/olaf-l.0.1",
        "Average":47.43,
        "Ko-ARC":47.01,
        "Ko-HellaSwag":54.51,
        "Ko-MMLU":43.07,
        "Ko-TruthfulQA":44.4,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.2",
        "Average":47.41,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":53.02,
        "Ko-MMLU":45.47,
        "Ko-TruthfulQA":47.52,
        "Ko-CommonGen V2":51.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Puluming\/AISquare-Instruct-llama2-koen-13b-v0.9.2",
        "Average":47.37,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":56.71,
        "Ko-MMLU":40.15,
        "Ko-TruthfulQA":39.18,
        "Ko-CommonGen V2":55.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/AIFT-ko-orca-plat-Yi-ko-6b-v1.0",
        "Average":47.33,
        "Ko-ARC":40.02,
        "Ko-HellaSwag":52.47,
        "Ko-MMLU":42.89,
        "Ko-TruthfulQA":41.06,
        "Ko-CommonGen V2":60.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"hongzoh\/Yi-Ko-6B_Open-Platypus",
        "Average":47.32,
        "Ko-ARC":40.44,
        "Ko-HellaSwag":52.7,
        "Ko-MMLU":44.64,
        "Ko-TruthfulQA":41.77,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/llama2_tmt-13b-v1",
        "Average":47.3,
        "Ko-ARC":42.92,
        "Ko-HellaSwag":55.77,
        "Ko-MMLU":39.67,
        "Ko-TruthfulQA":47.16,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.3.0",
        "Average":47.3,
        "Ko-ARC":38.74,
        "Ko-HellaSwag":49.86,
        "Ko-MMLU":44.53,
        "Ko-TruthfulQA":45.39,
        "Ko-CommonGen V2":57.97,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MNC-LLM\/Mistral-11B-Omni-OPA-u1k-ver0.7",
        "Average":47.29,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":49.23,
        "Ko-MMLU":44.79,
        "Ko-TruthfulQA":49.12,
        "Ko-CommonGen V2":54.31,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":11.0
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-11B-OP-u1k-ver0.7",
        "Average":47.27,
        "Ko-ARC":39.08,
        "Ko-HellaSwag":49.6,
        "Ko-MMLU":44.66,
        "Ko-TruthfulQA":49.5,
        "Ko-CommonGen V2":53.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":11.0
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/KoSOLAR-10.7B-QLoRA-NEFTune-kolon-v0.1",
        "Average":47.19,
        "Ko-ARC":42.41,
        "Ko-HellaSwag":57.01,
        "Ko-MMLU":51.33,
        "Ko-TruthfulQA":40.33,
        "Ko-CommonGen V2":44.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"kfkas\/llama-2-koen-13b-SFT-LoRA-4bit",
        "Average":47.18,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":56.44,
        "Ko-MMLU":40.62,
        "Ko-TruthfulQA":41.28,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v7.2",
        "Average":47.16,
        "Ko-ARC":47.7,
        "Ko-HellaSwag":58.2,
        "Ko-MMLU":42.94,
        "Ko-TruthfulQA":37.83,
        "Ko-CommonGen V2":49.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Minirecord\/Mini_DPO_test02",
        "Average":47.14,
        "Ko-ARC":44.71,
        "Ko-HellaSwag":51.83,
        "Ko-MMLU":43.65,
        "Ko-TruthfulQA":41.57,
        "Ko-CommonGen V2":53.96,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MNC-LLM\/Mistral-7B-O3k-Au1k-ver0.7",
        "Average":47.14,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":48.83,
        "Ko-MMLU":45.46,
        "Ko-TruthfulQA":47.26,
        "Ko-CommonGen V2":55.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"sanghwa-na\/llama2-13b.kor.v2",
        "Average":47.11,
        "Ko-ARC":44.2,
        "Ko-HellaSwag":54.86,
        "Ko-MMLU":40.35,
        "Ko-TruthfulQA":43.02,
        "Ko-CommonGen V2":53.13,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/KoSOLAR-10.7B-kolon",
        "Average":47.11,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":57.02,
        "Ko-MMLU":51.26,
        "Ko-TruthfulQA":40.32,
        "Ko-CommonGen V2":44.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"gangkongkong\/llama-2-koen-13b-gangkk-alpaca-cosine-all-epoch3-merge",
        "Average":47.06,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":55.72,
        "Ko-MMLU":39.11,
        "Ko-TruthfulQA":43.54,
        "Ko-CommonGen V2":53.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.0",
        "Average":47.03,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":53.19,
        "Ko-MMLU":45.72,
        "Ko-TruthfulQA":46.08,
        "Ko-CommonGen V2":51.24,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"kfkas\/llama-2-koen-13b-SFT-LoRA-4bit-re",
        "Average":47.02,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":56.44,
        "Ko-MMLU":38.53,
        "Ko-TruthfulQA":43.78,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.3",
        "Average":47.02,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":53.12,
        "Ko-MMLU":45.34,
        "Ko-TruthfulQA":47.37,
        "Ko-CommonGen V2":50.3,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"MNCLLM\/Mistral-7B-orca-platy-over1k",
        "Average":47.02,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":49.65,
        "Ko-MMLU":44.29,
        "Ko-TruthfulQA":46.67,
        "Ko-CommonGen V2":52.77,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCLLM\/Mistral-7B-OP-over1k-grad1.0",
        "Average":47.02,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":49.65,
        "Ko-MMLU":44.28,
        "Ko-TruthfulQA":46.67,
        "Ko-CommonGen V2":52.77,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/Yi-ko-1.2",
        "Average":47.0,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":54.79,
        "Ko-MMLU":44.52,
        "Ko-TruthfulQA":40.74,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/ku-mistral-7b-PGO-v2",
        "Average":47.0,
        "Ko-ARC":43.6,
        "Ko-HellaSwag":52.53,
        "Ko-MMLU":46.17,
        "Ko-TruthfulQA":45.58,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"OMK510\/omk_mixed2",
        "Average":46.98,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":54.62,
        "Ko-MMLU":38.55,
        "Ko-TruthfulQA":42.17,
        "Ko-CommonGen V2":56.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"shleeeee\/mistral-7b-ko-dpo-v1",
        "Average":46.98,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":49.27,
        "Ko-MMLU":44.9,
        "Ko-TruthfulQA":47.85,
        "Ko-CommonGen V2":54.31,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"ENERGY-DRINK-LOVE\/leaderboard_inst_v1.5_LDCC-SOLAR-10.7B_SFT",
        "Average":46.94,
        "Ko-ARC":49.32,
        "Ko-HellaSwag":59.95,
        "Ko-MMLU":49.71,
        "Ko-TruthfulQA":39.61,
        "Ko-CommonGen V2":36.13,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/ko-en-llama2-13b-mixed-v4",
        "Average":46.93,
        "Ko-ARC":43.0,
        "Ko-HellaSwag":54.5,
        "Ko-MMLU":38.53,
        "Ko-TruthfulQA":42.4,
        "Ko-CommonGen V2":56.2,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"dasomysky\/unv_v0.1.3",
        "Average":46.92,
        "Ko-ARC":60.58,
        "Ko-HellaSwag":50.97,
        "Ko-MMLU":39.38,
        "Ko-TruthfulQA":41.04,
        "Ko-CommonGen V2":42.62,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"taeminlee\/mistral_7B_ma",
        "Average":46.89,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":48.19,
        "Ko-MMLU":45.2,
        "Ko-TruthfulQA":46.13,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Average":46.89,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":48.19,
        "Ko-MMLU":45.2,
        "Ko-TruthfulQA":46.13,
        "Ko-CommonGen V2":56.79,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/yi-ko-SFT-LoRA-play-re-noprompt",
        "Average":46.88,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":51.0,
        "Ko-MMLU":43.96,
        "Ko-TruthfulQA":41.55,
        "Ko-CommonGen V2":58.21,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Byungchae\/k2s3_test_0002",
        "Average":46.88,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":49.18,
        "Ko-MMLU":50.08,
        "Ko-TruthfulQA":41.83,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/ko-en-llama2-13b-mixed-v5",
        "Average":46.87,
        "Ko-ARC":43.17,
        "Ko-HellaSwag":54.55,
        "Ko-MMLU":38.6,
        "Ko-TruthfulQA":42.19,
        "Ko-CommonGen V2":55.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"dltjdgh0928\/test_instruction",
        "Average":46.84,
        "Ko-ARC":41.21,
        "Ko-HellaSwag":49.56,
        "Ko-MMLU":43.14,
        "Ko-TruthfulQA":47.96,
        "Ko-CommonGen V2":52.3,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/Yi-ko-1.1",
        "Average":46.83,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":55.27,
        "Ko-MMLU":44.89,
        "Ko-TruthfulQA":42.28,
        "Ko-CommonGen V2":47.7,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-Mistral-7bx2-48layers_v1.2",
        "Average":46.8,
        "Ko-ARC":41.89,
        "Ko-HellaSwag":49.24,
        "Ko-MMLU":44.82,
        "Ko-TruthfulQA":47.88,
        "Ko-CommonGen V2":50.18,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-ko-7b-it-v2.0.1",
        "Average":46.79,
        "Ko-ARC":37.88,
        "Ko-HellaSwag":49.18,
        "Ko-MMLU":45.28,
        "Ko-TruthfulQA":44.09,
        "Ko-CommonGen V2":57.5,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"little-fox\/Leonardo",
        "Average":46.74,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":55.35,
        "Ko-MMLU":45.25,
        "Ko-TruthfulQA":46.09,
        "Ko-CommonGen V2":40.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.5-DPO",
        "Average":46.72,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":53.27,
        "Ko-MMLU":45.19,
        "Ko-TruthfulQA":48.37,
        "Ko-CommonGen V2":47.46,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"madatnlp\/marcoroni-7b-v3-safetensor",
        "Average":46.71,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":51.05,
        "Ko-MMLU":44.94,
        "Ko-TruthfulQA":53.65,
        "Ko-CommonGen V2":41.44,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/Yi-Ko-6B-instruct-v1.5",
        "Average":46.7,
        "Ko-ARC":39.16,
        "Ko-HellaSwag":53.31,
        "Ko-MMLU":45.32,
        "Ko-TruthfulQA":48.36,
        "Ko-CommonGen V2":47.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/Yi-Ko-6B-orca-alpaca-gpt4-math",
        "Average":46.69,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":52.22,
        "Ko-MMLU":41.79,
        "Ko-TruthfulQA":45.18,
        "Ko-CommonGen V2":54.78,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-13B_01",
        "Average":46.69,
        "Ko-ARC":44.71,
        "Ko-HellaSwag":57.33,
        "Ko-MMLU":44.16,
        "Ko-TruthfulQA":39.08,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/Mistral-7B-v0.1-OKI-v20231124-1e-5",
        "Average":46.68,
        "Ko-ARC":39.42,
        "Ko-HellaSwag":49.05,
        "Ko-MMLU":45.96,
        "Ko-TruthfulQA":45.25,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-OpenOrca-Platypus-v1",
        "Average":46.68,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":47.66,
        "Ko-MMLU":44.96,
        "Ko-TruthfulQA":45.82,
        "Ko-CommonGen V2":56.55,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/ku-mistral-7b-PGO-v1",
        "Average":46.67,
        "Ko-ARC":44.97,
        "Ko-HellaSwag":52.91,
        "Ko-MMLU":45.73,
        "Ko-TruthfulQA":45.49,
        "Ko-CommonGen V2":44.27,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"dasomysky\/unv_v0.1.4",
        "Average":46.65,
        "Ko-ARC":61.77,
        "Ko-HellaSwag":52.64,
        "Ko-MMLU":40.53,
        "Ko-TruthfulQA":43.46,
        "Ko-CommonGen V2":34.83,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-Zephyr-7B-v0.02",
        "Average":46.64,
        "Ko-ARC":46.16,
        "Ko-HellaSwag":51.11,
        "Ko-MMLU":44.33,
        "Ko-TruthfulQA":45.7,
        "Ko-CommonGen V2":45.93,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/MIstral-11B-Omni-OP-1k-2048-ver0.1",
        "Average":46.64,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":49.47,
        "Ko-MMLU":44.18,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":11.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Mistral-7B-Ko-v3",
        "Average":46.63,
        "Ko-ARC":38.74,
        "Ko-HellaSwag":48.62,
        "Ko-MMLU":45.09,
        "Ko-TruthfulQA":43.93,
        "Ko-CommonGen V2":56.79,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13B-v4",
        "Average":46.6,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":55.88,
        "Ko-MMLU":41.44,
        "Ko-TruthfulQA":47.96,
        "Ko-CommonGen V2":42.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.9",
        "Average":46.6,
        "Ko-ARC":43.43,
        "Ko-HellaSwag":56.05,
        "Ko-MMLU":38.61,
        "Ko-TruthfulQA":41.06,
        "Ko-CommonGen V2":53.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KoR-Orca-Platypus-13B",
        "Average":46.59,
        "Ko-ARC":42.06,
        "Ko-HellaSwag":53.95,
        "Ko-MMLU":42.28,
        "Ko-TruthfulQA":43.55,
        "Ko-CommonGen V2":51.12,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-7B-A-u0.5-b2-ver0.4",
        "Average":46.59,
        "Ko-ARC":37.71,
        "Ko-HellaSwag":47.66,
        "Ko-MMLU":45.31,
        "Ko-TruthfulQA":47.27,
        "Ko-CommonGen V2":55.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Ja3ck\/Mistral-instruct-Y24-DPO",
        "Average":46.58,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":51.2,
        "Ko-MMLU":45.49,
        "Ko-TruthfulQA":46.24,
        "Ko-CommonGen V2":47.23,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.6n_13b_pre",
        "Average":46.55,
        "Ko-ARC":48.29,
        "Ko-HellaSwag":59.85,
        "Ko-MMLU":41.51,
        "Ko-TruthfulQA":41.54,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/Yi-ko_3_1_7",
        "Average":46.54,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":55.26,
        "Ko-MMLU":43.88,
        "Ko-TruthfulQA":43.71,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.1.14",
        "Average":46.54,
        "Ko-ARC":43.26,
        "Ko-HellaSwag":53.93,
        "Ko-MMLU":39.87,
        "Ko-TruthfulQA":44.51,
        "Ko-CommonGen V2":51.12,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"OpenBuddy\/openbuddy-llemma-34b-v13.2",
        "Average":46.54,
        "Ko-ARC":41.47,
        "Ko-HellaSwag":45.72,
        "Ko-MMLU":45.69,
        "Ko-TruthfulQA":46.21,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Ja3ck\/Mistral-instruct-IPO-Y24-v1",
        "Average":46.53,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":51.09,
        "Ko-MMLU":45.33,
        "Ko-TruthfulQA":46.2,
        "Ko-CommonGen V2":47.7,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13B-v3",
        "Average":46.52,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":53.92,
        "Ko-MMLU":42.43,
        "Ko-TruthfulQA":43.56,
        "Ko-CommonGen V2":50.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-OpenOrca-Platypus-v2",
        "Average":46.5,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":47.74,
        "Ko-MMLU":44.17,
        "Ko-TruthfulQA":45.95,
        "Ko-CommonGen V2":57.02,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Jenti-Kaeri\/ko-llama2-13b-OrcaPlatypus",
        "Average":46.5,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":54.16,
        "Ko-MMLU":39.09,
        "Ko-TruthfulQA":43.13,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.9B-v0.3",
        "Average":46.48,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":51.99,
        "Ko-MMLU":42.52,
        "Ko-TruthfulQA":41.65,
        "Ko-CommonGen V2":52.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"madatnlp\/mist-enko-lora-2950",
        "Average":46.45,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":48.57,
        "Ko-MMLU":45.58,
        "Ko-TruthfulQA":47.03,
        "Ko-CommonGen V2":51.59,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"PracticeLLM\/Custom-KoLLM-13B-v3",
        "Average":46.4,
        "Ko-ARC":44.71,
        "Ko-HellaSwag":56.89,
        "Ko-MMLU":40.86,
        "Ko-TruthfulQA":44.22,
        "Ko-CommonGen V2":45.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCLLM\/Mistral-7B-OP-over1k-grad0.3",
        "Average":46.38,
        "Ko-ARC":41.04,
        "Ko-HellaSwag":49.49,
        "Ko-MMLU":43.75,
        "Ko-TruthfulQA":46.38,
        "Ko-CommonGen V2":51.24,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/Dolphin-Mistral-7B-OP-u1k-ver0.1",
        "Average":46.37,
        "Ko-ARC":40.78,
        "Ko-HellaSwag":49.66,
        "Ko-MMLU":44.1,
        "Ko-TruthfulQA":49.38,
        "Ko-CommonGen V2":47.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/aift-llama2-koen-instruct-v1.0",
        "Average":46.31,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":56.69,
        "Ko-MMLU":43.45,
        "Ko-TruthfulQA":39.73,
        "Ko-CommonGen V2":48.17,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Kosy-platypus2-13B-v3",
        "Average":46.31,
        "Ko-ARC":43.34,
        "Ko-HellaSwag":54.54,
        "Ko-MMLU":43.38,
        "Ko-TruthfulQA":44.11,
        "Ko-CommonGen V2":46.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-ko-13b-instruct",
        "Average":46.29,
        "Ko-ARC":44.8,
        "Ko-HellaSwag":54.56,
        "Ko-MMLU":42.01,
        "Ko-TruthfulQA":44.18,
        "Ko-CommonGen V2":45.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"freewheelin\/free-solar-instrunction-v0.3",
        "Average":46.29,
        "Ko-ARC":44.11,
        "Ko-HellaSwag":53.68,
        "Ko-MMLU":45.56,
        "Ko-TruthfulQA":41.01,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihunKim\/Mistral-7B-OpenOrca-orca-platy-out1kover",
        "Average":46.29,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":48.95,
        "Ko-MMLU":43.25,
        "Ko-TruthfulQA":47.51,
        "Ko-CommonGen V2":50.41,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"megastudyedu\/ME-7B-v1.0",
        "Average":46.28,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":53.09,
        "Ko-MMLU":47.6,
        "Ko-TruthfulQA":45.42,
        "Ko-CommonGen V2":40.14,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/aift-llama2-koen-instruct-v1.2",
        "Average":46.25,
        "Ko-ARC":44.54,
        "Ko-HellaSwag":57.84,
        "Ko-MMLU":43.22,
        "Ko-TruthfulQA":40.53,
        "Ko-CommonGen V2":45.1,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIdenU\/Mistral-7b-ko-Y24-DPO_v0.1",
        "Average":46.19,
        "Ko-ARC":40.53,
        "Ko-HellaSwag":49.15,
        "Ko-MMLU":43.3,
        "Ko-TruthfulQA":43.8,
        "Ko-CommonGen V2":54.19,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4",
        "Average":46.17,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":54.26,
        "Ko-MMLU":36.02,
        "Ko-TruthfulQA":45.28,
        "Ko-CommonGen V2":51.24,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-Yi-Ko-6B",
        "Average":46.15,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":48.15,
        "Ko-MMLU":46.78,
        "Ko-TruthfulQA":47.04,
        "Ko-CommonGen V2":47.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/MIstral-11B-Omni-OP-u1k-ver0.1",
        "Average":46.14,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":48.75,
        "Ko-MMLU":43.64,
        "Ko-TruthfulQA":47.51,
        "Ko-CommonGen V2":48.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openchat\/openchat-3.5-0106",
        "Average":46.13,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.08,
        "Ko-MMLU":45.03,
        "Ko-TruthfulQA":51.25,
        "Ko-CommonGen V2":47.46,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_orca_test01",
        "Average":46.1,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":50.32,
        "Ko-MMLU":41.73,
        "Ko-TruthfulQA":45.49,
        "Ko-CommonGen V2":49.0,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/aift-llama2-koen-instruct-v1.1",
        "Average":46.07,
        "Ko-ARC":44.03,
        "Ko-HellaSwag":57.15,
        "Ko-MMLU":43.69,
        "Ko-TruthfulQA":40.28,
        "Ko-CommonGen V2":45.22,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Ja3ck\/Mistral-instruct-Y24-v5",
        "Average":46.07,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":50.74,
        "Ko-MMLU":45.36,
        "Ko-TruthfulQA":44.26,
        "Ko-CommonGen V2":47.23,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"AIdenU\/Mistral-7b-ko-Y24_v0.1",
        "Average":46.06,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":48.85,
        "Ko-MMLU":43.57,
        "Ko-TruthfulQA":43.38,
        "Ko-CommonGen V2":54.9,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/mistral-7b-instruct-ko-test-v0.2",
        "Average":46.05,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":49.3,
        "Ko-MMLU":43.74,
        "Ko-TruthfulQA":45.11,
        "Ko-CommonGen V2":53.72,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.2",
        "Average":46.02,
        "Ko-ARC":41.47,
        "Ko-HellaSwag":49.35,
        "Ko-MMLU":44.53,
        "Ko-TruthfulQA":45.29,
        "Ko-CommonGen V2":49.47,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.37
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Big_Minirecord02",
        "Average":46.01,
        "Ko-ARC":43.43,
        "Ko-HellaSwag":51.29,
        "Ko-MMLU":44.56,
        "Ko-TruthfulQA":42.84,
        "Ko-CommonGen V2":47.93,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-Zephyr-7B-v0.01",
        "Average":46.0,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":51.4,
        "Ko-MMLU":44.26,
        "Ko-TruthfulQA":47.55,
        "Ko-CommonGen V2":43.09,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/seal_all_13b",
        "Average":45.99,
        "Ko-ARC":46.16,
        "Ko-HellaSwag":57.72,
        "Ko-MMLU":41.08,
        "Ko-TruthfulQA":36.71,
        "Ko-CommonGen V2":48.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-ko-7b-it-v2.0.0",
        "Average":45.99,
        "Ko-ARC":39.08,
        "Ko-HellaSwag":49.01,
        "Ko-MMLU":45.07,
        "Ko-TruthfulQA":43.31,
        "Ko-CommonGen V2":53.48,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/ko-en-llama2-13b-mixed-v3",
        "Average":45.97,
        "Ko-ARC":42.41,
        "Ko-HellaSwag":54.33,
        "Ko-MMLU":37.61,
        "Ko-TruthfulQA":41.69,
        "Ko-CommonGen V2":53.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.1.8",
        "Average":45.97,
        "Ko-ARC":45.14,
        "Ko-HellaSwag":54.12,
        "Ko-MMLU":30.02,
        "Ko-TruthfulQA":46.0,
        "Ko-CommonGen V2":54.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"AIJUUD\/juud-Mistral-7B-dpo",
        "Average":45.95,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":49.39,
        "Ko-MMLU":43.6,
        "Ko-TruthfulQA":49.35,
        "Ko-CommonGen V2":48.41,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-Yi-Ko-6B-v0.8",
        "Average":45.94,
        "Ko-ARC":41.47,
        "Ko-HellaSwag":53.6,
        "Ko-MMLU":44.13,
        "Ko-TruthfulQA":48.01,
        "Ko-CommonGen V2":42.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Average":45.94,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":47.48,
        "Ko-MMLU":43.29,
        "Ko-TruthfulQA":49.55,
        "Ko-CommonGen V2":50.06,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13b-v2",
        "Average":45.93,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":54.01,
        "Ko-MMLU":42.45,
        "Ko-TruthfulQA":43.61,
        "Ko-CommonGen V2":47.58,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.0",
        "Average":45.9,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":50.43,
        "Ko-MMLU":42.72,
        "Ko-TruthfulQA":44.48,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/aift-llama2-koen-instruct-v1.1-dpo-test1",
        "Average":45.89,
        "Ko-ARC":44.11,
        "Ko-HellaSwag":57.2,
        "Ko-MMLU":43.62,
        "Ko-TruthfulQA":40.23,
        "Ko-CommonGen V2":44.27,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"norispace\/marcoroni-kopenorcav3",
        "Average":45.87,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":49.97,
        "Ko-MMLU":44.62,
        "Ko-TruthfulQA":47.66,
        "Ko-CommonGen V2":45.81,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"wons\/mistral-7B-test-v0.1",
        "Average":45.86,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":48.71,
        "Ko-MMLU":45.03,
        "Ko-TruthfulQA":45.95,
        "Ko-CommonGen V2":50.3,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Jolteon-Instruct-13B-alpha",
        "Average":45.85,
        "Ko-ARC":45.31,
        "Ko-HellaSwag":49.33,
        "Ko-MMLU":47.94,
        "Ko-TruthfulQA":49.15,
        "Ko-CommonGen V2":37.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.42
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/mistral7b-lora-multi-turn-v2",
        "Average":45.79,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":47.66,
        "Ko-MMLU":44.39,
        "Ko-TruthfulQA":45.85,
        "Ko-CommonGen V2":52.07,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COLA3_13B",
        "Average":45.79,
        "Ko-ARC":42.24,
        "Ko-HellaSwag":54.35,
        "Ko-MMLU":39.95,
        "Ko-TruthfulQA":40.93,
        "Ko-CommonGen V2":51.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Ja3ck\/Mistral-instruct-DPO-Y24-v2",
        "Average":45.78,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":50.71,
        "Ko-MMLU":44.93,
        "Ko-TruthfulQA":46.64,
        "Ko-CommonGen V2":44.63,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MNCKim\/Mistral-7B-OpenHermes",
        "Average":45.77,
        "Ko-ARC":38.82,
        "Ko-HellaSwag":48.71,
        "Ko-MMLU":44.71,
        "Ko-TruthfulQA":49.28,
        "Ko-CommonGen V2":47.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kiyoonyoo\/ko-platypus-13b-control",
        "Average":45.77,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":53.88,
        "Ko-MMLU":42.42,
        "Ko-TruthfulQA":43.43,
        "Ko-CommonGen V2":46.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Mistral-7B-ko-v1",
        "Average":45.76,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":47.64,
        "Ko-MMLU":41.98,
        "Ko-TruthfulQA":43.67,
        "Ko-CommonGen V2":57.97,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"statpan\/singung-sft-v0.1",
        "Average":45.76,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":49.62,
        "Ko-MMLU":42.77,
        "Ko-TruthfulQA":47.19,
        "Ko-CommonGen V2":48.52,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jyoung105\/KoR-Orca-Platypus-13B-neft",
        "Average":45.76,
        "Ko-ARC":40.96,
        "Ko-HellaSwag":53.25,
        "Ko-MMLU":37.81,
        "Ko-TruthfulQA":45.41,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":45.74,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":48.0,
        "Ko-MMLU":42.96,
        "Ko-TruthfulQA":54.96,
        "Ko-CommonGen V2":43.8,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.6.0",
        "Average":45.72,
        "Ko-ARC":37.29,
        "Ko-HellaSwag":49.92,
        "Ko-MMLU":42.72,
        "Ko-TruthfulQA":44.36,
        "Ko-CommonGen V2":54.31,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIdenU\/LLAMA-2-13b-ko-Y24-DPO_v2.0",
        "Average":45.72,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":47.64,
        "Ko-MMLU":37.57,
        "Ko-TruthfulQA":47.96,
        "Ko-CommonGen V2":56.08,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.003",
        "Average":45.71,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":47.08,
        "Ko-MMLU":42.08,
        "Ko-TruthfulQA":45.11,
        "Ko-CommonGen V2":53.6,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kimwooglae\/AISquare-Instruct-SOLAR-10.7b-v0.5.32",
        "Average":45.71,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":48.15,
        "Ko-MMLU":46.72,
        "Ko-TruthfulQA":44.44,
        "Ko-CommonGen V2":51.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Mistral_test01",
        "Average":45.7,
        "Ko-ARC":38.23,
        "Ko-HellaSwag":47.89,
        "Ko-MMLU":44.45,
        "Ko-TruthfulQA":46.47,
        "Ko-CommonGen V2":51.48,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/llama-2-koen-13b-kolon",
        "Average":45.7,
        "Ko-ARC":43.6,
        "Ko-HellaSwag":55.49,
        "Ko-MMLU":38.97,
        "Ko-TruthfulQA":38.02,
        "Ko-CommonGen V2":52.42,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.0.2",
        "Average":45.69,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":49.54,
        "Ko-MMLU":43.64,
        "Ko-TruthfulQA":45.34,
        "Ko-CommonGen V2":49.59,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-tech-science-v1",
        "Average":45.69,
        "Ko-ARC":37.29,
        "Ko-HellaSwag":47.33,
        "Ko-MMLU":44.86,
        "Ko-TruthfulQA":45.02,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_orca_test03",
        "Average":45.65,
        "Ko-ARC":41.89,
        "Ko-HellaSwag":49.83,
        "Ko-MMLU":42.26,
        "Ko-TruthfulQA":47.05,
        "Ko-CommonGen V2":47.23,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jyoung105\/ko-platypus2-collective-13b",
        "Average":45.65,
        "Ko-ARC":44.28,
        "Ko-HellaSwag":54.28,
        "Ko-MMLU":42.5,
        "Ko-TruthfulQA":44.43,
        "Ko-CommonGen V2":42.74,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.0.1",
        "Average":45.65,
        "Ko-ARC":41.47,
        "Ko-HellaSwag":49.87,
        "Ko-MMLU":42.75,
        "Ko-TruthfulQA":45.38,
        "Ko-CommonGen V2":48.76,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-openorca-platypus-1epoch",
        "Average":45.64,
        "Ko-ARC":36.77,
        "Ko-HellaSwag":44.28,
        "Ko-MMLU":44.53,
        "Ko-TruthfulQA":47.71,
        "Ko-CommonGen V2":54.9,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/llama-2-koen-13b-QLoRA-NEFTune-kolon",
        "Average":45.63,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":55.49,
        "Ko-MMLU":38.94,
        "Ko-TruthfulQA":38.02,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/llama-2-koen-13b-QLoRA-NEFTune-kolon-v0.1",
        "Average":45.63,
        "Ko-ARC":43.52,
        "Ko-HellaSwag":55.49,
        "Ko-MMLU":38.94,
        "Ko-TruthfulQA":38.02,
        "Ko-CommonGen V2":52.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/mistralopithecus-v1-dpo",
        "Average":45.62,
        "Ko-ARC":52.73,
        "Ko-HellaSwag":55.66,
        "Ko-MMLU":42.0,
        "Ko-TruthfulQA":45.0,
        "Ko-CommonGen V2":32.7,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/mistralopithecus-v1-dpo-7b",
        "Average":45.61,
        "Ko-ARC":52.73,
        "Ko-HellaSwag":55.65,
        "Ko-MMLU":42.0,
        "Ko-TruthfulQA":44.99,
        "Ko-CommonGen V2":32.7,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kiyoonyoo\/ko-en-trans-platypus-13b-v2",
        "Average":45.61,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":54.3,
        "Ko-MMLU":38.89,
        "Ko-TruthfulQA":40.74,
        "Ko-CommonGen V2":51.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kiyoonyoo\/ko-en-trans-platypus-13b",
        "Average":45.61,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":54.3,
        "Ko-MMLU":38.89,
        "Ko-TruthfulQA":40.74,
        "Ko-CommonGen V2":51.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KO-Platypus2-13B",
        "Average":45.6,
        "Ko-ARC":44.2,
        "Ko-HellaSwag":54.31,
        "Ko-MMLU":42.47,
        "Ko-TruthfulQA":44.41,
        "Ko-CommonGen V2":42.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-34b-Instruct-hf",
        "Average":45.6,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":48.97,
        "Ko-MMLU":43.05,
        "Ko-TruthfulQA":47.99,
        "Ko-CommonGen V2":48.64,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":33.74
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"hyunseoki\/ko-en-llama2-13b",
        "Average":45.59,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":54.23,
        "Ko-MMLU":38.9,
        "Ko-TruthfulQA":40.74,
        "Ko-CommonGen V2":51.95,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCLLM\/Mistral-7B-OP-over500-grad1.0",
        "Average":45.58,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":48.19,
        "Ko-MMLU":42.63,
        "Ko-TruthfulQA":46.3,
        "Ko-CommonGen V2":47.93,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/llama2-70b-v0.1",
        "Average":45.58,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":48.7,
        "Ko-MMLU":44.51,
        "Ko-TruthfulQA":44.64,
        "Ko-CommonGen V2":48.05,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":69.22
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_orca_test04",
        "Average":45.57,
        "Ko-ARC":41.89,
        "Ko-HellaSwag":49.81,
        "Ko-MMLU":42.25,
        "Ko-TruthfulQA":47.04,
        "Ko-CommonGen V2":46.87,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jyoung105\/ko-platypus2-collective-13b_v1.1",
        "Average":45.56,
        "Ko-ARC":44.54,
        "Ko-HellaSwag":54.14,
        "Ko-MMLU":42.42,
        "Ko-TruthfulQA":45.98,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"instructkr\/ko-storywriter-nano",
        "Average":45.48,
        "Ko-ARC":40.1,
        "Ko-HellaSwag":51.85,
        "Ko-MMLU":39.82,
        "Ko-TruthfulQA":40.04,
        "Ko-CommonGen V2":55.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"maum-ai\/llamaum-13b-instruct-v1",
        "Average":45.46,
        "Ko-ARC":45.82,
        "Ko-HellaSwag":53.76,
        "Ko-MMLU":40.49,
        "Ko-TruthfulQA":44.26,
        "Ko-CommonGen V2":42.98,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Kosy-platypus2-13B-v2",
        "Average":45.45,
        "Ko-ARC":44.2,
        "Ko-HellaSwag":54.56,
        "Ko-MMLU":42.6,
        "Ko-TruthfulQA":42.68,
        "Ko-CommonGen V2":43.21,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"StatPan\/SinGung7B-DPO-v0.1-12600c",
        "Average":45.42,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":47.71,
        "Ko-MMLU":40.7,
        "Ko-TruthfulQA":51.47,
        "Ko-CommonGen V2":45.93,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-Instruct-v0.3",
        "Average":45.4,
        "Ko-ARC":45.48,
        "Ko-HellaSwag":51.91,
        "Ko-MMLU":45.13,
        "Ko-TruthfulQA":45.14,
        "Ko-CommonGen V2":39.32,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/sitebunny-13b",
        "Average":45.39,
        "Ko-ARC":41.13,
        "Ko-HellaSwag":47.51,
        "Ko-MMLU":42.64,
        "Ko-TruthfulQA":51.49,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihunKim\/Mistral-7B-SlimOrca-orca-platy-out1kover",
        "Average":45.38,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":48.79,
        "Ko-MMLU":42.94,
        "Ko-TruthfulQA":45.82,
        "Ko-CommonGen V2":47.82,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"cepiloth\/ko-en-llama2-13b-finetune",
        "Average":45.38,
        "Ko-ARC":42.75,
        "Ko-HellaSwag":53.62,
        "Ko-MMLU":39.45,
        "Ko-TruthfulQA":45.61,
        "Ko-CommonGen V2":45.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KoT-platypus2-13B",
        "Average":45.35,
        "Ko-ARC":43.69,
        "Ko-HellaSwag":53.05,
        "Ko-MMLU":42.29,
        "Ko-TruthfulQA":43.34,
        "Ko-CommonGen V2":44.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_category",
        "Average":45.33,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":48.3,
        "Ko-MMLU":43.61,
        "Ko-TruthfulQA":46.15,
        "Ko-CommonGen V2":49.7,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-7b-wiki",
        "Average":45.33,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":47.06,
        "Ko-MMLU":43.72,
        "Ko-TruthfulQA":45.1,
        "Ko-CommonGen V2":54.43,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-ref",
        "Average":45.33,
        "Ko-ARC":35.75,
        "Ko-HellaSwag":44.92,
        "Ko-MMLU":41.5,
        "Ko-TruthfulQA":47.21,
        "Ko-CommonGen V2":57.26,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-Yi-Ko-6B-v2.0",
        "Average":45.32,
        "Ko-ARC":42.83,
        "Ko-HellaSwag":53.73,
        "Ko-MMLU":44.39,
        "Ko-TruthfulQA":41.96,
        "Ko-CommonGen V2":43.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-Yi-Ko-6B-v1.0",
        "Average":45.31,
        "Ko-ARC":42.49,
        "Ko-HellaSwag":53.83,
        "Ko-MMLU":44.03,
        "Ko-TruthfulQA":43.12,
        "Ko-CommonGen V2":43.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"sanghwa-na\/llama2-13b.kor",
        "Average":45.28,
        "Ko-ARC":38.74,
        "Ko-HellaSwag":48.65,
        "Ko-MMLU":38.44,
        "Ko-TruthfulQA":42.85,
        "Ko-CommonGen V2":57.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"StatPan\/singung-dpo-v0.1-2200",
        "Average":45.27,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":48.21,
        "Ko-MMLU":40.98,
        "Ko-TruthfulQA":45.91,
        "Ko-CommonGen V2":49.7,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MRAIRR\/MRAI_synatra_7B_v1",
        "Average":45.26,
        "Ko-ARC":43.77,
        "Ko-HellaSwag":49.31,
        "Ko-MMLU":43.14,
        "Ko-TruthfulQA":45.9,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/mistral-7b-ko-1871-2p1",
        "Average":45.23,
        "Ko-ARC":36.09,
        "Ko-HellaSwag":47.59,
        "Ko-MMLU":43.04,
        "Ko-TruthfulQA":48.92,
        "Ko-CommonGen V2":50.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.005",
        "Average":45.21,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":46.96,
        "Ko-MMLU":42.6,
        "Ko-TruthfulQA":46.4,
        "Ko-CommonGen V2":50.18,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-alpaca-1k",
        "Average":45.19,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":46.97,
        "Ko-MMLU":42.81,
        "Ko-TruthfulQA":48.75,
        "Ko-CommonGen V2":53.01,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-Yi-Ko-6B-v0.61-ff-e1",
        "Average":45.18,
        "Ko-ARC":40.78,
        "Ko-HellaSwag":53.33,
        "Ko-MMLU":43.72,
        "Ko-TruthfulQA":41.91,
        "Ko-CommonGen V2":46.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"ehartford\/dolphin-2.2.1-mistral-7b",
        "Average":45.18,
        "Ko-ARC":39.76,
        "Ko-HellaSwag":46.48,
        "Ko-MMLU":43.64,
        "Ko-TruthfulQA":51.37,
        "Ko-CommonGen V2":44.63,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kiyoonyoo\/ko-en-trans-platypus-13b-v3",
        "Average":45.13,
        "Ko-ARC":43.43,
        "Ko-HellaSwag":54.08,
        "Ko-MMLU":42.93,
        "Ko-TruthfulQA":44.57,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/Zephyr-7B-alpha-OP-u1k-ver0.1",
        "Average":45.11,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":49.23,
        "Ko-MMLU":42.95,
        "Ko-TruthfulQA":45.6,
        "Ko-CommonGen V2":46.04,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Kosy-platypus2-13B-v5",
        "Average":45.08,
        "Ko-ARC":43.09,
        "Ko-HellaSwag":53.61,
        "Ko-MMLU":41.06,
        "Ko-TruthfulQA":43.47,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/ko_ocgn_ep1",
        "Average":45.05,
        "Ko-ARC":45.56,
        "Ko-HellaSwag":48.17,
        "Ko-MMLU":45.26,
        "Ko-TruthfulQA":44.59,
        "Ko-CommonGen V2":41.68,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"teknium\/OpenHermes-2-Mistral-7B",
        "Average":45.05,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":48.08,
        "Ko-MMLU":44.04,
        "Ko-TruthfulQA":49.1,
        "Ko-CommonGen V2":46.64,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/ku-mistral-7b-PGO-v4",
        "Average":45.03,
        "Ko-ARC":44.28,
        "Ko-HellaSwag":51.45,
        "Ko-MMLU":42.17,
        "Ko-TruthfulQA":43.55,
        "Ko-CommonGen V2":43.68,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.1",
        "Average":45.03,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":47.43,
        "Ko-MMLU":42.5,
        "Ko-TruthfulQA":46.52,
        "Ko-CommonGen V2":47.82,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.2",
        "Average":45.03,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":47.43,
        "Ko-MMLU":42.5,
        "Ko-TruthfulQA":46.52,
        "Ko-CommonGen V2":47.82,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Open-Orca\/Mistral-7B-SlimOrca",
        "Average":45.02,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":48.05,
        "Ko-MMLU":43.27,
        "Ko-TruthfulQA":49.96,
        "Ko-CommonGen V2":45.69,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/hyun-mistral-7b-orca-platypus-refine",
        "Average":45.01,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":46.24,
        "Ko-MMLU":41.88,
        "Ko-TruthfulQA":47.58,
        "Ko-CommonGen V2":50.77,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"moondriller\/solar10B-eugeneparkthebestv3",
        "Average":45.0,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":50.01,
        "Ko-MMLU":39.26,
        "Ko-TruthfulQA":47.83,
        "Ko-CommonGen V2":48.41,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/mistral7b-lora-multi-turn-v3",
        "Average":45.0,
        "Ko-ARC":39.42,
        "Ko-HellaSwag":48.09,
        "Ko-MMLU":43.22,
        "Ko-TruthfulQA":47.29,
        "Ko-CommonGen V2":46.99,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/mistral-Ko-Orca-7B",
        "Average":45.0,
        "Ko-ARC":37.2,
        "Ko-HellaSwag":47.69,
        "Ko-MMLU":40.11,
        "Ko-TruthfulQA":43.44,
        "Ko-CommonGen V2":56.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-Instruct-v0.2",
        "Average":44.97,
        "Ko-ARC":41.81,
        "Ko-HellaSwag":49.35,
        "Ko-MMLU":43.99,
        "Ko-TruthfulQA":45.77,
        "Ko-CommonGen V2":43.92,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/aift-llama2-koen-instruct-dpo-v1.01",
        "Average":44.97,
        "Ko-ARC":46.25,
        "Ko-HellaSwag":57.69,
        "Ko-MMLU":42.62,
        "Ko-TruthfulQA":40.16,
        "Ko-CommonGen V2":38.13,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_Test_orca01",
        "Average":44.95,
        "Ko-ARC":43.26,
        "Ko-HellaSwag":50.5,
        "Ko-MMLU":43.51,
        "Ko-TruthfulQA":44.04,
        "Ko-CommonGen V2":43.45,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tmdduq\/komt-mistral-7b-v1-dpo-osy-v1",
        "Average":44.92,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":48.06,
        "Ko-MMLU":39.98,
        "Ko-TruthfulQA":52.12,
        "Ko-CommonGen V2":46.04,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Kosy-platypus2-13B-v4",
        "Average":44.92,
        "Ko-ARC":42.92,
        "Ko-HellaSwag":54.48,
        "Ko-MMLU":42.99,
        "Ko-TruthfulQA":43.0,
        "Ko-CommonGen V2":41.2,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.3",
        "Average":44.91,
        "Ko-ARC":38.48,
        "Ko-HellaSwag":46.96,
        "Ko-MMLU":41.4,
        "Ko-TruthfulQA":45.18,
        "Ko-CommonGen V2":52.54,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"gl2een\/llama2-13b-instruct-full-fintune",
        "Average":44.91,
        "Ko-ARC":42.24,
        "Ko-HellaSwag":54.03,
        "Ko-MMLU":39.47,
        "Ko-TruthfulQA":43.11,
        "Ko-CommonGen V2":45.69,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Loyola\/Mistral-7b-ITmodel",
        "Average":44.9,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.75,
        "Ko-MMLU":44.21,
        "Ko-TruthfulQA":47.34,
        "Ko-CommonGen V2":45.34,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/koOpenChat-sft",
        "Average":44.86,
        "Ko-ARC":44.88,
        "Ko-HellaSwag":49.03,
        "Ko-MMLU":46.43,
        "Ko-TruthfulQA":47.11,
        "Ko-CommonGen V2":36.84,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"HumanF-MarkrAI\/pub-llama-13b-v1",
        "Average":44.84,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":53.22,
        "Ko-MMLU":42.23,
        "Ko-TruthfulQA":43.64,
        "Ko-CommonGen V2":43.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PerRing\/Yi-Ko-6x2B-v1",
        "Average":44.8,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":51.01,
        "Ko-MMLU":40.32,
        "Ko-TruthfulQA":41.25,
        "Ko-CommonGen V2":51.83,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":8.95
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/agiin-13.6B-v0.1",
        "Average":44.76,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":44.39,
        "Ko-MMLU":43.27,
        "Ko-TruthfulQA":54.65,
        "Ko-CommonGen V2":41.91,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.78
    },
    {
        "T":"\u2b55",
        "Model":"sanghwa-na\/llama2-13b.kor.v1",
        "Average":44.76,
        "Ko-ARC":37.97,
        "Ko-HellaSwag":46.52,
        "Ko-MMLU":37.97,
        "Ko-TruthfulQA":44.9,
        "Ko-CommonGen V2":56.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.2.1",
        "Average":44.75,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":53.62,
        "Ko-MMLU":39.71,
        "Ko-TruthfulQA":41.71,
        "Ko-CommonGen V2":48.76,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/aift-llama2-koen-instruct-dpo-v1.02",
        "Average":44.73,
        "Ko-ARC":46.59,
        "Ko-HellaSwag":57.64,
        "Ko-MMLU":43.79,
        "Ko-TruthfulQA":39.17,
        "Ko-CommonGen V2":36.48,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"daekeun-ml\/Llama-2-ko-OpenOrca-gugugo-13B",
        "Average":44.72,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":52.44,
        "Ko-MMLU":40.97,
        "Ko-TruthfulQA":42.01,
        "Ko-CommonGen V2":48.52,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/llama2-13b-dpo-v2",
        "Average":44.71,
        "Ko-ARC":40.19,
        "Ko-HellaSwag":46.88,
        "Ko-MMLU":40.95,
        "Ko-TruthfulQA":54.32,
        "Ko-CommonGen V2":41.2,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"wons\/mistral-7B-test-v0.3",
        "Average":44.69,
        "Ko-ARC":37.88,
        "Ko-HellaSwag":46.32,
        "Ko-MMLU":43.72,
        "Ko-TruthfulQA":50.77,
        "Ko-CommonGen V2":44.75,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-7b-tech",
        "Average":44.65,
        "Ko-ARC":37.71,
        "Ko-HellaSwag":47.83,
        "Ko-MMLU":43.63,
        "Ko-TruthfulQA":43.09,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-OpenOrca-2000",
        "Average":44.64,
        "Ko-ARC":37.2,
        "Ko-HellaSwag":47.77,
        "Ko-MMLU":42.57,
        "Ko-TruthfulQA":48.44,
        "Ko-CommonGen V2":47.23,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/mistral_ko_all_inst",
        "Average":44.59,
        "Ko-ARC":36.86,
        "Ko-HellaSwag":47.99,
        "Ko-MMLU":43.61,
        "Ko-TruthfulQA":46.66,
        "Ko-CommonGen V2":47.82,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"sohohuk\/test1",
        "Average":44.57,
        "Ko-ARC":36.86,
        "Ko-HellaSwag":45.09,
        "Ko-MMLU":42.48,
        "Ko-TruthfulQA":50.03,
        "Ko-CommonGen V2":48.41,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.1.12",
        "Average":44.56,
        "Ko-ARC":45.31,
        "Ko-HellaSwag":53.8,
        "Ko-MMLU":31.25,
        "Ko-TruthfulQA":47.01,
        "Ko-CommonGen V2":45.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"oh-yeontaek\/llama-2-13B-LoRA-assemble",
        "Average":44.52,
        "Ko-ARC":40.53,
        "Ko-HellaSwag":46.89,
        "Ko-MMLU":41.91,
        "Ko-TruthfulQA":51.84,
        "Ko-CommonGen V2":41.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"NousResearch\/Yarn-Mistral-7b-64k",
        "Average":44.5,
        "Ko-ARC":35.92,
        "Ko-HellaSwag":45.62,
        "Ko-MMLU":42.89,
        "Ko-TruthfulQA":48.12,
        "Ko-CommonGen V2":49.94,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HumanF-MarkrAI\/mistralopithecus-v3-dpo-7b",
        "Average":44.49,
        "Ko-ARC":50.77,
        "Ko-HellaSwag":54.2,
        "Ko-MMLU":41.9,
        "Ko-TruthfulQA":41.7,
        "Ko-CommonGen V2":33.88,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/240104_mistral_lora",
        "Average":44.47,
        "Ko-ARC":36.26,
        "Ko-HellaSwag":45.86,
        "Ko-MMLU":42.95,
        "Ko-TruthfulQA":49.01,
        "Ko-CommonGen V2":48.29,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Ja3ck\/Mistral-instruct-Y24-v6",
        "Average":44.47,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":49.41,
        "Ko-MMLU":45.41,
        "Ko-TruthfulQA":42.78,
        "Ko-CommonGen V2":45.22,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"DooDooHyun\/AIFT-Yi-Ko-6B-ao-instruct-all-v0.54",
        "Average":44.46,
        "Ko-ARC":41.55,
        "Ko-HellaSwag":53.75,
        "Ko-MMLU":44.0,
        "Ko-TruthfulQA":43.7,
        "Ko-CommonGen V2":39.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-11B-Testbench-2",
        "Average":44.46,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":48.78,
        "Ko-MMLU":43.01,
        "Ko-TruthfulQA":43.43,
        "Ko-CommonGen V2":45.1,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":11.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-V0.1-7B-Instruct",
        "Average":44.44,
        "Ko-ARC":41.72,
        "Ko-HellaSwag":49.28,
        "Ko-MMLU":43.27,
        "Ko-TruthfulQA":43.75,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJ1hun\/Mistral-7B-OP-u1k-ver0.5",
        "Average":44.44,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":48.51,
        "Ko-MMLU":42.49,
        "Ko-TruthfulQA":46.62,
        "Ko-CommonGen V2":44.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/ko_ocgn_ep0-4",
        "Average":44.43,
        "Ko-ARC":43.6,
        "Ko-HellaSwag":45.56,
        "Ko-MMLU":44.38,
        "Ko-TruthfulQA":47.67,
        "Ko-CommonGen V2":40.97,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"openchat\/openchat_3.5",
        "Average":44.39,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":47.16,
        "Ko-MMLU":44.4,
        "Ko-TruthfulQA":47.93,
        "Ko-CommonGen V2":45.1,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"NousResearch\/Yarn-Mistral-7b-128k",
        "Average":44.36,
        "Ko-ARC":35.84,
        "Ko-HellaSwag":45.4,
        "Ko-MMLU":42.91,
        "Ko-TruthfulQA":48.19,
        "Ko-CommonGen V2":49.47,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"HwiyeolJo\/testttt",
        "Average":44.36,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.41,
        "Ko-MMLU":42.16,
        "Ko-TruthfulQA":46.56,
        "Ko-CommonGen V2":45.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"HwiyeolJo\/TeamJaeCorpo-v0.2",
        "Average":44.36,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.41,
        "Ko-MMLU":42.16,
        "Ko-TruthfulQA":46.56,
        "Ko-CommonGen V2":45.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HwiyeolJo\/TeamJaeCorpo",
        "Average":44.36,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.41,
        "Ko-MMLU":42.16,
        "Ko-TruthfulQA":46.56,
        "Ko-CommonGen V2":45.81,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HwiyeolJo\/testtt",
        "Average":44.36,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.41,
        "Ko-MMLU":42.16,
        "Ko-TruthfulQA":46.56,
        "Ko-CommonGen V2":45.81,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-12.8b_lora-dpo_v1",
        "Average":44.35,
        "Ko-ARC":39.76,
        "Ko-HellaSwag":47.46,
        "Ko-MMLU":38.77,
        "Ko-TruthfulQA":42.4,
        "Ko-CommonGen V2":53.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"jhflow\/komt-mistral7b-kor-orca-lora",
        "Average":44.32,
        "Ko-ARC":37.2,
        "Ko-HellaSwag":46.31,
        "Ko-MMLU":41.6,
        "Ko-TruthfulQA":45.12,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COKAL-13b-v3",
        "Average":44.32,
        "Ko-ARC":41.89,
        "Ko-HellaSwag":52.3,
        "Ko-MMLU":42.18,
        "Ko-TruthfulQA":42.58,
        "Ko-CommonGen V2":42.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"heavytail\/kullm-mistral",
        "Average":44.31,
        "Ko-ARC":59.81,
        "Ko-HellaSwag":32.4,
        "Ko-MMLU":28.69,
        "Ko-TruthfulQA":60.64,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"wkshin89\/mistral-7b-instruct-ko-test-v0.1",
        "Average":44.3,
        "Ko-ARC":38.82,
        "Ko-HellaSwag":48.89,
        "Ko-MMLU":43.1,
        "Ko-TruthfulQA":45.96,
        "Ko-CommonGen V2":44.75,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/Zero_COKE_K-13B",
        "Average":44.3,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":46.93,
        "Ko-MMLU":41.48,
        "Ko-TruthfulQA":49.81,
        "Ko-CommonGen V2":43.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"dasomysky\/unv_v0.1.0",
        "Average":44.27,
        "Ko-ARC":47.35,
        "Ko-HellaSwag":46.76,
        "Ko-MMLU":42.37,
        "Ko-TruthfulQA":45.66,
        "Ko-CommonGen V2":39.2,
        "Type":"RL-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.1",
        "Average":44.25,
        "Ko-ARC":46.93,
        "Ko-HellaSwag":54.19,
        "Ko-MMLU":30.69,
        "Ko-TruthfulQA":49.06,
        "Ko-CommonGen V2":40.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.0.3",
        "Average":44.23,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":49.07,
        "Ko-MMLU":41.56,
        "Ko-TruthfulQA":44.41,
        "Ko-CommonGen V2":46.16,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.7",
        "Average":44.2,
        "Ko-ARC":40.44,
        "Ko-HellaSwag":47.71,
        "Ko-MMLU":41.42,
        "Ko-TruthfulQA":44.7,
        "Ko-CommonGen V2":46.75,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-exo-mrc-v1",
        "Average":44.2,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":46.75,
        "Ko-MMLU":43.94,
        "Ko-TruthfulQA":44.88,
        "Ko-CommonGen V2":48.05,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":44.14,
        "Ko-ARC":36.86,
        "Ko-HellaSwag":47.12,
        "Ko-MMLU":44.05,
        "Ko-TruthfulQA":47.44,
        "Ko-CommonGen V2":45.22,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Ja3ck\/llama-2-13b-instruct-Y24-v2",
        "Average":44.11,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":46.41,
        "Ko-MMLU":38.57,
        "Ko-TruthfulQA":43.03,
        "Ko-CommonGen V2":55.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-13b-lima-sft-dpo",
        "Average":44.08,
        "Ko-ARC":43.26,
        "Ko-HellaSwag":51.08,
        "Ko-MMLU":42.57,
        "Ko-TruthfulQA":45.14,
        "Ko-CommonGen V2":38.37,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"dltjdgh0928\/lsh_finetune_v0.11",
        "Average":44.06,
        "Ko-ARC":37.03,
        "Ko-HellaSwag":44.71,
        "Ko-MMLU":38.87,
        "Ko-TruthfulQA":50.58,
        "Ko-CommonGen V2":49.11,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"wngkdud\/llama2_DPO_test_v1",
        "Average":44.06,
        "Ko-ARC":38.82,
        "Ko-HellaSwag":52.53,
        "Ko-MMLU":35.94,
        "Ko-TruthfulQA":48.12,
        "Ko-CommonGen V2":44.86,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-exo-wiki-quiz-v1",
        "Average":44.05,
        "Ko-ARC":36.26,
        "Ko-HellaSwag":46.02,
        "Ko-MMLU":43.97,
        "Ko-TruthfulQA":44.2,
        "Ko-CommonGen V2":49.82,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"freewheelin\/free-solar-instrunction-v0.2",
        "Average":44.02,
        "Ko-ARC":41.64,
        "Ko-HellaSwag":50.32,
        "Ko-MMLU":40.31,
        "Ko-TruthfulQA":47.8,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-13b-dpo-test",
        "Average":44.01,
        "Ko-ARC":39.51,
        "Ko-HellaSwag":46.93,
        "Ko-MMLU":39.58,
        "Ko-TruthfulQA":39.95,
        "Ko-CommonGen V2":54.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.7.3",
        "Average":44.0,
        "Ko-ARC":37.71,
        "Ko-HellaSwag":48.71,
        "Ko-MMLU":41.52,
        "Ko-TruthfulQA":42.13,
        "Ko-CommonGen V2":49.94,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jin05102518\/Astral-7B-1.0Epoch-Instruct-v0.06",
        "Average":43.99,
        "Ko-ARC":42.15,
        "Ko-HellaSwag":50.13,
        "Ko-MMLU":43.96,
        "Ko-TruthfulQA":44.61,
        "Ko-CommonGen V2":39.08,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-11B-Omni-OP-u1k-ver0.5",
        "Average":43.98,
        "Ko-ARC":39.85,
        "Ko-HellaSwag":47.85,
        "Ko-MMLU":42.75,
        "Ko-TruthfulQA":47.05,
        "Ko-CommonGen V2":42.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":11.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.6",
        "Average":43.93,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":47.35,
        "Ko-MMLU":40.34,
        "Ko-TruthfulQA":47.03,
        "Ko-CommonGen V2":47.58,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/zephyr-7b-beta-KOR-OpenOrca-Platypus-1e-5",
        "Average":43.91,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":47.17,
        "Ko-MMLU":42.06,
        "Ko-TruthfulQA":48.45,
        "Ko-CommonGen V2":44.51,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.7.2",
        "Average":43.84,
        "Ko-ARC":41.47,
        "Ko-HellaSwag":51.04,
        "Ko-MMLU":44.47,
        "Ko-TruthfulQA":42.65,
        "Ko-CommonGen V2":39.55,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"yeheun\/llama-2-koen-13b-v1.3",
        "Average":43.83,
        "Ko-ARC":42.41,
        "Ko-HellaSwag":52.94,
        "Ko-MMLU":38.92,
        "Ko-TruthfulQA":38.13,
        "Ko-CommonGen V2":46.75,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-11B-Testbench",
        "Average":43.81,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":47.42,
        "Ko-MMLU":42.05,
        "Ko-TruthfulQA":44.75,
        "Ko-CommonGen V2":46.28,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PerRing\/Yi-Ko-6x2B-v0.0",
        "Average":43.8,
        "Ko-ARC":32.85,
        "Ko-HellaSwag":36.61,
        "Ko-MMLU":44.32,
        "Ko-TruthfulQA":50.9,
        "Ko-CommonGen V2":54.31,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":8.95
    },
    {
        "T":"\u2b55",
        "Model":"wngkdud\/llama2_koen_13b_SFTtrain",
        "Average":43.76,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":50.3,
        "Ko-MMLU":38.66,
        "Ko-TruthfulQA":45.3,
        "Ko-CommonGen V2":45.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"AIdenU\/LLAMA-2-13b-koen-Y24_v1.0",
        "Average":43.73,
        "Ko-ARC":36.6,
        "Ko-HellaSwag":45.96,
        "Ko-MMLU":38.63,
        "Ko-TruthfulQA":43.49,
        "Ko-CommonGen V2":53.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"Kaeri-Jenti\/llama-2-koen-13b-with-ko-wiki",
        "Average":43.73,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":49.84,
        "Ko-MMLU":38.85,
        "Ko-TruthfulQA":38.07,
        "Ko-CommonGen V2":47.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-7b-ko-v1",
        "Average":43.7,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":45.53,
        "Ko-MMLU":41.19,
        "Ko-TruthfulQA":46.83,
        "Ko-CommonGen V2":51.0,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"maywell\/PiVoT-10.7B-Mistral-v0.2",
        "Average":43.7,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":47.44,
        "Ko-MMLU":38.74,
        "Ko-TruthfulQA":48.33,
        "Ko-CommonGen V2":41.68,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.002",
        "Average":43.69,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":44.55,
        "Ko-MMLU":39.62,
        "Ko-TruthfulQA":48.64,
        "Ko-CommonGen V2":46.75,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"wons\/mistral-7B-test-v0.2",
        "Average":43.65,
        "Ko-ARC":37.03,
        "Ko-HellaSwag":46.45,
        "Ko-MMLU":43.68,
        "Ko-TruthfulQA":47.77,
        "Ko-CommonGen V2":43.33,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Kosy-Platypus2-13B",
        "Average":43.64,
        "Ko-ARC":43.94,
        "Ko-HellaSwag":53.88,
        "Ko-MMLU":42.68,
        "Ko-TruthfulQA":43.46,
        "Ko-CommonGen V2":34.24,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Mistral-koplatypus-v1",
        "Average":43.61,
        "Ko-ARC":37.71,
        "Ko-HellaSwag":47.79,
        "Ko-MMLU":44.41,
        "Ko-TruthfulQA":45.97,
        "Ko-CommonGen V2":42.15,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-v0.2",
        "Average":43.6,
        "Ko-ARC":38.74,
        "Ko-HellaSwag":50.74,
        "Ko-MMLU":38.98,
        "Ko-TruthfulQA":44.7,
        "Ko-CommonGen V2":44.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\u2b55",
        "Model":"lcw99\/zephykor-ko-beta-7b-chang",
        "Average":43.6,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":47.67,
        "Ko-MMLU":38.5,
        "Ko-TruthfulQA":48.86,
        "Ko-CommonGen V2":45.34,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.55
    },
    {
        "T":"\u2b55",
        "Model":"Korabbit\/llama-2-ko-7b-bilingual",
        "Average":43.57,
        "Ko-ARC":40.02,
        "Ko-HellaSwag":51.94,
        "Ko-MMLU":33.47,
        "Ko-TruthfulQA":41.27,
        "Ko-CommonGen V2":51.12,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.5.0",
        "Average":43.56,
        "Ko-ARC":37.46,
        "Ko-HellaSwag":50.11,
        "Ko-MMLU":44.6,
        "Ko-TruthfulQA":43.13,
        "Ko-CommonGen V2":42.5,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-mistral-7b-v1",
        "Average":43.56,
        "Ko-ARC":36.6,
        "Ko-HellaSwag":46.02,
        "Ko-MMLU":39.82,
        "Ko-TruthfulQA":47.07,
        "Ko-CommonGen V2":48.29,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.004",
        "Average":43.55,
        "Ko-ARC":38.48,
        "Ko-HellaSwag":45.48,
        "Ko-MMLU":37.88,
        "Ko-TruthfulQA":47.5,
        "Ko-CommonGen V2":48.41,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-OpenOrca-wiki-v1",
        "Average":43.55,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":47.52,
        "Ko-MMLU":40.77,
        "Ko-TruthfulQA":43.99,
        "Ko-CommonGen V2":49.11,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"AIdenU\/LLAMA-2-13b-ko-Y24_v2.0",
        "Average":43.43,
        "Ko-ARC":37.88,
        "Ko-HellaSwag":46.11,
        "Ko-MMLU":37.4,
        "Ko-TruthfulQA":42.53,
        "Ko-CommonGen V2":53.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIdenU\/LLAMA-2-13b-ko-Y24-DPO_v0.1",
        "Average":43.32,
        "Ko-ARC":37.8,
        "Ko-HellaSwag":46.88,
        "Ko-MMLU":39.87,
        "Ko-TruthfulQA":41.54,
        "Ko-CommonGen V2":50.53,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.9",
        "Average":43.28,
        "Ko-ARC":34.64,
        "Ko-HellaSwag":45.1,
        "Ko-MMLU":39.74,
        "Ko-TruthfulQA":45.19,
        "Ko-CommonGen V2":51.71,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kimwooglae\/AISquare-Instruct-SOLAR-10.7b-v0.5.31",
        "Average":43.23,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":48.16,
        "Ko-MMLU":39.57,
        "Ko-TruthfulQA":43.8,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"c1park\/20240105_mistral-step50",
        "Average":43.23,
        "Ko-ARC":36.26,
        "Ko-HellaSwag":45.96,
        "Ko-MMLU":43.54,
        "Ko-TruthfulQA":49.9,
        "Ko-CommonGen V2":40.5,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/Mistral-7B-Ko-v2",
        "Average":43.21,
        "Ko-ARC":36.69,
        "Ko-HellaSwag":46.89,
        "Ko-MMLU":40.16,
        "Ko-TruthfulQA":42.96,
        "Ko-CommonGen V2":49.35,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.5",
        "Average":43.2,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":46.91,
        "Ko-MMLU":39.42,
        "Ko-TruthfulQA":44.72,
        "Ko-CommonGen V2":46.4,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIdenU\/LLAMA-2-13b-ko-Y24-DPO_v2.1",
        "Average":43.2,
        "Ko-ARC":37.88,
        "Ko-HellaSwag":46.45,
        "Ko-MMLU":36.92,
        "Ko-TruthfulQA":41.96,
        "Ko-CommonGen V2":52.77,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":43.12,
        "Ko-ARC":38.48,
        "Ko-HellaSwag":44.91,
        "Ko-MMLU":40.34,
        "Ko-TruthfulQA":51.72,
        "Ko-CommonGen V2":40.14,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra_TbST11B_EP01",
        "Average":43.11,
        "Ko-ARC":40.78,
        "Ko-HellaSwag":47.22,
        "Ko-MMLU":42.9,
        "Ko-TruthfulQA":44.85,
        "Ko-CommonGen V2":39.79,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"DopeorNope\/Ko-Mixtral-MoE-7Bx2",
        "Average":43.03,
        "Ko-ARC":37.03,
        "Ko-HellaSwag":45.91,
        "Ko-MMLU":39.6,
        "Ko-TruthfulQA":47.97,
        "Ko-CommonGen V2":44.63,
        "Type":"pretrained",
        "Precision":"MixtralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.88
    },
    {
        "T":"\u2b55",
        "Model":"jin05102518\/Astral-7B-1.0Epoch-Instruct-v0.05",
        "Average":42.98,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":45.7,
        "Ko-MMLU":42.62,
        "Ko-TruthfulQA":47.46,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra_TbST02M_IN01",
        "Average":42.97,
        "Ko-ARC":38.31,
        "Ko-HellaSwag":44.51,
        "Ko-MMLU":43.33,
        "Ko-TruthfulQA":50.59,
        "Ko-CommonGen V2":38.13,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Ja3ck\/llama-2-13b-DPO-Y24-v2",
        "Average":42.95,
        "Ko-ARC":38.23,
        "Ko-HellaSwag":46.47,
        "Ko-MMLU":38.55,
        "Ko-TruthfulQA":41.09,
        "Ko-CommonGen V2":50.41,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.8",
        "Average":42.91,
        "Ko-ARC":36.26,
        "Ko-HellaSwag":45.64,
        "Ko-MMLU":39.52,
        "Ko-TruthfulQA":47.44,
        "Ko-CommonGen V2":45.69,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Ja3ck\/llama-2-13b-instruct-Y24-v1",
        "Average":42.89,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":46.42,
        "Ko-MMLU":38.61,
        "Ko-TruthfulQA":40.89,
        "Ko-CommonGen V2":50.41,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"Jenti-Kaeri\/ko-llama2-13b-platypus",
        "Average":42.89,
        "Ko-ARC":37.8,
        "Ko-HellaSwag":45.54,
        "Ko-MMLU":37.33,
        "Ko-TruthfulQA":46.21,
        "Ko-CommonGen V2":47.58,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"maum-ai\/llamaum-13b-chat-qlora-s",
        "Average":42.8,
        "Ko-ARC":39.42,
        "Ko-HellaSwag":46.22,
        "Ko-MMLU":41.32,
        "Ko-TruthfulQA":41.47,
        "Ko-CommonGen V2":45.57,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v4.1.2",
        "Average":42.77,
        "Ko-ARC":44.45,
        "Ko-HellaSwag":54.13,
        "Ko-MMLU":28.34,
        "Ko-TruthfulQA":44.91,
        "Ko-CommonGen V2":42.03,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"knlp\/KS-SOLAR-10.7B-v0.1",
        "Average":42.72,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":47.4,
        "Ko-MMLU":44.07,
        "Ko-TruthfulQA":43.67,
        "Ko-CommonGen V2":40.85,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-3data-merged",
        "Average":42.72,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":47.48,
        "Ko-MMLU":38.32,
        "Ko-TruthfulQA":45.99,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Average":42.68,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":46.61,
        "Ko-MMLU":39.95,
        "Ko-TruthfulQA":41.4,
        "Ko-CommonGen V2":47.82,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.001",
        "Average":42.68,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":44.88,
        "Ko-MMLU":39.37,
        "Ko-TruthfulQA":45.47,
        "Ko-CommonGen V2":46.04,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PerRing\/Yi-Ko-6x2B-v0.2",
        "Average":42.67,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":48.66,
        "Ko-MMLU":37.04,
        "Ko-TruthfulQA":44.05,
        "Ko-CommonGen V2":43.92,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":8.95
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.006",
        "Average":42.67,
        "Ko-ARC":38.91,
        "Ko-HellaSwag":46.51,
        "Ko-MMLU":38.6,
        "Ko-TruthfulQA":43.38,
        "Ko-CommonGen V2":45.93,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"genne\/eclectus1.1",
        "Average":42.64,
        "Ko-ARC":39.25,
        "Ko-HellaSwag":54.64,
        "Ko-MMLU":44.29,
        "Ko-TruthfulQA":41.5,
        "Ko-CommonGen V2":33.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"hyunseoki\/ko-ref-llama2-13b",
        "Average":42.49,
        "Ko-ARC":43.6,
        "Ko-HellaSwag":52.58,
        "Ko-MMLU":30.41,
        "Ko-TruthfulQA":40.89,
        "Ko-CommonGen V2":44.98,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v7",
        "Average":42.48,
        "Ko-ARC":45.31,
        "Ko-HellaSwag":54.89,
        "Ko-MMLU":30.96,
        "Ko-TruthfulQA":43.72,
        "Ko-CommonGen V2":37.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"HanaGroup\/Mini_orca_test02",
        "Average":42.46,
        "Ko-ARC":42.24,
        "Ko-HellaSwag":45.82,
        "Ko-MMLU":41.57,
        "Ko-TruthfulQA":44.1,
        "Ko-CommonGen V2":38.61,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"metterian\/llama-pro-ko-8b",
        "Average":42.46,
        "Ko-ARC":40.19,
        "Ko-HellaSwag":51.25,
        "Ko-MMLU":36.8,
        "Ko-TruthfulQA":40.24,
        "Ko-CommonGen V2":43.8,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":8.55
    },
    {
        "T":"\u2b55",
        "Model":"ifuseok\/yi-ko-playtus-instruct-v0.1",
        "Average":42.33,
        "Ko-ARC":37.03,
        "Ko-HellaSwag":47.81,
        "Ko-MMLU":38.45,
        "Ko-TruthfulQA":43.99,
        "Ko-CommonGen V2":44.39,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihunKim\/MIstral-7B-SlimOrca-OP-2k",
        "Average":42.33,
        "Ko-ARC":35.24,
        "Ko-HellaSwag":45.65,
        "Ko-MMLU":40.77,
        "Ko-TruthfulQA":46.32,
        "Ko-CommonGen V2":43.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"cepiloth\/ko-en-llama2-13b-finetune-ex",
        "Average":42.31,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":51.19,
        "Ko-MMLU":33.77,
        "Ko-TruthfulQA":48.33,
        "Ko-CommonGen V2":37.9,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PerRing\/Yi-Ko-6x2B-v0.3",
        "Average":42.31,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":49.06,
        "Ko-MMLU":36.34,
        "Ko-TruthfulQA":41.58,
        "Ko-CommonGen V2":46.16,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":8.95
    },
    {
        "T":"\u2b55",
        "Model":"Korabbit\/my_model",
        "Average":42.29,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":51.2,
        "Ko-MMLU":33.65,
        "Ko-TruthfulQA":39.62,
        "Ko-CommonGen V2":49.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.6n_13b",
        "Average":42.28,
        "Ko-ARC":41.89,
        "Ko-HellaSwag":52.71,
        "Ko-MMLU":38.74,
        "Ko-TruthfulQA":40.5,
        "Ko-CommonGen V2":37.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v4",
        "Average":42.22,
        "Ko-ARC":37.97,
        "Ko-HellaSwag":48.71,
        "Ko-MMLU":42.88,
        "Ko-TruthfulQA":45.54,
        "Ko-CommonGen V2":36.01,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"garage-bAInd\/Platypus2-13B",
        "Average":42.18,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":46.88,
        "Ko-MMLU":41.24,
        "Ko-TruthfulQA":44.25,
        "Ko-CommonGen V2":40.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.1.0",
        "Average":42.17,
        "Ko-ARC":42.32,
        "Ko-HellaSwag":47.61,
        "Ko-MMLU":40.68,
        "Ko-TruthfulQA":45.54,
        "Ko-CommonGen V2":34.71,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"We-Want-GPU\/Yi-Ko-SFT-FULL",
        "Average":42.11,
        "Ko-ARC":36.6,
        "Ko-HellaSwag":49.13,
        "Ko-MMLU":40.79,
        "Ko-TruthfulQA":42.91,
        "Ko-CommonGen V2":41.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/k2s3_test_24001",
        "Average":42.08,
        "Ko-ARC":37.12,
        "Ko-HellaSwag":46.6,
        "Ko-MMLU":39.45,
        "Ko-TruthfulQA":44.13,
        "Ko-CommonGen V2":43.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.10",
        "Average":42.07,
        "Ko-ARC":35.41,
        "Ko-HellaSwag":45.14,
        "Ko-MMLU":40.58,
        "Ko-TruthfulQA":42.59,
        "Ko-CommonGen V2":46.64,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Taekyoon\/llama2-org-koen-7b",
        "Average":42.06,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":53.7,
        "Ko-MMLU":30.85,
        "Ko-TruthfulQA":42.37,
        "Ko-CommonGen V2":44.39,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-orca-1k-platy-1k",
        "Average":42.02,
        "Ko-ARC":36.6,
        "Ko-HellaSwag":45.95,
        "Ko-MMLU":40.08,
        "Ko-TruthfulQA":47.7,
        "Ko-CommonGen V2":39.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"melonpower39\/unv_v0.1.5",
        "Average":42.02,
        "Ko-ARC":45.99,
        "Ko-HellaSwag":48.9,
        "Ko-MMLU":34.28,
        "Ko-TruthfulQA":39.73,
        "Ko-CommonGen V2":41.2,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v3",
        "Average":42.01,
        "Ko-ARC":41.3,
        "Ko-HellaSwag":48.96,
        "Ko-MMLU":38.49,
        "Ko-TruthfulQA":46.25,
        "Ko-CommonGen V2":35.06,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jin05102518\/Astral-7B-Instruct-v0.01",
        "Average":42.01,
        "Ko-ARC":38.31,
        "Ko-HellaSwag":47.95,
        "Ko-MMLU":39.95,
        "Ko-TruthfulQA":43.23,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"genne\/eclectus_7b_1.1",
        "Average":41.96,
        "Ko-ARC":44.2,
        "Ko-HellaSwag":53.76,
        "Ko-MMLU":37.92,
        "Ko-TruthfulQA":40.28,
        "Ko-CommonGen V2":33.65,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MNC-Jihun\/Mistral-7B-OP-u1k-ver0.6",
        "Average":41.96,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":44.76,
        "Ko-MMLU":41.76,
        "Ko-TruthfulQA":46.87,
        "Ko-CommonGen V2":38.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"lcw99\/zephykor-ko-7b-chang",
        "Average":41.88,
        "Ko-ARC":37.29,
        "Ko-HellaSwag":48.38,
        "Ko-MMLU":37.0,
        "Ko-TruthfulQA":49.08,
        "Ko-CommonGen V2":37.66,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.37
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-7B_01",
        "Average":41.87,
        "Ko-ARC":41.04,
        "Ko-HellaSwag":50.22,
        "Ko-MMLU":37.47,
        "Ko-TruthfulQA":38.71,
        "Ko-CommonGen V2":41.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"cepiloth\/ko-llama2-13b-finetune-ex",
        "Average":41.84,
        "Ko-ARC":36.95,
        "Ko-HellaSwag":45.49,
        "Ko-MMLU":37.51,
        "Ko-TruthfulQA":46.39,
        "Ko-CommonGen V2":42.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"jjourney1125\/llama2-dev",
        "Average":41.83,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":44.35,
        "Ko-MMLU":40.37,
        "Ko-TruthfulQA":44.48,
        "Ko-CommonGen V2":41.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"HY-KDPARK\/llama-2-koen-13b-sft-v0.1",
        "Average":41.8,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":47.45,
        "Ko-MMLU":37.36,
        "Ko-TruthfulQA":47.36,
        "Ko-CommonGen V2":40.5,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/kullama2-7b-platypus-kogpt4",
        "Average":41.79,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":53.2,
        "Ko-MMLU":29.51,
        "Ko-TruthfulQA":40.27,
        "Ko-CommonGen V2":46.4,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/PACK-13b-v1.0",
        "Average":41.78,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":47.89,
        "Ko-MMLU":39.42,
        "Ko-TruthfulQA":42.75,
        "Ko-CommonGen V2":41.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Unbabel\/TowerInstruct-7B-v0.1",
        "Average":41.78,
        "Ko-ARC":37.97,
        "Ko-HellaSwag":50.39,
        "Ko-MMLU":36.18,
        "Ko-TruthfulQA":46.1,
        "Ko-CommonGen V2":38.25,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-orca-platy-1k-ko-f-1871",
        "Average":41.71,
        "Ko-ARC":37.8,
        "Ko-HellaSwag":47.91,
        "Ko-MMLU":32.15,
        "Ko-TruthfulQA":45.74,
        "Ko-CommonGen V2":44.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/synatra_V0.01",
        "Average":41.68,
        "Ko-ARC":34.13,
        "Ko-HellaSwag":41.59,
        "Ko-MMLU":39.56,
        "Ko-TruthfulQA":49.92,
        "Ko-CommonGen V2":43.21,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v5",
        "Average":41.62,
        "Ko-ARC":34.81,
        "Ko-HellaSwag":44.48,
        "Ko-MMLU":40.61,
        "Ko-TruthfulQA":42.38,
        "Ko-CommonGen V2":45.81,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"cepiloth\/ko-llama2-13b-finetune",
        "Average":41.59,
        "Ko-ARC":38.31,
        "Ko-HellaSwag":45.36,
        "Ko-MMLU":37.47,
        "Ko-TruthfulQA":46.65,
        "Ko-CommonGen V2":40.14,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/ku-mistral-7b-PGO-v3",
        "Average":41.54,
        "Ko-ARC":40.87,
        "Ko-HellaSwag":47.77,
        "Ko-MMLU":38.87,
        "Ko-TruthfulQA":41.57,
        "Ko-CommonGen V2":38.61,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"colable\/llama-ko-peft",
        "Average":41.53,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":49.17,
        "Ko-MMLU":36.19,
        "Ko-TruthfulQA":40.06,
        "Ko-CommonGen V2":42.62,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/SOLAR_C-v1-10.7B",
        "Average":41.52,
        "Ko-ARC":47.53,
        "Ko-HellaSwag":34.48,
        "Ko-MMLU":45.97,
        "Ko-TruthfulQA":48.83,
        "Ko-CommonGen V2":30.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-orca-2k",
        "Average":41.51,
        "Ko-ARC":35.58,
        "Ko-HellaSwag":46.16,
        "Ko-MMLU":39.32,
        "Ko-TruthfulQA":49.06,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"genne\/electus_yiko_dpo",
        "Average":41.46,
        "Ko-ARC":39.25,
        "Ko-HellaSwag":51.9,
        "Ko-MMLU":36.38,
        "Ko-TruthfulQA":43.52,
        "Ko-CommonGen V2":36.25,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.18
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/kullama2-7b-ko-PGO",
        "Average":41.42,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":52.76,
        "Ko-MMLU":30.15,
        "Ko-TruthfulQA":40.68,
        "Ko-CommonGen V2":44.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/COKA-DPO-test-v1",
        "Average":41.42,
        "Ko-ARC":46.5,
        "Ko-HellaSwag":54.89,
        "Ko-MMLU":27.92,
        "Ko-TruthfulQA":38.22,
        "Ko-CommonGen V2":39.55,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCKim\/Mistral-7B-SlimOrca-OP-U2048-top4k",
        "Average":41.38,
        "Ko-ARC":34.81,
        "Ko-HellaSwag":43.12,
        "Ko-MMLU":40.74,
        "Ko-TruthfulQA":47.64,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/PACK-13b-v1.1",
        "Average":41.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":48.08,
        "Ko-MMLU":38.93,
        "Ko-TruthfulQA":42.2,
        "Ko-CommonGen V2":39.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"hyeogi\/open-llama2-7b-dpo-v0.1",
        "Average":41.33,
        "Ko-ARC":38.57,
        "Ko-HellaSwag":49.29,
        "Ko-MMLU":27.29,
        "Ko-TruthfulQA":51.48,
        "Ko-CommonGen V2":40.02,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"qutrino\/7b-finetune",
        "Average":41.21,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":48.76,
        "Ko-MMLU":34.7,
        "Ko-TruthfulQA":41.6,
        "Ko-CommonGen V2":41.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"The-matt\/llama2_ko-7b_sandy-fire-170_1530",
        "Average":41.13,
        "Ko-ARC":37.29,
        "Ko-HellaSwag":48.99,
        "Ko-MMLU":28.37,
        "Ko-TruthfulQA":39.66,
        "Ko-CommonGen V2":51.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-ko-13b-instruct-v1.1",
        "Average":41.09,
        "Ko-ARC":39.76,
        "Ko-HellaSwag":46.57,
        "Ko-MMLU":37.47,
        "Ko-TruthfulQA":41.96,
        "Ko-CommonGen V2":39.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"dltjdgh0928\/mistral_open_orca_ko",
        "Average":41.08,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":41.09,
        "Ko-MMLU":39.19,
        "Ko-TruthfulQA":50.83,
        "Ko-CommonGen V2":40.85,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCKim\/Mistral-7B-SlimOrca-OP-U2048-top2k",
        "Average":41.05,
        "Ko-ARC":35.58,
        "Ko-HellaSwag":43.41,
        "Ko-MMLU":41.14,
        "Ko-TruthfulQA":48.66,
        "Ko-CommonGen V2":36.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"refarde\/Mistral-7B-Instruct-v0.2-Ko-S-Core",
        "Average":41.01,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":42.45,
        "Ko-MMLU":39.95,
        "Ko-TruthfulQA":47.86,
        "Ko-CommonGen V2":40.38,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-SlimOrca-orca-platy-1k",
        "Average":40.96,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":45.56,
        "Ko-MMLU":37.3,
        "Ko-TruthfulQA":46.64,
        "Ko-CommonGen V2":41.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"lmsys\/vicuna-13b-v1.5",
        "Average":40.95,
        "Ko-ARC":36.18,
        "Ko-HellaSwag":45.18,
        "Ko-MMLU":39.9,
        "Ko-TruthfulQA":47.82,
        "Ko-CommonGen V2":35.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/mistral-7b-it-v1.2.0",
        "Average":40.88,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":46.71,
        "Ko-MMLU":40.89,
        "Ko-TruthfulQA":45.71,
        "Ko-CommonGen V2":32.94,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihunKim\/Mistral-7B-SlimOrca-OP-8k",
        "Average":40.76,
        "Ko-ARC":34.22,
        "Ko-HellaSwag":45.19,
        "Ko-MMLU":37.21,
        "Ko-TruthfulQA":46.07,
        "Ko-CommonGen V2":41.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"GAI-LLM\/KoSOLAR-10.7B-dpo-v1",
        "Average":40.76,
        "Ko-ARC":36.95,
        "Ko-HellaSwag":37.98,
        "Ko-MMLU":47.88,
        "Ko-TruthfulQA":51.58,
        "Ko-CommonGen V2":29.4,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-v1.0",
        "Average":40.75,
        "Ko-ARC":49.06,
        "Ko-HellaSwag":25.66,
        "Ko-MMLU":53.63,
        "Ko-TruthfulQA":45.76,
        "Ko-CommonGen V2":29.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-7B-v0.3-Translation",
        "Average":40.72,
        "Ko-ARC":39.33,
        "Ko-HellaSwag":45.5,
        "Ko-MMLU":40.65,
        "Ko-TruthfulQA":38.46,
        "Ko-CommonGen V2":39.67,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"vihangd\/smartyplats-7b-v1",
        "Average":40.72,
        "Ko-ARC":30.63,
        "Ko-HellaSwag":38.76,
        "Ko-MMLU":41.66,
        "Ko-TruthfulQA":45.44,
        "Ko-CommonGen V2":47.11,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"lcw99\/llama2-ko-chang-instruct-chat",
        "Average":40.59,
        "Ko-ARC":39.42,
        "Ko-HellaSwag":52.49,
        "Ko-MMLU":28.68,
        "Ko-TruthfulQA":42.12,
        "Ko-CommonGen V2":40.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"LI-ST\/Mistral-7B-ko-v0.4",
        "Average":40.55,
        "Ko-ARC":37.03,
        "Ko-HellaSwag":44.47,
        "Ko-MMLU":38.35,
        "Ko-TruthfulQA":42.27,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"colable\/llama-ko-peft-v0.5",
        "Average":40.55,
        "Ko-ARC":41.38,
        "Ko-HellaSwag":49.14,
        "Ko-MMLU":34.15,
        "Ko-TruthfulQA":40.51,
        "Ko-CommonGen V2":37.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/ko-ref-llama2-7b-Inst",
        "Average":40.51,
        "Ko-ARC":38.31,
        "Ko-HellaSwag":48.29,
        "Ko-MMLU":26.97,
        "Ko-TruthfulQA":39.4,
        "Ko-CommonGen V2":49.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCKim\/Mistral-7B-SlimOrca-OP-U2048-ran2k",
        "Average":40.49,
        "Ko-ARC":34.04,
        "Ko-HellaSwag":45.18,
        "Ko-MMLU":35.66,
        "Ko-TruthfulQA":45.68,
        "Ko-CommonGen V2":41.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"milkyyy\/llama-2-ko-kullm",
        "Average":40.49,
        "Ko-ARC":38.23,
        "Ko-HellaSwag":50.69,
        "Ko-MMLU":28.24,
        "Ko-TruthfulQA":39.39,
        "Ko-CommonGen V2":45.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-orca-platy-2k",
        "Average":40.47,
        "Ko-ARC":33.36,
        "Ko-HellaSwag":46.09,
        "Ko-MMLU":37.3,
        "Ko-TruthfulQA":45.94,
        "Ko-CommonGen V2":39.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"The-matt\/llama2_ko-7b_stilted-lion-205_1530",
        "Average":40.42,
        "Ko-ARC":36.95,
        "Ko-HellaSwag":49.87,
        "Ko-MMLU":29.84,
        "Ko-TruthfulQA":39.06,
        "Ko-CommonGen V2":46.4,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-v0.1-orca_platy-1k-ep4",
        "Average":40.37,
        "Ko-ARC":35.84,
        "Ko-HellaSwag":46.27,
        "Ko-MMLU":37.57,
        "Ko-TruthfulQA":45.95,
        "Ko-CommonGen V2":36.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"hyeogi\/open-llama2-7b-v0.1",
        "Average":40.31,
        "Ko-ARC":39.68,
        "Ko-HellaSwag":50.03,
        "Ko-MMLU":27.61,
        "Ko-TruthfulQA":40.46,
        "Ko-CommonGen V2":43.8,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"sanghwa-na\/mistrallite.kor",
        "Average":40.31,
        "Ko-ARC":34.04,
        "Ko-HellaSwag":41.34,
        "Ko-MMLU":37.24,
        "Ko-TruthfulQA":45.95,
        "Ko-CommonGen V2":42.98,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"krevas\/LDCC-Instruct-Llama-2-ko-13B-v7.3",
        "Average":40.26,
        "Ko-ARC":36.18,
        "Ko-HellaSwag":50.25,
        "Ko-MMLU":30.81,
        "Ko-TruthfulQA":38.39,
        "Ko-CommonGen V2":45.69,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"Chang-Su\/llama-2-13b-chat-ko",
        "Average":40.06,
        "Ko-ARC":34.64,
        "Ko-HellaSwag":45.43,
        "Ko-MMLU":37.45,
        "Ko-TruthfulQA":42.15,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"colable\/llama-ko-peft-v0.6",
        "Average":40.04,
        "Ko-ARC":39.93,
        "Ko-HellaSwag":48.9,
        "Ko-MMLU":32.36,
        "Ko-TruthfulQA":40.97,
        "Ko-CommonGen V2":38.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"DopeorNope\/Ko-Mixtral-v1.3-MoE-7Bx2",
        "Average":40.02,
        "Ko-ARC":31.4,
        "Ko-HellaSwag":37.57,
        "Ko-MMLU":36.61,
        "Ko-TruthfulQA":47.19,
        "Ko-CommonGen V2":47.34,
        "Type":"pretrained",
        "Precision":"MixtralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.88
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PerRing\/Yi-Ko-6x2B-v0.1",
        "Average":40.01,
        "Ko-ARC":37.46,
        "Ko-HellaSwag":48.8,
        "Ko-MMLU":35.58,
        "Ko-TruthfulQA":41.64,
        "Ko-CommonGen V2":36.6,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":8.95
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/seal3.1.6n_7b",
        "Average":39.98,
        "Ko-ARC":40.36,
        "Ko-HellaSwag":52.74,
        "Ko-MMLU":28.15,
        "Ko-TruthfulQA":38.86,
        "Ko-CommonGen V2":39.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.1",
        "Average":39.97,
        "Ko-ARC":35.58,
        "Ko-HellaSwag":42.74,
        "Ko-MMLU":36.87,
        "Ko-TruthfulQA":43.79,
        "Ko-CommonGen V2":40.85,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.37
    },
    {
        "T":"\u2b55",
        "Model":"hyunjae\/polyglot-ko-3.8b-total",
        "Average":39.93,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":47.79,
        "Ko-MMLU":31.45,
        "Ko-TruthfulQA":41.87,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":3.8
    },
    {
        "T":"\u2b55",
        "Model":"MRAIRR\/Navistral",
        "Average":39.88,
        "Ko-ARC":31.14,
        "Ko-HellaSwag":38.22,
        "Ko-MMLU":40.34,
        "Ko-TruthfulQA":45.4,
        "Ko-CommonGen V2":44.27,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/llama-2-ko-7b-emb-dev",
        "Average":39.87,
        "Ko-ARC":41.98,
        "Ko-HellaSwag":49.74,
        "Ko-MMLU":27.83,
        "Ko-TruthfulQA":42.75,
        "Ko-CommonGen V2":37.07,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexM-7B-Instruct-v0.1",
        "Average":39.81,
        "Ko-ARC":34.13,
        "Ko-HellaSwag":42.35,
        "Ko-MMLU":38.73,
        "Ko-TruthfulQA":45.46,
        "Ko-CommonGen V2":38.37,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/open-llama-2-ko-7b",
        "Average":39.74,
        "Ko-ARC":40.02,
        "Ko-HellaSwag":50.27,
        "Ko-MMLU":27.6,
        "Ko-TruthfulQA":38.67,
        "Ko-CommonGen V2":42.15,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"yuntaeyang\/Orca-2-7b-lora-kor",
        "Average":39.7,
        "Ko-ARC":34.47,
        "Ko-HellaSwag":40.54,
        "Ko-MMLU":38.84,
        "Ko-TruthfulQA":44.98,
        "Ko-CommonGen V2":39.67,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Unbabel\/TowerBase-7B-v0.1",
        "Average":39.68,
        "Ko-ARC":36.09,
        "Ko-HellaSwag":49.4,
        "Ko-MMLU":34.8,
        "Ko-TruthfulQA":39.99,
        "Ko-CommonGen V2":38.13,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"momo\/polyglot-ko-12.8b-Orca-Chat-QLoRA-Merge-v2",
        "Average":39.68,
        "Ko-ARC":37.46,
        "Ko-HellaSwag":50.45,
        "Ko-MMLU":30.35,
        "Ko-TruthfulQA":44.01,
        "Ko-CommonGen V2":36.13,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-combine-1k",
        "Average":39.67,
        "Ko-ARC":35.15,
        "Ko-HellaSwag":45.12,
        "Ko-MMLU":27.86,
        "Ko-TruthfulQA":46.17,
        "Ko-CommonGen V2":44.04,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"shleeeee\/mistral-ko-7b-wiki-neft",
        "Average":39.64,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":41.1,
        "Ko-MMLU":39.25,
        "Ko-TruthfulQA":41.03,
        "Ko-CommonGen V2":43.8,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"MRAIRR\/Nextstage",
        "Average":39.64,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":42.24,
        "Ko-MMLU":40.69,
        "Ko-TruthfulQA":42.64,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-ko-Orcapus-test-v1",
        "Average":39.63,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.47,
        "Ko-MMLU":28.88,
        "Ko-TruthfulQA":38.21,
        "Ko-CommonGen V2":43.45,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"The-matt\/llama2_ko-7b_distinctive-snowflake-182_1060",
        "Average":39.63,
        "Ko-ARC":35.84,
        "Ko-HellaSwag":49.1,
        "Ko-MMLU":28.07,
        "Ko-TruthfulQA":39.09,
        "Ko-CommonGen V2":46.04,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/KoQuality-Polyglot-5.8b",
        "Average":39.63,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":49.7,
        "Ko-MMLU":27.05,
        "Ko-TruthfulQA":40.82,
        "Ko-CommonGen V2":46.87,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"KRAFTON\/KORani-v1-13B",
        "Average":39.58,
        "Ko-ARC":35.15,
        "Ko-HellaSwag":51.15,
        "Ko-MMLU":23.72,
        "Ko-TruthfulQA":40.54,
        "Ko-CommonGen V2":47.34,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-orca-platy-2k-ep4",
        "Average":39.56,
        "Ko-ARC":34.3,
        "Ko-HellaSwag":46.35,
        "Ko-MMLU":36.54,
        "Ko-TruthfulQA":44.94,
        "Ko-CommonGen V2":35.66,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/llama2-ko-13b-instruct-v1.2",
        "Average":39.54,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":45.87,
        "Ko-MMLU":36.96,
        "Ko-TruthfulQA":39.42,
        "Ko-CommonGen V2":37.9,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Jaewoo1\/Llama2-7B-ShareGPT-Wiki_noprompt-News_noprompt-CoT-blending-circulus",
        "Average":39.51,
        "Ko-ARC":34.81,
        "Ko-HellaSwag":42.94,
        "Ko-MMLU":37.37,
        "Ko-TruthfulQA":47.51,
        "Ko-CommonGen V2":34.95,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/penguin3.1.6n_7b",
        "Average":39.51,
        "Ko-ARC":38.65,
        "Ko-HellaSwag":47.21,
        "Ko-MMLU":39.44,
        "Ko-TruthfulQA":42.86,
        "Ko-CommonGen V2":29.4,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/llama-2-ko-7b-it-v1.0.0",
        "Average":39.46,
        "Ko-ARC":38.31,
        "Ko-HellaSwag":51.86,
        "Ko-MMLU":29.58,
        "Ko-TruthfulQA":37.63,
        "Ko-CommonGen V2":39.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeon\/llama-ko-qlora-1024",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeonn\/llama-2-ko-qlora-prompt",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeonn\/llama-2-ko-qlora-prompt_1024",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeonn\/llama-2-ko-qlora-prompt_1024_new",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeon\/llama-2-ko-qlora4",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeonn\/llama-2-ko-qlora-prompt_1024_new_2",
        "Average":39.38,
        "Ko-ARC":38.14,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.57,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-platypus-7b-f",
        "Average":39.37,
        "Ko-ARC":37.54,
        "Ko-HellaSwag":49.18,
        "Ko-MMLU":30.37,
        "Ko-TruthfulQA":37.49,
        "Ko-CommonGen V2":42.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/llama-2-ko-7b",
        "Average":39.35,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.58,
        "Ko-MMLU":30.48,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":41.56,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-n-ox-test-v1",
        "Average":39.34,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.73,
        "Ko-MMLU":29.01,
        "Ko-TruthfulQA":37.77,
        "Ko-CommonGen V2":42.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/polyglot-ko-12.8b-instruct",
        "Average":39.31,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":51.59,
        "Ko-MMLU":26.38,
        "Ko-TruthfulQA":45.16,
        "Ko-CommonGen V2":37.07,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/koquality-ko-ref-llama2-7b",
        "Average":39.31,
        "Ko-ARC":37.8,
        "Ko-HellaSwag":48.76,
        "Ko-MMLU":27.93,
        "Ko-TruthfulQA":41.09,
        "Ko-CommonGen V2":40.97,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"4n3mone\/KoSOLAR_merge_test_v0.1",
        "Average":39.3,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":31.61,
        "Ko-MMLU":31.85,
        "Ko-TruthfulQA":53.64,
        "Ko-CommonGen V2":46.4,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Model Sha":7.32
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-ko-wiki-test-v1",
        "Average":39.29,
        "Ko-ARC":37.71,
        "Ko-HellaSwag":49.52,
        "Ko-MMLU":30.4,
        "Ko-TruthfulQA":37.14,
        "Ko-CommonGen V2":41.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-exo-test-v1",
        "Average":39.27,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":49.47,
        "Ko-MMLU":30.3,
        "Ko-TruthfulQA":36.92,
        "Ko-CommonGen V2":42.03,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"hyunseoki\/ko-ref-llama2-7b",
        "Average":39.26,
        "Ko-ARC":38.48,
        "Ko-HellaSwag":49.7,
        "Ko-MMLU":28.23,
        "Ko-TruthfulQA":39.53,
        "Ko-CommonGen V2":40.38,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-orca-1k",
        "Average":39.25,
        "Ko-ARC":35.75,
        "Ko-HellaSwag":46.43,
        "Ko-MMLU":33.33,
        "Ko-TruthfulQA":44.5,
        "Ko-CommonGen V2":36.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/stupid_model",
        "Average":39.25,
        "Ko-ARC":36.18,
        "Ko-HellaSwag":44.93,
        "Ko-MMLU":34.51,
        "Ko-TruthfulQA":45.43,
        "Ko-CommonGen V2":35.18,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-n-test-v1",
        "Average":39.24,
        "Ko-ARC":37.88,
        "Ko-HellaSwag":49.71,
        "Ko-MMLU":28.92,
        "Ko-TruthfulQA":37.64,
        "Ko-CommonGen V2":42.03,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"oopsung\/llama2-7b-koNqa-test-v1",
        "Average":39.2,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.71,
        "Ko-MMLU":28.68,
        "Ko-TruthfulQA":37.38,
        "Ko-CommonGen V2":42.15,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"HAERAE-HUB\/hae-tae_v0.1.2",
        "Average":39.14,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":48.19,
        "Ko-MMLU":26.62,
        "Ko-TruthfulQA":42.09,
        "Ko-CommonGen V2":45.81,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"beomi\/KoAlpaca-KoRWKV-6B",
        "Average":39.12,
        "Ko-ARC":31.91,
        "Ko-HellaSwag":44.03,
        "Ko-MMLU":24.81,
        "Ko-TruthfulQA":40.08,
        "Ko-CommonGen V2":54.78,
        "Type":"instruction-tuned",
        "Precision":"RwkvForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.53
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mistral-7B-Instruct-v0.1",
        "Average":39.02,
        "Ko-ARC":32.85,
        "Ko-HellaSwag":38.69,
        "Ko-MMLU":38.01,
        "Ko-TruthfulQA":49.92,
        "Ko-CommonGen V2":35.66,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"devhyun88\/ku-mistral-7b-PGO-v5",
        "Average":39.0,
        "Ko-ARC":35.24,
        "Ko-HellaSwag":44.28,
        "Ko-MMLU":31.87,
        "Ko-TruthfulQA":41.11,
        "Ko-CommonGen V2":42.5,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"msy127\/ft_240201_01",
        "Average":38.98,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.5,
        "Ko-MMLU":29.39,
        "Ko-TruthfulQA":38.64,
        "Ko-CommonGen V2":39.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":6.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/gemma-2b-ko-dev-pbmt192",
        "Average":38.9,
        "Ko-ARC":40.53,
        "Ko-HellaSwag":46.89,
        "Ko-MMLU":27.55,
        "Ko-TruthfulQA":42.22,
        "Ko-CommonGen V2":37.31,
        "Type":"pretrained",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-guanaco-1k-orca-platy-1k-ep4",
        "Average":38.9,
        "Ko-ARC":33.19,
        "Ko-HellaSwag":45.92,
        "Ko-MMLU":36.5,
        "Ko-TruthfulQA":47.48,
        "Ko-CommonGen V2":31.4,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"maum-ai\/llamaum-13b-instruct-s",
        "Average":38.89,
        "Ko-ARC":35.67,
        "Ko-HellaSwag":43.94,
        "Ko-MMLU":29.55,
        "Ko-TruthfulQA":44.69,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/polyglot-ko-12.8b-Inst",
        "Average":38.87,
        "Ko-ARC":34.13,
        "Ko-HellaSwag":50.83,
        "Ko-MMLU":25.87,
        "Ko-TruthfulQA":40.89,
        "Ko-CommonGen V2":42.62,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.4n_7b",
        "Average":38.82,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":52.6,
        "Ko-MMLU":28.42,
        "Ko-TruthfulQA":38.61,
        "Ko-CommonGen V2":33.77,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"shangrilar\/llama-2-ko-7b-ck",
        "Average":38.82,
        "Ko-ARC":37.97,
        "Ko-HellaSwag":50.37,
        "Ko-MMLU":29.8,
        "Ko-TruthfulQA":37.46,
        "Ko-CommonGen V2":38.49,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.4n_7B",
        "Average":38.81,
        "Ko-ARC":40.7,
        "Ko-HellaSwag":52.59,
        "Ko-MMLU":28.4,
        "Ko-TruthfulQA":38.61,
        "Ko-CommonGen V2":33.77,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"KRAFTON\/KORani-v2-13B",
        "Average":38.81,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":42.25,
        "Ko-MMLU":34.21,
        "Ko-TruthfulQA":44.33,
        "Ko-CommonGen V2":39.55,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"lamhieu\/ghost-7b-v0.9.0",
        "Average":38.81,
        "Ko-ARC":32.42,
        "Ko-HellaSwag":39.44,
        "Ko-MMLU":37.19,
        "Ko-TruthfulQA":48.38,
        "Ko-CommonGen V2":36.6,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"KRAFTON\/KORani-v3-13B",
        "Average":38.78,
        "Ko-ARC":34.73,
        "Ko-HellaSwag":43.14,
        "Ko-MMLU":34.82,
        "Ko-TruthfulQA":44.03,
        "Ko-CommonGen V2":37.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"gl2een\/polyglot-ko-12.8b-instrcut-full-finetune2",
        "Average":38.74,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":50.29,
        "Ko-MMLU":25.89,
        "Ko-TruthfulQA":39.94,
        "Ko-CommonGen V2":44.04,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"FINDA-FIT\/llama-p",
        "Average":38.71,
        "Ko-ARC":39.59,
        "Ko-HellaSwag":50.74,
        "Ko-MMLU":33.85,
        "Ko-TruthfulQA":38.09,
        "Ko-CommonGen V2":31.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COLA3-7B",
        "Average":38.68,
        "Ko-ARC":39.16,
        "Ko-HellaSwag":50.98,
        "Ko-MMLU":35.21,
        "Ko-TruthfulQA":37.81,
        "Ko-CommonGen V2":30.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"kaist-ai\/prometheus-13b-v1.0",
        "Average":38.67,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":40.02,
        "Ko-MMLU":36.2,
        "Ko-TruthfulQA":45.12,
        "Ko-CommonGen V2":39.43,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"maywell\/Synatra-RP-Orca-2-7b-v0.1",
        "Average":38.67,
        "Ko-ARC":34.73,
        "Ko-HellaSwag":39.76,
        "Ko-MMLU":37.64,
        "Ko-TruthfulQA":45.58,
        "Ko-CommonGen V2":35.66,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"momo\/polyglot-ko-12.8b-Chat-QLoRA-Merge",
        "Average":38.67,
        "Ko-ARC":35.49,
        "Ko-HellaSwag":49.93,
        "Ko-MMLU":25.97,
        "Ko-TruthfulQA":39.43,
        "Ko-CommonGen V2":42.5,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"lcw99\/polyglot-ko-12.8b-chang-instruct-chat",
        "Average":38.64,
        "Ko-ARC":34.9,
        "Ko-HellaSwag":52.72,
        "Ko-MMLU":25.98,
        "Ko-TruthfulQA":44.44,
        "Ko-CommonGen V2":35.18,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-platy-1k",
        "Average":38.64,
        "Ko-ARC":34.04,
        "Ko-HellaSwag":45.27,
        "Ko-MMLU":25.4,
        "Ko-TruthfulQA":44.34,
        "Ko-CommonGen V2":44.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/koquality-polyglot-12.8b",
        "Average":38.59,
        "Ko-ARC":35.49,
        "Ko-HellaSwag":52.84,
        "Ko-MMLU":26.33,
        "Ko-TruthfulQA":39.91,
        "Ko-CommonGen V2":38.37,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.89
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"mncai\/llama2-7b-dpo-v1",
        "Average":38.58,
        "Ko-ARC":32.68,
        "Ko-HellaSwag":41.92,
        "Ko-MMLU":36.24,
        "Ko-TruthfulQA":48.75,
        "Ko-CommonGen V2":33.29,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"wons\/tigerbot-13b-test-v0_1",
        "Average":38.57,
        "Ko-ARC":30.12,
        "Ko-HellaSwag":38.36,
        "Ko-MMLU":34.59,
        "Ko-TruthfulQA":48.48,
        "Ko-CommonGen V2":41.32,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":13.31
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/KoSOLAR-10.7B-mixed-v13",
        "Average":38.56,
        "Ko-ARC":35.49,
        "Ko-HellaSwag":37.4,
        "Ko-MMLU":50.13,
        "Ko-TruthfulQA":42.5,
        "Ko-CommonGen V2":27.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/polyglot-ko-5.8b-Inst-All",
        "Average":38.54,
        "Ko-ARC":31.91,
        "Ko-HellaSwag":47.32,
        "Ko-MMLU":27.99,
        "Ko-TruthfulQA":40.0,
        "Ko-CommonGen V2":45.45,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-v0.1",
        "Average":38.51,
        "Ko-ARC":32.25,
        "Ko-HellaSwag":40.57,
        "Ko-MMLU":30.67,
        "Ko-TruthfulQA":44.19,
        "Ko-CommonGen V2":44.86,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mncai\/Mistral-7B-v0.1-orca_platy-1k",
        "Average":38.49,
        "Ko-ARC":32.94,
        "Ko-HellaSwag":45.24,
        "Ko-MMLU":30.18,
        "Ko-TruthfulQA":45.84,
        "Ko-CommonGen V2":38.25,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KO-Platypus2-7B-ex",
        "Average":38.47,
        "Ko-ARC":39.08,
        "Ko-HellaSwag":50.86,
        "Ko-MMLU":34.6,
        "Ko-TruthfulQA":37.94,
        "Ko-CommonGen V2":29.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/llama-2-ko-7b-instruct",
        "Average":38.46,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":52.48,
        "Ko-MMLU":30.32,
        "Ko-TruthfulQA":39.81,
        "Ko-CommonGen V2":31.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/zephyr_all_7b",
        "Average":38.46,
        "Ko-ARC":34.56,
        "Ko-HellaSwag":45.54,
        "Ko-MMLU":37.51,
        "Ko-TruthfulQA":45.15,
        "Ko-CommonGen V2":29.52,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/COLA_LO-7B",
        "Average":38.43,
        "Ko-ARC":38.99,
        "Ko-HellaSwag":50.47,
        "Ko-MMLU":34.85,
        "Ko-TruthfulQA":38.22,
        "Ko-CommonGen V2":29.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v1.2",
        "Average":38.4,
        "Ko-ARC":32.68,
        "Ko-HellaSwag":45.93,
        "Ko-MMLU":26.72,
        "Ko-TruthfulQA":45.25,
        "Ko-CommonGen V2":41.44,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"gwonny\/KoSOLAR-10.7B-QLoRA-NEFTune-kolon-v2.0",
        "Average":38.38,
        "Ko-ARC":27.47,
        "Ko-HellaSwag":41.95,
        "Ko-MMLU":44.64,
        "Ko-TruthfulQA":43.97,
        "Ko-CommonGen V2":33.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"hwanhe\/Mistral_sum_test01",
        "Average":38.35,
        "Ko-ARC":30.46,
        "Ko-HellaSwag":38.91,
        "Ko-MMLU":37.3,
        "Ko-TruthfulQA":43.66,
        "Ko-CommonGen V2":41.44,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-sfte",
        "Average":38.35,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":50.03,
        "Ko-MMLU":29.03,
        "Ko-TruthfulQA":38.89,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.3",
        "Average":38.32,
        "Ko-ARC":40.1,
        "Ko-HellaSwag":52.29,
        "Ko-MMLU":27.76,
        "Ko-TruthfulQA":37.11,
        "Ko-CommonGen V2":34.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCKim\/Mistral-7B-SlimOrca-OP-U2048-ran4k",
        "Average":38.31,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":45.55,
        "Ko-MMLU":27.86,
        "Ko-TruthfulQA":45.72,
        "Ko-CommonGen V2":38.49,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/llama-2-ko-7b-Inst",
        "Average":38.31,
        "Ko-ARC":37.37,
        "Ko-HellaSwag":49.92,
        "Ko-MMLU":29.28,
        "Ko-TruthfulQA":36.51,
        "Ko-CommonGen V2":38.49,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/Orca-2-7b",
        "Average":38.3,
        "Ko-ARC":33.36,
        "Ko-HellaSwag":39.87,
        "Ko-MMLU":38.35,
        "Ko-TruthfulQA":45.22,
        "Ko-CommonGen V2":34.71,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":7.0
    },
    {
        "T":"?",
        "Model":"choco9966\/Llama-2-7b-instruct-tuning",
        "Average":38.29,
        "Ko-ARC":33.28,
        "Ko-HellaSwag":42.47,
        "Ko-MMLU":35.12,
        "Ko-TruthfulQA":51.41,
        "Ko-CommonGen V2":29.16,
        "Type":"",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/KoT-platypus2-7B",
        "Average":38.2,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.63,
        "Ko-MMLU":34.68,
        "Ko-TruthfulQA":37.69,
        "Ko-CommonGen V2":30.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"taeminlee\/polyglot_12.8b_ins_orcastyle_ma",
        "Average":38.18,
        "Ko-ARC":31.4,
        "Ko-HellaSwag":48.78,
        "Ko-MMLU":27.44,
        "Ko-TruthfulQA":44.1,
        "Ko-CommonGen V2":39.2,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"ingeol\/sft_merged_660",
        "Average":38.17,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":50.31,
        "Ko-MMLU":25.92,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":38.84,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":12.89
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-instruct-42dot_LLM-SFT-1.3B-dpo",
        "Average":38.15,
        "Ko-ARC":33.62,
        "Ko-HellaSwag":44.55,
        "Ko-MMLU":26.2,
        "Ko-TruthfulQA":41.74,
        "Ko-CommonGen V2":44.63,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-Llama2-13b-v1.0",
        "Average":38.11,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":41.66,
        "Ko-MMLU":35.89,
        "Ko-TruthfulQA":44.07,
        "Ko-CommonGen V2":35.42,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":13.26
    },
    {
        "T":"\u2b55",
        "Model":"kody0525\/KOpen-platypus-polyglot-ko-12.8b",
        "Average":38.07,
        "Ko-ARC":35.24,
        "Ko-HellaSwag":50.45,
        "Ko-MMLU":25.72,
        "Ko-TruthfulQA":37.26,
        "Ko-CommonGen V2":41.68,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-SFT-1.3B-v2.1",
        "Average":38.03,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":44.54,
        "Ko-MMLU":24.72,
        "Ko-TruthfulQA":41.98,
        "Ko-CommonGen V2":45.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/koquality-polyglot-ko-12.8b",
        "Average":38.03,
        "Ko-ARC":34.04,
        "Ko-HellaSwag":51.36,
        "Ko-MMLU":26.33,
        "Ko-TruthfulQA":40.62,
        "Ko-CommonGen V2":37.78,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Byungchae\/k2s3_test_0000",
        "Average":38.02,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":41.07,
        "Ko-MMLU":37.57,
        "Ko-TruthfulQA":45.46,
        "Ko-CommonGen V2":31.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.4_7b",
        "Average":38.02,
        "Ko-ARC":31.57,
        "Ko-HellaSwag":43.92,
        "Ko-MMLU":27.63,
        "Ko-TruthfulQA":50.16,
        "Ko-CommonGen V2":36.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"julleong\/illuni-llama-2-ko-7b-test",
        "Average":37.99,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":48.49,
        "Ko-MMLU":28.87,
        "Ko-TruthfulQA":39.94,
        "Ko-CommonGen V2":34.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-SFT-1.3B-v2.1.1",
        "Average":37.98,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":44.97,
        "Ko-MMLU":24.65,
        "Ko-TruthfulQA":40.64,
        "Ko-CommonGen V2":45.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"taeminlee\/polyglot_12.8b_ins_orcastyle",
        "Average":37.97,
        "Ko-ARC":32.85,
        "Ko-HellaSwag":49.8,
        "Ko-MMLU":24.58,
        "Ko-TruthfulQA":42.14,
        "Ko-CommonGen V2":40.5,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"ingeol\/sft_merged",
        "Average":37.96,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":50.39,
        "Ko-MMLU":25.8,
        "Ko-TruthfulQA":42.11,
        "Ko-CommonGen V2":37.54,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"garage-bAInd\/Platypus2-7B",
        "Average":37.96,
        "Ko-ARC":32.42,
        "Ko-HellaSwag":41.54,
        "Ko-MMLU":35.16,
        "Ko-TruthfulQA":45.72,
        "Ko-CommonGen V2":34.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-42dot_LLM-SFT-1.3B",
        "Average":37.94,
        "Ko-ARC":33.28,
        "Ko-HellaSwag":44.35,
        "Ko-MMLU":26.07,
        "Ko-TruthfulQA":41.63,
        "Ko-CommonGen V2":44.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"vitruv\/vitruv_2",
        "Average":37.93,
        "Ko-ARC":37.63,
        "Ko-HellaSwag":51.25,
        "Ko-MMLU":30.03,
        "Ko-TruthfulQA":37.69,
        "Ko-CommonGen V2":33.06,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-ck-sft",
        "Average":37.9,
        "Ko-ARC":36.52,
        "Ko-HellaSwag":50.35,
        "Ko-MMLU":28.69,
        "Ko-TruthfulQA":36.63,
        "Ko-CommonGen V2":37.31,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/KoRWKV-6B",
        "Average":37.89,
        "Ko-ARC":28.67,
        "Ko-HellaSwag":43.57,
        "Ko-MMLU":25.08,
        "Ko-TruthfulQA":38.07,
        "Ko-CommonGen V2":54.07,
        "Type":"pretrained",
        "Precision":"RwkvForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.53
    },
    {
        "T":"\u2b55",
        "Model":"Xwin-LM\/Xwin-LM-7B-V0.2",
        "Average":37.88,
        "Ko-ARC":33.28,
        "Ko-HellaSwag":42.19,
        "Ko-MMLU":36.45,
        "Ko-TruthfulQA":46.21,
        "Ko-CommonGen V2":31.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Walmart-the-bag\/Yi-6B-Infinity-Chat",
        "Average":37.88,
        "Ko-ARC":26.54,
        "Ko-HellaSwag":35.61,
        "Ko-MMLU":38.47,
        "Ko-TruthfulQA":48.18,
        "Ko-CommonGen V2":40.61,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Model Sha":6.06
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ingeol\/ppo_test",
        "Average":37.88,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":50.65,
        "Ko-MMLU":25.81,
        "Ko-TruthfulQA":42.08,
        "Ko-CommonGen V2":36.48,
        "Type":"RL-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"etri-xainlp\/polyglot-ko-12.8b-instruct",
        "Average":37.88,
        "Ko-ARC":34.64,
        "Ko-HellaSwag":51.98,
        "Ko-MMLU":26.26,
        "Ko-TruthfulQA":42.02,
        "Ko-CommonGen V2":34.47,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B",
        "Average":37.87,
        "Ko-ARC":26.11,
        "Ko-HellaSwag":35.01,
        "Ko-MMLU":39.64,
        "Ko-TruthfulQA":47.6,
        "Ko-CommonGen V2":40.97,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.06
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-42dot-1.3B",
        "Average":37.85,
        "Ko-ARC":34.9,
        "Ko-HellaSwag":45.44,
        "Ko-MMLU":25.94,
        "Ko-TruthfulQA":42.94,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/240103_test_nosafetensor",
        "Average":37.85,
        "Ko-ARC":34.9,
        "Ko-HellaSwag":45.44,
        "Ko-MMLU":25.94,
        "Ko-TruthfulQA":42.94,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"realPCH\/240102_test_noshard",
        "Average":37.85,
        "Ko-ARC":34.9,
        "Ko-HellaSwag":45.44,
        "Ko-MMLU":25.94,
        "Ko-TruthfulQA":42.94,
        "Ko-CommonGen V2":40.02,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"42MARU\/llama-2-ko-7b-instruction-v3",
        "Average":37.81,
        "Ko-ARC":38.65,
        "Ko-HellaSwag":50.23,
        "Ko-MMLU":32.85,
        "Ko-TruthfulQA":38.06,
        "Ko-CommonGen V2":29.28,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jingyeom\/seal_all_7b",
        "Average":37.77,
        "Ko-ARC":39.25,
        "Ko-HellaSwag":51.57,
        "Ko-MMLU":27.39,
        "Ko-TruthfulQA":35.12,
        "Ko-CommonGen V2":35.54,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"tlphams\/gollm-12.8b-instruct-tendency-t45",
        "Average":37.77,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":53.21,
        "Ko-MMLU":26.67,
        "Ko-TruthfulQA":42.13,
        "Ko-CommonGen V2":31.88,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"sue3489\/test0_kullm-polyglot-5.8b-v2-koalpaca-v1.1b",
        "Average":37.76,
        "Ko-ARC":31.06,
        "Ko-HellaSwag":46.56,
        "Ko-MMLU":27.47,
        "Ko-TruthfulQA":43.82,
        "Ko-CommonGen V2":39.91,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/polyglot-ko-5.8b-Inst",
        "Average":37.76,
        "Ko-ARC":31.91,
        "Ko-HellaSwag":48.28,
        "Ko-MMLU":26.63,
        "Ko-TruthfulQA":40.16,
        "Ko-CommonGen V2":41.79,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Average":37.73,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":50.28,
        "Ko-MMLU":25.88,
        "Ko-TruthfulQA":39.07,
        "Ko-CommonGen V2":39.91,
        "Type":"pretrained",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.06
    },
    {
        "T":"\u2b55",
        "Model":"GAI-LLM\/polyglot-12.8b-mixed-v3",
        "Average":37.72,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":50.29,
        "Ko-MMLU":25.91,
        "Ko-TruthfulQA":39.07,
        "Ko-CommonGen V2":39.91,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"nakhyeon\/polyglot-ko-12b-qlora",
        "Average":37.71,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":50.28,
        "Ko-MMLU":25.87,
        "Ko-TruthfulQA":39.07,
        "Ko-CommonGen V2":39.91,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"davidkim205\/komt-qwen1.5-7b-sft-v1",
        "Average":37.71,
        "Ko-ARC":31.48,
        "Ko-HellaSwag":38.14,
        "Ko-MMLU":37.97,
        "Ko-TruthfulQA":47.3,
        "Ko-CommonGen V2":33.65,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":7.72
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/Yi-6B-Llama",
        "Average":37.65,
        "Ko-ARC":26.28,
        "Ko-HellaSwag":35.08,
        "Ko-MMLU":39.69,
        "Ko-TruthfulQA":47.51,
        "Ko-CommonGen V2":39.67,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.06
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"igig98\/ppo2",
        "Average":37.64,
        "Ko-ARC":34.47,
        "Ko-HellaSwag":50.74,
        "Ko-MMLU":26.25,
        "Ko-TruthfulQA":42.29,
        "Ko-CommonGen V2":34.47,
        "Type":"RL-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":12.89
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-ck-sfte",
        "Average":37.64,
        "Ko-ARC":35.24,
        "Ko-HellaSwag":49.9,
        "Ko-MMLU":27.5,
        "Ko-TruthfulQA":39.2,
        "Ko-CommonGen V2":36.36,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-sftem",
        "Average":37.61,
        "Ko-ARC":37.46,
        "Ko-HellaSwag":49.65,
        "Ko-MMLU":28.11,
        "Ko-TruthfulQA":37.65,
        "Ko-CommonGen V2":35.18,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"junga\/hjys_LLM_final",
        "Average":37.6,
        "Ko-ARC":35.49,
        "Ko-HellaSwag":46.05,
        "Ko-MMLU":25.05,
        "Ko-TruthfulQA":44.23,
        "Ko-CommonGen V2":37.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/test-last",
        "Average":37.59,
        "Ko-ARC":34.64,
        "Ko-HellaSwag":45.2,
        "Ko-MMLU":32.07,
        "Ko-TruthfulQA":38.72,
        "Ko-CommonGen V2":37.31,
        "Type":"pretrained",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-v0.3",
        "Average":37.57,
        "Ko-ARC":33.87,
        "Ko-HellaSwag":42.47,
        "Ko-MMLU":28.21,
        "Ko-TruthfulQA":46.09,
        "Ko-CommonGen V2":37.19,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"42dot\/42dot_LLM-SFT-1.3B",
        "Average":37.55,
        "Ko-ARC":35.49,
        "Ko-HellaSwag":46.14,
        "Ko-MMLU":24.81,
        "Ko-TruthfulQA":43.77,
        "Ko-CommonGen V2":37.54,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"Byungchae\/k2s3_test_0001",
        "Average":37.55,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":41.15,
        "Ko-MMLU":36.97,
        "Ko-TruthfulQA":46.63,
        "Ko-CommonGen V2":29.28,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":13.02
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-SFT-1.3B-refine-v3",
        "Average":37.54,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":44.57,
        "Ko-MMLU":25.18,
        "Ko-TruthfulQA":41.08,
        "Ko-CommonGen V2":43.33,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/yi-ko-6b-it-v1.0.3",
        "Average":37.49,
        "Ko-ARC":34.04,
        "Ko-HellaSwag":43.4,
        "Ko-MMLU":27.18,
        "Ko-TruthfulQA":44.83,
        "Ko-CommonGen V2":38.02,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"currybab\/gemma-2b-ko-dev-pb",
        "Average":37.49,
        "Ko-ARC":35.75,
        "Ko-HellaSwag":45.39,
        "Ko-MMLU":26.8,
        "Ko-TruthfulQA":43.51,
        "Ko-CommonGen V2":36.01,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-SlimOrca-eng-kor-combined",
        "Average":37.47,
        "Ko-ARC":33.79,
        "Ko-HellaSwag":43.5,
        "Ko-MMLU":36.1,
        "Ko-TruthfulQA":46.0,
        "Ko-CommonGen V2":27.98,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/KoRWKV-1.5B",
        "Average":37.46,
        "Ko-ARC":26.88,
        "Ko-HellaSwag":39.5,
        "Ko-MMLU":25.63,
        "Ko-TruthfulQA":40.38,
        "Ko-CommonGen V2":54.9,
        "Type":"pretrained",
        "Precision":"RwkvForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":1.52
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B-Chat",
        "Average":37.42,
        "Ko-ARC":26.62,
        "Ko-HellaSwag":35.22,
        "Ko-MMLU":39.14,
        "Ko-TruthfulQA":48.7,
        "Ko-CommonGen V2":37.43,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.06
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-ck-sftm",
        "Average":37.41,
        "Ko-ARC":37.12,
        "Ko-HellaSwag":50.44,
        "Ko-MMLU":26.37,
        "Ko-TruthfulQA":36.88,
        "Ko-CommonGen V2":36.25,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"nlpai-lab\/kullm-polyglot-5.8b-v2",
        "Average":37.38,
        "Ko-ARC":32.94,
        "Ko-HellaSwag":47.3,
        "Ko-MMLU":27.3,
        "Ko-TruthfulQA":42.39,
        "Ko-CommonGen V2":36.95,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"nlpai-lab\/kullm-polyglot-12.8b-v2",
        "Average":37.37,
        "Ko-ARC":32.76,
        "Ko-HellaSwag":49.87,
        "Ko-MMLU":25.6,
        "Ko-TruthfulQA":39.04,
        "Ko-CommonGen V2":39.55,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-v1.3-42dot_LLM-SFT-1.3B",
        "Average":37.31,
        "Ko-ARC":33.87,
        "Ko-HellaSwag":45.04,
        "Ko-MMLU":26.19,
        "Ko-TruthfulQA":41.67,
        "Ko-CommonGen V2":39.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"metterian\/polyglot-ko-kullm-v2-fix",
        "Average":37.31,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":26.15,
        "Ko-TruthfulQA":39.7,
        "Ko-CommonGen V2":36.13,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"NousResearch\/Nous-Hermes-llama-2-7b",
        "Average":37.31,
        "Ko-ARC":31.91,
        "Ko-HellaSwag":41.68,
        "Ko-MMLU":34.11,
        "Ko-TruthfulQA":48.49,
        "Ko-CommonGen V2":30.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-sft",
        "Average":37.3,
        "Ko-ARC":35.58,
        "Ko-HellaSwag":50.18,
        "Ko-MMLU":28.3,
        "Ko-TruthfulQA":36.66,
        "Ko-CommonGen V2":35.77,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"Jaewoo1\/Platypus7B_Follow_LoRA",
        "Average":37.3,
        "Ko-ARC":35.07,
        "Ko-HellaSwag":48.57,
        "Ko-MMLU":34.4,
        "Ko-TruthfulQA":38.57,
        "Ko-CommonGen V2":29.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cepiloth\/ko-llama2-finetune-ex2",
        "Average":37.29,
        "Ko-ARC":32.17,
        "Ko-HellaSwag":40.92,
        "Ko-MMLU":32.62,
        "Ko-TruthfulQA":45.47,
        "Ko-CommonGen V2":35.3,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-instruct-dpo-v1.3-42dot_LLM-SFT-1.3B",
        "Average":37.29,
        "Ko-ARC":33.62,
        "Ko-HellaSwag":45.11,
        "Ko-MMLU":26.2,
        "Ko-TruthfulQA":41.76,
        "Ko-CommonGen V2":39.79,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"beomi\/KoAlpaca-Polyglot-12.8B",
        "Average":37.27,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":49.8,
        "Ko-MMLU":25.39,
        "Ko-TruthfulQA":41.96,
        "Ko-CommonGen V2":34.83,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":13.06
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-v0.2",
        "Average":37.27,
        "Ko-ARC":30.2,
        "Ko-HellaSwag":38.86,
        "Ko-MMLU":34.52,
        "Ko-TruthfulQA":42.17,
        "Ko-CommonGen V2":40.61,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"kfkas\/Llama-2-ko-7b-Chat",
        "Average":37.26,
        "Ko-ARC":38.4,
        "Ko-HellaSwag":50.48,
        "Ko-MMLU":29.54,
        "Ko-TruthfulQA":36.71,
        "Ko-CommonGen V2":31.17,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"sminpark\/ds-alpha-model-v0.1-merged",
        "Average":37.26,
        "Ko-ARC":32.25,
        "Ko-HellaSwag":49.65,
        "Ko-MMLU":25.71,
        "Ko-TruthfulQA":39.71,
        "Ko-CommonGen V2":38.96,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DooDooHyun\/AIFT-42dot_LLM-PLM-1.3B-v1.51",
        "Average":37.25,
        "Ko-ARC":32.34,
        "Ko-HellaSwag":44.58,
        "Ko-MMLU":25.28,
        "Ko-TruthfulQA":43.78,
        "Ko-CommonGen V2":40.26,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama2-ko-7b-kullm-base",
        "Average":37.22,
        "Ko-ARC":38.05,
        "Ko-HellaSwag":49.57,
        "Ko-MMLU":30.47,
        "Ko-TruthfulQA":37.06,
        "Ko-CommonGen V2":30.93,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.89
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-eng-kor-cot-combined",
        "Average":37.2,
        "Ko-ARC":34.81,
        "Ko-HellaSwag":43.75,
        "Ko-MMLU":35.9,
        "Ko-TruthfulQA":46.99,
        "Ko-CommonGen V2":24.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-SFT-1.3B-v1.1",
        "Average":37.2,
        "Ko-ARC":33.19,
        "Ko-HellaSwag":44.5,
        "Ko-MMLU":24.51,
        "Ko-TruthfulQA":40.94,
        "Ko-CommonGen V2":42.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/ZeroCoka-7B",
        "Average":37.18,
        "Ko-ARC":34.56,
        "Ko-HellaSwag":48.47,
        "Ko-MMLU":34.65,
        "Ko-TruthfulQA":38.26,
        "Ko-CommonGen V2":29.99,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"Trofish\/KULLM-RLHF",
        "Average":37.18,
        "Ko-ARC":32.0,
        "Ko-HellaSwag":49.54,
        "Ko-MMLU":25.68,
        "Ko-TruthfulQA":38.77,
        "Ko-CommonGen V2":39.91,
        "Type":"RL-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mncai\/Pr_Llama2_7B-Sh5K_Wi5K_Ne5K_Ct5K-Lr05_Ep4",
        "Average":37.16,
        "Ko-ARC":32.34,
        "Ko-HellaSwag":41.08,
        "Ko-MMLU":34.05,
        "Ko-TruthfulQA":45.63,
        "Ko-CommonGen V2":32.7,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"AIFT\/AIFT-instruct-SFT-dpo-1.3B-v1.1",
        "Average":37.15,
        "Ko-ARC":34.13,
        "Ko-HellaSwag":44.75,
        "Ko-MMLU":24.37,
        "Ko-TruthfulQA":41.3,
        "Ko-CommonGen V2":41.2,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v0.1",
        "Average":37.12,
        "Ko-ARC":31.31,
        "Ko-HellaSwag":41.18,
        "Ko-MMLU":29.79,
        "Ko-TruthfulQA":48.59,
        "Ko-CommonGen V2":34.71,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"rufjdk5480\/ko-llama7b-merged",
        "Average":37.11,
        "Ko-ARC":30.89,
        "Ko-HellaSwag":41.19,
        "Ko-MMLU":32.59,
        "Ko-TruthfulQA":46.32,
        "Ko-CommonGen V2":34.59,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"iknow-lab\/AULM-12.8b-v0",
        "Average":37.08,
        "Ko-ARC":33.11,
        "Ko-HellaSwag":47.47,
        "Ko-MMLU":24.87,
        "Ko-TruthfulQA":43.37,
        "Ko-CommonGen V2":36.6,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v1.3",
        "Average":37.06,
        "Ko-ARC":33.36,
        "Ko-HellaSwag":47.12,
        "Ko-MMLU":27.74,
        "Ko-TruthfulQA":45.57,
        "Ko-CommonGen V2":31.52,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"momo\/polyglot-ko-12.8b-Chat-QLoRA-Merge_v3",
        "Average":37.05,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":50.06,
        "Ko-MMLU":28.38,
        "Ko-TruthfulQA":39.86,
        "Ko-CommonGen V2":33.41,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"lamhieu\/ghost-7b-v0.9.1",
        "Average":36.99,
        "Ko-ARC":32.68,
        "Ko-HellaSwag":39.32,
        "Ko-MMLU":37.05,
        "Ko-TruthfulQA":43.91,
        "Ko-CommonGen V2":32.0,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-SOLAR-11b-v2.0",
        "Average":36.99,
        "Ko-ARC":33.19,
        "Ko-HellaSwag":40.75,
        "Ko-MMLU":31.71,
        "Ko-TruthfulQA":45.66,
        "Ko-CommonGen V2":33.65,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.92
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-OpenOrca-eng-kor-combined",
        "Average":36.98,
        "Ko-ARC":32.85,
        "Ko-HellaSwag":42.36,
        "Ko-MMLU":35.46,
        "Ko-TruthfulQA":47.54,
        "Ko-CommonGen V2":26.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cepiloth\/ko-llama2-finetune-ex5",
        "Average":36.92,
        "Ko-ARC":31.23,
        "Ko-HellaSwag":41.0,
        "Ko-MMLU":32.16,
        "Ko-TruthfulQA":45.05,
        "Ko-CommonGen V2":35.18,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yeen214\/test_llama2_7b",
        "Average":36.91,
        "Ko-ARC":31.06,
        "Ko-HellaSwag":41.13,
        "Ko-MMLU":33.15,
        "Ko-TruthfulQA":43.92,
        "Ko-CommonGen V2":35.3,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-SFT-1.3B-v1.6.2",
        "Average":36.9,
        "Ko-ARC":34.22,
        "Ko-HellaSwag":44.46,
        "Ko-MMLU":24.6,
        "Ko-TruthfulQA":40.84,
        "Ko-CommonGen V2":40.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TinyPixel\/Llama-2-7B-bf16-sharded",
        "Average":36.88,
        "Ko-ARC":30.97,
        "Ko-HellaSwag":41.13,
        "Ko-MMLU":33.11,
        "Ko-TruthfulQA":43.92,
        "Ko-CommonGen V2":35.3,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/LLaMA2-ko-7B-KNUT-v0.1",
        "Average":36.88,
        "Ko-ARC":35.84,
        "Ko-HellaSwag":42.94,
        "Ko-MMLU":26.12,
        "Ko-TruthfulQA":38.77,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v6.0",
        "Average":36.88,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":45.98,
        "Ko-MMLU":26.97,
        "Ko-TruthfulQA":44.11,
        "Ko-CommonGen V2":33.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/koquality-polyglot-3.8b",
        "Average":36.87,
        "Ko-ARC":30.97,
        "Ko-HellaSwag":46.02,
        "Ko-MMLU":26.41,
        "Ko-TruthfulQA":41.53,
        "Ko-CommonGen V2":39.43,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":3.8
    },
    {
        "T":"\u2b55",
        "Model":"kyujinpy\/CoT-llama-2k-7b",
        "Average":36.86,
        "Ko-ARC":36.77,
        "Ko-HellaSwag":49.38,
        "Ko-MMLU":29.8,
        "Ko-TruthfulQA":37.76,
        "Ko-CommonGen V2":30.58,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v1.0",
        "Average":36.85,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":46.57,
        "Ko-MMLU":27.71,
        "Ko-TruthfulQA":41.34,
        "Ko-CommonGen V2":35.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/42dot-1.3B-KOR-OpenOrca-Platypus-1e-5",
        "Average":36.83,
        "Ko-ARC":33.62,
        "Ko-HellaSwag":45.28,
        "Ko-MMLU":28.23,
        "Ko-TruthfulQA":40.67,
        "Ko-CommonGen V2":36.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"kodonho\/llama2-chat-koalpaca",
        "Average":36.83,
        "Ko-ARC":30.46,
        "Ko-HellaSwag":39.15,
        "Ko-MMLU":31.5,
        "Ko-TruthfulQA":48.09,
        "Ko-CommonGen V2":34.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":6.74
    },
    {
        "T":"\u2b55",
        "Model":"jojo0217\/ChatSKKU5.8B",
        "Average":36.78,
        "Ko-ARC":32.94,
        "Ko-HellaSwag":48.03,
        "Ko-MMLU":27.03,
        "Ko-TruthfulQA":41.57,
        "Ko-CommonGen V2":34.36,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.88
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.7",
        "Average":36.78,
        "Ko-ARC":29.61,
        "Ko-HellaSwag":41.71,
        "Ko-MMLU":26.41,
        "Ko-TruthfulQA":41.66,
        "Ko-CommonGen V2":44.51,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v1.5.3",
        "Average":36.78,
        "Ko-ARC":33.28,
        "Ko-HellaSwag":46.53,
        "Ko-MMLU":26.73,
        "Ko-TruthfulQA":44.88,
        "Ko-CommonGen V2":32.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"shangrilar\/llama-2-ko-7b-ck-sftem",
        "Average":36.78,
        "Ko-ARC":36.77,
        "Ko-HellaSwag":50.17,
        "Ko-MMLU":26.92,
        "Ko-TruthfulQA":38.38,
        "Ko-CommonGen V2":31.64,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v1.1",
        "Average":36.77,
        "Ko-ARC":33.87,
        "Ko-HellaSwag":47.12,
        "Ko-MMLU":28.16,
        "Ko-TruthfulQA":41.3,
        "Ko-CommonGen V2":33.41,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/test-pb-v0",
        "Average":36.75,
        "Ko-ARC":34.81,
        "Ko-HellaSwag":44.31,
        "Ko-MMLU":28.7,
        "Ko-TruthfulQA":40.76,
        "Ko-CommonGen V2":35.18,
        "Type":"pretrained",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"MarkrAI\/kyujin-Poly-platypus-ko-12.8b",
        "Average":36.75,
        "Ko-ARC":35.15,
        "Ko-HellaSwag":50.39,
        "Ko-MMLU":25.58,
        "Ko-TruthfulQA":38.74,
        "Ko-CommonGen V2":33.88,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"NousResearch\/Nous-Capybara-7B",
        "Average":36.71,
        "Ko-ARC":31.83,
        "Ko-HellaSwag":41.88,
        "Ko-MMLU":35.31,
        "Ko-TruthfulQA":47.12,
        "Ko-CommonGen V2":27.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"leeebs\/kollama2_ndap",
        "Average":36.7,
        "Ko-ARC":36.77,
        "Ko-HellaSwag":48.63,
        "Ko-MMLU":26.71,
        "Ko-TruthfulQA":39.14,
        "Ko-CommonGen V2":32.23,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"HAERAE-HUB\/hae-tae_v0.1.1",
        "Average":36.69,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":48.22,
        "Ko-MMLU":26.82,
        "Ko-TruthfulQA":39.75,
        "Ko-CommonGen V2":35.66,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v0.3",
        "Average":36.68,
        "Ko-ARC":31.14,
        "Ko-HellaSwag":40.72,
        "Ko-MMLU":29.91,
        "Ko-TruthfulQA":42.66,
        "Ko-CommonGen V2":38.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.74
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"kakaobrain\/kogpt",
        "Average":36.67,
        "Ko-ARC":32.25,
        "Ko-HellaSwag":43.3,
        "Ko-MMLU":26.45,
        "Ko-TruthfulQA":42.03,
        "Ko-CommonGen V2":39.32,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v1.4",
        "Average":36.66,
        "Ko-ARC":34.39,
        "Ko-HellaSwag":46.67,
        "Ko-MMLU":27.74,
        "Ko-TruthfulQA":44.29,
        "Ko-CommonGen V2":30.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v5.0",
        "Average":36.66,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":45.96,
        "Ko-MMLU":26.44,
        "Ko-TruthfulQA":44.06,
        "Ko-CommonGen V2":33.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/AULM-5.8b-v0804-hf",
        "Average":36.64,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":45.43,
        "Ko-MMLU":26.52,
        "Ko-TruthfulQA":40.8,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"amphora\/polyglot-5.8B-CoT-e1",
        "Average":36.62,
        "Ko-ARC":31.4,
        "Ko-HellaSwag":47.47,
        "Ko-MMLU":26.68,
        "Ko-TruthfulQA":39.16,
        "Ko-CommonGen V2":38.37,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v1.12",
        "Average":36.59,
        "Ko-ARC":32.76,
        "Ko-HellaSwag":46.4,
        "Ko-MMLU":27.57,
        "Ko-TruthfulQA":40.33,
        "Ko-CommonGen V2":35.89,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"cocoirun\/AIFT-42dot-PLM-1.3B-ao-instruct-all-v0.4-ff-e1",
        "Average":36.57,
        "Ko-ARC":33.28,
        "Ko-HellaSwag":45.13,
        "Ko-MMLU":26.51,
        "Ko-TruthfulQA":41.08,
        "Ko-CommonGen V2":36.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-SFT-1.3B-v1.0",
        "Average":36.56,
        "Ko-ARC":33.62,
        "Ko-HellaSwag":45.36,
        "Ko-MMLU":27.25,
        "Ko-TruthfulQA":42.12,
        "Ko-CommonGen V2":34.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v4.0",
        "Average":36.55,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":46.29,
        "Ko-MMLU":27.48,
        "Ko-TruthfulQA":41.0,
        "Ko-CommonGen V2":34.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/test-tt-last",
        "Average":36.54,
        "Ko-ARC":35.92,
        "Ko-HellaSwag":45.06,
        "Ko-MMLU":30.15,
        "Ko-TruthfulQA":39.48,
        "Ko-CommonGen V2":32.11,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"?",
        "Model":"EleutherAI\/polyglot-ko-5.8b",
        "Average":36.54,
        "Ko-ARC":32.76,
        "Ko-HellaSwag":48.15,
        "Ko-MMLU":26.92,
        "Ko-TruthfulQA":39.23,
        "Ko-CommonGen V2":35.66,
        "Type":"",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v0",
        "Average":36.54,
        "Ko-ARC":31.06,
        "Ko-HellaSwag":41.23,
        "Ko-MMLU":28.73,
        "Ko-TruthfulQA":46.49,
        "Ko-CommonGen V2":35.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-V3",
        "Average":36.53,
        "Ko-ARC":25.26,
        "Ko-HellaSwag":26.56,
        "Ko-MMLU":24.33,
        "Ko-TruthfulQA":51.82,
        "Ko-CommonGen V2":54.66,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.04
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-dpo-v1.0",
        "Average":36.52,
        "Ko-ARC":32.17,
        "Ko-HellaSwag":45.12,
        "Ko-MMLU":26.75,
        "Ko-TruthfulQA":43.51,
        "Ko-CommonGen V2":35.06,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v3.0",
        "Average":36.52,
        "Ko-ARC":32.17,
        "Ko-HellaSwag":45.12,
        "Ko-MMLU":26.75,
        "Ko-TruthfulQA":43.51,
        "Ko-CommonGen V2":35.06,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/WizardVicuna2-13b-hf",
        "Average":36.52,
        "Ko-ARC":31.91,
        "Ko-HellaSwag":39.23,
        "Ko-MMLU":32.3,
        "Ko-TruthfulQA":44.33,
        "Ko-CommonGen V2":34.83,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v0.4",
        "Average":36.5,
        "Ko-ARC":30.63,
        "Ko-HellaSwag":41.1,
        "Ko-MMLU":31.17,
        "Ko-TruthfulQA":45.34,
        "Ko-CommonGen V2":34.24,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.74
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/gemma-2b-ko-dev-pbc432",
        "Average":36.47,
        "Ko-ARC":36.35,
        "Ko-HellaSwag":46.09,
        "Ko-MMLU":25.84,
        "Ko-TruthfulQA":40.17,
        "Ko-CommonGen V2":33.88,
        "Type":"pretrained",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"DooDooHyun\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.55",
        "Average":36.41,
        "Ko-ARC":32.08,
        "Ko-HellaSwag":46.03,
        "Ko-MMLU":25.23,
        "Ko-TruthfulQA":41.63,
        "Ko-CommonGen V2":37.07,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.91",
        "Average":36.4,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":46.69,
        "Ko-MMLU":27.94,
        "Ko-TruthfulQA":41.64,
        "Ko-CommonGen V2":32.7,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v0.63",
        "Average":36.39,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":45.19,
        "Ko-MMLU":26.92,
        "Ko-TruthfulQA":41.37,
        "Ko-CommonGen V2":35.89,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cepiloth\/ko-llama2-finetune-ex3",
        "Average":36.38,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":41.15,
        "Ko-MMLU":29.59,
        "Ko-TruthfulQA":43.73,
        "Ko-CommonGen V2":33.88,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.9",
        "Average":36.37,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":46.59,
        "Ko-MMLU":27.27,
        "Ko-TruthfulQA":41.36,
        "Ko-CommonGen V2":33.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-v0.3",
        "Average":36.36,
        "Ko-ARC":30.55,
        "Ko-HellaSwag":40.02,
        "Ko-MMLU":32.82,
        "Ko-TruthfulQA":43.47,
        "Ko-CommonGen V2":34.95,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v2.0",
        "Average":36.35,
        "Ko-ARC":32.68,
        "Ko-HellaSwag":45.21,
        "Ko-MMLU":27.39,
        "Ko-TruthfulQA":41.74,
        "Ko-CommonGen V2":34.71,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"42dot\/42dot_LLM-PLM-1.3B",
        "Average":36.33,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":44.73,
        "Ko-MMLU":27.13,
        "Ko-TruthfulQA":40.37,
        "Ko-CommonGen V2":36.84,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"AIFT\/AIFT-instruct-v1.6-42dot_LLM-SFT-1.3B",
        "Average":36.33,
        "Ko-ARC":33.53,
        "Ko-HellaSwag":44.93,
        "Ko-MMLU":24.55,
        "Ko-TruthfulQA":41.31,
        "Ko-CommonGen V2":37.31,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"MrBananaHuman\/polyglot-ko-5.8b",
        "Average":36.3,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":49.85,
        "Ko-MMLU":25.22,
        "Ko-TruthfulQA":41.46,
        "Ko-CommonGen V2":29.99,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Jaewoo1\/Foundation_Platypus_data",
        "Average":36.24,
        "Ko-ARC":31.74,
        "Ko-HellaSwag":41.2,
        "Ko-MMLU":34.86,
        "Ko-TruthfulQA":42.49,
        "Ko-CommonGen V2":30.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v0.73",
        "Average":36.24,
        "Ko-ARC":33.02,
        "Ko-HellaSwag":45.33,
        "Ko-MMLU":27.65,
        "Ko-TruthfulQA":43.55,
        "Ko-CommonGen V2":31.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"DooDooHyun\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.54",
        "Average":36.2,
        "Ko-ARC":32.42,
        "Ko-HellaSwag":46.08,
        "Ko-MMLU":26.05,
        "Ko-TruthfulQA":41.63,
        "Ko-CommonGen V2":34.83,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-v0.4",
        "Average":36.2,
        "Ko-ARC":31.31,
        "Ko-HellaSwag":40.38,
        "Ko-MMLU":31.47,
        "Ko-TruthfulQA":42.28,
        "Ko-CommonGen V2":35.54,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"nayohan\/polyglot-ko-1.3b-Inst",
        "Average":36.19,
        "Ko-ARC":28.92,
        "Ko-HellaSwag":41.67,
        "Ko-MMLU":26.87,
        "Ko-TruthfulQA":40.39,
        "Ko-CommonGen V2":43.09,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.3
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/test_model1",
        "Average":36.18,
        "Ko-ARC":25.43,
        "Ko-HellaSwag":25.02,
        "Ko-MMLU":24.4,
        "Ko-TruthfulQA":49.75,
        "Ko-CommonGen V2":56.32,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-2.0",
        "Model Sha":0.06
    },
    {
        "T":"\u2b55",
        "Model":"sue3489\/test1_kullm-polyglot-5.8b-v2-koalpaca-v1.1b",
        "Average":36.17,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":47.59,
        "Ko-MMLU":25.59,
        "Ko-TruthfulQA":43.18,
        "Ko-CommonGen V2":31.88,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-SFT-1.3B-ao-instruct-all-v1.1",
        "Average":36.16,
        "Ko-ARC":34.3,
        "Ko-HellaSwag":46.03,
        "Ko-MMLU":25.34,
        "Ko-TruthfulQA":41.58,
        "Ko-CommonGen V2":33.53,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"Changgil\/K2S3-SOLAR-11b-v1.0",
        "Average":36.11,
        "Ko-ARC":33.19,
        "Ko-HellaSwag":42.92,
        "Ko-MMLU":28.82,
        "Ko-TruthfulQA":44.59,
        "Ko-CommonGen V2":31.05,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.92
    },
    {
        "T":"\u2b55",
        "Model":"Junmai\/KIT-5.8b",
        "Average":36.05,
        "Ko-ARC":28.41,
        "Ko-HellaSwag":45.23,
        "Ko-MMLU":27.11,
        "Ko-TruthfulQA":40.43,
        "Ko-CommonGen V2":39.08,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":5.8
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/1222-42dot-1.3B-Ko-CoT-Collection-2e-5",
        "Average":36.04,
        "Ko-ARC":34.73,
        "Ko-HellaSwag":44.39,
        "Ko-MMLU":27.55,
        "Ko-TruthfulQA":39.15,
        "Ko-CommonGen V2":34.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v0.61",
        "Average":36.01,
        "Ko-ARC":32.76,
        "Ko-HellaSwag":45.56,
        "Ko-MMLU":27.21,
        "Ko-TruthfulQA":40.63,
        "Ko-CommonGen V2":33.88,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot-LLM-PLM-ao-instruct-all-v0.3",
        "Average":35.96,
        "Ko-ARC":32.59,
        "Ko-HellaSwag":44.94,
        "Ko-MMLU":26.41,
        "Ko-TruthfulQA":39.39,
        "Ko-CommonGen V2":36.48,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot-LLM-PLM-1.3B-instruct-slim-v1.5",
        "Average":35.96,
        "Ko-ARC":31.57,
        "Ko-HellaSwag":43.73,
        "Ko-MMLU":27.27,
        "Ko-TruthfulQA":42.9,
        "Ko-CommonGen V2":34.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"skt\/kogpt2-base-v2",
        "Average":35.96,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":31.04,
        "Ko-MMLU":26.26,
        "Ko-TruthfulQA":45.65,
        "Ko-CommonGen V2":52.89,
        "Type":"pretrained",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"quantumaikr\/KoreanLM-1.5b",
        "Average":35.94,
        "Ko-ARC":27.82,
        "Ko-HellaSwag":26.48,
        "Ko-MMLU":25.76,
        "Ko-TruthfulQA":52.08,
        "Ko-CommonGen V2":47.58,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.28
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-SFT-1.3B-v2.0",
        "Average":35.93,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":46.75,
        "Ko-MMLU":24.95,
        "Ko-TruthfulQA":41.69,
        "Ko-CommonGen V2":31.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"jungyuko\/DAVinCI-42dot_LLM-PLM-1.3B-v0.71",
        "Average":35.9,
        "Ko-ARC":31.74,
        "Ko-HellaSwag":45.22,
        "Ko-MMLU":27.44,
        "Ko-TruthfulQA":41.46,
        "Ko-CommonGen V2":33.65,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"jiwoochris\/polyglot_350",
        "Average":35.89,
        "Ko-ARC":31.74,
        "Ko-HellaSwag":47.38,
        "Ko-MMLU":27.22,
        "Ko-TruthfulQA":40.64,
        "Ko-CommonGen V2":32.47,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/polyglot-ko-3.8b",
        "Average":35.88,
        "Ko-ARC":30.46,
        "Ko-HellaSwag":44.2,
        "Ko-MMLU":27.21,
        "Ko-TruthfulQA":40.45,
        "Ko-CommonGen V2":37.07,
        "Type":"pretrained",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":3.94
    },
    {
        "T":"\u2b55",
        "Model":"tlphams\/gollm-12.8b-instruct-v2.3",
        "Average":35.86,
        "Ko-ARC":29.61,
        "Ko-HellaSwag":42.99,
        "Ko-MMLU":26.88,
        "Ko-TruthfulQA":38.71,
        "Ko-CommonGen V2":41.09,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"leeebs\/llama2-ndap-10-7b",
        "Average":35.85,
        "Ko-ARC":35.75,
        "Ko-HellaSwag":48.0,
        "Ko-MMLU":25.33,
        "Ko-TruthfulQA":38.54,
        "Ko-CommonGen V2":31.64,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"amphora\/small-instruct",
        "Average":35.84,
        "Ko-ARC":32.76,
        "Ko-HellaSwag":43.14,
        "Ko-MMLU":26.0,
        "Ko-TruthfulQA":41.52,
        "Ko-CommonGen V2":35.77,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DILAB-HYU\/koquality-polyglot-1.3b",
        "Average":35.83,
        "Ko-ARC":28.92,
        "Ko-HellaSwag":41.83,
        "Ko-MMLU":26.29,
        "Ko-TruthfulQA":41.35,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.3
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot-LLM-PLM-1.3B-ao-instruct-all-v0.2",
        "Average":35.82,
        "Ko-ARC":32.34,
        "Ko-HellaSwag":44.86,
        "Ko-MMLU":25.07,
        "Ko-TruthfulQA":39.88,
        "Ko-CommonGen V2":36.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-PLM-1.3B-v1.0",
        "Average":35.81,
        "Ko-ARC":32.08,
        "Ko-HellaSwag":45.48,
        "Ko-MMLU":26.4,
        "Ko-TruthfulQA":41.8,
        "Ko-CommonGen V2":33.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"chahyunmook\/42dot_law",
        "Average":35.81,
        "Ko-ARC":32.0,
        "Ko-HellaSwag":44.03,
        "Ko-MMLU":26.12,
        "Ko-TruthfulQA":42.42,
        "Ko-CommonGen V2":34.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"kimjaewon\/open-llama-2-ko-7b-kullm",
        "Average":35.79,
        "Ko-ARC":30.29,
        "Ko-HellaSwag":37.5,
        "Ko-MMLU":25.46,
        "Ko-TruthfulQA":42.11,
        "Ko-CommonGen V2":43.57,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"Jaewoo1\/KoT-Platypus2_foundation",
        "Average":35.79,
        "Ko-ARC":33.19,
        "Ko-HellaSwag":44.72,
        "Ko-MMLU":30.53,
        "Ko-TruthfulQA":42.97,
        "Ko-CommonGen V2":27.51,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MarkrAI\/kyujin-CoTy-platypus-ko-12.8b",
        "Average":35.78,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":49.11,
        "Ko-MMLU":25.68,
        "Ko-TruthfulQA":37.59,
        "Ko-CommonGen V2":31.52,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.2",
        "Average":35.77,
        "Ko-ARC":30.12,
        "Ko-HellaSwag":41.76,
        "Ko-MMLU":25.41,
        "Ko-TruthfulQA":40.81,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-V2",
        "Average":35.76,
        "Ko-ARC":24.32,
        "Ko-HellaSwag":25.42,
        "Ko-MMLU":23.39,
        "Ko-TruthfulQA":49.93,
        "Ko-CommonGen V2":55.73,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.04
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gemmathon\/test-twk-last",
        "Average":35.74,
        "Ko-ARC":34.56,
        "Ko-HellaSwag":42.14,
        "Ko-MMLU":30.6,
        "Ko-TruthfulQA":39.54,
        "Ko-CommonGen V2":31.88,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter2.1",
        "Average":35.68,
        "Ko-ARC":34.98,
        "Ko-HellaSwag":45.66,
        "Ko-MMLU":28.82,
        "Ko-TruthfulQA":40.83,
        "Ko-CommonGen V2":28.1,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"beomi\/KoAlpaca-KoRWKV-1.5B",
        "Average":35.66,
        "Ko-ARC":26.02,
        "Ko-HellaSwag":30.85,
        "Ko-MMLU":23.26,
        "Ko-TruthfulQA":47.65,
        "Ko-CommonGen V2":50.53,
        "Type":"instruction-tuned",
        "Precision":"RwkvForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.5
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.6",
        "Average":35.64,
        "Ko-ARC":29.52,
        "Ko-HellaSwag":41.92,
        "Ko-MMLU":25.35,
        "Ko-TruthfulQA":40.66,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"tlphams\/gollm-instruct-all-in-one-v1",
        "Average":35.62,
        "Ko-ARC":31.57,
        "Ko-HellaSwag":43.18,
        "Ko-MMLU":26.17,
        "Ko-TruthfulQA":40.48,
        "Ko-CommonGen V2":36.72,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"chahyunmook\/42dot-test-upload",
        "Average":35.6,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":44.89,
        "Ko-MMLU":27.19,
        "Ko-TruthfulQA":39.75,
        "Ko-CommonGen V2":32.23,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/llama-2-ko-7b-chat",
        "Average":35.59,
        "Ko-ARC":34.73,
        "Ko-HellaSwag":47.23,
        "Ko-MMLU":27.63,
        "Ko-TruthfulQA":39.46,
        "Ko-CommonGen V2":28.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/polyglot-ko-3.8b-chat",
        "Average":35.59,
        "Ko-ARC":30.89,
        "Ko-HellaSwag":43.97,
        "Ko-MMLU":26.18,
        "Ko-TruthfulQA":42.82,
        "Ko-CommonGen V2":34.12,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":3.81
    },
    {
        "T":"\u2b55",
        "Model":"MNCJihun\/Mistral-7B-eng-kor-cot-combined",
        "Average":35.59,
        "Ko-ARC":33.45,
        "Ko-HellaSwag":42.68,
        "Ko-MMLU":33.3,
        "Ko-TruthfulQA":46.56,
        "Ko-CommonGen V2":21.96,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.4",
        "Average":35.57,
        "Ko-ARC":32.17,
        "Ko-HellaSwag":46.02,
        "Ko-MMLU":25.03,
        "Ko-TruthfulQA":40.15,
        "Ko-CommonGen V2":34.47,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"heegyu\/kogpt-j-base",
        "Average":35.56,
        "Ko-ARC":24.57,
        "Ko-HellaSwag":32.1,
        "Ko-MMLU":25.69,
        "Ko-TruthfulQA":46.67,
        "Ko-CommonGen V2":48.76,
        "Type":"pretrained",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/polyglot-ko-5.8b-chat",
        "Average":35.53,
        "Ko-ARC":31.66,
        "Ko-HellaSwag":45.22,
        "Ko-MMLU":26.39,
        "Ko-TruthfulQA":40.28,
        "Ko-CommonGen V2":34.12,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":5.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"metterian\/llama-2-ko-7b-pt",
        "Average":35.51,
        "Ko-ARC":31.23,
        "Ko-HellaSwag":41.57,
        "Ko-MMLU":27.0,
        "Ko-TruthfulQA":40.46,
        "Ko-CommonGen V2":37.31,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":6.72
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.4",
        "Average":35.48,
        "Ko-ARC":30.89,
        "Ko-HellaSwag":42.06,
        "Ko-MMLU":25.63,
        "Ko-TruthfulQA":41.41,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"leo911kim\/Exodia-kor-7B-v2",
        "Average":35.44,
        "Ko-ARC":31.23,
        "Ko-HellaSwag":45.22,
        "Ko-MMLU":32.18,
        "Ko-TruthfulQA":38.34,
        "Ko-CommonGen V2":30.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"leo911kim\/Exodia-kor-7b-v2",
        "Average":35.44,
        "Ko-ARC":31.23,
        "Ko-HellaSwag":45.22,
        "Ko-MMLU":32.18,
        "Ko-TruthfulQA":38.34,
        "Ko-CommonGen V2":30.22,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/TinyWand-SFT",
        "Average":35.42,
        "Ko-ARC":30.8,
        "Ko-HellaSwag":40.53,
        "Ko-MMLU":25.79,
        "Ko-TruthfulQA":45.65,
        "Ko-CommonGen V2":34.36,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.63
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.52",
        "Average":35.42,
        "Ko-ARC":32.25,
        "Ko-HellaSwag":46.42,
        "Ko-MMLU":26.43,
        "Ko-TruthfulQA":41.09,
        "Ko-CommonGen V2":30.93,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"GUSSSSSSSSSSS\/polyglot-ko-12.8b-instruction",
        "Average":35.41,
        "Ko-ARC":28.58,
        "Ko-HellaSwag":44.2,
        "Ko-MMLU":24.72,
        "Ko-TruthfulQA":41.07,
        "Ko-CommonGen V2":38.49,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"leo911kim\/Exodia-kor-7b",
        "Average":35.39,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":48.48,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":39.31,
        "Ko-CommonGen V2":30.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexS-10.7B-v0.1",
        "Average":35.39,
        "Ko-ARC":28.84,
        "Ko-HellaSwag":39.79,
        "Ko-MMLU":35.98,
        "Ko-TruthfulQA":44.72,
        "Ko-CommonGen V2":27.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"URP\/urllm-ko-7b",
        "Average":35.36,
        "Ko-ARC":32.42,
        "Ko-HellaSwag":43.12,
        "Ko-MMLU":26.71,
        "Ko-TruthfulQA":44.43,
        "Ko-CommonGen V2":30.11,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":6.9
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"MrBananaHuman\/kogpt2_small",
        "Average":35.35,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":28.86,
        "Ko-MMLU":25.4,
        "Ko-TruthfulQA":48.69,
        "Ko-CommonGen V2":49.82,
        "Type":"pretrained",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.1",
        "Average":35.35,
        "Ko-ARC":28.41,
        "Ko-HellaSwag":41.92,
        "Ko-MMLU":25.94,
        "Ko-TruthfulQA":41.74,
        "Ko-CommonGen V2":38.72,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"ITT-AF\/ITT-42dot_LLM-SFT-1.3B-v3.0",
        "Average":35.31,
        "Ko-ARC":33.96,
        "Ko-HellaSwag":46.27,
        "Ko-MMLU":25.39,
        "Ko-TruthfulQA":41.07,
        "Ko-CommonGen V2":29.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.3",
        "Average":35.21,
        "Ko-ARC":30.8,
        "Ko-HellaSwag":41.95,
        "Ko-MMLU":25.33,
        "Ko-TruthfulQA":40.32,
        "Ko-CommonGen V2":37.66,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-V4",
        "Average":35.19,
        "Ko-ARC":23.63,
        "Ko-HellaSwag":24.98,
        "Ko-MMLU":22.95,
        "Ko-TruthfulQA":49.62,
        "Ko-CommonGen V2":54.78,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.04
    },
    {
        "T":"\u2b55",
        "Model":"tlphams\/gollm-12.8b-instruct-v2.1",
        "Average":35.14,
        "Ko-ARC":29.69,
        "Ko-HellaSwag":41.8,
        "Ko-MMLU":25.71,
        "Ko-TruthfulQA":38.97,
        "Ko-CommonGen V2":39.55,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\u2b55",
        "Model":"chahyunmook\/42dot_label",
        "Average":35.08,
        "Ko-ARC":32.85,
        "Ko-HellaSwag":44.66,
        "Ko-MMLU":27.73,
        "Ko-TruthfulQA":43.24,
        "Ko-CommonGen V2":26.92,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-SFT-1.3B-ao-instruct-all-v0.9",
        "Average":35.08,
        "Ko-ARC":33.7,
        "Ko-HellaSwag":46.96,
        "Ko-MMLU":26.38,
        "Ko-TruthfulQA":41.66,
        "Ko-CommonGen V2":26.68,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"BM-K\/polyglot-ko-1.3b-it-v1.0",
        "Average":35.07,
        "Ko-ARC":27.73,
        "Ko-HellaSwag":41.59,
        "Ko-MMLU":25.5,
        "Ko-TruthfulQA":41.34,
        "Ko-CommonGen V2":39.2,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/LIMA2-7b-hf",
        "Average":35.02,
        "Ko-ARC":30.46,
        "Ko-HellaSwag":40.1,
        "Ko-MMLU":29.05,
        "Ko-TruthfulQA":45.64,
        "Ko-CommonGen V2":29.87,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"Nara-Lab\/nallm-polyglot-ko-3.8b-base",
        "Average":35.02,
        "Ko-ARC":32.34,
        "Ko-HellaSwag":45.73,
        "Ko-MMLU":24.51,
        "Ko-TruthfulQA":41.45,
        "Ko-CommonGen V2":31.05,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":3.8
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.5",
        "Average":35.01,
        "Ko-ARC":32.34,
        "Ko-HellaSwag":46.51,
        "Ko-MMLU":25.17,
        "Ko-TruthfulQA":40.7,
        "Ko-CommonGen V2":30.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"quantumaikr\/KoreanLM",
        "Average":34.92,
        "Ko-ARC":30.12,
        "Ko-HellaSwag":37.39,
        "Ko-MMLU":27.74,
        "Ko-TruthfulQA":42.26,
        "Ko-CommonGen V2":37.07,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/koalpaca-355m",
        "Average":34.85,
        "Ko-ARC":26.88,
        "Ko-HellaSwag":34.58,
        "Ko-MMLU":26.43,
        "Ko-TruthfulQA":42.81,
        "Ko-CommonGen V2":43.57,
        "Type":"instruction-tuned",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.36
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Jaewoo1\/Llama2-7B-Blend-3rd-dup-Active-LoRA",
        "Average":34.85,
        "Ko-ARC":30.03,
        "Ko-HellaSwag":38.54,
        "Ko-MMLU":34.45,
        "Ko-TruthfulQA":41.97,
        "Ko-CommonGen V2":29.28,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"maywell\/TinyWand-DPO",
        "Average":34.79,
        "Ko-ARC":30.97,
        "Ko-HellaSwag":40.45,
        "Ko-MMLU":25.77,
        "Ko-TruthfulQA":47.57,
        "Ko-CommonGen V2":29.16,
        "Type":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.63
    },
    {
        "T":"\u2b55",
        "Model":"Jaewoo1\/Platypus7B_Follow_FT",
        "Average":34.77,
        "Ko-ARC":26.54,
        "Ko-HellaSwag":36.68,
        "Ko-MMLU":26.48,
        "Ko-TruthfulQA":47.56,
        "Ko-CommonGen V2":36.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"quantumaikr\/KoreanLM-3B",
        "Average":34.7,
        "Ko-ARC":24.49,
        "Ko-HellaSwag":27.75,
        "Ko-MMLU":25.34,
        "Ko-TruthfulQA":48.22,
        "Ko-CommonGen V2":47.7,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":2.83
    },
    {
        "T":"\u2b55",
        "Model":"FINDA-FIT\/llama-r",
        "Average":34.68,
        "Ko-ARC":26.37,
        "Ko-HellaSwag":27.92,
        "Ko-MMLU":26.31,
        "Ko-TruthfulQA":54.06,
        "Ko-CommonGen V2":38.72,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"FINDA-FIT\/llama-2-ko-plain",
        "Average":34.61,
        "Ko-ARC":26.37,
        "Ko-HellaSwag":27.88,
        "Ko-MMLU":26.52,
        "Ko-TruthfulQA":53.68,
        "Ko-CommonGen V2":38.61,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"DopeorNope\/KOAT-5.8b",
        "Average":34.6,
        "Ko-ARC":30.72,
        "Ko-HellaSwag":41.54,
        "Ko-MMLU":25.03,
        "Ko-TruthfulQA":41.02,
        "Ko-CommonGen V2":34.71,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":5.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"heegyu\/kogpt-j-350m",
        "Average":34.58,
        "Ko-ARC":25.43,
        "Ko-HellaSwag":34.3,
        "Ko-MMLU":25.32,
        "Ko-TruthfulQA":45.73,
        "Ko-CommonGen V2":42.15,
        "Type":"pretrained",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.35
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"heegyu\/ajoublue-gpt2-medium",
        "Average":34.51,
        "Ko-ARC":25.43,
        "Ko-HellaSwag":33.81,
        "Ko-MMLU":26.06,
        "Ko-TruthfulQA":44.41,
        "Ko-CommonGen V2":42.86,
        "Type":"pretrained",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"MNCLLM\/Mistral-7B-KoCot-Platypus-4096",
        "Average":34.51,
        "Ko-ARC":33.87,
        "Ko-HellaSwag":42.13,
        "Ko-MMLU":33.97,
        "Ko-TruthfulQA":44.62,
        "Ko-CommonGen V2":17.95,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/AIFT-polyglot-ko-1.3b-ao-instruct-v0.91",
        "Average":34.5,
        "Ko-ARC":29.61,
        "Ko-HellaSwag":41.82,
        "Ko-MMLU":25.25,
        "Ko-TruthfulQA":42.17,
        "Ko-CommonGen V2":33.65,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.33
    },
    {
        "T":"\u2b55",
        "Model":"blueapple8259\/ANHSY_test2",
        "Average":34.45,
        "Ko-ARC":24.4,
        "Ko-HellaSwag":32.77,
        "Ko-MMLU":25.24,
        "Ko-TruthfulQA":44.75,
        "Ko-CommonGen V2":45.1,
        "Type":"instruction-tuned",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.16
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"skt\/ko-gpt-trinity-1.2B-v0.5",
        "Average":34.45,
        "Ko-ARC":26.88,
        "Ko-HellaSwag":37.36,
        "Ko-MMLU":25.87,
        "Ko-TruthfulQA":42.69,
        "Ko-CommonGen V2":39.43,
        "Type":"pretrained",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":1.2
    },
    {
        "T":"\u2b55",
        "Model":"blueapple8259\/ANHSY_test",
        "Average":34.42,
        "Ko-ARC":25.17,
        "Ko-HellaSwag":32.82,
        "Ko-MMLU":25.65,
        "Ko-TruthfulQA":44.2,
        "Ko-CommonGen V2":44.27,
        "Type":"instruction-tuned",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.16
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-v5-c",
        "Average":34.42,
        "Ko-ARC":25.26,
        "Ko-HellaSwag":28.3,
        "Ko-MMLU":24.81,
        "Ko-TruthfulQA":47.45,
        "Ko-CommonGen V2":46.28,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.04
    },
    {
        "T":"\u2b55",
        "Model":"jb723\/cross_lingual_epoch2",
        "Average":34.4,
        "Ko-ARC":28.41,
        "Ko-HellaSwag":29.11,
        "Ko-MMLU":28.88,
        "Ko-TruthfulQA":49.49,
        "Ko-CommonGen V2":36.13,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"FINDA-FIT\/llama-ko-7b",
        "Average":34.37,
        "Ko-ARC":26.54,
        "Ko-HellaSwag":27.82,
        "Ko-MMLU":26.22,
        "Ko-TruthfulQA":53.86,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"blueapple8259\/ANHSY_0.1",
        "Average":34.36,
        "Ko-ARC":25.94,
        "Ko-HellaSwag":32.42,
        "Ko-MMLU":25.32,
        "Ko-TruthfulQA":43.5,
        "Ko-CommonGen V2":44.63,
        "Type":"instruction-tuned",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Model Sha":0.16
    },
    {
        "T":"\u2b55",
        "Model":"FINDA-FIT\/llama-m",
        "Average":34.35,
        "Ko-ARC":26.19,
        "Ko-HellaSwag":27.76,
        "Ko-MMLU":26.09,
        "Ko-TruthfulQA":53.82,
        "Ko-CommonGen V2":37.9,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"heegyu\/ajoublue-gpt2-base",
        "Average":34.28,
        "Ko-ARC":25.0,
        "Ko-HellaSwag":31.88,
        "Ko-MMLU":27.36,
        "Ko-TruthfulQA":46.79,
        "Ko-CommonGen V2":40.38,
        "Type":"pretrained",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"blueapple8259\/ANHSY_half_0.2",
        "Average":34.27,
        "Ko-ARC":25.77,
        "Ko-HellaSwag":32.97,
        "Ko-MMLU":26.37,
        "Ko-TruthfulQA":43.39,
        "Ko-CommonGen V2":42.86,
        "Type":"instruction-tuned",
        "Precision":"GPTJForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.16
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"heegyu\/42dot_LLM-PLM-1.3B-mt-steps-50000",
        "Average":34.25,
        "Ko-ARC":32.17,
        "Ko-HellaSwag":41.88,
        "Ko-MMLU":25.33,
        "Ko-TruthfulQA":40.71,
        "Ko-CommonGen V2":31.17,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.3
    },
    {
        "T":"\u2b55",
        "Model":"mu0gum\/polyglot-ko-1.3b-slim_orca_10000-epoch2",
        "Average":34.22,
        "Ko-ARC":26.71,
        "Ko-HellaSwag":40.59,
        "Ko-MMLU":26.72,
        "Ko-TruthfulQA":40.59,
        "Ko-CommonGen V2":36.48,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.33
    },
    {
        "T":"?",
        "Model":"EleutherAI\/polyglot-ko-1.3b",
        "Average":34.14,
        "Ko-ARC":28.16,
        "Ko-HellaSwag":41.36,
        "Ko-MMLU":26.04,
        "Ko-TruthfulQA":41.17,
        "Ko-CommonGen V2":34.0,
        "Type":"",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Korabbit\/llama-2-ko-7b",
        "Average":34.12,
        "Ko-ARC":27.13,
        "Ko-HellaSwag":33.6,
        "Ko-MMLU":31.27,
        "Ko-TruthfulQA":46.26,
        "Ko-CommonGen V2":32.35,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"JYKIM-AI\/Mistral-7B-SFT",
        "Average":34.12,
        "Ko-ARC":31.14,
        "Ko-HellaSwag":40.29,
        "Ko-MMLU":28.29,
        "Ko-TruthfulQA":43.73,
        "Ko-CommonGen V2":27.15,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"JYKIM-AI\/Mistral-7B-SFT-v0.1",
        "Average":34.12,
        "Ko-ARC":31.14,
        "Ko-HellaSwag":40.29,
        "Ko-MMLU":28.29,
        "Ko-TruthfulQA":43.73,
        "Ko-CommonGen V2":27.15,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"caisarl76\/Mistral-7B-Openorca-cot-2157",
        "Average":34.11,
        "Ko-ARC":29.61,
        "Ko-HellaSwag":30.87,
        "Ko-MMLU":32.98,
        "Ko-TruthfulQA":48.75,
        "Ko-CommonGen V2":28.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-13b",
        "Average":34.07,
        "Ko-ARC":25.94,
        "Ko-HellaSwag":35.71,
        "Ko-MMLU":30.76,
        "Ko-TruthfulQA":43.56,
        "Ko-CommonGen V2":34.36,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":13.02
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo",
        "Average":34.04,
        "Ko-ARC":27.22,
        "Ko-HellaSwag":25.14,
        "Ko-MMLU":27.07,
        "Ko-TruthfulQA":51.11,
        "Ko-CommonGen V2":39.67,
        "Type":"pretrained",
        "Precision":"MistralModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.03
    },
    {
        "T":"\u2b55",
        "Model":"jylee420\/gemma-2b-data-std-v0",
        "Average":34.04,
        "Ko-ARC":29.35,
        "Ko-HellaSwag":36.89,
        "Ko-MMLU":30.74,
        "Ko-TruthfulQA":45.25,
        "Ko-CommonGen V2":27.98,
        "Type":"instruction-tuned",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sel303\/gpt2-ko-base_3",
        "Average":34.01,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":27.66,
        "Ko-MMLU":25.51,
        "Ko-TruthfulQA":50.37,
        "Ko-CommonGen V2":42.5,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.14
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-SOLAR-10.7B_01",
        "Average":33.93,
        "Ko-ARC":26.28,
        "Ko-HellaSwag":28.36,
        "Ko-MMLU":23.27,
        "Ko-TruthfulQA":48.89,
        "Ko-CommonGen V2":42.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"Nara-Lab\/nallm-bart",
        "Average":33.9,
        "Ko-ARC":25.94,
        "Ko-HellaSwag":25.26,
        "Ko-MMLU":25.55,
        "Ko-TruthfulQA":50.34,
        "Ko-CommonGen V2":42.38,
        "Type":"instruction-tuned",
        "Precision":"BartForConditionalGeneration",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/polyglot-ko-1.3b-chat",
        "Average":33.85,
        "Ko-ARC":27.56,
        "Ko-HellaSwag":39.95,
        "Ko-MMLU":26.24,
        "Ko-TruthfulQA":41.05,
        "Ko-CommonGen V2":34.47,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":1.33
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Mistral-ko-7B-v0.1",
        "Average":33.85,
        "Ko-ARC":31.14,
        "Ko-HellaSwag":31.43,
        "Ko-MMLU":33.52,
        "Ko-TruthfulQA":42.33,
        "Ko-CommonGen V2":30.81,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"beomi\/KoAlpaca-Polyglot-5.8B",
        "Average":33.76,
        "Ko-ARC":30.38,
        "Ko-HellaSwag":41.47,
        "Ko-MMLU":25.15,
        "Ko-TruthfulQA":40.04,
        "Ko-CommonGen V2":31.76,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/SmallKo",
        "Average":33.74,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":28.46,
        "Ko-MMLU":25.86,
        "Ko-TruthfulQA":47.83,
        "Ko-CommonGen V2":40.85,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.19
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKoWiki-v1",
        "Average":33.73,
        "Ko-ARC":23.21,
        "Ko-HellaSwag":25.14,
        "Ko-MMLU":24.39,
        "Ko-TruthfulQA":48.11,
        "Ko-CommonGen V2":47.82,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.04
    },
    {
        "T":"\u2b55",
        "Model":"fiveflow\/kolong-llama-v0.1",
        "Average":33.52,
        "Ko-ARC":32.08,
        "Ko-HellaSwag":45.72,
        "Ko-MMLU":27.97,
        "Ko-TruthfulQA":37.75,
        "Ko-CommonGen V2":24.09,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cepiloth\/ko-llama2-finetune-ex4",
        "Average":33.48,
        "Ko-ARC":31.06,
        "Ko-HellaSwag":37.58,
        "Ko-MMLU":26.74,
        "Ko-TruthfulQA":42.97,
        "Ko-CommonGen V2":29.04,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-v5-b",
        "Average":33.43,
        "Ko-ARC":24.4,
        "Ko-HellaSwag":28.1,
        "Ko-MMLU":23.52,
        "Ko-TruthfulQA":45.68,
        "Ko-CommonGen V2":45.45,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.04
    },
    {
        "T":"\u2b55",
        "Model":"NotoriousH2\/42dot_1.3B_notolab",
        "Average":33.43,
        "Ko-ARC":26.02,
        "Ko-HellaSwag":32.79,
        "Ko-MMLU":25.45,
        "Ko-TruthfulQA":44.86,
        "Ko-CommonGen V2":38.02,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.44
    },
    {
        "T":"\u2b55",
        "Model":"inoutro\/phi2-ko-instruction-tune",
        "Average":33.37,
        "Ko-ARC":31.57,
        "Ko-HellaSwag":37.05,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":41.3,
        "Ko-CommonGen V2":31.52,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-3.0",
        "Model Sha":2.86
    },
    {
        "T":"\u2b55",
        "Model":"kmyoon\/mzllm-solar-10.7B",
        "Average":33.29,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":31.62,
        "Ko-MMLU":23.76,
        "Ko-TruthfulQA":47.49,
        "Ko-CommonGen V2":37.9,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.81
    },
    {
        "T":"\u2b55",
        "Model":"norispace\/marcoroni-openorca",
        "Average":33.29,
        "Ko-ARC":24.74,
        "Ko-HellaSwag":26.13,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":51.72,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Nara-Lab\/nallm-polyglot-ko-1.3b-base",
        "Average":33.27,
        "Ko-ARC":30.55,
        "Ko-HellaSwag":40.32,
        "Ko-MMLU":25.43,
        "Ko-TruthfulQA":41.02,
        "Ko-CommonGen V2":29.04,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":1.3
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-7b",
        "Average":33.26,
        "Ko-ARC":25.26,
        "Ko-HellaSwag":33.44,
        "Ko-MMLU":26.47,
        "Ko-TruthfulQA":44.06,
        "Ko-CommonGen V2":37.07,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":6.74
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Korabbit\/llama-2-ko-7b-pru",
        "Average":33.26,
        "Ko-ARC":27.9,
        "Ko-HellaSwag":32.1,
        "Ko-MMLU":27.72,
        "Ko-TruthfulQA":45.98,
        "Ko-CommonGen V2":32.59,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-13B_02",
        "Average":33.12,
        "Ko-ARC":26.71,
        "Ko-HellaSwag":25.12,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":50.28,
        "Ko-CommonGen V2":40.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":13.16
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.7B-qlora-v1.2",
        "Average":33.06,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":25.45,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":49.15,
        "Ko-CommonGen V2":41.91,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.7
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/LIMA-13b-hf",
        "Average":33.05,
        "Ko-ARC":26.02,
        "Ko-HellaSwag":35.58,
        "Ko-MMLU":29.91,
        "Ko-TruthfulQA":43.3,
        "Ko-CommonGen V2":30.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":13.0
    },
    {
        "T":"\u2b55",
        "Model":"giprime\/OOM-7B_02",
        "Average":32.98,
        "Ko-ARC":26.11,
        "Ko-HellaSwag":25.17,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":49.77,
        "Ko-CommonGen V2":40.73,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":6.86
    },
    {
        "T":"\u2b55",
        "Model":"rrw-x2\/KoSOLAR-10.7B-qlora-v1.2.1",
        "Average":32.97,
        "Ko-ARC":25.6,
        "Ko-HellaSwag":25.45,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":49.14,
        "Ko-CommonGen V2":41.56,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.7
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/kollama-13b",
        "Average":32.86,
        "Ko-ARC":24.06,
        "Ko-HellaSwag":29.83,
        "Ko-MMLU":26.33,
        "Ko-TruthfulQA":47.02,
        "Ko-CommonGen V2":37.07,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":13.22
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"DopeorNope\/mistralopithecus-v2-dpo-7b",
        "Average":32.77,
        "Ko-ARC":25.26,
        "Ko-HellaSwag":24.58,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":49.65,
        "Ko-CommonGen V2":38.96,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"Surromind\/gemma-2b-v0.1",
        "Average":32.71,
        "Ko-ARC":30.12,
        "Ko-HellaSwag":35.73,
        "Ko-MMLU":32.45,
        "Ko-TruthfulQA":42.6,
        "Ko-CommonGen V2":22.67,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\u2b55",
        "Model":"jb723\/LLaMA2_crosslingual_transfer_1",
        "Average":32.67,
        "Ko-ARC":26.88,
        "Ko-HellaSwag":29.21,
        "Ko-MMLU":25.8,
        "Ko-TruthfulQA":49.33,
        "Ko-CommonGen V2":32.11,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"blueapple8259\/TinyKo-v5-a",
        "Average":32.66,
        "Ko-ARC":24.66,
        "Ko-HellaSwag":28.0,
        "Ko-MMLU":22.89,
        "Ko-TruthfulQA":45.0,
        "Ko-CommonGen V2":42.74,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":0.04
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/kodialogpt-v1",
        "Average":32.61,
        "Ko-ARC":23.12,
        "Ko-HellaSwag":25.6,
        "Ko-MMLU":25.45,
        "Ko-TruthfulQA":52.04,
        "Ko-CommonGen V2":36.84,
        "Type":"instruction-tuned",
        "Precision":"GPT2LMHeadModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"OMK510\/ko-llama2-toy",
        "Average":32.61,
        "Ko-ARC":27.47,
        "Ko-HellaSwag":26.05,
        "Ko-MMLU":26.62,
        "Ko-TruthfulQA":52.45,
        "Ko-CommonGen V2":30.46,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-715k-1.5T",
        "Average":32.43,
        "Ko-ARC":25.6,
        "Ko-HellaSwag":31.51,
        "Ko-MMLU":23.7,
        "Ko-TruthfulQA":50.3,
        "Ko-CommonGen V2":31.05,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.1
    },
    {
        "T":"\u2b55",
        "Model":"fiveflow\/koMistral-v0.1-neftune",
        "Average":32.37,
        "Ko-ARC":23.21,
        "Ko-HellaSwag":28.59,
        "Ko-MMLU":23.69,
        "Ko-TruthfulQA":46.23,
        "Ko-CommonGen V2":40.14,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"jylee420\/gemma-2b-data-std",
        "Average":32.14,
        "Ko-ARC":28.07,
        "Ko-HellaSwag":35.26,
        "Ko-MMLU":27.2,
        "Ko-TruthfulQA":46.79,
        "Ko-CommonGen V2":23.38,
        "Type":"instruction-tuned",
        "Precision":"GemmaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Model Sha":2.51
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"realPCH\/240103_llama_test_2",
        "Average":32.12,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":32.55,
        "Ko-MMLU":26.59,
        "Ko-TruthfulQA":48.99,
        "Ko-CommonGen V2":26.8,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.1
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Average":32.12,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":32.55,
        "Ko-MMLU":26.59,
        "Ko-TruthfulQA":48.99,
        "Ko-CommonGen V2":26.8,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":1.1
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"realPCH\/240103_llama_test_3",
        "Average":32.12,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":32.55,
        "Ko-MMLU":26.59,
        "Ko-TruthfulQA":48.99,
        "Ko-CommonGen V2":26.8,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":1.1
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"realPCH\/240103_llama_test_1",
        "Average":32.12,
        "Ko-ARC":25.68,
        "Ko-HellaSwag":32.55,
        "Ko-MMLU":26.59,
        "Ko-TruthfulQA":48.99,
        "Ko-CommonGen V2":26.8,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.1
    },
    {
        "T":"\u2b55",
        "Model":"FINGU-AI\/FinguAI-Chat-v1",
        "Average":31.99,
        "Ko-ARC":25.0,
        "Ko-HellaSwag":30.88,
        "Ko-MMLU":27.83,
        "Ko-TruthfulQA":46.85,
        "Ko-CommonGen V2":29.4,
        "Type":"instruction-tuned",
        "Precision":"Qwen2ForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":0.46
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"DopeorNope\/Mistralopithecus-v0.1-10.7B",
        "Average":31.97,
        "Ko-ARC":22.53,
        "Ko-HellaSwag":28.2,
        "Ko-MMLU":28.45,
        "Ko-TruthfulQA":47.35,
        "Ko-CommonGen V2":33.29,
        "Type":"pretrained",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":10.85
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v1.2",
        "Average":31.92,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":30.69,
        "Ko-MMLU":25.94,
        "Ko-TruthfulQA":46.51,
        "Ko-CommonGen V2":32.47,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/42dot_LLM-PLM-1.3B-mt",
        "Average":31.9,
        "Ko-ARC":26.28,
        "Ko-HellaSwag":37.89,
        "Ko-MMLU":26.62,
        "Ko-TruthfulQA":38.37,
        "Ko-CommonGen V2":30.34,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":1.3
    },
    {
        "T":"\u2b55",
        "Model":"OpenBuddy\/openbuddy-zephyr-7b-v14.1",
        "Average":31.83,
        "Ko-ARC":25.0,
        "Ko-HellaSwag":25.08,
        "Ko-MMLU":32.22,
        "Ko-TruthfulQA":44.26,
        "Ko-CommonGen V2":32.59,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"genne\/otter3.1.3.0",
        "Average":31.72,
        "Ko-ARC":25.0,
        "Ko-HellaSwag":35.63,
        "Ko-MMLU":23.19,
        "Ko-TruthfulQA":49.96,
        "Ko-CommonGen V2":24.79,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"maywell\/Synatra-11B-Tb2M_SM",
        "Average":31.71,
        "Ko-ARC":24.15,
        "Ko-HellaSwag":24.97,
        "Ko-MMLU":24.49,
        "Ko-TruthfulQA":47.52,
        "Ko-CommonGen V2":37.43,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yeen214\/test_llama2_ko_7b",
        "Average":31.71,
        "Ko-ARC":25.77,
        "Ko-HellaSwag":25.32,
        "Ko-MMLU":25.39,
        "Ko-TruthfulQA":49.82,
        "Ko-CommonGen V2":32.23,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"sronger\/ko-llm-llama-2-7b-chat3",
        "Average":31.66,
        "Ko-ARC":24.49,
        "Ko-HellaSwag":24.75,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":50.4,
        "Ko-CommonGen V2":33.29,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.62
    },
    {
        "T":"\u2b55",
        "Model":"Edentns\/DataVortexTL-1.1B-v0.1",
        "Average":31.5,
        "Ko-ARC":25.26,
        "Ko-HellaSwag":33.53,
        "Ko-MMLU":24.56,
        "Ko-TruthfulQA":43.34,
        "Ko-CommonGen V2":30.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Model Sha":1.1
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v1.3",
        "Average":31.45,
        "Ko-ARC":24.83,
        "Ko-HellaSwag":31.35,
        "Ko-MMLU":25.91,
        "Ko-TruthfulQA":46.01,
        "Ko-CommonGen V2":29.16,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"sronger\/ko-llm-llama-2-7b-chat2",
        "Average":31.38,
        "Ko-ARC":23.55,
        "Ko-HellaSwag":24.51,
        "Ko-MMLU":25.41,
        "Ko-TruthfulQA":50.52,
        "Ko-CommonGen V2":32.94,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.62
    },
    {
        "T":"\u2b55",
        "Model":"sronger\/ko-llm-llama-2-7b-LoRA-IA3",
        "Average":31.32,
        "Ko-ARC":24.57,
        "Ko-HellaSwag":24.89,
        "Ko-MMLU":24.38,
        "Ko-TruthfulQA":49.58,
        "Ko-CommonGen V2":33.18,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.63
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/WizardVicuna-open-llama-3b-v2",
        "Average":31.3,
        "Ko-ARC":25.77,
        "Ko-HellaSwag":30.61,
        "Ko-MMLU":25.14,
        "Ko-TruthfulQA":46.19,
        "Ko-CommonGen V2":28.81,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":3.43
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AtAndDev\/ShortKingv0.1",
        "Average":31.29,
        "Ko-ARC":24.83,
        "Ko-HellaSwag":29.88,
        "Ko-MMLU":25.02,
        "Ko-TruthfulQA":49.22,
        "Ko-CommonGen V2":27.51,
        "Type":"pretrained",
        "Precision":"GPTNeoXForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":1.42
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v1.1",
        "Average":31.24,
        "Ko-ARC":25.34,
        "Ko-HellaSwag":29.9,
        "Ko-MMLU":26.94,
        "Ko-TruthfulQA":45.82,
        "Ko-CommonGen V2":28.22,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"jb723\/3B_test_model",
        "Average":31.2,
        "Ko-ARC":26.28,
        "Ko-HellaSwag":26.03,
        "Ko-MMLU":24.85,
        "Ko-TruthfulQA":50.49,
        "Ko-CommonGen V2":28.34,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":3.52
    },
    {
        "T":"\u2b55",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v17.1-32k",
        "Average":31.18,
        "Ko-ARC":24.74,
        "Ko-HellaSwag":25.19,
        "Ko-MMLU":25.83,
        "Ko-TruthfulQA":48.14,
        "Ko-CommonGen V2":32.0,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.28
    },
    {
        "T":"\u2b55",
        "Model":"sronger\/mistral-ko-llm",
        "Average":31.17,
        "Ko-ARC":24.74,
        "Ko-HellaSwag":24.78,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":48.37,
        "Ko-CommonGen V2":32.59,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.76
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"jin05102518\/Astral-7B-0.5Epoch-Test",
        "Average":31.02,
        "Ko-ARC":25.17,
        "Ko-HellaSwag":29.64,
        "Ko-MMLU":28.81,
        "Ko-TruthfulQA":45.04,
        "Ko-CommonGen V2":26.45,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"leo911kim\/Exodia-7B",
        "Average":30.49,
        "Ko-ARC":23.63,
        "Ko-HellaSwag":29.7,
        "Ko-MMLU":25.47,
        "Ko-TruthfulQA":42.02,
        "Ko-CommonGen V2":31.64,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"eclipsemint\/kollama2-7b-v1",
        "Average":30.41,
        "Ko-ARC":22.78,
        "Ko-HellaSwag":31.01,
        "Ko-MMLU":26.2,
        "Ko-TruthfulQA":44.8,
        "Ko-CommonGen V2":27.27,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"heegyu\/WizardVicuna-3B-0719",
        "Average":30.39,
        "Ko-ARC":22.78,
        "Ko-HellaSwag":30.77,
        "Ko-MMLU":23.99,
        "Ko-TruthfulQA":46.54,
        "Ko-CommonGen V2":27.86,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":3.0
    },
    {
        "T":"\u2b55",
        "Model":"lifelongeek\/ko-7b-ins",
        "Average":30.38,
        "Ko-ARC":23.63,
        "Ko-HellaSwag":24.63,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":49.02,
        "Ko-CommonGen V2":31.52,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"papercat404\/llama-test2-fp16",
        "Average":30.35,
        "Ko-ARC":24.49,
        "Ko-HellaSwag":24.09,
        "Ko-MMLU":23.12,
        "Ko-TruthfulQA":50.44,
        "Ko-CommonGen V2":29.63,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":6.74
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"boracious\/llama-2-7b-test",
        "Average":30.31,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":24.45,
        "Ko-MMLU":24.44,
        "Ko-TruthfulQA":48.36,
        "Ko-CommonGen V2":30.34,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"juengsi\/DT-EQ-SOLAR-10.7B-v0.1",
        "Average":30.29,
        "Ko-ARC":23.55,
        "Ko-HellaSwag":24.88,
        "Ko-MMLU":26.75,
        "Ko-TruthfulQA":49.0,
        "Ko-CommonGen V2":27.27,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Herry443\/Mistral-7B-KNUT-ref-ALL",
        "Average":30.14,
        "Ko-ARC":23.98,
        "Ko-HellaSwag":31.61,
        "Ko-MMLU":27.32,
        "Ko-TruthfulQA":42.75,
        "Ko-CommonGen V2":25.03,
        "Type":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Model Sha":7.24
    },
    {
        "T":"\u2b55",
        "Model":"juengsi\/EVO-SOLAR-10.7B-v0.1",
        "Average":30.04,
        "Ko-ARC":24.06,
        "Ko-HellaSwag":25.41,
        "Ko-MMLU":25.38,
        "Ko-TruthfulQA":49.99,
        "Ko-CommonGen V2":25.38,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.3
    },
    {
        "T":"\u2b55",
        "Model":"juengsi\/DT-SL-MLP-SOLAR-10.7B-v0.1",
        "Average":29.95,
        "Ko-ARC":20.99,
        "Ko-HellaSwag":30.42,
        "Ko-MMLU":27.27,
        "Ko-TruthfulQA":41.42,
        "Ko-CommonGen V2":29.63,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"squarelike\/llama2-ko-medical-7b",
        "Average":29.86,
        "Ko-ARC":23.81,
        "Ko-HellaSwag":25.59,
        "Ko-MMLU":25.42,
        "Ko-TruthfulQA":49.21,
        "Ko-CommonGen V2":25.27,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"juengsi\/DT-SL-SOLAR-10.7B-v0.1",
        "Average":29.82,
        "Ko-ARC":25.77,
        "Ko-HellaSwag":25.02,
        "Ko-MMLU":26.79,
        "Ko-TruthfulQA":47.55,
        "Ko-CommonGen V2":23.97,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"papercat404\/testcat_v0.2",
        "Average":29.81,
        "Ko-ARC":22.87,
        "Ko-HellaSwag":24.79,
        "Ko-MMLU":27.04,
        "Ko-TruthfulQA":46.72,
        "Ko-CommonGen V2":27.63,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Model Sha":10.73
    },
    {
        "T":"\u2b55",
        "Model":"Junmai\/KIT-7b-v2",
        "Average":29.68,
        "Ko-ARC":23.46,
        "Ko-HellaSwag":23.89,
        "Ko-MMLU":26.04,
        "Ko-TruthfulQA":46.32,
        "Ko-CommonGen V2":28.69,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"Junmai\/KIT-7B-v2",
        "Average":29.68,
        "Ko-ARC":23.46,
        "Ko-HellaSwag":23.89,
        "Ko-MMLU":26.04,
        "Ko-TruthfulQA":46.32,
        "Ko-CommonGen V2":28.69,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v1",
        "Average":29.68,
        "Ko-ARC":23.72,
        "Ko-HellaSwag":30.28,
        "Ko-MMLU":26.91,
        "Ko-TruthfulQA":39.73,
        "Ko-CommonGen V2":27.74,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.52
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"peterkang\/mymodel_v2",
        "Average":29.68,
        "Ko-ARC":23.72,
        "Ko-HellaSwag":30.28,
        "Ko-MMLU":26.91,
        "Ko-TruthfulQA":39.73,
        "Ko-CommonGen V2":27.74,
        "Type":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.52
    },
    {
        "T":"\u2b55",
        "Model":"asapppppp\/polyglot_12.8B_lora_finetuning",
        "Average":29.53,
        "Ko-ARC":23.38,
        "Ko-HellaSwag":26.22,
        "Ko-MMLU":27.09,
        "Ko-TruthfulQA":47.01,
        "Ko-CommonGen V2":23.97,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"Junmai\/KIT-7B-v1",
        "Average":29.5,
        "Ko-ARC":23.89,
        "Ko-HellaSwag":23.95,
        "Ko-MMLU":26.21,
        "Ko-TruthfulQA":46.07,
        "Ko-CommonGen V2":27.39,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"jb723\/llama2-ko-7B-model",
        "Average":29.44,
        "Ko-ARC":26.28,
        "Ko-HellaSwag":29.64,
        "Ko-MMLU":28.23,
        "Ko-TruthfulQA":43.44,
        "Ko-CommonGen V2":19.6,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    },
    {
        "T":"\u2b55",
        "Model":"mssongit\/Koala-12.8b-v1",
        "Average":29.33,
        "Ko-ARC":24.32,
        "Ko-HellaSwag":27.11,
        "Ko-MMLU":26.2,
        "Ko-TruthfulQA":46.11,
        "Ko-CommonGen V2":22.9,
        "Type":"instruction-tuned",
        "Precision":"GPTNeoXModel",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Model Sha":12.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"metterian\/llama-2-7b-pt",
        "Average":28.95,
        "Ko-ARC":23.55,
        "Ko-HellaSwag":26.04,
        "Ko-MMLU":23.26,
        "Ko-TruthfulQA":46.52,
        "Ko-CommonGen V2":25.38,
        "Type":"pretrained",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"asapppppp\/kullm-polyglot-12.8b-v2_lora_finetuning",
        "Average":28.91,
        "Ko-ARC":23.72,
        "Ko-HellaSwag":26.35,
        "Ko-MMLU":24.54,
        "Ko-TruthfulQA":46.71,
        "Ko-CommonGen V2":23.26,
        "Type":"instruction-tuned",
        "Precision":"?",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":0.0
    },
    {
        "T":"\u2b55",
        "Model":"OpenBuddy\/openbuddy-llama2-13b-v8.1-fp16",
        "Average":28.67,
        "Ko-ARC":26.02,
        "Ko-HellaSwag":25.17,
        "Ko-MMLU":25.66,
        "Ko-TruthfulQA":44.63,
        "Ko-CommonGen V2":21.84,
        "Type":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"jb723\/LLaMA2-en-ko-7B-model",
        "Average":28.39,
        "Ko-ARC":24.57,
        "Ko-HellaSwag":28.18,
        "Ko-MMLU":26.66,
        "Ko-TruthfulQA":42.92,
        "Ko-CommonGen V2":19.6,
        "Type":"pretrained",
        "Precision":"LlamaForCausalLM",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Model Sha":7.0
    }
]