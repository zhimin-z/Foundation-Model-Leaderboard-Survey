[
    {
        "table_id":18583,
        "row_id":61619,
        "rank":1,
        "Model":"bloom",
        "mlmodel":{
            "last_updated":"2022-09-27T15:58:41.000000+0000",
            "id":9625,
            "url":null
        },
        "method_short":"bloom",
        "method_details":null,
        "mlmodel_short":"bloom",
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-18",
        "metrics":{
            "byte_perplexity":"12.002"
        },
        "raw_metrics":{
            "byte_perplexity":12.002
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":"https:\/\/huggingface.co\/bigscience\/bloom-3b",
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18583,
        "row_id":61759,
        "rank":2,
        "Model":"bloom",
        "mlmodel":{
            "last_updated":"2022-09-27T15:58:41.000000+0000",
            "id":9625,
            "url":null
        },
        "method_short":"bloom",
        "method_details":null,
        "mlmodel_short":"bloom",
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-18",
        "metrics":{
            "byte_perplexity":"12.002"
        },
        "raw_metrics":{
            "byte_perplexity":12.002
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":"https:\/\/huggingface.co\/model-attribution-challenge\/bloom-2b5",
        "tags":[

        ],
        "reports":[

        ]
    }
]