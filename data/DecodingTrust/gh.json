[
    {
        "Model":"Claude",
        "Toxicity":92.11,
        "Stereotype Bias":100.0,
        "Adversarial Robustness":57.98,
        "Out-of-Distribution Robustness":85.77,
        "Robustness to Adversarial Demonstrations":72.97,
        "Privacy":85.35,
        "Machine Ethics":85.17,
        "Fairness":96.81,
        "Overall":84.52
    },
    {
        "Model":"Llama2-7b-chat",
        "Toxicity":80.0,
        "Stereotype Bias":97.6,
        "Adversarial Robustness":51.01,
        "Out-of-Distribution Robustness":75.65,
        "Robustness to Adversarial Demonstrations":55.54,
        "Privacy":97.39,
        "Machine Ethics":40.58,
        "Fairness":100.0,
        "Overall":74.72125
    },
    {
        "Model":"GPT-3.5",
        "Toxicity":47.0,
        "Stereotype Bias":87.0,
        "Adversarial Robustness":56.69,
        "Out-of-Distribution Robustness":73.58,
        "Robustness to Adversarial Demonstrations":81.28,
        "Privacy":70.13,
        "Machine Ethics":86.38,
        "Fairness":77.57,
        "Overall":72.45375
    },
    {
        "Model":"GPT-4",
        "Toxicity":41.0,
        "Stereotype Bias":77.0,
        "Adversarial Robustness":64.04,
        "Out-of-Distribution Robustness":87.55,
        "Robustness to Adversarial Demonstrations":77.94,
        "Privacy":66.11,
        "Machine Ethics":76.6,
        "Fairness":63.67,
        "Overall":69.23875
    },
    {
        "Model":"Tulu-2-13b",
        "Toxicity":44.8,
        "Stereotype Bias":89.33,
        "Adversarial Robustness":43.14,
        "Out-of-Distribution Robustness":70.17,
        "Robustness to Adversarial Demonstrations":71.17,
        "Privacy":78.9,
        "Machine Ethics":36.64,
        "Fairness":97.9,
        "Overall":66.50625
    },
    {
        "Model":"Tulu-2-7b",
        "Toxicity":29.46,
        "Stereotype Bias":96.6,
        "Adversarial Robustness":44.62,
        "Out-of-Distribution Robustness":69.3,
        "Robustness to Adversarial Demonstrations":60.49,
        "Privacy":75.82,
        "Machine Ethics":49.0,
        "Fairness":83.21,
        "Overall":63.5625
    },
    {
        "Model":"Zephyr-7B-beta",
        "Toxicity":31.97,
        "Stereotype Bias":92.6,
        "Adversarial Robustness":26.81,
        "Out-of-Distribution Robustness":65.58,
        "Robustness to Adversarial Demonstrations":68.68,
        "Privacy":84.18,
        "Machine Ethics":41.03,
        "Fairness":95.07,
        "Overall":63.24
    },
    {
        "Model":"MPT",
        "Toxicity":40.0,
        "Stereotype Bias":84.6,
        "Adversarial Robustness":46.2,
        "Out-of-Distribution Robustness":64.26,
        "Robustness to Adversarial Demonstrations":58.25,
        "Privacy":78.93,
        "Machine Ethics":26.11,
        "Fairness":100.0,
        "Overall":62.29375
    },
    {
        "Model":"Vicuna",
        "Toxicity":28.0,
        "Stereotype Bias":81.0,
        "Adversarial Robustness":52.16,
        "Out-of-Distribution Robustness":59.1,
        "Robustness to Adversarial Demonstrations":57.99,
        "Privacy":72.96,
        "Machine Ethics":48.22,
        "Fairness":85.53,
        "Overall":60.62
    },
    {
        "Model":"Falcon",
        "Toxicity":39.0,
        "Stereotype Bias":87.0,
        "Adversarial Robustness":43.98,
        "Out-of-Distribution Robustness":51.45,
        "Robustness to Adversarial Demonstrations":33.95,
        "Privacy":70.26,
        "Machine Ethics":50.28,
        "Fairness":100.0,
        "Overall":59.49
    },
    {
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Toxicity":30.12,
        "Stereotype Bias":79.33,
        "Adversarial Robustness":47.23,
        "Out-of-Distribution Robustness":73.4,
        "Robustness to Adversarial Demonstrations":62.15,
        "Privacy":77.36,
        "Machine Ethics":34.21,
        "Fairness":66.76,
        "Overall":58.82
    },
    {
        "Model":"RedPajama",
        "Toxicity":18.0,
        "Stereotype Bias":73.0,
        "Adversarial Robustness":44.81,
        "Out-of-Distribution Robustness":54.21,
        "Robustness to Adversarial Demonstrations":58.51,
        "Privacy":76.64,
        "Machine Ethics":27.49,
        "Fairness":100.0,
        "Overall":56.5825
    },
    {
        "Model":"Alpaca",
        "Toxicity":22.0,
        "Stereotype Bias":43.0,
        "Adversarial Robustness":46.43,
        "Out-of-Distribution Robustness":51.79,
        "Robustness to Adversarial Demonstrations":34.15,
        "Privacy":46.39,
        "Machine Ethics":30.43,
        "Fairness":92.63,
        "Overall":45.8525
    }
]