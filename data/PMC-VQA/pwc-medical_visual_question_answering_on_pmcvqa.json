[
    {
        "table_id":24369,
        "row_id":104920,
        "rank":1,
        "Model":"MedVInT",
        "mlmodel":{

        },
        "method_short":"MedVInT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"42.3"
        },
        "raw_metrics":{
            "Accuracy":42.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210652,
            "title":"PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering",
            "url":"\/paper\/pmc-vqa-visual-instruction-tuning-for-medical",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pmc-vqa-visual-instruction-tuning-for-medical\/review\/?hl=104920"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24369,
        "row_id":104923,
        "rank":2,
        "Model":"Open-Flamingo",
        "mlmodel":{

        },
        "method_short":"Open-Flamingo",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-29",
        "metrics":{
            "Accuracy":"26.4"
        },
        "raw_metrics":{
            "Accuracy":26.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001838,
            "title":"Flamingo: a Visual Language Model for Few-Shot Learning",
            "url":"\/paper\/flamingo-a-visual-language-model-for-few-shot-1",
            "published":"2022-04-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24369,
        "row_id":104924,
        "rank":3,
        "Model":"PMC-CLIP",
        "mlmodel":{

        },
        "method_short":"PMC-CLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-13",
        "metrics":{
            "Accuracy":"24.7"
        },
        "raw_metrics":{
            "Accuracy":24.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1172477,
            "title":"PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents",
            "url":"\/paper\/pmc-clip-contrastive-language-image-pre",
            "published":"2023-03-13T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24369,
        "row_id":104925,
        "rank":4,
        "Model":"BLIP-2",
        "mlmodel":{

        },
        "method_short":"BLIP-2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-30",
        "metrics":{
            "Accuracy":"24.3"
        },
        "raw_metrics":{
            "Accuracy":24.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1149122,
            "title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
            "url":"\/paper\/blip-2-bootstrapping-language-image-pre",
            "published":"2023-01-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/blip-2-bootstrapping-language-image-pre\/review\/?hl=104925"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]