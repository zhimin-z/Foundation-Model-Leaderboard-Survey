[
    {
        "table_id":18649,
        "row_id":112823,
        "rank":1,
        "method":"Orca 2-13B",
        "mlmodel":{

        },
        "method_short":"Orca 2-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-18",
        "metrics":{
            "Accuracy":"86.86"
        },
        "raw_metrics":{
            "Accuracy":86.86
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323875,
            "title":"Orca 2: Teaching Small Language Models How to Reason",
            "url":"\/paper\/orca-2-teaching-small-language-models-how-to",
            "published":"2023-11-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/orca-2-teaching-small-language-models-how-to\/review\/?hl=112823"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18649,
        "row_id":112821,
        "rank":2,
        "method":"Orca 2-7B",
        "mlmodel":{

        },
        "method_short":"Orca 2-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-18",
        "metrics":{
            "Accuracy":"84.31"
        },
        "raw_metrics":{
            "Accuracy":84.31
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323875,
            "title":"Orca 2: Teaching Small Language Models How to Reason",
            "url":"\/paper\/orca-2-teaching-small-language-models-how-to",
            "published":"2023-11-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/orca-2-teaching-small-language-models-how-to\/review\/?hl=112821"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18649,
        "row_id":59396,
        "rank":3,
        "method":"Chinchilla-70B (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"Chinchilla-70B ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-29",
        "metrics":{
            "Accuracy":"75.0"
        },
        "raw_metrics":{
            "Accuracy":75.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":985465,
            "title":"Training Compute-Optimal Large Language Models",
            "url":"\/paper\/training-compute-optimal-large-language",
            "published":"2022-03-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":18649,
        "row_id":59397,
        "rank":4,
        "method":"Gopher-280B (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"Gopher-280B ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-08",
        "metrics":{
            "Accuracy":"56.8"
        },
        "raw_metrics":{
            "Accuracy":56.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":942590,
            "title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
            "url":"\/paper\/scaling-language-models-methods-analysis-1",
            "published":"2021-12-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]