[
    {
        "table_id":6070,
        "row_id":113904,
        "rank":1,
        "Model":"Qwen-Audio",
        "mlmodel":{

        },
        "method_short":"Qwen-Audio",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-15",
        "metrics":{
            "Word Error Rate (WER)":"1.29",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.29,
            "Params(M)":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1320758,
            "title":"Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models",
            "url":"\/paper\/qwen-audio-advancing-universal-audio",
            "published":"2023-11-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":88939,
        "rank":2,
        "Model":"MMSpeech With LM",
        "mlmodel":{

        },
        "method_short":"MMSpeech With LM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-29",
        "metrics":{
            "Word Error Rate (WER)":"1.9",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.9,
            "Params(M)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1121784,
            "title":"MMSpeech: Multi-modal Multi-task Encoder-Decoder Pre-training for Speech Recognition",
            "url":"\/paper\/mmspeech-multi-modal-multi-task-encoder",
            "published":"2022-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mmspeech-multi-modal-multi-task-encoder\/review\/?hl=88939"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":328,
                "name":"Pretrained",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":102981,
        "rank":3,
        "Model":"Paraformer-large",
        "mlmodel":{

        },
        "method_short":"Paraformer-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-18",
        "metrics":{
            "Word Error Rate (WER)":"1.95",
            "Params(M)":"220"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.95,
            "Params(M)":220.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1211329,
            "title":"FunASR: A Fundamental End-to-End Speech Recognition Toolkit",
            "url":"\/paper\/funasr-a-fundamental-end-to-end-speech",
            "published":"2023-05-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/funasr-a-fundamental-end-to-end-speech\/review\/?hl=102981"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":60904,
        "rank":4,
        "Model":"SE-WSBO With LM",
        "mlmodel":{

        },
        "method_short":"SE-WSBO With LM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-24",
        "metrics":{
            "Word Error Rate (WER)":"4.1",
            "Params(M)":"46"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.1,
            "Params(M)":46.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1048769,
            "title":"Improving Mandarin Speech Recogntion with Block-augmented Transformer",
            "url":"\/paper\/improving-mandarin-speech-recogntion-with",
            "published":"2022-07-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-mandarin-speech-recogntion-with\/review\/?hl=60904"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":108776,
        "rank":5,
        "Model":"UMA",
        "mlmodel":{

        },
        "method_short":"UMA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-15",
        "metrics":{
            "Word Error Rate (WER)":"4.7",
            "Params(M)":"44.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.7,
            "Params(M)":44.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1281608,
            "title":"Unimodal Aggregation for CTC-based Speech Recognition",
            "url":"\/paper\/unimodal-aggregation-for-ctc-based-speech",
            "published":"2023-09-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unimodal-aggregation-for-ctc-based-speech\/review\/?hl=108776"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":111807,
        "rank":6,
        "Model":"U2",
        "mlmodel":{

        },
        "method_short":"U2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-10",
        "metrics":{
            "Word Error Rate (WER)":"4.72",
            "Params(M)":"47"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.72,
            "Params(M)":47.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":726759,
            "title":"Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition",
            "url":"\/paper\/unified-streaming-and-non-streaming-two-pass",
            "published":"2020-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unified-streaming-and-non-streaming-two-pass\/review\/?hl=111807"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":25219,
        "rank":7,
        "Model":"CTC\/Att",
        "mlmodel":{

        },
        "method_short":"CTC\/Att",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-10",
        "metrics":{
            "Word Error Rate (WER)":"4.72",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.72,
            "Params(M)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":726759,
            "title":"Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition",
            "url":"\/paper\/unified-streaming-and-non-streaming-two-pass",
            "published":"2020-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unified-streaming-and-non-streaming-two-pass\/review\/?hl=25219"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":102984,
        "rank":8,
        "Model":"Paraformer",
        "mlmodel":{

        },
        "method_short":"Paraformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-18",
        "metrics":{
            "Word Error Rate (WER)":"4.95",
            "Params(M)":"46.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.95,
            "Params(M)":46.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1211329,
            "title":"FunASR: A Fundamental End-to-End Speech Recognition Toolkit",
            "url":"\/paper\/funasr-a-fundamental-end-to-end-speech",
            "published":"2023-05-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/funasr-a-fundamental-end-to-end-speech\/review\/?hl=102984"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":105745,
        "rank":9,
        "Model":"BAT",
        "mlmodel":{

        },
        "method_short":"BAT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-19",
        "metrics":{
            "Word Error Rate (WER)":"4.97",
            "Params(M)":"90"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.97,
            "Params(M)":90.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212358,
            "title":"BAT: Boundary aware transducer for memory-efficient and low-latency ASR",
            "url":"\/paper\/bat-boundary-aware-transducer-for-memory",
            "published":"2023-05-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bat-boundary-aware-transducer-for-memory\/review\/?hl=105745"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":25151,
        "rank":10,
        "Model":"CTC-CRF 4gram-LM",
        "mlmodel":{

        },
        "method_short":"CTC-CRF 4gram-LM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-27",
        "metrics":{
            "Word Error Rate (WER)":"6.34",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.34,
            "Params(M)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":197953,
            "title":"CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency",
            "url":"\/paper\/cat-a-ctc-crf-based-asr-toolkit-bridging-the",
            "published":"2020-05-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cat-a-ctc-crf-based-asr-toolkit-bridging-the\/review\/?hl=25151"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":111805,
        "rank":11,
        "Model":"BRA-E",
        "mlmodel":{

        },
        "method_short":"BRA-E",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-23",
        "metrics":{
            "Word Error Rate (WER)":"6.63",
            "Params(M)":"8.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.63,
            "Params(M)":8.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1179372,
            "title":"Beyond Universal Transformer: block reusing with adaptor in Transformer for automatic speech recognition",
            "url":"\/paper\/beyond-universal-transformer-block-reusing",
            "published":"2023-03-23T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/beyond-universal-transformer-block-reusing\/review\/?hl=111805"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":25164,
        "rank":12,
        "Model":"CTC\/Att",
        "mlmodel":{

        },
        "method_short":"CTC\/Att",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-13",
        "metrics":{
            "Word Error Rate (WER)":"6.7",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.7,
            "Params(M)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":153553,
            "title":"A Comparative Study on Transformer vs RNN in Speech Applications",
            "url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in",
            "published":"2019-09-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in\/review\/?hl=25164"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":6070,
        "row_id":25165,
        "rank":13,
        "Model":"Att",
        "mlmodel":{

        },
        "method_short":"Att",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-08-30",
        "metrics":{
            "Word Error Rate (WER)":"18.7",
            "Params(M)":null
        },
        "raw_metrics":{
            "Word Error Rate (WER)":18.7,
            "Params(M)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":56364,
            "title":"End-to-end Speech Recognition with Adaptive Computation Steps",
            "url":"\/paper\/end-to-end-speech-recognition-with-adaptive",
            "published":"2018-08-30T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]