[
    {
        "Model":"GPT-4V",
        "Question Pair Acc":12.2047,
        "Paper":"HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models",
        "Year":2023
    },
    {
        "Model":"LLaVA-1.5",
        "Question Pair Acc":4.3307,
        "Paper":"Visual Instruction Tuning",
        "Year":2023
    },
    {
        "Model":"mPLUG-Owl",
        "Question Pair Acc":2.36,
        "Paper":"mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality",
        "Year":2023
    },
    {
        "Model":"LRV-Instruct",
        "Question Pair Acc":1.57,
        "Paper":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning",
        "Year":2023
    }
]