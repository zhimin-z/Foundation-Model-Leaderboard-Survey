[
    {
        "Model":"Ray2333\/reward-model-Mistral-7B-instruct-Unified-Feedback",
        "Model Type":"Seq. Classifier",
        "Average":73.9,
        "anthropic_harmless":72.3,
        "anthropic_helpful":70.3,
        "anthropic_hhh":89.6,
        "mtbench_gpt4":79.4,
        "mtbench_human":68.6,
        "shp":64.3,
        "summarize":73.2
    },
    {
        "Model":"Cohere March 2024",
        "Model Type":"Custom Classifier",
        "Average":73.3,
        "anthropic_harmless":63.4,
        "anthropic_helpful":68.1,
        "anthropic_hhh":89.6,
        "mtbench_gpt4":80.6,
        "mtbench_human":70.5,
        "shp":64.9,
        "summarize":75.7
    },
    {
        "Model":"Nexusflow\/Starling-RM-34B",
        "Model Type":"Seq. Classifier",
        "Average":71.6,
        "anthropic_harmless":59.9,
        "anthropic_helpful":66.4,
        "anthropic_hhh":87.3,
        "mtbench_gpt4":83.8,
        "mtbench_human":71.9,
        "shp":67.1,
        "summarize":64.6
    },
    {
        "Model":"weqweasdas\/RM-Mistral-7B",
        "Model Type":"Seq. Classifier",
        "Average":71.1,
        "anthropic_harmless":50.9,
        "anthropic_helpful":72.0,
        "anthropic_hhh":87.8,
        "mtbench_gpt4":77.4,
        "mtbench_human":68.0,
        "shp":80.9,
        "summarize":60.5
    },
    {
        "Model":"hendrydong\/Mistral-RM-for-RAFT-GSHF-v0",
        "Model Type":"Seq. Classifier",
        "Average":71.0,
        "anthropic_harmless":49.6,
        "anthropic_helpful":72.0,
        "anthropic_hhh":86.4,
        "mtbench_gpt4":77.8,
        "mtbench_human":68.9,
        "shp":80.8,
        "summarize":61.2
    },
    {
        "Model":"berkeley-nest\/Starling-RM-7B-alpha",
        "Model Type":"Seq. Classifier",
        "Average":68.8,
        "anthropic_harmless":60.3,
        "anthropic_helpful":63.6,
        "anthropic_hhh":81.9,
        "mtbench_gpt4":81.3,
        "mtbench_human":68.3,
        "shp":61.6,
        "summarize":64.6
    },
    {
        "Model":"openbmb\/UltraRM-13b",
        "Model Type":"Seq. Classifier",
        "Average":67.9,
        "anthropic_harmless":44.2,
        "anthropic_helpful":66.9,
        "anthropic_hhh":79.6,
        "mtbench_gpt4":72.9,
        "mtbench_human":66.4,
        "shp":75.8,
        "summarize":69.4
    },
    {
        "Model":"OpenAssistant\/oasst-rm-2-pythia-6.9b-epoch-1",
        "Model Type":"Seq. Classifier",
        "Average":67.3,
        "anthropic_harmless":59.8,
        "anthropic_helpful":63.7,
        "anthropic_hhh":70.1,
        "mtbench_gpt4":73.2,
        "mtbench_human":66.2,
        "shp":74.8,
        "summarize":63.5
    },
    {
        "Model":"OpenAssistant\/oasst-rm-2.1-pythia-1.4b-epoch-2.5",
        "Model Type":"Seq. Classifier",
        "Average":67.1,
        "anthropic_harmless":64.5,
        "anthropic_helpful":62.1,
        "anthropic_hhh":69.7,
        "mtbench_gpt4":76.2,
        "mtbench_human":67.9,
        "shp":68.2,
        "summarize":61.3
    },
    {
        "Model":"weqweasdas\/RM-Gemma-7B-4096",
        "Model Type":"Seq. Classifier",
        "Average":66.6,
        "anthropic_harmless":38.2,
        "anthropic_helpful":71.6,
        "anthropic_hhh":78.7,
        "mtbench_gpt4":77.5,
        "mtbench_human":69.2,
        "shp":79.5,
        "summarize":51.2
    },
    {
        "Model":"llm-blender\/PairRM-hf",
        "Model Type":"Seq. Classifier",
        "Average":66.4,
        "anthropic_harmless":49.2,
        "anthropic_helpful":64.8,
        "anthropic_hhh":83.7,
        "mtbench_gpt4":72.4,
        "mtbench_human":65.0,
        "shp":58.7,
        "summarize":71.2
    },
    {
        "Model":"weqweasdas\/RM-Gemma-7B",
        "Model Type":"Seq. Classifier",
        "Average":66.1,
        "anthropic_harmless":34.9,
        "anthropic_helpful":71.2,
        "anthropic_hhh":79.2,
        "mtbench_gpt4":75.8,
        "mtbench_human":69.2,
        "shp":79.0,
        "summarize":53.4
    },
    {
        "Model":"IDEA-CCNL\/Ziya-LLaMA-7B-Reward",
        "Model Type":"Seq. Classifier",
        "Average":64.2,
        "anthropic_harmless":47.3,
        "anthropic_helpful":60.4,
        "anthropic_hhh":76.9,
        "mtbench_gpt4":75.4,
        "mtbench_human":68.1,
        "shp":61.1,
        "summarize":60.0
    },
    {
        "Model":"weqweasdas\/RM-Gemma-2B",
        "Model Type":"Seq. Classifier",
        "Average":63.9,
        "anthropic_harmless":35.1,
        "anthropic_helpful":69.0,
        "anthropic_hhh":72.9,
        "mtbench_gpt4":76.7,
        "mtbench_human":69.7,
        "shp":76.7,
        "summarize":47.6
    },
    {
        "Model":"stanfordnlp\/SteamSHP-flan-t5-xl",
        "Model Type":"Custom Classifier",
        "Average":62.8,
        "anthropic_harmless":38.4,
        "anthropic_helpful":63.3,
        "anthropic_hhh":63.8,
        "mtbench_gpt4":76.8,
        "mtbench_human":64.9,
        "shp":79.6,
        "summarize":53.2
    },
    {
        "Model":"weqweasdas\/hh_rlhf_rm_open_llama_3b",
        "Model Type":"Seq. Classifier",
        "Average":62.1,
        "anthropic_harmless":41.8,
        "anthropic_helpful":75.7,
        "anthropic_hhh":65.6,
        "mtbench_gpt4":68.5,
        "mtbench_human":61.8,
        "shp":63.1,
        "summarize":58.1
    },
    {
        "Model":"stanfordnlp\/SteamSHP-flan-t5-large",
        "Model Type":"Custom Classifier",
        "Average":61.5,
        "anthropic_harmless":37.9,
        "anthropic_helpful":62.9,
        "anthropic_hhh":55.7,
        "mtbench_gpt4":76.1,
        "mtbench_human":65.8,
        "shp":79.1,
        "summarize":53.3
    },
    {
        "Model":"OpenAssistant\/reward-model-deberta-v3-large-v2",
        "Model Type":"Seq. Classifier",
        "Average":60.8,
        "anthropic_harmless":56.4,
        "anthropic_helpful":70.9,
        "anthropic_hhh":52.0,
        "mtbench_gpt4":72.1,
        "mtbench_human":63.7,
        "shp":33.8,
        "summarize":76.7
    },
    {
        "Model":"PKU-Alignment\/beaver-7b-v1.0-reward",
        "Model Type":"Seq. Classifier",
        "Average":59.7,
        "anthropic_harmless":38.0,
        "anthropic_helpful":57.2,
        "anthropic_hhh":59.7,
        "mtbench_gpt4":74.0,
        "mtbench_human":66.4,
        "shp":67.8,
        "summarize":55.0
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_llama30b",
        "Model Type":"DPO",
        "Average":59.6,
        "anthropic_harmless":55.0,
        "anthropic_helpful":55.6,
        "anthropic_hhh":61.1,
        "mtbench_gpt4":64.8,
        "mtbench_human":62.6,
        "shp":68.4,
        "summarize":49.4
    },
    {
        "Model":"NousResearch\/Nous-Hermes-2-Mistral-7B-DPO",
        "Model Type":"DPO",
        "Average":59.0,
        "anthropic_harmless":53.0,
        "anthropic_helpful":51.9,
        "anthropic_hhh":65.6,
        "mtbench_gpt4":70.8,
        "mtbench_human":67.2,
        "shp":49.5,
        "summarize":55.0
    },
    {
        "Model":"0-hero\/Matter-0.1-7B-boost-DPO-preview",
        "Model Type":"DPO",
        "Average":58.1,
        "anthropic_harmless":49.0,
        "anthropic_helpful":52.8,
        "anthropic_hhh":67.9,
        "mtbench_gpt4":69.9,
        "mtbench_human":65.2,
        "shp":49.5,
        "summarize":52.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_pythia6-9b",
        "Model Type":"DPO",
        "Average":57.8,
        "anthropic_harmless":46.9,
        "anthropic_helpful":54.8,
        "anthropic_hhh":58.8,
        "mtbench_gpt4":67.7,
        "mtbench_human":61.5,
        "shp":63.8,
        "summarize":51.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_llama13b",
        "Model Type":"DPO",
        "Average":57.8,
        "anthropic_harmless":46.8,
        "anthropic_helpful":53.9,
        "anthropic_hhh":56.1,
        "mtbench_gpt4":65.9,
        "mtbench_human":61.8,
        "shp":67.2,
        "summarize":53.2
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-alpha",
        "Model Type":"DPO",
        "Average":57.4,
        "anthropic_harmless":55.3,
        "anthropic_helpful":51.7,
        "anthropic_hhh":62.4,
        "mtbench_gpt4":68.0,
        "mtbench_human":64.1,
        "shp":43.5,
        "summarize":56.4
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_pythia2-8b",
        "Model Type":"DPO",
        "Average":56.9,
        "anthropic_harmless":46.1,
        "anthropic_helpful":54.8,
        "anthropic_hhh":53.4,
        "mtbench_gpt4":69.0,
        "mtbench_human":60.5,
        "shp":64.3,
        "summarize":50.3
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_llama30b",
        "Model Type":"DPO",
        "Average":56.8,
        "anthropic_harmless":56.3,
        "anthropic_helpful":52.6,
        "anthropic_hhh":60.2,
        "mtbench_gpt4":55.8,
        "mtbench_human":57.4,
        "shp":67.1,
        "summarize":48.3
    },
    {
        "Model":"allenai\/tulu-2-dpo-70b",
        "Model Type":"DPO",
        "Average":56.6,
        "anthropic_harmless":52.4,
        "anthropic_helpful":51.6,
        "anthropic_hhh":58.4,
        "mtbench_gpt4":68.7,
        "mtbench_human":63.9,
        "shp":45.4,
        "summarize":55.8
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_pythia1-4b",
        "Model Type":"DPO",
        "Average":56.4,
        "anthropic_harmless":46.0,
        "anthropic_helpful":56.0,
        "anthropic_hhh":51.6,
        "mtbench_gpt4":68.3,
        "mtbench_human":58.9,
        "shp":65.7,
        "summarize":48.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_pythia2-8b",
        "Model Type":"DPO",
        "Average":56.4,
        "anthropic_harmless":45.4,
        "anthropic_helpful":54.3,
        "anthropic_hhh":53.4,
        "mtbench_gpt4":69.0,
        "mtbench_human":60.5,
        "shp":62.6,
        "summarize":49.8
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_pythia6-9b",
        "Model Type":"DPO",
        "Average":56.3,
        "anthropic_harmless":45.7,
        "anthropic_helpful":54.5,
        "anthropic_hhh":54.3,
        "mtbench_gpt4":68.0,
        "mtbench_human":59.7,
        "shp":60.8,
        "summarize":50.9
    },
    {
        "Model":"0-hero\/Matter-0.1-7B-DPO-preview",
        "Model Type":"DPO",
        "Average":56.0,
        "anthropic_harmless":44.5,
        "anthropic_helpful":54.8,
        "anthropic_hhh":53.4,
        "mtbench_gpt4":68.1,
        "mtbench_human":65.5,
        "shp":52.9,
        "summarize":52.8
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_llama13b",
        "Model Type":"DPO",
        "Average":55.8,
        "anthropic_harmless":52.4,
        "anthropic_helpful":53.4,
        "anthropic_hhh":60.2,
        "mtbench_gpt4":56.3,
        "mtbench_human":56.0,
        "shp":62.7,
        "summarize":50.0
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Model Type":"DPO",
        "Average":55.8,
        "anthropic_harmless":55.3,
        "anthropic_helpful":50.9,
        "anthropic_hhh":59.7,
        "mtbench_gpt4":62.7,
        "mtbench_human":63.9,
        "shp":43.5,
        "summarize":54.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_pythia12-0b",
        "Model Type":"DPO",
        "Average":55.6,
        "anthropic_harmless":46.1,
        "anthropic_helpful":53.7,
        "anthropic_hhh":54.8,
        "mtbench_gpt4":64.2,
        "mtbench_human":58.6,
        "shp":60.4,
        "summarize":51.2
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_pythia1-4b",
        "Model Type":"DPO",
        "Average":55.4,
        "anthropic_harmless":47.0,
        "anthropic_helpful":53.8,
        "anthropic_hhh":50.7,
        "mtbench_gpt4":65.2,
        "mtbench_human":58.4,
        "shp":63.9,
        "summarize":48.7
    },
    {
        "Model":"PKU-Alignment\/beaver-7b-v1.0-cost",
        "Model Type":"Seq. Classifier",
        "Average":55.1,
        "anthropic_harmless":67.8,
        "anthropic_helpful":54.6,
        "anthropic_hhh":72.9,
        "mtbench_gpt4":43.3,
        "mtbench_human":46.7,
        "shp":50.1,
        "summarize":50.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-kto_llama7b",
        "Model Type":"DPO",
        "Average":54.9,
        "anthropic_harmless":46.0,
        "anthropic_helpful":54.8,
        "anthropic_hhh":50.7,
        "mtbench_gpt4":57.6,
        "mtbench_human":57.8,
        "shp":66.7,
        "summarize":50.8
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_llama7b",
        "Model Type":"DPO",
        "Average":54.9,
        "anthropic_harmless":47.0,
        "anthropic_helpful":54.3,
        "anthropic_hhh":47.5,
        "mtbench_gpt4":58.4,
        "mtbench_human":57.0,
        "shp":67.9,
        "summarize":52.0
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-gemma-v0.1",
        "Model Type":"DPO",
        "Average":53.9,
        "anthropic_harmless":50.9,
        "anthropic_helpful":53.0,
        "anthropic_hhh":53.8,
        "mtbench_gpt4":58.0,
        "mtbench_human":61.3,
        "shp":45.0,
        "summarize":55.0
    },
    {
        "Model":"stabilityai\/stablelm-2-zephyr-1_6b",
        "Model Type":"DPO",
        "Average":53.9,
        "anthropic_harmless":53.1,
        "anthropic_helpful":51.9,
        "anthropic_hhh":52.0,
        "mtbench_gpt4":64.8,
        "mtbench_human":64.4,
        "shp":36.2,
        "summarize":54.5
    },
    {
        "Model":"ContextualAI\/archangel_sft-dpo_pythia12-0b",
        "Model Type":"DPO",
        "Average":53.6,
        "anthropic_harmless":45.8,
        "anthropic_helpful":50.9,
        "anthropic_hhh":52.5,
        "mtbench_gpt4":60.8,
        "mtbench_human":56.6,
        "shp":58.2,
        "summarize":50.5
    },
    {
        "Model":"mistralai\/Mixtral-8x7B-Instruct-v0.1",
        "Model Type":"DPO",
        "Average":53.6,
        "anthropic_harmless":51.9,
        "anthropic_helpful":52.8,
        "anthropic_hhh":54.3,
        "mtbench_gpt4":59.6,
        "mtbench_human":62.3,
        "shp":39.4,
        "summarize":54.8
    },
    {
        "Model":"allenai\/OLMo-7B-Instruct",
        "Model Type":"DPO",
        "Average":53.5,
        "anthropic_harmless":48.1,
        "anthropic_helpful":54.1,
        "anthropic_hhh":52.0,
        "mtbench_gpt4":60.0,
        "mtbench_human":59.8,
        "shp":46.2,
        "summarize":54.6
    },
    {
        "Model":"allenai\/tulu-2-dpo-13b",
        "Model Type":"DPO",
        "Average":53.2,
        "anthropic_harmless":51.9,
        "anthropic_helpful":50.4,
        "anthropic_hhh":48.4,
        "mtbench_gpt4":60.9,
        "mtbench_human":61.9,
        "shp":45.4,
        "summarize":53.6
    },
    {
        "Model":"allenai\/tulu-2-dpo-7b",
        "Model Type":"DPO",
        "Average":52.9,
        "anthropic_harmless":53.0,
        "anthropic_helpful":50.5,
        "anthropic_hhh":44.3,
        "mtbench_gpt4":63.3,
        "mtbench_human":62.6,
        "shp":45.6,
        "summarize":50.5
    },
    {
        "Model":"stabilityai\/stablelm-zephyr-3b",
        "Model Type":"DPO",
        "Average":52.7,
        "anthropic_harmless":53.8,
        "anthropic_helpful":51.7,
        "anthropic_hhh":58.8,
        "mtbench_gpt4":53.1,
        "mtbench_human":59.1,
        "shp":34.8,
        "summarize":57.7
    },
    {
        "Model":"random",
        "Model Type":null,
        "Average":50.0,
        "anthropic_harmless":50.0,
        "anthropic_helpful":50.0,
        "anthropic_hhh":null,
        "mtbench_gpt4":null,
        "mtbench_human":null,
        "shp":50.0,
        "summarize":50.0
    },
    {
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Model Type":"DPO",
        "Average":49.9,
        "anthropic_harmless":45.9,
        "anthropic_helpful":49.6,
        "anthropic_hhh":52.9,
        "mtbench_gpt4":47.7,
        "mtbench_human":45.4,
        "shp":61.0,
        "summarize":47.1
    },
    {
        "Model":"Qwen\/Qwen1.5-72B-Chat",
        "Model Type":"DPO",
        "Average":45.3,
        "anthropic_harmless":55.1,
        "anthropic_helpful":44.5,
        "anthropic_hhh":34.4,
        "mtbench_gpt4":44.1,
        "mtbench_human":48.9,
        "shp":38.9,
        "summarize":51.3
    },
    {
        "Model":"Qwen\/Qwen1.5-7B-Chat",
        "Model Type":"DPO",
        "Average":44.6,
        "anthropic_harmless":56.3,
        "anthropic_helpful":46.2,
        "anthropic_hhh":40.7,
        "mtbench_gpt4":39.2,
        "mtbench_human":45.3,
        "shp":34.8,
        "summarize":49.8
    },
    {
        "Model":"Qwen\/Qwen1.5-14B-Chat",
        "Model Type":"DPO",
        "Average":44.6,
        "anthropic_harmless":56.7,
        "anthropic_helpful":45.3,
        "anthropic_hhh":36.7,
        "mtbench_gpt4":42.9,
        "mtbench_human":47.5,
        "shp":34.0,
        "summarize":48.9
    },
    {
        "Model":"Qwen\/Qwen1.5-1.8B-Chat",
        "Model Type":"DPO",
        "Average":43.6,
        "anthropic_harmless":53.6,
        "anthropic_helpful":48.2,
        "anthropic_hhh":40.7,
        "mtbench_gpt4":28.6,
        "mtbench_human":45.1,
        "shp":36.2,
        "summarize":53.0
    },
    {
        "Model":"Qwen\/Qwen1.5-4B-Chat",
        "Model Type":"DPO",
        "Average":43.4,
        "anthropic_harmless":54.4,
        "anthropic_helpful":50.4,
        "anthropic_hhh":43.0,
        "mtbench_gpt4":26.6,
        "mtbench_human":44.3,
        "shp":33.7,
        "summarize":51.8
    },
    {
        "Model":"Qwen\/Qwen1.5-0.5B-Chat",
        "Model Type":"DPO",
        "Average":43.2,
        "anthropic_harmless":55.3,
        "anthropic_helpful":47.6,
        "anthropic_hhh":52.9,
        "mtbench_gpt4":23.9,
        "mtbench_human":37.8,
        "shp":33.3,
        "summarize":51.3
    }
]