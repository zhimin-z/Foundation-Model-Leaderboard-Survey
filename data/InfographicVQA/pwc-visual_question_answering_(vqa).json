[
    {
        "table_id":24391,
        "row_id":113527,
        "rank":1,
        "method":"Gemini Ultra (pixel only)",
        "mlmodel":{

        },
        "method_short":"Gemini Ultra ",
        "method_details":"pixel only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-06",
        "metrics":{
            "ANLS":"80.3"
        },
        "raw_metrics":{
            "ANLS":80.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336342,
            "title":"Gemini: A Family of Highly Capable Multimodal Models",
            "url":"\/paper\/gemini-a-family-of-highly-capable-multimodal",
            "published":"2023-12-06T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":114171,
        "rank":2,
        "method":"SMoLA-PaLI-X Specialist",
        "mlmodel":{

        },
        "method_short":"SMoLA-PaLI-X Specialist",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "ANLS":"66.2"
        },
        "raw_metrics":{
            "ANLS":66.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":1335830,
            "title":"Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts",
            "url":"\/paper\/omni-smola-boosting-generalist-multimodal",
            "published":"2023-12-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/omni-smola-boosting-generalist-multimodal\/review\/?hl=114171"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":114172,
        "rank":3,
        "method":"SMoLA-PaLI-X Generalist",
        "mlmodel":{

        },
        "method_short":"SMoLA-PaLI-X Generalist",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "ANLS":"65.6"
        },
        "raw_metrics":{
            "ANLS":65.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1335830,
            "title":"Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts",
            "url":"\/paper\/omni-smola-boosting-generalist-multimodal",
            "published":"2023-12-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/omni-smola-boosting-generalist-multimodal\/review\/?hl=114172"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110506,
        "rank":4,
        "method":"UDOP (aux)",
        "mlmodel":{

        },
        "method_short":"UDOP ",
        "method_details":"aux",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-05",
        "metrics":{
            "ANLS":"63.0"
        },
        "raw_metrics":{
            "ANLS":63.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1124203,
            "title":"Unifying Vision, Text, and Layout for Universal Document Processing",
            "url":"\/paper\/unifying-vision-text-and-layout-for-universal",
            "published":"2022-12-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unifying-vision-text-and-layout-for-universal\/review\/?hl=110506"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110549,
        "rank":5,
        "method":"PaLI-3 (w\/ OCR)",
        "mlmodel":{

        },
        "method_short":"PaLI-3 ",
        "method_details":"w\/ OCR",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-13",
        "metrics":{
            "ANLS":"62.4"
        },
        "raw_metrics":{
            "ANLS":62.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1300142,
            "title":"PaLI-3 Vision Language Models: Smaller, Faster, Stronger",
            "url":"\/paper\/pali-3-vision-language-models-smaller-faster",
            "published":"2023-10-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-3-vision-language-models-smaller-faster\/review\/?hl=110549"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110450,
        "rank":6,
        "method":"TILT-Large",
        "mlmodel":{

        },
        "method_short":"TILT-Large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-18",
        "metrics":{
            "ANLS":"61.20"
        },
        "raw_metrics":{
            "ANLS":61.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":746494,
            "title":"Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer",
            "url":"\/paper\/going-full-tilt-boogie-on-document",
            "published":"2021-02-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/going-full-tilt-boogie-on-document\/review\/?hl=110450"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110551,
        "rank":7,
        "method":"PaLI-3",
        "mlmodel":{

        },
        "method_short":"PaLI-3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-13",
        "metrics":{
            "ANLS":"57.8"
        },
        "raw_metrics":{
            "ANLS":57.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1300142,
            "title":"PaLI-3 Vision Language Models: Smaller, Faster, Stronger",
            "url":"\/paper\/pali-3-vision-language-models-smaller-faster",
            "published":"2023-10-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-3-vision-language-models-smaller-faster\/review\/?hl=110551"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110119,
        "rank":8,
        "method":"PaLI-X (Single-task FT w\/ OCR)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Single-task FT w\/ OCR",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "ANLS":"54.8"
        },
        "raw_metrics":{
            "ANLS":54.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110119"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110802,
        "rank":9,
        "method":"Claude + LATIN-Prompt",
        "mlmodel":{

        },
        "method_short":"Claude + LATIN-Prompt",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-01",
        "metrics":{
            "ANLS":"54.51"
        },
        "raw_metrics":{
            "ANLS":54.51
        },
        "uses_additional_data":false,
        "paper":{
            "id":1221165,
            "title":"Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering",
            "url":"\/paper\/layout-and-task-aware-instruction-prompt-for",
            "published":"2023-06-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/layout-and-task-aware-instruction-prompt-for\/review\/?hl=110802"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110118,
        "rank":10,
        "method":"PaLI-X (Multi-task FT)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Multi-task FT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "ANLS":"50.7"
        },
        "raw_metrics":{
            "ANLS":50.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110118"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110117,
        "rank":11,
        "method":"PaLI-X (Single-task FT)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Single-task FT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "ANLS":"49.2"
        },
        "raw_metrics":{
            "ANLS":49.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110117"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110894,
        "rank":12,
        "method":"GPT-3.5 + LATIN-Prompt",
        "mlmodel":{

        },
        "method_short":"GPT-3.5 + LATIN-Prompt",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-01",
        "metrics":{
            "ANLS":"48.98"
        },
        "raw_metrics":{
            "ANLS":48.98
        },
        "uses_additional_data":false,
        "paper":{
            "id":1221165,
            "title":"Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering",
            "url":"\/paper\/layout-and-task-aware-instruction-prompt-for",
            "published":"2023-06-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/layout-and-task-aware-instruction-prompt-for\/review\/?hl=110894"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110453,
        "rank":13,
        "method":"DocFormerv2-large",
        "mlmodel":{

        },
        "method_short":"DocFormerv2-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "ANLS":"48.8"
        },
        "raw_metrics":{
            "ANLS":48.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":1222205,
            "title":"DocFormerv2: Local Features for Document Understanding",
            "url":"\/paper\/docformerv2-local-features-for-document",
            "published":"2023-06-02T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/docformerv2-local-features-for-document\/review\/?hl=110453"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110282,
        "rank":14,
        "method":"UDOP",
        "mlmodel":{

        },
        "method_short":"UDOP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-05",
        "metrics":{
            "ANLS":"47.4"
        },
        "raw_metrics":{
            "ANLS":47.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1124203,
            "title":"Unifying Vision, Text, and Layout for Universal Document Processing",
            "url":"\/paper\/unifying-vision-text-and-layout-for-universal",
            "published":"2022-12-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unifying-vision-text-and-layout-for-universal\/review\/?hl=110282"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110132,
        "rank":15,
        "method":"DUBLIN (variable resolution)",
        "mlmodel":{

        },
        "method_short":"DUBLIN ",
        "method_details":"variable resolution",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "ANLS":"42.6"
        },
        "raw_metrics":{
            "ANLS":42.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1214268,
            "title":"DUBLIN -- Document Understanding By Language-Image Network",
            "url":"\/paper\/dublin-document-understanding-by-language",
            "published":"2023-05-23T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/dublin-document-understanding-by-language\/review\/?hl=110132"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110279,
        "rank":16,
        "method":"Pix2Struct-large",
        "mlmodel":{

        },
        "method_short":"Pix2Struct-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-07",
        "metrics":{
            "ANLS":"40"
        },
        "raw_metrics":{
            "ANLS":40.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1088385,
            "title":"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
            "url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining",
            "published":"2022-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining\/review\/?hl=110279"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110277,
        "rank":17,
        "method":"Pix2Struct-base",
        "mlmodel":{

        },
        "method_short":"Pix2Struct-base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-07",
        "metrics":{
            "ANLS":"38.2"
        },
        "raw_metrics":{
            "ANLS":38.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1088385,
            "title":"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
            "url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining",
            "published":"2022-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining\/review\/?hl=110277"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":110834,
        "rank":18,
        "method":"MatCha",
        "mlmodel":{

        },
        "method_short":"MatCha",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-19",
        "metrics":{
            "ANLS":"37.2"
        },
        "raw_metrics":{
            "ANLS":37.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1130468,
            "title":"MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering",
            "url":"\/paper\/matcha-enhancing-visual-language-pretraining",
            "published":"2022-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/matcha-enhancing-visual-language-pretraining\/review\/?hl=110834"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24391,
        "row_id":104952,
        "rank":19,
        "method":"DUBLIN",
        "mlmodel":{

        },
        "method_short":"DUBLIN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "ANLS":"36.82"
        },
        "raw_metrics":{
            "ANLS":36.82
        },
        "uses_additional_data":true,
        "paper":{
            "id":1214268,
            "title":"DUBLIN -- Document Understanding By Language-Image Network",
            "url":"\/paper\/dublin-document-understanding-by-language",
            "published":"2023-05-23T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/dublin-document-understanding-by-language\/review\/?hl=104952"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]