[
    {
        "table_id":2953,
        "row_id":106250,
        "rank":1,
        "method":"MaMMUT (ours)",
        "mlmodel":{

        },
        "Model":"MaMMUT ",
        "method_details":"ours",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-29",
        "metrics":{
            "CIDEr":"195.6",
            "BLEU-4":null,
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "CIDEr":195.6,
            "BLEU-4":null,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1182696,
            "title":"MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks",
            "url":"\/paper\/mammut-a-simple-architecture-for-joint",
            "published":"2023-03-29T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/mammut-a-simple-architecture-for-joint\/review\/?hl=106250"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":103554,
        "rank":2,
        "method":"VLAB",
        "mlmodel":{

        },
        "Model":"VLAB",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-22",
        "metrics":{
            "CIDEr":"179.8",
            "BLEU-4":"79.3",
            "METEOR":"51.2",
            "ROUGE-L":"87.9"
        },
        "raw_metrics":{
            "CIDEr":179.8,
            "BLEU-4":79.3,
            "METEOR":51.2,
            "ROUGE-L":87.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":1212983,
            "title":"VLAB: Enhancing Video Language Pre-training by Feature Adapting and Blending",
            "url":"\/paper\/vlab-enhancing-video-language-pre-training-by",
            "published":"2023-05-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/vlab-enhancing-video-language-pre-training-by\/review\/?hl=103554"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":101413,
        "rank":3,
        "method":"VALOR",
        "mlmodel":{

        },
        "Model":"VALOR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-17",
        "metrics":{
            "CIDEr":"178.5",
            "BLEU-4":"80.7",
            "METEOR":"51.0",
            "ROUGE-L":"87.9"
        },
        "raw_metrics":{
            "CIDEr":178.5,
            "BLEU-4":80.7,
            "METEOR":51.0,
            "ROUGE-L":87.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191887,
            "title":"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset",
            "url":"\/paper\/valor-vision-audio-language-omni-perception",
            "published":"2023-04-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/valor-vision-audio-language-omni-perception\/review\/?hl=101413"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":96432,
        "rank":4,
        "method":"mPLUG-2",
        "mlmodel":{

        },
        "Model":"mPLUG-2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-01",
        "metrics":{
            "CIDEr":"165.8",
            "BLEU-4":"70.5",
            "METEOR":"48.4",
            "ROUGE-L":"85.3"
        },
        "raw_metrics":{
            "CIDEr":165.8,
            "BLEU-4":70.5,
            "METEOR":48.4,
            "ROUGE-L":85.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1151002,
            "title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video",
            "url":"\/paper\/mplug-2-a-modularized-multi-modal-foundation",
            "published":"2023-02-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mplug-2-a-modularized-multi-modal-foundation\/review\/?hl=96432"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":88520,
        "rank":5,
        "method":"HiTeA",
        "mlmodel":{

        },
        "Model":"HiTeA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-30",
        "metrics":{
            "CIDEr":"146.9",
            "BLEU-4":"71.0",
            "METEOR":"45.3",
            "ROUGE-L":"81.4"
        },
        "raw_metrics":{
            "CIDEr":146.9,
            "BLEU-4":71.0,
            "METEOR":45.3,
            "ROUGE-L":81.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":1136078,
            "title":"HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training",
            "url":"\/paper\/hitea-hierarchical-temporal-aware-video",
            "published":"2022-12-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/hitea-hierarchical-temporal-aware-video\/review\/?hl=88520"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":98739,
        "rank":6,
        "method":"Vid2Seq",
        "mlmodel":{

        },
        "Model":"Vid2Seq",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "CIDEr":"146.2",
            "BLEU-4":null,
            "METEOR":"45.3",
            "ROUGE-L":null
        },
        "raw_metrics":{
            "CIDEr":146.2,
            "BLEU-4":null,
            "METEOR":45.3,
            "ROUGE-L":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1165314,
            "title":"Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning",
            "url":"\/paper\/vid2seq-large-scale-pretraining-of-a-visual",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vid2seq-large-scale-pretraining-of-a-visual\/review\/?hl=98739"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":96100,
        "rank":7,
        "method":"VIOLETv2",
        "mlmodel":{

        },
        "Model":"VIOLETv2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-04",
        "metrics":{
            "CIDEr":"139.2",
            "BLEU-4":null,
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "CIDEr":139.2,
            "BLEU-4":null,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1069338,
            "title":"An Empirical Study of End-to-End Video-Language Transformers with Masked Visual Modeling",
            "url":"\/paper\/an-empirical-study-of-end-to-end-video",
            "published":"2022-09-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-end-to-end-video\/review\/?hl=96100"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":109133,
        "rank":8,
        "method":"CoCap (ViT\/L14)",
        "mlmodel":{

        },
        "Model":"CoCap ",
        "method_details":"ViT\/L14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-22",
        "metrics":{
            "CIDEr":"121.5",
            "BLEU-4":"60.1",
            "METEOR":"41.4",
            "ROUGE-L":"78.2"
        },
        "raw_metrics":{
            "CIDEr":121.5,
            "BLEU-4":60.1,
            "METEOR":41.4,
            "ROUGE-L":78.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1286060,
            "title":"Accurate and Fast Compressed Video Captioning",
            "url":"\/paper\/accurate-and-fast-compressed-video-captioning",
            "published":"2023-09-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/accurate-and-fast-compressed-video-captioning\/review\/?hl=109133"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":110292,
        "rank":9,
        "method":"VASTA (Vatex-backbone)",
        "mlmodel":{

        },
        "Model":"VASTA ",
        "method_details":"Vatex-backbone",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-08-19",
        "metrics":{
            "CIDEr":"119.7",
            "BLEU-4":"59.2",
            "METEOR":"40.65",
            "ROUGE-L":"76.7"
        },
        "raw_metrics":{
            "CIDEr":119.7,
            "BLEU-4":59.2,
            "METEOR":40.65,
            "ROUGE-L":76.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1061664,
            "title":"Diverse Video Captioning by Adaptive Spatio-temporal Attention",
            "url":"\/paper\/diverse-video-captioning-by-adaptive-spatio",
            "published":"2022-08-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/diverse-video-captioning-by-adaptive-spatio\/review\/?hl=110292"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":113894,
        "rank":10,
        "method":"IcoCap (ViT-B\/16)",
        "mlmodel":{

        },
        "Model":"IcoCap ",
        "method_details":"ViT-B\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "CIDEr":"110.3",
            "BLEU-4":"59.1",
            "METEOR":"39.5",
            "ROUGE-L":"76.5"
        },
        "raw_metrics":{
            "CIDEr":110.3,
            "BLEU-4":59.1,
            "METEOR":39.5,
            "ROUGE-L":76.5
        },
        "uses_additional_data":true,
        "paper":{
            "id":1340144,
            "title":"IcoCap: Improving Video Captioning by Compounding Images",
            "url":"\/paper\/icocap-improving-video-captioning-by",
            "published":"2023-10-05T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":110291,
        "rank":11,
        "method":"VASTA (Kinetics-backbone)",
        "mlmodel":{

        },
        "Model":"VASTA ",
        "method_details":"Kinetics-backbone",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-08-19",
        "metrics":{
            "CIDEr":"106.4",
            "BLEU-4":"56.1",
            "METEOR":"39.1",
            "ROUGE-L":"74.5"
        },
        "raw_metrics":{
            "CIDEr":106.4,
            "BLEU-4":56.1,
            "METEOR":39.1,
            "ROUGE-L":74.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1061664,
            "title":"Diverse Video Captioning by Adaptive Spatio-temporal Attention",
            "url":"\/paper\/diverse-video-captioning-by-adaptive-spatio",
            "published":"2022-08-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/diverse-video-captioning-by-adaptive-spatio\/review\/?hl=110291"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":113893,
        "rank":12,
        "method":"IcoCap (ViT-B\/32)",
        "mlmodel":{

        },
        "Model":"IcoCap ",
        "method_details":"ViT-B\/32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "CIDEr":"103.8",
            "BLEU-4":"56.3",
            "METEOR":"38.9",
            "ROUGE-L":"75.0"
        },
        "raw_metrics":{
            "CIDEr":103.8,
            "BLEU-4":56.3,
            "METEOR":38.9,
            "ROUGE-L":75.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1340144,
            "title":"IcoCap: Improving Video Captioning by Compounding Images",
            "url":"\/paper\/icocap-improving-video-captioning-by",
            "published":"2023-10-05T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2953,
        "row_id":15795,
        "rank":13,
        "method":"ORG-TRL",
        "mlmodel":{

        },
        "Model":"ORG-TRL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-01",
        "metrics":{
            "CIDEr":"95.2",
            "BLEU-4":"54.3",
            "METEOR":"36.4",
            "ROUGE-L":"73.9"
        },
        "raw_metrics":{
            "CIDEr":95.2,
            "BLEU-4":54.3,
            "METEOR":36.4,
            "ROUGE-L":73.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":184857,
            "title":"Object Relational Graph with Teacher-Recommended Learning for Video Captioning",
            "url":"\/paper\/object-relational-graph-with-teacher",
            "published":"2020-02-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/object-relational-graph-with-teacher\/review\/?hl=15795"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]