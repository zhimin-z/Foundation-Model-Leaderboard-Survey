[
    {
        "table_id":3940,
        "row_id":110819,
        "rank":1,
        "Model":"LLaMA-VQA",
        "mlmodel":{

        },
        "method_short":"LLaMA-VQA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-24",
        "metrics":{
            "Accuracy":"82.2"
        },
        "raw_metrics":{
            "Accuracy":82.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1307209,
            "title":"Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
            "url":"\/paper\/large-language-models-are-temporal-and-causal",
            "published":"2023-10-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-temporal-and-causal\/review\/?hl=110819"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3940,
        "row_id":70086,
        "rank":2,
        "Model":"FrozenBiLM",
        "mlmodel":{

        },
        "method_short":"FrozenBiLM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-16",
        "metrics":{
            "Accuracy":"82"
        },
        "raw_metrics":{
            "Accuracy":82.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1028387,
            "title":"Zero-Shot Video Question Answering via Frozen Bidirectional Language Models",
            "url":"\/paper\/zero-shot-video-question-answering-via-frozen",
            "published":"2022-06-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/zero-shot-video-question-answering-via-frozen\/review\/?hl=70086"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3940,
        "row_id":21725,
        "rank":3,
        "Model":"iPerceive (Chadha et al., 2020)",
        "mlmodel":{

        },
        "method_short":"iPerceive ",
        "method_details":"Chadha et al., 2020",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-16",
        "metrics":{
            "Accuracy":"76.96"
        },
        "raw_metrics":{
            "Accuracy":76.96
        },
        "uses_additional_data":false,
        "paper":{
            "id":235356,
            "title":"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering",
            "url":"\/paper\/iperceive-applying-common-sense-reasoning-to-1",
            "published":"2020-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/iperceive-applying-common-sense-reasoning-to-1\/review\/?hl=21725"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3940,
        "row_id":20643,
        "rank":4,
        "Model":"Hero w\/ pre-training",
        "mlmodel":{

        },
        "method_short":"Hero w\/ pre-training",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-01",
        "metrics":{
            "Accuracy":"74.24"
        },
        "raw_metrics":{
            "Accuracy":74.24
        },
        "uses_additional_data":false,
        "paper":{
            "id":193276,
            "title":"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training",
            "url":"\/paper\/hero-hierarchical-encoder-for-video-language",
            "published":"2020-05-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/hero-hierarchical-encoder-for-video-language\/review\/?hl=20643"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3940,
        "row_id":20646,
        "rank":5,
        "Model":"STAGE (Lei et al., 2019)",
        "mlmodel":{

        },
        "method_short":"STAGE ",
        "method_details":"Lei et al., 2019",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-25",
        "metrics":{
            "Accuracy":"70.50"
        },
        "raw_metrics":{
            "Accuracy":70.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":112909,
            "title":"TVQA+: Spatio-Temporal Grounding for Video Question Answering",
            "url":"\/paper\/tvqa-spatio-temporal-grounding-for-video",
            "published":"2019-04-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tvqa-spatio-temporal-grounding-for-video\/review\/?hl=20646"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]