[
    {
        "table_id":25793,
        "row_id":113087,
        "rank":1,
        "Model":"VideoChat2",
        "mlmodel":{

        },
        "method_short":"VideoChat2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "Accuracy":"40.6"
        },
        "raw_metrics":{
            "Accuracy":40.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1329478,
            "title":"MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
            "url":"\/paper\/mvbench-a-comprehensive-multi-modal-video",
            "published":"2023-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mvbench-a-comprehensive-multi-modal-video\/review\/?hl=113087"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25793,
        "row_id":113086,
        "rank":2,
        "Model":"SEVILA",
        "mlmodel":{

        },
        "method_short":"SEVILA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Accuracy":"38.2"
        },
        "raw_metrics":{
            "Accuracy":38.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333248,
            "title":"Self-Chained Image-Language Model for Video Localization and Question Answering",
            "url":"\/paper\/self-chained-image-language-model-for-video-1",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25793,
        "row_id":113083,
        "rank":3,
        "Model":"InternVideo",
        "mlmodel":{

        },
        "method_short":"InternVideo",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-06",
        "metrics":{
            "Accuracy":"35.9"
        },
        "raw_metrics":{
            "Accuracy":35.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1124231,
            "title":"InternVideo: General Video Foundation Models via Generative and Discriminative Learning",
            "url":"\/paper\/internvideo-general-video-foundation-models",
            "published":"2022-12-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/internvideo-general-video-foundation-models\/review\/?hl=113083"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25793,
        "row_id":113085,
        "rank":4,
        "Model":"FrozenBILM",
        "mlmodel":{

        },
        "method_short":"FrozenBILM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-16",
        "metrics":{
            "Accuracy":"29.7"
        },
        "raw_metrics":{
            "Accuracy":29.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1028387,
            "title":"Zero-Shot Video Question Answering via Frozen Bidirectional Language Models",
            "url":"\/paper\/zero-shot-video-question-answering-via-frozen",
            "published":"2022-06-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/zero-shot-video-question-answering-via-frozen\/review\/?hl=113085"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]