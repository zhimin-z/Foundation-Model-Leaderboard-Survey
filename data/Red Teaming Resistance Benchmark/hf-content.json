[
    {
        "Model":"gpt-4-0125-preview",
        "Average":"99.194",
        "Illegal Activity":"99.181",
        "Children Harm":"97.818",
        "Hate\/Harass\/Violence":"98.897",
        "Malware":"100.000",
        "Physical Harm":"97.986",
        "Economic Harm":"99.759",
        "Fraud\/Deception":"99.486",
        "Adult Content":"100.000",
        "Political Campaigning":"98.851",
        "Privacy Violation":"100.000",
        "Legal Advice":"100.000",
        "Financial Advice":"100.000",
        "Medical Advice":"100.000",
        "Government Advice":"100.000",
        "Sexual Content":"95.930"
    },
    {
        "Model":"claude-2.1",
        "Average":"99.162",
        "Illegal Activity":"99.454",
        "Children Harm":"98.182",
        "Hate\/Harass\/Violence":"98.962",
        "Malware":"100.000",
        "Physical Harm":"97.986",
        "Economic Harm":"100.000",
        "Fraud\/Deception":"99.743",
        "Adult Content":"98.077",
        "Political Campaigning":"98.851",
        "Privacy Violation":"100.000",
        "Legal Advice":"100.000",
        "Financial Advice":"100.000",
        "Medical Advice":"99.666",
        "Government Advice":"100.000",
        "Sexual Content":"96.512"
    },
    {
        "Model":"NewstaR\/Koss-7B-chat",
        "Average":"94.495",
        "Illegal Activity":"91.229",
        "Children Harm":"91.154",
        "Hate\/Harass\/Violence":"95.136",
        "Malware":"92.537",
        "Physical Harm":"90.102",
        "Economic Harm":"93.158",
        "Fraud\/Deception":"93.939",
        "Adult Content":"96.491",
        "Political Campaigning":"100.000",
        "Privacy Violation":"97.727",
        "Legal Advice":"95.652",
        "Financial Advice":"100.000",
        "Medical Advice":"96.154",
        "Government Advice":"89.474",
        "Sexual Content":"94.675"
    },
    {
        "Model":"NousResearch\/Llama-2-7b-chat-hf",
        "Average":"94.337",
        "Illegal Activity":"91.552",
        "Children Harm":"90.000",
        "Hate\/Harass\/Violence":"94.617",
        "Malware":"88.060",
        "Physical Harm":"89.811",
        "Economic Harm":"93.158",
        "Fraud\/Deception":"93.362",
        "Adult Content":"94.737",
        "Political Campaigning":"96.629",
        "Privacy Violation":"97.727",
        "Legal Advice":"95.652",
        "Financial Advice":"100.000",
        "Medical Advice":"96.853",
        "Government Advice":"100.000",
        "Sexual Content":"92.899"
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "Average":"86.687",
        "Illegal Activity":"84.721",
        "Children Harm":"83.077",
        "Hate\/Harass\/Violence":"86.706",
        "Malware":"88.060",
        "Physical Harm":"81.368",
        "Economic Harm":"84.737",
        "Fraud\/Deception":"84.416",
        "Adult Content":"77.193",
        "Political Campaigning":"89.888",
        "Privacy Violation":"91.818",
        "Legal Advice":"91.304",
        "Financial Advice":"100.000",
        "Medical Advice":"90.559",
        "Government Advice":"84.211",
        "Sexual Content":"82.249"
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Average":"80.788",
        "Illegal Activity":"76.880",
        "Children Harm":"74.615",
        "Hate\/Harass\/Violence":"77.237",
        "Malware":"73.134",
        "Physical Harm":"71.470",
        "Economic Harm":"77.105",
        "Fraud\/Deception":"77.778",
        "Adult Content":"70.175",
        "Political Campaigning":"84.270",
        "Privacy Violation":"88.636",
        "Legal Advice":"91.304",
        "Financial Advice":"100.000",
        "Medical Advice":"89.860",
        "Government Advice":"84.211",
        "Sexual Content":"75.148"
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":"79.263",
        "Illegal Activity":"71.787",
        "Children Harm":"78.077",
        "Hate\/Harass\/Violence":"80.610",
        "Malware":"59.701",
        "Physical Harm":"68.413",
        "Economic Harm":"76.579",
        "Fraud\/Deception":"74.026",
        "Adult Content":"71.930",
        "Political Campaigning":"89.888",
        "Privacy Violation":"96.818",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"92.308",
        "Government Advice":"78.947",
        "Sexual Content":"71.598"
    },
    {
        "Model":"EleutherAI\/pythia-6.9b",
        "Average":"78.975",
        "Illegal Activity":"74.454",
        "Children Harm":"77.308",
        "Hate\/Harass\/Violence":"76.978",
        "Malware":"71.642",
        "Physical Harm":"74.381",
        "Economic Harm":"76.842",
        "Fraud\/Deception":"76.479",
        "Adult Content":"70.175",
        "Political Campaigning":"92.135",
        "Privacy Violation":"86.364",
        "Legal Advice":"91.304",
        "Financial Advice":"80.000",
        "Medical Advice":"86.014",
        "Government Advice":"78.947",
        "Sexual Content":"71.598"
    },
    {
        "Model":"databricks\/dolly-v2-7b",
        "Average":"78.757",
        "Illegal Activity":"77.526",
        "Children Harm":"75.385",
        "Hate\/Harass\/Violence":"81.064",
        "Malware":"73.134",
        "Physical Harm":"74.236",
        "Economic Harm":"79.211",
        "Fraud\/Deception":"79.798",
        "Adult Content":"77.193",
        "Political Campaigning":"84.270",
        "Privacy Violation":"88.182",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"85.315",
        "Government Advice":"52.632",
        "Sexual Content":"75.148"
    },
    {
        "Model":"command - Cohere",
        "Average":"78.633",
        "Illegal Activity":"77.316",
        "Children Harm":"53.310",
        "Hate\/Harass\/Violence":"85.558",
        "Malware":"76.744",
        "Physical Harm":"63.173",
        "Economic Harm":"86.085",
        "Fraud\/Deception":"81.043",
        "Adult Content":"57.143",
        "Political Campaigning":"88.235",
        "Privacy Violation":"96.861",
        "Legal Advice":"96.154",
        "Financial Advice":"100.000",
        "Medical Advice":"91.973",
        "Government Advice":"73.333",
        "Sexual Content":"52.571"
    },
    {
        "Model":"togethercomputer\/GPT-JT-6B-v1",
        "Average":"78.376",
        "Illegal Activity":"73.686",
        "Children Harm":"70.385",
        "Hate\/Harass\/Violence":"76.719",
        "Malware":"67.164",
        "Physical Harm":"71.325",
        "Economic Harm":"79.737",
        "Fraud\/Deception":"73.737",
        "Adult Content":"73.684",
        "Political Campaigning":"88.764",
        "Privacy Violation":"86.818",
        "Legal Advice":"86.957",
        "Financial Advice":"100.000",
        "Medical Advice":"79.021",
        "Government Advice":"73.684",
        "Sexual Content":"73.964"
    },
    {
        "Model":"openchat\/openchat_3.5",
        "Average":"77.627",
        "Illegal Activity":"68.432",
        "Children Harm":"71.923",
        "Hate\/Harass\/Violence":"80.026",
        "Malware":"65.672",
        "Physical Harm":"64.192",
        "Economic Harm":"76.842",
        "Fraud\/Deception":"70.274",
        "Adult Content":"68.421",
        "Political Campaigning":"85.393",
        "Privacy Violation":"92.727",
        "Legal Advice":"86.957",
        "Financial Advice":"100.000",
        "Medical Advice":"89.510",
        "Government Advice":"78.947",
        "Sexual Content":"65.089"
    },
    {
        "Model":"microsoft\/phi-2",
        "Average":"76.721",
        "Illegal Activity":"70.816",
        "Children Harm":"75.000",
        "Hate\/Harass\/Violence":"83.593",
        "Malware":"41.791",
        "Physical Harm":"71.033",
        "Economic Harm":"73.158",
        "Fraud\/Deception":"72.727",
        "Adult Content":"70.175",
        "Political Campaigning":"91.011",
        "Privacy Violation":"88.636",
        "Legal Advice":"82.609",
        "Financial Advice":"100.000",
        "Medical Advice":"91.958",
        "Government Advice":"63.158",
        "Sexual Content":"75.148"
    },
    {
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":"76.331",
        "Illegal Activity":"71.099",
        "Children Harm":"71.538",
        "Hate\/Harass\/Violence":"81.453",
        "Malware":"67.164",
        "Physical Harm":"67.686",
        "Economic Harm":"75.000",
        "Fraud\/Deception":"69.986",
        "Adult Content":"66.667",
        "Political Campaigning":"89.888",
        "Privacy Violation":"95.455",
        "Legal Advice":"69.565",
        "Financial Advice":"100.000",
        "Medical Advice":"90.559",
        "Government Advice":"57.895",
        "Sexual Content":"71.006"
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Average":"76.330",
        "Illegal Activity":"70.372",
        "Children Harm":"70.385",
        "Hate\/Harass\/Violence":"78.275",
        "Malware":"47.761",
        "Physical Harm":"67.540",
        "Economic Harm":"75.526",
        "Fraud\/Deception":"73.593",
        "Adult Content":"68.421",
        "Political Campaigning":"87.640",
        "Privacy Violation":"87.727",
        "Legal Advice":"91.304",
        "Financial Advice":"100.000",
        "Medical Advice":"84.615",
        "Government Advice":"68.421",
        "Sexual Content":"73.373"
    },
    {
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Average":"76.009",
        "Illegal Activity":"66.815",
        "Children Harm":"76.154",
        "Hate\/Harass\/Violence":"78.275",
        "Malware":"38.806",
        "Physical Harm":"64.047",
        "Economic Harm":"73.421",
        "Fraud\/Deception":"69.697",
        "Adult Content":"66.667",
        "Political Campaigning":"87.640",
        "Privacy Violation":"95.000",
        "Legal Advice":"100.000",
        "Financial Advice":"100.000",
        "Medical Advice":"93.007",
        "Government Advice":"63.158",
        "Sexual Content":"67.456"
    },
    {
        "Model":"amazon\/MistralLite",
        "Average":"74.806",
        "Illegal Activity":"64.875",
        "Children Harm":"67.692",
        "Hate\/Harass\/Violence":"78.534",
        "Malware":"43.284",
        "Physical Harm":"64.338",
        "Economic Harm":"71.316",
        "Fraud\/Deception":"70.851",
        "Adult Content":"70.175",
        "Political Campaigning":"95.506",
        "Privacy Violation":"87.727",
        "Legal Advice":"95.652",
        "Financial Advice":"100.000",
        "Medical Advice":"89.161",
        "Government Advice":"57.895",
        "Sexual Content":"65.089"
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Average":"74.590",
        "Illegal Activity":"66.451",
        "Children Harm":"69.231",
        "Hate\/Harass\/Violence":"75.551",
        "Malware":"41.791",
        "Physical Harm":"66.084",
        "Economic Harm":"70.263",
        "Fraud\/Deception":"67.965",
        "Adult Content":"71.930",
        "Political Campaigning":"85.393",
        "Privacy Violation":"91.364",
        "Legal Advice":"82.609",
        "Financial Advice":"100.000",
        "Medical Advice":"83.217",
        "Government Advice":"78.947",
        "Sexual Content":"68.047"
    },
    {
        "Model":"princeton-nlp\/Sheared-LLaMA-2.7B",
        "Average":"72.608",
        "Illegal Activity":"65.562",
        "Children Harm":"67.692",
        "Hate\/Harass\/Violence":"73.281",
        "Malware":"47.761",
        "Physical Harm":"61.718",
        "Economic Harm":"68.421",
        "Fraud\/Deception":"69.841",
        "Adult Content":"63.158",
        "Political Campaigning":"83.146",
        "Privacy Violation":"89.091",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"85.315",
        "Government Advice":"68.421",
        "Sexual Content":"67.456"
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-7b-base",
        "Average":"71.407",
        "Illegal Activity":"62.449",
        "Children Harm":"63.846",
        "Hate\/Harass\/Violence":"74.189",
        "Malware":"40.299",
        "Physical Harm":"62.591",
        "Economic Harm":"70.000",
        "Fraud\/Deception":"67.677",
        "Adult Content":"59.649",
        "Political Campaigning":"89.888",
        "Privacy Violation":"85.000",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"83.217",
        "Government Advice":"73.684",
        "Sexual Content":"60.355"
    },
    {
        "Model":"teknium\/OpenHermes-2.5-Mistral-7B",
        "Average":"71.334",
        "Illegal Activity":"60.994",
        "Children Harm":"68.462",
        "Hate\/Harass\/Violence":"75.162",
        "Malware":"32.836",
        "Physical Harm":"60.699",
        "Economic Harm":"67.105",
        "Fraud\/Deception":"64.935",
        "Adult Content":"61.404",
        "Political Campaigning":"80.899",
        "Privacy Violation":"89.091",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"86.713",
        "Government Advice":"78.947",
        "Sexual Content":"64.497"
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Average":"71.052",
        "Illegal Activity":"63.500",
        "Children Harm":"66.923",
        "Hate\/Harass\/Violence":"73.281",
        "Malware":"37.313",
        "Physical Harm":"62.154",
        "Economic Harm":"62.368",
        "Fraud\/Deception":"66.378",
        "Adult Content":"73.684",
        "Political Campaigning":"82.022",
        "Privacy Violation":"86.818",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"86.014",
        "Government Advice":"63.158",
        "Sexual Content":"63.905"
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Average":"71.034",
        "Illegal Activity":"63.864",
        "Children Harm":"68.846",
        "Hate\/Harass\/Violence":"72.763",
        "Malware":"37.313",
        "Physical Harm":"60.116",
        "Economic Harm":"66.053",
        "Fraud\/Deception":"68.398",
        "Adult Content":"63.158",
        "Political Campaigning":"80.899",
        "Privacy Violation":"85.455",
        "Legal Advice":"86.957",
        "Financial Advice":"100.000",
        "Medical Advice":"88.112",
        "Government Advice":"57.895",
        "Sexual Content":"65.680"
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Average":"69.609",
        "Illegal Activity":"61.803",
        "Children Harm":"67.692",
        "Hate\/Harass\/Violence":"72.827",
        "Malware":"32.836",
        "Physical Harm":"59.098",
        "Economic Harm":"63.684",
        "Fraud\/Deception":"65.224",
        "Adult Content":"63.158",
        "Political Campaigning":"78.652",
        "Privacy Violation":"86.818",
        "Legal Advice":"78.261",
        "Financial Advice":"100.000",
        "Medical Advice":"81.818",
        "Government Advice":"73.684",
        "Sexual Content":"58.580"
    },
    {
        "Model":"ehartford\/dolphin-2.2.1-mistral-7b",
        "Average":"67.767",
        "Illegal Activity":"56.629",
        "Children Harm":"69.231",
        "Hate\/Harass\/Violence":"73.671",
        "Malware":"40.299",
        "Physical Harm":"53.566",
        "Economic Harm":"60.000",
        "Fraud\/Deception":"56.421",
        "Adult Content":"49.123",
        "Political Campaigning":"82.022",
        "Privacy Violation":"88.182",
        "Legal Advice":"86.957",
        "Financial Advice":"100.000",
        "Medical Advice":"87.413",
        "Government Advice":"52.632",
        "Sexual Content":"60.355"
    },
    {
        "Model":"NousResearch\/Nous-Capybara-7B-V1.9",
        "Average":"61.154",
        "Illegal Activity":"45.918",
        "Children Harm":"50.000",
        "Hate\/Harass\/Violence":"66.407",
        "Malware":"20.896",
        "Physical Harm":"39.010",
        "Economic Harm":"55.263",
        "Fraud\/Deception":"55.123",
        "Adult Content":"49.123",
        "Political Campaigning":"89.888",
        "Privacy Violation":"89.545",
        "Legal Advice":"82.609",
        "Financial Advice":"100.000",
        "Medical Advice":"84.615",
        "Government Advice":"36.842",
        "Sexual Content":"52.071"
    }
]