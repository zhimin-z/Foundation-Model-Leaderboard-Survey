[
    {
        "table_id":2555,
        "row_id":109451,
        "rank":1,
        "method":"GPT4RoI",
        "mlmodel":{

        },
        "Model":"GPT4RoI",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-07",
        "metrics":{
            "Accuracy":"91.0"
        },
        "raw_metrics":{
            "Accuracy":91.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1242643,
            "title":"GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest",
            "url":"\/paper\/gpt4roi-instruction-tuning-large-language",
            "published":"2023-07-07T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":24389,
        "rank":2,
        "method":"ERNIE-ViL-large(ensemble of 15 models)",
        "mlmodel":{

        },
        "Model":"ERNIE-ViL-large",
        "method_details":"ensemble of 15 models",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-30",
        "metrics":{
            "Accuracy":"86.1"
        },
        "raw_metrics":{
            "Accuracy":86.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":206405,
            "title":"ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph",
            "url":"\/paper\/ernie-vil-knowledge-enhanced-vision-language",
            "published":"2020-06-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/ernie-vil-knowledge-enhanced-vision-language\/review\/?hl=24389"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":24388,
        "rank":3,
        "method":"UNITER-large (ensemble of 10 models)",
        "mlmodel":{

        },
        "Model":"UNITER-large ",
        "method_details":"ensemble of 10 models",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-25",
        "metrics":{
            "Accuracy":"83.4"
        },
        "raw_metrics":{
            "Accuracy":83.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":156206,
            "title":"UNITER: UNiversal Image-TExt Representation Learning",
            "url":"\/paper\/uniter-learning-universal-image-text-1",
            "published":"2019-09-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uniter-learning-universal-image-text-1\/review\/?hl=24388"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":14804,
        "rank":4,
        "method":"UNITER (Large)",
        "mlmodel":{

        },
        "Model":"UNITER ",
        "method_details":"Large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-25",
        "metrics":{
            "Accuracy":"80.8"
        },
        "raw_metrics":{
            "Accuracy":80.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":156206,
            "title":"UNITER: UNiversal Image-TExt Representation Learning",
            "url":"\/paper\/uniter-learning-universal-image-text-1",
            "published":"2019-09-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uniter-learning-universal-image-text-1\/review\/?hl=14804"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":40438,
        "rank":5,
        "method":"KVL-BERTLARGE",
        "mlmodel":{

        },
        "Model":"KVL-BERTLARGE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-13",
        "metrics":{
            "Accuracy":"78.6"
        },
        "raw_metrics":{
            "Accuracy":78.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":727505,
            "title":"KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning",
            "url":"\/paper\/kvl-bert-knowledge-enhanced-visual-and",
            "published":"2020-12-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/kvl-bert-knowledge-enhanced-visual-and\/review\/?hl=40438"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":14805,
        "rank":6,
        "method":"VL-BERTLARGE",
        "mlmodel":{

        },
        "Model":"VL-BERTLARGE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-22",
        "metrics":{
            "Accuracy":"78.4"
        },
        "raw_metrics":{
            "Accuracy":78.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":150926,
            "title":"VL-BERT: Pre-training of Generic Visual-Linguistic Representations",
            "url":"\/paper\/vl-bert-pre-training-of-generic-visual",
            "published":"2019-08-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vl-bert-pre-training-of-generic-visual\/review\/?hl=14805"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":50620,
        "rank":7,
        "method":"VL-T5",
        "mlmodel":{

        },
        "Model":"VL-T5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-04",
        "metrics":{
            "Accuracy":"77.8"
        },
        "raw_metrics":{
            "Accuracy":77.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":742287,
            "title":"Unifying Vision-and-Language Tasks via Text Generation",
            "url":"\/paper\/unifying-vision-and-language-tasks-via-text",
            "published":"2021-02-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unifying-vision-and-language-tasks-via-text\/review\/?hl=50620"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":2555,
        "row_id":14806,
        "rank":8,
        "method":"VisualBERT",
        "mlmodel":{

        },
        "Model":"VisualBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-09",
        "metrics":{
            "Accuracy":"73.2"
        },
        "raw_metrics":{
            "Accuracy":73.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":149599,
            "title":"VisualBERT: A Simple and Performant Baseline for Vision and Language",
            "url":"\/paper\/visualbert-a-simple-and-performant-baseline",
            "published":"2019-08-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/visualbert-a-simple-and-performant-baseline\/review\/?hl=14806"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]