[
    {
        "table_id":3159,
        "row_id":60412,
        "rank":1,
        "Model":"ST-MoE-32B",
        "mlmodel":{

        },
        "method_short":"ST-MoE-32B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-17",
        "metrics":{
            "Accuracy":"95.2"
        },
        "raw_metrics":{
            "Accuracy":95.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":964307,
            "title":"ST-MoE: Designing Stable and Transferable Sparse Expert Models",
            "url":"\/paper\/designing-effective-sparse-expert-models",
            "published":"2022-02-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/designing-effective-sparse-expert-models\/review\/?hl=60412"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":102556,
        "rank":2,
        "Model":"PaLM 2-L (one-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM 2-L ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"89.7"
        },
        "raw_metrics":{
            "Accuracy":89.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210556,
            "title":"PaLM 2 Technical Report",
            "url":"\/paper\/palm-2-technical-report-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/palm-2-technical-report-1\/review\/?hl=102556"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":102555,
        "rank":3,
        "Model":"PaLM 2-M (one-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM 2-M ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"88.0"
        },
        "raw_metrics":{
            "Accuracy":88.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210556,
            "title":"PaLM 2 Technical Report",
            "url":"\/paper\/palm-2-technical-report-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/palm-2-technical-report-1\/review\/?hl=102555"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":102554,
        "rank":4,
        "Model":"PaLM 2-S (one-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM 2-S ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"85.6"
        },
        "raw_metrics":{
            "Accuracy":85.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210556,
            "title":"PaLM 2 Technical Report",
            "url":"\/paper\/palm-2-technical-report-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/palm-2-technical-report-1\/review\/?hl=102554"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":105775,
        "rank":5,
        "Model":"LLaMA-65B+CFG (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA-65B+CFG ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-30",
        "metrics":{
            "Accuracy":"84.2"
        },
        "raw_metrics":{
            "Accuracy":84.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1238561,
            "title":"Stay on topic with Classifier-Free Guidance",
            "url":"\/paper\/stay-on-topic-with-classifier-free-guidance",
            "published":"2023-06-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/stay-on-topic-with-classifier-free-guidance\/review\/?hl=105775"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":85071,
        "rank":6,
        "Model":"GAL 120B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GAL 120B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"83.8"
        },
        "raw_metrics":{
            "Accuracy":83.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85071"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":105774,
        "rank":7,
        "Model":"LLaMA-30B+CFG (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA-30B+CFG ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-30",
        "metrics":{
            "Accuracy":"83.2"
        },
        "raw_metrics":{
            "Accuracy":83.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1238561,
            "title":"Stay on topic with Classifier-Free Guidance",
            "url":"\/paper\/stay-on-topic-with-classifier-free-guidance",
            "published":"2023-06-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/stay-on-topic-with-classifier-free-guidance\/review\/?hl=105774"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":97627,
        "rank":8,
        "Model":"LLaMA 33B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 33B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"80.0"
        },
        "raw_metrics":{
            "Accuracy":80.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97627"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":112773,
        "rank":9,
        "Model":"Mistral 7B",
        "mlmodel":{

        },
        "method_short":"Mistral 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-10",
        "metrics":{
            "Accuracy":"80.0"
        },
        "raw_metrics":{
            "Accuracy":80.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1297015,
            "title":"Mistral 7B",
            "url":"\/paper\/mistral-7b",
            "published":"2023-10-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mistral-7b\/review\/?hl=112773"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":105773,
        "rank":10,
        "Model":"LLaMA-13B+CFG (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA-13B+CFG ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-30",
        "metrics":{
            "Accuracy":"79.1"
        },
        "raw_metrics":{
            "Accuracy":79.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1238561,
            "title":"Stay on topic with Classifier-Free Guidance",
            "url":"\/paper\/stay-on-topic-with-classifier-free-guidance",
            "published":"2023-06-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/stay-on-topic-with-classifier-free-guidance\/review\/?hl=105773"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":97628,
        "rank":11,
        "Model":"LLaMA 65B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 65B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"78.9"
        },
        "raw_metrics":{
            "Accuracy":78.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97628"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":108556,
        "rank":12,
        "Model":"phi-1.5-web 1.3B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"phi-1.5-web 1.3B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-11",
        "metrics":{
            "Accuracy":"76.1"
        },
        "raw_metrics":{
            "Accuracy":76.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1275377,
            "title":"Textbooks Are All You Need II: phi-1.5 technical report",
            "url":"\/paper\/textbooks-are-all-you-need-ii-phi-1-5",
            "published":"2023-09-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/textbooks-are-all-you-need-ii-phi-1-5\/review\/?hl=108556"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":100767,
        "rank":13,
        "Model":"BLOOM 176B (one-shot)",
        "mlmodel":{

        },
        "method_short":"BLOOM 176B ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Accuracy":"75.93"
        },
        "raw_metrics":{
            "Accuracy":75.93
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183339,
            "title":"BloombergGPT: A Large Language Model for Finance",
            "url":"\/paper\/bloomberggpt-a-large-language-model-for",
            "published":"2023-03-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/bloomberggpt-a-large-language-model-for\/review\/?hl=100767"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":60407,
        "rank":14,
        "Model":"GLaM (64B\/64E) (5-shot)",
        "mlmodel":{

        },
        "method_short":"GLaM ",
        "method_details":"64B\/64E",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-13",
        "metrics":{
            "Accuracy":"74.8"
        },
        "raw_metrics":{
            "Accuracy":74.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":929896,
            "title":"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts",
            "url":"\/paper\/glam-efficient-scaling-of-language-models",
            "published":"2021-12-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/glam-efficient-scaling-of-language-models\/review\/?hl=60407"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":97626,
        "rank":15,
        "Model":"LLaMA 13B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 13B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"74.8"
        },
        "raw_metrics":{
            "Accuracy":74.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97626"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":100764,
        "rank":16,
        "Model":"Bloomberg GPT (one-shot)",
        "mlmodel":{

        },
        "method_short":"Bloomberg GPT ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Accuracy":"73.99"
        },
        "raw_metrics":{
            "Accuracy":73.99
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183339,
            "title":"BloombergGPT: A Large Language Model for Finance",
            "url":"\/paper\/bloomberggpt-a-large-language-model-for",
            "published":"2023-03-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/bloomberggpt-a-large-language-model-for\/review\/?hl=100764"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":97625,
        "rank":17,
        "Model":"LLaMA 7B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 7B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"72.8"
        },
        "raw_metrics":{
            "Accuracy":72.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97625"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":100766,
        "rank":18,
        "Model":"OPT 66B (one-shot)",
        "mlmodel":{

        },
        "method_short":"OPT 66B ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Accuracy":"71.25"
        },
        "raw_metrics":{
            "Accuracy":71.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183339,
            "title":"BloombergGPT: A Large Language Model for Finance",
            "url":"\/paper\/bloomberggpt-a-large-language-model-for",
            "published":"2023-03-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/bloomberggpt-a-large-language-model-for\/review\/?hl=100766"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":60405,
        "rank":19,
        "Model":"GPT-3 175B (1 shot)",
        "mlmodel":{

        },
        "method_short":"GPT-3 175B ",
        "method_details":"1 shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-28",
        "metrics":{
            "Accuracy":"71.2"
        },
        "raw_metrics":{
            "Accuracy":71.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":198147,
            "title":"Language Models are Few-Shot Learners",
            "url":"\/paper\/language-models-are-few-shot-learners",
            "published":"2020-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/language-models-are-few-shot-learners\/review\/?hl=60405"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":88779,
        "rank":20,
        "Model":"OPT-175B",
        "mlmodel":{

        },
        "method_short":"OPT-175B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "Accuracy":"71.04"
        },
        "raw_metrics":{
            "Accuracy":71.04
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136959,
            "title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "url":"\/paper\/massive-language-models-can-be-accurately",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/massive-language-models-can-be-accurately\/review\/?hl=88779"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":100765,
        "rank":21,
        "Model":"GPT-NeoX (one-shot)",
        "mlmodel":{

        },
        "method_short":"GPT-NeoX ",
        "method_details":"one-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-30",
        "metrics":{
            "Accuracy":"70.79"
        },
        "raw_metrics":{
            "Accuracy":70.79
        },
        "uses_additional_data":false,
        "paper":{
            "id":1183339,
            "title":"BloombergGPT: A Large Language Model for Finance",
            "url":"\/paper\/bloomberggpt-a-large-language-model-for",
            "published":"2023-03-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/bloomberggpt-a-large-language-model-for\/review\/?hl=100765"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":88794,
        "rank":22,
        "Model":"SparseGPT (175B, 50% Sparsity)",
        "mlmodel":{

        },
        "method_short":"SparseGPT ",
        "method_details":"175B, 50% Sparsity",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "Accuracy":"69.65"
        },
        "raw_metrics":{
            "Accuracy":69.65
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136959,
            "title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "url":"\/paper\/massive-language-models-can-be-accurately",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/massive-language-models-can-be-accurately\/review\/?hl=88794"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":16805,
        "rank":23,
        "Model":"GPT-3 175B (0 shot)",
        "mlmodel":{

        },
        "method_short":"GPT-3 175B ",
        "method_details":"0 shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-28",
        "metrics":{
            "Accuracy":"68.8"
        },
        "raw_metrics":{
            "Accuracy":68.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":198147,
            "title":"Language Models are Few-Shot Learners",
            "url":"\/paper\/language-models-are-few-shot-learners",
            "published":"2020-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/language-models-are-few-shot-learners\/review\/?hl=16805"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":85100,
        "rank":24,
        "Model":"GPT-3 (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GPT-3 ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"68.8"
        },
        "raw_metrics":{
            "Accuracy":68.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85100"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":88795,
        "rank":25,
        "Model":"SparseGPT (175B, 4:8 Sparsity)",
        "mlmodel":{

        },
        "method_short":"SparseGPT ",
        "method_details":"175B, 4:8 Sparsity",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "Accuracy":"68.35"
        },
        "raw_metrics":{
            "Accuracy":68.35
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136959,
            "title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "url":"\/paper\/massive-language-models-can-be-accurately",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/massive-language-models-can-be-accurately\/review\/?hl=88795"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":60406,
        "rank":26,
        "Model":"GLaM 64B\/64E (0-shot)",
        "mlmodel":{

        },
        "method_short":"GLaM 64B\/64E ",
        "method_details":"0-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-13",
        "metrics":{
            "Accuracy":"68.0"
        },
        "raw_metrics":{
            "Accuracy":68.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":929896,
            "title":"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts",
            "url":"\/paper\/glam-efficient-scaling-of-language-models",
            "published":"2021-12-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/glam-efficient-scaling-of-language-models\/review\/?hl=60406"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":88796,
        "rank":27,
        "Model":"SparseGPT (175B, 2:4 Sparsity)",
        "mlmodel":{

        },
        "method_short":"SparseGPT ",
        "method_details":"175B, 2:4 Sparsity",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "Accuracy":"67.08"
        },
        "raw_metrics":{
            "Accuracy":67.08
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136959,
            "title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "url":"\/paper\/massive-language-models-can-be-accurately",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/massive-language-models-can-be-accurately\/review\/?hl=88796"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":105772,
        "rank":28,
        "Model":"LLaMA-7B+CFG (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA-7B+CFG ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-30",
        "metrics":{
            "Accuracy":"58.9"
        },
        "raw_metrics":{
            "Accuracy":58.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1238561,
            "title":"Stay on topic with Classifier-Free Guidance",
            "url":"\/paper\/stay-on-topic-with-classifier-free-guidance",
            "published":"2023-06-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/stay-on-topic-with-classifier-free-guidance\/review\/?hl=105772"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":85099,
        "rank":29,
        "Model":"BLOOM (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"BLOOM ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"40.7"
        },
        "raw_metrics":{
            "Accuracy":40.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85099"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":85098,
        "rank":30,
        "Model":"OPT (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"OPT ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"37.4"
        },
        "raw_metrics":{
            "Accuracy":37.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85098"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":3159,
        "row_id":88793,
        "rank":31,
        "Model":"OPT-175B (50% Sparsity)",
        "mlmodel":{

        },
        "method_short":"OPT-175B ",
        "method_details":"50% Sparsity",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-02",
        "metrics":{
            "Accuracy":"28.03"
        },
        "raw_metrics":{
            "Accuracy":28.03
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136959,
            "title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "url":"\/paper\/massive-language-models-can-be-accurately",
            "published":"2023-01-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/massive-language-models-can-be-accurately\/review\/?hl=88793"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]