[
    {
        "table_id":24022,
        "row_id":114137,
        "rank":1,
        "method":"VLAP (4 frames)",
        "mlmodel":{

        },
        "Model":"VLAP ",
        "method_details":"4 frames",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-13",
        "metrics":{
            "Average Accuracy":"67.1"
        },
        "raw_metrics":{
            "Average Accuracy":67.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1342616,
            "title":"VLAP: Efficient Video-Language Alignment via Frame Prompting and Distilling for Video Question Answering",
            "url":"\/paper\/vlap-efficient-video-language-alignment-via",
            "published":"2023-12-13T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":110816,
        "rank":2,
        "method":"LLaMA-VQA",
        "mlmodel":{

        },
        "Model":"LLaMA-VQA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-24",
        "metrics":{
            "Average Accuracy":"65.4"
        },
        "raw_metrics":{
            "Average Accuracy":65.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1307209,
            "title":"Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
            "url":"\/paper\/large-language-models-are-temporal-and-causal",
            "published":"2023-10-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-temporal-and-causal\/review\/?hl=110816"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102694,
        "rank":3,
        "method":"SeViLA",
        "mlmodel":{

        },
        "Model":"SeViLA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Average Accuracy":"64.9"
        },
        "raw_metrics":{
            "Average Accuracy":64.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102703,
        "rank":4,
        "method":"InternVideo",
        "mlmodel":{

        },
        "Model":"InternVideo",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-06",
        "metrics":{
            "Average Accuracy":"58.7"
        },
        "raw_metrics":{
            "Average Accuracy":58.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1124231,
            "title":"InternVideo: General Video Foundation Models via Generative and Discriminative Learning",
            "url":"\/paper\/internvideo-general-video-foundation-models",
            "published":"2022-12-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/internvideo-general-video-foundation-models\/review\/?hl=102703"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102695,
        "rank":5,
        "method":"MIST",
        "mlmodel":{

        },
        "Model":"MIST",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-19",
        "metrics":{
            "Average Accuracy":"51.13"
        },
        "raw_metrics":{
            "Average Accuracy":51.13
        },
        "uses_additional_data":false,
        "paper":{
            "id":1130557,
            "title":"MIST: Multi-modal Iterative Spatial-Temporal Transformer for Long-form Video Question Answering",
            "url":"\/paper\/mist-multi-modal-iterative-spatial-temporal",
            "published":"2022-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mist-multi-modal-iterative-spatial-temporal\/review\/?hl=102695"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102700,
        "rank":6,
        "method":"Temp[ATP]",
        "mlmodel":{

        },
        "Model":"Temp[ATP]",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-03",
        "metrics":{
            "Average Accuracy":"48.37"
        },
        "raw_metrics":{
            "Average Accuracy":48.37
        },
        "uses_additional_data":false,
        "paper":{
            "id":1021055,
            "title":"Revisiting the \"Video\" in Video-Language Understanding",
            "url":"\/paper\/revisiting-the-video-in-video-language",
            "published":"2022-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/revisiting-the-video-in-video-language\/review\/?hl=102700"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":109538,
        "rank":7,
        "method":"AnyMAL-70B (0-shot)",
        "mlmodel":{

        },
        "Model":"AnyMAL-70B ",
        "method_details":"0-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-27",
        "metrics":{
            "Average Accuracy":"48.2"
        },
        "raw_metrics":{
            "Average Accuracy":48.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1290413,
            "title":"AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model",
            "url":"\/paper\/anymal-an-efficient-and-scalable-any-modality",
            "published":"2023-09-27T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/anymal-an-efficient-and-scalable-any-modality\/review\/?hl=109538"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102697,
        "rank":8,
        "method":"All-in-one",
        "mlmodel":{

        },
        "Model":"All-in-one",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-14",
        "metrics":{
            "Average Accuracy":"47.5"
        },
        "raw_metrics":{
            "Average Accuracy":47.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":976242,
            "title":"All in One: Exploring Unified Video-Language Pre-training",
            "url":"\/paper\/all-in-one-exploring-unified-video-language",
            "published":"2022-03-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/all-in-one-exploring-unified-video-language\/review\/?hl=102697"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102841,
        "rank":9,
        "method":"SeViLA (0-shot)",
        "mlmodel":{

        },
        "Model":"SeViLA ",
        "method_details":"0-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Average Accuracy":"44.6"
        },
        "raw_metrics":{
            "Average Accuracy":44.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102701,
        "rank":10,
        "method":"Flamingo-9B (4-shot)",
        "mlmodel":{

        },
        "Model":"Flamingo-9B ",
        "method_details":"4-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-29",
        "metrics":{
            "Average Accuracy":"42.8"
        },
        "raw_metrics":{
            "Average Accuracy":42.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001838,
            "title":"Flamingo: a Visual Language Model for Few-Shot Learning",
            "url":"\/paper\/flamingo-a-visual-language-model-for-few-shot-1",
            "published":"2022-04-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102702,
        "rank":11,
        "method":"Flamingo-80B (4-shot)",
        "mlmodel":{

        },
        "Model":"Flamingo-80B ",
        "method_details":"4-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-29",
        "metrics":{
            "Average Accuracy":"42.4"
        },
        "raw_metrics":{
            "Average Accuracy":42.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001838,
            "title":"Flamingo: a Visual Language Model for Few-Shot Learning",
            "url":"\/paper\/flamingo-a-visual-language-model-for-few-shot-1",
            "published":"2022-04-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102698,
        "rank":12,
        "method":"Flamingo-9B (0-shot)",
        "mlmodel":{

        },
        "Model":"Flamingo-9B ",
        "method_details":"0-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-29",
        "metrics":{
            "Average Accuracy":"41.8"
        },
        "raw_metrics":{
            "Average Accuracy":41.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001838,
            "title":"Flamingo: a Visual Language Model for Few-Shot Learning",
            "url":"\/paper\/flamingo-a-visual-language-model-for-few-shot-1",
            "published":"2022-04-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24022,
        "row_id":102699,
        "rank":13,
        "method":"Flamingo-80B (0-shot)",
        "mlmodel":{

        },
        "Model":"Flamingo-80B ",
        "method_details":"0-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-29",
        "metrics":{
            "Average Accuracy":"39.7"
        },
        "raw_metrics":{
            "Average Accuracy":39.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1001838,
            "title":"Flamingo: a Visual Language Model for Few-Shot Learning",
            "url":"\/paper\/flamingo-a-visual-language-model-for-few-shot-1",
            "published":"2022-04-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]