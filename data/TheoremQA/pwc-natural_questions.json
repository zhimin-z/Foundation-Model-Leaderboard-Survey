[
    {
        "table_id":24730,
        "row_id":107201,
        "rank":1,
        "Model":"GPT-4 (PoT)",
        "mlmodel":{

        },
        "method_short":"GPT-4 ",
        "method_details":"PoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-21",
        "metrics":{
            "Accuracy":"52.4"
        },
        "raw_metrics":{
            "Accuracy":52.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107201"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107200,
        "rank":2,
        "Model":"GPT-4 (CoT)",
        "mlmodel":{

        },
        "method_short":"GPT-4 ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-21",
        "metrics":{
            "Accuracy":"43.8"
        },
        "raw_metrics":{
            "Accuracy":43.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107200"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107203,
        "rank":3,
        "Model":"GPT-3.5-turbo (PoT)",
        "mlmodel":{

        },
        "method_short":"GPT-3.5-turbo ",
        "method_details":"PoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Accuracy":"35.6"
        },
        "raw_metrics":{
            "Accuracy":35.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107203"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107204,
        "rank":4,
        "Model":"PaLM-2-unicorn (CoT)",
        "mlmodel":{

        },
        "method_short":"PaLM-2-unicorn ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "Accuracy":"31.8"
        },
        "raw_metrics":{
            "Accuracy":31.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107204"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107202,
        "rank":5,
        "Model":"GPT-3.5-turbo (CoT)",
        "mlmodel":{

        },
        "method_short":"GPT-3.5-turbo ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Accuracy":"30.2"
        },
        "raw_metrics":{
            "Accuracy":30.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107202"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107205,
        "rank":6,
        "Model":"Claude-v1 (PoT)",
        "mlmodel":{

        },
        "method_short":"Claude-v1 ",
        "method_details":"PoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Accuracy":"25.9"
        },
        "raw_metrics":{
            "Accuracy":25.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107205"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107206,
        "rank":7,
        "Model":"Claude-v1 (CoT)",
        "mlmodel":{

        },
        "method_short":"Claude-v1 ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Accuracy":"24.9"
        },
        "raw_metrics":{
            "Accuracy":24.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107206"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107208,
        "rank":8,
        "Model":"code-davinci-002",
        "mlmodel":{

        },
        "method_short":"code-davinci-002",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Accuracy":"23.9"
        },
        "raw_metrics":{
            "Accuracy":23.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107208"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107207,
        "rank":9,
        "Model":"Claude-instant (CoT)",
        "mlmodel":{

        },
        "method_short":"Claude-instant ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "Accuracy":"23.6"
        },
        "raw_metrics":{
            "Accuracy":23.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107207"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107209,
        "rank":10,
        "Model":"text-davinci-003",
        "mlmodel":{

        },
        "method_short":"text-davinci-003",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-02",
        "metrics":{
            "Accuracy":"22.8"
        },
        "raw_metrics":{
            "Accuracy":22.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107209"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24730,
        "row_id":107210,
        "rank":11,
        "Model":"PaLM-2-bison (CoT)",
        "mlmodel":{

        },
        "method_short":"PaLM-2-bison ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-01",
        "metrics":{
            "Accuracy":"21.0"
        },
        "raw_metrics":{
            "Accuracy":21.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212898,
            "title":"TheoremQA: A Theorem-driven Question Answering dataset",
            "url":"\/paper\/theoremqa-a-theorem-driven-question-answering",
            "published":"2023-05-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/theoremqa-a-theorem-driven-question-answering\/review\/?hl=107210"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]