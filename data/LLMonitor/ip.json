[
    {
        "Model":"GPT 4 03\/14 (Legacy)",
        "Score":93
    },
    {
        "Model":"GPT 4",
        "Score":89
    },
    {
        "Model":"GPT 3.5 Turbo Instruct",
        "Score":84
    },
    {
        "Model":"GPT 3.5 Turbo",
        "Score":81
    },
    {
        "Model":"GPT 3.5 Turbo 03\/01 (Legacy)",
        "Score":79
    },
    {
        "Model":"Claude v2",
        "Score":68
    },
    {
        "Model":"Falcon Chat (180B)",
        "Score":67
    },
    {
        "Model":"Hermes Llama2 13B",
        "Score":66
    },
    {
        "Model":"Claude v1",
        "Score":66
    },
    {
        "Model":"Jurassic 2 Ultra",
        "Score":61
    },
    {
        "Model":"ReMM SLERP L2 13B",
        "Score":61
    },
    {
        "Model":"Synthia 70B",
        "Score":61
    },
    {
        "Model":"PaLM 2 Bison (Code Chat)",
        "Score":60
    },
    {
        "Model":"Jurassic 2 Mid",
        "Score":60
    },
    {
        "Model":"Claude Instant v1",
        "Score":60
    },
    {
        "Model":"LLaMA-2-Chat (70B)",
        "Score":60
    },
    {
        "Model":"Mythalion 13B",
        "Score":59
    },
    {
        "Model":"Phind CodeLlama 34B v2",
        "Score":57
    },
    {
        "Model":"PaLM 2 Bison",
        "Score":57
    },
    {
        "Model":"Mistral 7B Instruct v0.1",
        "Score":57
    },
    {
        "Model":"MythoMax-L2 (13B)",
        "Score":56
    },
    {
        "Model":"command",
        "Score":55
    },
    {
        "Model":"Guanaco (65B)",
        "Score":51
    },
    {
        "Model":"Airoboros L2 70B",
        "Score":51
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Score":50
    },
    {
        "Model":"LLaMA-2-Chat (13B)",
        "Score":50
    },
    {
        "Model":"LLaMA-2-Chat (7B)",
        "Score":50
    },
    {
        "Model":"command-nightly",
        "Score":47
    },
    {
        "Model":"Chronos Hermes (13B)",
        "Score":45
    },
    {
        "Model":"MPT-Chat (7B)",
        "Score":43
    },
    {
        "Model":"Guanaco (33B)",
        "Score":43
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Score":41
    },
    {
        "Model":"MPT-Chat (30B)",
        "Score":40
    },
    {
        "Model":"Falcon Instruct (40B)",
        "Score":40
    },
    {
        "Model":"Alpaca (7B)",
        "Score":39
    },
    {
        "Model":"Pythia-Chat-Base (7B)",
        "Score":38
    },
    {
        "Model":"Code Llama Instruct (13B)",
        "Score":38
    },
    {
        "Model":"RedPajama-INCITE Chat (7B)",
        "Score":38
    },
    {
        "Model":"GPT-NeoXT-Chat-Base (20B)",
        "Score":34
    },
    {
        "Model":"Code Llama Instruct (34B)",
        "Score":34
    },
    {
        "Model":"StarCoderChat Alpha (16B)",
        "Score":33
    },
    {
        "Model":"command-light",
        "Score":33
    },
    {
        "Model":"Weaver 12k",
        "Score":32
    },
    {
        "Model":"Falcon Instruct (7B)",
        "Score":32
    },
    {
        "Model":"Koala (13B)",
        "Score":31
    },
    {
        "Model":"Jurassic 2 Light",
        "Score":30
    },
    {
        "Model":"Guanaco (13B)",
        "Score":30
    },
    {
        "Model":"Code Llama Instruct (7B)",
        "Score":24
    },
    {
        "Model":"RedPajama-INCITE Chat (3B)",
        "Score":24
    },
    {
        "Model":"Dolly v2 (12B)",
        "Score":23
    },
    {
        "Model":"Dolly v2 (7B)",
        "Score":21
    },
    {
        "Model":"Dolly v2 (3B)",
        "Score":17
    },
    {
        "Model":"Open-Assistant StableLM SFT-7 (7B)",
        "Score":10
    },
    {
        "Model":"Open-Assistant Pythia SFT-4 (12B)",
        "Score":7
    }
]