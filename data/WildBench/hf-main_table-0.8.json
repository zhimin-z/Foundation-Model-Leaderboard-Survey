[
    {
        "Model":"Claude 3 Opus",
        "Overall Elo":1123,
        "Task-Avg Elo":1106.8,
        "# battles":4039,
        "Length":2460.3
    },
    {
        "Model":"Mistral-Large",
        "Overall Elo":1104,
        "Task-Avg Elo":1090.4,
        "# battles":2434,
        "Length":2352.2
    },
    {
        "Model":"Claude 3 Sonnet",
        "Overall Elo":1104,
        "Task-Avg Elo":1086.2,
        "# battles":3127,
        "Length":2456.2
    },
    {
        "Model":"gpt-3.5-turbo-0125",
        "Overall Elo":1101,
        "Task-Avg Elo":1108.1,
        "# battles":14627,
        "Length":1725.7
    },
    {
        "Model":"gpt-4-0125-preview",
        "Overall Elo":1094,
        "Task-Avg Elo":1091.0,
        "# battles":6163,
        "Length":3190.7
    },
    {
        "Model":"gemini-1.0-pro",
        "Overall Elo":1087,
        "Task-Avg Elo":1071.0,
        "# battles":2139,
        "Length":2407.6
    },
    {
        "Model":"DBRX Instruct",
        "Overall Elo":1063,
        "Task-Avg Elo":1044.1,
        "# battles":2014,
        "Length":2148.7
    },
    {
        "Model":"Mixtral-8x7B-Instruct",
        "Overall Elo":1044,
        "Task-Avg Elo":1029.7,
        "# battles":3739,
        "Length":2484.0
    },
    {
        "Model":"StarlingLM-7B-beta",
        "Overall Elo":1021,
        "Task-Avg Elo":1013.2,
        "# battles":2045,
        "Length":2920.4
    },
    {
        "Model":"Yi-34B-Chat",
        "Overall Elo":1017,
        "Task-Avg Elo":1006.8,
        "# battles":2731,
        "Length":2899.2
    },
    {
        "Model":"Mistral-7B-Instruct (v0.2)",
        "Overall Elo":1015,
        "Task-Avg Elo":1014.3,
        "# battles":2637,
        "Length":2852.3
    },
    {
        "Model":"Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Overall Elo":1010,
        "Task-Avg Elo":1005.8,
        "# battles":1599,
        "Length":2878.8
    },
    {
        "Model":"Gemma-7B-it",
        "Overall Elo":1001,
        "Task-Avg Elo":1011.3,
        "# battles":2863,
        "Length":1960.8
    },
    {
        "Model":"Zephyr-7b-Gemma",
        "Overall Elo":983,
        "Task-Avg Elo":982.5,
        "# battles":1647,
        "Length":2552.0
    },
    {
        "Model":"Vicuna-13b-v1.5",
        "Overall Elo":972,
        "Task-Avg Elo":971.8,
        "# battles":2831,
        "Length":1864.3
    },
    {
        "Model":"Tulu-2-dpo-70b",
        "Overall Elo":962,
        "Task-Avg Elo":951.5,
        "# battles":3743,
        "Length":2630.2
    },
    {
        "Model":"Llama-2-70B-chat",
        "Overall Elo":961,
        "Task-Avg Elo":971.2,
        "# battles":2295,
        "Length":3077.1
    },
    {
        "Model":"Llama-2-13B-chat",
        "Overall Elo":941,
        "Task-Avg Elo":946.4,
        "# battles":2207,
        "Length":2943.3
    },
    {
        "Model":"Llama-2-7B-chat",
        "Overall Elo":924,
        "Task-Avg Elo":935.8,
        "# battles":2216,
        "Length":2965.4
    },
    {
        "Model":"Zephyr-7b-beta",
        "Overall Elo":923,
        "Task-Avg Elo":923.9,
        "# battles":3691,
        "Length":3011.3
    },
    {
        "Model":"Llama-2-7B-chat (+sys prmpt)",
        "Overall Elo":899,
        "Task-Avg Elo":919.4,
        "# battles":2381,
        "Length":2137.3
    },
    {
        "Model":"Mistral-7B-Instruct",
        "Overall Elo":883,
        "Task-Avg Elo":904.5,
        "# battles":2768,
        "Length":2208.8
    }
]