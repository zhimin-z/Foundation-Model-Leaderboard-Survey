[
    {
        "table_id":16199,
        "row_id":102920,
        "rank":1,
        "method":"Med-PaLM 2 (ER)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"ER",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"85.4"
        },
        "raw_metrics":{
            "Accuracy":85.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102920"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":102919,
        "rank":2,
        "method":"Med-PaLM 2 (CoT + SC)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"CoT + SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"83.7"
        },
        "raw_metrics":{
            "Accuracy":83.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102919"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":102918,
        "rank":3,
        "method":"Med-PaLM 2 (5-shot)",
        "mlmodel":{

        },
        "method_short":"Med-PaLM 2 ",
        "method_details":"5-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-16",
        "metrics":{
            "Accuracy":"79.7"
        },
        "raw_metrics":{
            "Accuracy":79.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208956,
            "title":"Towards Expert-Level Medical Question Answering with Large Language Models",
            "url":"\/paper\/towards-expert-level-medical-question",
            "published":"2023-05-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-expert-level-medical-question\/review\/?hl=102918"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":112892,
        "rank":4,
        "method":"Meditron-70B (CoT + SC)",
        "mlmodel":{

        },
        "method_short":"Meditron-70B ",
        "method_details":"CoT + SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-12",
        "metrics":{
            "Accuracy":"70.2"
        },
        "raw_metrics":{
            "Accuracy":70.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1327790,
            "title":"MEDITRON-70B: Scaling Medical Pretraining for Large Language Models",
            "url":"\/paper\/meditron-70b-scaling-medical-pretraining-for",
            "published":"2023-11-27T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":88374,
        "rank":5,
        "method":"Flan-PaLM (540 B)",
        "mlmodel":{

        },
        "method_short":"Flan-PaLM ",
        "method_details":"540 B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"67.6"
        },
        "raw_metrics":{
            "Accuracy":67.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88374"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":88029,
        "rank":6,
        "method":"Codex 5-shot CoT",
        "mlmodel":{

        },
        "method_short":"Codex 5-shot CoT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-17",
        "metrics":{
            "Accuracy":"60.2"
        },
        "raw_metrics":{
            "Accuracy":60.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1044892,
            "title":"Can large language models reason about medical questions?",
            "url":"\/paper\/can-large-language-models-reason-about",
            "published":"2022-07-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/can-large-language-models-reason-about\/review\/?hl=88029"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":95730,
        "rank":7,
        "method":"VOD (BioLinkBERT)",
        "mlmodel":{

        },
        "method_short":"VOD ",
        "method_details":"BioLinkBERT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-23",
        "metrics":{
            "Accuracy":"55.0"
        },
        "raw_metrics":{
            "Accuracy":55.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1091919,
            "title":"Variational Open-Domain Question Answering",
            "url":"\/paper\/variational-open-domain-question-answering",
            "published":"2022-09-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":108172,
        "rank":8,
        "method":"BioMedGPT-10B",
        "mlmodel":{

        },
        "method_short":"BioMedGPT-10B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"50.4"
        },
        "raw_metrics":{
            "Accuracy":50.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265550,
            "title":"BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine",
            "url":"\/paper\/biomedgpt-open-multimodal-generative-pre",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biomedgpt-open-multimodal-generative-pre\/review\/?hl=108172"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":88375,
        "rank":9,
        "method":"PubMedGPT (2.7 B)",
        "mlmodel":{

        },
        "method_short":"PubMedGPT ",
        "method_details":"2.7 B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"50.3"
        },
        "raw_metrics":{
            "Accuracy":50.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88375"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":72311,
        "rank":10,
        "method":"DRAGON + BioLinkBERT",
        "mlmodel":{

        },
        "method_short":"DRAGON + BioLinkBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-17",
        "metrics":{
            "Accuracy":"47.5"
        },
        "raw_metrics":{
            "Accuracy":47.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1095473,
            "title":"Deep Bidirectional Language-Knowledge Graph Pretraining",
            "url":"\/paper\/deep-bidirectional-language-knowledge-graph",
            "published":"2022-10-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-bidirectional-language-knowledge-graph\/review\/?hl=72311"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":88377,
        "rank":11,
        "method":"BioLinkBERT (340 M)",
        "mlmodel":{

        },
        "method_short":"BioLinkBERT ",
        "method_details":"340 M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"45.1"
        },
        "raw_metrics":{
            "Accuracy":45.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88377"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":80264,
        "rank":12,
        "method":"GAL 120B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GAL 120B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"44.4"
        },
        "raw_metrics":{
            "Accuracy":44.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=80264"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":50836,
        "rank":13,
        "method":"BioLinkBERT (base)",
        "mlmodel":{

        },
        "method_short":"BioLinkBERT ",
        "method_details":"base",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-29",
        "metrics":{
            "Accuracy":"40.0"
        },
        "raw_metrics":{
            "Accuracy":40.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":986102,
            "title":"LinkBERT: Pretraining Language Models with Document Links",
            "url":"\/paper\/linkbert-pretraining-language-models-with",
            "published":"2022-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/linkbert-pretraining-language-models-with\/review\/?hl=50836"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":104731,
        "rank":14,
        "method":"GrapeQA: PEGA",
        "mlmodel":{

        },
        "method_short":"GrapeQA: PEGA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-22",
        "metrics":{
            "Accuracy":"39.51"
        },
        "raw_metrics":{
            "Accuracy":39.51
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178601,
            "title":"GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering",
            "url":"\/paper\/grapeqa-graph-augmentation-and-pruning-to",
            "published":"2023-03-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/grapeqa-graph-augmentation-and-pruning-to\/review\/?hl=104731"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":50837,
        "rank":15,
        "method":"BioBERT (large)",
        "mlmodel":{

        },
        "method_short":"BioBERT ",
        "method_details":"large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Accuracy":"36.7"
        },
        "raw_metrics":{
            "Accuracy":36.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":88412,
            "title":"BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
            "url":"\/paper\/biobert-a-pre-trained-biomedical-language",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":50839,
        "rank":16,
        "method":"BioBERT (base)",
        "mlmodel":{

        },
        "method_short":"BioBERT ",
        "method_details":"base",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Accuracy":"34.1"
        },
        "raw_metrics":{
            "Accuracy":34.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":88412,
            "title":"BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
            "url":"\/paper\/biobert-a-pre-trained-biomedical-language",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":88380,
        "rank":17,
        "method":"GPT-Neo (2.7 B)",
        "mlmodel":{

        },
        "method_short":"GPT-Neo ",
        "method_details":"2.7 B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "Accuracy":"33.3"
        },
        "raw_metrics":{
            "Accuracy":33.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134527,
            "title":"Large Language Models Encode Clinical Knowledge",
            "url":"\/paper\/large-language-models-encode-clinical",
            "published":"2022-12-26T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-encode-clinical\/review\/?hl=88380"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":85178,
        "rank":18,
        "method":"BLOOM (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"BLOOM ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"23.3"
        },
        "raw_metrics":{
            "Accuracy":23.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85178"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16199,
        "row_id":85177,
        "rank":19,
        "method":"OPT (few-shot, k=5)",
        "mlmodel":{

        },
        "method_short":"OPT ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-16",
        "metrics":{
            "Accuracy":"22.8"
        },
        "raw_metrics":{
            "Accuracy":22.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112728,
            "title":"Galactica: A Large Language Model for Science",
            "url":"\/paper\/galactica-a-large-language-model-for-science-1",
            "published":"2022-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/galactica-a-large-language-model-for-science-1\/review\/?hl=85177"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]