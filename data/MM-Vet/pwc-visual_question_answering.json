[
    {
        "table_id":25145,
        "row_id":110824,
        "rank":1,
        "Model":"GPT-4V",
        "mlmodel":{

        },
        "method_short":"GPT-4V",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-25",
        "metrics":{
            "GPT-4 score":"67.7\u00b10.3",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":67.7,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=110824"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":502,
                "name":"Involve APIs",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112087,
        "rank":2,
        "Model":"GPT-4V-Turbo-detail:high",
        "mlmodel":{

        },
        "method_short":"GPT-4V-Turbo-detail:high",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-06",
        "metrics":{
            "GPT-4 score":"67.6\u00b10.1",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":67.6,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=112087"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":502,
                "name":"Involve APIs",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112088,
        "rank":3,
        "Model":"GPT-4V-Turbo-detail:low",
        "mlmodel":{

        },
        "method_short":"GPT-4V-Turbo-detail:low",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-06",
        "metrics":{
            "GPT-4 score":"60.2\u00b10.3",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":60.2,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=112088"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":502,
                "name":"Involve APIs",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112649,
        "rank":4,
        "Model":"CogVLM(Vicuna-13B)",
        "mlmodel":{

        },
        "method_short":"CogVLM",
        "method_details":"Vicuna-13B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "GPT-4 score":"56.8",
            "Params":"30B"
        },
        "raw_metrics":{
            "GPT-4 score":56.8,
            "Params":30.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1315192,
            "title":"CogVLM: Visual Expert for Pretrained Language Models",
            "url":"\/paper\/cogvlm-visual-expert-for-pretrained-language",
            "published":"2023-11-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cogvlm-visual-expert-for-pretrained-language\/review\/?hl=112649"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":111815,
        "rank":5,
        "Model":"CogVLM(Vicuna-7B)",
        "mlmodel":{

        },
        "method_short":"CogVLM",
        "method_details":"Vicuna-7B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-06",
        "metrics":{
            "GPT-4 score":"52.8",
            "Params":"17B"
        },
        "raw_metrics":{
            "GPT-4 score":52.8,
            "Params":17.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1315192,
            "title":"CogVLM: Visual Expert for Pretrained Language Models",
            "url":"\/paper\/cogvlm-visual-expert-for-pretrained-language",
            "published":"2023-11-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cogvlm-visual-expert-for-pretrained-language\/review\/?hl=111815"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109825,
        "rank":6,
        "Model":"MM-ReAct-GPT-4",
        "mlmodel":{

        },
        "method_short":"MM-ReAct-GPT-4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-20",
        "metrics":{
            "GPT-4 score":"44.6\u00b10.2",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":44.6,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1177841,
            "title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action",
            "url":"\/paper\/mm-react-prompting-chatgpt-for-multimodal",
            "published":"2023-03-20T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":502,
                "name":"Involve APIs",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112480,
        "rank":7,
        "Model":"ShareGPT4V-13B",
        "mlmodel":{

        },
        "method_short":"ShareGPT4V-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-21",
        "metrics":{
            "GPT-4 score":"43.1",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":43.1,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1325159,
            "title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions",
            "url":"\/paper\/sharegpt4v-improving-large-multi-modal-models",
            "published":"2023-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sharegpt4v-improving-large-multi-modal-models\/review\/?hl=112480"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112115,
        "rank":8,
        "Model":"SPHINX-2k",
        "mlmodel":{

        },
        "method_short":"SPHINX-2k",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-13",
        "metrics":{
            "GPT-4 score":"40.2",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":40.2,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1319249,
            "title":"SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models",
            "url":"\/paper\/sphinx-the-joint-mixing-of-weights-tasks-and",
            "published":"2023-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sphinx-the-joint-mixing-of-weights-tasks-and\/review\/?hl=112115"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112173,
        "rank":9,
        "Model":"LLaVA-1.5 (LVIS-Instrcut4V)",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5 ",
        "method_details":"LVIS-Instrcut4V",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-13",
        "metrics":{
            "GPT-4 score":"40.2",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":40.2,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1319366,
            "title":"To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning",
            "url":"\/paper\/to-see-is-to-believe-prompting-gpt-4v-for",
            "published":"2023-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/to-see-is-to-believe-prompting-gpt-4v-for\/review\/?hl=112173"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112340,
        "rank":10,
        "Model":"VOLCANO 13B",
        "mlmodel":{

        },
        "method_short":"VOLCANO 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-13",
        "metrics":{
            "GPT-4 score":"38.0",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":38.0,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1319384,
            "title":"Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision",
            "url":"\/paper\/volcano-mitigating-multimodal-hallucination",
            "published":"2023-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/volcano-mitigating-multimodal-hallucination\/review\/?hl=112340"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112481,
        "rank":11,
        "Model":"ShareGPT4V-7B",
        "mlmodel":{

        },
        "method_short":"ShareGPT4V-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-21",
        "metrics":{
            "GPT-4 score":"37.6",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":37.6,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1325159,
            "title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions",
            "url":"\/paper\/sharegpt4v-improving-large-multi-modal-models",
            "published":"2023-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sharegpt4v-improving-large-multi-modal-models\/review\/?hl=112481"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109838,
        "rank":12,
        "Model":"LLaVA-1.5-13B",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "GPT-4 score":"36.3\u00b10.2",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":36.3,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=109838"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109841,
        "rank":13,
        "Model":"Emu-14B",
        "mlmodel":{

        },
        "method_short":"Emu-14B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-11",
        "metrics":{
            "GPT-4 score":"36.3\u00b10.3",
            "Params":"14B"
        },
        "raw_metrics":{
            "GPT-4 score":36.3,
            "Params":14.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1244202,
            "title":"Generative Pretraining in Multimodality",
            "url":"\/paper\/generative-pretraining-in-multimodality",
            "published":"2023-07-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/generative-pretraining-in-multimodality\/review\/?hl=109841"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":111760,
        "rank":14,
        "Model":"mPLUG-Owl2",
        "mlmodel":{

        },
        "method_short":"mPLUG-Owl2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-07",
        "metrics":{
            "GPT-4 score":"36.3\u00b10.1",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":36.3,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1316925,
            "title":"mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration",
            "url":"\/paper\/mplug-owl2-revolutionizing-multi-modal-large",
            "published":"2023-11-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mplug-owl2-revolutionizing-multi-modal-large\/review\/?hl=111760"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109836,
        "rank":15,
        "Model":"DreamLLM-7B",
        "mlmodel":{

        },
        "method_short":"DreamLLM-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-20",
        "metrics":{
            "GPT-4 score":"35.9",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":35.9,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1284047,
            "title":"DreamLLM: Synergistic Multimodal Comprehension and Creation",
            "url":"\/paper\/dreamllm-synergistic-multimodal-comprehension",
            "published":"2023-09-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/dreamllm-synergistic-multimodal-comprehension\/review\/?hl=109836"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112174,
        "rank":16,
        "Model":"LLaVA-Plus-13B (All Tools, V1.3, 336px)",
        "mlmodel":{

        },
        "method_short":"LLaVA-Plus-13B ",
        "method_details":"All Tools, V1.3, 336px",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-09",
        "metrics":{
            "GPT-4 score":"35.0\u00b10.0",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":35.0,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1317898,
            "title":"LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents",
            "url":"\/paper\/llava-plus-learning-to-use-tools-for-creating",
            "published":"2023-11-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llava-plus-learning-to-use-tools-for-creating\/review\/?hl=112174"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109821,
        "rank":17,
        "Model":"LLaVA-13B (LLaMA-2)",
        "mlmodel":{

        },
        "method_short":"LLaVA-13B ",
        "method_details":"LLaMA-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-19",
        "metrics":{
            "GPT-4 score":"32.9\u00b10.1",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":32.9,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109822,
        "rank":18,
        "Model":"LLaVA-13B (Vicuna1.3, 336px)",
        "mlmodel":{

        },
        "method_short":"LLaVA-13B ",
        "method_details":"Vicuna1.3, 336px",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-19",
        "metrics":{
            "GPT-4 score":"32.5\u00b10.1",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":32.5,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112341,
        "rank":19,
        "Model":"VOLCANO 7B",
        "mlmodel":{

        },
        "method_short":"VOLCANO 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-13",
        "metrics":{
            "GPT-4 score":"32.0",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":32.0,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1319384,
            "title":"Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision",
            "url":"\/paper\/volcano-mitigating-multimodal-hallucination",
            "published":"2023-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/volcano-mitigating-multimodal-hallucination\/review\/?hl=112341"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":110210,
        "rank":20,
        "Model":"LRV-Instruction-7B",
        "mlmodel":{

        },
        "method_short":"LRV-Instruction-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-26",
        "metrics":{
            "GPT-4 score":"31.7\u00b10.1",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":31.7,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1235034,
            "title":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning",
            "url":"\/paper\/aligning-large-multi-modal-model-with-robust",
            "published":"2023-06-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/aligning-large-multi-modal-model-with-robust\/review\/?hl=110210"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109835,
        "rank":21,
        "Model":"LLaMA-Adapter v2-7B",
        "mlmodel":{

        },
        "method_short":"LLaMA-Adapter v2-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-25",
        "metrics":{
            "GPT-4 score":"31.4\u00b10.1",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":31.4,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1199360,
            "title":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model",
            "url":"\/paper\/llama-adapter-v2-parameter-efficient-visual",
            "published":"2023-04-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-adapter-v2-parameter-efficient-visual\/review\/?hl=109835"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109837,
        "rank":22,
        "Model":"LLaVA-1.5-7B",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "GPT-4 score":"31.1\u00b10.2",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":31.1,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=109837"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109823,
        "rank":23,
        "Model":"LLaVA-7B (LLaMA-2)",
        "mlmodel":{

        },
        "method_short":"LLaVA-7B ",
        "method_details":"LLaMA-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-19",
        "metrics":{
            "GPT-4 score":"28.1\u00b10.4",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":28.1,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109824,
        "rank":24,
        "Model":"MM-ReAct-GPT-3.5",
        "mlmodel":{

        },
        "method_short":"MM-ReAct-GPT-3.5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-20",
        "metrics":{
            "GPT-4 score":"27.9\u00b10.1",
            "Params":null
        },
        "raw_metrics":{
            "GPT-4 score":27.9,
            "Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1177841,
            "title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action",
            "url":"\/paper\/mm-react-prompting-chatgpt-for-multimodal",
            "published":"2023-03-20T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":502,
                "name":"Involve APIs",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":112175,
        "rank":25,
        "Model":"LLaVA-Plus-7B (All Tools)",
        "mlmodel":{

        },
        "method_short":"LLaVA-Plus-7B ",
        "method_details":"All Tools",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-09",
        "metrics":{
            "GPT-4 score":"27.5\u00b10.3",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":27.5,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1317898,
            "title":"LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents",
            "url":"\/paper\/llava-plus-learning-to-use-tools-for-creating",
            "published":"2023-11-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llava-plus-learning-to-use-tools-for-creating\/review\/?hl=112175"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109826,
        "rank":26,
        "Model":"LLaVA-13B",
        "mlmodel":{

        },
        "method_short":"LLaVA-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-08",
        "metrics":{
            "GPT-4 score":"26.4\u00b10.1",
            "Params":"13B"
        },
        "raw_metrics":{
            "GPT-4 score":26.4,
            "Params":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109827,
        "rank":27,
        "Model":"InstructBLIP-8B",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-8B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-03",
        "metrics":{
            "GPT-4 score":"26.2\u00b10.2",
            "Params":"8B"
        },
        "raw_metrics":{
            "GPT-4 score":26.2,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109828,
        "rank":28,
        "Model":"InstructBLIP-14B",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-14B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-03",
        "metrics":{
            "GPT-4 score":"25.6\u00b10.3",
            "Params":"14B"
        },
        "raw_metrics":{
            "GPT-4 score":25.6,
            "Params":14.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":110190,
        "rank":29,
        "Model":"OpenFlamingo-9B (MPT-7B)",
        "mlmodel":{

        },
        "method_short":"OpenFlamingo-9B ",
        "method_details":"MPT-7B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-14",
        "metrics":{
            "GPT-4 score":"24.8\u00b10.2",
            "Params":"9B"
        },
        "raw_metrics":{
            "GPT-4 score":24.8,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1257786,
            "title":"OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models",
            "url":"\/paper\/openflamingo-an-open-source-framework-for",
            "published":"2023-08-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/openflamingo-an-open-source-framework-for\/review\/?hl=110190"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":110191,
        "rank":30,
        "Model":"Otter-9B (MPT-7B)",
        "mlmodel":{

        },
        "method_short":"Otter-9B ",
        "method_details":"MPT-7B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-17",
        "metrics":{
            "GPT-4 score":"24.7\u00b10.3",
            "Params":"9B"
        },
        "raw_metrics":{
            "GPT-4 score":24.7,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1225835,
            "title":"MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
            "url":"\/paper\/mimic-it-multi-modal-in-context-instruction",
            "published":"2023-06-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109829,
        "rank":31,
        "Model":"Otter-9B (LLaMA)",
        "mlmodel":{

        },
        "method_short":"Otter-9B ",
        "method_details":"LLaMA",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-25",
        "metrics":{
            "GPT-4 score":"24.6\u00b10.2",
            "Params":"9B"
        },
        "raw_metrics":{
            "GPT-4 score":24.6,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1225835,
            "title":"MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
            "url":"\/paper\/mimic-it-multi-modal-in-context-instruction",
            "published":"2023-06-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109830,
        "rank":32,
        "Model":"MiniGPT-4-14B",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4-14B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-20",
        "metrics":{
            "GPT-4 score":"24.4\u00b10.4",
            "Params":"14B"
        },
        "raw_metrics":{
            "GPT-4 score":24.4,
            "Params":14.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1195560,
            "title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
            "url":"\/paper\/minigpt-4-enhancing-vision-language",
            "published":"2023-04-20T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109831,
        "rank":33,
        "Model":"LLaVA-7B",
        "mlmodel":{

        },
        "method_short":"LLaVA-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-19",
        "metrics":{
            "GPT-4 score":"23.8\u00b10.6",
            "Params":"7B"
        },
        "raw_metrics":{
            "GPT-4 score":23.8,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109832,
        "rank":34,
        "Model":"BLIP-2-12B",
        "mlmodel":{

        },
        "method_short":"BLIP-2-12B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-30",
        "metrics":{
            "GPT-4 score":"22.4\u00b10.2",
            "Params":"12B"
        },
        "raw_metrics":{
            "GPT-4 score":22.4,
            "Params":12.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1149122,
            "title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
            "url":"\/paper\/blip-2-bootstrapping-language-image-pre",
            "published":"2023-01-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/blip-2-bootstrapping-language-image-pre\/review\/?hl=109832"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109833,
        "rank":35,
        "Model":"MiniGPT-4-8B",
        "mlmodel":{

        },
        "method_short":"MiniGPT-4-8B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-20",
        "metrics":{
            "GPT-4 score":"22.1\u00b10.1",
            "Params":"8B"
        },
        "raw_metrics":{
            "GPT-4 score":22.1,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1195560,
            "title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
            "url":"\/paper\/minigpt-4-enhancing-vision-language",
            "published":"2023-04-20T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25145,
        "row_id":109834,
        "rank":36,
        "Model":"OpenFlamingo-9B (LLaMA-7B)",
        "mlmodel":{

        },
        "method_short":"OpenFlamingo-9B ",
        "method_details":"LLaMA-7B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-19",
        "metrics":{
            "GPT-4 score":"21.8\u00b10.1",
            "Params":"9B"
        },
        "raw_metrics":{
            "GPT-4 score":21.8,
            "Params":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1257786,
            "title":"OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models",
            "url":"\/paper\/openflamingo-an-open-source-framework-for",
            "published":"2023-08-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/openflamingo-an-open-source-framework-for\/review\/?hl=109834"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]