[
    {
        "Model":"Random",
        "Avg. All":28.45459441,
        "Avg. Video-Exclusive":25.84861538,
        "Avg. Prior-Knowledge QA":24.47045673,
        "Avg. Decision-Making":35.04471112,
        "ActivityNet":0.3458,
        "MSVD":0.26224,
        "MSRVTT":0.265,
        "TGIF":0.22377,
        "Youcook2":0.25,
        "Ucfcrime":0.25,
        "MOT":0.1667,
        "TVQA":0.2,
        "MV":0.26151895,
        "NBA":0.272594752,
        "Driving-exam":0.368055556,
        "Driving-decision-making":0.44209,
        "SQA3D":0.25
    },
    {
        "Model":"VideoChat-7B",
        "Avg. All":35.41215477,
        "Avg. Video-Exclusive":34.12376923,
        "Avg. Prior-Knowledge QA":29.60966667,
        "Avg. Decision-Making":42.5030284,
        "ActivityNet":0.4455,
        "MSVD":0.4215,
        "MSRVTT":0.374,
        "TGIF":0.33744,
        "Youcook2":0.27663,
        "Ucfcrime":0.2241,
        "MOT":0.27775,
        "TVQA":0.2615,
        "MV":0.34109,
        "NBA":0.2857,
        "Driving-exam":0.388888,
        "Driving-decision-making":0.553846,
        "SQA3D":0.31428571
    },
    {
        "Model":"Video-ChatGPT-7B",
        "Avg. All":38.5186297,
        "Avg. Video-Exclusive":39.81651709,
        "Avg. Prior-Knowledge QA":29.244,
        "Avg. Decision-Making":46.495372,
        "ActivityNet":0.466,
        "MSVD":0.575,
        "MSRVTT":0.463,
        "TGIF":0.3559,
        "Youcook2":0.348,
        "Ucfcrime":0.2413,
        "MOT":0.277747222,
        "TVQA":0.28764,
        "MV":0.3652,
        "NBA":0.22448,
        "Driving-exam":0.4166666,
        "Driving-decision-making":0.582051,
        "SQA3D":0.372
    },
    {
        "Model":"Otter-7B",
        "Avg. All":37.47000387,
        "Avg. Video-Exclusive":37.51728162,
        "Avg. Prior-Knowledge QA":32.99,
        "Avg. Decision-Making":41.90273,
        "ActivityNet":0.443,
        "MSVD":0.5495,
        "MSRVTT":0.4695,
        "TGIF":0.34266,
        "Youcook2":0.3265,
        "Ucfcrime":0.22413,
        "MOT":0.166666611,
        "TVQA":0.2765,
        "MV":0.370635,
        "NBA":0.342565,
        "Driving-exam":0.5277777,
        "Driving-decision-making":0.4871794,
        "SQA3D":0.2965
    },
    {
        "Model":"PandaGPT-7B",
        "Avg. All":37.52393217,
        "Avg. Video-Exclusive":37.53914677,
        "Avg. Prior-Knowledge QA":31.98733333,
        "Avg. Decision-Making":43.0453164,
        "ActivityNet":0.449624,
        "MSVD":0.5042521,
        "MSRVTT":0.44594594,
        "TGIF":0.29663,
        "Youcook2":0.33016,
        "Ucfcrime":0.3301,
        "MOT":0.166665,
        "TVQA":0.2785,
        "MV":0.37063,
        "NBA":0.31049,
        "Driving-exam":0.4166,
        "Driving-decision-making":0.5602564,
        "SQA3D":0.30757651
    },
    {
        "Model":"Valley-7B",
        "Avg. All":33.95521521,
        "Avg. Video-Exclusive":28.38772829,
        "Avg. Prior-Knowledge QA":29.20933333,
        "Avg. Decision-Making":44.268584,
        "ActivityNet":0.381,
        "MSVD":0.32032,
        "MSRVTT":0.2802802,
        "TGIF":0.3141,
        "Youcook2":0.2905,
        "Ucfcrime":0.203448,
        "MOT":0.111108278,
        "TVQA":0.237,
        "MV":0.32587,
        "NBA":0.31341,
        "Driving-exam":0.41666,
        "Driving-decision-making":0.5653846,
        "SQA3D":0.333
    },
    {
        "Model":"mPLUG-owl-7B",
        "Avg. All":33.14659856,
        "Avg. Video-Exclusive":33.16526701,
        "Avg. Prior-Knowledge QA":26.39762867,
        "Avg. Decision-Making":39.8769,
        "ActivityNet":0.41470735,
        "MSVD":0.4245,
        "MSRVTT":0.363,
        "TGIF":0.31656,
        "Youcook2":0.2705,
        "Ucfcrime":0.2275862,
        "MOT":0.277777611,
        "TVQA":0.2395,
        "MV":0.3017,
        "NBA":0.25072886,
        "Driving-exam":0.333333,
        "Driving-decision-making":0.510256,
        "SQA3D":0.32
    },
    {
        "Model":"Video-LLaMA-7B",
        "Avg. All":32.83174044,
        "Avg. Video-Exclusive":32.48401966,
        "Avg. Prior-Knowledge QA":27.79906667,
        "Avg. Decision-Making":38.212135,
        "ActivityNet":0.3985,
        "MSVD":0.4115,
        "MSRVTT":0.3405,
        "TGIF":0.312766,
        "Youcook2":0.289,
        "Ucfcrime":0.275862,
        "MOT":0.166666556,
        "TVQA":0.2475,
        "MV":0.324082,
        "NBA":0.26239,
        "Driving-exam":0.30555555,
        "Driving-decision-making":0.4910256,
        "SQA3D":0.3115
    },
    {
        "Model":"Chat-UniVi-7B",
        "Avg. All":35.31147004,
        "Avg. Video-Exclusive":37.87,
        "Avg. Prior-Knowledge QA":27.43,
        "Avg. Decision-Making":40.64,
        "ActivityNet":0.49,
        "MSVD":0.486,
        "MSRVTT":0.4165,
        "TGIF":0.413,
        "Youcook2":0.29,
        "Ucfcrime":0.2827,
        "MOT":0.166666649,
        "TVQA":0.2305,
        "MV":0.3357,
        "NBA":0.2566,
        "Driving-exam":0.3889,
        "Driving-decision-making":0.5308,
        "SQA3D":0.2907
    },
    {
        "Model":"sphinx-v2",
        "Avg. All":45.53190476,
        "Avg. Video-Exclusive":44.22571429,
        "Avg. Prior-Knowledge QA":41.81666667,
        "Avg. Decision-Making":50.55333333,
        "ActivityNet":0.5307,
        "MSVD":0.6845,
        "MSRVTT":0.5395,
        "TGIF":0.5341,
        "Youcook2":0.42,
        "Ucfcrime":0.2759,
        "MOT":0.1111,
        "TVQA":0.3645,
        "MV":0.4396,
        "NBA":0.4504,
        "Driving-exam":0.4722,
        "Driving-decision-making":0.5564,
        "SQA3D":0.488
    }
]