[
    {
        "abstain":14.0,
        "entailment":21.2418712538,
        "neutral":49.8186428445,
        "contradiction":28.9394859017,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":0.0,
        "entailment":28.7379323892,
        "neutral":40.9354008565,
        "contradiction":30.3266667543,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":6.0,
        "entailment":17.9057775593,
        "neutral":48.0442205896,
        "contradiction":34.0500018512,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":2.0,
        "entailment":63.6516933657,
        "neutral":19.1573186928,
        "contradiction":17.1909879415,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":4.0,
        "entailment":37.258990243,
        "neutral":51.6081562078,
        "contradiction":11.1328535492,
        "Model":"Claude 2"
    },
    {
        "abstain":3.0,
        "entailment":26.3676157748,
        "neutral":29.1280254682,
        "contradiction":44.5043587569,
        "Model":"InstructGPT"
    },
    {
        "abstain":27.0,
        "entailment":44.6575342466,
        "neutral":10.6278538813,
        "contradiction":44.7146118721,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":16.0,
        "entailment":48.9021164021,
        "neutral":12.3611111111,
        "contradiction":38.7367724868,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":2.0,
        "entailment":40.9417668485,
        "neutral":49.4108894671,
        "contradiction":9.6473436844,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":0.0,
        "entailment":77.3892857143,
        "neutral":13.0273809524,
        "contradiction":9.5833333333,
        "Model":"GPT-4"
    },
    {
        "abstain":0.0,
        "entailment":45.1750765574,
        "neutral":49.3707646112,
        "contradiction":5.4541588314,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":5.0,
        "entailment":23.0299466615,
        "neutral":21.1263093632,
        "contradiction":55.8437439753,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":1.0,
        "entailment":17.6226075603,
        "neutral":57.5573845278,
        "contradiction":24.8200079119,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":1.0,
        "entailment":24.4593239976,
        "neutral":57.0599006527,
        "contradiction":18.4807753497,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":6.0,
        "entailment":29.7031461611,
        "neutral":58.0739259359,
        "contradiction":12.222927903,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":1.0,
        "entailment":25.4077390062,
        "neutral":38.9646829041,
        "contradiction":35.6275780897,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":17.0,
        "entailment":40.3128901693,
        "neutral":36.4439475673,
        "contradiction":23.2431622634,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":3.0,
        "entailment":20.2024686788,
        "neutral":32.2070702695,
        "contradiction":47.5904610516,
        "Model":"Phi-2"
    }
]