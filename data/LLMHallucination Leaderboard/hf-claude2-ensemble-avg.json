[
    {
        "abstain":8.0,
        "entailment":57.5896872085,
        "neutral":22.9076752318,
        "contradiction":19.5026375597,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":2.0,
        "entailment":66.7759783953,
        "neutral":19.5512300335,
        "contradiction":13.6727915712,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":66.5278524174,
        "neutral":18.7030415807,
        "contradiction":14.7691060019,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":10.0,
        "entailment":83.1954286148,
        "neutral":8.3774407042,
        "contradiction":8.427130681,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":3.6666666667,
        "entailment":74.381342462,
        "neutral":20.0267786318,
        "contradiction":5.5918789062,
        "Model":"Claude 2"
    },
    {
        "abstain":4.6666666667,
        "entailment":61.6684126868,
        "neutral":15.0163894963,
        "contradiction":23.3151978169,
        "Model":"InstructGPT"
    },
    {
        "abstain":17.3333333333,
        "entailment":68.5426415707,
        "neutral":10.8871557825,
        "contradiction":20.5702026468,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":19.6666666667,
        "entailment":77.2713409228,
        "neutral":6.645565131,
        "contradiction":16.0830939462,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":4.6666666667,
        "entailment":66.2246241553,
        "neutral":27.1928818443,
        "contradiction":6.5824940004,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":4.6666666667,
        "entailment":90.5146925267,
        "neutral":5.5808206945,
        "contradiction":3.9044867788,
        "Model":"GPT-4"
    },
    {
        "abstain":1.3333333333,
        "entailment":76.9407723415,
        "neutral":19.8793279069,
        "contradiction":3.1798997516,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":8.6666666667,
        "entailment":64.9171145157,
        "neutral":9.8004843899,
        "contradiction":25.2824010944,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":63.6191135967,
        "neutral":24.7318835131,
        "contradiction":11.6490028903,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":3.0,
        "entailment":66.1432882919,
        "neutral":24.7702494587,
        "contradiction":9.0864622494,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":3.3333333333,
        "entailment":71.3093274553,
        "neutral":22.8151287711,
        "contradiction":5.8755437735,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":2.6666666667,
        "entailment":67.4381339441,
        "neutral":17.4936778424,
        "contradiction":15.0681882135,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":6.6666666667,
        "entailment":77.0929860304,
        "neutral":14.602725741,
        "contradiction":8.3042882286,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":8.0,
        "entailment":60.9439639493,
        "neutral":15.7959652155,
        "contradiction":23.2600708352,
        "Model":"Phi-2"
    }
]