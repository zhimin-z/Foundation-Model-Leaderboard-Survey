[
    {
        "abstain":8.0,
        "entailment":73.7583652849,
        "neutral":15.2457686649,
        "contradiction":10.9958660502,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":2.0,
        "entailment":75.1812826757,
        "neutral":15.2120588904,
        "contradiction":9.6066584339,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":76.311006578,
        "neutral":15.0519330543,
        "contradiction":8.6370603676,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":10.0,
        "entailment":85.4152335373,
        "neutral":8.622207525,
        "contradiction":5.9625589377,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":3.6666666667,
        "entailment":77.7970590615,
        "neutral":16.3275590702,
        "contradiction":5.8753818683,
        "Model":"Claude 2"
    },
    {
        "abstain":4.6666666667,
        "entailment":73.3648446542,
        "neutral":14.1932222789,
        "contradiction":12.4419330669,
        "Model":"InstructGPT"
    },
    {
        "abstain":17.3333333333,
        "entailment":78.9838835658,
        "neutral":8.1319173658,
        "contradiction":12.8841990684,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":19.6666666667,
        "entailment":84.4801751959,
        "neutral":10.4091747349,
        "contradiction":5.1106500692,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":4.6666666667,
        "entailment":88.3198745699,
        "neutral":7.2187534688,
        "contradiction":4.4613719614,
        "Model":"GPT-4"
    },
    {
        "abstain":1.3333333333,
        "entailment":80.5089903362,
        "neutral":14.7409487924,
        "contradiction":4.7500608714,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":8.6666666667,
        "entailment":78.7988400488,
        "neutral":13.7077885618,
        "contradiction":7.4933713894,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":72.8968856495,
        "neutral":18.515951701,
        "contradiction":8.5871626495,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":3.0,
        "entailment":74.5404940099,
        "neutral":17.2007110019,
        "contradiction":8.2587949883,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":3.3333333333,
        "entailment":76.718138415,
        "neutral":17.2099304947,
        "contradiction":6.0719310903,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":2.6666666667,
        "entailment":75.2195374164,
        "neutral":15.2026913308,
        "contradiction":9.5777712528,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":6.6666666667,
        "entailment":81.880429505,
        "neutral":11.7982050925,
        "contradiction":6.3213654025,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":4.6666666667,
        "entailment":72.409375535,
        "neutral":20.0208946893,
        "contradiction":7.5697297756,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":8.0,
        "entailment":73.0267657553,
        "neutral":14.1089132858,
        "contradiction":12.864320959,
        "Model":"Phi-2"
    }
]