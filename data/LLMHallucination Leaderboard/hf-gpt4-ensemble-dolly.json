[
    {
        "abstain":6,
        "entailment":85.271592745,
        "neutral":6.9058541133,
        "contradiction":7.8225531417,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":4,
        "entailment":89.4821338962,
        "neutral":7.6726572039,
        "contradiction":2.8452088999,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":0,
        "entailment":90.7525684962,
        "neutral":2.877344563,
        "contradiction":6.3700869408,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":0,
        "entailment":95.4348484848,
        "neutral":2.5651515152,
        "contradiction":2.0,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":0,
        "entailment":95.0669599724,
        "neutral":3.7595551791,
        "contradiction":1.1734848485,
        "Model":"Claude 2"
    },
    {
        "abstain":0,
        "entailment":85.9876651127,
        "neutral":4.3454545455,
        "contradiction":9.6668803419,
        "Model":"InstructGPT"
    },
    {
        "abstain":1,
        "entailment":84.1934216177,
        "neutral":10.7015251321,
        "contradiction":5.1050532502,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":21,
        "entailment":91.223628692,
        "neutral":5.8227848101,
        "contradiction":2.9535864979,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":0,
        "entailment":85.034846079,
        "neutral":11.4188965292,
        "contradiction":3.5462573918,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":0,
        "entailment":94.35,
        "neutral":1.8742424242,
        "contradiction":3.7757575758,
        "Model":"GPT-4"
    },
    {
        "abstain":0,
        "entailment":93.3321630167,
        "neutral":4.8614549389,
        "contradiction":1.8063820443,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":1,
        "entailment":95.8946608947,
        "neutral":0.7215007215,
        "contradiction":3.3838383838,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":0,
        "entailment":91.5319832945,
        "neutral":5.9077242202,
        "contradiction":2.5602924853,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":0,
        "entailment":90.6781216006,
        "neutral":6.5391472416,
        "contradiction":2.7827311577,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":0,
        "entailment":94.0176587302,
        "neutral":3.0763888889,
        "contradiction":2.905952381,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":0,
        "entailment":92.9566555993,
        "neutral":3.7103216264,
        "contradiction":3.3330227743,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":0,
        "entailment":95.0181911226,
        "neutral":2.4274743231,
        "contradiction":2.5543345543,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":1,
        "entailment":87.4257182212,
        "neutral":6.7968591453,
        "contradiction":5.7774226335,
        "Model":"Phi-2"
    }
]