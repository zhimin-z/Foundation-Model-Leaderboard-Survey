[
    {
        "abstain":4.0,
        "entailment":51.3446462795,
        "neutral":27.4472989133,
        "contradiction":21.2080548072,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":1.3333333333,
        "entailment":62.4654768589,
        "neutral":23.2281208844,
        "contradiction":14.3064022568,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":0.3333333333,
        "entailment":63.1092650282,
        "neutral":20.0644292041,
        "contradiction":16.8263057678,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":0.0,
        "entailment":75.0924556362,
        "neutral":10.6312401125,
        "contradiction":14.2763042513,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":0.0,
        "entailment":68.6451985635,
        "neutral":26.6339127622,
        "contradiction":4.7208886744,
        "Model":"Claude 2"
    },
    {
        "abstain":0.0,
        "entailment":56.5587088837,
        "neutral":15.0089225589,
        "contradiction":28.4323685574,
        "Model":"InstructGPT"
    },
    {
        "abstain":0.3333333333,
        "entailment":58.0360417939,
        "neutral":17.8082356306,
        "contradiction":24.1557225755,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":14.0,
        "entailment":71.0332841147,
        "neutral":9.2001968746,
        "contradiction":19.7665190107,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":0.0,
        "entailment":86.594569646,
        "neutral":8.1118326118,
        "contradiction":5.2935977421,
        "Model":"GPT-4"
    },
    {
        "abstain":0.0,
        "entailment":74.9915236785,
        "neutral":21.6889500618,
        "contradiction":3.3195262597,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":0.6666666667,
        "entailment":58.6198151215,
        "neutral":14.1196117455,
        "contradiction":27.2605731331,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":0.0,
        "entailment":60.6101298503,
        "neutral":28.0492607764,
        "contradiction":11.3406093733,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":0.0,
        "entailment":63.8972121179,
        "neutral":26.8582009058,
        "contradiction":9.2445869762,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":0.0,
        "entailment":65.1923965597,
        "neutral":26.8202338253,
        "contradiction":7.987369615,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":0.0,
        "entailment":64.612727219,
        "neutral":18.4282001142,
        "contradiction":16.9590726668,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":3.0,
        "entailment":72.2497195598,
        "neutral":18.6935611,
        "contradiction":9.0567193402,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":0.0,
        "entailment":61.8173372174,
        "neutral":33.3121267167,
        "contradiction":4.8705360659,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":0.6666666667,
        "entailment":53.2813530004,
        "neutral":17.4952542039,
        "contradiction":29.2233927957,
        "Model":"Phi-2"
    }
]