[
    {
        "abstain":8.0,
        "entailment":55.3567691603,
        "neutral":19.1266011447,
        "contradiction":25.516629695,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":2.0,
        "entailment":61.511256179,
        "neutral":19.3166163738,
        "contradiction":19.1721274472,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":61.5931999267,
        "neutral":15.6357533029,
        "contradiction":22.7710467704,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":10.0,
        "entailment":78.1960904253,
        "neutral":9.2221688769,
        "contradiction":12.5817406978,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":3.6666666667,
        "entailment":70.8801044347,
        "neutral":16.5664303373,
        "contradiction":12.553465228,
        "Model":"Claude 2"
    },
    {
        "abstain":4.6666666667,
        "entailment":55.1791555375,
        "neutral":17.5834441394,
        "contradiction":27.2374003231,
        "Model":"InstructGPT"
    },
    {
        "abstain":17.3333333333,
        "entailment":65.8968754338,
        "neutral":12.3031979024,
        "contradiction":21.7999266638,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":19.6666666667,
        "entailment":73.6331435968,
        "neutral":8.5039188566,
        "contradiction":17.8629375465,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":4.6666666667,
        "entailment":85.0609025039,
        "neutral":5.8026078716,
        "contradiction":9.1364896245,
        "Model":"GPT-4"
    },
    {
        "abstain":1.3333333333,
        "entailment":72.4933129859,
        "neutral":18.294409043,
        "contradiction":9.2122779711,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":8.6666666667,
        "entailment":61.7685511974,
        "neutral":9.1010890974,
        "contradiction":29.1303597052,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":2.3333333333,
        "entailment":60.8506771828,
        "neutral":20.4850312396,
        "contradiction":18.6642915777,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":3.0,
        "entailment":62.5326283416,
        "neutral":20.5801192168,
        "contradiction":16.8872524415,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":3.3333333333,
        "entailment":68.5565635037,
        "neutral":18.8426445553,
        "contradiction":12.600791941,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":2.6666666667,
        "entailment":63.0996143384,
        "neutral":16.2289653283,
        "contradiction":20.6714203333,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":6.6666666667,
        "entailment":72.6530623009,
        "neutral":12.9719751864,
        "contradiction":14.3749625126,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":4.6666666667,
        "entailment":63.2525400887,
        "neutral":22.5691656406,
        "contradiction":14.1782942707,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":8.0,
        "entailment":57.2124465106,
        "neutral":14.2570166321,
        "contradiction":28.5305368573,
        "Model":"Phi-2"
    }
]