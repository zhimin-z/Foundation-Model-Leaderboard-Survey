[
    {
        "abstain":8,
        "entailment":80.0506422925,
        "neutral":8.9507850242,
        "contradiction":10.9985726834,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":5,
        "entailment":86.9611273704,
        "neutral":9.4791969251,
        "contradiction":3.5596757044,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":0,
        "entailment":90.8209166236,
        "neutral":4.1901491053,
        "contradiction":4.9889342712,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":1,
        "entailment":95.4234808401,
        "neutral":2.4681337181,
        "contradiction":2.1083854417,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":2,
        "entailment":92.8588772954,
        "neutral":3.7146200689,
        "contradiction":3.4265026357,
        "Model":"Claude 2"
    },
    {
        "abstain":1,
        "entailment":83.5817423317,
        "neutral":6.2736491903,
        "contradiction":10.1446084779,
        "Model":"InstructGPT"
    },
    {
        "abstain":1,
        "entailment":78.1395610562,
        "neutral":13.840680924,
        "contradiction":8.0197580198,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":20,
        "entailment":86.8162878788,
        "neutral":10.1142676768,
        "contradiction":3.0694444444,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":4,
        "entailment":97.3838083213,
        "neutral":1.7303240741,
        "contradiction":0.8858676046,
        "Model":"GPT-4"
    },
    {
        "abstain":2,
        "entailment":93.1497847277,
        "neutral":5.7566999441,
        "contradiction":1.0935153282,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":4,
        "entailment":92.9538690476,
        "neutral":3.3482142857,
        "contradiction":3.6979166667,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":2,
        "entailment":84.8932169576,
        "neutral":8.8231961811,
        "contradiction":6.2835868613,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":1,
        "entailment":87.1703069959,
        "neutral":6.6248289922,
        "contradiction":6.2048640119,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":0,
        "entailment":91.5227342102,
        "neutral":4.9252525253,
        "contradiction":3.5520132645,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":0,
        "entailment":89.2314212361,
        "neutral":6.3888012916,
        "contradiction":4.3797774723,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":0,
        "entailment":95.5137594432,
        "neutral":2.8262838469,
        "contradiction":1.65995671,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":2,
        "entailment":81.0717628023,
        "neutral":15.2551019926,
        "contradiction":3.6731352051,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":3,
        "entailment":83.7804749759,
        "neutral":10.4647643209,
        "contradiction":5.7547607032,
        "Model":"Phi-2"
    }
]