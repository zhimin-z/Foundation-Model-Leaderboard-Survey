[
    {
        "abstain":2,
        "entailment":64.4505183026,
        "neutral":14.1735503725,
        "contradiction":21.3759313249,
        "Model":"Alpaca 7B"
    },
    {
        "abstain":1,
        "entailment":83.6579778246,
        "neutral":9.1827925161,
        "contradiction":7.1592296592,
        "Model":"Baichuan 2 13B Chat"
    },
    {
        "abstain":1,
        "entailment":86.7038283944,
        "neutral":6.3987359442,
        "contradiction":6.8974356614,
        "Model":"ChatGLM 3 6B"
    },
    {
        "abstain":27,
        "entailment":91.1388205909,
        "neutral":3.5897435897,
        "contradiction":5.2714358194,
        "Model":"GPT-3.5-Turbo"
    },
    {
        "abstain":5,
        "entailment":88.6489835052,
        "neutral":7.0093934861,
        "contradiction":4.3416230086,
        "Model":"Claude 2"
    },
    {
        "abstain":10,
        "entailment":71.4398009398,
        "neutral":11.6107041107,
        "contradiction":16.9494949495,
        "Model":"InstructGPT"
    },
    {
        "abstain":24,
        "entailment":71.217013121,
        "neutral":11.6902550494,
        "contradiction":17.0927318296,
        "Model":"Falcon 40B Instruct"
    },
    {
        "abstain":23,
        "entailment":90.0671550672,
        "neutral":2.7622377622,
        "contradiction":7.1706071706,
        "Model":"Gemini Pro (API)"
    },
    {
        "abstain":10,
        "entailment":73.3191517313,
        "neutral":19.394666167,
        "contradiction":7.2861821017,
        "Model":"Gemini Pro (Bard)"
    },
    {
        "abstain":10,
        "entailment":97.2860113742,
        "neutral":1.8152958153,
        "contradiction":0.8986928105,
        "Model":"GPT-4"
    },
    {
        "abstain":2,
        "entailment":92.1459810031,
        "neutral":4.9567773496,
        "contradiction":2.8972416472,
        "Model":"GPT-4-Turbo"
    },
    {
        "abstain":17,
        "entailment":77.9020845286,
        "neutral":4.9627079748,
        "contradiction":17.1352074967,
        "Model":"InternLM 20B Chat"
    },
    {
        "abstain":4,
        "entailment":84.3219558434,
        "neutral":9.3024830879,
        "contradiction":6.3755610687,
        "Model":"LLaMA 2 7B Chat"
    },
    {
        "abstain":7,
        "entailment":83.7883440366,
        "neutral":11.0654481813,
        "contradiction":5.146207782,
        "Model":"LLaMA 2 13B Chat"
    },
    {
        "abstain":4,
        "entailment":87.8355385808,
        "neutral":9.1242183114,
        "contradiction":3.0402431078,
        "Model":"LLaMA 2 70B Chat"
    },
    {
        "abstain":7,
        "entailment":85.7728559128,
        "neutral":7.7817117816,
        "contradiction":6.4454323056,
        "Model":"Mistral 7B Instruct"
    },
    {
        "abstain":3,
        "entailment":89.3060707173,
        "neutral":8.2967894358,
        "contradiction":2.3971398469,
        "Model":"ERNIE Bot 4.0 (\u6587\u5fc3\u4e00\u8a004.0)"
    },
    {
        "abstain":18,
        "entailment":76.6560573573,
        "neutral":5.782967033,
        "contradiction":17.5609756098,
        "Model":"Phi-2"
    }
]