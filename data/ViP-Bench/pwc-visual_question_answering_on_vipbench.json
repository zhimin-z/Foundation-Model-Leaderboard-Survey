[
    {
        "table_id":25936,
        "row_id":114160,
        "rank":1,
        "Model":"GPT-4V-turbo-detail:high (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"GPT-4V-turbo-detail:high ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "GPT-4 score (bbox)":"60.7",
            "GPT-4 score (human)":"59.9"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":60.7,
            "GPT-4 score (human)":59.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=114160"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114368,
        "rank":2,
        "Model":"GPT-4V-turbo-detail:low (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"GPT-4V-turbo-detail:low ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "GPT-4 score (bbox)":"52.8",
            "GPT-4 score (human)":"51.4"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":52.8,
            "GPT-4 score (human)":51.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=114368"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114159,
        "rank":3,
        "Model":"ViP-LLaVA-13B (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"ViP-LLaVA-13B ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "GPT-4 score (bbox)":"48.3",
            "GPT-4 score (human)":"48.2"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":48.3,
            "GPT-4 score (human)":48.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1311868,
            "title":"Making Large Language Models Better Data Creators",
            "url":"\/paper\/making-large-language-models-better-data",
            "published":"2023-10-31T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114161,
        "rank":4,
        "Model":"LLaVA-1.5-13B (Coordinates)",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-13B ",
        "method_details":"Coordinates",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "GPT-4 score (bbox)":"47.1",
            "GPT-4 score (human)":null
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":47.1,
            "GPT-4 score (human)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=114161"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114163,
        "rank":5,
        "Model":"Qwen-VL-Chat (Coordinates)",
        "mlmodel":{

        },
        "method_short":"Qwen-VL-Chat ",
        "method_details":"Coordinates",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-24",
        "metrics":{
            "GPT-4 score (bbox)":"45.3",
            "GPT-4 score (human)":null
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":45.3,
            "GPT-4 score (human)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1269007,
            "title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
            "url":"\/paper\/qwen-vl-a-frontier-large-vision-language",
            "published":"2023-08-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114162,
        "rank":6,
        "Model":"LLaVA-1.5-13B (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-13B ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "GPT-4 score (bbox)":"41.8",
            "GPT-4 score (human)":"42.9"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":41.8,
            "GPT-4 score (human)":42.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=114162"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114164,
        "rank":7,
        "Model":"Qwen-VL-Chat (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"Qwen-VL-Chat ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-24",
        "metrics":{
            "GPT-4 score (bbox)":"39.2",
            "GPT-4 score (human)":"41.7"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":39.2,
            "GPT-4 score (human)":41.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1269007,
            "title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
            "url":"\/paper\/qwen-vl-a-frontier-large-vision-language",
            "published":"2023-08-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114165,
        "rank":8,
        "Model":"InstructBLIP-13B (Visual Prompt)",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-13B ",
        "method_details":"Visual Prompt",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "GPT-4 score (bbox)":"35.8",
            "GPT-4 score (human)":"35.2"
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":35.8,
            "GPT-4 score (human)":35.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333348,
            "title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
            "url":"\/paper\/instructblip-towards-general-purpose-vision",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114167,
        "rank":9,
        "Model":"GPT4ROI 7B (ROI)",
        "mlmodel":{

        },
        "method_short":"GPT4ROI 7B ",
        "method_details":"ROI",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-07",
        "metrics":{
            "GPT-4 score (bbox)":"35.1",
            "GPT-4 score (human)":null
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":35.1,
            "GPT-4 score (human)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1242643,
            "title":"GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest",
            "url":"\/paper\/gpt4roi-instruction-tuning-large-language",
            "published":"2023-07-07T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114168,
        "rank":10,
        "Model":"Shikra-7B (Coordinates)",
        "mlmodel":{

        },
        "method_short":"Shikra-7B ",
        "method_details":"Coordinates",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-27",
        "metrics":{
            "GPT-4 score (bbox)":"33.7",
            "GPT-4 score (human)":null
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":33.7,
            "GPT-4 score (human)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1236350,
            "title":"Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic",
            "url":"\/paper\/shikra-unleashing-multimodal-llm-s",
            "published":"2023-06-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/shikra-unleashing-multimodal-llm-s\/review\/?hl=114168"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25936,
        "row_id":114166,
        "rank":11,
        "Model":"Kosmos-2 (Discrete Token)",
        "mlmodel":{

        },
        "method_short":"Kosmos-2 ",
        "method_details":"Discrete Token",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-26",
        "metrics":{
            "GPT-4 score (bbox)":"26.9",
            "GPT-4 score (human)":null
        },
        "raw_metrics":{
            "GPT-4 score (bbox)":26.9,
            "GPT-4 score (human)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1235152,
            "title":"Kosmos-2: Grounding Multimodal Large Language Models to the World",
            "url":"\/paper\/kosmos-2-grounding-multimodal-large-language",
            "published":"2023-06-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]