[
    {
        "T":"\ud83d\udd12",
        "Model":"anthropic\/claude-2.0",
        "Non-toxicity":84.52,
        "Non-Stereotype":92.11,
        "AdvGLUE++":100.0,
        "OoD":57.98,
        "Adv Demo":85.77,
        "Privacy":72.97,
        "Ethics":85.35,
        "Fairness":85.17,
        "Type":96.81,
        "Architecture":"",
        "Precision":"?",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"meta-llama\/Llama-2-7b-chat-hf",
        "Non-toxicity":74.72,
        "Non-Stereotype":80.0,
        "AdvGLUE++":97.6,
        "OoD":51.01,
        "Adv Demo":75.65,
        "Privacy":55.54,
        "Ethics":97.39,
        "Fairness":40.58,
        "Type":100.0,
        "Architecture":"RL-tuned",
        "Precision":"?",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\ud83d\udd12",
        "Model":"openai\/gpt-3.5-turbo-0301",
        "Non-toxicity":72.45,
        "Non-Stereotype":47.0,
        "AdvGLUE++":87.0,
        "OoD":56.69,
        "Adv Demo":73.58,
        "Privacy":81.28,
        "Ethics":70.13,
        "Fairness":86.38,
        "Type":77.57,
        "Architecture":"",
        "Precision":"?",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"compressed-llm\/llama-2-13b-chat-gptq",
        "Non-toxicity":71.99,
        "Non-Stereotype":80.87,
        "AdvGLUE++":100.0,
        "OoD":37.12,
        "Adv Demo":59.1,
        "Privacy":67.2,
        "Ethics":95.56,
        "Fairness":53.93,
        "Type":82.11,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-8bit"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"compressed-llm\/llama-2-13b-chat-awq",
        "Non-toxicity":71.32,
        "Non-Stereotype":80.96,
        "AdvGLUE++":100.0,
        "OoD":39.48,
        "Adv Demo":58.16,
        "Privacy":61.38,
        "Ethics":95.59,
        "Fairness":62.81,
        "Type":72.15,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-4bit"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"compressed-llm\/llama-2-13b-chat-awq",
        "Non-toxicity":70.68,
        "Non-Stereotype":75.44,
        "AdvGLUE++":98.67,
        "OoD":41.99,
        "Adv Demo":58.17,
        "Privacy":57.27,
        "Ethics":93.13,
        "Fairness":62.56,
        "Type":78.19,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-3bit"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"compressed-llm\/llama-2-13b-chat-awq",
        "Non-toxicity":69.95,
        "Non-Stereotype":80.69,
        "AdvGLUE++":100.0,
        "OoD":37.39,
        "Adv Demo":58.38,
        "Privacy":66.29,
        "Ethics":96.31,
        "Fairness":52.35,
        "Type":68.17,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-8bit"
    },
    {
        "T":"\ud83d\udd12",
        "Model":"openai\/gpt-4-0314",
        "Non-toxicity":69.24,
        "Non-Stereotype":41.0,
        "AdvGLUE++":77.0,
        "OoD":64.04,
        "Adv Demo":87.55,
        "Privacy":77.94,
        "Ethics":66.11,
        "Fairness":76.6,
        "Type":63.67,
        "Architecture":"",
        "Precision":"?",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"allenai\/tulu-2-13b",
        "Non-toxicity":66.51,
        "Non-Stereotype":44.8,
        "AdvGLUE++":89.33,
        "OoD":43.14,
        "Adv Demo":70.17,
        "Privacy":71.17,
        "Ethics":78.9,
        "Fairness":36.64,
        "Type":97.9,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3_gptq",
        "Non-toxicity":65.96,
        "Non-Stereotype":48.81,
        "AdvGLUE++":67.0,
        "OoD":39.27,
        "Adv Demo":62.91,
        "Privacy":60.38,
        "Ethics":79.3,
        "Fairness":73.66,
        "Type":96.36,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-4bit"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"allenai\/tulu-2-7b",
        "Non-toxicity":63.56,
        "Non-Stereotype":29.46,
        "AdvGLUE++":96.6,
        "OoD":44.62,
        "Adv Demo":69.3,
        "Privacy":60.49,
        "Ethics":75.82,
        "Fairness":49.0,
        "Type":83.21,
        "Architecture":"RL-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\ud83d\udfe6",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Non-toxicity":63.24,
        "Non-Stereotype":31.97,
        "AdvGLUE++":92.6,
        "OoD":26.81,
        "Adv Demo":65.58,
        "Privacy":68.68,
        "Ethics":84.18,
        "Fairness":41.03,
        "Type":95.07,
        "Architecture":"RL-tuned",
        "Precision":"MistralForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3_gptq",
        "Non-toxicity":62.91,
        "Non-Stereotype":50.46,
        "AdvGLUE++":82.67,
        "OoD":39.96,
        "Adv Demo":59.41,
        "Privacy":60.59,
        "Ethics":78.51,
        "Fairness":54.66,
        "Type":77.0,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-8bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-awq",
        "Non-toxicity":62.54,
        "Non-Stereotype":23.4,
        "AdvGLUE++":78.0,
        "OoD":50.35,
        "Adv Demo":53.13,
        "Privacy":38.97,
        "Ethics":75.53,
        "Fairness":81.85,
        "Type":99.07,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-3bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-awq",
        "Non-toxicity":62.47,
        "Non-Stereotype":21.52,
        "AdvGLUE++":77.33,
        "OoD":40.64,
        "Adv Demo":55.65,
        "Privacy":49.48,
        "Ethics":74.38,
        "Fairness":82.47,
        "Type":98.28,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-8bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-gptq",
        "Non-toxicity":62.4,
        "Non-Stereotype":22.41,
        "AdvGLUE++":77.67,
        "OoD":40.76,
        "Adv Demo":55.63,
        "Privacy":49.65,
        "Ethics":72.14,
        "Fairness":82.4,
        "Type":98.51,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-8bit"
    },
    {
        "T":"\u2b55",
        "Model":"mosaicml\/mpt-7b-chat",
        "Non-toxicity":62.29,
        "Non-Stereotype":40.0,
        "AdvGLUE++":84.6,
        "OoD":46.2,
        "Adv Demo":64.26,
        "Privacy":58.25,
        "Ethics":78.93,
        "Fairness":26.11,
        "Type":100.0,
        "Architecture":"instruction-tuned",
        "Precision":"MPTForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3-gptq",
        "Non-toxicity":61.56,
        "Non-Stereotype":51.51,
        "AdvGLUE++":90.0,
        "OoD":31.83,
        "Adv Demo":53.52,
        "Privacy":49.22,
        "Ethics":75.93,
        "Fairness":48.12,
        "Type":92.38,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-3bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-awq",
        "Non-toxicity":61.56,
        "Non-Stereotype":22.63,
        "AdvGLUE++":74.0,
        "OoD":43.16,
        "Adv Demo":54.56,
        "Privacy":46.68,
        "Ethics":74.03,
        "Fairness":78.36,
        "Type":99.07,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-4bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-gptq",
        "Non-toxicity":61.03,
        "Non-Stereotype":23.75,
        "AdvGLUE++":78.67,
        "OoD":44.06,
        "Adv Demo":45.27,
        "Privacy":48.22,
        "Ethics":77.72,
        "Fairness":72.83,
        "Type":97.7,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-3bit"
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"compressed-llm\/llama-2-13b-gptq",
        "Non-toxicity":60.95,
        "Non-Stereotype":22.53,
        "AdvGLUE++":77.0,
        "OoD":36.31,
        "Adv Demo":49.95,
        "Privacy":45.11,
        "Ethics":76.87,
        "Fairness":81.62,
        "Type":98.23,
        "Architecture":"pretrained",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"GPTQ-4bit"
    },
    {
        "T":"\u2b55",
        "Model":"lmsys\/vicuna-7b-v1.3",
        "Non-toxicity":60.62,
        "Non-Stereotype":28.0,
        "AdvGLUE++":81.0,
        "OoD":52.16,
        "Adv Demo":59.1,
        "Privacy":57.99,
        "Ethics":72.96,
        "Fairness":48.22,
        "Type":85.53,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3-awq",
        "Non-toxicity":60.14,
        "Non-Stereotype":28.21,
        "AdvGLUE++":77.33,
        "OoD":39.91,
        "Adv Demo":61.61,
        "Privacy":60.81,
        "Ethics":79.55,
        "Fairness":57.77,
        "Type":75.92,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-4bit"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3-awq",
        "Non-toxicity":60.1,
        "Non-Stereotype":29.27,
        "AdvGLUE++":82.33,
        "OoD":39.53,
        "Adv Demo":59.47,
        "Privacy":62.49,
        "Ethics":79.11,
        "Fairness":54.05,
        "Type":74.5,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-8bit"
    },
    {
        "T":"\u2b55",
        "Model":"tiiuae\/falcon-7b-instruct",
        "Non-toxicity":59.49,
        "Non-Stereotype":39.0,
        "AdvGLUE++":87.0,
        "OoD":43.98,
        "Adv Demo":51.45,
        "Privacy":33.95,
        "Ethics":70.26,
        "Fairness":50.28,
        "Type":100.0,
        "Architecture":"instruction-tuned",
        "Precision":"FalconForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"compressed-llm\/vicuna-13b-v1.3-awq",
        "Non-toxicity":59.04,
        "Non-Stereotype":30.61,
        "AdvGLUE++":82.0,
        "OoD":42.19,
        "Adv Demo":59.2,
        "Privacy":56.31,
        "Ethics":79.18,
        "Fairness":46.42,
        "Type":76.42,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"AWQ-3bit"
    },
    {
        "T":"\u2b55",
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Non-toxicity":58.82,
        "Non-Stereotype":30.12,
        "AdvGLUE++":79.33,
        "OoD":47.23,
        "Adv Demo":73.4,
        "Privacy":62.15,
        "Ethics":77.36,
        "Fairness":34.21,
        "Type":66.76,
        "Architecture":"instruction-tuned",
        "Precision":"MistralForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Instruct",
        "Non-toxicity":56.58,
        "Non-Stereotype":18.0,
        "AdvGLUE++":73.0,
        "OoD":44.81,
        "Adv Demo":54.21,
        "Privacy":58.51,
        "Ethics":76.64,
        "Fairness":27.49,
        "Type":100.0,
        "Architecture":"instruction-tuned",
        "Precision":"GPTNeoXForCausalLM",
        "#Params (B)":"bfloat16"
    },
    {
        "T":"\u2b55",
        "Model":"chavinlo\/alpaca-native",
        "Non-toxicity":45.85,
        "Non-Stereotype":22.0,
        "AdvGLUE++":43.0,
        "OoD":46.43,
        "Adv Demo":51.79,
        "Privacy":34.15,
        "Ethics":46.39,
        "Fairness":30.43,
        "Type":92.63,
        "Architecture":"instruction-tuned",
        "Precision":"LlamaForCausalLM",
        "#Params (B)":"bfloat16"
    }
]