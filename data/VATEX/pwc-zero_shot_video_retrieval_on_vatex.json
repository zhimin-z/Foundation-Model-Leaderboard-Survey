[
    {
        "table_id":21940,
        "row_id":96472,
        "rank":1,
        "Model":"VideoCoCa",
        "mlmodel":{

        },
        "method_short":"VideoCoCa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-09",
        "metrics":{
            "text-to-video R@1":"53.2",
            "text-to-video R@5":"83.3",
            "text-to-video R@10":"90.1",
            "video-to-text R@1":"73.6",
            "video-to-text R@5":"93.2",
            "video-to-text R@10":"97.2"
        },
        "raw_metrics":{
            "text-to-video R@1":53.2,
            "text-to-video R@5":83.3,
            "text-to-video R@10":90.1,
            "video-to-text R@1":73.6,
            "video-to-text R@5":93.2,
            "video-to-text R@10":97.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":1126258,
            "title":"VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners",
            "url":"\/paper\/video-text-modeling-with-zero-shot-transfer",
            "published":"2022-12-09T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/video-text-modeling-with-zero-shot-transfer\/review\/?hl=96472"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":21940,
        "row_id":86738,
        "rank":2,
        "Model":"InternVideo",
        "mlmodel":{

        },
        "method_short":"InternVideo",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-06",
        "metrics":{
            "text-to-video R@1":"49.5",
            "text-to-video R@5":null,
            "text-to-video R@10":null,
            "video-to-text R@1":"69.5",
            "video-to-text R@5":null,
            "video-to-text R@10":null
        },
        "raw_metrics":{
            "text-to-video R@1":49.5,
            "text-to-video R@5":null,
            "text-to-video R@10":null,
            "video-to-text R@1":69.5,
            "video-to-text R@5":null,
            "video-to-text R@10":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1124231,
            "title":"InternVideo: General Video Foundation Models via Generative and Discriminative Learning",
            "url":"\/paper\/internvideo-general-video-foundation-models",
            "published":"2022-12-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/internvideo-general-video-foundation-models\/review\/?hl=86738"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]