[
    {
        "Model":"TigerBot-70B-Chat-V2\n\nTigerResearch",
        "Release":"2023\/9\/15updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"70B",
        "Average(EN)":74.5,
        "BoolQ":95.5,
        "CommonSenseQA":84.9,
        "TriviaQA":75.2,
        "NaturalQuestions":42.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"GPT-4\n\nOpenAI",
        "Release":"2023\/3\/15updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":null,
        "Average(EN)":73.5,
        "BoolQ":90.6,
        "CommonSenseQA":88.3,
        "TriviaQA":75.0,
        "NaturalQuestions":40.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"WeMix-LLaMA2-70B\n\nShanghai AI Lab",
        "Release":"2023\/10\/16updated:2023\/10\/16",
        "Type":"Chat",
        "Parameters":"70B",
        "Average(EN)":68.8,
        "BoolQ":90.3,
        "CommonSenseQA":74.7,
        "TriviaQA":72.2,
        "NaturalQuestions":38.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-70B\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"70B",
        "Average(EN)":67.7,
        "BoolQ":87.7,
        "CommonSenseQA":78.3,
        "TriviaQA":70.7,
        "NaturalQuestions":34.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-65B\n\nMeta",
        "Release":"2023\/2\/24updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"65B",
        "Average(EN)":66.0,
        "BoolQ":86.6,
        "CommonSenseQA":74.1,
        "TriviaQA":69.8,
        "NaturalQuestions":33.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-70B-Chat\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"70B",
        "Average(EN)":65.0,
        "BoolQ":88.3,
        "CommonSenseQA":78.1,
        "TriviaQA":63.0,
        "NaturalQuestions":30.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Yi-34B\n\n01.AI",
        "Release":"2023\/11\/2updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"34B",
        "Average(EN)":64.5,
        "BoolQ":89.1,
        "CommonSenseQA":73.4,
        "TriviaQA":62.1,
        "NaturalQuestions":33.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"ChatGPT\n\nOpenAI",
        "Release":"2023\/3\/1updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":null,
        "Average(EN)":64.5,
        "BoolQ":87.2,
        "CommonSenseQA":80.2,
        "TriviaQA":63.8,
        "NaturalQuestions":27.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-70B-Chat-V1\n\nTigerResearch",
        "Release":"2023\/9\/6updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"70B",
        "Average(EN)":64.0,
        "BoolQ":94.2,
        "CommonSenseQA":79.0,
        "TriviaQA":62.0,
        "NaturalQuestions":20.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-30B\n\nMeta",
        "Release":"2023\/2\/24updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"30B",
        "Average(EN)":64.0,
        "BoolQ":84.4,
        "CommonSenseQA":69.0,
        "TriviaQA":71.8,
        "NaturalQuestions":30.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"WeMix-LLaMa2-13B\n\nShanghai AI Lab",
        "Release":"2023\/10\/11updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":62.9,
        "BoolQ":88.2,
        "CommonSenseQA":71.0,
        "TriviaQA":61.3,
        "NaturalQuestions":31.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-13B-Chat-V3\n\nTigerResearch",
        "Release":"2023\/9\/15updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":62.3,
        "BoolQ":83.4,
        "CommonSenseQA":77.4,
        "TriviaQA":60.2,
        "NaturalQuestions":28.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"StableBeluga2\n\nStability AI",
        "Release":"2023\/7\/21updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"70B",
        "Average(EN)":62.2,
        "BoolQ":89.4,
        "CommonSenseQA":72.6,
        "TriviaQA":61.7,
        "NaturalQuestions":25.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"ChatGLM3-6B-Base\n\nZhipuAI",
        "Release":"2023\/10\/27updated:2023\/10\/30",
        "Type":"Base",
        "Parameters":"6B",
        "Average(EN)":62.0,
        "BoolQ":86.5,
        "CommonSenseQA":62.4,
        "TriviaQA":63.5,
        "NaturalQuestions":35.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-33B-v1.3\n\nUC Berkeley",
        "Release":"2023\/4\/7updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"33B",
        "Average(EN)":61.3,
        "BoolQ":85.7,
        "CommonSenseQA":71.0,
        "TriviaQA":61.2,
        "NaturalQuestions":27.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Qwen-14B-Chat\n\nAlibaba",
        "Release":"2023\/9\/25updated:2023\/9\/25",
        "Type":"Chat",
        "Parameters":"14B",
        "Average(EN)":61.2,
        "BoolQ":84.3,
        "CommonSenseQA":83.0,
        "TriviaQA":54.1,
        "NaturalQuestions":23.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"XuanYuan-70B\n\nDuxiaoman",
        "Release":"2023\/9\/22updated:2023\/10\/13",
        "Type":"Base",
        "Parameters":"70B",
        "Average(EN)":60.6,
        "BoolQ":88.7,
        "CommonSenseQA":69.5,
        "TriviaQA":60.6,
        "NaturalQuestions":23.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"InternLM-20B\n\nShanghai AI Lab & SenseTime",
        "Release":"2023\/9\/20updated:2023\/9\/20",
        "Type":"Base",
        "Parameters":"20B",
        "Average(EN)":60.1,
        "BoolQ":87.5,
        "CommonSenseQA":70.6,
        "TriviaQA":57.3,
        "NaturalQuestions":25.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-13B-v1.5\n\nLMSYS",
        "Release":"2023\/7\/29updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":59.6,
        "BoolQ":85.7,
        "CommonSenseQA":70.6,
        "TriviaQA":56.3,
        "NaturalQuestions":25.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"WeMix-LLaMa2-7B\n\nShanghai AI Lab",
        "Release":"2023\/8\/31updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":59.4,
        "BoolQ":85.6,
        "CommonSenseQA":69.9,
        "TriviaQA":56.1,
        "NaturalQuestions":26.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Aquila2-34B\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"34B",
        "Average(EN)":59.2,
        "BoolQ":87.0,
        "CommonSenseQA":69.0,
        "TriviaQA":58.8,
        "NaturalQuestions":22.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Dolphin-2.2.1-Mistral-7B\n\nEric Hartford",
        "Release":"2023\/10\/11updated:2023\/11\/14",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":58.4,
        "BoolQ":87.6,
        "CommonSenseQA":78.8,
        "TriviaQA":50.1,
        "NaturalQuestions":16.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Ziya-LLaMA-13B\n\nIDEA-CCNL",
        "Release":"2023\/5\/30updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":58.4,
        "BoolQ":85.5,
        "CommonSenseQA":67.1,
        "TriviaQA":56.7,
        "NaturalQuestions":24.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-13B\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":58.3,
        "BoolQ":82.4,
        "CommonSenseQA":66.7,
        "TriviaQA":59.4,
        "NaturalQuestions":24.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-13B\n\nMeta",
        "Release":"2023\/2\/24updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":58.2,
        "BoolQ":78.7,
        "CommonSenseQA":67.4,
        "TriviaQA":66.5,
        "NaturalQuestions":20.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Mistral-7B-v0.1\n\nmistralai",
        "Release":"2023\/9\/27updated:2023\/10\/13",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":58.1,
        "BoolQ":84.1,
        "CommonSenseQA":67.4,
        "TriviaQA":56.5,
        "NaturalQuestions":24.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-Chinese-13B\n\nFlagAlpha",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":58.1,
        "BoolQ":83.5,
        "CommonSenseQA":67.4,
        "TriviaQA":56.1,
        "NaturalQuestions":25.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-13B-Chat\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":58.1,
        "BoolQ":82.4,
        "CommonSenseQA":69.9,
        "TriviaQA":55.0,
        "NaturalQuestions":25.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-13B-v1.5-16k\n\nLMSYS",
        "Release":"2023\/7\/31updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":58.0,
        "BoolQ":83.5,
        "CommonSenseQA":70.3,
        "TriviaQA":54.6,
        "NaturalQuestions":23.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-70B-Base-V1\n\nTigerResearch",
        "Release":"2023\/9\/6updated:2023\/10\/13",
        "Type":"Base",
        "Parameters":"70B",
        "Average(EN)":57.8,
        "BoolQ":81.4,
        "CommonSenseQA":72.8,
        "TriviaQA":57.6,
        "NaturalQuestions":19.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"BELLE-LLaMA-2\n\nLianjiaTech",
        "Release":"2023\/7\/27updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":57.5,
        "BoolQ":86.2,
        "CommonSenseQA":73.8,
        "TriviaQA":52.9,
        "NaturalQuestions":17.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-13B-v1.3\n\nUC Berkeley",
        "Release":"2023\/4\/7updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":57.2,
        "BoolQ":83.4,
        "CommonSenseQA":69.8,
        "TriviaQA":53.1,
        "NaturalQuestions":22.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-13B-Chat-V1\n\nTigerResearch",
        "Release":"2023\/8\/8updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":56.8,
        "BoolQ":84.5,
        "CommonSenseQA":65.4,
        "TriviaQA":57.0,
        "NaturalQuestions":20.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Yulan-Chat-2-13B\n\nGSAI, Renmin University of China",
        "Release":"2023\/8\/2updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":56.6,
        "BoolQ":85.8,
        "CommonSenseQA":65.8,
        "TriviaQA":51.9,
        "NaturalQuestions":22.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Qwen-14B\n\nAlibaba",
        "Release":"2023\/9\/25updated:2023\/9\/25",
        "Type":"Base",
        "Parameters":"14B",
        "Average(EN)":56.1,
        "BoolQ":86.1,
        "CommonSenseQA":70.1,
        "TriviaQA":48.4,
        "NaturalQuestions":19.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-13B-Chinese-Chat\n\nshareAI",
        "Release":"2023\/7\/20updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":55.9,
        "BoolQ":78.3,
        "CommonSenseQA":66.6,
        "TriviaQA":56.8,
        "NaturalQuestions":22.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Qwen-7B-Chat\n\nAlibaba",
        "Release":"2023\/9\/25updated:2023\/9\/25",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":54.7,
        "BoolQ":79.1,
        "CommonSenseQA":77.6,
        "TriviaQA":44.3,
        "NaturalQuestions":17.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-7B-Chat\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":54.3,
        "BoolQ":81.3,
        "CommonSenseQA":69.9,
        "TriviaQA":46.4,
        "NaturalQuestions":19.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-7B\n\nMeta",
        "Release":"2023\/2\/24updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":53.9,
        "BoolQ":75.4,
        "CommonSenseQA":64.9,
        "TriviaQA":60.0,
        "NaturalQuestions":15.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan-13B-Chat\n\nBaichuan Intelligent Technology",
        "Release":"2023\/7\/10updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":53.6,
        "BoolQ":78.8,
        "CommonSenseQA":67.7,
        "TriviaQA":48.3,
        "NaturalQuestions":19.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-7B\n\nMeta",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":53.3,
        "BoolQ":74.9,
        "CommonSenseQA":66.5,
        "TriviaQA":52.8,
        "NaturalQuestions":19.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-7B-v1.5-16k\n\nLMSYS",
        "Release":"2023\/8\/7updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":53.0,
        "BoolQ":80.8,
        "CommonSenseQA":64.9,
        "TriviaQA":48.0,
        "NaturalQuestions":18.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Skywork-13B-base\n\nKunlun Inc.",
        "Release":"2023\/10\/30updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":52.7,
        "BoolQ":80.9,
        "CommonSenseQA":64.6,
        "TriviaQA":48.1,
        "NaturalQuestions":17.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-13B-Base-V1\n\nTigerResearch",
        "Release":"2023\/8\/8updated:2023\/9\/26",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":52.5,
        "BoolQ":70.7,
        "CommonSenseQA":66.7,
        "TriviaQA":50.8,
        "NaturalQuestions":21.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-13B-Base-V2\n\nTigerResearch",
        "Release":"2023\/8\/25updated:2023\/9\/26",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":52.2,
        "BoolQ":72.8,
        "CommonSenseQA":66.6,
        "TriviaQA":49.6,
        "NaturalQuestions":19.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan2-13B-Chat\n\nBaichuan Intelligent Technology",
        "Release":"2023\/9\/6updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":51.9,
        "BoolQ":82.8,
        "CommonSenseQA":71.6,
        "TriviaQA":40.0,
        "NaturalQuestions":13.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-7B-v1.5\n\nLMSYS",
        "Release":"2023\/7\/29updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":51.8,
        "BoolQ":81.4,
        "CommonSenseQA":67.2,
        "TriviaQA":42.8,
        "NaturalQuestions":15.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Vicuna-7B-v1.3\n\nUC Berkeley",
        "Release":"2023\/4\/7updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":51.7,
        "BoolQ":78.3,
        "CommonSenseQA":66.4,
        "TriviaQA":45.6,
        "NaturalQuestions":16.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LLaMA-2-Chinese-7B\n\nFlagAlpha",
        "Release":"2023\/7\/19updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":51.4,
        "BoolQ":74.1,
        "CommonSenseQA":66.7,
        "TriviaQA":46.0,
        "NaturalQuestions":18.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-13B-Chat-V2\n\nTigerResearch",
        "Release":"2023\/8\/21updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":50.9,
        "BoolQ":67.5,
        "CommonSenseQA":61.8,
        "TriviaQA":54.5,
        "NaturalQuestions":19.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-Chat-V3\n\nTigerResearch",
        "Release":"2023\/8\/21updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":50.9,
        "BoolQ":78.0,
        "CommonSenseQA":63.1,
        "TriviaQA":48.1,
        "NaturalQuestions":14.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"WizardLM-7B\n\nMicrosoft",
        "Release":"2023\/4\/25updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":50.4,
        "BoolQ":72.3,
        "CommonSenseQA":69.2,
        "TriviaQA":43.5,
        "NaturalQuestions":16.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"InternLM-Chat-7B-8K\n\nShanghai AI Lab & SenseTime",
        "Release":"2023\/7\/6updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":50.1,
        "BoolQ":82.9,
        "CommonSenseQA":75.0,
        "TriviaQA":29.8,
        "NaturalQuestions":12.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"XVERSE-13B-Chat\n\nShenzhen Yuanxiang Technology",
        "Release":"2023\/8\/19updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":49.7,
        "BoolQ":80.6,
        "CommonSenseQA":73.0,
        "TriviaQA":33.4,
        "NaturalQuestions":11.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Yi-6B\n\n01.AI",
        "Release":"2023\/11\/2updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"6B",
        "Average(EN)":49.4,
        "BoolQ":77.1,
        "CommonSenseQA":65.7,
        "TriviaQA":41.7,
        "NaturalQuestions":13.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"InternLM-20B-Chat\n\nShanghai AI Lab & SenseTime",
        "Release":"2023\/9\/20updated:2023\/10\/16",
        "Type":"Chat",
        "Parameters":"20B",
        "Average(EN)":49.3,
        "BoolQ":75.5,
        "CommonSenseQA":78.1,
        "TriviaQA":30.1,
        "NaturalQuestions":13.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan2-7B-Chat\n\nBaichuan Intelligent Technology",
        "Release":"2023\/9\/6updated:2023\/9\/8",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":49.0,
        "BoolQ":77.1,
        "CommonSenseQA":68.6,
        "TriviaQA":37.6,
        "NaturalQuestions":12.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan2-13B-Base\n\nBaichuan Intelligent Technology",
        "Release":"2023\/9\/6updated:2023\/9\/8",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":48.9,
        "BoolQ":67.0,
        "CommonSenseQA":65.6,
        "TriviaQA":46.6,
        "NaturalQuestions":16.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"InternLM-Chat-7B\n\nShanghai AI Lab & SenseTime",
        "Release":"2023\/7\/6updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":48.8,
        "BoolQ":80.7,
        "CommonSenseQA":74.6,
        "TriviaQA":28.7,
        "NaturalQuestions":11.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-Base-V3\n\nTigerResearch",
        "Release":"2023\/8\/21updated:2023\/9\/26",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":48.8,
        "BoolQ":71.3,
        "CommonSenseQA":62.7,
        "TriviaQA":45.4,
        "NaturalQuestions":16.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Chinese-Alpaca-2-7B\n\niFLYTEK",
        "Release":"2023\/7\/31updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":48.6,
        "BoolQ":80.7,
        "CommonSenseQA":66.0,
        "TriviaQA":35.2,
        "NaturalQuestions":12.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Qwen-7B\n\nAlibaba",
        "Release":"2023\/9\/25updated:2023\/9\/25",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":48.1,
        "BoolQ":76.1,
        "CommonSenseQA":66.8,
        "TriviaQA":36.4,
        "NaturalQuestions":13.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"XVERSE-7B-Chat\n\nShenzhen Yuanxiang Technology",
        "Release":"2023\/9\/26updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":47.3,
        "BoolQ":78.7,
        "CommonSenseQA":69.7,
        "TriviaQA":29.5,
        "NaturalQuestions":11.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Mistral-7B-Instruct-v0.1\n\nmistralai",
        "Release":"2023\/9\/27updated:2023\/10\/13",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":46.3,
        "BoolQ":64.4,
        "CommonSenseQA":68.1,
        "TriviaQA":39.5,
        "NaturalQuestions":13.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"oppo-experiemental-7B\n\nOPPO Research Institute",
        "Release":"2023\/10\/27updated:2023\/11\/10",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":45.9,
        "BoolQ":65.1,
        "CommonSenseQA":73.8,
        "TriviaQA":32.4,
        "NaturalQuestions":12.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan-13B-Base\n\nBaichuan Intelligent Technology",
        "Release":"2023\/7\/10updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"13B",
        "Average(EN)":45.5,
        "BoolQ":73.6,
        "CommonSenseQA":63.8,
        "TriviaQA":37.3,
        "NaturalQuestions":7.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"OpenLLaMA-7Bv2\n\nopenlm-research",
        "Release":"2023\/7\/16updated:2023\/9\/8",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":45.4,
        "BoolQ":69.2,
        "CommonSenseQA":60.8,
        "TriviaQA":40.0,
        "NaturalQuestions":11.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"ChatGLM2-6B\n\nZhipuAI",
        "Release":"2023\/6\/25updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"6B",
        "Average(EN)":44.6,
        "BoolQ":79.0,
        "CommonSenseQA":65.4,
        "TriviaQA":24.1,
        "NaturalQuestions":9.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Alpaca-7B\n\nStanford University",
        "Release":"2023\/3\/14updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":44.6,
        "BoolQ":79.5,
        "CommonSenseQA":69.4,
        "TriviaQA":25.1,
        "NaturalQuestions":4.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"GoGPT\n\nInstitute of Computing Technology Chinese Academy of Sciences",
        "Release":"2023\/7\/21updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":44.4,
        "BoolQ":74.2,
        "CommonSenseQA":62.4,
        "TriviaQA":31.8,
        "NaturalQuestions":9.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Aquila2-7B\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":44.3,
        "BoolQ":77.6,
        "CommonSenseQA":63.6,
        "TriviaQA":27.3,
        "NaturalQuestions":8.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan2-7B-Base\n\nBaichuan Intelligent Technology",
        "Release":"2023\/9\/6updated:2023\/9\/8",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":44.3,
        "BoolQ":63.2,
        "CommonSenseQA":63.0,
        "TriviaQA":41.4,
        "NaturalQuestions":9.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"ChatGLM3-6B\n\nZhipuAI",
        "Release":"2023\/10\/27updated:2023\/10\/30",
        "Type":"Chat",
        "Parameters":"6B",
        "Average(EN)":43.6,
        "BoolQ":74.7,
        "CommonSenseQA":70.3,
        "TriviaQA":21.8,
        "NaturalQuestions":7.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"MPT-7B\n\nMosaicML",
        "Release":"2023\/5\/6updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":43.4,
        "BoolQ":72.6,
        "CommonSenseQA":61.8,
        "TriviaQA":31.3,
        "NaturalQuestions":7.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Claude-1\n\nAnthropic",
        "Release":"2023\/3\/14updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":null,
        "Average(EN)":43.2,
        "BoolQ":75.7,
        "CommonSenseQA":null,
        "TriviaQA":65.9,
        "NaturalQuestions":31.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"XVERSE-7B\n\nShenzhen Yuanxiang Technology",
        "Release":"2023\/9\/26updated:2023\/10\/13",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":43.1,
        "BoolQ":71.4,
        "CommonSenseQA":62.9,
        "TriviaQA":30.7,
        "NaturalQuestions":7.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"AquilaChat2-34B\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Chat",
        "Parameters":"34B",
        "Average(EN)":42.4,
        "BoolQ":57.1,
        "CommonSenseQA":79.4,
        "TriviaQA":26.7,
        "NaturalQuestions":6.2,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"OpenLLaMA-3Bv2\n\nopenlm-research",
        "Release":"2023\/7\/16updated:2023\/9\/8",
        "Type":"Base",
        "Parameters":"3B",
        "Average(EN)":42.1,
        "BoolQ":63.5,
        "CommonSenseQA":59.1,
        "TriviaQA":34.8,
        "NaturalQuestions":10.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-SFT-V1\n\nTigerResearch",
        "Release":"2023\/6\/15updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":41.4,
        "BoolQ":76.5,
        "CommonSenseQA":52.7,
        "TriviaQA":29.9,
        "NaturalQuestions":6.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"InternLM-7B\n\nShanghai AI Lab & SenseTime",
        "Release":"2023\/7\/6updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":41.3,
        "BoolQ":64.1,
        "CommonSenseQA":59.8,
        "TriviaQA":32.3,
        "NaturalQuestions":8.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"MPT-Instruct-7B\n\nMosaicML",
        "Release":"2023\/5\/6updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":40.8,
        "BoolQ":70.1,
        "CommonSenseQA":64.6,
        "TriviaQA":23.0,
        "NaturalQuestions":5.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"LingoWhale-8B\n\nDeepLang AI",
        "Release":"2023\/11\/1updated:2023\/11\/14",
        "Type":"Base",
        "Parameters":"8B",
        "Average(EN)":40.7,
        "BoolQ":39.8,
        "CommonSenseQA":57.9,
        "TriviaQA":43.9,
        "NaturalQuestions":21.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Baichuan-7B\n\nBaichuan Intelligent Technology",
        "Release":"2023\/6\/15updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":38.8,
        "BoolQ":67.0,
        "CommonSenseQA":59.3,
        "TriviaQA":26.2,
        "NaturalQuestions":2.5,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"AquilaChat2-7B\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":37.9,
        "BoolQ":58.5,
        "CommonSenseQA":56.8,
        "TriviaQA":28.8,
        "NaturalQuestions":7.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Phi-1.5-1.3B\n\nMicrosoft",
        "Release":"2023\/9\/10updated:2023\/9\/19",
        "Type":"Base",
        "Parameters":"1.3B",
        "Average(EN)":35.4,
        "BoolQ":73.5,
        "CommonSenseQA":59.7,
        "TriviaQA":6.4,
        "NaturalQuestions":1.9,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-SFT-V2\n\nTigerResearch",
        "Release":"2023\/7\/8updated:2023\/9\/26",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":34.4,
        "BoolQ":75.4,
        "CommonSenseQA":45.3,
        "TriviaQA":13.1,
        "NaturalQuestions":3.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"MOSS-Moon\n\nFudan university",
        "Release":"2023\/4\/21updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"16B",
        "Average(EN)":33.0,
        "BoolQ":59.4,
        "CommonSenseQA":53.0,
        "TriviaQA":15.6,
        "NaturalQuestions":4.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-Base-V1\n\nTigerResearch",
        "Release":"2023\/6\/7updated:2023\/9\/26",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":33.0,
        "BoolQ":63.0,
        "CommonSenseQA":50.7,
        "TriviaQA":14.8,
        "NaturalQuestions":3.6,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"XVERSE-13B\n\nShenzhen Yuanxiang Technology",
        "Release":"2023\/8\/6updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"13B",
        "Average(EN)":32.9,
        "BoolQ":64.2,
        "CommonSenseQA":62.2,
        "TriviaQA":4.8,
        "NaturalQuestions":0.3,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Chinese-LLaMA-2-7B\n\niFLYTEK",
        "Release":"2023\/7\/31updated:2023\/9\/1",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":32.7,
        "BoolQ":65.2,
        "CommonSenseQA":49.3,
        "TriviaQA":11.7,
        "NaturalQuestions":4.7,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"TigerBot-7B-Base-V2\n\nTigerResearch",
        "Release":"2023\/7\/8updated:2023\/9\/26",
        "Type":"Base",
        "Parameters":"7B",
        "Average(EN)":31.9,
        "BoolQ":64.3,
        "CommonSenseQA":52.4,
        "TriviaQA":8.9,
        "NaturalQuestions":2.0,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"Xwin-LM-7B-V0.1\n\nXwin-LM",
        "Release":"2023\/9\/19updated:2023\/10\/13",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":30.5,
        "BoolQ":23.6,
        "CommonSenseQA":48.2,
        "TriviaQA":39.8,
        "NaturalQuestions":10.4,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"MOSS-Moon-SFT\n\nFudan university",
        "Release":"2023\/4\/21updated:2023\/9\/1",
        "Type":"Chat",
        "Parameters":"16B",
        "Average(EN)":29.1,
        "BoolQ":66.5,
        "CommonSenseQA":39.7,
        "TriviaQA":8.3,
        "NaturalQuestions":2.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"AquilaChat2-34B-16K\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Chat",
        "Parameters":"34B",
        "Average(EN)":28.4,
        "BoolQ":27.7,
        "CommonSenseQA":57.1,
        "TriviaQA":20.2,
        "NaturalQuestions":8.8,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    },
    {
        "Model":"AquilaChat2-7B-16K\n\nBAAI",
        "Release":"2023\/10\/25updated:2023\/11\/14",
        "Type":"Chat",
        "Parameters":"7B",
        "Average(EN)":27.7,
        "BoolQ":48.7,
        "CommonSenseQA":46.4,
        "TriviaQA":10.8,
        "NaturalQuestions":5.1,
        "Unnamed: 9":null,
        "Unnamed: 10":null,
        "Unnamed: 11":null,
        "Unnamed: 12":null,
        "Unnamed: 13":null,
        "Unnamed: 14":null,
        "Unnamed: 15":null,
        "Unnamed: 16":null,
        "Unnamed: 17":null,
        "Unnamed: 18":null,
        "Unnamed: 19":null,
        "Unnamed: 20":null
    }
]