[
    {
        "table_id":964,
        "row_id":86565,
        "rank":1,
        "Model":"MT-DNN-SMART",
        "mlmodel":{

        },
        "method_short":"MT-DNN-SMART",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-08",
        "metrics":{
            "Accuracy":"93.7%",
            "F1":"91.7"
        },
        "raw_metrics":{
            "Accuracy":93.7,
            "F1":91.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":169701,
            "title":"SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization",
            "url":"\/paper\/smart-robust-and-efficient-fine-tuning-for",
            "published":"2019-11-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/smart-robust-and-efficient-fine-tuning-for\/review\/?hl=86565"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":7991,
        "rank":2,
        "Model":"ALBERT",
        "mlmodel":{

        },
        "method_short":"ALBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-26",
        "metrics":{
            "Accuracy":"93.4%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":93.4,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":156146,
            "title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
            "url":"\/paper\/albert-a-lite-bert-for-self-supervised",
            "published":"2019-09-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/albert-a-lite-bert-for-self-supervised\/review\/?hl=7991"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":6024,
        "rank":3,
        "Model":"RoBERTa",
        "mlmodel":{

        },
        "method_short":"RoBERTa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-26",
        "metrics":{
            "Accuracy":"92.3%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":92.3,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":148282,
            "title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach",
            "url":"\/paper\/roberta-a-robustly-optimized-bert-pretraining",
            "published":"2019-07-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/roberta-a-robustly-optimized-bert-pretraining\/review\/?hl=6024"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":30635,
        "rank":4,
        "Model":"StructBERTRoBERTa ensemble",
        "mlmodel":{

        },
        "method_short":"StructBERTRoBERTa ensemble",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-13",
        "metrics":{
            "Accuracy":"91.5%",
            "F1":"93.6%"
        },
        "raw_metrics":{
            "Accuracy":91.5,
            "F1":93.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":149844,
            "title":"StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding",
            "url":"\/paper\/structbert-incorporating-language-structures",
            "published":"2019-08-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/structbert-incorporating-language-structures\/review\/?hl=30635"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":18185,
        "rank":5,
        "Model":"FLOATER-large",
        "mlmodel":{

        },
        "method_short":"FLOATER-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-03-13",
        "metrics":{
            "Accuracy":"91.4%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":91.4,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":187817,
            "title":"Learning to Encode Position for Transformer with Continuous Dynamical Model",
            "url":"\/paper\/learning-to-encode-position-for-transformer",
            "published":"2020-03-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-to-encode-position-for-transformer\/review\/?hl=18185"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":24674,
        "rank":6,
        "Model":"SMART",
        "mlmodel":{

        },
        "method_short":"SMART",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-08",
        "metrics":{
            "Accuracy":"91.3%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":91.3,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":169701,
            "title":"SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization",
            "url":"\/paper\/smart-robust-and-efficient-fine-tuning-for",
            "published":"2019-11-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/smart-robust-and-efficient-fine-tuning-for\/review\/?hl=24674"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":63592,
        "rank":7,
        "Model":"Vector-wise",
        "mlmodel":{

        },
        "method_short":"Vector-wise",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-08-15",
        "metrics":{
            "Accuracy":"91.0%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":91.0,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1058964,
            "title":"LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale",
            "url":"\/paper\/llm-int8-8-bit-matrix-multiplication-for",
            "published":"2022-08-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llm-int8-8-bit-matrix-multiplication-for\/review\/?hl=63592"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":7925,
        "rank":8,
        "Model":"SpanBERT",
        "mlmodel":{

        },
        "method_short":"SpanBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-24",
        "metrics":{
            "Accuracy":"90.9%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.9,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":146696,
            "title":"SpanBERT: Improving Pre-training by Representing and Predicting Spans",
            "url":"\/paper\/spanbert-improving-pre-training-by",
            "published":"2019-07-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/spanbert-improving-pre-training-by\/review\/?hl=7925"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12722,
        "rank":9,
        "Model":"XLNet (single model)",
        "mlmodel":{

        },
        "method_short":"XLNet ",
        "method_details":"single model",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-19",
        "metrics":{
            "Accuracy":"90.8%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.8,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":143172,
            "title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding",
            "url":"\/paper\/xlnet-generalized-autoregressive-pretraining",
            "published":"2019-06-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/xlnet-generalized-autoregressive-pretraining\/review\/?hl=12722"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":71999,
        "rank":10,
        "Model":"AutoBERT-Zero (Large)",
        "mlmodel":{

        },
        "method_short":"AutoBERT-Zero ",
        "method_details":"Large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-15",
        "metrics":{
            "Accuracy":"90.7%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.7,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":836302,
            "title":"AutoBERT-Zero: Evolving BERT Backbone from Scratch",
            "url":"\/paper\/autobert-zero-evolving-bert-backbone-from",
            "published":"2021-07-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/autobert-zero-evolving-bert-backbone-from\/review\/?hl=71999"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":24202,
        "rank":11,
        "Model":"MLM+ del-word+ reorder",
        "mlmodel":{

        },
        "method_short":"MLM+ del-word+ reorder",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-31",
        "metrics":{
            "Accuracy":"90.6%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.6,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":732544,
            "title":"CLEAR: Contrastive Learning for Sentence Representation",
            "url":"\/paper\/clear-contrastive-learning-for-sentence",
            "published":"2020-12-31T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/clear-contrastive-learning-for-sentence\/review\/?hl=24202"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":71998,
        "rank":12,
        "Model":"AutoBERT-Zero (Base)",
        "mlmodel":{

        },
        "method_short":"AutoBERT-Zero ",
        "method_details":"Base",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-15",
        "metrics":{
            "Accuracy":"90.5%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.5,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":836302,
            "title":"AutoBERT-Zero: Evolving BERT Backbone from Scratch",
            "url":"\/paper\/autobert-zero-evolving-bert-backbone-from",
            "published":"2021-07-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/autobert-zero-evolving-bert-backbone-from\/review\/?hl=71998"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8113,
        "rank":13,
        "Model":"DistilBERT",
        "mlmodel":{

        },
        "method_short":"DistilBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-02",
        "metrics":{
            "Accuracy":"90.2%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":90.2,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":156821,
            "title":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
            "url":"\/paper\/distilbert-a-distilled-version-of-bert",
            "published":"2019-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/distilbert-a-distilled-version-of-bert\/review\/?hl=8113"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8332,
        "rank":14,
        "Model":"T5-11B",
        "mlmodel":{

        },
        "method_short":"T5-11B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-23",
        "metrics":{
            "Accuracy":"90.0%",
            "F1":"91.9%"
        },
        "raw_metrics":{
            "Accuracy":90.0,
            "F1":91.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":166345,
            "title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "url":"\/paper\/exploring-the-limits-of-transfer-learning",
            "published":"2019-10-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-the-limits-of-transfer-learning\/review\/?hl=8332"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8334,
        "rank":15,
        "Model":"T5-Large",
        "mlmodel":{

        },
        "method_short":"T5-Large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-23",
        "metrics":{
            "Accuracy":"89.9%",
            "F1":"92.4%"
        },
        "raw_metrics":{
            "Accuracy":89.9,
            "F1":92.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":166345,
            "title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "url":"\/paper\/exploring-the-limits-of-transfer-learning",
            "published":"2019-10-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-the-limits-of-transfer-learning\/review\/?hl=8334"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":7926,
        "rank":16,
        "Model":"ELECTRA",
        "mlmodel":{

        },
        "method_short":"ELECTRA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy":"89.6%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":89.6,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8333,
        "rank":17,
        "Model":"T5-3B",
        "mlmodel":{

        },
        "method_short":"T5-3B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-23",
        "metrics":{
            "Accuracy":"89.2%",
            "F1":"92.5%"
        },
        "raw_metrics":{
            "Accuracy":89.2,
            "F1":92.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":166345,
            "title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "url":"\/paper\/exploring-the-limits-of-transfer-learning",
            "published":"2019-10-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-the-limits-of-transfer-learning\/review\/?hl=8333"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":71985,
        "rank":18,
        "Model":"MobileBERT",
        "mlmodel":{

        },
        "method_short":"MobileBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-04-06",
        "metrics":{
            "Accuracy":"88.8%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":88.8,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":189976,
            "title":"MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices",
            "url":"\/paper\/mobilebert-a-compact-task-agnostic-bert-for",
            "published":"2020-04-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mobilebert-a-compact-task-agnostic-bert-for\/review\/?hl=71985"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12723,
        "rank":19,
        "Model":"ERNIE",
        "mlmodel":{

        },
        "method_short":"ERNIE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-17",
        "metrics":{
            "Accuracy":"88.2%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":88.2,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":114976,
            "title":"ERNIE: Enhanced Language Representation with Informative Entities",
            "url":"\/paper\/ernie-enhanced-language-representation-with",
            "published":"2019-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-enhanced-language-representation-with\/review\/?hl=12723"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":33089,
        "rank":20,
        "Model":"FNet-Large",
        "mlmodel":{

        },
        "method_short":"FNet-Large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-09",
        "metrics":{
            "Accuracy":"88%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":88.0,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":796253,
            "title":"FNet: Mixing Tokens with Fourier Transforms",
            "url":"\/paper\/fnet-mixing-tokens-with-fourier-transforms",
            "published":"2021-05-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fnet-mixing-tokens-with-fourier-transforms\/review\/?hl=33089"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":71976,
        "rank":21,
        "Model":"SqueezeBERT",
        "mlmodel":{

        },
        "method_short":"SqueezeBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-19",
        "metrics":{
            "Accuracy":"87.8%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":87.8,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":205166,
            "title":"SqueezeBERT: What can computer vision teach NLP about efficient neural networks?",
            "url":"\/paper\/squeezebert-what-can-computer-vision-teach",
            "published":"2020-06-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/squeezebert-what-can-computer-vision-teach\/review\/?hl=71976"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":36316,
        "rank":22,
        "Model":"Charformer-Tall",
        "mlmodel":{

        },
        "method_short":"Charformer-Tall",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-23",
        "metrics":{
            "Accuracy":"87.5%",
            "F1":"91.4"
        },
        "raw_metrics":{
            "Accuracy":87.5,
            "F1":91.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":824266,
            "title":"Charformer: Fast Character Transformers via Gradient-based Subword Tokenization",
            "url":"\/paper\/charformer-fast-character-transformers-via",
            "published":"2021-06-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/charformer-fast-character-transformers-via\/review\/?hl=36316"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8335,
        "rank":23,
        "Model":"T5-Base",
        "mlmodel":{

        },
        "method_short":"T5-Base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-23",
        "metrics":{
            "Accuracy":"87.5%",
            "F1":"90.7%"
        },
        "raw_metrics":{
            "Accuracy":87.5,
            "F1":90.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":166345,
            "title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "url":"\/paper\/exploring-the-limits-of-transfer-learning",
            "published":"2019-10-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-the-limits-of-transfer-learning\/review\/?hl=8335"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":30350,
        "rank":24,
        "Model":"24hBERT",
        "mlmodel":{

        },
        "method_short":"24hBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-15",
        "metrics":{
            "Accuracy":"87.5%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":87.5,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":783560,
            "title":"How to Train BERT with an Academic Budget",
            "url":"\/paper\/how-to-train-bert-with-an-academic-budget",
            "published":"2021-04-15T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":6071,
        "rank":25,
        "Model":"ERNIE 2.0 Large",
        "mlmodel":{

        },
        "method_short":"ERNIE 2.0 Large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-29",
        "metrics":{
            "Accuracy":"87.4%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":87.4,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":148407,
            "title":"ERNIE 2.0: A Continual Pre-training Framework for Language Understanding",
            "url":"\/paper\/ernie-20-a-continual-pre-training-framework",
            "published":"2019-07-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-20-a-continual-pre-training-framework\/review\/?hl=6071"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":30629,
        "rank":26,
        "Model":"RealFormer",
        "mlmodel":{

        },
        "method_short":"RealFormer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-21",
        "metrics":{
            "Accuracy":"87.01%",
            "F1":"90.91%"
        },
        "raw_metrics":{
            "Accuracy":87.01,
            "F1":90.91
        },
        "uses_additional_data":false,
        "paper":{
            "id":730853,
            "title":"RealFormer: Transformer Likes Residual Attention",
            "url":"\/paper\/informer-transformer-likes-informed-attention",
            "published":"2020-12-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/informer-transformer-likes-informed-attention\/review\/?hl=30629"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":8336,
        "rank":27,
        "Model":"T5-Small",
        "mlmodel":{

        },
        "method_short":"T5-Small",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-23",
        "metrics":{
            "Accuracy":"86.6%",
            "F1":"89.7%"
        },
        "raw_metrics":{
            "Accuracy":86.6,
            "F1":89.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":166345,
            "title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "url":"\/paper\/exploring-the-limits-of-transfer-learning",
            "published":"2019-10-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-the-limits-of-transfer-learning\/review\/?hl=8336"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12724,
        "rank":28,
        "Model":"TinyBERT",
        "mlmodel":{

        },
        "method_short":"TinyBERT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-23",
        "metrics":{
            "Accuracy":"86.4%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":86.4,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":154692,
            "title":"TinyBERT: Distilling BERT for Natural Language Understanding",
            "url":"\/paper\/190910351",
            "published":"2019-09-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/190910351\/review\/?hl=12724"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":6070,
        "rank":29,
        "Model":"ERNIE 2.0 Base",
        "mlmodel":{

        },
        "method_short":"ERNIE 2.0 Base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-29",
        "metrics":{
            "Accuracy":"86.1%",
            "F1":null
        },
        "raw_metrics":{
            "Accuracy":86.1,
            "F1":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":148407,
            "title":"ERNIE 2.0: A Continual Pre-training Framework for Language Understanding",
            "url":"\/paper\/ernie-20-a-continual-pre-training-framework",
            "published":"2019-07-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-20-a-continual-pre-training-framework\/review\/?hl=6070"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12725,
        "rank":30,
        "Model":"TF-KLD",
        "mlmodel":{

        },
        "method_short":"TF-KLD",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2013-10-01",
        "metrics":{
            "Accuracy":"80.4%",
            "F1":"85.9%"
        },
        "raw_metrics":{
            "Accuracy":80.4,
            "F1":85.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":97260,
            "title":"Discriminative Improvements to Distributional Sentence Similarity",
            "url":"\/paper\/discriminative-improvements-to-distributional",
            "published":"2013-10-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12726,
        "rank":31,
        "Model":"GenSen",
        "mlmodel":{

        },
        "method_short":"GenSen",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-03-30",
        "metrics":{
            "Accuracy":"78.6%",
            "F1":"84.4%"
        },
        "raw_metrics":{
            "Accuracy":78.6,
            "F1":84.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":7029,
            "title":"Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning",
            "url":"\/paper\/learning-general-purpose-distributed-sentence",
            "published":"2018-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-general-purpose-distributed-sentence\/review\/?hl=12726"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":12727,
        "rank":32,
        "Model":"InferSent",
        "mlmodel":{

        },
        "method_short":"InferSent",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-05",
        "metrics":{
            "Accuracy":"76.2%",
            "F1":"83.1%"
        },
        "raw_metrics":{
            "Accuracy":76.2,
            "F1":83.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":20039,
            "title":"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data",
            "url":"\/paper\/supervised-learning-of-universal-sentence",
            "published":"2017-05-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/supervised-learning-of-universal-sentence\/review\/?hl=12727"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":18894,
        "rank":33,
        "Model":"BigBird",
        "mlmodel":{

        },
        "method_short":"BigBird",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-28",
        "metrics":{
            "Accuracy":null,
            "F1":"91.5%"
        },
        "raw_metrics":{
            "Accuracy":null,
            "F1":91.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":210706,
            "title":"Big Bird: Transformers for Longer Sequences",
            "url":"\/paper\/big-bird-transformers-for-longer-sequences",
            "published":"2020-07-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/big-bird-transformers-for-longer-sequences\/review\/?hl=18894"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":31484,
        "rank":34,
        "Model":"EFL",
        "mlmodel":{

        },
        "method_short":"EFL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Accuracy":null,
            "F1":"91.0"
        },
        "raw_metrics":{
            "Accuracy":null,
            "F1":91.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":791525,
            "title":"Entailment as Few-Shot Learner",
            "url":"\/paper\/entailment-as-few-shot-learner",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/entailment-as-few-shot-learner\/review\/?hl=31484"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":86509,
        "rank":35,
        "Model":"BERT-LARGE",
        "mlmodel":{

        },
        "method_short":"BERT-LARGE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-10-11",
        "metrics":{
            "Accuracy":null,
            "F1":"89.3"
        },
        "raw_metrics":{
            "Accuracy":null,
            "F1":89.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":59204,
            "title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "url":"\/paper\/bert-pre-training-of-deep-bidirectional",
            "published":"2018-10-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bert-pre-training-of-deep-bidirectional\/review\/?hl=86509"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":964,
        "row_id":25279,
        "rank":36,
        "Model":"Nystr\u00f6mformer",
        "mlmodel":{

        },
        "method_short":"Nystr\u00f6mformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-07",
        "metrics":{
            "Accuracy":null,
            "F1":"88.1%"
        },
        "raw_metrics":{
            "Accuracy":null,
            "F1":88.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":743243,
            "title":"Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention",
            "url":"\/paper\/nystromformer-a-nystrom-based-algorithm-for",
            "published":"2021-02-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/nystromformer-a-nystrom-based-algorithm-for\/review\/?hl=25279"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]