[
    {
        "T":"\ud83d\udd36",
        "Model":"davidkim205\/Rhea-72b-v0.5",
        "Average":81.22,
        "ARC":79.78,
        "HellaSwag":91.15,
        "MMLU":77.95,
        "TruthfulQA":74.5,
        "Winogrande":87.85,
        "GSM8K":76.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Contamination\/contaminated_proof_7b_v1.0_safetensor",
        "Average":81.14,
        "ARC":78.07,
        "HellaSwag":90.22,
        "MMLU":78.92,
        "TruthfulQA":82.29,
        "Winogrande":88.16,
        "GSM8K":69.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"davidkim205\/Rhea-72b-v0.4",
        "Average":81.09,
        "ARC":78.5,
        "HellaSwag":90.75,
        "MMLU":78.01,
        "TruthfulQA":73.91,
        "Winogrande":86.74,
        "GSM8K":78.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MTSAIR\/MultiVerse_70B",
        "Average":81.0,
        "ARC":78.67,
        "HellaSwag":89.77,
        "MMLU":78.22,
        "TruthfulQA":75.18,
        "Winogrande":87.53,
        "GSM8K":76.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"binbi\/Ein-72B-v0.1",
        "Average":80.99,
        "ARC":76.45,
        "HellaSwag":89.43,
        "MMLU":77.14,
        "TruthfulQA":78.09,
        "Winogrande":84.77,
        "GSM8K":80.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MTSAIR\/MultiVerse_70B",
        "Average":80.98,
        "ARC":78.58,
        "HellaSwag":89.74,
        "MMLU":78.27,
        "TruthfulQA":75.09,
        "Winogrande":87.37,
        "GSM8K":76.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"davidkim205\/Rhea-72b-v0.2",
        "Average":80.95,
        "ARC":77.56,
        "HellaSwag":90.84,
        "MMLU":77.98,
        "TruthfulQA":74.5,
        "Winogrande":86.35,
        "GSM8K":78.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"davidkim205\/Rhea-72b-v0.3",
        "Average":80.85,
        "ARC":76.79,
        "HellaSwag":89.98,
        "MMLU":77.47,
        "TruthfulQA":75.93,
        "Winogrande":85.08,
        "GSM8K":79.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SF-Foundation\/Ein-72B-v0.11",
        "Average":80.81,
        "ARC":76.79,
        "HellaSwag":89.02,
        "MMLU":77.2,
        "TruthfulQA":79.02,
        "Winogrande":84.06,
        "GSM8K":78.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SF-Foundation\/Ein-72B-v0.13",
        "Average":80.79,
        "ARC":76.19,
        "HellaSwag":89.44,
        "MMLU":77.07,
        "TruthfulQA":77.82,
        "Winogrande":84.93,
        "GSM8K":79.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"binbi\/Ein-72B-v0.1",
        "Average":80.79,
        "ARC":76.54,
        "HellaSwag":89.2,
        "MMLU":77.11,
        "TruthfulQA":78.47,
        "Winogrande":84.06,
        "GSM8K":79.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SF-Foundation\/Ein-72B-v0.12",
        "Average":80.72,
        "ARC":76.19,
        "HellaSwag":89.46,
        "MMLU":77.17,
        "TruthfulQA":77.78,
        "Winogrande":84.45,
        "GSM8K":79.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaug-72B-v0.1",
        "Average":80.48,
        "ARC":76.02,
        "HellaSwag":89.27,
        "MMLU":77.15,
        "TruthfulQA":76.67,
        "Winogrande":85.08,
        "GSM8K":78.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":430.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/alpaca-dragon-72b-v1",
        "Average":79.3,
        "ARC":73.89,
        "HellaSwag":88.16,
        "MMLU":77.4,
        "TruthfulQA":72.69,
        "Winogrande":86.03,
        "GSM8K":77.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"moreh\/MoMo-72B-lora-1.8.7-DPO",
        "Average":78.55,
        "ARC":70.82,
        "HellaSwag":85.96,
        "MMLU":77.13,
        "TruthfulQA":74.71,
        "Winogrande":84.06,
        "GSM8K":78.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO_f16",
        "Average":77.91,
        "ARC":74.06,
        "HellaSwag":86.74,
        "MMLU":76.65,
        "TruthfulQA":72.24,
        "Winogrande":83.35,
        "GSM8K":74.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v1.0",
        "Average":77.74,
        "ARC":77.47,
        "HellaSwag":91.88,
        "MMLU":68.1,
        "TruthfulQA":79.17,
        "Winogrande":87.45,
        "GSM8K":62.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HanNayeoniee\/LHK_DPO_v1",
        "Average":77.62,
        "ARC":74.74,
        "HellaSwag":89.3,
        "MMLU":64.9,
        "TruthfulQA":79.89,
        "Winogrande":88.32,
        "GSM8K":68.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/TomGrc_FusionNet_34Bx2_MoE_v0.1_full_linear_DPO",
        "Average":77.52,
        "ARC":74.06,
        "HellaSwag":86.67,
        "MMLU":76.69,
        "TruthfulQA":71.32,
        "Winogrande":83.43,
        "GSM8K":72.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v0.2",
        "Average":77.51,
        "ARC":76.71,
        "HellaSwag":91.61,
        "MMLU":68.27,
        "TruthfulQA":79.8,
        "Winogrande":87.06,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-v8.1",
        "Average":77.5,
        "ARC":73.81,
        "HellaSwag":89.22,
        "MMLU":64.92,
        "TruthfulQA":78.57,
        "Winogrande":87.37,
        "GSM8K":71.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B",
        "Average":77.44,
        "ARC":74.91,
        "HellaSwag":89.3,
        "MMLU":64.67,
        "TruthfulQA":78.02,
        "Winogrande":88.24,
        "GSM8K":69.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Asura_v1",
        "Average":77.43,
        "ARC":73.89,
        "HellaSwag":89.07,
        "MMLU":75.44,
        "TruthfulQA":71.75,
        "Winogrande":86.35,
        "GSM8K":68.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-SimpleSmaug-34b-v1beta",
        "Average":77.41,
        "ARC":74.57,
        "HellaSwag":86.74,
        "MMLU":76.68,
        "TruthfulQA":70.17,
        "Winogrande":83.82,
        "GSM8K":72.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_34Bx2_MoE_v0.1",
        "Average":77.38,
        "ARC":73.72,
        "HellaSwag":86.46,
        "MMLU":76.72,
        "TruthfulQA":71.01,
        "Winogrande":83.35,
        "GSM8K":73.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":60.81,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v0.1",
        "Average":77.32,
        "ARC":76.79,
        "HellaSwag":91.79,
        "MMLU":68.18,
        "TruthfulQA":76.7,
        "Winogrande":87.53,
        "GSM8K":62.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-72B-v1.5b",
        "Average":77.3,
        "ARC":71.25,
        "HellaSwag":85.53,
        "MMLU":76.63,
        "TruthfulQA":71.99,
        "Winogrande":81.45,
        "GSM8K":76.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"moreh\/MoMo-72B-lora-1.8.6-DPO",
        "Average":77.29,
        "ARC":70.14,
        "HellaSwag":86.03,
        "MMLU":77.4,
        "TruthfulQA":69.0,
        "Winogrande":84.37,
        "GSM8K":76.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaug-34B-v0.1",
        "Average":77.29,
        "ARC":74.23,
        "HellaSwag":86.76,
        "MMLU":76.66,
        "TruthfulQA":70.22,
        "Winogrande":83.66,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":50.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaugv0.1",
        "Average":77.29,
        "ARC":74.23,
        "HellaSwag":86.76,
        "MMLU":76.66,
        "TruthfulQA":70.22,
        "Winogrande":83.66,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE",
        "Average":77.28,
        "ARC":72.87,
        "HellaSwag":86.52,
        "MMLU":76.96,
        "TruthfulQA":73.28,
        "Winogrande":83.19,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":60.81,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/MoeLovely-13B",
        "Average":77.25,
        "ARC":73.72,
        "HellaSwag":89.49,
        "MMLU":64.78,
        "TruthfulQA":78.74,
        "Winogrande":87.61,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v0.4",
        "Average":77.23,
        "ARC":76.88,
        "HellaSwag":91.83,
        "MMLU":68.06,
        "TruthfulQA":76.72,
        "Winogrande":87.21,
        "GSM8K":62.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/orthorus-125b-v2",
        "Average":77.22,
        "ARC":73.63,
        "HellaSwag":89.04,
        "MMLU":75.99,
        "TruthfulQA":70.19,
        "Winogrande":85.48,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":125.35,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Luminex-34B-v0.2",
        "Average":77.19,
        "ARC":74.49,
        "HellaSwag":86.76,
        "MMLU":76.55,
        "TruthfulQA":70.21,
        "Winogrande":83.27,
        "GSM8K":71.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"senseable\/Wilbur-30B",
        "Average":77.18,
        "ARC":74.06,
        "HellaSwag":86.68,
        "MMLU":76.7,
        "TruthfulQA":69.96,
        "Winogrande":83.43,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"RubielLabarta\/LogoS-7Bx2-MoE-13B-v0.2",
        "Average":77.15,
        "ARC":74.4,
        "HellaSwag":89.09,
        "MMLU":64.9,
        "TruthfulQA":74.53,
        "Winogrande":88.4,
        "GSM8K":71.57,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RubielLabarta\/LogoS-7Bx2-MoE-13B-v0.1",
        "Average":77.14,
        "ARC":74.49,
        "HellaSwag":89.07,
        "MMLU":64.74,
        "TruthfulQA":74.57,
        "Winogrande":88.32,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yunconglong\/DARE_TIES_13B",
        "Average":77.1,
        "ARC":74.32,
        "HellaSwag":89.5,
        "MMLU":64.47,
        "TruthfulQA":78.66,
        "Winogrande":88.08,
        "GSM8K":67.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "other"
        ],
        "Available on the Hub":12.88,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yunconglong\/13B_MATH_DPO",
        "Average":77.08,
        "ARC":74.66,
        "HellaSwag":89.51,
        "MMLU":64.53,
        "TruthfulQA":78.63,
        "Winogrande":88.08,
        "GSM8K":67.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_34Bx2_MoE",
        "Average":77.07,
        "ARC":72.95,
        "HellaSwag":86.22,
        "MMLU":77.05,
        "TruthfulQA":71.31,
        "Winogrande":83.98,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":60.81,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Luminex-34B-v0.1",
        "Average":77.06,
        "ARC":73.63,
        "HellaSwag":86.59,
        "MMLU":76.55,
        "TruthfulQA":69.68,
        "Winogrande":83.43,
        "GSM8K":72.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yunconglong\/MoE_13B_DPO",
        "Average":77.05,
        "ARC":74.32,
        "HellaSwag":89.39,
        "MMLU":64.48,
        "TruthfulQA":78.47,
        "Winogrande":88.0,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":12.88,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Asura_v3.0",
        "Average":77.03,
        "ARC":72.95,
        "HellaSwag":88.86,
        "MMLU":75.41,
        "TruthfulQA":69.1,
        "Winogrande":85.08,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"4season\/alignment_model_test",
        "Average":76.97,
        "ARC":78.24,
        "HellaSwag":89.68,
        "MMLU":68.08,
        "TruthfulQA":80.88,
        "Winogrande":86.5,
        "GSM8K":58.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/4bit_quant_TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO",
        "Average":76.95,
        "ARC":73.21,
        "HellaSwag":86.11,
        "MMLU":75.44,
        "TruthfulQA":72.78,
        "Winogrande":82.95,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":31.8,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/YamshadowExperiment28-7B",
        "Average":76.86,
        "ARC":73.29,
        "HellaSwag":89.25,
        "MMLU":64.38,
        "TruthfulQA":78.53,
        "Winogrande":85.24,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alchemonaut\/QuartetAnemoi-70B-t0.0001",
        "Average":76.86,
        "ARC":73.38,
        "HellaSwag":88.9,
        "MMLU":75.42,
        "TruthfulQA":69.53,
        "Winogrande":85.32,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":68.98,
        "Model Sha":25.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/Multiverse-Experiment-slerp-7b",
        "Average":76.82,
        "ARC":72.87,
        "HellaSwag":89.15,
        "MMLU":64.5,
        "TruthfulQA":77.93,
        "Winogrande":84.77,
        "GSM8K":71.72,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"liminerity\/M7-7b",
        "Average":76.82,
        "ARC":72.87,
        "HellaSwag":89.15,
        "MMLU":64.5,
        "TruthfulQA":77.93,
        "Winogrande":84.77,
        "GSM8K":71.72,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AurelPx\/Percival_01-7b-slerp",
        "Average":76.79,
        "ARC":73.21,
        "HellaSwag":89.16,
        "MMLU":64.42,
        "TruthfulQA":77.97,
        "Winogrande":85.08,
        "GSM8K":70.89,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LewisDeBenoisIV\/Jason1903_SLERP",
        "Average":76.77,
        "ARC":73.12,
        "HellaSwag":89.13,
        "MMLU":64.43,
        "TruthfulQA":78.13,
        "Winogrande":85.08,
        "GSM8K":70.74,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Infinimol\/miiqu-f16",
        "Average":76.77,
        "ARC":72.87,
        "HellaSwag":88.97,
        "MMLU":75.99,
        "TruthfulQA":69.37,
        "Winogrande":85.56,
        "GSM8K":67.85,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":90.37,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Asura_v1.1.0",
        "Average":76.75,
        "ARC":73.21,
        "HellaSwag":88.55,
        "MMLU":75.43,
        "TruthfulQA":69.55,
        "Winogrande":85.32,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/T3QM7",
        "Average":76.75,
        "ARC":73.12,
        "HellaSwag":89.14,
        "MMLU":64.48,
        "TruthfulQA":77.96,
        "Winogrande":85.08,
        "GSM8K":70.74,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bardsai\/jaskier-7b-dpo-v7.1",
        "Average":76.74,
        "ARC":73.38,
        "HellaSwag":89.28,
        "MMLU":64.37,
        "TruthfulQA":78.28,
        "Winogrande":85.24,
        "GSM8K":69.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment26-7B",
        "Average":76.74,
        "ARC":73.38,
        "HellaSwag":89.15,
        "MMLU":64.32,
        "TruthfulQA":78.24,
        "Winogrande":84.93,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":71.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"ammarali32\/multi_verse_model",
        "Average":76.74,
        "ARC":72.87,
        "HellaSwag":89.2,
        "MMLU":64.4,
        "TruthfulQA":77.92,
        "Winogrande":84.77,
        "GSM8K":71.27,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MTSAIR\/multi_verse_model",
        "Average":76.74,
        "ARC":72.87,
        "HellaSwag":89.2,
        "MMLU":64.4,
        "TruthfulQA":77.92,
        "Winogrande":84.77,
        "GSM8K":71.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":19.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Maxine-7B-0401-stock",
        "Average":76.73,
        "ARC":73.12,
        "HellaSwag":89.13,
        "MMLU":64.42,
        "TruthfulQA":78.07,
        "Winogrande":85.0,
        "GSM8K":70.66,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/Experiment27Pastiche-7B",
        "Average":76.73,
        "ARC":73.04,
        "HellaSwag":89.08,
        "MMLU":64.2,
        "TruthfulQA":79.31,
        "Winogrande":85.4,
        "GSM8K":69.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cloudyu\/Yi-34Bx2-MoE-60B",
        "Average":76.72,
        "ARC":71.08,
        "HellaSwag":85.23,
        "MMLU":77.47,
        "TruthfulQA":66.19,
        "Winogrande":84.85,
        "GSM8K":75.51,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":59.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/T3QM7XP",
        "Average":76.71,
        "ARC":73.04,
        "HellaSwag":89.12,
        "MMLU":64.45,
        "TruthfulQA":78.06,
        "Winogrande":85.0,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chihoonlee10\/T3Q-Mistral-Orca-Math-DPO",
        "Average":76.7,
        "ARC":72.95,
        "HellaSwag":89.23,
        "MMLU":64.42,
        "TruthfulQA":78.41,
        "Winogrande":84.93,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AurelPx\/Meliodas-7b-dare",
        "Average":76.69,
        "ARC":72.87,
        "HellaSwag":89.11,
        "MMLU":64.43,
        "TruthfulQA":78.02,
        "Winogrande":84.77,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_32-7B-slerp",
        "Average":76.68,
        "ARC":72.95,
        "HellaSwag":89.0,
        "MMLU":64.52,
        "TruthfulQA":77.94,
        "Winogrande":85.0,
        "GSM8K":70.66,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment26-7B",
        "Average":76.67,
        "ARC":73.12,
        "HellaSwag":89.12,
        "MMLU":64.3,
        "TruthfulQA":78.04,
        "Winogrande":85.0,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":71.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MSL7\/INEX12-7b",
        "Average":76.66,
        "ARC":72.95,
        "HellaSwag":89.14,
        "MMLU":64.4,
        "TruthfulQA":78.04,
        "Winogrande":85.24,
        "GSM8K":70.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cloudyu\/Mixtral_34Bx2_MoE_60B",
        "Average":76.66,
        "ARC":71.33,
        "HellaSwag":85.25,
        "MMLU":77.34,
        "TruthfulQA":66.59,
        "Winogrande":84.85,
        "GSM8K":74.6,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":105.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/experiment26-truthy-iter-0",
        "Average":76.65,
        "ARC":73.29,
        "HellaSwag":89.11,
        "MMLU":64.35,
        "TruthfulQA":77.86,
        "Winogrande":84.93,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"NExtNewChattingAI\/Mutliverse_model_official",
        "Average":76.64,
        "ARC":72.87,
        "HellaSwag":89.13,
        "MMLU":64.42,
        "TruthfulQA":77.93,
        "Winogrande":85.08,
        "GSM8K":70.43,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eurdem\/megatron_2.1_MoE_2x7B",
        "Average":76.64,
        "ARC":72.95,
        "HellaSwag":88.94,
        "MMLU":64.56,
        "TruthfulQA":78.2,
        "Winogrande":84.53,
        "GSM8K":70.66,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/shadow-clown-7B-slerp",
        "Average":76.64,
        "ARC":73.38,
        "HellaSwag":89.05,
        "MMLU":64.32,
        "TruthfulQA":77.95,
        "Winogrande":84.85,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/T3QM7X",
        "Average":76.63,
        "ARC":73.12,
        "HellaSwag":89.14,
        "MMLU":64.45,
        "TruthfulQA":78.02,
        "Winogrande":85.08,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cloudyu\/Mixtral_34Bx2_MoE_60B",
        "Average":76.63,
        "ARC":71.25,
        "HellaSwag":85.36,
        "MMLU":77.28,
        "TruthfulQA":66.61,
        "Winogrande":84.69,
        "GSM8K":74.6,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":105.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-2x7b-v6",
        "Average":76.63,
        "ARC":73.38,
        "HellaSwag":89.16,
        "MMLU":64.53,
        "TruthfulQA":78.58,
        "Winogrande":84.77,
        "GSM8K":69.37,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment30-7B",
        "Average":76.62,
        "ARC":73.38,
        "HellaSwag":89.13,
        "MMLU":64.28,
        "TruthfulQA":77.98,
        "Winogrande":84.93,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment28-7B",
        "Average":76.62,
        "ARC":73.04,
        "HellaSwag":89.04,
        "MMLU":64.44,
        "TruthfulQA":78.49,
        "Winogrande":85.4,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Calme-7B-Instruct-v0.2",
        "Average":76.61,
        "ARC":73.12,
        "HellaSwag":89.19,
        "MMLU":64.36,
        "TruthfulQA":78.0,
        "Winogrande":84.93,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/YamShadow-7B",
        "Average":76.6,
        "ARC":72.53,
        "HellaSwag":88.9,
        "MMLU":64.64,
        "TruthfulQA":78.35,
        "Winogrande":85.0,
        "GSM8K":70.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/experiment26-truthy-iter-1",
        "Average":76.6,
        "ARC":73.21,
        "HellaSwag":89.13,
        "MMLU":64.34,
        "TruthfulQA":77.66,
        "Winogrande":84.85,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/yam-jom-7B",
        "Average":76.6,
        "ARC":73.38,
        "HellaSwag":89.15,
        "MMLU":64.51,
        "TruthfulQA":78.04,
        "Winogrande":84.93,
        "GSM8K":69.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Undi95\/Miqu-70B-Alpaca-DPO",
        "Average":76.6,
        "ARC":73.21,
        "HellaSwag":88.6,
        "MMLU":75.41,
        "TruthfulQA":69.44,
        "Winogrande":85.4,
        "GSM8K":67.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":70.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mayacinka\/yam-jom-7B-dare",
        "Average":76.6,
        "ARC":73.38,
        "HellaSwag":89.14,
        "MMLU":64.38,
        "TruthfulQA":78.04,
        "Winogrande":84.85,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralSirKrishna-7b",
        "Average":76.6,
        "ARC":73.72,
        "HellaSwag":89.05,
        "MMLU":64.63,
        "TruthfulQA":75.6,
        "Winogrande":85.32,
        "GSM8K":71.27,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/experiment26-truthy-iter-2",
        "Average":76.6,
        "ARC":73.38,
        "HellaSwag":89.11,
        "MMLU":64.36,
        "TruthfulQA":77.3,
        "Winogrande":85.0,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/AlloyIngotNeoY",
        "Average":76.59,
        "ARC":72.78,
        "HellaSwag":89.12,
        "MMLU":64.32,
        "TruthfulQA":77.99,
        "Winogrande":85.08,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-Merge-Mistral7B",
        "Average":76.59,
        "ARC":72.95,
        "HellaSwag":89.15,
        "MMLU":64.44,
        "TruthfulQA":77.96,
        "Winogrande":85.0,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"152334H\/miqu-1-70b-sf",
        "Average":76.59,
        "ARC":73.04,
        "HellaSwag":88.61,
        "MMLU":75.49,
        "TruthfulQA":69.38,
        "Winogrande":85.32,
        "GSM8K":67.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":68.98,
        "Model Sha":205.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_3.m1",
        "Average":76.59,
        "ARC":74.06,
        "HellaSwag":88.96,
        "MMLU":64.45,
        "TruthfulQA":77.67,
        "Winogrande":85.0,
        "GSM8K":69.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment31-7B",
        "Average":76.58,
        "ARC":73.55,
        "HellaSwag":89.19,
        "MMLU":64.36,
        "TruthfulQA":78.31,
        "Winogrande":85.0,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralArjuna-7B-DT",
        "Average":76.58,
        "ARC":73.12,
        "HellaSwag":88.97,
        "MMLU":64.63,
        "TruthfulQA":76.68,
        "Winogrande":85.24,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment31-7B",
        "Average":76.57,
        "ARC":73.55,
        "HellaSwag":89.14,
        "MMLU":64.29,
        "TruthfulQA":78.43,
        "Winogrande":85.16,
        "GSM8K":68.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment24-7B",
        "Average":76.56,
        "ARC":73.81,
        "HellaSwag":89.06,
        "MMLU":64.34,
        "TruthfulQA":78.54,
        "Winogrande":85.16,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mlabonne\/Zebrafish-7B",
        "Average":76.56,
        "ARC":73.12,
        "HellaSwag":89.13,
        "MMLU":64.36,
        "TruthfulQA":77.92,
        "Winogrande":84.93,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v7.0",
        "Average":76.55,
        "ARC":74.23,
        "HellaSwag":89.37,
        "MMLU":64.54,
        "TruthfulQA":74.26,
        "Winogrande":87.77,
        "GSM8K":69.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":16.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"bobofrut\/ladybird-base-7B-v8",
        "Average":76.55,
        "ARC":73.21,
        "HellaSwag":89.19,
        "MMLU":64.39,
        "TruthfulQA":76.82,
        "Winogrande":85.32,
        "GSM8K":70.36,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/ShadowYamshadow-7B",
        "Average":76.54,
        "ARC":72.7,
        "HellaSwag":88.99,
        "MMLU":64.65,
        "TruthfulQA":78.1,
        "Winogrande":84.85,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-2x7b-v7",
        "Average":76.54,
        "ARC":73.21,
        "HellaSwag":89.05,
        "MMLU":64.63,
        "TruthfulQA":78.34,
        "Winogrande":84.93,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"222limin\/Nexim-7b",
        "Average":76.53,
        "ARC":73.04,
        "HellaSwag":89.1,
        "MMLU":64.48,
        "TruthfulQA":77.68,
        "Winogrande":84.77,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralContamination-7B-ties",
        "Average":76.53,
        "ARC":73.46,
        "HellaSwag":88.9,
        "MMLU":64.76,
        "TruthfulQA":76.71,
        "Winogrande":85.0,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural-Krishna-Multiverse-7b-v3",
        "Average":76.53,
        "ARC":72.87,
        "HellaSwag":89.07,
        "MMLU":64.55,
        "TruthfulQA":77.39,
        "Winogrande":84.93,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment29-7B",
        "Average":76.53,
        "ARC":73.12,
        "HellaSwag":89.06,
        "MMLU":64.49,
        "TruthfulQA":78.72,
        "Winogrande":85.0,
        "GSM8K":68.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/Strangemerges_32Yamshadow-7B",
        "Average":76.53,
        "ARC":72.95,
        "HellaSwag":88.88,
        "MMLU":64.52,
        "TruthfulQA":78.06,
        "Winogrande":84.77,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment30-7B",
        "Average":76.53,
        "ARC":73.46,
        "HellaSwag":89.09,
        "MMLU":64.4,
        "TruthfulQA":77.76,
        "Winogrande":84.85,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"automerger\/NeuralsirkrishnaExperiment26-7B",
        "Average":76.52,
        "ARC":73.89,
        "HellaSwag":89.14,
        "MMLU":64.32,
        "TruthfulQA":77.25,
        "Winogrande":84.85,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_30-7B-slerp",
        "Average":76.52,
        "ARC":74.15,
        "HellaSwag":89.15,
        "MMLU":64.65,
        "TruthfulQA":76.12,
        "Winogrande":84.85,
        "GSM8K":70.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/OgnoExperiment27-7B",
        "Average":76.51,
        "ARC":73.38,
        "HellaSwag":89.4,
        "MMLU":64.43,
        "TruthfulQA":78.41,
        "Winogrande":84.85,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/shadow-clown-7B-dare",
        "Average":76.51,
        "ARC":72.61,
        "HellaSwag":88.86,
        "MMLU":64.44,
        "TruthfulQA":78.33,
        "Winogrande":85.24,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/PasticheInex12-7B",
        "Average":76.51,
        "ARC":73.81,
        "HellaSwag":89.25,
        "MMLU":64.76,
        "TruthfulQA":77.56,
        "Winogrande":85.0,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/pastiche-crown-clown-7b-dare-dpo",
        "Average":76.5,
        "ARC":72.78,
        "HellaSwag":89.15,
        "MMLU":64.51,
        "TruthfulQA":78.8,
        "Winogrande":84.85,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisgrc\/Montebello_7B_SLERP",
        "Average":76.5,
        "ARC":72.95,
        "HellaSwag":89.07,
        "MMLU":64.56,
        "TruthfulQA":79.33,
        "Winogrande":84.77,
        "GSM8K":68.31,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural-Krishna-Multiverse-7b-v2",
        "Average":76.49,
        "ARC":72.95,
        "HellaSwag":89.06,
        "MMLU":64.62,
        "TruthfulQA":77.35,
        "Winogrande":84.69,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MSL7\/INEX16-7b",
        "Average":76.49,
        "ARC":73.12,
        "HellaSwag":89.1,
        "MMLU":64.56,
        "TruthfulQA":77.35,
        "Winogrande":84.45,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Calme-7B-Instruct-v0.1.1",
        "Average":76.49,
        "ARC":72.95,
        "HellaSwag":89.26,
        "MMLU":64.32,
        "TruthfulQA":78.1,
        "Winogrande":85.16,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/UltraMerge-7B",
        "Average":76.49,
        "ARC":73.04,
        "HellaSwag":89.25,
        "MMLU":64.4,
        "TruthfulQA":78.17,
        "Winogrande":84.85,
        "GSM8K":69.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alchemonaut\/BoreanGale-70B",
        "Average":76.48,
        "ARC":73.89,
        "HellaSwag":89.37,
        "MMLU":75.19,
        "TruthfulQA":68.6,
        "Winogrande":84.53,
        "GSM8K":67.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":68.98,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Truthful_DPO_cloudyu_Mixtral_34Bx2_MoE_60B",
        "Average":76.48,
        "ARC":71.25,
        "HellaSwag":85.24,
        "MMLU":77.28,
        "TruthfulQA":66.74,
        "Winogrande":84.29,
        "GSM8K":74.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":60.81,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment27-7B",
        "Average":76.47,
        "ARC":73.55,
        "HellaSwag":89.13,
        "MMLU":64.45,
        "TruthfulQA":78.7,
        "Winogrande":84.93,
        "GSM8K":68.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/pastiche-crown-clown-7b-dare",
        "Average":76.46,
        "ARC":73.81,
        "HellaSwag":89.09,
        "MMLU":64.65,
        "TruthfulQA":76.55,
        "Winogrande":84.85,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/yam-jom-7B-slerp",
        "Average":76.45,
        "ARC":72.7,
        "HellaSwag":89.02,
        "MMLU":64.64,
        "TruthfulQA":77.77,
        "Winogrande":84.69,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b-OH-PREF-DPO",
        "Average":76.45,
        "ARC":73.12,
        "HellaSwag":89.09,
        "MMLU":64.8,
        "TruthfulQA":77.45,
        "Winogrande":84.77,
        "GSM8K":69.45,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/yam-jom-7B-ties",
        "Average":76.44,
        "ARC":73.21,
        "HellaSwag":89.05,
        "MMLU":64.77,
        "TruthfulQA":77.51,
        "Winogrande":84.53,
        "GSM8K":69.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v2",
        "Average":76.44,
        "ARC":73.12,
        "HellaSwag":89.07,
        "MMLU":64.8,
        "TruthfulQA":77.46,
        "Winogrande":84.69,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/ShadowYam-7B",
        "Average":76.44,
        "ARC":73.21,
        "HellaSwag":89.07,
        "MMLU":64.49,
        "TruthfulQA":78.05,
        "Winogrande":84.77,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Yi-34Bx2-MoE-60B-DPO",
        "Average":76.44,
        "ARC":71.25,
        "HellaSwag":85.1,
        "MMLU":77.36,
        "TruthfulQA":66.24,
        "Winogrande":84.77,
        "GSM8K":73.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MSL7\/INEX8-7B",
        "Average":76.44,
        "ARC":73.29,
        "HellaSwag":89.19,
        "MMLU":64.47,
        "TruthfulQA":77.83,
        "Winogrande":84.85,
        "GSM8K":68.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/SmaugDolphin-60B",
        "Average":76.44,
        "ARC":73.38,
        "HellaSwag":86.55,
        "MMLU":76.78,
        "TruthfulQA":67.44,
        "Winogrande":83.5,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chihoonlee10\/T3Q-EN-DPO-Mistral-7B",
        "Average":76.43,
        "ARC":73.04,
        "HellaSwag":89.3,
        "MMLU":64.13,
        "TruthfulQA":78.71,
        "Winogrande":85.32,
        "GSM8K":68.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b",
        "Average":76.43,
        "ARC":73.04,
        "HellaSwag":89.09,
        "MMLU":64.78,
        "TruthfulQA":77.44,
        "Winogrande":84.77,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisgrc\/Marengoli_7B_SLERP",
        "Average":76.42,
        "ARC":73.63,
        "HellaSwag":89.24,
        "MMLU":64.68,
        "TruthfulQA":77.23,
        "Winogrande":85.08,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Ramakrishna-7b-v3",
        "Average":76.42,
        "ARC":73.63,
        "HellaSwag":89.0,
        "MMLU":64.57,
        "TruthfulQA":76.67,
        "Winogrande":84.45,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/AiMaven-Merkaba-7b",
        "Average":76.42,
        "ARC":73.21,
        "HellaSwag":89.03,
        "MMLU":64.53,
        "TruthfulQA":78.3,
        "Winogrande":84.61,
        "GSM8K":68.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"automerger\/Experiment27Neuralsirkrishna-7B",
        "Average":76.41,
        "ARC":73.21,
        "HellaSwag":89.04,
        "MMLU":64.62,
        "TruthfulQA":77.4,
        "Winogrande":84.85,
        "GSM8K":69.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AurelPx\/Pegasus-7b-slerp",
        "Average":76.41,
        "ARC":72.7,
        "HellaSwag":89.05,
        "MMLU":64.47,
        "TruthfulQA":77.13,
        "Winogrande":85.0,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"arcee-ai\/Clown-DPO-Extended",
        "Average":76.41,
        "ARC":73.12,
        "HellaSwag":89.09,
        "MMLU":64.52,
        "TruthfulQA":78.78,
        "Winogrande":84.69,
        "GSM8K":68.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bardsai\/jaskier-7b-dpo-v5.6",
        "Average":76.41,
        "ARC":73.04,
        "HellaSwag":89.0,
        "MMLU":64.38,
        "TruthfulQA":77.81,
        "Winogrande":84.53,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Asura_v2.1",
        "Average":76.41,
        "ARC":72.53,
        "HellaSwag":88.75,
        "MMLU":74.96,
        "TruthfulQA":67.33,
        "Winogrande":85.87,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/Neurotic-Jomainotrik-7b-slerp",
        "Average":76.4,
        "ARC":72.95,
        "HellaSwag":89.15,
        "MMLU":64.28,
        "TruthfulQA":77.64,
        "Winogrande":85.4,
        "GSM8K":68.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment25-7B",
        "Average":76.4,
        "ARC":73.21,
        "HellaSwag":89.01,
        "MMLU":64.45,
        "TruthfulQA":78.49,
        "Winogrande":85.4,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v3",
        "Average":76.4,
        "ARC":73.04,
        "HellaSwag":89.11,
        "MMLU":64.79,
        "TruthfulQA":77.48,
        "Winogrande":84.77,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Kaltsit-16x7B-bf16",
        "Average":76.38,
        "ARC":73.46,
        "HellaSwag":88.92,
        "MMLU":64.62,
        "TruthfulQA":75.63,
        "Winogrande":84.53,
        "GSM8K":71.11,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":91.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/neurotic-crown-clown-7b-tak-stack-dpo",
        "Average":76.38,
        "ARC":72.44,
        "HellaSwag":88.73,
        "MMLU":64.56,
        "TruthfulQA":78.37,
        "Winogrande":83.82,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/MonaTrix-v4",
        "Average":76.38,
        "ARC":73.38,
        "HellaSwag":89.11,
        "MMLU":64.08,
        "TruthfulQA":78.02,
        "Winogrande":84.85,
        "GSM8K":68.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/neurotic-crown-clown-7b-ties",
        "Average":76.38,
        "ARC":72.35,
        "HellaSwag":88.61,
        "MMLU":64.77,
        "TruthfulQA":76.5,
        "Winogrande":84.69,
        "GSM8K":71.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jan-hq\/stealth-v2",
        "Average":76.37,
        "ARC":73.89,
        "HellaSwag":89.26,
        "MMLU":64.94,
        "TruthfulQA":72.47,
        "Winogrande":88.0,
        "GSM8K":69.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/NeuralBeagleJaskier",
        "Average":76.37,
        "ARC":73.21,
        "HellaSwag":89.05,
        "MMLU":64.47,
        "TruthfulQA":77.08,
        "Winogrande":84.37,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralKrishnaMath-7B-slerp",
        "Average":76.37,
        "ARC":73.29,
        "HellaSwag":88.92,
        "MMLU":64.67,
        "TruthfulQA":75.52,
        "Winogrande":84.93,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bardsai\/jaskier-7b-dpo-v6.1",
        "Average":76.36,
        "ARC":73.29,
        "HellaSwag":88.89,
        "MMLU":64.39,
        "TruthfulQA":77.47,
        "Winogrande":84.69,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b-v2",
        "Average":76.35,
        "ARC":72.87,
        "HellaSwag":89.15,
        "MMLU":64.77,
        "TruthfulQA":77.76,
        "Winogrande":84.29,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bardsai\/jaskier-7b-dpo-v4.3",
        "Average":76.35,
        "ARC":72.61,
        "HellaSwag":89.09,
        "MMLU":64.29,
        "TruthfulQA":78.27,
        "Winogrande":84.77,
        "GSM8K":69.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/strange_3236-7B",
        "Average":76.35,
        "ARC":73.21,
        "HellaSwag":88.96,
        "MMLU":64.78,
        "TruthfulQA":77.6,
        "Winogrande":84.77,
        "GSM8K":68.76,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eren23\/ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v4-test",
        "Average":76.34,
        "ARC":73.12,
        "HellaSwag":89.09,
        "MMLU":64.79,
        "TruthfulQA":77.52,
        "Winogrande":84.69,
        "GSM8K":68.84,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chihoonlee10\/T3Q-DPO-Mistral-7B",
        "Average":76.34,
        "ARC":72.78,
        "HellaSwag":89.29,
        "MMLU":64.25,
        "TruthfulQA":78.57,
        "Winogrande":84.93,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/OGNO-7B",
        "Average":76.34,
        "ARC":73.12,
        "HellaSwag":89.0,
        "MMLU":64.59,
        "TruthfulQA":76.52,
        "Winogrande":84.69,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_43-7B-dare_ties",
        "Average":76.33,
        "ARC":73.55,
        "HellaSwag":89.05,
        "MMLU":64.8,
        "TruthfulQA":75.72,
        "Winogrande":84.77,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ammarali32\/MultiVerse_LASER",
        "Average":76.33,
        "ARC":72.53,
        "HellaSwag":88.81,
        "MMLU":64.52,
        "TruthfulQA":77.7,
        "Winogrande":84.93,
        "GSM8K":69.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_25-7B-dare_ties",
        "Average":76.33,
        "ARC":73.46,
        "HellaSwag":88.89,
        "MMLU":64.37,
        "TruthfulQA":76.54,
        "Winogrande":84.29,
        "GSM8K":70.43,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/Omningotex-7b-slerp",
        "Average":76.33,
        "ARC":73.29,
        "HellaSwag":88.96,
        "MMLU":64.69,
        "TruthfulQA":76.32,
        "Winogrande":84.21,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralMergeTest-001",
        "Average":76.32,
        "ARC":73.38,
        "HellaSwag":88.95,
        "MMLU":64.64,
        "TruthfulQA":75.82,
        "Winogrande":85.0,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BuckeyBarnes\/TriFusionNexus-7b",
        "Average":76.32,
        "ARC":72.78,
        "HellaSwag":89.17,
        "MMLU":64.44,
        "TruthfulQA":78.13,
        "Winogrande":84.93,
        "GSM8K":68.46,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AtAndDev\/Ogno-Monarch-Neurotic-7B-Dare-Ties",
        "Average":76.32,
        "ARC":73.21,
        "HellaSwag":88.99,
        "MMLU":64.58,
        "TruthfulQA":77.53,
        "Winogrande":84.53,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eren23\/dpo-binarized-NeutrixOmnibe-7B",
        "Average":76.31,
        "ARC":72.78,
        "HellaSwag":89.05,
        "MMLU":64.6,
        "TruthfulQA":76.9,
        "Winogrande":85.08,
        "GSM8K":69.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_50-7B-slerp",
        "Average":76.31,
        "ARC":73.04,
        "HellaSwag":88.73,
        "MMLU":64.67,
        "TruthfulQA":76.51,
        "Winogrande":84.69,
        "GSM8K":70.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuTrixOmniBe-7B-model-remix",
        "Average":76.3,
        "ARC":72.7,
        "HellaSwag":89.03,
        "MMLU":64.57,
        "TruthfulQA":76.9,
        "Winogrande":85.08,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"yleo\/OgnoMonarch-7B",
        "Average":76.3,
        "ARC":72.61,
        "HellaSwag":88.92,
        "MMLU":64.94,
        "TruthfulQA":77.06,
        "Winogrande":84.21,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Jupiter-k-7B-slerp",
        "Average":76.29,
        "ARC":74.23,
        "HellaSwag":88.82,
        "MMLU":65.01,
        "TruthfulQA":73.96,
        "Winogrande":85.24,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_21-7B-slerp",
        "Average":76.29,
        "ARC":74.23,
        "HellaSwag":88.95,
        "MMLU":65.05,
        "TruthfulQA":73.81,
        "Winogrande":84.61,
        "GSM8K":71.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/Merkaba-Maven-0.1",
        "Average":76.28,
        "ARC":72.87,
        "HellaSwag":89.2,
        "MMLU":64.45,
        "TruthfulQA":77.45,
        "Winogrande":84.93,
        "GSM8K":68.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/crown-clown-7b-slerp",
        "Average":76.27,
        "ARC":73.46,
        "HellaSwag":89.26,
        "MMLU":64.13,
        "TruthfulQA":77.52,
        "Winogrande":84.93,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural-Krishna-Multiverse-7b",
        "Average":76.27,
        "ARC":72.87,
        "HellaSwag":89.06,
        "MMLU":64.72,
        "TruthfulQA":76.75,
        "Winogrande":84.69,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralTrix-bf16",
        "Average":76.26,
        "ARC":72.87,
        "HellaSwag":89.12,
        "MMLU":64.27,
        "TruthfulQA":79.54,
        "Winogrande":84.61,
        "GSM8K":67.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liminerity\/Blur-7b-slerp-v1.46",
        "Average":76.26,
        "ARC":73.29,
        "HellaSwag":89.07,
        "MMLU":64.37,
        "TruthfulQA":76.61,
        "Winogrande":84.53,
        "GSM8K":69.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mlabonne\/Monarch-7B",
        "Average":76.25,
        "ARC":73.04,
        "HellaSwag":89.03,
        "MMLU":64.41,
        "TruthfulQA":77.35,
        "Winogrande":84.61,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_42-7B-dare_ties",
        "Average":76.24,
        "ARC":73.38,
        "HellaSwag":88.96,
        "MMLU":64.62,
        "TruthfulQA":75.44,
        "Winogrande":85.0,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuTrixOmniBe-7B-model-remix",
        "Average":76.24,
        "ARC":72.61,
        "HellaSwag":89.07,
        "MMLU":64.63,
        "TruthfulQA":76.91,
        "Winogrande":85.08,
        "GSM8K":69.14,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-4x7b-v4",
        "Average":76.23,
        "ARC":72.53,
        "HellaSwag":88.85,
        "MMLU":64.53,
        "TruthfulQA":75.3,
        "Winogrande":84.85,
        "GSM8K":71.34,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralTrixlaser-bf16",
        "Average":76.23,
        "ARC":72.18,
        "HellaSwag":89.06,
        "MMLU":64.21,
        "TruthfulQA":78.69,
        "Winogrande":84.77,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"moreh\/MoMo-72B-lora-1.8.4-DPO",
        "Average":76.23,
        "ARC":69.62,
        "HellaSwag":85.35,
        "MMLU":77.33,
        "TruthfulQA":64.64,
        "Winogrande":84.14,
        "GSM8K":76.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"u66u\/NeuralJaskier-7b-dpo",
        "Average":76.22,
        "ARC":71.59,
        "HellaSwag":88.87,
        "MMLU":64.49,
        "TruthfulQA":78.42,
        "Winogrande":84.45,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yleo\/ParrotOgno-7B",
        "Average":76.22,
        "ARC":73.04,
        "HellaSwag":89.03,
        "MMLU":64.51,
        "TruthfulQA":76.53,
        "Winogrande":84.61,
        "GSM8K":69.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/AlloyIngotNeoX",
        "Average":76.21,
        "ARC":74.32,
        "HellaSwag":89.07,
        "MMLU":64.97,
        "TruthfulQA":74.57,
        "Winogrande":84.53,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Wind-Elementals-2x70B",
        "Average":76.21,
        "ARC":73.38,
        "HellaSwag":89.08,
        "MMLU":75.79,
        "TruthfulQA":65.57,
        "Winogrande":84.85,
        "GSM8K":68.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":125.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/DPOB-INMTOB-7B",
        "Average":76.21,
        "ARC":73.21,
        "HellaSwag":89.0,
        "MMLU":64.54,
        "TruthfulQA":76.6,
        "Winogrande":84.69,
        "GSM8K":69.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_24-7B-slerp",
        "Average":76.21,
        "ARC":73.98,
        "HellaSwag":89.09,
        "MMLU":64.99,
        "TruthfulQA":75.52,
        "Winogrande":84.69,
        "GSM8K":68.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/merged-dpo-binarized-NeutrixOmnibe-7B",
        "Average":76.2,
        "ARC":72.7,
        "HellaSwag":89.03,
        "MMLU":64.59,
        "TruthfulQA":76.9,
        "Winogrande":85.08,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/AlloyIngot",
        "Average":76.2,
        "ARC":73.98,
        "HellaSwag":89.05,
        "MMLU":64.83,
        "TruthfulQA":75.12,
        "Winogrande":85.08,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mayacinka\/Buttercup-7b-dpo-ties",
        "Average":76.19,
        "ARC":72.7,
        "HellaSwag":89.09,
        "MMLU":64.5,
        "TruthfulQA":77.17,
        "Winogrande":84.77,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mayacinka\/Buttercup-7b-dpo-slerp",
        "Average":76.19,
        "ARC":72.7,
        "HellaSwag":89.09,
        "MMLU":64.5,
        "TruthfulQA":77.17,
        "Winogrande":84.77,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_26-7B-dare_ties",
        "Average":76.19,
        "ARC":72.95,
        "HellaSwag":89.0,
        "MMLU":64.35,
        "TruthfulQA":76.39,
        "Winogrande":84.45,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Yi-34Bx3-MoE-90B",
        "Average":76.18,
        "ARC":70.9,
        "HellaSwag":85.33,
        "MMLU":77.41,
        "TruthfulQA":66.31,
        "Winogrande":84.29,
        "GSM8K":72.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":87.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralCeptrix-7B-SLERP",
        "Average":76.18,
        "ARC":72.44,
        "HellaSwag":89.3,
        "MMLU":64.5,
        "TruthfulQA":79.13,
        "Winogrande":85.08,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_27-7B-dare_ties",
        "Average":76.17,
        "ARC":73.72,
        "HellaSwag":89.0,
        "MMLU":64.5,
        "TruthfulQA":76.36,
        "Winogrande":84.61,
        "GSM8K":68.84,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_23-7B-slerp",
        "Average":76.17,
        "ARC":73.55,
        "HellaSwag":88.9,
        "MMLU":64.87,
        "TruthfulQA":75.13,
        "Winogrande":84.29,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralMaxime-7B-slerp",
        "Average":76.17,
        "ARC":73.38,
        "HellaSwag":89.18,
        "MMLU":64.44,
        "TruthfulQA":77.79,
        "Winogrande":84.45,
        "GSM8K":67.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eren23\/dpo-binarized-NeuralTrix-7B",
        "Average":76.17,
        "ARC":72.35,
        "HellaSwag":88.89,
        "MMLU":64.09,
        "TruthfulQA":79.07,
        "Winogrande":84.61,
        "GSM8K":68.01,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sumo43\/Yi-32b-x2-v2.0",
        "Average":76.17,
        "ARC":73.04,
        "HellaSwag":85.95,
        "MMLU":76.79,
        "TruthfulQA":73.22,
        "Winogrande":82.79,
        "GSM8K":65.2,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":60.81,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuTrixOmniBe-DPO",
        "Average":76.17,
        "ARC":72.78,
        "HellaSwag":89.03,
        "MMLU":64.28,
        "TruthfulQA":77.21,
        "Winogrande":85.16,
        "GSM8K":68.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_22-7B-slerp",
        "Average":76.16,
        "ARC":73.72,
        "HellaSwag":89.03,
        "MMLU":64.8,
        "TruthfulQA":74.9,
        "Winogrande":84.77,
        "GSM8K":69.75,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_7Bx2_MoE_v0.1",
        "Average":76.16,
        "ARC":74.06,
        "HellaSwag":88.9,
        "MMLU":65.0,
        "TruthfulQA":71.2,
        "Winogrande":87.53,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralTrix-7B-dpo",
        "Average":76.15,
        "ARC":72.27,
        "HellaSwag":88.91,
        "MMLU":64.06,
        "TruthfulQA":79.06,
        "Winogrande":84.61,
        "GSM8K":68.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/MergeCeption-7B-v3",
        "Average":76.15,
        "ARC":72.95,
        "HellaSwag":89.18,
        "MMLU":64.59,
        "TruthfulQA":78.62,
        "Winogrande":85.0,
        "GSM8K":66.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/NeuralMonarch-7B",
        "Average":76.15,
        "ARC":73.21,
        "HellaSwag":89.09,
        "MMLU":64.41,
        "TruthfulQA":77.79,
        "Winogrande":84.61,
        "GSM8K":67.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eren23\/OGNO-7b-dpo-truthful",
        "Average":76.14,
        "ARC":72.95,
        "HellaSwag":89.02,
        "MMLU":64.61,
        "TruthfulQA":76.61,
        "Winogrande":84.69,
        "GSM8K":68.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"moreh\/MoMo-70B-lora-1.8.5-DPO",
        "Average":76.14,
        "ARC":69.54,
        "HellaSwag":85.6,
        "MMLU":77.49,
        "TruthfulQA":65.79,
        "Winogrande":84.14,
        "GSM8K":74.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/MBX-7B-v3-DPO",
        "Average":76.13,
        "ARC":73.55,
        "HellaSwag":89.11,
        "MMLU":64.91,
        "TruthfulQA":74.0,
        "Winogrande":85.56,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuTrixOmniBe-DPO",
        "Average":76.13,
        "ARC":72.95,
        "HellaSwag":89.04,
        "MMLU":64.34,
        "TruthfulQA":77.22,
        "Winogrande":84.93,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralKrishna-7B-v3",
        "Average":76.13,
        "ARC":73.63,
        "HellaSwag":88.91,
        "MMLU":64.45,
        "TruthfulQA":74.11,
        "Winogrande":84.69,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bardsai\/jaskier-7b-dpo-v3.3",
        "Average":76.12,
        "ARC":72.27,
        "HellaSwag":88.89,
        "MMLU":64.34,
        "TruthfulQA":79.0,
        "Winogrande":84.37,
        "GSM8K":67.85,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralMarioMonarch-7B-slerp",
        "Average":76.11,
        "ARC":73.81,
        "HellaSwag":89.04,
        "MMLU":64.61,
        "TruthfulQA":74.97,
        "Winogrande":85.0,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/MonarchLake-7B",
        "Average":76.1,
        "ARC":74.15,
        "HellaSwag":89.29,
        "MMLU":64.44,
        "TruthfulQA":74.97,
        "Winogrande":85.48,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/CarbonBeagle-11B-truthy",
        "Average":76.1,
        "ARC":72.27,
        "HellaSwag":89.31,
        "MMLU":66.55,
        "TruthfulQA":78.55,
        "Winogrande":83.82,
        "GSM8K":66.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_29-7B-dare_ties",
        "Average":76.09,
        "ARC":73.04,
        "HellaSwag":89.04,
        "MMLU":64.29,
        "TruthfulQA":76.98,
        "Winogrande":84.53,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dddsaty\/FusionNet_7Bx2_MoE_Ko_DPO_Adapter_Attach",
        "Average":76.09,
        "ARC":73.89,
        "HellaSwag":88.94,
        "MMLU":65.03,
        "TruthfulQA":71.24,
        "Winogrande":87.61,
        "GSM8K":69.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_53-7B-model_stock",
        "Average":76.07,
        "ARC":72.78,
        "HellaSwag":88.46,
        "MMLU":64.97,
        "TruthfulQA":73.86,
        "Winogrande":83.66,
        "GSM8K":72.71,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Kukedlc\/Fasciculus-Arcuatus-7B-slerp",
        "Average":76.07,
        "ARC":73.55,
        "HellaSwag":88.95,
        "MMLU":64.65,
        "TruthfulQA":72.53,
        "Winogrande":85.71,
        "GSM8K":71.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralExperiment-7b-dare-ties",
        "Average":76.06,
        "ARC":73.63,
        "HellaSwag":88.87,
        "MMLU":64.66,
        "TruthfulQA":74.86,
        "Winogrande":84.45,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/RoleBeagle-11B",
        "Average":76.06,
        "ARC":72.35,
        "HellaSwag":89.77,
        "MMLU":66.35,
        "TruthfulQA":77.92,
        "Winogrande":84.06,
        "GSM8K":65.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Calme-7B-Instruct-v0.5",
        "Average":76.05,
        "ARC":72.87,
        "HellaSwag":88.77,
        "MMLU":64.69,
        "TruthfulQA":73.68,
        "Winogrande":84.37,
        "GSM8K":71.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Capricorn-7B-DPO",
        "Average":76.04,
        "ARC":72.87,
        "HellaSwag":88.47,
        "MMLU":64.29,
        "TruthfulQA":77.23,
        "Winogrande":83.11,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/binarized-ingotrix-slerp-7b",
        "Average":76.04,
        "ARC":73.21,
        "HellaSwag":88.64,
        "MMLU":64.85,
        "TruthfulQA":75.57,
        "Winogrande":82.87,
        "GSM8K":71.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rwitz\/experiment26-SPIN-iter-0",
        "Average":76.04,
        "ARC":72.44,
        "HellaSwag":88.74,
        "MMLU":64.64,
        "TruthfulQA":74.9,
        "Winogrande":85.24,
        "GSM8K":70.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural-4-ARC-7b",
        "Average":76.04,
        "ARC":74.06,
        "HellaSwag":89.05,
        "MMLU":64.93,
        "TruthfulQA":74.12,
        "Winogrande":84.77,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/AlloyIngotNeo",
        "Average":76.02,
        "ARC":72.87,
        "HellaSwag":88.99,
        "MMLU":64.61,
        "TruthfulQA":75.95,
        "Winogrande":84.29,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-4x7b-v5",
        "Average":76.02,
        "ARC":73.89,
        "HellaSwag":89.0,
        "MMLU":64.69,
        "TruthfulQA":73.73,
        "Winogrande":85.08,
        "GSM8K":69.75,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_36-7B-slerp",
        "Average":76.01,
        "ARC":72.61,
        "HellaSwag":88.83,
        "MMLU":64.77,
        "TruthfulQA":77.05,
        "Winogrande":84.29,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/MonaTrix-v6",
        "Average":76.01,
        "ARC":72.78,
        "HellaSwag":88.9,
        "MMLU":64.45,
        "TruthfulQA":77.45,
        "Winogrande":84.61,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Kukedlc\/NeuralKrishna-7B-V2-DPO",
        "Average":76.0,
        "ARC":74.06,
        "HellaSwag":88.97,
        "MMLU":64.41,
        "TruthfulQA":76.19,
        "Winogrande":84.29,
        "GSM8K":68.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/DPOB-NMTOB-7B",
        "Average":76.0,
        "ARC":73.12,
        "HellaSwag":88.95,
        "MMLU":64.7,
        "TruthfulQA":75.08,
        "Winogrande":85.16,
        "GSM8K":68.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralMona_MoE-4x7B",
        "Average":76.0,
        "ARC":73.72,
        "HellaSwag":89.03,
        "MMLU":64.3,
        "TruthfulQA":77.25,
        "Winogrande":84.29,
        "GSM8K":67.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abideen\/AlphaMonarch-laser",
        "Average":76.0,
        "ARC":73.12,
        "HellaSwag":89.21,
        "MMLU":64.43,
        "TruthfulQA":77.9,
        "Winogrande":84.61,
        "GSM8K":66.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralGanesha-7b",
        "Average":75.99,
        "ARC":73.98,
        "HellaSwag":88.85,
        "MMLU":64.41,
        "TruthfulQA":74.14,
        "Winogrande":84.06,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralMona_MoE-4x7B",
        "Average":75.99,
        "ARC":73.89,
        "HellaSwag":89.02,
        "MMLU":64.31,
        "TruthfulQA":77.27,
        "Winogrande":84.06,
        "GSM8K":67.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/AlphaMonarch-7B",
        "Average":75.99,
        "ARC":73.04,
        "HellaSwag":89.18,
        "MMLU":64.4,
        "TruthfulQA":77.91,
        "Winogrande":84.69,
        "GSM8K":66.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":131.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/OmniBeagleSquaredMBX-v3-7B-v2",
        "Average":75.98,
        "ARC":74.06,
        "HellaSwag":88.93,
        "MMLU":64.53,
        "TruthfulQA":72.93,
        "Winogrande":85.56,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/Blur-7b-slerp-v1.41",
        "Average":75.98,
        "ARC":72.78,
        "HellaSwag":88.65,
        "MMLU":64.84,
        "TruthfulQA":74.23,
        "Winogrande":83.9,
        "GSM8K":71.49,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"touqir\/Cyrax-7B",
        "Average":75.98,
        "ARC":72.95,
        "HellaSwag":88.19,
        "MMLU":64.6,
        "TruthfulQA":77.01,
        "Winogrande":83.9,
        "GSM8K":69.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/NMTOB-7B",
        "Average":75.97,
        "ARC":73.04,
        "HellaSwag":88.94,
        "MMLU":64.63,
        "TruthfulQA":75.06,
        "Winogrande":85.16,
        "GSM8K":68.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"flemmingmiguel\/MBX-7B-v3",
        "Average":75.97,
        "ARC":74.15,
        "HellaSwag":88.91,
        "MMLU":65.06,
        "TruthfulQA":71.87,
        "Winogrande":85.56,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Eric111\/UltraCatunaMayo-DPO",
        "Average":75.96,
        "ARC":72.87,
        "HellaSwag":88.75,
        "MMLU":65.18,
        "TruthfulQA":76.44,
        "Winogrande":83.98,
        "GSM8K":68.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/OmniBeagleMBX-v3-7B",
        "Average":75.96,
        "ARC":73.81,
        "HellaSwag":89.07,
        "MMLU":64.66,
        "TruthfulQA":73.52,
        "Winogrande":85.4,
        "GSM8K":69.29,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Maxine-7B-0401-ties",
        "Average":75.96,
        "ARC":71.76,
        "HellaSwag":88.84,
        "MMLU":64.35,
        "TruthfulQA":74.51,
        "Winogrande":83.27,
        "GSM8K":73.01,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bardsai\/jaskier-7b-dpo-v4.1",
        "Average":75.95,
        "ARC":72.95,
        "HellaSwag":89.07,
        "MMLU":64.75,
        "TruthfulQA":75.92,
        "Winogrande":84.69,
        "GSM8K":68.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abideen\/AlphaMonarch-daser",
        "Average":75.94,
        "ARC":73.04,
        "HellaSwag":89.23,
        "MMLU":64.43,
        "TruthfulQA":78.01,
        "Winogrande":84.69,
        "GSM8K":66.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Kukedlc\/NeuralFusion-7b-Dare-Ties",
        "Average":75.94,
        "ARC":73.21,
        "HellaSwag":88.96,
        "MMLU":64.77,
        "TruthfulQA":73.32,
        "Winogrande":85.56,
        "GSM8K":69.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v6.0",
        "Average":75.94,
        "ARC":73.38,
        "HellaSwag":89.02,
        "MMLU":64.61,
        "TruthfulQA":70.45,
        "Winogrande":89.27,
        "GSM8K":68.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment21-7B",
        "Average":75.93,
        "ARC":71.42,
        "HellaSwag":89.03,
        "MMLU":63.92,
        "TruthfulQA":79.79,
        "Winogrande":85.48,
        "GSM8K":65.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/UltraCatunaMayo",
        "Average":75.93,
        "ARC":72.61,
        "HellaSwag":88.37,
        "MMLU":65.03,
        "TruthfulQA":74.06,
        "Winogrande":83.19,
        "GSM8K":72.33,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/NeuralOmniBeagleMBX-v3-7B",
        "Average":75.93,
        "ARC":73.38,
        "HellaSwag":88.91,
        "MMLU":64.99,
        "TruthfulQA":73.1,
        "Winogrande":84.21,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/NeuralTrix-7B-dpo-laser",
        "Average":75.92,
        "ARC":71.33,
        "HellaSwag":88.51,
        "MMLU":63.99,
        "TruthfulQA":78.15,
        "Winogrande":84.45,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_7Bx2_MoE_14B",
        "Average":75.91,
        "ARC":73.55,
        "HellaSwag":88.84,
        "MMLU":64.68,
        "TruthfulQA":69.6,
        "Winogrande":88.16,
        "GSM8K":70.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v0.3",
        "Average":75.91,
        "ARC":76.28,
        "HellaSwag":91.53,
        "MMLU":68.1,
        "TruthfulQA":69.44,
        "Winogrande":87.37,
        "GSM8K":62.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/OmniBeagleSquaredMBX-v3-7B",
        "Average":75.91,
        "ARC":74.4,
        "HellaSwag":88.82,
        "MMLU":65.09,
        "TruthfulQA":72.7,
        "Winogrande":85.24,
        "GSM8K":69.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_40-7B-dare_ties",
        "Average":75.91,
        "ARC":73.04,
        "HellaSwag":88.62,
        "MMLU":64.59,
        "TruthfulQA":77.21,
        "Winogrande":83.98,
        "GSM8K":68.01,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment22-7B",
        "Average":75.9,
        "ARC":71.5,
        "HellaSwag":88.89,
        "MMLU":64.13,
        "TruthfulQA":79.47,
        "Winogrande":84.77,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/MyModelsMerge-7b",
        "Average":75.9,
        "ARC":73.46,
        "HellaSwag":88.59,
        "MMLU":64.39,
        "TruthfulQA":74.47,
        "Winogrande":84.21,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YKM12\/Mistral-7B-summ-privatev1",
        "Average":75.9,
        "ARC":74.15,
        "HellaSwag":88.85,
        "MMLU":64.99,
        "TruthfulQA":71.89,
        "Winogrande":85.32,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Yi-34Bx2-MOE-200K",
        "Average":75.89,
        "ARC":70.48,
        "HellaSwag":84.63,
        "MMLU":76.64,
        "TruthfulQA":68.19,
        "Winogrande":82.72,
        "GSM8K":72.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vicgalleorg\/test1",
        "Average":75.89,
        "ARC":72.27,
        "HellaSwag":89.52,
        "MMLU":66.67,
        "TruthfulQA":78.32,
        "Winogrande":83.9,
        "GSM8K":64.67,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/MiquMaid-v2-2x70B-DPO",
        "Average":75.89,
        "ARC":72.53,
        "HellaSwag":88.36,
        "MMLU":75.31,
        "TruthfulQA":66.5,
        "Winogrande":85.32,
        "GSM8K":67.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":125.35,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Mixtral_7Bx2_MoE_DPO",
        "Average":75.88,
        "ARC":73.04,
        "HellaSwag":88.76,
        "MMLU":64.94,
        "TruthfulQA":81.5,
        "Winogrande":82.16,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/MoNeuTrix-7B-v1",
        "Average":75.87,
        "ARC":72.87,
        "HellaSwag":88.98,
        "MMLU":64.65,
        "TruthfulQA":77.18,
        "Winogrande":84.37,
        "GSM8K":67.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Kukedlc\/Brocae-Area-7B-slerp",
        "Average":75.86,
        "ARC":73.81,
        "HellaSwag":88.98,
        "MMLU":64.55,
        "TruthfulQA":74.13,
        "Winogrande":85.08,
        "GSM8K":68.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_28-7B-dare_ties",
        "Average":75.86,
        "ARC":72.18,
        "HellaSwag":89.08,
        "MMLU":64.68,
        "TruthfulQA":77.55,
        "Winogrande":83.5,
        "GSM8K":68.16,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abideen\/AlphaMonarch-dora",
        "Average":75.86,
        "ARC":73.21,
        "HellaSwag":89.26,
        "MMLU":64.47,
        "TruthfulQA":78.02,
        "Winogrande":84.45,
        "GSM8K":65.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alnrg2arg\/blockchainlabs_joe_bez_seminar",
        "Average":75.85,
        "ARC":73.81,
        "HellaSwag":88.72,
        "MMLU":65.12,
        "TruthfulQA":71.86,
        "Winogrande":85.16,
        "GSM8K":70.43,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/supermario_v4",
        "Average":75.85,
        "ARC":73.46,
        "HellaSwag":88.77,
        "MMLU":65.41,
        "TruthfulQA":72.07,
        "Winogrande":85.24,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SF-Foundation\/TextSum-v0.1",
        "Average":75.84,
        "ARC":72.78,
        "HellaSwag":89.44,
        "MMLU":64.37,
        "TruthfulQA":77.26,
        "Winogrande":84.85,
        "GSM8K":66.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SF-Foundation\/TextBase-v0.1",
        "Average":75.84,
        "ARC":72.78,
        "HellaSwag":89.44,
        "MMLU":64.37,
        "TruthfulQA":77.26,
        "Winogrande":84.85,
        "GSM8K":66.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MSL7\/INEX4-7b",
        "Average":75.84,
        "ARC":72.95,
        "HellaSwag":88.79,
        "MMLU":64.7,
        "TruthfulQA":74.42,
        "Winogrande":83.9,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/NeuralTrix-7B-v1",
        "Average":75.81,
        "ARC":74.15,
        "HellaSwag":89.27,
        "MMLU":64.55,
        "TruthfulQA":74.87,
        "Winogrande":84.93,
        "GSM8K":67.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AiMavenAi\/Prometheus-1.3",
        "Average":75.81,
        "ARC":72.61,
        "HellaSwag":89.02,
        "MMLU":64.26,
        "TruthfulQA":79.29,
        "Winogrande":85.16,
        "GSM8K":64.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Samlagast-7B-bf16",
        "Average":75.81,
        "ARC":73.98,
        "HellaSwag":89.34,
        "MMLU":64.58,
        "TruthfulQA":73.9,
        "Winogrande":85.48,
        "GSM8K":67.55,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralKrishna-7B-slerp",
        "Average":75.79,
        "ARC":73.46,
        "HellaSwag":88.96,
        "MMLU":64.62,
        "TruthfulQA":74.29,
        "Winogrande":83.27,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alnrg2arg\/blockchainlabs_joe_bez_seminar",
        "Average":75.77,
        "ARC":73.98,
        "HellaSwag":88.75,
        "MMLU":65.17,
        "TruthfulQA":71.9,
        "Winogrande":85.24,
        "GSM8K":69.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"yleo\/EmertonMonarch-7B-slerp",
        "Average":75.77,
        "ARC":73.04,
        "HellaSwag":88.94,
        "MMLU":64.44,
        "TruthfulQA":76.55,
        "Winogrande":83.58,
        "GSM8K":68.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ChaoticNeutrals\/Prima-LelantaclesV7-experimental-7b",
        "Average":75.76,
        "ARC":72.87,
        "HellaSwag":88.72,
        "MMLU":64.31,
        "TruthfulQA":74.62,
        "Winogrande":84.77,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Capricorn-7B",
        "Average":75.76,
        "ARC":72.44,
        "HellaSwag":88.41,
        "MMLU":64.9,
        "TruthfulQA":73.76,
        "Winogrande":83.27,
        "GSM8K":71.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v4.0",
        "Average":75.76,
        "ARC":73.04,
        "HellaSwag":88.79,
        "MMLU":64.67,
        "TruthfulQA":68.15,
        "Winogrande":90.92,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/supermario_v3",
        "Average":75.75,
        "ARC":73.81,
        "HellaSwag":88.92,
        "MMLU":65.07,
        "TruthfulQA":72.01,
        "Winogrande":85.48,
        "GSM8K":69.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Cognito-2x7B-bf16",
        "Average":75.74,
        "ARC":72.95,
        "HellaSwag":88.96,
        "MMLU":64.86,
        "TruthfulQA":71.7,
        "Winogrande":85.64,
        "GSM8K":70.36,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YKM11\/Mistral-7B-adaptv1",
        "Average":75.74,
        "ARC":73.98,
        "HellaSwag":89.37,
        "MMLU":64.42,
        "TruthfulQA":74.55,
        "Winogrande":85.48,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yleo\/EmertonMonarch-7B",
        "Average":75.74,
        "ARC":72.7,
        "HellaSwag":89.16,
        "MMLU":64.05,
        "TruthfulQA":78.09,
        "Winogrande":85.16,
        "GSM8K":65.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/OmniCorso-7B",
        "Average":75.74,
        "ARC":72.7,
        "HellaSwag":88.7,
        "MMLU":64.91,
        "TruthfulQA":73.43,
        "Winogrande":83.74,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AiMavenAi\/AiMaven-Prometheus",
        "Average":75.74,
        "ARC":73.98,
        "HellaSwag":88.83,
        "MMLU":65.17,
        "TruthfulQA":72.22,
        "Winogrande":85.16,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Nanashi-2x7B-bf16",
        "Average":75.72,
        "ARC":73.12,
        "HellaSwag":88.76,
        "MMLU":65.04,
        "TruthfulQA":71.31,
        "Winogrande":86.11,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/SuperThetaMaven",
        "Average":75.71,
        "ARC":73.63,
        "HellaSwag":89.0,
        "MMLU":64.82,
        "TruthfulQA":71.77,
        "Winogrande":84.93,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment20-7B",
        "Average":75.71,
        "ARC":73.04,
        "HellaSwag":88.62,
        "MMLU":63.23,
        "TruthfulQA":77.72,
        "Winogrande":85.0,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alnrg2arg\/blockchainlabs_test3_seminar",
        "Average":75.7,
        "ARC":72.18,
        "HellaSwag":88.94,
        "MMLU":64.63,
        "TruthfulQA":72.47,
        "Winogrande":85.64,
        "GSM8K":70.36,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Prima-LelantaclesV6.69-7b",
        "Average":75.7,
        "ARC":72.61,
        "HellaSwag":88.65,
        "MMLU":64.53,
        "TruthfulQA":75.26,
        "Winogrande":84.69,
        "GSM8K":68.46,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Topxtral-4x7B-v0.1",
        "Average":75.68,
        "ARC":72.53,
        "HellaSwag":88.33,
        "MMLU":64.96,
        "TruthfulQA":73.38,
        "Winogrande":83.19,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yleo\/EmertonOmniBeagle-7B-dpo",
        "Average":75.67,
        "ARC":72.7,
        "HellaSwag":88.44,
        "MMLU":64.44,
        "TruthfulQA":75.62,
        "Winogrande":84.29,
        "GSM8K":68.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeoCortex-7B-slerp",
        "Average":75.67,
        "ARC":72.87,
        "HellaSwag":88.68,
        "MMLU":64.71,
        "TruthfulQA":70.43,
        "Winogrande":85.56,
        "GSM8K":71.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rizla\/rizla-17",
        "Average":75.67,
        "ARC":73.63,
        "HellaSwag":89.72,
        "MMLU":64.4,
        "TruthfulQA":76.93,
        "Winogrande":87.85,
        "GSM8K":61.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":15.64,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vishnukv\/WestSeverusJaskier",
        "Average":75.67,
        "ARC":71.76,
        "HellaSwag":88.16,
        "MMLU":64.94,
        "TruthfulQA":73.18,
        "Winogrande":82.87,
        "GSM8K":73.09,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b-v6",
        "Average":75.66,
        "ARC":72.78,
        "HellaSwag":88.77,
        "MMLU":64.74,
        "TruthfulQA":70.89,
        "Winogrande":86.42,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mlabonne\/OmniBeagle-7B",
        "Average":75.66,
        "ARC":72.61,
        "HellaSwag":88.93,
        "MMLU":64.8,
        "TruthfulQA":74.45,
        "Winogrande":83.11,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/NeuralTrix-7B-dpo-relaser",
        "Average":75.66,
        "ARC":71.33,
        "HellaSwag":88.41,
        "MMLU":64.01,
        "TruthfulQA":77.98,
        "Winogrande":84.06,
        "GSM8K":68.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mlabonne\/Beyonder-4x7B-v3",
        "Average":75.65,
        "ARC":71.67,
        "HellaSwag":88.86,
        "MMLU":64.87,
        "TruthfulQA":74.44,
        "Winogrande":83.5,
        "GSM8K":70.58,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":24.15,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YKM11\/Mistral-7B-adaptv0.9",
        "Average":75.65,
        "ARC":73.55,
        "HellaSwag":88.96,
        "MMLU":64.73,
        "TruthfulQA":73.12,
        "Winogrande":85.64,
        "GSM8K":67.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaug-Mixtral-v0.1",
        "Average":75.64,
        "ARC":74.91,
        "HellaSwag":87.79,
        "MMLU":70.08,
        "TruthfulQA":66.88,
        "Winogrande":81.69,
        "GSM8K":72.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/OmniCorso-7B",
        "Average":75.64,
        "ARC":72.44,
        "HellaSwag":88.78,
        "MMLU":65.08,
        "TruthfulQA":73.5,
        "Winogrande":83.5,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"daxiongshu\/Pluto_24B_DPO_63",
        "Average":75.63,
        "ARC":73.98,
        "HellaSwag":88.17,
        "MMLU":64.49,
        "TruthfulQA":79.36,
        "Winogrande":81.69,
        "GSM8K":66.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/merge_7B_state_2",
        "Average":75.58,
        "ARC":73.12,
        "HellaSwag":88.62,
        "MMLU":65.0,
        "TruthfulQA":71.37,
        "Winogrande":83.5,
        "GSM8K":71.87,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralShiva-7B-DT",
        "Average":75.57,
        "ARC":72.7,
        "HellaSwag":88.68,
        "MMLU":64.66,
        "TruthfulQA":74.17,
        "Winogrande":84.14,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/pikus-pikantny-7B-dare",
        "Average":75.56,
        "ARC":72.18,
        "HellaSwag":88.56,
        "MMLU":65.0,
        "TruthfulQA":73.29,
        "Winogrande":83.43,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kaitchup\/Mayonnaise-4in1-022",
        "Average":75.56,
        "ARC":72.87,
        "HellaSwag":88.63,
        "MMLU":64.93,
        "TruthfulQA":71.73,
        "Winogrande":84.69,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"NeuralNovel\/Confinus-2x7B",
        "Average":75.55,
        "ARC":73.89,
        "HellaSwag":88.82,
        "MMLU":65.12,
        "TruthfulQA":71.88,
        "Winogrande":84.77,
        "GSM8K":68.84,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_20-7B-slerp",
        "Average":75.52,
        "ARC":73.12,
        "HellaSwag":88.45,
        "MMLU":65.06,
        "TruthfulQA":70.9,
        "Winogrande":83.43,
        "GSM8K":72.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/OrcaHermes-Mistral-70B-miqu",
        "Average":75.51,
        "ARC":71.33,
        "HellaSwag":87.78,
        "MMLU":75.47,
        "TruthfulQA":60.72,
        "Winogrande":84.53,
        "GSM8K":73.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_44-7B-dare_ties",
        "Average":75.51,
        "ARC":71.76,
        "HellaSwag":87.84,
        "MMLU":65.61,
        "TruthfulQA":71.85,
        "Winogrande":83.74,
        "GSM8K":72.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/bruphin-lambda",
        "Average":75.5,
        "ARC":72.35,
        "HellaSwag":88.22,
        "MMLU":64.9,
        "TruthfulQA":72.36,
        "Winogrande":84.45,
        "GSM8K":70.74,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_49-7B-dare_ties",
        "Average":75.5,
        "ARC":72.35,
        "HellaSwag":88.3,
        "MMLU":64.31,
        "TruthfulQA":74.7,
        "Winogrande":83.74,
        "GSM8K":69.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaug-Mixtral-v0.1",
        "Average":75.49,
        "ARC":74.66,
        "HellaSwag":87.72,
        "MMLU":70.06,
        "TruthfulQA":66.95,
        "Winogrande":81.61,
        "GSM8K":71.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/supermario_v2",
        "Average":75.49,
        "ARC":72.95,
        "HellaSwag":88.53,
        "MMLU":64.99,
        "TruthfulQA":71.22,
        "Winogrande":83.9,
        "GSM8K":71.34,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-34B-ties",
        "Average":75.48,
        "ARC":70.99,
        "HellaSwag":84.83,
        "MMLU":76.63,
        "TruthfulQA":70.32,
        "Winogrande":82.64,
        "GSM8K":67.48,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Phoenix_DPO_60B",
        "Average":75.48,
        "ARC":71.16,
        "HellaSwag":85.46,
        "MMLU":77.66,
        "TruthfulQA":63.84,
        "Winogrande":84.93,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-orca-dpo-2h",
        "Average":75.48,
        "ARC":73.12,
        "HellaSwag":88.65,
        "MMLU":64.99,
        "TruthfulQA":71.31,
        "Winogrande":84.21,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Helion-4x34B",
        "Average":75.48,
        "ARC":69.71,
        "HellaSwag":85.28,
        "MMLU":77.33,
        "TruthfulQA":63.91,
        "Winogrande":84.37,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":113.66,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Paradigm_7B",
        "Average":75.47,
        "ARC":73.63,
        "HellaSwag":88.66,
        "MMLU":64.02,
        "TruthfulQA":75.19,
        "Winogrande":84.53,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b-v4",
        "Average":75.47,
        "ARC":72.53,
        "HellaSwag":88.77,
        "MMLU":64.85,
        "TruthfulQA":70.74,
        "Winogrande":86.27,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-34BeagleSimpleMath-32K-v1",
        "Average":75.45,
        "ARC":74.15,
        "HellaSwag":85.98,
        "MMLU":76.52,
        "TruthfulQA":73.74,
        "Winogrande":83.27,
        "GSM8K":59.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ShinojiResearch\/Senku-70B-Full",
        "Average":75.44,
        "ARC":71.5,
        "HellaSwag":87.88,
        "MMLU":75.2,
        "TruthfulQA":61.96,
        "Winogrande":84.77,
        "GSM8K":71.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc0-1.0",
        "Available on the Hub":68.98,
        "Model Sha":134.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-sumz-dpo-3h",
        "Average":75.43,
        "ARC":73.04,
        "HellaSwag":88.67,
        "MMLU":64.78,
        "TruthfulQA":71.53,
        "Winogrande":84.21,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-orca-dpo-4h",
        "Average":75.42,
        "ARC":73.38,
        "HellaSwag":88.73,
        "MMLU":64.97,
        "TruthfulQA":71.65,
        "Winogrande":84.29,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/SeverusWestLake-7B-DPO",
        "Average":75.42,
        "ARC":72.18,
        "HellaSwag":88.94,
        "MMLU":64.65,
        "TruthfulQA":71.49,
        "Winogrande":86.11,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"one-man-army\/UNA-34Beagles-32K-bf16-v1",
        "Average":75.41,
        "ARC":73.55,
        "HellaSwag":85.93,
        "MMLU":76.45,
        "TruthfulQA":73.55,
        "Winogrande":82.95,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-34Beagles-32K-v1",
        "Average":75.41,
        "ARC":73.55,
        "HellaSwag":85.93,
        "MMLU":76.45,
        "TruthfulQA":73.55,
        "Winogrande":82.95,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-spef",
        "Average":75.41,
        "ARC":73.21,
        "HellaSwag":88.68,
        "MMLU":64.9,
        "TruthfulQA":71.91,
        "Winogrande":84.85,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-spnf",
        "Average":75.41,
        "ARC":73.04,
        "HellaSwag":88.67,
        "MMLU":64.91,
        "TruthfulQA":71.85,
        "Winogrande":84.77,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Scorpio-7B",
        "Average":75.4,
        "ARC":71.33,
        "HellaSwag":88.5,
        "MMLU":64.7,
        "TruthfulQA":72.51,
        "Winogrande":83.5,
        "GSM8K":71.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/ConfigurableBeagle-11B",
        "Average":75.4,
        "ARC":72.53,
        "HellaSwag":88.85,
        "MMLU":66.71,
        "TruthfulQA":77.13,
        "Winogrande":83.27,
        "GSM8K":63.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Cosmosis-3x34B",
        "Average":75.39,
        "ARC":69.71,
        "HellaSwag":85.18,
        "MMLU":77.25,
        "TruthfulQA":63.82,
        "Winogrande":84.14,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":87.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-privatemix-ia1",
        "Average":75.39,
        "ARC":72.78,
        "HellaSwag":88.59,
        "MMLU":64.5,
        "TruthfulQA":71.79,
        "Winogrande":85.08,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Nitral-AI\/Lelanta-lake-7b",
        "Average":75.39,
        "ARC":72.27,
        "HellaSwag":88.95,
        "MMLU":64.31,
        "TruthfulQA":73.05,
        "Winogrande":84.61,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MoEv4Config-TestWeightedTIES-7b",
        "Average":75.39,
        "ARC":71.59,
        "HellaSwag":88.19,
        "MMLU":65.07,
        "TruthfulQA":70.87,
        "Winogrande":83.82,
        "GSM8K":72.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yleo\/EmertonBeagle-7B-dpo",
        "Average":75.39,
        "ARC":72.78,
        "HellaSwag":89.12,
        "MMLU":64.47,
        "TruthfulQA":75.96,
        "Winogrande":83.58,
        "GSM8K":66.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"shadowml\/BeagSake-7B",
        "Average":75.38,
        "ARC":72.44,
        "HellaSwag":88.39,
        "MMLU":65.23,
        "TruthfulQA":72.27,
        "Winogrande":82.16,
        "GSM8K":71.8,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Eris_PrimeV3.05-Vision-7B",
        "Average":75.37,
        "ARC":72.78,
        "HellaSwag":88.48,
        "MMLU":65.09,
        "TruthfulQA":72.76,
        "Winogrande":83.66,
        "GSM8K":69.45,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/WestLake-7B-v2-laser-truthy-dpo",
        "Average":75.37,
        "ARC":73.89,
        "HellaSwag":88.85,
        "MMLU":64.84,
        "TruthfulQA":69.81,
        "Winogrande":86.66,
        "GSM8K":68.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":21.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Azathoth-16x7B-bf16",
        "Average":75.36,
        "ARC":73.81,
        "HellaSwag":88.87,
        "MMLU":64.6,
        "TruthfulQA":69.61,
        "Winogrande":85.48,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":91.8,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/RandomMergeNoNormWEIGHTED-7B-DARETIES",
        "Average":75.36,
        "ARC":73.38,
        "HellaSwag":88.5,
        "MMLU":64.94,
        "TruthfulQA":71.5,
        "Winogrande":83.58,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment19-7B",
        "Average":75.36,
        "ARC":72.35,
        "HellaSwag":88.61,
        "MMLU":63.08,
        "TruthfulQA":78.18,
        "Winogrande":84.53,
        "GSM8K":65.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ShinojiResearch\/Senku-70B-Full",
        "Average":75.36,
        "ARC":71.33,
        "HellaSwag":87.86,
        "MMLU":75.14,
        "TruthfulQA":61.95,
        "Winogrande":84.53,
        "GSM8K":71.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc0-1.0",
        "Available on the Hub":68.98,
        "Model Sha":134.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnowMee\/Mistral-7b-instruct-v0.2-summ-dpo-ed2",
        "Average":75.34,
        "ARC":74.4,
        "HellaSwag":89.29,
        "MMLU":64.23,
        "TruthfulQA":72.34,
        "Winogrande":84.14,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnowMee\/Mistral-7b-instruct-v0.2-summ-dpo-ed3",
        "Average":75.34,
        "ARC":74.23,
        "HellaSwag":89.28,
        "MMLU":64.37,
        "TruthfulQA":72.31,
        "Winogrande":84.37,
        "GSM8K":67.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment23-7B",
        "Average":75.31,
        "ARC":72.35,
        "HellaSwag":88.77,
        "MMLU":64.17,
        "TruthfulQA":78.87,
        "Winogrande":85.32,
        "GSM8K":62.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural4gsm8k",
        "Average":75.31,
        "ARC":72.27,
        "HellaSwag":88.45,
        "MMLU":64.76,
        "TruthfulQA":69.65,
        "Winogrande":83.35,
        "GSM8K":73.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-4x7b-v3",
        "Average":75.31,
        "ARC":74.4,
        "HellaSwag":88.62,
        "MMLU":64.82,
        "TruthfulQA":70.78,
        "Winogrande":85.0,
        "GSM8K":68.23,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/Wernicke-7B-dpo",
        "Average":75.31,
        "ARC":71.84,
        "HellaSwag":88.63,
        "MMLU":65.22,
        "TruthfulQA":73.91,
        "Winogrande":84.61,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-v0.2",
        "Average":75.3,
        "ARC":73.81,
        "HellaSwag":88.65,
        "MMLU":64.76,
        "TruthfulQA":69.79,
        "Winogrande":84.29,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-sumz-dpo-4h",
        "Average":75.3,
        "ARC":72.95,
        "HellaSwag":88.81,
        "MMLU":64.8,
        "TruthfulQA":71.74,
        "Winogrande":83.98,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/kiqu-70b",
        "Average":75.29,
        "ARC":72.1,
        "HellaSwag":87.94,
        "MMLU":74.93,
        "TruthfulQA":63.48,
        "Winogrande":84.85,
        "GSM8K":68.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":68.98,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/WestSeverus-7B-DPO-v2",
        "Average":75.29,
        "ARC":71.42,
        "HellaSwag":88.27,
        "MMLU":64.79,
        "TruthfulQA":72.37,
        "Winogrande":83.27,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-70B-v1.6",
        "Average":75.29,
        "ARC":71.33,
        "HellaSwag":87.06,
        "MMLU":74.76,
        "TruthfulQA":63.8,
        "Winogrande":83.98,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-v0.21",
        "Average":75.29,
        "ARC":73.98,
        "HellaSwag":88.61,
        "MMLU":64.81,
        "TruthfulQA":69.76,
        "Winogrande":84.29,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/WildMarcoroni-Variant1-7B",
        "Average":75.29,
        "ARC":73.98,
        "HellaSwag":88.61,
        "MMLU":64.81,
        "TruthfulQA":69.76,
        "Winogrande":84.29,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test3_sft_16bit",
        "Average":75.28,
        "ARC":73.55,
        "HellaSwag":88.87,
        "MMLU":64.63,
        "TruthfulQA":69.77,
        "Winogrande":84.45,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/blockchainlabs_7B_merged_test2_4",
        "Average":75.28,
        "ARC":73.55,
        "HellaSwag":88.87,
        "MMLU":64.63,
        "TruthfulQA":69.77,
        "Winogrande":84.45,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test2_4",
        "Average":75.28,
        "ARC":73.55,
        "HellaSwag":88.87,
        "MMLU":64.63,
        "TruthfulQA":69.77,
        "Winogrande":84.45,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e2",
        "Average":75.28,
        "ARC":73.81,
        "HellaSwag":88.85,
        "MMLU":64.61,
        "TruthfulQA":72.14,
        "Winogrande":83.27,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kquant03\/Buttercup-V2-bf16",
        "Average":75.26,
        "ARC":73.72,
        "HellaSwag":88.54,
        "MMLU":64.68,
        "TruthfulQA":69.47,
        "Winogrande":86.5,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AbacusResearch\/haLLawa4-7b",
        "Average":75.25,
        "ARC":71.5,
        "HellaSwag":88.36,
        "MMLU":64.49,
        "TruthfulQA":74.27,
        "Winogrande":82.4,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Faraday-7B",
        "Average":75.25,
        "ARC":72.27,
        "HellaSwag":88.9,
        "MMLU":64.69,
        "TruthfulQA":73.07,
        "Winogrande":85.32,
        "GSM8K":67.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Astralis-4x34B",
        "Average":75.24,
        "ARC":69.71,
        "HellaSwag":85.17,
        "MMLU":77.24,
        "TruthfulQA":63.55,
        "Winogrande":84.14,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":113.66,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"flemmingmiguel\/MBX-7B-v2",
        "Average":75.24,
        "ARC":73.55,
        "HellaSwag":88.5,
        "MMLU":64.78,
        "TruthfulQA":70.21,
        "Winogrande":83.9,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e1",
        "Average":75.24,
        "ARC":73.98,
        "HellaSwag":89.27,
        "MMLU":64.16,
        "TruthfulQA":72.79,
        "Winogrande":84.45,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Bagel-Hermes-34B-Slerp",
        "Average":75.24,
        "ARC":70.73,
        "HellaSwag":85.68,
        "MMLU":77.29,
        "TruthfulQA":67.09,
        "Winogrande":84.37,
        "GSM8K":66.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/WestMonarchLasers-7B-slerp",
        "Average":75.23,
        "ARC":72.44,
        "HellaSwag":88.66,
        "MMLU":64.73,
        "TruthfulQA":72.4,
        "Winogrande":85.56,
        "GSM8K":67.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Mistral-7B-Instruct-exp-e2",
        "Average":75.23,
        "ARC":72.53,
        "HellaSwag":88.5,
        "MMLU":65.0,
        "TruthfulQA":71.26,
        "Winogrande":83.9,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-v0.23",
        "Average":75.23,
        "ARC":72.53,
        "HellaSwag":88.5,
        "MMLU":65.0,
        "TruthfulQA":71.26,
        "Winogrande":83.9,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-v0.22",
        "Average":75.23,
        "ARC":72.53,
        "HellaSwag":88.5,
        "MMLU":65.0,
        "TruthfulQA":71.26,
        "Winogrande":83.9,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-v0.21",
        "Average":75.23,
        "ARC":72.53,
        "HellaSwag":88.5,
        "MMLU":65.0,
        "TruthfulQA":71.26,
        "Winogrande":83.9,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnowMee\/Mistral-7b-instruct-v0.2-summ-sft-dpo-ed2",
        "Average":75.23,
        "ARC":74.06,
        "HellaSwag":89.25,
        "MMLU":64.25,
        "TruthfulQA":72.73,
        "Winogrande":84.69,
        "GSM8K":66.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Faraday-7B",
        "Average":75.22,
        "ARC":72.44,
        "HellaSwag":88.91,
        "MMLU":64.68,
        "TruthfulQA":73.03,
        "Winogrande":85.56,
        "GSM8K":66.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-sumz-dpo-5h",
        "Average":75.22,
        "ARC":72.7,
        "HellaSwag":88.99,
        "MMLU":64.78,
        "TruthfulQA":72.36,
        "Winogrande":83.9,
        "GSM8K":68.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"shadowml\/WestBeagle-7B",
        "Average":75.22,
        "ARC":72.27,
        "HellaSwag":88.29,
        "MMLU":65.17,
        "TruthfulQA":71.71,
        "Winogrande":82.0,
        "GSM8K":71.87,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/Wernicke-7B-v8",
        "Average":75.21,
        "ARC":72.44,
        "HellaSwag":88.7,
        "MMLU":64.62,
        "TruthfulQA":71.3,
        "Winogrande":84.85,
        "GSM8K":69.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kaitchup\/Mayonnaise-4in1-02",
        "Average":75.21,
        "ARC":73.38,
        "HellaSwag":88.51,
        "MMLU":64.89,
        "TruthfulQA":69.04,
        "Winogrande":84.37,
        "GSM8K":71.04,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v2.0",
        "Average":75.2,
        "ARC":73.38,
        "HellaSwag":88.81,
        "MMLU":64.65,
        "TruthfulQA":69.76,
        "Winogrande":83.82,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnowMee\/Mistral-7b-instruct-v0.2-summ-sft-dpo-ed3",
        "Average":75.2,
        "ARC":73.98,
        "HellaSwag":89.26,
        "MMLU":64.28,
        "TruthfulQA":72.76,
        "Winogrande":84.69,
        "GSM8K":66.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/TurdusTrixBeagle-DARETIES-7B",
        "Average":75.2,
        "ARC":73.46,
        "HellaSwag":88.61,
        "MMLU":64.89,
        "TruthfulQA":68.81,
        "Winogrande":85.16,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kaitchup\/Mayonnaise-4in1-01",
        "Average":75.19,
        "ARC":73.46,
        "HellaSwag":88.47,
        "MMLU":64.95,
        "TruthfulQA":69.18,
        "Winogrande":84.14,
        "GSM8K":70.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/CombinaTrix-7B",
        "Average":75.19,
        "ARC":72.87,
        "HellaSwag":88.4,
        "MMLU":64.85,
        "TruthfulQA":70.63,
        "Winogrande":84.14,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eric111\/CatunaMayo-DPO",
        "Average":75.19,
        "ARC":72.87,
        "HellaSwag":88.3,
        "MMLU":65.24,
        "TruthfulQA":71.82,
        "Winogrande":82.72,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen10-mistral-7B",
        "Average":75.19,
        "ARC":71.76,
        "HellaSwag":88.27,
        "MMLU":64.75,
        "TruthfulQA":72.23,
        "Winogrande":82.72,
        "GSM8K":71.42,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/Wernicke-7B-v9",
        "Average":75.18,
        "ARC":72.44,
        "HellaSwag":88.54,
        "MMLU":64.9,
        "TruthfulQA":71.86,
        "Winogrande":84.06,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/Severusectum-7B-DPO",
        "Average":75.18,
        "ARC":71.5,
        "HellaSwag":88.55,
        "MMLU":64.79,
        "TruthfulQA":72.45,
        "Winogrande":83.27,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PetroGPT\/WestSeverus-7B-DPO",
        "Average":75.17,
        "ARC":70.73,
        "HellaSwag":88.01,
        "MMLU":64.93,
        "TruthfulQA":70.53,
        "Winogrande":83.5,
        "GSM8K":73.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"udkai\/Garrulus",
        "Average":75.16,
        "ARC":73.29,
        "HellaSwag":88.87,
        "MMLU":64.57,
        "TruthfulQA":68.23,
        "Winogrande":91.48,
        "GSM8K":64.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/Wernicke-7B-v1",
        "Average":75.15,
        "ARC":73.21,
        "HellaSwag":88.48,
        "MMLU":64.95,
        "TruthfulQA":70.95,
        "Winogrande":83.74,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/HermesBagel-34B-v0.1",
        "Average":75.15,
        "ARC":70.56,
        "HellaSwag":85.74,
        "MMLU":77.38,
        "TruthfulQA":67.34,
        "Winogrande":84.61,
        "GSM8K":65.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/TurdusBeagle-7B",
        "Average":75.15,
        "ARC":73.63,
        "HellaSwag":88.89,
        "MMLU":64.7,
        "TruthfulQA":69.71,
        "Winogrande":83.9,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jambroz\/sixtyoneeighty-FNCARL-7B-slerp",
        "Average":75.14,
        "ARC":71.59,
        "HellaSwag":87.78,
        "MMLU":65.27,
        "TruthfulQA":71.52,
        "Winogrande":83.19,
        "GSM8K":71.49,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-orca-dpo-8h",
        "Average":75.14,
        "ARC":72.44,
        "HellaSwag":88.99,
        "MMLU":64.59,
        "TruthfulQA":72.96,
        "Winogrande":84.45,
        "GSM8K":67.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Sectumsempra-7B-DPO",
        "Average":75.14,
        "ARC":71.5,
        "HellaSwag":88.7,
        "MMLU":64.9,
        "TruthfulQA":72.49,
        "Winogrande":83.19,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-S5-v0.1",
        "Average":75.14,
        "ARC":72.53,
        "HellaSwag":88.71,
        "MMLU":65.01,
        "TruthfulQA":67.58,
        "Winogrande":86.19,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/OmniTrixAI",
        "Average":75.13,
        "ARC":72.95,
        "HellaSwag":88.52,
        "MMLU":65.12,
        "TruthfulQA":70.12,
        "Winogrande":83.58,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_6-7B-dare_ties",
        "Average":75.12,
        "ARC":73.04,
        "HellaSwag":88.82,
        "MMLU":64.52,
        "TruthfulQA":72.0,
        "Winogrande":85.71,
        "GSM8K":66.64,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/MiquMaid-v1-70B",
        "Average":75.12,
        "ARC":71.67,
        "HellaSwag":87.96,
        "MMLU":74.9,
        "TruthfulQA":61.79,
        "Winogrande":85.08,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":70.0,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/SevereNeuralBeagleTrix-7B",
        "Average":75.12,
        "ARC":72.78,
        "HellaSwag":88.33,
        "MMLU":65.09,
        "TruthfulQA":69.02,
        "Winogrande":83.82,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-7B-0211-ties",
        "Average":75.11,
        "ARC":71.42,
        "HellaSwag":88.86,
        "MMLU":63.91,
        "TruthfulQA":71.46,
        "Winogrande":84.37,
        "GSM8K":70.66,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/MarcBeagle-7B",
        "Average":75.11,
        "ARC":73.12,
        "HellaSwag":88.43,
        "MMLU":64.92,
        "TruthfulQA":69.18,
        "Winogrande":83.82,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eren23\/slerp-test-turdus-beagle",
        "Average":75.11,
        "ARC":73.55,
        "HellaSwag":88.85,
        "MMLU":64.62,
        "TruthfulQA":69.69,
        "Winogrande":83.9,
        "GSM8K":70.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Direct-sm-private-e1",
        "Average":75.1,
        "ARC":72.53,
        "HellaSwag":88.98,
        "MMLU":64.55,
        "TruthfulQA":72.81,
        "Winogrande":83.82,
        "GSM8K":67.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Mistral-7b-instruct-v0.2-private-eds2",
        "Average":75.1,
        "ARC":72.7,
        "HellaSwag":89.05,
        "MMLU":64.21,
        "TruthfulQA":73.88,
        "Winogrande":83.98,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xDAN2099\/xDAN-L2-moe-2x-v1",
        "Average":75.1,
        "ARC":68.52,
        "HellaSwag":86.31,
        "MMLU":76.76,
        "TruthfulQA":61.77,
        "Winogrande":84.29,
        "GSM8K":72.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":60.81,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Bagel-Hermes-2x34B",
        "Average":75.1,
        "ARC":69.8,
        "HellaSwag":85.26,
        "MMLU":77.24,
        "TruthfulQA":64.82,
        "Winogrande":84.77,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/WildMBXMarconi-SLERP-7B",
        "Average":75.09,
        "ARC":73.29,
        "HellaSwag":88.49,
        "MMLU":64.9,
        "TruthfulQA":68.98,
        "Winogrande":83.98,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v5.0",
        "Average":75.08,
        "ARC":73.63,
        "HellaSwag":88.93,
        "MMLU":64.65,
        "TruthfulQA":69.83,
        "Winogrande":83.98,
        "GSM8K":69.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Samlagast-7B-laser-bf16",
        "Average":75.06,
        "ARC":72.87,
        "HellaSwag":88.96,
        "MMLU":64.35,
        "TruthfulQA":73.16,
        "Winogrande":85.4,
        "GSM8K":65.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AbacusResearch\/jaLLAbi2-7b",
        "Average":75.06,
        "ARC":71.67,
        "HellaSwag":88.29,
        "MMLU":64.92,
        "TruthfulQA":70.16,
        "Winogrande":83.35,
        "GSM8K":71.95,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen5-mistral-7B",
        "Average":75.05,
        "ARC":72.01,
        "HellaSwag":88.47,
        "MMLU":64.95,
        "TruthfulQA":72.17,
        "Winogrande":82.87,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarryFutureman\/WestLakeX-7B-EvoMerge-Variant2",
        "Average":75.04,
        "ARC":72.53,
        "HellaSwag":88.52,
        "MMLU":64.77,
        "TruthfulQA":70.35,
        "Winogrande":85.79,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Cygnus-7B",
        "Average":75.04,
        "ARC":70.9,
        "HellaSwag":87.82,
        "MMLU":63.81,
        "TruthfulQA":72.61,
        "Winogrande":81.93,
        "GSM8K":73.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/merge_7B_state_1",
        "Average":75.04,
        "ARC":73.81,
        "HellaSwag":88.57,
        "MMLU":64.87,
        "TruthfulQA":69.11,
        "Winogrande":83.9,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/MBX-7B",
        "Average":75.04,
        "ARC":72.87,
        "HellaSwag":88.38,
        "MMLU":64.93,
        "TruthfulQA":69.11,
        "Winogrande":83.66,
        "GSM8K":71.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v1.1",
        "Average":75.03,
        "ARC":78.24,
        "HellaSwag":89.68,
        "MMLU":68.08,
        "TruthfulQA":80.88,
        "Winogrande":86.5,
        "GSM8K":46.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"4season\/alignment-model-test3",
        "Average":75.03,
        "ARC":78.24,
        "HellaSwag":89.68,
        "MMLU":68.08,
        "TruthfulQA":80.88,
        "Winogrande":86.5,
        "GSM8K":46.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sumo43\/Yi-34b-x2",
        "Average":75.02,
        "ARC":72.87,
        "HellaSwag":85.7,
        "MMLU":76.64,
        "TruthfulQA":72.1,
        "Winogrande":82.79,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/ChatMarc-YesAnotherMerge-7B",
        "Average":75.02,
        "ARC":72.78,
        "HellaSwag":88.39,
        "MMLU":65.01,
        "TruthfulQA":70.04,
        "Winogrande":83.9,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b-v5",
        "Average":75.01,
        "ARC":72.18,
        "HellaSwag":88.42,
        "MMLU":65.06,
        "TruthfulQA":70.37,
        "Winogrande":86.03,
        "GSM8K":68.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-Instruct-v1.0",
        "Average":74.99,
        "ARC":74.06,
        "HellaSwag":88.25,
        "MMLU":64.25,
        "TruthfulQA":69.61,
        "Winogrande":84.29,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"alnrg2arg\/test3_sft_16bit_dpo2",
        "Average":74.98,
        "ARC":73.63,
        "HellaSwag":89.03,
        "MMLU":64.63,
        "TruthfulQA":70.71,
        "Winogrande":84.37,
        "GSM8K":67.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/WONMSeverusDevil-TIES-7B",
        "Average":74.97,
        "ARC":72.95,
        "HellaSwag":88.45,
        "MMLU":64.77,
        "TruthfulQA":72.0,
        "Winogrande":83.43,
        "GSM8K":68.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andrijdavid\/Macaroni-7b-Tied",
        "Average":74.96,
        "ARC":72.87,
        "HellaSwag":88.14,
        "MMLU":64.73,
        "TruthfulQA":70.54,
        "Winogrande":81.93,
        "GSM8K":71.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-T-v0.1",
        "Average":74.96,
        "ARC":73.63,
        "HellaSwag":88.85,
        "MMLU":64.22,
        "TruthfulQA":70.78,
        "Winogrande":85.79,
        "GSM8K":66.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LewisDeBenoisIV\/BillyTheKid1803",
        "Average":74.96,
        "ARC":71.84,
        "HellaSwag":88.09,
        "MMLU":65.07,
        "TruthfulQA":72.16,
        "Winogrande":82.32,
        "GSM8K":70.28,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saltlux\/luxia-21.4b-alignment-v1.1",
        "Average":74.96,
        "ARC":78.24,
        "HellaSwag":89.69,
        "MMLU":68.22,
        "TruthfulQA":80.91,
        "Winogrande":86.66,
        "GSM8K":46.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":21.42,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ycros\/BagelMIsteryTour-v2-8x7B",
        "Average":74.95,
        "ARC":72.7,
        "HellaSwag":87.36,
        "MMLU":71.16,
        "TruthfulQA":74.54,
        "Winogrande":82.64,
        "GSM8K":61.33,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":15.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/CatunaMayo",
        "Average":74.95,
        "ARC":71.76,
        "HellaSwag":87.9,
        "MMLU":65.21,
        "TruthfulQA":69.96,
        "Winogrande":82.56,
        "GSM8K":72.33,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eric111\/CatunaMayo",
        "Average":74.95,
        "ARC":71.76,
        "HellaSwag":87.9,
        "MMLU":65.21,
        "TruthfulQA":69.96,
        "Winogrande":82.56,
        "GSM8K":72.33,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Buttercup-V2-laser",
        "Average":74.95,
        "ARC":73.12,
        "HellaSwag":88.48,
        "MMLU":64.74,
        "TruthfulQA":69.0,
        "Winogrande":86.27,
        "GSM8K":68.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"rwitz2\/go-bruins-v2.1.1",
        "Average":74.95,
        "ARC":72.87,
        "HellaSwag":88.33,
        "MMLU":65.18,
        "TruthfulQA":69.8,
        "Winogrande":82.24,
        "GSM8K":71.27,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":22.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kaitchup\/TheMayonnaise",
        "Average":74.94,
        "ARC":73.46,
        "HellaSwag":88.46,
        "MMLU":64.88,
        "TruthfulQA":69.19,
        "Winogrande":84.29,
        "GSM8K":69.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-dogwalker-7b",
        "Average":74.94,
        "ARC":72.01,
        "HellaSwag":88.17,
        "MMLU":64.96,
        "TruthfulQA":71.39,
        "Winogrande":82.0,
        "GSM8K":71.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ConvexAI\/BurningBruce-004",
        "Average":74.94,
        "ARC":73.29,
        "HellaSwag":88.63,
        "MMLU":64.68,
        "TruthfulQA":68.39,
        "Winogrande":84.06,
        "GSM8K":70.58,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-privatemix-ia3",
        "Average":74.94,
        "ARC":73.38,
        "HellaSwag":88.69,
        "MMLU":64.14,
        "TruthfulQA":70.13,
        "Winogrande":86.66,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/TurdusDareBeagle-7B",
        "Average":74.94,
        "ARC":72.7,
        "HellaSwag":88.45,
        "MMLU":64.87,
        "TruthfulQA":68.9,
        "Winogrande":83.98,
        "GSM8K":70.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-S4-v0.1",
        "Average":74.94,
        "ARC":72.18,
        "HellaSwag":88.29,
        "MMLU":65.03,
        "TruthfulQA":65.56,
        "Winogrande":85.16,
        "GSM8K":73.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"NLPinas\/yi-bagel-2x34b",
        "Average":74.93,
        "ARC":72.7,
        "HellaSwag":85.44,
        "MMLU":76.6,
        "TruthfulQA":71.42,
        "Winogrande":82.72,
        "GSM8K":60.73,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NLPinas\/yi-bagel-2x34b-moe",
        "Average":74.93,
        "ARC":72.7,
        "HellaSwag":85.44,
        "MMLU":76.6,
        "TruthfulQA":71.42,
        "Winogrande":82.72,
        "GSM8K":60.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-privatemix-ia2",
        "Average":74.92,
        "ARC":72.27,
        "HellaSwag":88.59,
        "MMLU":64.53,
        "TruthfulQA":71.33,
        "Winogrande":83.9,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/complect-7B-slerp",
        "Average":74.91,
        "ARC":72.27,
        "HellaSwag":88.19,
        "MMLU":64.89,
        "TruthfulQA":71.14,
        "Winogrande":84.53,
        "GSM8K":68.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nfaheem\/Marcoroni-7b-DPO-Merge",
        "Average":74.9,
        "ARC":73.04,
        "HellaSwag":88.8,
        "MMLU":64.24,
        "TruthfulQA":70.47,
        "Winogrande":85.24,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Eris-Floramix-7b",
        "Average":74.9,
        "ARC":73.12,
        "HellaSwag":88.28,
        "MMLU":64.63,
        "TruthfulQA":70.96,
        "Winogrande":84.69,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Starling_Monarch_Westlake_Garten-7B-v0.1",
        "Average":74.9,
        "ARC":71.76,
        "HellaSwag":88.15,
        "MMLU":65.07,
        "TruthfulQA":67.92,
        "Winogrande":84.53,
        "GSM8K":71.95,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/Beagle_Turdus",
        "Average":74.9,
        "ARC":73.63,
        "HellaSwag":88.82,
        "MMLU":64.62,
        "TruthfulQA":68.27,
        "Winogrande":86.03,
        "GSM8K":68.01,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tushar310\/Hippy-AAI-7B",
        "Average":74.9,
        "ARC":71.84,
        "HellaSwag":88.04,
        "MMLU":65.17,
        "TruthfulQA":72.02,
        "Winogrande":82.32,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-sia",
        "Average":74.89,
        "ARC":72.53,
        "HellaSwag":89.08,
        "MMLU":64.45,
        "TruthfulQA":72.44,
        "Winogrande":84.14,
        "GSM8K":66.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/NeuralMonarchCoderPearlBeagle-T3Q-Mistral-Orca-Math-DPO-7b",
        "Average":74.89,
        "ARC":71.16,
        "HellaSwag":88.22,
        "MMLU":64.97,
        "TruthfulQA":71.45,
        "Winogrande":82.48,
        "GSM8K":71.04,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-royale-v3-7b",
        "Average":74.88,
        "ARC":71.76,
        "HellaSwag":88.23,
        "MMLU":65.06,
        "TruthfulQA":71.13,
        "Winogrande":82.32,
        "GSM8K":70.81,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Pigris-7b-v0.3",
        "Average":74.88,
        "ARC":71.5,
        "HellaSwag":88.15,
        "MMLU":64.53,
        "TruthfulQA":71.21,
        "Winogrande":84.14,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/A0126",
        "Average":74.87,
        "ARC":70.39,
        "HellaSwag":85.87,
        "MMLU":84.03,
        "TruthfulQA":61.53,
        "Winogrande":81.53,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/quantum-dpo-v0.1",
        "Average":74.87,
        "ARC":72.53,
        "HellaSwag":88.37,
        "MMLU":65.29,
        "TruthfulQA":69.92,
        "Winogrande":82.32,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ChaoticNeutrals\/Eris_Floramix_DPO_7B",
        "Average":74.87,
        "ARC":73.04,
        "HellaSwag":88.28,
        "MMLU":64.71,
        "TruthfulQA":70.94,
        "Winogrande":84.69,
        "GSM8K":67.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tushar310\/Hippy-AAI-7B",
        "Average":74.87,
        "ARC":71.59,
        "HellaSwag":88.07,
        "MMLU":65.15,
        "TruthfulQA":71.95,
        "Winogrande":82.32,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen13-mistral-7B",
        "Average":74.86,
        "ARC":71.5,
        "HellaSwag":88.33,
        "MMLU":64.79,
        "TruthfulQA":72.34,
        "Winogrande":82.24,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/MDBX-7B",
        "Average":74.86,
        "ARC":72.01,
        "HellaSwag":88.31,
        "MMLU":64.97,
        "TruthfulQA":68.19,
        "Winogrande":83.5,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CultriX\/MergeTrix-7B-v2",
        "Average":74.85,
        "ARC":72.7,
        "HellaSwag":88.48,
        "MMLU":64.89,
        "TruthfulQA":67.17,
        "Winogrande":86.74,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/supermario_v1",
        "Average":74.85,
        "ARC":73.72,
        "HellaSwag":88.71,
        "MMLU":64.57,
        "TruthfulQA":68.23,
        "Winogrande":85.64,
        "GSM8K":68.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Eris-Daturamix-7b",
        "Average":74.83,
        "ARC":72.78,
        "HellaSwag":88.23,
        "MMLU":64.52,
        "TruthfulQA":71.05,
        "Winogrande":84.69,
        "GSM8K":67.7,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/NeuralTurdusVariant1-7B",
        "Average":74.83,
        "ARC":73.12,
        "HellaSwag":88.61,
        "MMLU":64.75,
        "TruthfulQA":69.99,
        "Winogrande":85.16,
        "GSM8K":67.32,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-dogpark-7b",
        "Average":74.82,
        "ARC":71.84,
        "HellaSwag":88.15,
        "MMLU":65.07,
        "TruthfulQA":71.14,
        "Winogrande":82.24,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/MixtureofMerges-MoE-v2",
        "Average":74.82,
        "ARC":72.44,
        "HellaSwag":88.41,
        "MMLU":64.88,
        "TruthfulQA":70.92,
        "Winogrande":83.58,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Mistral-7b-instruct-v0.2-private-eds2",
        "Average":74.82,
        "ARC":73.12,
        "HellaSwag":89.23,
        "MMLU":64.11,
        "TruthfulQA":72.25,
        "Winogrande":84.69,
        "GSM8K":65.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/WildWest-Variant3-7B",
        "Average":74.81,
        "ARC":73.21,
        "HellaSwag":88.37,
        "MMLU":64.76,
        "TruthfulQA":68.09,
        "Winogrande":84.37,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/connate-7B-slerp",
        "Average":74.8,
        "ARC":72.1,
        "HellaSwag":88.37,
        "MMLU":64.96,
        "TruthfulQA":71.16,
        "Winogrande":84.61,
        "GSM8K":67.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhishekchohan\/SOLAR-10.7B-Instruct-Forest-DPO-v1",
        "Average":74.8,
        "ARC":71.93,
        "HellaSwag":88.44,
        "MMLU":65.63,
        "TruthfulQA":76.13,
        "Winogrande":82.16,
        "GSM8K":64.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/MetaMath-Bagel-DPO-34B",
        "Average":74.8,
        "ARC":68.17,
        "HellaSwag":84.23,
        "MMLU":76.54,
        "TruthfulQA":65.44,
        "Winogrande":82.24,
        "GSM8K":72.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janai-hq\/trinity-v1",
        "Average":74.8,
        "ARC":72.27,
        "HellaSwag":88.36,
        "MMLU":65.2,
        "TruthfulQA":69.31,
        "Winogrande":82.0,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/trinity-v1",
        "Average":74.8,
        "ARC":72.27,
        "HellaSwag":88.36,
        "MMLU":65.2,
        "TruthfulQA":69.31,
        "Winogrande":82.0,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"222gate\/Blurred-Beagle-7b-slerp",
        "Average":74.8,
        "ARC":72.78,
        "HellaSwag":88.58,
        "MMLU":64.95,
        "TruthfulQA":69.39,
        "Winogrande":83.19,
        "GSM8K":69.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_11-7B-slerp",
        "Average":74.8,
        "ARC":72.53,
        "HellaSwag":88.2,
        "MMLU":65.04,
        "TruthfulQA":69.81,
        "Winogrande":82.32,
        "GSM8K":70.89,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-royale-v2-7b",
        "Average":74.8,
        "ARC":72.01,
        "HellaSwag":88.15,
        "MMLU":65.07,
        "TruthfulQA":71.1,
        "Winogrande":82.24,
        "GSM8K":70.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Eris_PrimeV4-Vision-7B",
        "Average":74.79,
        "ARC":72.78,
        "HellaSwag":88.47,
        "MMLU":65.13,
        "TruthfulQA":71.43,
        "Winogrande":83.82,
        "GSM8K":67.1,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/WestLake-7B-v2-laser",
        "Average":74.78,
        "ARC":73.29,
        "HellaSwag":88.66,
        "MMLU":64.72,
        "TruthfulQA":67.04,
        "Winogrande":86.74,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":33.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen8-mistral-7B",
        "Average":74.78,
        "ARC":71.93,
        "HellaSwag":88.06,
        "MMLU":64.92,
        "TruthfulQA":72.02,
        "Winogrande":82.24,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rizla\/raccoon-small",
        "Average":74.78,
        "ARC":74.4,
        "HellaSwag":88.73,
        "MMLU":64.55,
        "TruthfulQA":76.74,
        "Winogrande":87.37,
        "GSM8K":56.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.19,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_10-7B-slerp",
        "Average":74.77,
        "ARC":72.35,
        "HellaSwag":88.3,
        "MMLU":64.87,
        "TruthfulQA":69.49,
        "Winogrande":83.5,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Vasanth\/Beast-Soul-new",
        "Average":74.76,
        "ARC":73.12,
        "HellaSwag":88.35,
        "MMLU":64.74,
        "TruthfulQA":67.38,
        "Winogrande":85.24,
        "GSM8K":69.75,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Beagle14-7B",
        "Average":74.76,
        "ARC":72.95,
        "HellaSwag":87.95,
        "MMLU":64.7,
        "TruthfulQA":68.88,
        "Winogrande":82.64,
        "GSM8K":71.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test2_3",
        "Average":74.76,
        "ARC":72.95,
        "HellaSwag":88.42,
        "MMLU":64.8,
        "TruthfulQA":68.4,
        "Winogrande":84.14,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/MarcDareBeagle-7B",
        "Average":74.75,
        "ARC":72.1,
        "HellaSwag":88.33,
        "MMLU":65.03,
        "TruthfulQA":68.09,
        "Winogrande":83.19,
        "GSM8K":71.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GreenNode\/GreenNodeLM-v3olet-7B",
        "Average":74.75,
        "ARC":72.27,
        "HellaSwag":88.25,
        "MMLU":65.27,
        "TruthfulQA":69.52,
        "Winogrande":82.48,
        "GSM8K":70.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_35-7B-slerp",
        "Average":74.75,
        "ARC":71.67,
        "HellaSwag":88.34,
        "MMLU":64.66,
        "TruthfulQA":75.76,
        "Winogrande":83.35,
        "GSM8K":64.75,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/60B_MoE_Coder_v3",
        "Average":74.75,
        "ARC":71.16,
        "HellaSwag":85.44,
        "MMLU":75.37,
        "TruthfulQA":67.01,
        "Winogrande":82.56,
        "GSM8K":66.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ignos\/LeoScorpius-GreenNode-Alpaca-7B-v1",
        "Average":74.74,
        "ARC":72.35,
        "HellaSwag":88.16,
        "MMLU":65.23,
        "TruthfulQA":69.35,
        "Winogrande":82.32,
        "GSM8K":71.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/NeuralBeagle14-7B",
        "Average":74.74,
        "ARC":72.95,
        "HellaSwag":88.34,
        "MMLU":64.55,
        "TruthfulQA":69.93,
        "Winogrande":82.4,
        "GSM8K":70.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":146.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-royale-7b",
        "Average":74.74,
        "ARC":71.76,
        "HellaSwag":88.2,
        "MMLU":65.13,
        "TruthfulQA":71.12,
        "Winogrande":82.32,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"core-3\/kuno-royale-7B",
        "Average":74.74,
        "ARC":71.76,
        "HellaSwag":88.2,
        "MMLU":65.13,
        "TruthfulQA":71.12,
        "Winogrande":82.32,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saishf\/Multi-Verse-RP-7B",
        "Average":74.73,
        "ARC":72.35,
        "HellaSwag":88.37,
        "MMLU":63.94,
        "TruthfulQA":73.19,
        "Winogrande":84.14,
        "GSM8K":66.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/NeuralLake-Variant1-7B",
        "Average":74.73,
        "ARC":73.12,
        "HellaSwag":88.45,
        "MMLU":64.67,
        "TruthfulQA":68.37,
        "Winogrande":84.45,
        "GSM8K":69.29,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kaitchup\/Mayonnaise-4in1-03",
        "Average":74.73,
        "ARC":72.95,
        "HellaSwag":88.29,
        "MMLU":64.76,
        "TruthfulQA":68.79,
        "Winogrande":83.58,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ChaoticNeutrals\/Eris_Remix_DPO_7B",
        "Average":74.71,
        "ARC":72.44,
        "HellaSwag":88.03,
        "MMLU":65.29,
        "TruthfulQA":68.92,
        "Winogrande":84.77,
        "GSM8K":68.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Eris_Remix_7B",
        "Average":74.7,
        "ARC":72.35,
        "HellaSwag":88.04,
        "MMLU":65.26,
        "TruthfulQA":69.12,
        "Winogrande":84.77,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/aegolius-acadicus-v1-30b",
        "Average":74.7,
        "ARC":72.61,
        "HellaSwag":87.99,
        "MMLU":65.11,
        "TruthfulQA":67.06,
        "Winogrande":84.85,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":29.79,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/aegolius-acadicus-30b",
        "Average":74.7,
        "ARC":72.61,
        "HellaSwag":88.01,
        "MMLU":65.07,
        "TruthfulQA":67.07,
        "Winogrande":84.93,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":29.79,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Eric111\/CatunaLaserPi-DPO",
        "Average":74.7,
        "ARC":72.95,
        "HellaSwag":88.33,
        "MMLU":64.95,
        "TruthfulQA":70.01,
        "Winogrande":82.64,
        "GSM8K":69.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/nontoxic-bagel-34b-v0.2",
        "Average":74.69,
        "ARC":72.44,
        "HellaSwag":85.64,
        "MMLU":76.41,
        "TruthfulQA":72.7,
        "Winogrande":82.48,
        "GSM8K":58.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/bagel-dpo-34b-v0.2",
        "Average":74.69,
        "ARC":71.93,
        "HellaSwag":85.25,
        "MMLU":76.58,
        "TruthfulQA":70.05,
        "Winogrande":83.35,
        "GSM8K":60.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":87.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/quantum-v0.01",
        "Average":74.68,
        "ARC":72.53,
        "HellaSwag":88.27,
        "MMLU":65.2,
        "TruthfulQA":69.28,
        "Winogrande":82.56,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"senseable\/WestLake-7B-v2",
        "Average":74.68,
        "ARC":73.04,
        "HellaSwag":88.65,
        "MMLU":64.71,
        "TruthfulQA":67.06,
        "Winogrande":86.98,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":85.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/quantum-trinity-v0.1",
        "Average":74.67,
        "ARC":72.53,
        "HellaSwag":88.28,
        "MMLU":65.19,
        "TruthfulQA":69.28,
        "Winogrande":82.56,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"moreh\/MoMo-72B-LoRA-V1.4",
        "Average":74.67,
        "ARC":69.2,
        "HellaSwag":85.07,
        "MMLU":77.12,
        "TruthfulQA":62.66,
        "Winogrande":83.74,
        "GSM8K":70.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":86.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Manolo26\/metis-chat-instruct-7b",
        "Average":74.66,
        "ARC":72.87,
        "HellaSwag":88.17,
        "MMLU":64.92,
        "TruthfulQA":69.44,
        "Winogrande":81.85,
        "GSM8K":70.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ycros\/BagelMIsteryTour-8x7B",
        "Average":74.66,
        "ARC":72.44,
        "HellaSwag":87.5,
        "MMLU":71.25,
        "TruthfulQA":74.95,
        "Winogrande":82.0,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-7B-0210-ties",
        "Average":74.66,
        "ARC":71.08,
        "HellaSwag":88.63,
        "MMLU":63.81,
        "TruthfulQA":70.47,
        "Winogrande":83.98,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BarryFutureman\/WildMarcoroni-Variant3-7B",
        "Average":74.66,
        "ARC":72.27,
        "HellaSwag":88.96,
        "MMLU":64.38,
        "TruthfulQA":71.68,
        "Winogrande":84.53,
        "GSM8K":66.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"udkai\/Turdus",
        "Average":74.66,
        "ARC":73.38,
        "HellaSwag":88.56,
        "MMLU":64.52,
        "TruthfulQA":67.11,
        "Winogrande":86.66,
        "GSM8K":67.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Calme-7B-Instruct-v0.4",
        "Average":74.65,
        "ARC":70.73,
        "HellaSwag":87.75,
        "MMLU":64.4,
        "TruthfulQA":70.25,
        "Winogrande":82.08,
        "GSM8K":72.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kevin009\/llamaRAGdrama",
        "Average":74.65,
        "ARC":72.01,
        "HellaSwag":88.83,
        "MMLU":64.5,
        "TruthfulQA":70.24,
        "Winogrande":86.66,
        "GSM8K":65.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Cedaros\/Test-7B",
        "Average":74.65,
        "ARC":73.21,
        "HellaSwag":88.17,
        "MMLU":64.37,
        "TruthfulQA":69.91,
        "Winogrande":82.48,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Eris-Lelanacles-7b",
        "Average":74.64,
        "ARC":71.67,
        "HellaSwag":87.91,
        "MMLU":64.9,
        "TruthfulQA":68.97,
        "Winogrande":83.9,
        "GSM8K":70.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/Mixtral-7Bx2-truthy",
        "Average":74.64,
        "ARC":72.18,
        "HellaSwag":87.88,
        "MMLU":65.2,
        "TruthfulQA":74.68,
        "Winogrande":80.66,
        "GSM8K":67.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vicgalle\/CarbonBeagle-11B",
        "Average":74.64,
        "ARC":71.84,
        "HellaSwag":88.93,
        "MMLU":66.62,
        "TruthfulQA":69.43,
        "Winogrande":84.06,
        "GSM8K":66.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"moreh\/MoMo-72B-LoRA-V1.4",
        "Average":74.64,
        "ARC":69.11,
        "HellaSwag":85.0,
        "MMLU":77.26,
        "TruthfulQA":62.71,
        "Winogrande":83.74,
        "GSM8K":69.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":86.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-oia",
        "Average":74.63,
        "ARC":72.78,
        "HellaSwag":89.24,
        "MMLU":64.26,
        "TruthfulQA":73.15,
        "Winogrande":83.74,
        "GSM8K":64.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/O0128",
        "Average":74.61,
        "ARC":67.92,
        "HellaSwag":85.34,
        "MMLU":83.59,
        "TruthfulQA":60.13,
        "Winogrande":82.24,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andrijdavid\/macaroni-7b",
        "Average":74.6,
        "ARC":73.12,
        "HellaSwag":88.17,
        "MMLU":64.58,
        "TruthfulQA":68.76,
        "Winogrande":84.37,
        "GSM8K":68.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/NeuralDareBeagle-7B-slerp",
        "Average":74.6,
        "ARC":72.1,
        "HellaSwag":88.2,
        "MMLU":64.99,
        "TruthfulQA":69.18,
        "Winogrande":82.56,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/CatunaLaserPi",
        "Average":74.59,
        "ARC":71.5,
        "HellaSwag":88.06,
        "MMLU":64.95,
        "TruthfulQA":67.83,
        "Winogrande":83.03,
        "GSM8K":72.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen11-mistral-7B",
        "Average":74.59,
        "ARC":70.99,
        "HellaSwag":88.06,
        "MMLU":65.06,
        "TruthfulQA":71.73,
        "Winogrande":82.16,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shadowml\/DareBeagle-7B",
        "Average":74.58,
        "ARC":71.67,
        "HellaSwag":88.01,
        "MMLU":65.03,
        "TruthfulQA":68.98,
        "Winogrande":82.32,
        "GSM8K":71.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/yam-sam-7B",
        "Average":74.58,
        "ARC":70.9,
        "HellaSwag":87.92,
        "MMLU":65.39,
        "TruthfulQA":71.3,
        "Winogrande":83.03,
        "GSM8K":68.92,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_3-7B-slerp",
        "Average":74.57,
        "ARC":70.82,
        "HellaSwag":87.79,
        "MMLU":65.12,
        "TruthfulQA":68.86,
        "Winogrande":82.56,
        "GSM8K":72.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/iWillChangeTheNameLater",
        "Average":74.56,
        "ARC":72.01,
        "HellaSwag":88.23,
        "MMLU":64.97,
        "TruthfulQA":69.41,
        "Winogrande":84.21,
        "GSM8K":68.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/ThetaMaven5",
        "Average":74.56,
        "ARC":72.01,
        "HellaSwag":88.38,
        "MMLU":64.77,
        "TruthfulQA":69.67,
        "Winogrande":82.64,
        "GSM8K":69.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-D-v0.1",
        "Average":74.54,
        "ARC":71.76,
        "HellaSwag":88.21,
        "MMLU":64.86,
        "TruthfulQA":66.32,
        "Winogrande":84.37,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Prokaryote-8x7B-bf16",
        "Average":74.53,
        "ARC":73.72,
        "HellaSwag":88.18,
        "MMLU":64.97,
        "TruthfulQA":67.79,
        "Winogrande":83.03,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ConvexAI\/BurningBruce-005",
        "Average":74.53,
        "ARC":72.01,
        "HellaSwag":88.31,
        "MMLU":64.76,
        "TruthfulQA":67.27,
        "Winogrande":83.35,
        "GSM8K":71.49,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/mistral-7b-dpo-merge-v1.1",
        "Average":74.53,
        "ARC":72.53,
        "HellaSwag":88.15,
        "MMLU":64.83,
        "TruthfulQA":68.48,
        "Winogrande":82.32,
        "GSM8K":70.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/WestOrcaNeural-V2-DARETIES-7B",
        "Average":74.53,
        "ARC":72.1,
        "HellaSwag":88.21,
        "MMLU":64.64,
        "TruthfulQA":67.81,
        "Winogrande":83.74,
        "GSM8K":70.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-10.7B-v4",
        "Average":74.52,
        "ARC":71.25,
        "HellaSwag":88.48,
        "MMLU":66.27,
        "TruthfulQA":71.95,
        "Winogrande":83.58,
        "GSM8K":65.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rwitz2\/go-bruins-v2.1",
        "Average":74.5,
        "ARC":71.93,
        "HellaSwag":88.33,
        "MMLU":65.0,
        "TruthfulQA":69.16,
        "Winogrande":82.16,
        "GSM8K":70.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-dpo-34b-v0.2",
        "Average":74.5,
        "ARC":72.01,
        "HellaSwag":85.24,
        "MMLU":76.58,
        "TruthfulQA":70.16,
        "Winogrande":83.03,
        "GSM8K":59.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":87.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/mistral-7b-dpo-v6",
        "Average":74.5,
        "ARC":72.53,
        "HellaSwag":88.1,
        "MMLU":64.68,
        "TruthfulQA":68.24,
        "Winogrande":82.56,
        "GSM8K":70.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"RatanRohith\/NeuralPizza-WestSeverus-7B-Merge-slerp",
        "Average":74.5,
        "ARC":71.42,
        "HellaSwag":88.25,
        "MMLU":64.74,
        "TruthfulQA":70.4,
        "Winogrande":83.11,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"logicker\/SkkuDataScienceGlobal-10.7b",
        "Average":74.5,
        "ARC":71.25,
        "HellaSwag":88.41,
        "MMLU":66.31,
        "TruthfulQA":71.92,
        "Winogrande":83.35,
        "GSM8K":65.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shadowml\/DareBeagel-2x7B",
        "Average":74.49,
        "ARC":72.01,
        "HellaSwag":88.12,
        "MMLU":64.51,
        "TruthfulQA":69.09,
        "Winogrande":82.72,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"senseable\/Westlake-7B",
        "Average":74.48,
        "ARC":73.21,
        "HellaSwag":88.49,
        "MMLU":64.64,
        "TruthfulQA":67.36,
        "Winogrande":86.03,
        "GSM8K":67.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rizla\/trrapi-16b",
        "Average":74.48,
        "ARC":72.1,
        "HellaSwag":88.88,
        "MMLU":64.26,
        "TruthfulQA":74.13,
        "Winogrande":86.35,
        "GSM8K":61.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":18.79,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/MM-OV-bagel-DPO-34b-c1000-250",
        "Average":74.47,
        "ARC":68.17,
        "HellaSwag":83.97,
        "MMLU":76.33,
        "TruthfulQA":63.67,
        "Winogrande":82.4,
        "GSM8K":72.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"invalid-coder\/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp",
        "Average":74.45,
        "ARC":71.25,
        "HellaSwag":88.42,
        "MMLU":66.31,
        "TruthfulQA":71.94,
        "Winogrande":83.43,
        "GSM8K":65.35,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/NeuralOmniWestBeaglake-7B",
        "Average":74.43,
        "ARC":73.72,
        "HellaSwag":89.69,
        "MMLU":63.96,
        "TruthfulQA":75.1,
        "Winogrande":84.93,
        "GSM8K":59.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_linear",
        "Average":74.43,
        "ARC":71.25,
        "HellaSwag":88.44,
        "MMLU":66.35,
        "TruthfulQA":71.94,
        "Winogrande":83.27,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gagan3012\/MetaModel_moe",
        "Average":74.42,
        "ARC":71.25,
        "HellaSwag":88.4,
        "MMLU":66.26,
        "TruthfulQA":71.86,
        "Winogrande":83.35,
        "GSM8K":65.43,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seyf1elislam\/KuTrix-7b",
        "Average":74.42,
        "ARC":70.48,
        "HellaSwag":87.94,
        "MMLU":65.28,
        "TruthfulQA":70.85,
        "Winogrande":81.93,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-10.7B-v2",
        "Average":74.42,
        "ARC":71.25,
        "HellaSwag":88.4,
        "MMLU":66.31,
        "TruthfulQA":71.94,
        "Winogrande":83.35,
        "GSM8K":65.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nbeerbower\/bruphin-epsilon",
        "Average":74.42,
        "ARC":72.1,
        "HellaSwag":88.09,
        "MMLU":65.04,
        "TruthfulQA":66.95,
        "Winogrande":83.82,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DopeorNope\/SOLARC-M-10.7B",
        "Average":74.42,
        "ARC":71.16,
        "HellaSwag":88.41,
        "MMLU":66.31,
        "TruthfulQA":71.85,
        "Winogrande":83.35,
        "GSM8K":65.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cloudyu\/Mixtral_11Bx2_MoE_19B",
        "Average":74.41,
        "ARC":71.16,
        "HellaSwag":88.47,
        "MMLU":66.31,
        "TruthfulQA":72.0,
        "Winogrande":83.27,
        "GSM8K":65.28,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.19,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v5",
        "Average":74.41,
        "ARC":70.99,
        "HellaSwag":88.48,
        "MMLU":66.34,
        "TruthfulQA":71.84,
        "Winogrande":83.58,
        "GSM8K":65.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-10.7B-v3",
        "Average":74.41,
        "ARC":70.99,
        "HellaSwag":88.48,
        "MMLU":66.34,
        "TruthfulQA":71.84,
        "Winogrande":83.58,
        "GSM8K":65.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gagan3012\/MetaModel",
        "Average":74.4,
        "ARC":71.08,
        "HellaSwag":88.45,
        "MMLU":66.26,
        "TruthfulQA":71.84,
        "Winogrande":83.43,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kyujinpy\/Sakura-SOLAR-Instruct",
        "Average":74.4,
        "ARC":70.99,
        "HellaSwag":88.42,
        "MMLU":66.33,
        "TruthfulQA":71.79,
        "Winogrande":83.66,
        "GSM8K":65.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Xenon1\/MetaModel_moex8",
        "Average":74.39,
        "ARC":71.16,
        "HellaSwag":88.38,
        "MMLU":66.29,
        "TruthfulQA":71.91,
        "Winogrande":83.27,
        "GSM8K":65.35,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":69.92,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"gagan3012\/MetaModelv3",
        "Average":74.39,
        "ARC":71.16,
        "HellaSwag":88.39,
        "MMLU":66.32,
        "TruthfulQA":71.86,
        "Winogrande":83.35,
        "GSM8K":65.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet",
        "Average":74.38,
        "ARC":71.25,
        "HellaSwag":88.42,
        "MMLU":66.36,
        "TruthfulQA":71.95,
        "Winogrande":83.27,
        "GSM8K":65.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Vasanth\/Beast-Soul",
        "Average":74.37,
        "ARC":72.53,
        "HellaSwag":88.15,
        "MMLU":64.76,
        "TruthfulQA":66.76,
        "Winogrande":83.43,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarryFutureman\/WestLakeX-7B-EvoMerge",
        "Average":74.37,
        "ARC":71.42,
        "HellaSwag":88.08,
        "MMLU":64.84,
        "TruthfulQA":67.5,
        "Winogrande":84.77,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen3",
        "Average":74.36,
        "ARC":70.82,
        "HellaSwag":87.98,
        "MMLU":64.81,
        "TruthfulQA":70.69,
        "Winogrande":82.16,
        "GSM8K":69.67,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/DareBeagle-7B",
        "Average":74.35,
        "ARC":71.59,
        "HellaSwag":87.98,
        "MMLU":65.21,
        "TruthfulQA":68.3,
        "Winogrande":81.93,
        "GSM8K":71.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"222gate\/Blurdus-7b-v0.1",
        "Average":74.35,
        "ARC":72.27,
        "HellaSwag":88.5,
        "MMLU":64.82,
        "TruthfulQA":69.72,
        "Winogrande":82.95,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Franken-MoE-18B-v0.1",
        "Average":74.35,
        "ARC":72.1,
        "HellaSwag":88.3,
        "MMLU":65.01,
        "TruthfulQA":67.51,
        "Winogrande":83.74,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ConvexAI\/Solutus-3x7B",
        "Average":74.35,
        "ARC":72.01,
        "HellaSwag":88.31,
        "MMLU":64.77,
        "TruthfulQA":67.52,
        "Winogrande":83.66,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kodonho\/Solar-OrcaDPO-Solar-Instruct-SLERP",
        "Average":74.35,
        "ARC":70.99,
        "HellaSwag":88.22,
        "MMLU":66.22,
        "TruthfulQA":71.95,
        "Winogrande":83.43,
        "GSM8K":65.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DopeorNope\/SOLARC-MOE-10.7Bx6",
        "Average":74.35,
        "ARC":70.9,
        "HellaSwag":88.4,
        "MMLU":66.36,
        "TruthfulQA":71.85,
        "Winogrande":83.66,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":53.01,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/MergeTrix-7B",
        "Average":74.33,
        "ARC":72.27,
        "HellaSwag":87.84,
        "MMLU":64.88,
        "TruthfulQA":66.27,
        "Winogrande":83.5,
        "GSM8K":71.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"invalid-coder\/SOLAR-10.7B-Instruct-SOLARC-M-10.7B-slerp",
        "Average":74.32,
        "ARC":71.08,
        "HellaSwag":88.34,
        "MMLU":66.29,
        "TruthfulQA":71.73,
        "Winogrande":83.74,
        "GSM8K":64.75,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v6",
        "Average":74.31,
        "ARC":71.16,
        "HellaSwag":88.5,
        "MMLU":66.31,
        "TruthfulQA":71.96,
        "Winogrande":83.43,
        "GSM8K":64.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-10.7B-v5",
        "Average":74.31,
        "ARC":71.16,
        "HellaSwag":88.51,
        "MMLU":66.44,
        "TruthfulQA":71.97,
        "Winogrande":83.35,
        "GSM8K":64.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/Truthful_DPO_MOE_19B",
        "Average":74.3,
        "ARC":71.08,
        "HellaSwag":88.46,
        "MMLU":66.13,
        "TruthfulQA":72.29,
        "Winogrande":83.35,
        "GSM8K":64.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.19,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/BurningBruce-003",
        "Average":74.3,
        "ARC":71.25,
        "HellaSwag":88.22,
        "MMLU":64.48,
        "TruthfulQA":66.39,
        "Winogrande":83.19,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"222gate\/Blur-4x7b-MOE-v0.1",
        "Average":74.29,
        "ARC":72.27,
        "HellaSwag":88.14,
        "MMLU":65.05,
        "TruthfulQA":68.82,
        "Winogrande":82.56,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kodonho\/SolarM-SakuraSolar-SLERP",
        "Average":74.29,
        "ARC":71.16,
        "HellaSwag":88.47,
        "MMLU":66.24,
        "TruthfulQA":72.1,
        "Winogrande":83.11,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/Kindred-7B-slerp",
        "Average":74.29,
        "ARC":71.76,
        "HellaSwag":87.78,
        "MMLU":64.76,
        "TruthfulQA":68.12,
        "Winogrande":83.11,
        "GSM8K":70.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v4",
        "Average":74.29,
        "ARC":71.25,
        "HellaSwag":88.5,
        "MMLU":66.24,
        "TruthfulQA":71.89,
        "Winogrande":83.43,
        "GSM8K":64.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gagan3012\/MetaModel_moe",
        "Average":74.28,
        "ARC":71.08,
        "HellaSwag":88.39,
        "MMLU":66.31,
        "TruthfulQA":71.82,
        "Winogrande":83.5,
        "GSM8K":64.59,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/NeuralExperiment-7b-MagicCoder-v7.5",
        "Average":74.28,
        "ARC":71.33,
        "HellaSwag":87.94,
        "MMLU":64.62,
        "TruthfulQA":72.11,
        "Winogrande":83.5,
        "GSM8K":66.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-13B-v1",
        "Average":74.28,
        "ARC":71.25,
        "HellaSwag":88.46,
        "MMLU":66.42,
        "TruthfulQA":71.98,
        "Winogrande":83.27,
        "GSM8K":64.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeonsworld\/CarbonVillain-en-10.7B-v1",
        "Average":74.28,
        "ARC":71.25,
        "HellaSwag":88.46,
        "MMLU":66.42,
        "TruthfulQA":71.98,
        "Winogrande":83.27,
        "GSM8K":64.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ResplendentAI\/Datura_7B",
        "Average":74.28,
        "ARC":72.1,
        "HellaSwag":88.27,
        "MMLU":64.15,
        "TruthfulQA":71.03,
        "Winogrande":84.53,
        "GSM8K":65.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Patronum-7B",
        "Average":74.27,
        "ARC":71.67,
        "HellaSwag":88.33,
        "MMLU":64.84,
        "TruthfulQA":70.41,
        "Winogrande":81.85,
        "GSM8K":68.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DopeorNope\/SOLARC-MOE-10.7Bx4",
        "Average":74.27,
        "ARC":70.99,
        "HellaSwag":88.43,
        "MMLU":66.34,
        "TruthfulQA":71.91,
        "Winogrande":83.58,
        "GSM8K":64.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":36.1,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bhavinjawade\/SOLAR-10B-OrcaDPO-Jawade",
        "Average":74.27,
        "ARC":71.16,
        "HellaSwag":88.27,
        "MMLU":66.12,
        "TruthfulQA":71.57,
        "Winogrande":83.66,
        "GSM8K":64.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ResplendentAI\/Flora_DPO_7B",
        "Average":74.26,
        "ARC":71.76,
        "HellaSwag":88.28,
        "MMLU":64.13,
        "TruthfulQA":71.08,
        "Winogrande":84.53,
        "GSM8K":65.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/SauerkrautLM-UNA-SOLAR-Instruct",
        "Average":74.26,
        "ARC":70.9,
        "HellaSwag":88.3,
        "MMLU":66.15,
        "TruthfulQA":71.8,
        "Winogrande":83.74,
        "GSM8K":64.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/SauerkrautLM-UNA-SOLAR-Instruct-test",
        "Average":74.26,
        "ARC":70.9,
        "HellaSwag":88.3,
        "MMLU":66.15,
        "TruthfulQA":71.8,
        "Winogrande":83.74,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Flora_7B",
        "Average":74.26,
        "ARC":72.1,
        "HellaSwag":88.31,
        "MMLU":64.16,
        "TruthfulQA":71.19,
        "Winogrande":84.45,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/SOLAR-math-2x10.7b-v0.2",
        "Average":74.25,
        "ARC":70.9,
        "HellaSwag":88.29,
        "MMLU":66.25,
        "TruthfulQA":71.68,
        "Winogrande":83.5,
        "GSM8K":64.9,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.19,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/testtest",
        "Average":74.24,
        "ARC":70.82,
        "HellaSwag":84.88,
        "MMLU":76.66,
        "TruthfulQA":69.9,
        "Winogrande":82.08,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"222gate\/BrurryDog-7b-v0.1",
        "Average":74.24,
        "ARC":72.53,
        "HellaSwag":88.37,
        "MMLU":64.74,
        "TruthfulQA":70.05,
        "Winogrande":82.87,
        "GSM8K":66.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gagan3012\/MetaModelv2",
        "Average":74.24,
        "ARC":71.08,
        "HellaSwag":88.56,
        "MMLU":66.29,
        "TruthfulQA":71.94,
        "Winogrande":83.11,
        "GSM8K":64.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/MonarchCoder-MoE-2x7B",
        "Average":74.23,
        "ARC":70.99,
        "HellaSwag":87.99,
        "MMLU":65.11,
        "TruthfulQA":71.25,
        "Winogrande":80.66,
        "GSM8K":69.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_45-7B-dare_ties",
        "Average":74.23,
        "ARC":69.8,
        "HellaSwag":87.6,
        "MMLU":65.06,
        "TruthfulQA":67.79,
        "Winogrande":82.32,
        "GSM8K":72.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BryanSwk\/LaserPipe-7B-SLERP",
        "Average":74.22,
        "ARC":71.08,
        "HellaSwag":87.89,
        "MMLU":64.86,
        "TruthfulQA":65.38,
        "Winogrande":83.35,
        "GSM8K":72.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Valor-7B-v0.1",
        "Average":74.21,
        "ARC":72.27,
        "HellaSwag":86.59,
        "MMLU":64.09,
        "TruthfulQA":69.84,
        "Winogrande":83.35,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"naseerfaheem\/SOLAR-10.7B-Instruct-ties",
        "Average":74.21,
        "ARC":70.9,
        "HellaSwag":88.58,
        "MMLU":66.34,
        "TruthfulQA":71.88,
        "Winogrande":83.5,
        "GSM8K":64.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v2",
        "Average":74.21,
        "ARC":71.08,
        "HellaSwag":88.6,
        "MMLU":66.23,
        "TruthfulQA":72.01,
        "Winogrande":83.5,
        "GSM8K":63.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-SOLAR-Instruct",
        "Average":74.21,
        "ARC":70.82,
        "HellaSwag":88.63,
        "MMLU":66.2,
        "TruthfulQA":71.95,
        "Winogrande":83.5,
        "GSM8K":64.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/GarrulusMarcoro-7B-v0.1",
        "Average":74.2,
        "ARC":72.35,
        "HellaSwag":88.0,
        "MMLU":64.65,
        "TruthfulQA":67.05,
        "Winogrande":87.21,
        "GSM8K":65.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v1",
        "Average":74.2,
        "ARC":70.9,
        "HellaSwag":88.41,
        "MMLU":66.32,
        "TruthfulQA":71.71,
        "Winogrande":83.74,
        "GSM8K":64.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Eris_PrimeV3-Vision-7B",
        "Average":74.2,
        "ARC":70.65,
        "HellaSwag":87.87,
        "MMLU":65.32,
        "TruthfulQA":70.32,
        "Winogrande":83.35,
        "GSM8K":67.7,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"upstage\/SOLAR-10.7B-Instruct-v1.0",
        "Average":74.2,
        "ARC":71.08,
        "HellaSwag":88.16,
        "MMLU":66.21,
        "TruthfulQA":71.43,
        "Winogrande":83.58,
        "GSM8K":64.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":554.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-SOLAR-10.7B-Instruct-v1.0",
        "Average":74.2,
        "ARC":70.56,
        "HellaSwag":88.18,
        "MMLU":66.08,
        "TruthfulQA":72.05,
        "Winogrande":83.66,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":10.73,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cloudyu\/Venus_DPO_50",
        "Average":74.2,
        "ARC":70.73,
        "HellaSwag":88.47,
        "MMLU":66.3,
        "TruthfulQA":72.63,
        "Winogrande":83.43,
        "GSM8K":63.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":19.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bhavinjawade\/SOLAR-10B-Nector-DPO-Jawade",
        "Average":74.19,
        "ARC":71.33,
        "HellaSwag":88.62,
        "MMLU":66.22,
        "TruthfulQA":70.92,
        "Winogrande":83.43,
        "GSM8K":64.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shadowml\/Mixolar-4x7b",
        "Average":74.18,
        "ARC":71.08,
        "HellaSwag":88.44,
        "MMLU":66.29,
        "TruthfulQA":71.81,
        "Winogrande":83.58,
        "GSM8K":63.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"GreenNode\/GreenNodeLM-7B-v4leo",
        "Average":74.18,
        "ARC":71.25,
        "HellaSwag":88.24,
        "MMLU":65.01,
        "TruthfulQA":69.65,
        "Winogrande":82.32,
        "GSM8K":68.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liminerity\/Blur-7b-v1.21",
        "Average":74.18,
        "ARC":70.82,
        "HellaSwag":88.07,
        "MMLU":64.85,
        "TruthfulQA":67.99,
        "Winogrande":83.82,
        "GSM8K":69.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/una-xaberius-34b-v1beta",
        "Average":74.18,
        "ARC":70.39,
        "HellaSwag":86.77,
        "MMLU":78.15,
        "TruthfulQA":61.45,
        "Winogrande":84.93,
        "GSM8K":63.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":34.39,
        "Model Sha":84.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seyf1elislam\/WestKunai-X-7b",
        "Average":74.18,
        "ARC":71.08,
        "HellaSwag":87.86,
        "MMLU":65.42,
        "TruthfulQA":68.01,
        "Winogrande":82.87,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/Sakura-SOLRCA-Math-Instruct-DPO-v2",
        "Average":74.17,
        "ARC":71.25,
        "HellaSwag":88.52,
        "MMLU":66.13,
        "TruthfulQA":72.16,
        "Winogrande":83.03,
        "GSM8K":63.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/Sakura-SOLAR-Instruct-DPO-v2",
        "Average":74.14,
        "ARC":70.9,
        "HellaSwag":88.41,
        "MMLU":66.48,
        "TruthfulQA":71.86,
        "Winogrande":83.43,
        "GSM8K":63.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ozayezerceli\/Lowke-2x7B-v1",
        "Average":74.14,
        "ARC":71.5,
        "HellaSwag":87.3,
        "MMLU":64.4,
        "TruthfulQA":72.67,
        "Winogrande":82.08,
        "GSM8K":66.87,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Liberated-Qwen1.5-72B",
        "Average":74.13,
        "ARC":65.7,
        "HellaSwag":84.62,
        "MMLU":77.13,
        "TruthfulQA":60.64,
        "Winogrande":83.03,
        "GSM8K":73.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.0,
        "Model Sha":69.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Seraphim-8x10.7B-bf16",
        "Average":74.13,
        "ARC":71.16,
        "HellaSwag":88.68,
        "MMLU":66.26,
        "TruthfulQA":70.66,
        "Winogrande":83.5,
        "GSM8K":64.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":69.92,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/Sakura-SOLRCA-Math-Instruct-DPO-v1",
        "Average":74.13,
        "ARC":71.25,
        "HellaSwag":88.48,
        "MMLU":66.21,
        "TruthfulQA":72.12,
        "Winogrande":82.87,
        "GSM8K":63.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Seraphim-8x10.7B-bf16",
        "Average":74.12,
        "ARC":70.99,
        "HellaSwag":88.72,
        "MMLU":66.16,
        "TruthfulQA":70.77,
        "Winogrande":83.74,
        "GSM8K":64.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":69.92,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/NeuralDaredevil-7B",
        "Average":74.12,
        "ARC":69.88,
        "HellaSwag":87.62,
        "MMLU":65.12,
        "TruthfulQA":66.85,
        "Winogrande":82.08,
        "GSM8K":73.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dddsaty\/SOLAR-Instruct-ko-Adapter-Attach",
        "Average":74.11,
        "ARC":71.08,
        "HellaSwag":88.2,
        "MMLU":66.09,
        "TruthfulQA":71.51,
        "Winogrande":83.5,
        "GSM8K":64.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/SOLAR-10.7b-Instruct-truthy-dpo",
        "Average":74.11,
        "ARC":72.1,
        "HellaSwag":88.44,
        "MMLU":65.45,
        "TruthfulQA":76.75,
        "Winogrande":82.72,
        "GSM8K":59.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Liberated-Qwen1.5-72B",
        "Average":74.11,
        "ARC":65.7,
        "HellaSwag":84.58,
        "MMLU":77.08,
        "TruthfulQA":60.56,
        "Winogrande":83.11,
        "GSM8K":73.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.0,
        "Model Sha":69.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/19B_MATH_DPO",
        "Average":74.1,
        "ARC":71.08,
        "HellaSwag":88.43,
        "MMLU":66.25,
        "TruthfulQA":72.11,
        "Winogrande":82.95,
        "GSM8K":63.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Eric111\/openchat-3.5-0106-128k-DPO_dpo-binarized-NeuralTrix-7B",
        "Average":74.09,
        "ARC":70.99,
        "HellaSwag":87.06,
        "MMLU":65.57,
        "TruthfulQA":68.0,
        "Winogrande":82.87,
        "GSM8K":70.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/Neural-Cosmic-Boy-7B-slerp",
        "Average":74.08,
        "ARC":70.48,
        "HellaSwag":87.65,
        "MMLU":64.92,
        "TruthfulQA":67.1,
        "Winogrande":82.0,
        "GSM8K":72.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BryanSwk\/LaserPipe-7B-SLERP",
        "Average":74.08,
        "ARC":70.82,
        "HellaSwag":87.88,
        "MMLU":64.77,
        "TruthfulQA":65.34,
        "Winogrande":83.27,
        "GSM8K":72.4,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhanushreddy29\/BrokenKeyboard",
        "Average":74.08,
        "ARC":71.25,
        "HellaSwag":88.34,
        "MMLU":66.04,
        "TruthfulQA":71.36,
        "Winogrande":83.19,
        "GSM8K":64.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"brucethemoose\/SUS-Bagel-200K-DARE-Test",
        "Average":74.07,
        "ARC":68.09,
        "HellaSwag":85.38,
        "MMLU":76.98,
        "TruthfulQA":61.2,
        "Winogrande":83.5,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ichigoberry\/MonarchPipe-7B-slerp",
        "Average":74.07,
        "ARC":69.97,
        "HellaSwag":87.66,
        "MMLU":65.3,
        "TruthfulQA":66.4,
        "Winogrande":81.69,
        "GSM8K":73.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"fblgit\/UNA-SOLAR-10.7B-Instruct-v1.0",
        "Average":74.07,
        "ARC":70.73,
        "HellaSwag":88.32,
        "MMLU":66.1,
        "TruthfulQA":72.52,
        "Winogrande":83.35,
        "GSM8K":63.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":10.73,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-POLAR-10.7B-InstructMath-v2",
        "Average":74.07,
        "ARC":70.73,
        "HellaSwag":88.2,
        "MMLU":66.03,
        "TruthfulQA":71.73,
        "Winogrande":82.95,
        "GSM8K":64.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":10.73,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Nous-Hermes-2-SUS-Chat-34B-Slerp",
        "Average":74.06,
        "ARC":66.72,
        "HellaSwag":84.97,
        "MMLU":77.0,
        "TruthfulQA":59.23,
        "Winogrande":83.58,
        "GSM8K":72.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yhyu13\/LMCocktail-10.7B-v1",
        "Average":74.06,
        "ARC":70.65,
        "HellaSwag":88.13,
        "MMLU":66.21,
        "TruthfulQA":71.03,
        "Winogrande":83.35,
        "GSM8K":64.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":10.73,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yhyu13\/LMCocktail-10.7B-v1",
        "Average":74.06,
        "ARC":70.65,
        "HellaSwag":88.13,
        "MMLU":66.21,
        "TruthfulQA":71.03,
        "Winogrande":83.35,
        "GSM8K":64.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/Sakura-SOLRCA-Instruct-DPO",
        "Average":74.05,
        "ARC":71.16,
        "HellaSwag":88.49,
        "MMLU":66.17,
        "TruthfulQA":72.1,
        "Winogrande":82.95,
        "GSM8K":63.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNAversal-2x7B-v1",
        "Average":74.05,
        "ARC":73.38,
        "HellaSwag":87.87,
        "MMLU":63.49,
        "TruthfulQA":69.93,
        "Winogrande":82.08,
        "GSM8K":67.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/SuperMente-7B-v4",
        "Average":74.04,
        "ARC":70.48,
        "HellaSwag":87.63,
        "MMLU":63.35,
        "TruthfulQA":71.46,
        "Winogrande":82.08,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-S3-v0.1",
        "Average":74.03,
        "ARC":70.9,
        "HellaSwag":88.0,
        "MMLU":65.13,
        "TruthfulQA":64.47,
        "Winogrande":83.66,
        "GSM8K":72.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"dddsaty\/Merge_Sakura_Solar",
        "Average":74.03,
        "ARC":70.73,
        "HellaSwag":88.51,
        "MMLU":66.03,
        "TruthfulQA":72.21,
        "Winogrande":82.72,
        "GSM8K":63.99,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/Westest-7B",
        "Average":74.03,
        "ARC":72.18,
        "HellaSwag":88.52,
        "MMLU":64.43,
        "TruthfulQA":66.72,
        "Winogrande":86.58,
        "GSM8K":65.73,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/una-cybertron-7b-v3-OMA",
        "Average":74.01,
        "ARC":73.04,
        "HellaSwag":87.94,
        "MMLU":63.44,
        "TruthfulQA":69.85,
        "Winogrande":82.08,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kekmodel\/StopCarbon-10.7B-v3",
        "Average":74.01,
        "ARC":70.99,
        "HellaSwag":88.57,
        "MMLU":66.13,
        "TruthfulQA":71.94,
        "Winogrande":83.19,
        "GSM8K":63.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"h2m\/mhm-8x7B-FrankenMoE-v1.0",
        "Average":74.01,
        "ARC":70.9,
        "HellaSwag":87.75,
        "MMLU":64.7,
        "TruthfulQA":67.1,
        "Winogrande":82.0,
        "GSM8K":71.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/Laser-WestLake-2x7b",
        "Average":74.0,
        "ARC":72.27,
        "HellaSwag":88.44,
        "MMLU":64.71,
        "TruthfulQA":69.25,
        "Winogrande":85.79,
        "GSM8K":63.53,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/WestOrcaNeuralMarco-DPO-v2-DARETIES-7B",
        "Average":73.98,
        "ARC":71.93,
        "HellaSwag":88.06,
        "MMLU":64.99,
        "TruthfulQA":65.96,
        "Winogrande":82.79,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/WhyAreWeStillHere-7B-slerp",
        "Average":73.96,
        "ARC":71.67,
        "HellaSwag":88.25,
        "MMLU":64.92,
        "TruthfulQA":68.12,
        "Winogrande":85.48,
        "GSM8K":65.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Mayoroya",
        "Average":73.96,
        "ARC":71.08,
        "HellaSwag":87.52,
        "MMLU":65.28,
        "TruthfulQA":64.79,
        "Winogrande":83.43,
        "GSM8K":71.65,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/C0325-L",
        "Average":73.96,
        "ARC":67.58,
        "HellaSwag":87.43,
        "MMLU":74.72,
        "TruthfulQA":58.66,
        "Winogrande":80.82,
        "GSM8K":74.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"CohereForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralMaths-Experiment-7b",
        "Average":73.95,
        "ARC":69.71,
        "HellaSwag":87.48,
        "MMLU":65.01,
        "TruthfulQA":63.83,
        "Winogrande":82.48,
        "GSM8K":75.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/MixTAO-7Bx2-MoE-DPO",
        "Average":73.94,
        "ARC":70.9,
        "HellaSwag":87.12,
        "MMLU":64.72,
        "TruthfulQA":69.34,
        "Winogrande":81.22,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/meow",
        "Average":73.94,
        "ARC":70.48,
        "HellaSwag":88.08,
        "MMLU":66.25,
        "TruthfulQA":70.49,
        "Winogrande":83.43,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/ConfigurableSOLAR-10.7B",
        "Average":73.94,
        "ARC":70.39,
        "HellaSwag":88.03,
        "MMLU":66.44,
        "TruthfulQA":72.34,
        "Winogrande":83.03,
        "GSM8K":63.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"viethq188\/LeoScorpius-7B-Chat-DPO",
        "Average":73.92,
        "ARC":70.48,
        "HellaSwag":87.97,
        "MMLU":65.08,
        "TruthfulQA":68.83,
        "Winogrande":82.08,
        "GSM8K":69.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Aratako\/Beyonder-4x7B-random-lora",
        "Average":73.91,
        "ARC":71.25,
        "HellaSwag":87.4,
        "MMLU":64.78,
        "TruthfulQA":70.49,
        "Winogrande":82.16,
        "GSM8K":67.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Buttercup-4x7B-bf16",
        "Average":73.9,
        "ARC":72.1,
        "HellaSwag":87.74,
        "MMLU":64.58,
        "TruthfulQA":67.2,
        "Winogrande":81.93,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_5-7B-ties",
        "Average":73.89,
        "ARC":71.67,
        "HellaSwag":87.88,
        "MMLU":64.91,
        "TruthfulQA":66.37,
        "Winogrande":83.66,
        "GSM8K":68.84,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"222gate\/bleagle-7b-v0.1-test",
        "Average":73.89,
        "ARC":72.27,
        "HellaSwag":88.24,
        "MMLU":64.37,
        "TruthfulQA":67.83,
        "Winogrande":85.48,
        "GSM8K":65.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"fblgit\/UNA-TheBeagle-7b-v1",
        "Average":73.87,
        "ARC":73.04,
        "HellaSwag":88.0,
        "MMLU":63.48,
        "TruthfulQA":69.85,
        "Winogrande":82.16,
        "GSM8K":66.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/mistral-7b-dpo-v5",
        "Average":73.87,
        "ARC":72.01,
        "HellaSwag":87.57,
        "MMLU":63.85,
        "TruthfulQA":66.86,
        "Winogrande":82.24,
        "GSM8K":70.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/OpenBeagle-11B",
        "Average":73.85,
        "ARC":70.48,
        "HellaSwag":88.76,
        "MMLU":66.94,
        "TruthfulQA":67.01,
        "Winogrande":83.5,
        "GSM8K":66.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"InferenceIllusionist\/Excalibur-7b-DPO",
        "Average":73.84,
        "ARC":70.9,
        "HellaSwag":87.93,
        "MMLU":65.46,
        "TruthfulQA":70.82,
        "Winogrande":82.48,
        "GSM8K":65.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/Westgate",
        "Average":73.84,
        "ARC":71.42,
        "HellaSwag":88.14,
        "MMLU":65.11,
        "TruthfulQA":62.59,
        "Winogrande":85.71,
        "GSM8K":70.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v3",
        "Average":73.83,
        "ARC":71.33,
        "HellaSwag":88.71,
        "MMLU":71.07,
        "TruthfulQA":73.33,
        "Winogrande":81.22,
        "GSM8K":57.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/10.7Bx2_DPO_200",
        "Average":73.83,
        "ARC":70.22,
        "HellaSwag":88.23,
        "MMLU":66.25,
        "TruthfulQA":75.38,
        "Winogrande":81.93,
        "GSM8K":60.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":19.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Nous-Hermes-2-SUS-Chat-2x34B",
        "Average":73.82,
        "ARC":66.81,
        "HellaSwag":85.22,
        "MMLU":76.65,
        "TruthfulQA":57.42,
        "Winogrande":83.74,
        "GSM8K":73.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":60.81,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/MarcMistral-7B",
        "Average":73.81,
        "ARC":71.16,
        "HellaSwag":87.78,
        "MMLU":65.38,
        "TruthfulQA":64.92,
        "Winogrande":81.69,
        "GSM8K":71.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Sao10K\/Typhon-Mixtral-v1",
        "Average":73.81,
        "ARC":71.84,
        "HellaSwag":87.47,
        "MMLU":71.11,
        "TruthfulQA":68.81,
        "Winogrande":81.77,
        "GSM8K":61.87,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/LUNA-SOLARkrautLM-Instruct",
        "Average":73.79,
        "ARC":71.16,
        "HellaSwag":88.28,
        "MMLU":66.11,
        "TruthfulQA":73.37,
        "Winogrande":82.95,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"antiven0m\/finch",
        "Average":73.78,
        "ARC":71.59,
        "HellaSwag":87.87,
        "MMLU":64.81,
        "TruthfulQA":67.96,
        "Winogrande":84.14,
        "GSM8K":66.34,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNAversal-8x7B-v1beta",
        "Average":73.78,
        "ARC":69.8,
        "HellaSwag":86.9,
        "MMLU":70.39,
        "TruthfulQA":71.97,
        "Winogrande":82.0,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":46.7,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Llama2-2x70B",
        "Average":73.77,
        "ARC":72.61,
        "HellaSwag":89.57,
        "MMLU":71.67,
        "TruthfulQA":66.49,
        "Winogrande":84.37,
        "GSM8K":57.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":125.35,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sophosympatheia\/Aurora-Nights-70B-v1.0",
        "Average":73.77,
        "ARC":71.33,
        "HellaSwag":88.33,
        "MMLU":70.47,
        "TruthfulQA":62.81,
        "Winogrande":83.35,
        "GSM8K":66.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"allenai\/tulu-2-dpo-70b",
        "Average":73.77,
        "ARC":72.1,
        "HellaSwag":88.99,
        "MMLU":69.84,
        "TruthfulQA":65.78,
        "Winogrande":83.27,
        "GSM8K":62.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":68.98,
        "Model Sha":142.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/Lumosia-v2-MoE-4x10.7",
        "Average":73.75,
        "ARC":70.39,
        "HellaSwag":87.87,
        "MMLU":66.45,
        "TruthfulQA":68.48,
        "Winogrande":84.21,
        "GSM8K":65.13,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nbeerbower\/SuperBruphin-3x7B",
        "Average":73.75,
        "ARC":71.16,
        "HellaSwag":87.74,
        "MMLU":64.58,
        "TruthfulQA":66.85,
        "Winogrande":81.53,
        "GSM8K":70.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/BeagleMist-7B",
        "Average":73.74,
        "ARC":71.08,
        "HellaSwag":87.47,
        "MMLU":65.29,
        "TruthfulQA":64.83,
        "Winogrande":81.93,
        "GSM8K":71.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-2-Yi-34B",
        "Average":73.74,
        "ARC":66.89,
        "HellaSwag":85.49,
        "MMLU":76.7,
        "TruthfulQA":60.37,
        "Winogrande":82.95,
        "GSM8K":70.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":215.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC56\/Mistral-7B-orca-dpo-12h",
        "Average":73.73,
        "ARC":71.59,
        "HellaSwag":89.01,
        "MMLU":64.23,
        "TruthfulQA":72.15,
        "Winogrande":84.53,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen11X-mistral-7B",
        "Average":73.73,
        "ARC":71.16,
        "HellaSwag":88.23,
        "MMLU":64.81,
        "TruthfulQA":70.18,
        "Winogrande":82.16,
        "GSM8K":65.81,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"decruz07\/kellemar-DPO-Orca-Distilled-7B-SLERP",
        "Average":73.71,
        "ARC":70.48,
        "HellaSwag":87.56,
        "MMLU":65.33,
        "TruthfulQA":64.97,
        "Winogrande":81.93,
        "GSM8K":72.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-34B-dare",
        "Average":73.71,
        "ARC":68.43,
        "HellaSwag":83.61,
        "MMLU":76.4,
        "TruthfulQA":68.5,
        "Winogrande":81.77,
        "GSM8K":63.53,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Nous-Hermes-2-SUS-Chat-34B-Linear",
        "Average":73.69,
        "ARC":66.38,
        "HellaSwag":84.94,
        "MMLU":76.82,
        "TruthfulQA":59.19,
        "Winogrande":82.79,
        "GSM8K":72.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"v1olet\/v1olet_merged_dpo_7B_v3",
        "Average":73.68,
        "ARC":72.61,
        "HellaSwag":87.7,
        "MMLU":63.51,
        "TruthfulQA":69.07,
        "Winogrande":82.32,
        "GSM8K":66.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"GreenNode\/GreenNodeLM-7B-v1olet",
        "Average":73.68,
        "ARC":72.61,
        "HellaSwag":87.7,
        "MMLU":63.51,
        "TruthfulQA":69.07,
        "Winogrande":82.32,
        "GSM8K":66.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/MM-Orc-Vic-bagel-34b-c1000",
        "Average":73.68,
        "ARC":67.32,
        "HellaSwag":83.52,
        "MMLU":76.09,
        "TruthfulQA":60.57,
        "Winogrande":82.32,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Eris_7B",
        "Average":73.68,
        "ARC":71.42,
        "HellaSwag":87.99,
        "MMLU":65.24,
        "TruthfulQA":66.95,
        "Winogrande":84.21,
        "GSM8K":66.26,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ChaoticNeutrals\/Prodigy_7B",
        "Average":73.68,
        "ARC":71.59,
        "HellaSwag":88.09,
        "MMLU":64.92,
        "TruthfulQA":68.57,
        "Winogrande":84.53,
        "GSM8K":64.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AiMavenAi\/MavenWest",
        "Average":73.68,
        "ARC":71.59,
        "HellaSwag":88.44,
        "MMLU":64.63,
        "TruthfulQA":65.29,
        "Winogrande":83.27,
        "GSM8K":68.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/West-Dare-7B",
        "Average":73.65,
        "ARC":71.42,
        "HellaSwag":87.57,
        "MMLU":64.29,
        "TruthfulQA":66.25,
        "Winogrande":84.53,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FelixChao\/WestSeverus-10.7B",
        "Average":73.65,
        "ARC":72.18,
        "HellaSwag":87.47,
        "MMLU":65.06,
        "TruthfulQA":72.3,
        "Winogrande":82.72,
        "GSM8K":62.17,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/NeuDist-Ro-7B",
        "Average":73.64,
        "ARC":71.25,
        "HellaSwag":87.48,
        "MMLU":65.13,
        "TruthfulQA":64.93,
        "Winogrande":82.08,
        "GSM8K":70.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/distilabeled-Marcoro14-7B-slerp",
        "Average":73.63,
        "ARC":70.73,
        "HellaSwag":87.47,
        "MMLU":65.22,
        "TruthfulQA":65.1,
        "Winogrande":82.08,
        "GSM8K":71.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/A0125",
        "Average":73.63,
        "ARC":69.71,
        "HellaSwag":85.0,
        "MMLU":86.64,
        "TruthfulQA":60.27,
        "Winogrande":80.51,
        "GSM8K":59.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Asura_v2",
        "Average":73.62,
        "ARC":70.82,
        "HellaSwag":88.09,
        "MMLU":74.72,
        "TruthfulQA":56.97,
        "Winogrande":85.24,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnowMee\/Mistral-7b-instruct-v0.2-summ-sft-ed2",
        "Average":73.62,
        "ARC":71.42,
        "HellaSwag":87.42,
        "MMLU":64.32,
        "TruthfulQA":64.49,
        "Winogrande":82.87,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-72B",
        "Average":73.6,
        "ARC":65.19,
        "HellaSwag":85.94,
        "MMLU":77.37,
        "TruthfulQA":60.19,
        "Winogrande":82.48,
        "GSM8K":70.43,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":314.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/West-Hermes-7B",
        "Average":73.6,
        "ARC":71.67,
        "HellaSwag":87.6,
        "MMLU":64.83,
        "TruthfulQA":64.26,
        "Winogrande":84.69,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"InferenceIllusionist\/Excalibur-7B",
        "Average":73.6,
        "ARC":69.71,
        "HellaSwag":87.56,
        "MMLU":65.66,
        "TruthfulQA":67.24,
        "Winogrande":82.79,
        "GSM8K":68.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rombodawg\/Open_Gpt4_8x7B_v0.2",
        "Average":73.59,
        "ARC":68.69,
        "HellaSwag":86.16,
        "MMLU":72.07,
        "TruthfulQA":71.92,
        "Winogrande":83.58,
        "GSM8K":59.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":46.7,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/Umbra-v2.1-MoE-4x10.7",
        "Average":73.59,
        "ARC":69.11,
        "HellaSwag":87.57,
        "MMLU":66.48,
        "TruthfulQA":66.57,
        "Winogrande":83.11,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/MistralTrix-SLERP",
        "Average":73.58,
        "ARC":70.82,
        "HellaSwag":87.54,
        "MMLU":64.98,
        "TruthfulQA":65.35,
        "Winogrande":81.69,
        "GSM8K":71.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-spef",
        "Average":73.58,
        "ARC":69.88,
        "HellaSwag":87.34,
        "MMLU":63.27,
        "TruthfulQA":69.01,
        "Winogrande":83.98,
        "GSM8K":68.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/NeuralMarcoro14-7B",
        "Average":73.57,
        "ARC":71.42,
        "HellaSwag":87.59,
        "MMLU":64.84,
        "TruthfulQA":65.64,
        "Winogrande":81.22,
        "GSM8K":70.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":38.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Kuno-Lake-7B",
        "Average":73.56,
        "ARC":71.84,
        "HellaSwag":88.15,
        "MMLU":64.76,
        "TruthfulQA":66.83,
        "Winogrande":84.45,
        "GSM8K":65.35,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment7-7B",
        "Average":73.55,
        "ARC":71.84,
        "HellaSwag":88.04,
        "MMLU":65.25,
        "TruthfulQA":70.59,
        "Winogrande":80.82,
        "GSM8K":64.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-7B",
        "Average":73.54,
        "ARC":70.05,
        "HellaSwag":87.5,
        "MMLU":65.06,
        "TruthfulQA":65.43,
        "Winogrande":82.16,
        "GSM8K":71.04,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/SOLAR-10.7b-Instruct-dpo",
        "Average":73.54,
        "ARC":71.76,
        "HellaSwag":88.08,
        "MMLU":66.06,
        "TruthfulQA":71.98,
        "Winogrande":82.32,
        "GSM8K":61.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_52-7B-dare_ties",
        "Average":73.51,
        "ARC":69.03,
        "HellaSwag":87.15,
        "MMLU":64.94,
        "TruthfulQA":65.76,
        "Winogrande":81.93,
        "GSM8K":72.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seyf1elislam\/WestKunai-Hermes-7b",
        "Average":73.51,
        "ARC":71.16,
        "HellaSwag":87.76,
        "MMLU":64.77,
        "TruthfulQA":65.25,
        "Winogrande":83.03,
        "GSM8K":69.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/NexoNimbus-7B",
        "Average":73.5,
        "ARC":70.82,
        "HellaSwag":87.86,
        "MMLU":64.69,
        "TruthfulQA":62.43,
        "Winogrande":84.85,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A0127",
        "Average":73.49,
        "ARC":68.6,
        "HellaSwag":84.51,
        "MMLU":84.9,
        "TruthfulQA":58.38,
        "Winogrande":79.87,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment15-7B",
        "Average":73.48,
        "ARC":72.18,
        "HellaSwag":88.68,
        "MMLU":60.01,
        "TruthfulQA":77.05,
        "Winogrande":84.21,
        "GSM8K":58.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment10-7B",
        "Average":73.47,
        "ARC":72.18,
        "HellaSwag":87.96,
        "MMLU":65.32,
        "TruthfulQA":71.1,
        "Winogrande":80.74,
        "GSM8K":63.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment8-7B",
        "Average":73.47,
        "ARC":72.1,
        "HellaSwag":88.13,
        "MMLU":65.25,
        "TruthfulQA":70.25,
        "Winogrande":80.66,
        "GSM8K":64.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-7B-0210-dare",
        "Average":73.46,
        "ARC":70.9,
        "HellaSwag":88.8,
        "MMLU":61.69,
        "TruthfulQA":71.46,
        "Winogrande":84.53,
        "GSM8K":63.38,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mychen76\/mistral-7b-merged-dare_6x7",
        "Average":73.46,
        "ARC":69.62,
        "HellaSwag":87.04,
        "MMLU":65.18,
        "TruthfulQA":66.98,
        "Winogrande":80.58,
        "GSM8K":71.34,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Neuronovo\/neuronovo-7B-v0.2",
        "Average":73.44,
        "ARC":73.04,
        "HellaSwag":88.32,
        "MMLU":65.15,
        "TruthfulQA":71.02,
        "Winogrande":80.66,
        "GSM8K":62.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/bruphin-kappa",
        "Average":73.44,
        "ARC":70.05,
        "HellaSwag":87.38,
        "MMLU":64.9,
        "TruthfulQA":65.99,
        "Winogrande":82.95,
        "GSM8K":69.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cloudyu\/Mixtral-8x7B-Instruct-v0.1-DPO",
        "Average":73.44,
        "ARC":69.8,
        "HellaSwag":87.83,
        "MMLU":71.05,
        "TruthfulQA":69.18,
        "Winogrande":81.37,
        "GSM8K":61.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cloudyu\/Mixtral_7Bx2_MoE",
        "Average":73.43,
        "ARC":71.25,
        "HellaSwag":87.45,
        "MMLU":64.98,
        "TruthfulQA":67.23,
        "Winogrande":81.22,
        "GSM8K":68.46,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Neuronovo\/neuronovo-9B-v0.4",
        "Average":73.42,
        "ARC":72.44,
        "HellaSwag":88.33,
        "MMLU":65.24,
        "TruthfulQA":71.07,
        "Winogrande":80.66,
        "GSM8K":62.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/BruinHermes",
        "Average":73.42,
        "ARC":70.14,
        "HellaSwag":87.07,
        "MMLU":65.22,
        "TruthfulQA":65.6,
        "Winogrande":81.29,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Prima-LelantaclesV6-7b",
        "Average":73.41,
        "ARC":71.5,
        "HellaSwag":87.65,
        "MMLU":64.64,
        "TruthfulQA":64.29,
        "Winogrande":84.85,
        "GSM8K":67.55,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/distilabeled-Marcoro14-7B-slerp-full",
        "Average":73.4,
        "ARC":70.65,
        "HellaSwag":87.55,
        "MMLU":65.33,
        "TruthfulQA":64.21,
        "Winogrande":82.0,
        "GSM8K":70.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Steelskull\/Umbra-MoE-4x10.7",
        "Average":73.4,
        "ARC":70.31,
        "HellaSwag":87.81,
        "MMLU":66.42,
        "TruthfulQA":67.82,
        "Winogrande":83.27,
        "GSM8K":64.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/MistralTrix-v1",
        "Average":73.39,
        "ARC":72.27,
        "HellaSwag":88.33,
        "MMLU":65.24,
        "TruthfulQA":70.73,
        "Winogrande":80.98,
        "GSM8K":62.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":106.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Mixtral_7Bx5_MoE_30B",
        "Average":73.39,
        "ARC":69.97,
        "HellaSwag":86.82,
        "MMLU":64.42,
        "TruthfulQA":65.97,
        "Winogrande":80.98,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":29.79,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment9-7B",
        "Average":73.39,
        "ARC":72.01,
        "HellaSwag":88.06,
        "MMLU":65.32,
        "TruthfulQA":70.42,
        "Winogrande":80.74,
        "GSM8K":63.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_8-7B-slerp",
        "Average":73.39,
        "ARC":71.08,
        "HellaSwag":87.75,
        "MMLU":65.26,
        "TruthfulQA":64.52,
        "Winogrande":84.45,
        "GSM8K":67.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment1-7B",
        "Average":73.39,
        "ARC":72.53,
        "HellaSwag":88.17,
        "MMLU":65.28,
        "TruthfulQA":69.98,
        "Winogrande":80.82,
        "GSM8K":63.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment2-7B",
        "Average":73.38,
        "ARC":72.18,
        "HellaSwag":88.15,
        "MMLU":65.1,
        "TruthfulQA":69.97,
        "Winogrande":81.22,
        "GSM8K":63.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/Experiment4-7B",
        "Average":73.38,
        "ARC":72.18,
        "HellaSwag":88.09,
        "MMLU":65.03,
        "TruthfulQA":70.39,
        "Winogrande":81.14,
        "GSM8K":63.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/caTUNABeagle",
        "Average":73.38,
        "ARC":70.05,
        "HellaSwag":87.35,
        "MMLU":65.02,
        "TruthfulQA":65.31,
        "Winogrande":81.22,
        "GSM8K":71.34,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/SOLAR-math-2x10.7b",
        "Average":73.37,
        "ARC":68.43,
        "HellaSwag":86.31,
        "MMLU":66.9,
        "TruthfulQA":64.21,
        "Winogrande":83.35,
        "GSM8K":71.04,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":19.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Sao10K\/Franziska-Mixtral-v1",
        "Average":73.36,
        "ARC":71.76,
        "HellaSwag":87.37,
        "MMLU":69.78,
        "TruthfulQA":70.07,
        "Winogrande":80.9,
        "GSM8K":60.27,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Daredevil-7B",
        "Average":73.36,
        "ARC":69.37,
        "HellaSwag":87.17,
        "MMLU":65.3,
        "TruthfulQA":64.09,
        "Winogrande":81.29,
        "GSM8K":72.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Average":73.35,
        "ARC":71.08,
        "HellaSwag":87.29,
        "MMLU":72.17,
        "TruthfulQA":54.83,
        "Winogrande":83.11,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":320.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen13X-mistral-7B",
        "Average":73.35,
        "ARC":69.88,
        "HellaSwag":87.28,
        "MMLU":64.99,
        "TruthfulQA":66.74,
        "Winogrande":82.0,
        "GSM8K":69.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Eris_PrimeV4-Vision-7B",
        "Average":73.35,
        "ARC":70.22,
        "HellaSwag":87.56,
        "MMLU":65.01,
        "TruthfulQA":67.76,
        "Winogrande":81.69,
        "GSM8K":67.85,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/DaturaCookie_7B",
        "Average":73.35,
        "ARC":71.25,
        "HellaSwag":88.0,
        "MMLU":64.28,
        "TruthfulQA":68.48,
        "Winogrande":82.79,
        "GSM8K":65.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/MoE-StrangeMerges-2x7B",
        "Average":73.34,
        "ARC":70.82,
        "HellaSwag":87.83,
        "MMLU":65.04,
        "TruthfulQA":65.86,
        "Winogrande":82.79,
        "GSM8K":67.7,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/kellemar-KrishnaHercules-0.1-7b-slerp",
        "Average":73.33,
        "ARC":70.22,
        "HellaSwag":87.29,
        "MMLU":65.61,
        "TruthfulQA":63.03,
        "Winogrande":82.24,
        "GSM8K":71.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ryandt\/MusingCaterpillar",
        "Average":73.33,
        "ARC":72.53,
        "HellaSwag":88.34,
        "MMLU":65.26,
        "TruthfulQA":70.93,
        "Winogrande":80.66,
        "GSM8K":62.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b-v2",
        "Average":73.33,
        "ARC":70.48,
        "HellaSwag":87.59,
        "MMLU":65.09,
        "TruthfulQA":60.63,
        "Winogrande":84.29,
        "GSM8K":71.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cloudyu\/Mixtral_7Bx6_MoE_35B",
        "Average":73.32,
        "ARC":70.14,
        "HellaSwag":86.77,
        "MMLU":64.74,
        "TruthfulQA":65.79,
        "Winogrande":81.06,
        "GSM8K":71.42,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_9-7B-dare_ties",
        "Average":73.32,
        "ARC":70.31,
        "HellaSwag":87.46,
        "MMLU":65.08,
        "TruthfulQA":65.08,
        "Winogrande":81.37,
        "GSM8K":70.58,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/MixtureofMerges-MoE-2x7bRP-v8",
        "Average":73.31,
        "ARC":71.33,
        "HellaSwag":88.06,
        "MMLU":64.33,
        "TruthfulQA":68.69,
        "Winogrande":82.95,
        "GSM8K":64.52,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Mixtral_7Bx6_MoE_35B",
        "Average":73.31,
        "ARC":69.97,
        "HellaSwag":86.82,
        "MMLU":64.91,
        "TruthfulQA":65.77,
        "Winogrande":81.14,
        "GSM8K":71.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/Peagle-9b",
        "Average":73.3,
        "ARC":71.5,
        "HellaSwag":87.34,
        "MMLU":64.36,
        "TruthfulQA":70.16,
        "Winogrande":80.35,
        "GSM8K":66.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibndias\/Nous-Hermes-2-MoE-2x34B",
        "Average":73.3,
        "ARC":66.64,
        "HellaSwag":85.73,
        "MMLU":76.49,
        "TruthfulQA":58.08,
        "Winogrande":83.35,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":60.81,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/FrankenBeagle-SmallOverlap-test",
        "Average":73.3,
        "ARC":72.01,
        "HellaSwag":88.16,
        "MMLU":64.71,
        "TruthfulQA":69.69,
        "Winogrande":81.85,
        "GSM8K":63.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.55,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zyh3826\/GML-Mistral-merged-v1",
        "Average":73.3,
        "ARC":71.25,
        "HellaSwag":87.88,
        "MMLU":65.42,
        "TruthfulQA":69.28,
        "Winogrande":80.98,
        "GSM8K":64.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"GreenNode\/GreenNodeLM-7B-v2leo",
        "Average":73.29,
        "ARC":69.8,
        "HellaSwag":88.02,
        "MMLU":65.0,
        "TruthfulQA":67.83,
        "Winogrande":82.0,
        "GSM8K":67.1,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Neuronovo\/neuronovo-7B-v0.3",
        "Average":73.29,
        "ARC":72.7,
        "HellaSwag":88.26,
        "MMLU":65.1,
        "TruthfulQA":71.35,
        "Winogrande":80.9,
        "GSM8K":61.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"gradientai\/v-alpha-tross",
        "Average":73.28,
        "ARC":71.93,
        "HellaSwag":86.82,
        "MMLU":70.38,
        "TruthfulQA":65.21,
        "Winogrande":83.58,
        "GSM8K":61.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Mistral-7b-instruct-v0.2-private-edw2",
        "Average":73.28,
        "ARC":69.88,
        "HellaSwag":87.33,
        "MMLU":64.85,
        "TruthfulQA":63.89,
        "Winogrande":80.66,
        "GSM8K":73.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mychen76\/mistral-7b-merged-dare",
        "Average":73.28,
        "ARC":69.71,
        "HellaSwag":87.05,
        "MMLU":65.07,
        "TruthfulQA":63.24,
        "Winogrande":81.61,
        "GSM8K":73.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seyf1elislam\/WestKunai-XD-7b",
        "Average":73.27,
        "ARC":71.25,
        "HellaSwag":87.59,
        "MMLU":64.69,
        "TruthfulQA":67.29,
        "Winogrande":82.24,
        "GSM8K":66.57,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eric111\/NeuralBeagleOpenChat",
        "Average":73.26,
        "ARC":70.31,
        "HellaSwag":86.26,
        "MMLU":65.62,
        "TruthfulQA":60.91,
        "Winogrande":82.08,
        "GSM8K":74.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"carsenk\/flippa-exp26-v3-7b",
        "Average":73.25,
        "ARC":68.09,
        "HellaSwag":86.5,
        "MMLU":64.42,
        "TruthfulQA":67.35,
        "Winogrande":84.77,
        "GSM8K":68.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"occultml\/CatMarcoro14-7B-slerp",
        "Average":73.25,
        "ARC":69.37,
        "HellaSwag":86.92,
        "MMLU":65.27,
        "TruthfulQA":63.24,
        "Winogrande":81.69,
        "GSM8K":73.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Copium-Cola-9B",
        "Average":73.25,
        "ARC":71.42,
        "HellaSwag":87.42,
        "MMLU":64.83,
        "TruthfulQA":68.6,
        "Winogrande":83.98,
        "GSM8K":63.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Eukaryote-8x7B-bf16",
        "Average":73.23,
        "ARC":69.45,
        "HellaSwag":87.29,
        "MMLU":65.15,
        "TruthfulQA":63.17,
        "Winogrande":82.4,
        "GSM8K":71.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ZoidBB\/MultiKory-0.1-4x11b-pre1",
        "Average":73.23,
        "ARC":72.87,
        "HellaSwag":87.9,
        "MMLU":64.6,
        "TruthfulQA":67.67,
        "Winogrande":85.4,
        "GSM8K":60.96,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ZoidBB\/Kory-0.1-11b-pre1",
        "Average":73.23,
        "ARC":72.87,
        "HellaSwag":87.9,
        "MMLU":64.59,
        "TruthfulQA":67.68,
        "Winogrande":85.4,
        "GSM8K":60.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/WinterGoddess-1.4x-70B-L2",
        "Average":73.23,
        "ARC":72.78,
        "HellaSwag":90.11,
        "MMLU":71.12,
        "TruthfulQA":65.76,
        "Winogrande":85.0,
        "GSM8K":54.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/BurningBruce-SOLAR-8x10.7B-bf16",
        "Average":73.23,
        "ARC":69.11,
        "HellaSwag":87.81,
        "MMLU":66.27,
        "TruthfulQA":68.67,
        "Winogrande":83.35,
        "GSM8K":64.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":69.92,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"SUSTech\/SUS-Chat-34B",
        "Average":73.22,
        "ARC":66.3,
        "HellaSwag":83.91,
        "MMLU":76.41,
        "TruthfulQA":57.04,
        "Winogrande":83.5,
        "GSM8K":72.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":111.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/SOLAR-10.7B-NahIdWin",
        "Average":73.21,
        "ARC":64.51,
        "HellaSwag":85.67,
        "MMLU":64.17,
        "TruthfulQA":76.73,
        "Winogrande":80.51,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dillfrescott\/trinity-medium",
        "Average":73.21,
        "ARC":71.5,
        "HellaSwag":86.99,
        "MMLU":65.04,
        "TruthfulQA":69.54,
        "Winogrande":81.14,
        "GSM8K":65.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Vasanth\/Valor_Macaroni_moe",
        "Average":73.2,
        "ARC":70.31,
        "HellaSwag":86.62,
        "MMLU":64.57,
        "TruthfulQA":64.65,
        "Winogrande":82.24,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/7Bx4_DPO",
        "Average":73.2,
        "ARC":69.37,
        "HellaSwag":86.89,
        "MMLU":64.73,
        "TruthfulQA":65.66,
        "Winogrande":80.58,
        "GSM8K":71.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":24.15,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/notus-8x7b-experiment",
        "Average":73.18,
        "ARC":70.99,
        "HellaSwag":87.73,
        "MMLU":71.33,
        "TruthfulQA":65.79,
        "Winogrande":81.61,
        "GSM8K":61.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Cedaros\/BetaMonarch-10.7B",
        "Average":73.18,
        "ARC":72.7,
        "HellaSwag":88.37,
        "MMLU":64.37,
        "TruthfulQA":76.85,
        "Winogrande":83.35,
        "GSM8K":53.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/MistralTrixTest",
        "Average":73.17,
        "ARC":72.53,
        "HellaSwag":88.4,
        "MMLU":65.22,
        "TruthfulQA":70.77,
        "Winogrande":81.37,
        "GSM8K":60.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/Orca-SOLAR-4x10.7b",
        "Average":73.17,
        "ARC":68.52,
        "HellaSwag":86.78,
        "MMLU":67.03,
        "TruthfulQA":64.54,
        "Winogrande":83.9,
        "GSM8K":68.23,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YouKnwMe\/Mistral-7b-instruct-v0.2-private-edw2",
        "Average":73.17,
        "ARC":69.8,
        "HellaSwag":87.32,
        "MMLU":64.9,
        "TruthfulQA":63.83,
        "Winogrande":80.9,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/WestSeverus-7B",
        "Average":73.16,
        "ARC":70.31,
        "HellaSwag":87.46,
        "MMLU":64.98,
        "TruthfulQA":62.89,
        "Winogrande":83.58,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gradientai\/v-alpha-tross",
        "Average":73.16,
        "ARC":71.84,
        "HellaSwag":86.84,
        "MMLU":70.44,
        "TruthfulQA":65.22,
        "Winogrande":83.11,
        "GSM8K":61.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0204",
        "Average":73.14,
        "ARC":70.31,
        "HellaSwag":84.42,
        "MMLU":86.86,
        "TruthfulQA":57.94,
        "Winogrande":80.82,
        "GSM8K":58.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Luna-2x7B-MoE",
        "Average":73.13,
        "ARC":71.16,
        "HellaSwag":88.12,
        "MMLU":64.41,
        "TruthfulQA":68.66,
        "Winogrande":83.27,
        "GSM8K":63.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"brucethemoose\/Yi-34B-200K-DARE-merge-v7",
        "Average":73.12,
        "ARC":68.09,
        "HellaSwag":85.99,
        "MMLU":77.3,
        "TruthfulQA":58.9,
        "Winogrande":83.11,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Average":73.12,
        "ARC":71.42,
        "HellaSwag":87.21,
        "MMLU":72.28,
        "TruthfulQA":54.53,
        "Winogrande":82.64,
        "GSM8K":70.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":320.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AurelPx\/Dare-k-7B-ties",
        "Average":73.12,
        "ARC":69.11,
        "HellaSwag":87.08,
        "MMLU":65.02,
        "TruthfulQA":63.91,
        "Winogrande":82.0,
        "GSM8K":71.57,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"samir-fama\/SamirGPT-v1",
        "Average":73.11,
        "ARC":69.54,
        "HellaSwag":87.04,
        "MMLU":65.3,
        "TruthfulQA":63.37,
        "Winogrande":81.69,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rombodawg\/Open_Gpt4_8x7B",
        "Average":73.1,
        "ARC":69.28,
        "HellaSwag":86.77,
        "MMLU":71.2,
        "TruthfulQA":70.39,
        "Winogrande":81.77,
        "GSM8K":59.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Slerp-CM-mist-dpo",
        "Average":73.1,
        "ARC":69.62,
        "HellaSwag":87.09,
        "MMLU":64.81,
        "TruthfulQA":62.82,
        "Winogrande":81.45,
        "GSM8K":72.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vishnukv\/newmerge",
        "Average":73.1,
        "ARC":69.2,
        "HellaSwag":87.05,
        "MMLU":64.93,
        "TruthfulQA":65.99,
        "Winogrande":82.87,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Lelantos-DPO-7B",
        "Average":73.09,
        "ARC":71.08,
        "HellaSwag":87.22,
        "MMLU":64.0,
        "TruthfulQA":67.77,
        "Winogrande":80.03,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/Umbra-v3-MoE-4x11b",
        "Average":73.09,
        "ARC":68.43,
        "HellaSwag":87.83,
        "MMLU":65.99,
        "TruthfulQA":69.3,
        "Winogrande":83.9,
        "GSM8K":63.08,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ChaoticNeutrals\/Prima-LelantaclesV5-7b",
        "Average":73.09,
        "ARC":70.65,
        "HellaSwag":87.87,
        "MMLU":64.52,
        "TruthfulQA":68.26,
        "Winogrande":82.4,
        "GSM8K":64.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/Einstein-4d-Marcoro14-nddmpk-KrishnaHercules-7b-slerp",
        "Average":73.08,
        "ARC":69.71,
        "HellaSwag":87.04,
        "MMLU":65.32,
        "TruthfulQA":64.37,
        "Winogrande":81.37,
        "GSM8K":70.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Mayo",
        "Average":73.08,
        "ARC":70.14,
        "HellaSwag":86.27,
        "MMLU":65.58,
        "TruthfulQA":60.93,
        "Winogrande":82.16,
        "GSM8K":73.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b-v3",
        "Average":73.07,
        "ARC":70.39,
        "HellaSwag":87.65,
        "MMLU":65.07,
        "TruthfulQA":59.7,
        "Winogrande":84.06,
        "GSM8K":71.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Pasta-Lake-7b",
        "Average":73.07,
        "ARC":70.82,
        "HellaSwag":87.91,
        "MMLU":64.41,
        "TruthfulQA":68.28,
        "Winogrande":82.64,
        "GSM8K":64.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/notux-8x7b-v1-epoch-2",
        "Average":73.05,
        "ARC":70.65,
        "HellaSwag":87.8,
        "MMLU":71.43,
        "TruthfulQA":65.97,
        "Winogrande":82.08,
        "GSM8K":60.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/34b-beta",
        "Average":73.04,
        "ARC":70.56,
        "HellaSwag":84.2,
        "MMLU":85.6,
        "TruthfulQA":58.38,
        "Winogrande":81.29,
        "GSM8K":58.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jsfs11\/SnorkelWestBeagle-DARETIES-7B",
        "Average":73.03,
        "ARC":71.16,
        "HellaSwag":87.35,
        "MMLU":64.35,
        "TruthfulQA":70.05,
        "Winogrande":83.19,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Prima-LelantaclesV7-7b",
        "Average":73.03,
        "ARC":70.65,
        "HellaSwag":87.94,
        "MMLU":64.67,
        "TruthfulQA":67.45,
        "Winogrande":84.69,
        "GSM8K":62.77,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shadowml\/Marcoro14-7B-ties",
        "Average":73.01,
        "ARC":69.8,
        "HellaSwag":87.13,
        "MMLU":65.11,
        "TruthfulQA":63.54,
        "Winogrande":81.61,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Marcoro14-7B-slerp",
        "Average":73.01,
        "ARC":69.8,
        "HellaSwag":87.13,
        "MMLU":65.11,
        "TruthfulQA":63.54,
        "Winogrande":81.61,
        "GSM8K":70.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AbacusResearch\/RasGulla1-7b",
        "Average":73.0,
        "ARC":69.71,
        "HellaSwag":87.4,
        "MMLU":64.94,
        "TruthfulQA":63.31,
        "Winogrande":80.9,
        "GSM8K":71.72,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen9-mistral-7B",
        "Average":73.0,
        "ARC":69.62,
        "HellaSwag":87.74,
        "MMLU":64.41,
        "TruthfulQA":68.54,
        "Winogrande":81.93,
        "GSM8K":65.73,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/7Bx4_DPO_2e",
        "Average":72.99,
        "ARC":68.94,
        "HellaSwag":86.8,
        "MMLU":64.5,
        "TruthfulQA":65.6,
        "Winogrande":80.74,
        "GSM8K":71.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/RoyalNoroichi-7B-slerp",
        "Average":72.98,
        "ARC":70.48,
        "HellaSwag":87.38,
        "MMLU":64.78,
        "TruthfulQA":66.28,
        "Winogrande":82.24,
        "GSM8K":66.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"argilla\/notux-8x7b-v1",
        "Average":72.97,
        "ARC":70.65,
        "HellaSwag":87.72,
        "MMLU":71.39,
        "TruthfulQA":66.21,
        "Winogrande":80.74,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":161.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Test-Instruct-Solar-v1",
        "Average":72.97,
        "ARC":70.39,
        "HellaSwag":87.76,
        "MMLU":66.33,
        "TruthfulQA":62.64,
        "Winogrande":83.9,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/whattest",
        "Average":72.96,
        "ARC":66.81,
        "HellaSwag":84.43,
        "MMLU":76.59,
        "TruthfulQA":58.04,
        "Winogrande":82.48,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/Cognate-7B-slerp",
        "Average":72.96,
        "ARC":70.48,
        "HellaSwag":87.33,
        "MMLU":64.85,
        "TruthfulQA":65.16,
        "Winogrande":82.56,
        "GSM8K":67.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/NeuralBeagle-11B",
        "Average":72.95,
        "ARC":73.29,
        "HellaSwag":87.61,
        "MMLU":63.8,
        "TruthfulQA":71.36,
        "Winogrande":82.64,
        "GSM8K":58.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":6.0
    },
    {
        "T":"?",
        "Model":"jan-ai\/Pandora-10.7B-v1",
        "Average":72.93,
        "ARC":71.08,
        "HellaSwag":87.06,
        "MMLU":64.95,
        "TruthfulQA":70.67,
        "Winogrande":81.37,
        "GSM8K":62.47,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"The-Face-Of-Goonery\/HuginnV5.5-12.6B",
        "Average":72.93,
        "ARC":72.01,
        "HellaSwag":86.7,
        "MMLU":64.5,
        "TruthfulQA":70.45,
        "Winogrande":81.29,
        "GSM8K":62.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":12.91,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralKukedlc-7B-Labonned",
        "Average":72.92,
        "ARC":70.82,
        "HellaSwag":86.99,
        "MMLU":64.49,
        "TruthfulQA":64.1,
        "Winogrande":80.98,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bardsai\/jaskier-7b-dpo",
        "Average":72.91,
        "ARC":70.82,
        "HellaSwag":87.02,
        "MMLU":64.67,
        "TruthfulQA":64.41,
        "Winogrande":80.19,
        "GSM8K":70.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen2-beta-72B",
        "Average":72.91,
        "ARC":65.87,
        "HellaSwag":85.99,
        "MMLU":77.2,
        "TruthfulQA":59.61,
        "Winogrande":83.03,
        "GSM8K":65.73,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-72B",
        "Average":72.91,
        "ARC":65.87,
        "HellaSwag":85.99,
        "MMLU":77.2,
        "TruthfulQA":59.61,
        "Winogrande":83.03,
        "GSM8K":65.73,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"logicker\/SkkuDS-DPO-72B-v1",
        "Average":72.89,
        "ARC":65.96,
        "HellaSwag":86.0,
        "MMLU":77.33,
        "TruthfulQA":59.54,
        "Winogrande":82.64,
        "GSM8K":65.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-Mixtral-8x7B-Instruct",
        "Average":72.89,
        "ARC":70.48,
        "HellaSwag":87.75,
        "MMLU":71.37,
        "TruthfulQA":65.71,
        "Winogrande":81.22,
        "GSM8K":60.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.2",
        "Average":72.88,
        "ARC":68.86,
        "HellaSwag":87.01,
        "MMLU":65.05,
        "TruthfulQA":64.19,
        "Winogrande":81.69,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/NeuralPearlBeagle",
        "Average":72.88,
        "ARC":68.26,
        "HellaSwag":87.25,
        "MMLU":64.05,
        "TruthfulQA":62.85,
        "Winogrande":81.69,
        "GSM8K":73.16,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"samir-fama\/FernandoGPT-v1",
        "Average":72.87,
        "ARC":69.45,
        "HellaSwag":86.94,
        "MMLU":65.19,
        "TruthfulQA":61.18,
        "Winogrande":81.14,
        "GSM8K":73.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Bianca-7b",
        "Average":72.87,
        "ARC":69.71,
        "HellaSwag":86.11,
        "MMLU":65.25,
        "TruthfulQA":63.95,
        "Winogrande":80.9,
        "GSM8K":71.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kukedlc\/NeuralKukedlc-7B-Labonned",
        "Average":72.84,
        "ARC":70.73,
        "HellaSwag":86.9,
        "MMLU":64.58,
        "TruthfulQA":64.09,
        "Winogrande":81.22,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Sirius-10B",
        "Average":72.83,
        "ARC":71.93,
        "HellaSwag":87.32,
        "MMLU":64.73,
        "TruthfulQA":68.1,
        "Winogrande":82.79,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen3X",
        "Average":72.82,
        "ARC":70.14,
        "HellaSwag":87.37,
        "MMLU":64.69,
        "TruthfulQA":66.37,
        "Winogrande":80.98,
        "GSM8K":67.4,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Himitsui\/Kaiju-11B",
        "Average":72.82,
        "ARC":69.97,
        "HellaSwag":87.72,
        "MMLU":66.79,
        "TruthfulQA":62.15,
        "Winogrande":83.5,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/CM-14",
        "Average":72.82,
        "ARC":69.37,
        "HellaSwag":86.97,
        "MMLU":65.37,
        "TruthfulQA":61.9,
        "Winogrande":81.06,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Bianca-7b",
        "Average":72.82,
        "ARC":69.45,
        "HellaSwag":86.08,
        "MMLU":65.08,
        "TruthfulQA":64.04,
        "Winogrande":81.06,
        "GSM8K":71.19,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/O0201",
        "Average":72.81,
        "ARC":67.83,
        "HellaSwag":84.49,
        "MMLU":89.35,
        "TruthfulQA":58.63,
        "Winogrande":79.79,
        "GSM8K":56.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PetroGPT\/Severus-7B-DPO",
        "Average":72.81,
        "ARC":70.22,
        "HellaSwag":87.09,
        "MMLU":64.93,
        "TruthfulQA":64.41,
        "Winogrande":80.66,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"S-miguel\/The-Trinity-Coder-7B",
        "Average":72.81,
        "ARC":69.37,
        "HellaSwag":86.17,
        "MMLU":64.9,
        "TruthfulQA":61.25,
        "Winogrande":81.77,
        "GSM8K":73.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"v1olet\/v1olet_marcoroni-go-bruins-merge-7B",
        "Average":72.81,
        "ARC":70.05,
        "HellaSwag":87.17,
        "MMLU":65.17,
        "TruthfulQA":61.42,
        "Winogrande":81.45,
        "GSM8K":71.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_16-7B-slerp",
        "Average":72.8,
        "ARC":69.03,
        "HellaSwag":87.15,
        "MMLU":65.65,
        "TruthfulQA":62.97,
        "Winogrande":81.29,
        "GSM8K":70.74,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"logicker\/SkkuDS-DPO-72B-v3",
        "Average":72.8,
        "ARC":66.04,
        "HellaSwag":86.11,
        "MMLU":77.34,
        "TruthfulQA":59.73,
        "Winogrande":82.64,
        "GSM8K":64.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PSanni\/MPOMixtral-8x7B-Instruct-v0.1",
        "Average":72.8,
        "ARC":70.99,
        "HellaSwag":87.95,
        "MMLU":70.26,
        "TruthfulQA":66.52,
        "Winogrande":82.56,
        "GSM8K":58.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/piccolo-8x7b",
        "Average":72.8,
        "ARC":69.62,
        "HellaSwag":86.98,
        "MMLU":64.13,
        "TruthfulQA":64.17,
        "Winogrande":79.87,
        "GSM8K":72.02,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/19B_TRUTH_DPO",
        "Average":72.8,
        "ARC":71.67,
        "HellaSwag":88.63,
        "MMLU":65.78,
        "TruthfulQA":72.23,
        "Winogrande":82.16,
        "GSM8K":56.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/A0124",
        "Average":72.79,
        "ARC":67.83,
        "HellaSwag":84.71,
        "MMLU":83.7,
        "TruthfulQA":56.52,
        "Winogrande":80.74,
        "GSM8K":63.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Lelantos-7B",
        "Average":72.78,
        "ARC":69.03,
        "HellaSwag":86.9,
        "MMLU":64.1,
        "TruthfulQA":65.18,
        "Winogrande":80.66,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v3.3",
        "Average":72.76,
        "ARC":70.39,
        "HellaSwag":87.88,
        "MMLU":71.43,
        "TruthfulQA":67.41,
        "Winogrande":81.22,
        "GSM8K":58.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/RoyalMaid-7B-slerp",
        "Average":72.75,
        "ARC":70.39,
        "HellaSwag":87.25,
        "MMLU":64.72,
        "TruthfulQA":64.18,
        "Winogrande":82.4,
        "GSM8K":67.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/OpenCM-14",
        "Average":72.75,
        "ARC":69.28,
        "HellaSwag":86.89,
        "MMLU":65.01,
        "TruthfulQA":61.07,
        "Winogrande":81.29,
        "GSM8K":72.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-7B-slerp",
        "Average":72.75,
        "ARC":68.0,
        "HellaSwag":87.16,
        "MMLU":64.04,
        "TruthfulQA":62.35,
        "Winogrande":81.29,
        "GSM8K":73.62,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Sao10K\/Skadi-Mixtral-v1",
        "Average":72.74,
        "ARC":70.14,
        "HellaSwag":87.65,
        "MMLU":72.19,
        "TruthfulQA":60.43,
        "Winogrande":81.29,
        "GSM8K":64.75,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/CatMacaroni-Slerp",
        "Average":72.74,
        "ARC":69.28,
        "HellaSwag":86.88,
        "MMLU":65.02,
        "TruthfulQA":61.02,
        "Winogrande":81.14,
        "GSM8K":73.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"damerajee\/Oot-v2_lll",
        "Average":72.73,
        "ARC":69.28,
        "HellaSwag":86.6,
        "MMLU":64.96,
        "TruthfulQA":62.57,
        "Winogrande":80.82,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-Mixtral-8x7B-Instruct",
        "Average":72.73,
        "ARC":70.56,
        "HellaSwag":87.74,
        "MMLU":71.08,
        "TruthfulQA":65.72,
        "Winogrande":81.45,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":19.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Fimbulvetr-Kuro-Lotus-10.7B",
        "Average":72.73,
        "ARC":69.54,
        "HellaSwag":87.87,
        "MMLU":66.99,
        "TruthfulQA":60.95,
        "Winogrande":84.14,
        "GSM8K":66.87,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":14.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-Gamma-V2-9B",
        "Average":72.72,
        "ARC":69.88,
        "HellaSwag":86.84,
        "MMLU":64.22,
        "TruthfulQA":68.85,
        "Winogrande":82.87,
        "GSM8K":63.68,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tenyx\/TenyxChat-8x7B-v1",
        "Average":72.72,
        "ARC":69.71,
        "HellaSwag":87.76,
        "MMLU":71.12,
        "TruthfulQA":65.42,
        "Winogrande":81.22,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ChaoticNeutrals\/RP_Vision_7B",
        "Average":72.71,
        "ARC":70.65,
        "HellaSwag":87.81,
        "MMLU":64.58,
        "TruthfulQA":68.5,
        "Winogrande":82.64,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mistralai\/Mixtral-8x7B-Instruct-v0.1",
        "Average":72.7,
        "ARC":70.14,
        "HellaSwag":87.55,
        "MMLU":71.4,
        "TruthfulQA":64.98,
        "Winogrande":81.06,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3540.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/CatMacaroni14",
        "Average":72.68,
        "ARC":69.11,
        "HellaSwag":86.92,
        "MMLU":65.07,
        "TruthfulQA":61.58,
        "Winogrande":81.06,
        "GSM8K":72.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/RPMix-4x7B-MoE",
        "Average":72.68,
        "ARC":71.08,
        "HellaSwag":87.79,
        "MMLU":64.36,
        "TruthfulQA":67.29,
        "Winogrande":81.93,
        "GSM8K":63.61,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/pmmpk-EinstainMorcoro14KrishnaHercules-7b-slerp",
        "Average":72.67,
        "ARC":69.28,
        "HellaSwag":86.59,
        "MMLU":65.13,
        "TruthfulQA":62.69,
        "Winogrande":80.9,
        "GSM8K":71.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"SJ-Donald\/SJ-SOLAR-10.7b-DPO",
        "Average":72.67,
        "ARC":68.26,
        "HellaSwag":86.95,
        "MMLU":66.73,
        "TruthfulQA":67.74,
        "Winogrande":84.21,
        "GSM8K":62.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"senseable\/garten2-7b",
        "Average":72.65,
        "ARC":69.37,
        "HellaSwag":87.54,
        "MMLU":65.44,
        "TruthfulQA":59.5,
        "Winogrande":84.69,
        "GSM8K":69.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-34b",
        "Average":72.65,
        "ARC":66.98,
        "HellaSwag":84.79,
        "MMLU":76.0,
        "TruthfulQA":62.68,
        "Winogrande":83.43,
        "GSM8K":62.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Fimbulvetr-11B-v2-Test-14",
        "Average":72.64,
        "ARC":70.05,
        "HellaSwag":87.79,
        "MMLU":66.78,
        "TruthfulQA":63.43,
        "Winogrande":82.95,
        "GSM8K":64.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Sao10K\/Fimbulvetr-11B-v2",
        "Average":72.63,
        "ARC":70.14,
        "HellaSwag":87.79,
        "MMLU":66.83,
        "TruthfulQA":63.43,
        "Winogrande":82.95,
        "GSM8K":64.67,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/ComplectMaid-7B-slerp",
        "Average":72.63,
        "ARC":69.97,
        "HellaSwag":87.34,
        "MMLU":64.62,
        "TruthfulQA":65.88,
        "Winogrande":82.08,
        "GSM8K":65.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_4-7B-slerp",
        "Average":72.63,
        "ARC":69.45,
        "HellaSwag":87.01,
        "MMLU":65.33,
        "TruthfulQA":62.4,
        "Winogrande":82.95,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/WestMaid_HermesMonarchv0.1",
        "Average":72.62,
        "ARC":70.22,
        "HellaSwag":87.42,
        "MMLU":64.31,
        "TruthfulQA":61.99,
        "Winogrande":82.16,
        "GSM8K":69.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mistralai\/Mixtral-8x7B-Instruct-v0.1",
        "Average":72.62,
        "ARC":70.22,
        "HellaSwag":87.63,
        "MMLU":71.16,
        "TruthfulQA":64.58,
        "Winogrande":81.37,
        "GSM8K":60.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3540.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/CultriX-MoE-BF16",
        "Average":72.6,
        "ARC":68.94,
        "HellaSwag":86.96,
        "MMLU":65.2,
        "TruthfulQA":63.47,
        "Winogrande":81.06,
        "GSM8K":69.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen12-mistral-7B",
        "Average":72.6,
        "ARC":69.03,
        "HellaSwag":87.34,
        "MMLU":64.92,
        "TruthfulQA":66.99,
        "Winogrande":80.9,
        "GSM8K":66.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Severus-7B",
        "Average":72.58,
        "ARC":68.43,
        "HellaSwag":86.89,
        "MMLU":65.2,
        "TruthfulQA":61.36,
        "Winogrande":80.9,
        "GSM8K":72.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"SJ-Donald\/SOLAR-10.7B-slerp",
        "Average":72.58,
        "ARC":68.17,
        "HellaSwag":86.91,
        "MMLU":66.73,
        "TruthfulQA":67.42,
        "Winogrande":84.06,
        "GSM8K":62.17,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Himitsui\/KuroMitsu-11B",
        "Average":72.58,
        "ARC":70.31,
        "HellaSwag":88.07,
        "MMLU":66.66,
        "TruthfulQA":61.36,
        "Winogrande":84.69,
        "GSM8K":64.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":11.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/PiVoT-SUS-RP",
        "Average":72.57,
        "ARC":66.55,
        "HellaSwag":84.23,
        "MMLU":76.23,
        "TruthfulQA":54.57,
        "Winogrande":83.35,
        "GSM8K":70.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-S2-v0.1",
        "Average":72.57,
        "ARC":69.45,
        "HellaSwag":87.15,
        "MMLU":64.98,
        "TruthfulQA":62.18,
        "Winogrande":79.64,
        "GSM8K":72.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"brucethemoose\/Yi-34B-200K-DARE-megamerge-v8",
        "Average":72.56,
        "ARC":67.75,
        "HellaSwag":86.06,
        "MMLU":77.03,
        "TruthfulQA":56.31,
        "Winogrande":82.79,
        "GSM8K":65.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Harmony-4x7B-bf16",
        "Average":72.56,
        "ARC":68.34,
        "HellaSwag":86.75,
        "MMLU":64.73,
        "TruthfulQA":62.06,
        "Winogrande":81.37,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/bophades-mistral-7B",
        "Average":72.54,
        "ARC":69.97,
        "HellaSwag":87.28,
        "MMLU":64.77,
        "TruthfulQA":59.83,
        "Winogrande":83.74,
        "GSM8K":69.67,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/EveryNight-7B-slerp",
        "Average":72.54,
        "ARC":70.05,
        "HellaSwag":87.7,
        "MMLU":64.88,
        "TruthfulQA":66.07,
        "Winogrande":82.87,
        "GSM8K":63.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"fhai50032\/RolePlayLake-7B",
        "Average":72.54,
        "ARC":70.56,
        "HellaSwag":87.42,
        "MMLU":64.55,
        "TruthfulQA":64.38,
        "Winogrande":83.27,
        "GSM8K":65.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIDC-ai-business\/Marcoroni-7B-v3",
        "Average":72.53,
        "ARC":69.45,
        "HellaSwag":86.78,
        "MMLU":65.0,
        "TruthfulQA":60.4,
        "Winogrande":81.45,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bardsai\/jaskier-7b-dpo-v2",
        "Average":72.53,
        "ARC":69.28,
        "HellaSwag":86.8,
        "MMLU":64.92,
        "TruthfulQA":61.64,
        "Winogrande":80.74,
        "GSM8K":71.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"leveldevai\/MBA-7B",
        "Average":72.52,
        "ARC":69.45,
        "HellaSwag":87.22,
        "MMLU":65.16,
        "TruthfulQA":62.71,
        "Winogrande":81.53,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Toten5\/Marcoroni-v3-neural-chat-v3-3-Slerp",
        "Average":72.51,
        "ARC":68.77,
        "HellaSwag":86.55,
        "MMLU":64.51,
        "TruthfulQA":62.7,
        "Winogrande":80.74,
        "GSM8K":71.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen9X-mistral-7B",
        "Average":72.51,
        "ARC":69.54,
        "HellaSwag":87.46,
        "MMLU":64.7,
        "TruthfulQA":65.57,
        "Winogrande":81.53,
        "GSM8K":66.26,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mychen76\/openmixtral-4x7b-merged",
        "Average":72.51,
        "ARC":69.45,
        "HellaSwag":86.75,
        "MMLU":65.29,
        "TruthfulQA":61.33,
        "Winogrande":81.06,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz2\/pee",
        "Average":72.5,
        "ARC":69.88,
        "HellaSwag":86.89,
        "MMLU":64.95,
        "TruthfulQA":60.56,
        "Winogrande":81.77,
        "GSM8K":70.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Toten5\/Marcoroni-neural-chat-7B-v2",
        "Average":72.5,
        "ARC":68.6,
        "HellaSwag":86.33,
        "MMLU":64.65,
        "TruthfulQA":61.84,
        "Winogrande":80.43,
        "GSM8K":73.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/bruphin-iota",
        "Average":72.5,
        "ARC":68.43,
        "HellaSwag":86.55,
        "MMLU":65.02,
        "TruthfulQA":66.17,
        "Winogrande":81.06,
        "GSM8K":67.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/Einstein-4D-MoE-2x7b-test",
        "Average":72.5,
        "ARC":69.71,
        "HellaSwag":86.52,
        "MMLU":65.41,
        "TruthfulQA":62.29,
        "Winogrande":81.45,
        "GSM8K":69.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-dpo-8x7b-v0.2",
        "Average":72.49,
        "ARC":72.1,
        "HellaSwag":86.41,
        "MMLU":70.27,
        "TruthfulQA":72.83,
        "Winogrande":83.27,
        "GSM8K":50.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":20.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"pabloce\/Dolphin-2.8-slerp",
        "Average":72.48,
        "ARC":68.0,
        "HellaSwag":86.51,
        "MMLU":64.38,
        "TruthfulQA":65.2,
        "Winogrande":82.16,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ignos\/Mistral-T5-7B-v1",
        "Average":72.47,
        "ARC":68.6,
        "HellaSwag":86.3,
        "MMLU":64.62,
        "TruthfulQA":61.86,
        "Winogrande":80.27,
        "GSM8K":73.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Kunoichi-DPO-v2-7B",
        "Average":72.46,
        "ARC":69.62,
        "HellaSwag":87.44,
        "MMLU":64.94,
        "TruthfulQA":66.06,
        "Winogrande":80.82,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":54.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Marcoroni-8x7B-v3-MoE",
        "Average":72.45,
        "ARC":69.37,
        "HellaSwag":86.78,
        "MMLU":65.01,
        "TruthfulQA":60.4,
        "Winogrande":81.45,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/RPLakeCoder-TxC",
        "Average":72.45,
        "ARC":70.39,
        "HellaSwag":87.36,
        "MMLU":64.48,
        "TruthfulQA":64.37,
        "Winogrande":83.11,
        "GSM8K":64.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Brillibits\/Instruct_Mixtral-8x7B-v0.1_Dolly15K",
        "Average":72.44,
        "ARC":69.28,
        "HellaSwag":87.59,
        "MMLU":70.96,
        "TruthfulQA":64.83,
        "Winogrande":82.56,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen6-mistral-7B",
        "Average":72.44,
        "ARC":69.2,
        "HellaSwag":86.99,
        "MMLU":64.17,
        "TruthfulQA":63.48,
        "Winogrande":81.29,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/RPLakeCoder-TxC",
        "Average":72.43,
        "ARC":70.39,
        "HellaSwag":87.35,
        "MMLU":64.5,
        "TruthfulQA":64.34,
        "Winogrande":83.43,
        "GSM8K":64.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChuckMcSneed\/PMaxxxer-v1-70b",
        "Average":72.41,
        "ARC":71.08,
        "HellaSwag":87.88,
        "MMLU":70.39,
        "TruthfulQA":59.77,
        "Winogrande":82.64,
        "GSM8K":62.7,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_15-7B-slerp",
        "Average":72.41,
        "ARC":68.0,
        "HellaSwag":86.82,
        "MMLU":65.58,
        "TruthfulQA":59.99,
        "Winogrande":82.56,
        "GSM8K":71.49,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Sao10K\/Fimbulvetr-11B-v2",
        "Average":72.4,
        "ARC":70.14,
        "HellaSwag":87.77,
        "MMLU":66.68,
        "TruthfulQA":63.42,
        "Winogrande":82.72,
        "GSM8K":63.68,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/Blur-7B-slerp-v0.1",
        "Average":72.4,
        "ARC":68.77,
        "HellaSwag":86.58,
        "MMLU":65.18,
        "TruthfulQA":60.64,
        "Winogrande":81.14,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Kunoichi-DPO-v2-7B",
        "Average":72.4,
        "ARC":69.37,
        "HellaSwag":87.42,
        "MMLU":64.83,
        "TruthfulQA":66.0,
        "Winogrande":80.74,
        "GSM8K":66.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":54.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/neuronal-7b-Mlab",
        "Average":72.4,
        "ARC":69.97,
        "HellaSwag":86.79,
        "MMLU":64.51,
        "TruthfulQA":63.36,
        "Winogrande":81.06,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.1",
        "Average":72.39,
        "ARC":69.11,
        "HellaSwag":86.7,
        "MMLU":65.34,
        "TruthfulQA":63.43,
        "Winogrande":80.19,
        "GSM8K":69.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/IamSoTired-7B-slerp",
        "Average":72.37,
        "ARC":69.88,
        "HellaSwag":87.15,
        "MMLU":64.85,
        "TruthfulQA":63.75,
        "Winogrande":82.4,
        "GSM8K":66.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/mixtral-instruct-0.1-laser",
        "Average":72.36,
        "ARC":70.48,
        "HellaSwag":87.28,
        "MMLU":71.07,
        "TruthfulQA":65.83,
        "Winogrande":80.82,
        "GSM8K":58.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-Alpha-V2-7B",
        "Average":72.35,
        "ARC":69.62,
        "HellaSwag":87.14,
        "MMLU":65.11,
        "TruthfulQA":61.08,
        "Winogrande":81.22,
        "GSM8K":69.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/laserxtral",
        "Average":72.34,
        "ARC":69.03,
        "HellaSwag":86.76,
        "MMLU":64.68,
        "TruthfulQA":63.8,
        "Winogrande":80.03,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":24.15,
        "Model Sha":76.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"fhai50032\/BeagleLake-7B",
        "Average":72.34,
        "ARC":70.39,
        "HellaSwag":87.38,
        "MMLU":64.25,
        "TruthfulQA":64.92,
        "Winogrande":83.19,
        "GSM8K":63.91,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mindy-labs\/mindy-7b",
        "Average":72.34,
        "ARC":69.11,
        "HellaSwag":86.57,
        "MMLU":64.69,
        "TruthfulQA":60.89,
        "Winogrande":81.06,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janhq\/supermario-v2",
        "Average":72.34,
        "ARC":68.52,
        "HellaSwag":86.51,
        "MMLU":64.88,
        "TruthfulQA":60.58,
        "Winogrande":81.37,
        "GSM8K":72.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/FrankenDPO-4x7B-bf16",
        "Average":72.34,
        "ARC":68.69,
        "HellaSwag":86.07,
        "MMLU":64.93,
        "TruthfulQA":63.14,
        "Winogrande":83.5,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"grimjim\/kuno-kunoichi-v1-DPO-v2-SLERP-7B",
        "Average":72.33,
        "ARC":69.11,
        "HellaSwag":87.33,
        "MMLU":64.8,
        "TruthfulQA":65.12,
        "Winogrande":80.9,
        "GSM8K":66.72,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-deepseek-67b-v15.2",
        "Average":72.33,
        "ARC":68.6,
        "HellaSwag":86.37,
        "MMLU":71.5,
        "TruthfulQA":56.2,
        "Winogrande":84.45,
        "GSM8K":66.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.42,
        "Model Sha":10.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mychen76\/openmixtral-6x7b-v2",
        "Average":72.33,
        "ARC":68.52,
        "HellaSwag":86.75,
        "MMLU":65.11,
        "TruthfulQA":65.13,
        "Winogrande":79.87,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Beyonder-4x7B-v2",
        "Average":72.33,
        "ARC":68.77,
        "HellaSwag":86.8,
        "MMLU":65.1,
        "TruthfulQA":60.68,
        "Winogrande":80.9,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":24.15,
        "Model Sha":120.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janhq\/supermario-slerp",
        "Average":72.32,
        "ARC":68.94,
        "HellaSwag":86.58,
        "MMLU":64.93,
        "TruthfulQA":60.11,
        "Winogrande":81.29,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/piccolo-math-2x7b",
        "Average":72.32,
        "ARC":69.11,
        "HellaSwag":87.27,
        "MMLU":63.69,
        "TruthfulQA":63.86,
        "Winogrande":79.87,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"chasedreaminf\/Dream-7B-slerp",
        "Average":72.32,
        "ARC":68.52,
        "HellaSwag":86.35,
        "MMLU":64.6,
        "TruthfulQA":61.85,
        "Winogrande":80.35,
        "GSM8K":72.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v0.1",
        "Average":72.32,
        "ARC":70.05,
        "HellaSwag":87.27,
        "MMLU":71.21,
        "TruthfulQA":63.23,
        "Winogrande":80.35,
        "GSM8K":61.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/CatPPT",
        "Average":72.32,
        "ARC":68.09,
        "HellaSwag":86.69,
        "MMLU":65.16,
        "TruthfulQA":61.55,
        "Winogrande":81.61,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":15.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"R136a1\/InfinityKuno-2x7B",
        "Average":72.32,
        "ARC":69.62,
        "HellaSwag":87.44,
        "MMLU":64.49,
        "TruthfulQA":63.28,
        "Winogrande":82.72,
        "GSM8K":66.34,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-ai\/Solar-10.7B-SLERP",
        "Average":72.31,
        "ARC":70.73,
        "HellaSwag":87.87,
        "MMLU":65.77,
        "TruthfulQA":65.72,
        "Winogrande":82.48,
        "GSM8K":61.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"pabloce\/Dolphin-2.8-slerp",
        "Average":72.28,
        "ARC":68.0,
        "HellaSwag":86.43,
        "MMLU":64.39,
        "TruthfulQA":65.22,
        "Winogrande":82.0,
        "GSM8K":67.63,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cstr\/Spaetzle-v8-7b",
        "Average":72.27,
        "ARC":68.69,
        "HellaSwag":86.68,
        "MMLU":64.6,
        "TruthfulQA":64.05,
        "Winogrande":81.45,
        "GSM8K":68.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/yi-34B-v3",
        "Average":72.26,
        "ARC":67.06,
        "HellaSwag":85.11,
        "MMLU":75.8,
        "TruthfulQA":57.54,
        "Winogrande":83.5,
        "GSM8K":64.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/CausalLM-RP-34B",
        "Average":72.26,
        "ARC":68.0,
        "HellaSwag":83.43,
        "MMLU":83.1,
        "TruthfulQA":54.51,
        "Winogrande":82.16,
        "GSM8K":62.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":34.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Fimbulvetr-10.7B-v1",
        "Average":72.25,
        "ARC":68.94,
        "HellaSwag":87.27,
        "MMLU":66.59,
        "TruthfulQA":60.54,
        "Winogrande":83.5,
        "GSM8K":66.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":32.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jan-hq\/supermario-v2",
        "Average":72.25,
        "ARC":68.43,
        "HellaSwag":86.51,
        "MMLU":64.96,
        "TruthfulQA":60.61,
        "Winogrande":80.74,
        "GSM8K":72.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"rishiraj\/CatPPT-base",
        "Average":72.25,
        "ARC":67.92,
        "HellaSwag":86.64,
        "MMLU":65.26,
        "TruthfulQA":61.72,
        "Winogrande":81.29,
        "GSM8K":70.66,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":41.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Kunoichi-DPO-7B",
        "Average":72.24,
        "ARC":69.62,
        "HellaSwag":87.14,
        "MMLU":64.79,
        "TruthfulQA":67.31,
        "Winogrande":80.58,
        "GSM8K":63.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChuckMcSneed\/SMaxxxer-v1-70b",
        "Average":72.23,
        "ARC":70.65,
        "HellaSwag":88.02,
        "MMLU":70.55,
        "TruthfulQA":60.7,
        "Winogrande":82.87,
        "GSM8K":60.58,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jan-hq\/supermario-slerp-v3",
        "Average":72.22,
        "ARC":69.28,
        "HellaSwag":86.71,
        "MMLU":65.11,
        "TruthfulQA":61.77,
        "Winogrande":80.51,
        "GSM8K":69.98,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_7-7B-slerp",
        "Average":72.21,
        "ARC":69.88,
        "HellaSwag":87.66,
        "MMLU":64.85,
        "TruthfulQA":60.45,
        "Winogrande":83.19,
        "GSM8K":67.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CultriX\/CultriX-MoE-Model",
        "Average":72.21,
        "ARC":70.05,
        "HellaSwag":87.22,
        "MMLU":64.95,
        "TruthfulQA":68.04,
        "Winogrande":80.9,
        "GSM8K":62.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"viethq188\/LeoScorpius-7B",
        "Average":72.21,
        "ARC":69.28,
        "HellaSwag":87.01,
        "MMLU":65.04,
        "TruthfulQA":63.95,
        "Winogrande":81.53,
        "GSM8K":66.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v3.1",
        "Average":72.2,
        "ARC":69.62,
        "HellaSwag":87.45,
        "MMLU":71.2,
        "TruthfulQA":64.17,
        "Winogrande":81.14,
        "GSM8K":59.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/A0123",
        "Average":72.19,
        "ARC":67.66,
        "HellaSwag":84.87,
        "MMLU":78.45,
        "TruthfulQA":58.42,
        "Winogrande":80.35,
        "GSM8K":63.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rwitz2\/grindin",
        "Average":72.18,
        "ARC":69.88,
        "HellaSwag":87.02,
        "MMLU":64.98,
        "TruthfulQA":59.34,
        "Winogrande":80.9,
        "GSM8K":70.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adonlee\/Mistral_7B_SFT_DPO_v0",
        "Average":72.17,
        "ARC":66.3,
        "HellaSwag":84.9,
        "MMLU":64.53,
        "TruthfulQA":69.72,
        "Winogrande":81.77,
        "GSM8K":65.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"brucethemoose\/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
        "Average":72.15,
        "ARC":67.41,
        "HellaSwag":85.77,
        "MMLU":77.44,
        "TruthfulQA":57.84,
        "Winogrande":83.11,
        "GSM8K":61.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/Open-StarLake-Swap-7B",
        "Average":72.15,
        "ARC":70.56,
        "HellaSwag":86.99,
        "MMLU":65.11,
        "TruthfulQA":57.5,
        "Winogrande":83.19,
        "GSM8K":69.52,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cstr\/Spaetzle-v8-7b",
        "Average":72.14,
        "ARC":68.69,
        "HellaSwag":86.66,
        "MMLU":64.59,
        "TruthfulQA":64.06,
        "Winogrande":81.37,
        "GSM8K":67.48,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Kunoichi-7B",
        "Average":72.13,
        "ARC":68.69,
        "HellaSwag":87.1,
        "MMLU":64.9,
        "TruthfulQA":64.04,
        "Winogrande":81.06,
        "GSM8K":67.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":66.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/yi-34B-v2",
        "Average":72.12,
        "ARC":66.13,
        "HellaSwag":85.0,
        "MMLU":75.64,
        "TruthfulQA":57.34,
        "Winogrande":83.66,
        "GSM8K":64.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/72B-preview",
        "Average":72.12,
        "ARC":65.19,
        "HellaSwag":83.23,
        "MMLU":77.14,
        "TruthfulQA":52.58,
        "Winogrande":82.48,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A0120",
        "Average":72.11,
        "ARC":67.06,
        "HellaSwag":85.15,
        "MMLU":74.49,
        "TruthfulQA":57.48,
        "Winogrande":81.37,
        "GSM8K":67.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mindy-labs\/mindy-7b-v2",
        "Average":72.11,
        "ARC":68.69,
        "HellaSwag":86.59,
        "MMLU":65.18,
        "TruthfulQA":60.16,
        "Winogrande":81.06,
        "GSM8K":70.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/chatty-djinn-14B",
        "Average":72.08,
        "ARC":70.39,
        "HellaSwag":86.45,
        "MMLU":64.4,
        "TruthfulQA":67.57,
        "Winogrande":83.11,
        "GSM8K":60.58,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":13.57,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/go-bruins-v2",
        "Average":72.07,
        "ARC":69.8,
        "HellaSwag":87.05,
        "MMLU":64.75,
        "TruthfulQA":59.7,
        "Winogrande":81.45,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-SFT",
        "Average":72.07,
        "ARC":69.71,
        "HellaSwag":86.74,
        "MMLU":72.21,
        "TruthfulQA":51.22,
        "Winogrande":82.95,
        "GSM8K":69.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":55.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0221",
        "Average":72.07,
        "ARC":68.52,
        "HellaSwag":85.13,
        "MMLU":84.48,
        "TruthfulQA":55.13,
        "Winogrande":81.29,
        "GSM8K":57.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/72B-preview",
        "Average":72.06,
        "ARC":64.85,
        "HellaSwag":83.28,
        "MMLU":77.21,
        "TruthfulQA":52.51,
        "Winogrande":82.48,
        "GSM8K":72.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/NeuralBeagle-11B-truthy",
        "Average":72.06,
        "ARC":73.63,
        "HellaSwag":87.86,
        "MMLU":63.11,
        "TruthfulQA":75.92,
        "Winogrande":82.08,
        "GSM8K":49.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/ToppyLake-7B-slerp",
        "Average":72.05,
        "ARC":69.2,
        "HellaSwag":86.98,
        "MMLU":64.85,
        "TruthfulQA":62.54,
        "Winogrande":82.79,
        "GSM8K":65.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/DonutLM-v1",
        "Average":72.05,
        "ARC":69.11,
        "HellaSwag":85.91,
        "MMLU":65.45,
        "TruthfulQA":63.36,
        "Winogrande":81.69,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/dec10",
        "Average":72.05,
        "ARC":69.11,
        "HellaSwag":86.46,
        "MMLU":64.98,
        "TruthfulQA":60.42,
        "Winogrande":80.74,
        "GSM8K":70.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ChaoticNeutrals\/This_is_fine_7B",
        "Average":72.05,
        "ARC":70.31,
        "HellaSwag":87.28,
        "MMLU":64.51,
        "TruthfulQA":65.79,
        "Winogrande":81.61,
        "GSM8K":62.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/NeuralDareDMistralPro-7b-slerp",
        "Average":72.04,
        "ARC":69.03,
        "HellaSwag":86.74,
        "MMLU":63.46,
        "TruthfulQA":64.12,
        "Winogrande":80.19,
        "GSM8K":68.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"llmixer\/BigWeave-v16-103b",
        "Average":72.02,
        "ARC":65.87,
        "HellaSwag":87.61,
        "MMLU":73.22,
        "TruthfulQA":63.81,
        "Winogrande":80.43,
        "GSM8K":61.18,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"unknown",
        "Available on the Hub":103.2,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/dec10",
        "Average":72.01,
        "ARC":69.2,
        "HellaSwag":86.48,
        "MMLU":64.91,
        "TruthfulQA":60.52,
        "Winogrande":80.43,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/72B-preview-llamafied-qwen-llamafy",
        "Average":72.0,
        "ARC":65.19,
        "HellaSwag":83.24,
        "MMLU":77.04,
        "TruthfulQA":52.55,
        "Winogrande":82.4,
        "GSM8K":71.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":72.0,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"brucethemoose\/Yi-34B-200K-DARE-merge-v5",
        "Average":71.98,
        "ARC":66.47,
        "HellaSwag":85.54,
        "MMLU":77.22,
        "TruthfulQA":57.46,
        "Winogrande":82.24,
        "GSM8K":62.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":21.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/Bophades-BruinsMaid-7B",
        "Average":71.97,
        "ARC":69.54,
        "HellaSwag":86.52,
        "MMLU":64.93,
        "TruthfulQA":60.5,
        "Winogrande":82.56,
        "GSM8K":67.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/Maidphin-Kunoichi-7B",
        "Average":71.96,
        "ARC":69.37,
        "HellaSwag":87.11,
        "MMLU":64.78,
        "TruthfulQA":64.27,
        "Winogrande":80.35,
        "GSM8K":65.88,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.5",
        "Average":71.96,
        "ARC":68.69,
        "HellaSwag":86.45,
        "MMLU":65.65,
        "TruthfulQA":59.12,
        "Winogrande":80.66,
        "GSM8K":71.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/go-bruins-v2",
        "Average":71.95,
        "ARC":69.8,
        "HellaSwag":87.06,
        "MMLU":64.95,
        "TruthfulQA":59.68,
        "Winogrande":81.22,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenPipe\/mistral-ft-optimized-1218",
        "Average":71.94,
        "ARC":67.92,
        "HellaSwag":86.26,
        "MMLU":64.99,
        "TruthfulQA":59.48,
        "Winogrande":80.74,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":150.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/Valkyrie-V1",
        "Average":71.92,
        "ARC":67.24,
        "HellaSwag":86.27,
        "MMLU":64.82,
        "TruthfulQA":60.4,
        "Winogrande":81.45,
        "GSM8K":71.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_47-7B-dare_ties",
        "Average":71.91,
        "ARC":69.45,
        "HellaSwag":86.69,
        "MMLU":63.27,
        "TruthfulQA":67.86,
        "Winogrande":82.24,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Kuro-Lotus-10.7B",
        "Average":71.9,
        "ARC":68.69,
        "HellaSwag":87.51,
        "MMLU":66.64,
        "TruthfulQA":58.27,
        "Winogrande":84.21,
        "GSM8K":66.11,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"databricks\/dbrx-base",
        "Average":71.9,
        "ARC":66.04,
        "HellaSwag":89.0,
        "MMLU":74.7,
        "TruthfulQA":55.07,
        "Winogrande":78.06,
        "GSM8K":68.54,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":131.6,
        "Model Sha":452.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"arcee-ai\/Saul-Instruct-Clown-7b",
        "Average":71.9,
        "ARC":68.09,
        "HellaSwag":86.23,
        "MMLU":64.41,
        "TruthfulQA":63.2,
        "Winogrande":81.61,
        "GSM8K":67.85,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/A0110",
        "Average":71.89,
        "ARC":66.38,
        "HellaSwag":84.73,
        "MMLU":74.48,
        "TruthfulQA":58.6,
        "Winogrande":82.32,
        "GSM8K":64.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Karko\/Proctora",
        "Average":71.88,
        "ARC":67.83,
        "HellaSwag":86.68,
        "MMLU":65.49,
        "TruthfulQA":59.55,
        "Winogrande":79.79,
        "GSM8K":71.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ozayezerceli\/BetterSaul-7B-slerp",
        "Average":71.88,
        "ARC":68.09,
        "HellaSwag":86.3,
        "MMLU":64.31,
        "TruthfulQA":63.08,
        "Winogrande":82.32,
        "GSM8K":67.17,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Pluto_24B_DPO_200",
        "Average":71.88,
        "ARC":65.61,
        "HellaSwag":86.38,
        "MMLU":64.59,
        "TruthfulQA":69.86,
        "Winogrande":78.93,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Prima-LelantaclesV6.25-7b",
        "Average":71.88,
        "ARC":69.11,
        "HellaSwag":87.29,
        "MMLU":64.42,
        "TruthfulQA":67.44,
        "Winogrande":82.64,
        "GSM8K":60.35,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Darewin-7B",
        "Average":71.87,
        "ARC":68.6,
        "HellaSwag":86.22,
        "MMLU":65.21,
        "TruthfulQA":60.38,
        "Winogrande":79.79,
        "GSM8K":71.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Cookie_7B",
        "Average":71.87,
        "ARC":69.71,
        "HellaSwag":87.57,
        "MMLU":64.51,
        "TruthfulQA":66.88,
        "Winogrande":81.37,
        "GSM8K":61.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Cookie_7B",
        "Average":71.87,
        "ARC":69.71,
        "HellaSwag":87.57,
        "MMLU":64.51,
        "TruthfulQA":66.88,
        "Winogrande":81.37,
        "GSM8K":61.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DopeorNope\/COKAL-v1-70B",
        "Average":71.87,
        "ARC":87.46,
        "HellaSwag":83.29,
        "MMLU":68.13,
        "TruthfulQA":72.79,
        "Winogrande":80.27,
        "GSM8K":39.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":69.44,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Seraph-7B",
        "Average":71.86,
        "ARC":67.83,
        "HellaSwag":86.22,
        "MMLU":65.07,
        "TruthfulQA":59.49,
        "Winogrande":80.66,
        "GSM8K":71.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bn22\/Nous-Hermes-2-SOLAR-10.7B-MISALIGNED",
        "Average":71.83,
        "ARC":68.26,
        "HellaSwag":86.11,
        "MMLU":66.26,
        "TruthfulQA":57.79,
        "Winogrande":83.43,
        "GSM8K":69.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/A0109",
        "Average":71.83,
        "ARC":66.55,
        "HellaSwag":84.7,
        "MMLU":74.44,
        "TruthfulQA":58.75,
        "Winogrande":82.16,
        "GSM8K":64.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_34-7B-slerp",
        "Average":71.83,
        "ARC":70.05,
        "HellaSwag":87.46,
        "MMLU":61.82,
        "TruthfulQA":73.24,
        "Winogrande":81.29,
        "GSM8K":57.09,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/openchat-3.5-1210-Seraph-Slerp",
        "Average":71.82,
        "ARC":68.09,
        "HellaSwag":86.48,
        "MMLU":65.33,
        "TruthfulQA":57.77,
        "Winogrande":80.82,
        "GSM8K":72.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"arlineka\/Brunhilde-2x7b-MOE-DPO-v.01.5",
        "Average":71.81,
        "ARC":69.54,
        "HellaSwag":87.02,
        "MMLU":64.93,
        "TruthfulQA":65.47,
        "Winogrande":80.9,
        "GSM8K":63.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/go-bruins",
        "Average":71.81,
        "ARC":69.11,
        "HellaSwag":86.73,
        "MMLU":64.94,
        "TruthfulQA":58.71,
        "Winogrande":81.45,
        "GSM8K":69.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0308-G",
        "Average":71.81,
        "ARC":68.34,
        "HellaSwag":83.64,
        "MMLU":84.07,
        "TruthfulQA":54.02,
        "Winogrande":80.43,
        "GSM8K":60.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/C0318-G",
        "Average":71.81,
        "ARC":64.51,
        "HellaSwag":83.88,
        "MMLU":74.16,
        "TruthfulQA":58.61,
        "Winogrande":79.32,
        "GSM8K":70.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"CohereForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-deepseek-67b-v18.1-4k",
        "Average":71.8,
        "ARC":67.75,
        "HellaSwag":84.65,
        "MMLU":70.58,
        "TruthfulQA":55.66,
        "Winogrande":82.95,
        "GSM8K":69.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.42,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"deepseek-ai\/deepseek-llm-67b-chat",
        "Average":71.79,
        "ARC":67.75,
        "HellaSwag":86.82,
        "MMLU":72.42,
        "TruthfulQA":55.85,
        "Winogrande":84.21,
        "GSM8K":63.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.0,
        "Model Sha":157.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rwitz\/go-bruins",
        "Average":71.79,
        "ARC":69.11,
        "HellaSwag":86.68,
        "MMLU":64.96,
        "TruthfulQA":58.72,
        "Winogrande":81.37,
        "GSM8K":69.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/NeuralDarewin-7B",
        "Average":71.79,
        "ARC":70.14,
        "HellaSwag":86.4,
        "MMLU":64.85,
        "TruthfulQA":62.92,
        "Winogrande":79.72,
        "GSM8K":66.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-V4-Alpha-7B",
        "Average":71.78,
        "ARC":69.28,
        "HellaSwag":87.06,
        "MMLU":64.95,
        "TruthfulQA":63.94,
        "Winogrande":81.45,
        "GSM8K":63.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-deepseek-67b-v15.1",
        "Average":71.76,
        "ARC":67.66,
        "HellaSwag":86.49,
        "MMLU":70.3,
        "TruthfulQA":54.42,
        "Winogrande":84.77,
        "GSM8K":66.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.42,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/openchat-3.5-1210-Seraph-Slerp",
        "Average":71.74,
        "ARC":67.92,
        "HellaSwag":86.43,
        "MMLU":65.26,
        "TruthfulQA":57.75,
        "Winogrande":80.82,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen",
        "Average":71.74,
        "ARC":68.17,
        "HellaSwag":87.06,
        "MMLU":64.68,
        "TruthfulQA":63.02,
        "Winogrande":81.45,
        "GSM8K":66.03,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-M-Creative-v1.0",
        "Average":71.73,
        "ARC":66.81,
        "HellaSwag":85.14,
        "MMLU":75.54,
        "TruthfulQA":57.68,
        "Winogrande":83.11,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mvpmaster\/Einstein-4D-Marcoro14-7b-full-slerp",
        "Average":71.73,
        "ARC":68.86,
        "HellaSwag":85.98,
        "MMLU":64.57,
        "TruthfulQA":62.07,
        "Winogrande":80.43,
        "GSM8K":68.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_51-7B-dare_ties",
        "Average":71.73,
        "ARC":66.98,
        "HellaSwag":85.9,
        "MMLU":64.54,
        "TruthfulQA":60.72,
        "Winogrande":82.08,
        "GSM8K":70.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"VitalContribution\/Evangelion-7B",
        "Average":71.71,
        "ARC":68.94,
        "HellaSwag":86.45,
        "MMLU":63.97,
        "TruthfulQA":64.01,
        "Winogrande":79.95,
        "GSM8K":66.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bhenrym14\/platypus-yi-34b",
        "Average":71.69,
        "ARC":68.43,
        "HellaSwag":85.21,
        "MMLU":78.13,
        "TruthfulQA":54.48,
        "Winogrande":84.06,
        "GSM8K":59.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RatanRohith\/NeuralPizza-7B-V0.3",
        "Average":71.68,
        "ARC":71.08,
        "HellaSwag":87.38,
        "MMLU":64.29,
        "TruthfulQA":67.93,
        "Winogrande":80.51,
        "GSM8K":58.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PracticeLLM\/SOLAR-tail-10.7B-Merge-v1.0",
        "Average":71.68,
        "ARC":66.13,
        "HellaSwag":86.54,
        "MMLU":66.52,
        "TruthfulQA":60.57,
        "Winogrande":84.77,
        "GSM8K":65.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Loyal-Macaroni-Maid-7B",
        "Average":71.68,
        "ARC":68.0,
        "HellaSwag":86.39,
        "MMLU":64.87,
        "TruthfulQA":62.5,
        "Winogrande":79.87,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":48.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlabonne\/FrankenMonarch-7B",
        "Average":71.67,
        "ARC":71.59,
        "HellaSwag":88.59,
        "MMLU":63.93,
        "TruthfulQA":73.69,
        "Winogrande":83.58,
        "GSM8K":48.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v4-yi-34b",
        "Average":71.67,
        "ARC":66.81,
        "HellaSwag":84.44,
        "MMLU":74.34,
        "TruthfulQA":57.89,
        "Winogrande":82.4,
        "GSM8K":64.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"llmixer\/BigWeave-v15-103b",
        "Average":71.67,
        "ARC":69.71,
        "HellaSwag":86.41,
        "MMLU":71.25,
        "TruthfulQA":66.1,
        "Winogrande":80.35,
        "GSM8K":56.18,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":103.2,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Fett-Eris-Mix-7B",
        "Average":71.66,
        "ARC":68.77,
        "HellaSwag":87.33,
        "MMLU":63.65,
        "TruthfulQA":71.91,
        "Winogrande":80.82,
        "GSM8K":57.47,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/MixSwap",
        "Average":71.66,
        "ARC":69.45,
        "HellaSwag":86.95,
        "MMLU":65.18,
        "TruthfulQA":56.56,
        "Winogrande":83.19,
        "GSM8K":68.61,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-V3-AlphaFlavour-7B",
        "Average":71.64,
        "ARC":68.86,
        "HellaSwag":86.85,
        "MMLU":61.17,
        "TruthfulQA":71.94,
        "Winogrande":81.53,
        "GSM8K":59.51,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Calme-7B-Instruct-v0.1",
        "Average":71.63,
        "ARC":67.24,
        "HellaSwag":85.57,
        "MMLU":64.97,
        "TruthfulQA":59.38,
        "Winogrande":83.35,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/e.star.7b",
        "Average":71.62,
        "ARC":66.81,
        "HellaSwag":87.12,
        "MMLU":63.6,
        "TruthfulQA":62.63,
        "Winogrande":82.4,
        "GSM8K":67.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/B0121",
        "Average":71.61,
        "ARC":68.34,
        "HellaSwag":85.3,
        "MMLU":85.63,
        "TruthfulQA":58.63,
        "Winogrande":80.19,
        "GSM8K":51.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Samee-ur\/NeuralPipe-7B-slerp-DPO",
        "Average":71.6,
        "ARC":69.28,
        "HellaSwag":86.34,
        "MMLU":63.7,
        "TruthfulQA":63.53,
        "Winogrande":80.51,
        "GSM8K":66.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AGI-0\/Magistral-7B-v0.1",
        "Average":71.6,
        "ARC":67.15,
        "HellaSwag":86.3,
        "MMLU":64.3,
        "TruthfulQA":61.39,
        "Winogrande":83.5,
        "GSM8K":66.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-14b-MoE-LaserChat",
        "Average":71.6,
        "ARC":66.72,
        "HellaSwag":84.88,
        "MMLU":65.17,
        "TruthfulQA":57.64,
        "Winogrande":81.93,
        "GSM8K":73.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_33-7B-slerp",
        "Average":71.59,
        "ARC":70.73,
        "HellaSwag":87.26,
        "MMLU":63.87,
        "TruthfulQA":68.09,
        "Winogrande":81.69,
        "GSM8K":57.92,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RatanRohith\/NeuralPizza-7B-V0.2",
        "Average":71.59,
        "ARC":68.77,
        "HellaSwag":86.11,
        "MMLU":64.32,
        "TruthfulQA":61.38,
        "Winogrande":80.35,
        "GSM8K":68.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/flammen2",
        "Average":71.57,
        "ARC":68.94,
        "HellaSwag":86.87,
        "MMLU":64.78,
        "TruthfulQA":63.12,
        "Winogrande":80.74,
        "GSM8K":64.97,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Top-Western-Maid-7B",
        "Average":71.57,
        "ARC":69.37,
        "HellaSwag":87.4,
        "MMLU":64.63,
        "TruthfulQA":58.79,
        "Winogrande":83.27,
        "GSM8K":65.96,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"scaledown\/ScaleDown-7B-slerp-v0.1",
        "Average":71.57,
        "ARC":68.0,
        "HellaSwag":85.7,
        "MMLU":65.26,
        "TruthfulQA":61.9,
        "Winogrande":81.37,
        "GSM8K":67.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mayacinka\/NeuralZephyr-Beagle-7B",
        "Average":71.57,
        "ARC":68.6,
        "HellaSwag":86.38,
        "MMLU":64.67,
        "TruthfulQA":65.17,
        "Winogrande":81.14,
        "GSM8K":63.46,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"brucethemoose\/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
        "Average":71.57,
        "ARC":66.89,
        "HellaSwag":85.69,
        "MMLU":77.35,
        "TruthfulQA":57.63,
        "Winogrande":82.0,
        "GSM8K":59.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Stopwolf\/DistilabelCerberus-7B-slerp",
        "Average":71.56,
        "ARC":68.17,
        "HellaSwag":86.78,
        "MMLU":64.2,
        "TruthfulQA":60.93,
        "Winogrande":79.48,
        "GSM8K":69.83,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/NeuralPipe-7B-ties",
        "Average":71.55,
        "ARC":67.92,
        "HellaSwag":86.04,
        "MMLU":64.24,
        "TruthfulQA":61.37,
        "Winogrande":80.19,
        "GSM8K":69.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RatanRohith\/NeuralPizza-7B-V0.1",
        "Average":71.53,
        "ARC":70.48,
        "HellaSwag":87.3,
        "MMLU":64.42,
        "TruthfulQA":67.22,
        "Winogrande":80.35,
        "GSM8K":59.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A0106",
        "Average":71.53,
        "ARC":66.38,
        "HellaSwag":85.05,
        "MMLU":74.0,
        "TruthfulQA":57.88,
        "Winogrande":82.87,
        "GSM8K":63.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"R136a1\/InfinityKumon-2x7B",
        "Average":71.52,
        "ARC":69.62,
        "HellaSwag":87.09,
        "MMLU":64.97,
        "TruthfulQA":61.99,
        "Winogrande":81.93,
        "GSM8K":63.53,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-llm-67b-chat",
        "Average":71.52,
        "ARC":67.75,
        "HellaSwag":86.8,
        "MMLU":72.19,
        "TruthfulQA":55.83,
        "Winogrande":84.21,
        "GSM8K":62.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.0,
        "Model Sha":157.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/NeuralMonarchCoderPearlBeagle",
        "Average":71.5,
        "ARC":68.52,
        "HellaSwag":87.22,
        "MMLU":64.53,
        "TruthfulQA":61.19,
        "Winogrande":80.51,
        "GSM8K":67.02,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/Nandine-7b",
        "Average":71.47,
        "ARC":69.28,
        "HellaSwag":87.01,
        "MMLU":64.83,
        "TruthfulQA":62.1,
        "Winogrande":83.19,
        "GSM8K":62.4,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/14B-Glacier-Stack",
        "Average":71.47,
        "ARC":71.67,
        "HellaSwag":88.35,
        "MMLU":66.73,
        "TruthfulQA":65.37,
        "Winogrande":84.06,
        "GSM8K":52.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":14.22,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Yuna-7b-Merge",
        "Average":71.46,
        "ARC":67.49,
        "HellaSwag":86.84,
        "MMLU":64.86,
        "TruthfulQA":61.2,
        "Winogrande":80.74,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luqmanxyz\/LelaStarling-7B",
        "Average":71.45,
        "ARC":67.58,
        "HellaSwag":86.33,
        "MMLU":64.98,
        "TruthfulQA":57.73,
        "Winogrande":80.98,
        "GSM8K":71.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jan-hq\/supermario-slerp-v2",
        "Average":71.45,
        "ARC":69.71,
        "HellaSwag":86.54,
        "MMLU":64.82,
        "TruthfulQA":63.06,
        "Winogrande":80.74,
        "GSM8K":63.84,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A0106",
        "Average":71.44,
        "ARC":66.47,
        "HellaSwag":85.05,
        "MMLU":74.03,
        "TruthfulQA":57.82,
        "Winogrande":82.72,
        "GSM8K":62.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dillfrescott\/amadeus-v0.1",
        "Average":71.42,
        "ARC":68.94,
        "HellaSwag":86.98,
        "MMLU":64.69,
        "TruthfulQA":63.82,
        "Winogrande":79.95,
        "GSM8K":64.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":24.15,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/L0223",
        "Average":71.42,
        "ARC":67.92,
        "HellaSwag":82.99,
        "MMLU":82.59,
        "TruthfulQA":53.59,
        "Winogrande":79.79,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-deepseek-67b-v15.3-4k",
        "Average":71.42,
        "ARC":67.58,
        "HellaSwag":85.15,
        "MMLU":70.38,
        "TruthfulQA":54.88,
        "Winogrande":83.35,
        "GSM8K":67.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.42,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/Deita-20b",
        "Average":71.4,
        "ARC":63.91,
        "HellaSwag":83.11,
        "MMLU":67.4,
        "TruthfulQA":57.29,
        "Winogrande":84.61,
        "GSM8K":72.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LDCC\/LDCC-SOLAR-10.7B",
        "Average":71.4,
        "ARC":67.32,
        "HellaSwag":88.11,
        "MMLU":66.83,
        "TruthfulQA":68.85,
        "Winogrande":83.66,
        "GSM8K":53.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LDCC\/LDCC-SOLAR-10.7B",
        "Average":71.4,
        "ARC":67.58,
        "HellaSwag":88.11,
        "MMLU":66.63,
        "TruthfulQA":68.87,
        "Winogrande":83.66,
        "GSM8K":53.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deacon-34b-qlora-adapter",
        "Average":71.39,
        "ARC":64.85,
        "HellaSwag":85.56,
        "MMLU":76.38,
        "TruthfulQA":56.21,
        "Winogrande":83.11,
        "GSM8K":62.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "Average":71.38,
        "ARC":68.09,
        "HellaSwag":86.2,
        "MMLU":64.26,
        "TruthfulQA":62.78,
        "Winogrande":79.16,
        "GSM8K":67.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mychen76\/mistral-7b-merged-ties",
        "Average":71.37,
        "ARC":67.92,
        "HellaSwag":85.93,
        "MMLU":64.07,
        "TruthfulQA":61.31,
        "Winogrande":80.03,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/MisterUkrainianDPO",
        "Average":71.37,
        "ARC":68.34,
        "HellaSwag":86.78,
        "MMLU":62.92,
        "TruthfulQA":70.18,
        "Winogrande":80.74,
        "GSM8K":59.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/Marcoroni-neural-chat-7B-v2_gsm8k_merged_s",
        "Average":71.37,
        "ARC":67.15,
        "HellaSwag":85.68,
        "MMLU":62.72,
        "TruthfulQA":63.29,
        "Winogrande":79.56,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DiscoResearch\/DiscoLM-70b",
        "Average":71.37,
        "ARC":68.77,
        "HellaSwag":86.1,
        "MMLU":68.58,
        "TruthfulQA":57.64,
        "Winogrande":83.58,
        "GSM8K":63.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"leejunhyeok\/MoMo-70B-LoRA-V1.2_1",
        "Average":71.36,
        "ARC":70.65,
        "HellaSwag":86.4,
        "MMLU":69.9,
        "TruthfulQA":61.41,
        "Winogrande":83.19,
        "GSM8K":56.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/A0113",
        "Average":71.36,
        "ARC":66.38,
        "HellaSwag":84.86,
        "MMLU":74.39,
        "TruthfulQA":59.65,
        "Winogrande":82.0,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Novocoders\/jaskier-7b-NeuralDPO",
        "Average":71.36,
        "ARC":73.46,
        "HellaSwag":88.16,
        "MMLU":63.15,
        "TruthfulQA":59.92,
        "Winogrande":85.48,
        "GSM8K":58.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A0121",
        "Average":71.36,
        "ARC":67.15,
        "HellaSwag":85.45,
        "MMLU":74.93,
        "TruthfulQA":59.61,
        "Winogrande":80.43,
        "GSM8K":60.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janhq\/supermario-slerp-v2",
        "Average":71.35,
        "ARC":69.37,
        "HellaSwag":86.6,
        "MMLU":64.91,
        "TruthfulQA":62.96,
        "Winogrande":80.82,
        "GSM8K":63.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/Solar-10.7B-Cato",
        "Average":71.35,
        "ARC":68.69,
        "HellaSwag":86.16,
        "MMLU":65.76,
        "TruthfulQA":61.68,
        "Winogrande":81.22,
        "GSM8K":64.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/MetaMath-Cybertron-Starling",
        "Average":71.35,
        "ARC":67.75,
        "HellaSwag":86.23,
        "MMLU":65.24,
        "TruthfulQA":55.94,
        "Winogrande":81.45,
        "GSM8K":71.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"binbi\/MoMo-70B-V1.2_1",
        "Average":71.34,
        "ARC":70.9,
        "HellaSwag":86.47,
        "MMLU":69.95,
        "TruthfulQA":61.31,
        "Winogrande":83.11,
        "GSM8K":56.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK-v1.3.0-DPO",
        "Average":71.34,
        "ARC":67.49,
        "HellaSwag":86.48,
        "MMLU":66.57,
        "TruthfulQA":67.81,
        "Winogrande":84.21,
        "GSM8K":55.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AbacusResearch\/haLLAwa3",
        "Average":71.34,
        "ARC":67.83,
        "HellaSwag":87.02,
        "MMLU":64.23,
        "TruthfulQA":63.71,
        "Winogrande":80.51,
        "GSM8K":64.75,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Swisslex\/Mixtral-8x7b-DPO-v0.2",
        "Average":71.32,
        "ARC":70.39,
        "HellaSwag":87.73,
        "MMLU":71.03,
        "TruthfulQA":58.69,
        "Winogrande":82.56,
        "GSM8K":57.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RatanRohith\/NeuralMathChat-7B-V0.2",
        "Average":71.32,
        "ARC":67.41,
        "HellaSwag":85.78,
        "MMLU":65.09,
        "TruthfulQA":59.09,
        "Winogrande":80.27,
        "GSM8K":70.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"brucethemoose\/CapyTessBorosYi-34B-200K-DARE-Ties",
        "Average":71.31,
        "ARC":64.93,
        "HellaSwag":85.92,
        "MMLU":76.18,
        "TruthfulQA":55.84,
        "Winogrande":83.03,
        "GSM8K":61.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rwitz2\/ipo-test",
        "Average":71.29,
        "ARC":67.92,
        "HellaSwag":85.99,
        "MMLU":65.05,
        "TruthfulQA":55.87,
        "Winogrande":80.9,
        "GSM8K":72.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Eris_PrimeV3.075-Vision-7B",
        "Average":71.29,
        "ARC":68.26,
        "HellaSwag":86.44,
        "MMLU":64.9,
        "TruthfulQA":62.72,
        "Winogrande":81.06,
        "GSM8K":64.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aqweteddy\/mistral_tv-neural-marconroni",
        "Average":71.27,
        "ARC":69.2,
        "HellaSwag":86.26,
        "MMLU":65.07,
        "TruthfulQA":60.03,
        "Winogrande":80.9,
        "GSM8K":66.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/OpenHermes-2.5-neural-chat-v3-3-openchat-3.5-1210-Slerp",
        "Average":71.26,
        "ARC":67.92,
        "HellaSwag":86.32,
        "MMLU":65.47,
        "TruthfulQA":56.45,
        "Winogrande":79.72,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SyedAbdul\/test-7B-slerp",
        "Average":71.26,
        "ARC":68.09,
        "HellaSwag":86.08,
        "MMLU":64.57,
        "TruthfulQA":62.6,
        "Winogrande":80.82,
        "GSM8K":65.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-V3-BetaFlavour-7B",
        "Average":71.25,
        "ARC":68.17,
        "HellaSwag":86.88,
        "MMLU":61.39,
        "TruthfulQA":72.92,
        "Winogrande":81.29,
        "GSM8K":56.86,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/MetaMath-Cybertron-Starling",
        "Average":71.25,
        "ARC":67.41,
        "HellaSwag":86.26,
        "MMLU":65.09,
        "TruthfulQA":55.95,
        "Winogrande":81.29,
        "GSM8K":71.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Pigris-7b-v0.4",
        "Average":71.23,
        "ARC":66.72,
        "HellaSwag":86.7,
        "MMLU":64.78,
        "TruthfulQA":55.8,
        "Winogrande":84.21,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Riiid\/sheep-duck-llama-2-70b-v1.1",
        "Average":71.22,
        "ARC":73.12,
        "HellaSwag":87.77,
        "MMLU":70.77,
        "TruthfulQA":64.55,
        "Winogrande":83.11,
        "GSM8K":47.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kimou605\/shadow-clown-BioMistral-7B-DARE",
        "Average":71.21,
        "ARC":67.41,
        "HellaSwag":86.78,
        "MMLU":64.07,
        "TruthfulQA":67.68,
        "Winogrande":81.61,
        "GSM8K":59.74,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"APMIC\/caigun-lora-model-34B-v2",
        "Average":71.19,
        "ARC":65.02,
        "HellaSwag":85.28,
        "MMLU":75.69,
        "TruthfulQA":58.03,
        "Winogrande":83.03,
        "GSM8K":60.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-3-Slerp",
        "Average":71.19,
        "ARC":66.64,
        "HellaSwag":85.43,
        "MMLU":62.19,
        "TruthfulQA":63.2,
        "Winogrande":79.72,
        "GSM8K":69.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Bioxtral-4x7B-v0.1",
        "Average":71.19,
        "ARC":68.34,
        "HellaSwag":87.27,
        "MMLU":63.57,
        "TruthfulQA":68.45,
        "Winogrande":82.87,
        "GSM8K":56.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.4",
        "Average":71.19,
        "ARC":66.81,
        "HellaSwag":86.15,
        "MMLU":65.1,
        "TruthfulQA":58.25,
        "Winogrande":80.03,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/V0201",
        "Average":71.18,
        "ARC":67.24,
        "HellaSwag":83.3,
        "MMLU":88.78,
        "TruthfulQA":53.76,
        "Winogrande":80.51,
        "GSM8K":53.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-3.0-Yi-34B",
        "Average":71.18,
        "ARC":64.59,
        "HellaSwag":85.61,
        "MMLU":75.98,
        "TruthfulQA":56.38,
        "Winogrande":83.5,
        "GSM8K":61.03,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/neural-chat-v3-3-8x7b-MoE",
        "Average":71.17,
        "ARC":66.64,
        "HellaSwag":85.43,
        "MMLU":62.22,
        "TruthfulQA":63.2,
        "Winogrande":79.72,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/NeuralPipe-7B-slerp",
        "Average":71.17,
        "ARC":67.75,
        "HellaSwag":86.15,
        "MMLU":63.94,
        "TruthfulQA":59.8,
        "Winogrande":79.64,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Jingyu6\/MergeTest-7B-slerp",
        "Average":71.17,
        "ARC":67.75,
        "HellaSwag":86.15,
        "MMLU":63.94,
        "TruthfulQA":59.8,
        "Winogrande":79.64,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"abideen\/MonarchCoder-7B",
        "Average":71.17,
        "ARC":68.52,
        "HellaSwag":87.3,
        "MMLU":64.65,
        "TruthfulQA":61.21,
        "Winogrande":80.19,
        "GSM8K":65.13,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deacon-34b-Adapter",
        "Average":71.16,
        "ARC":64.76,
        "HellaSwag":85.57,
        "MMLU":76.28,
        "TruthfulQA":56.24,
        "Winogrande":82.95,
        "GSM8K":61.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Llama-Q",
        "Average":71.13,
        "ARC":65.7,
        "HellaSwag":85.22,
        "MMLU":78.78,
        "TruthfulQA":53.64,
        "Winogrande":83.03,
        "GSM8K":60.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Mathral",
        "Average":71.13,
        "ARC":66.3,
        "HellaSwag":86.17,
        "MMLU":63.27,
        "TruthfulQA":58.79,
        "Winogrande":79.56,
        "GSM8K":72.71,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0304",
        "Average":71.13,
        "ARC":67.58,
        "HellaSwag":82.78,
        "MMLU":84.5,
        "TruthfulQA":53.35,
        "Winogrande":78.53,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v18.1-32k",
        "Average":71.13,
        "ARC":68.09,
        "HellaSwag":84.29,
        "MMLU":71.08,
        "TruthfulQA":56.74,
        "Winogrande":81.22,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/Experiment26-12B",
        "Average":71.12,
        "ARC":68.86,
        "HellaSwag":88.59,
        "MMLU":63.75,
        "TruthfulQA":72.12,
        "Winogrande":83.43,
        "GSM8K":49.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/stealth-v1.3",
        "Average":71.12,
        "ARC":67.49,
        "HellaSwag":86.74,
        "MMLU":64.45,
        "TruthfulQA":55.71,
        "Winogrande":80.74,
        "GSM8K":71.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NExtNewChattingAI\/shark_tank_ai_7_b",
        "Average":71.1,
        "ARC":66.89,
        "HellaSwag":86.61,
        "MMLU":65.27,
        "TruthfulQA":60.19,
        "Winogrande":81.93,
        "GSM8K":65.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/InnerILLM-7B-slerp",
        "Average":71.09,
        "ARC":67.58,
        "HellaSwag":86.19,
        "MMLU":64.15,
        "TruthfulQA":59.84,
        "Winogrande":80.11,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FredrikBL\/NeuralPipe-7B-slerp",
        "Average":71.09,
        "ARC":67.58,
        "HellaSwag":86.19,
        "MMLU":64.15,
        "TruthfulQA":59.84,
        "Winogrande":80.11,
        "GSM8K":68.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FredrikBL\/NeuralPipe-7B-slerp",
        "Average":71.09,
        "ARC":67.75,
        "HellaSwag":86.17,
        "MMLU":64.05,
        "TruthfulQA":59.85,
        "Winogrande":80.19,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AurelPx\/NeuralPipe-7B-slerp",
        "Average":71.09,
        "ARC":67.75,
        "HellaSwag":86.17,
        "MMLU":64.05,
        "TruthfulQA":59.85,
        "Winogrande":80.19,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Samee-ur\/NeuralPipe-7B-slerp",
        "Average":71.09,
        "ARC":67.75,
        "HellaSwag":86.17,
        "MMLU":64.05,
        "TruthfulQA":59.85,
        "Winogrande":80.19,
        "GSM8K":68.54,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mychen76\/mistral-7b-merged-slerp",
        "Average":71.09,
        "ARC":67.75,
        "HellaSwag":86.17,
        "MMLU":64.05,
        "TruthfulQA":59.85,
        "Winogrande":80.19,
        "GSM8K":68.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-2.0-Yi-34B",
        "Average":71.09,
        "ARC":64.33,
        "HellaSwag":85.66,
        "MMLU":76.09,
        "TruthfulQA":55.3,
        "Winogrande":83.11,
        "GSM8K":62.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zhengr\/NeuralPipe-7B-slerp",
        "Average":71.08,
        "ARC":67.41,
        "HellaSwag":86.12,
        "MMLU":64.07,
        "TruthfulQA":59.82,
        "Winogrande":79.79,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Abhinav7\/NeuralPipe-7B-slerp",
        "Average":71.08,
        "ARC":67.41,
        "HellaSwag":86.12,
        "MMLU":64.07,
        "TruthfulQA":59.82,
        "Winogrande":79.79,
        "GSM8K":69.29,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_SOLAR",
        "Average":71.08,
        "ARC":71.59,
        "HellaSwag":88.4,
        "MMLU":65.29,
        "TruthfulQA":69.21,
        "Winogrande":81.06,
        "GSM8K":50.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":15.97,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dillfrescott\/Nous-Hermes-2-SOLAR-10.7B-x2-MoE",
        "Average":71.08,
        "ARC":67.15,
        "HellaSwag":84.83,
        "MMLU":66.52,
        "TruthfulQA":55.85,
        "Winogrande":83.11,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":19.19,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Loyal-Toppy-Bruins-Maid-7B-DARE",
        "Average":71.07,
        "ARC":68.86,
        "HellaSwag":86.03,
        "MMLU":64.84,
        "TruthfulQA":61.19,
        "Winogrande":79.72,
        "GSM8K":65.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/MetaMath-bagel-34b-v0.2-c1500",
        "Average":71.06,
        "ARC":63.91,
        "HellaSwag":82.43,
        "MMLU":74.51,
        "TruthfulQA":53.7,
        "Winogrande":80.98,
        "GSM8K":70.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rufjdk5480\/WestLake-dpo-train-sft-v1",
        "Average":71.06,
        "ARC":65.78,
        "HellaSwag":85.76,
        "MMLU":61.8,
        "TruthfulQA":67.8,
        "Winogrande":82.79,
        "GSM8K":62.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/smol_bruin-7b",
        "Average":71.05,
        "ARC":67.58,
        "HellaSwag":86.48,
        "MMLU":65.05,
        "TruthfulQA":55.65,
        "Winogrande":81.14,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-RAW-1701",
        "Average":71.04,
        "ARC":66.81,
        "HellaSwag":85.79,
        "MMLU":75.44,
        "TruthfulQA":57.91,
        "Winogrande":80.35,
        "GSM8K":59.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/L0225",
        "Average":71.04,
        "ARC":68.17,
        "HellaSwag":82.73,
        "MMLU":83.04,
        "TruthfulQA":54.19,
        "Winogrande":78.61,
        "GSM8K":59.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/OpenMia-Indo-Mistral-7b-v3",
        "Average":71.04,
        "ARC":66.13,
        "HellaSwag":85.47,
        "MMLU":64.03,
        "TruthfulQA":60.05,
        "Winogrande":82.95,
        "GSM8K":67.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nisten\/shqiponja-15b-v1",
        "Average":71.03,
        "ARC":66.38,
        "HellaSwag":85.26,
        "MMLU":64.62,
        "TruthfulQA":56.81,
        "Winogrande":84.06,
        "GSM8K":69.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":15.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Metabird-7B",
        "Average":71.03,
        "ARC":69.54,
        "HellaSwag":87.54,
        "MMLU":65.27,
        "TruthfulQA":57.94,
        "Winogrande":83.03,
        "GSM8K":62.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/NeuralPipe-7B-slerp",
        "Average":71.01,
        "ARC":67.58,
        "HellaSwag":86.17,
        "MMLU":64.06,
        "TruthfulQA":59.84,
        "Winogrande":80.19,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DeepKarkhanis\/NeuralPipe-7B-slerp",
        "Average":71.01,
        "ARC":67.58,
        "HellaSwag":86.17,
        "MMLU":64.06,
        "TruthfulQA":59.84,
        "Winogrande":80.19,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"superlazycoder\/NeuralPipe-7B-slerp",
        "Average":71.01,
        "ARC":67.58,
        "HellaSwag":86.17,
        "MMLU":64.06,
        "TruthfulQA":59.84,
        "Winogrande":80.19,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DeepKarkhanis\/Mistral-Passthrough-8L-10B",
        "Average":71.01,
        "ARC":67.58,
        "HellaSwag":86.17,
        "MMLU":64.06,
        "TruthfulQA":59.84,
        "Winogrande":80.19,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/WestuccineBagel-7B-slerp",
        "Average":71.01,
        "ARC":69.37,
        "HellaSwag":86.53,
        "MMLU":64.8,
        "TruthfulQA":67.06,
        "Winogrande":82.56,
        "GSM8K":55.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-v2",
        "Average":71.0,
        "ARC":67.92,
        "HellaSwag":85.61,
        "MMLU":75.22,
        "TruthfulQA":56.74,
        "Winogrande":81.61,
        "GSM8K":58.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-2-SOLAR-10.7B",
        "Average":71.0,
        "ARC":66.72,
        "HellaSwag":84.89,
        "MMLU":66.3,
        "TruthfulQA":55.82,
        "Winogrande":82.79,
        "GSM8K":69.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":185.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/yi-34b-200k-rawrr-dpo-1",
        "Average":70.97,
        "ARC":65.44,
        "HellaSwag":85.69,
        "MMLU":76.09,
        "TruthfulQA":54.0,
        "Winogrande":82.79,
        "GSM8K":61.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/Yi-34B-Llama",
        "Average":70.95,
        "ARC":64.59,
        "HellaSwag":85.63,
        "MMLU":76.31,
        "TruthfulQA":55.6,
        "Winogrande":82.79,
        "GSM8K":60.8,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":54.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v18.1-32k",
        "Average":70.95,
        "ARC":67.66,
        "HellaSwag":84.3,
        "MMLU":70.94,
        "TruthfulQA":56.72,
        "Winogrande":80.98,
        "GSM8K":65.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Loyal-Toppy-Bruins-Maid-7B-DARE",
        "Average":70.95,
        "ARC":68.69,
        "HellaSwag":86.04,
        "MMLU":64.89,
        "TruthfulQA":61.26,
        "Winogrande":79.56,
        "GSM8K":65.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/KukulStanta-7B",
        "Average":70.95,
        "ARC":68.43,
        "HellaSwag":86.37,
        "MMLU":65.0,
        "TruthfulQA":62.19,
        "Winogrande":80.03,
        "GSM8K":63.68,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decapoda-research\/Antares-11b-v2",
        "Average":70.94,
        "ARC":69.03,
        "HellaSwag":87.54,
        "MMLU":66.19,
        "TruthfulQA":59.17,
        "Winogrande":83.19,
        "GSM8K":60.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIDC-ai-business\/Marcoroni-7B-v2",
        "Average":70.92,
        "ARC":68.26,
        "HellaSwag":86.27,
        "MMLU":63.39,
        "TruthfulQA":61.96,
        "Winogrande":80.11,
        "GSM8K":65.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/WizardLM-Math-70B-v0.1",
        "Average":70.92,
        "ARC":67.06,
        "HellaSwag":86.01,
        "MMLU":69.14,
        "TruthfulQA":57.07,
        "Winogrande":81.77,
        "GSM8K":64.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"agpl-3.0",
        "Available on the Hub":68.98,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Seraph-openchat-3.5-1210-Slerp",
        "Average":70.89,
        "ARC":68.0,
        "HellaSwag":86.13,
        "MMLU":65.5,
        "TruthfulQA":54.12,
        "Winogrande":79.56,
        "GSM8K":72.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Draco-8x7B",
        "Average":70.89,
        "ARC":65.02,
        "HellaSwag":85.24,
        "MMLU":64.96,
        "TruthfulQA":62.65,
        "Winogrande":80.66,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bhavinjawade\/SuperAligned-Jawade",
        "Average":70.86,
        "ARC":71.59,
        "HellaSwag":90.58,
        "MMLU":60.81,
        "TruthfulQA":69.17,
        "Winogrande":83.82,
        "GSM8K":49.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Nitral-AI\/Mika-Lelantacles-7b-Longtext",
        "Average":70.86,
        "ARC":67.66,
        "HellaSwag":86.34,
        "MMLU":63.29,
        "TruthfulQA":70.15,
        "Winogrande":79.79,
        "GSM8K":57.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rizla\/trrapi-16",
        "Average":70.85,
        "ARC":66.38,
        "HellaSwag":85.05,
        "MMLU":64.84,
        "TruthfulQA":56.47,
        "Winogrande":84.14,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yunconglong\/7Bx4_DPO_700",
        "Average":70.85,
        "ARC":64.68,
        "HellaSwag":86.12,
        "MMLU":62.23,
        "TruthfulQA":68.99,
        "Winogrande":79.72,
        "GSM8K":63.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chanwit\/flux-7b-v0.1",
        "Average":70.85,
        "ARC":67.06,
        "HellaSwag":86.18,
        "MMLU":65.4,
        "TruthfulQA":55.05,
        "Winogrande":79.01,
        "GSM8K":72.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/MiaAffogato-Indo-Mistral-7b",
        "Average":70.83,
        "ARC":66.38,
        "HellaSwag":85.43,
        "MMLU":64.11,
        "TruthfulQA":58.18,
        "Winogrande":83.19,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Lelantos-low-tune",
        "Average":70.82,
        "ARC":67.06,
        "HellaSwag":86.06,
        "MMLU":64.11,
        "TruthfulQA":61.33,
        "Winogrande":79.56,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/MarcoHermes",
        "Average":70.79,
        "ARC":66.21,
        "HellaSwag":85.5,
        "MMLU":64.81,
        "TruthfulQA":58.46,
        "Winogrande":80.74,
        "GSM8K":68.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AbacusResearch\/Jallabi-34B",
        "Average":70.73,
        "ARC":66.04,
        "HellaSwag":83.81,
        "MMLU":76.4,
        "TruthfulQA":51.46,
        "Winogrande":81.45,
        "GSM8K":65.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/Terminis-7B",
        "Average":70.73,
        "ARC":67.92,
        "HellaSwag":86.22,
        "MMLU":64.07,
        "TruthfulQA":67.31,
        "Winogrande":81.29,
        "GSM8K":57.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/Nyxene-v3-11B",
        "Average":70.72,
        "ARC":69.62,
        "HellaSwag":85.33,
        "MMLU":64.75,
        "TruthfulQA":60.91,
        "Winogrande":80.19,
        "GSM8K":63.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"one-man-army\/una-neural-chat-v3-3-P2-OMA",
        "Average":70.72,
        "ARC":67.32,
        "HellaSwag":86.33,
        "MMLU":63.14,
        "TruthfulQA":65.49,
        "Winogrande":79.79,
        "GSM8K":62.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-02-v0",
        "Average":70.69,
        "ARC":67.49,
        "HellaSwag":85.78,
        "MMLU":64.1,
        "TruthfulQA":60.52,
        "Winogrande":79.01,
        "GSM8K":67.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/stealth-v1.2",
        "Average":70.68,
        "ARC":66.38,
        "HellaSwag":86.14,
        "MMLU":64.33,
        "TruthfulQA":54.23,
        "Winogrande":80.74,
        "GSM8K":72.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/Merged-AGI-7B",
        "Average":70.68,
        "ARC":68.6,
        "HellaSwag":86.16,
        "MMLU":65.02,
        "TruthfulQA":60.24,
        "Winogrande":80.66,
        "GSM8K":63.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vishnukv\/speechless-mistral-dolphin-orca-platypus-samantha-WestSeverusJaskier-7b",
        "Average":70.67,
        "ARC":68.0,
        "HellaSwag":86.56,
        "MMLU":64.92,
        "TruthfulQA":59.9,
        "Winogrande":80.66,
        "GSM8K":63.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/internlm2-20b-llama",
        "Average":70.66,
        "ARC":64.59,
        "HellaSwag":83.12,
        "MMLU":67.27,
        "TruthfulQA":54.13,
        "Winogrande":84.21,
        "GSM8K":70.66,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v3.2",
        "Average":70.65,
        "ARC":69.45,
        "HellaSwag":86.91,
        "MMLU":70.68,
        "TruthfulQA":58.81,
        "Winogrande":80.98,
        "GSM8K":57.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/internlm2-20b-llama",
        "Average":70.61,
        "ARC":64.68,
        "HellaSwag":83.16,
        "MMLU":67.17,
        "TruthfulQA":54.17,
        "Winogrande":84.29,
        "GSM8K":70.2,
        "Type":"pretrained",
        "Architecture":"L;l;a;m;a;F;o;r;C;a;u;s;a;l;L;M",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/strix-rufipes-70b",
        "Average":70.61,
        "ARC":71.33,
        "HellaSwag":87.86,
        "MMLU":69.13,
        "TruthfulQA":56.72,
        "Winogrande":84.77,
        "GSM8K":53.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/Diana-7B",
        "Average":70.6,
        "ARC":68.34,
        "HellaSwag":86.73,
        "MMLU":64.58,
        "TruthfulQA":60.55,
        "Winogrande":80.19,
        "GSM8K":63.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/dolphin-2.2-70b",
        "Average":70.6,
        "ARC":70.05,
        "HellaSwag":85.97,
        "MMLU":69.18,
        "TruthfulQA":60.14,
        "Winogrande":81.45,
        "GSM8K":56.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/MetaMath-Cybertron",
        "Average":70.6,
        "ARC":66.47,
        "HellaSwag":85.54,
        "MMLU":63.71,
        "TruthfulQA":57.71,
        "Winogrande":79.64,
        "GSM8K":70.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dreamgen\/opus-v1-34b",
        "Average":70.57,
        "ARC":64.33,
        "HellaSwag":84.9,
        "MMLU":75.43,
        "TruthfulQA":55.92,
        "Winogrande":81.29,
        "GSM8K":61.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":34.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DrNicefellow\/ChatAllInOne-Yi-34B-200K-V1",
        "Average":70.56,
        "ARC":65.96,
        "HellaSwag":84.53,
        "MMLU":74.13,
        "TruthfulQA":56.96,
        "Winogrande":82.72,
        "GSM8K":59.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DrNicefellow\/ChatAllInOne-Yi-34B-200K-V1",
        "Average":70.55,
        "ARC":65.96,
        "HellaSwag":84.58,
        "MMLU":73.95,
        "TruthfulQA":56.82,
        "Winogrande":82.48,
        "GSM8K":59.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"one-man-army\/una-neural-chat-v3-3-P2-OMA",
        "Average":70.55,
        "ARC":67.24,
        "HellaSwag":86.34,
        "MMLU":63.18,
        "TruthfulQA":65.48,
        "Winogrande":79.64,
        "GSM8K":61.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/Eida_10.7B",
        "Average":70.54,
        "ARC":70.9,
        "HellaSwag":87.36,
        "MMLU":64.3,
        "TruthfulQA":71.33,
        "Winogrande":81.22,
        "GSM8K":48.14,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenPipe\/mistral-ft-optimized-1227",
        "Average":70.54,
        "ARC":67.06,
        "HellaSwag":85.85,
        "MMLU":65.19,
        "TruthfulQA":54.57,
        "Winogrande":78.85,
        "GSM8K":71.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":76.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/kaori-70b-v1",
        "Average":70.54,
        "ARC":69.8,
        "HellaSwag":87.36,
        "MMLU":70.82,
        "TruthfulQA":58.81,
        "Winogrande":84.06,
        "GSM8K":52.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Open_Hermes_Maid_Sam_Mistral_dtv0.1",
        "Average":70.53,
        "ARC":67.75,
        "HellaSwag":86.39,
        "MMLU":64.6,
        "TruthfulQA":57.97,
        "Winogrande":81.14,
        "GSM8K":65.35,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Open_Maid_Samantha_Hermes_Orca_dare_ties",
        "Average":70.53,
        "ARC":67.75,
        "HellaSwag":86.39,
        "MMLU":64.6,
        "TruthfulQA":57.97,
        "Winogrande":81.14,
        "GSM8K":65.35,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Eclipse-13B-dpo",
        "Average":70.53,
        "ARC":64.59,
        "HellaSwag":85.0,
        "MMLU":64.85,
        "TruthfulQA":54.76,
        "Winogrande":84.61,
        "GSM8K":69.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/Mistral_Sonyichi-7B-slerp",
        "Average":70.52,
        "ARC":67.49,
        "HellaSwag":86.43,
        "MMLU":63.58,
        "TruthfulQA":63.25,
        "Winogrande":78.53,
        "GSM8K":63.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"openrail",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.2",
        "Average":70.51,
        "ARC":64.59,
        "HellaSwag":83.44,
        "MMLU":75.53,
        "TruthfulQA":55.29,
        "Winogrande":81.61,
        "GSM8K":62.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChuckMcSneed\/Gembo-v1-70b",
        "Average":70.51,
        "ARC":71.25,
        "HellaSwag":86.98,
        "MMLU":70.85,
        "TruthfulQA":63.25,
        "Winogrande":80.51,
        "GSM8K":50.19,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenPipe\/mistral-ft-optimized-1227",
        "Average":70.5,
        "ARC":67.24,
        "HellaSwag":85.9,
        "MMLU":65.17,
        "TruthfulQA":54.51,
        "Winogrande":78.85,
        "GSM8K":71.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":76.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RaduGabriel\/SirUkrainian",
        "Average":70.5,
        "ARC":67.32,
        "HellaSwag":85.54,
        "MMLU":63.14,
        "TruthfulQA":68.74,
        "Winogrande":81.53,
        "GSM8K":56.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.2",
        "Average":70.49,
        "ARC":64.51,
        "HellaSwag":83.47,
        "MMLU":75.64,
        "TruthfulQA":55.27,
        "Winogrande":81.37,
        "GSM8K":62.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freeCS-dot-org\/ThetaWave-7B-v0.1",
        "Average":70.49,
        "ARC":68.09,
        "HellaSwag":86.33,
        "MMLU":62.11,
        "TruthfulQA":71.68,
        "Winogrande":79.08,
        "GSM8K":55.65,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/JustToSuffer-7B-slerp",
        "Average":70.48,
        "ARC":68.94,
        "HellaSwag":86.79,
        "MMLU":64.66,
        "TruthfulQA":62.69,
        "Winogrande":80.03,
        "GSM8K":59.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AetherResearch\/Cerebrum-1.0-8x7b",
        "Average":70.47,
        "ARC":68.09,
        "HellaSwag":87.3,
        "MMLU":72.45,
        "TruthfulQA":50.63,
        "Winogrande":82.4,
        "GSM8K":61.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":78.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Swisslex\/Mixtral-8x7b-DPO-v0.1",
        "Average":70.45,
        "ARC":70.9,
        "HellaSwag":87.61,
        "MMLU":70.66,
        "TruthfulQA":57.38,
        "Winogrande":82.4,
        "GSM8K":53.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_37-7B-dare_ties",
        "Average":70.44,
        "ARC":70.31,
        "HellaSwag":86.82,
        "MMLU":59.4,
        "TruthfulQA":75.23,
        "Winogrande":81.85,
        "GSM8K":49.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Konstanta-Gamma-10.9B",
        "Average":70.44,
        "ARC":68.26,
        "HellaSwag":87.38,
        "MMLU":64.5,
        "TruthfulQA":64.18,
        "Winogrande":80.98,
        "GSM8K":57.32,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.95,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/NewtoccineLake-slerp-7B",
        "Average":70.43,
        "ARC":68.69,
        "HellaSwag":85.98,
        "MMLU":64.62,
        "TruthfulQA":59.95,
        "Winogrande":81.53,
        "GSM8K":61.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2.01",
        "Average":70.43,
        "ARC":68.86,
        "HellaSwag":86.12,
        "MMLU":63.9,
        "TruthfulQA":63.5,
        "Winogrande":80.51,
        "GSM8K":59.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/MistInst-v0.2_ochat-3.5-0106_dpo-binarized-NeuralTrix-7B",
        "Average":70.42,
        "ARC":69.71,
        "HellaSwag":85.86,
        "MMLU":61.23,
        "TruthfulQA":67.93,
        "Winogrande":82.08,
        "GSM8K":55.72,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/BagelLake-7B-slerp",
        "Average":70.41,
        "ARC":68.26,
        "HellaSwag":85.07,
        "MMLU":64.3,
        "TruthfulQA":63.76,
        "Winogrande":83.66,
        "GSM8K":57.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-8x7B-MoE",
        "Average":70.4,
        "ARC":68.77,
        "HellaSwag":86.11,
        "MMLU":63.86,
        "TruthfulQA":63.5,
        "Winogrande":80.51,
        "GSM8K":59.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dreamgen\/opus-v1-34b",
        "Average":70.39,
        "ARC":64.42,
        "HellaSwag":84.85,
        "MMLU":75.38,
        "TruthfulQA":55.88,
        "Winogrande":81.61,
        "GSM8K":60.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":34.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Sinerva_7B",
        "Average":70.38,
        "ARC":70.14,
        "HellaSwag":85.59,
        "MMLU":61.77,
        "TruthfulQA":59.93,
        "Winogrande":82.56,
        "GSM8K":62.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openagi-project\/OpenAGI-7B-v0.2",
        "Average":70.37,
        "ARC":68.52,
        "HellaSwag":86.03,
        "MMLU":63.02,
        "TruthfulQA":72.04,
        "Winogrande":79.16,
        "GSM8K":53.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kukedlc\/FrankeMerge-12.5B",
        "Average":70.36,
        "ARC":68.34,
        "HellaSwag":87.74,
        "MMLU":64.01,
        "TruthfulQA":66.88,
        "Winogrande":81.53,
        "GSM8K":53.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Prima-Pastacles-7b-128k",
        "Average":70.36,
        "ARC":68.09,
        "HellaSwag":86.57,
        "MMLU":64.58,
        "TruthfulQA":62.51,
        "Winogrande":81.06,
        "GSM8K":59.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HyperbeeAI\/Tulpar-7b-v2",
        "Average":70.36,
        "ARC":67.49,
        "HellaSwag":84.89,
        "MMLU":63.02,
        "TruthfulQA":63.65,
        "Winogrande":79.48,
        "GSM8K":63.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChuckMcSneed\/Gembo-v1.1-70b",
        "Average":70.35,
        "ARC":70.99,
        "HellaSwag":86.9,
        "MMLU":70.63,
        "TruthfulQA":62.45,
        "Winogrande":80.51,
        "GSM8K":50.64,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openagi-project\/OpenAGI-7B-v0.1-test-ada",
        "Average":70.34,
        "ARC":66.72,
        "HellaSwag":86.13,
        "MMLU":63.53,
        "TruthfulQA":69.55,
        "Winogrande":79.48,
        "GSM8K":56.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openagi-project\/OpenAGI-7B-v0.1",
        "Average":70.34,
        "ARC":66.72,
        "HellaSwag":86.13,
        "MMLU":63.53,
        "TruthfulQA":69.55,
        "Winogrande":79.48,
        "GSM8K":56.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ValiantLabs\/ShiningValiant",
        "Average":70.34,
        "ARC":68.69,
        "HellaSwag":87.31,
        "MMLU":69.64,
        "TruthfulQA":55.78,
        "Winogrande":84.14,
        "GSM8K":56.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":72.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-mixtral-8x7b-v1",
        "Average":70.34,
        "ARC":68.09,
        "HellaSwag":85.76,
        "MMLU":71.49,
        "TruthfulQA":55.31,
        "Winogrande":82.08,
        "GSM8K":59.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-mixtral-8x7b-v0.1",
        "Average":70.34,
        "ARC":68.09,
        "HellaSwag":85.76,
        "MMLU":71.49,
        "TruthfulQA":55.31,
        "Winogrande":82.08,
        "GSM8K":59.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Falkor-7b",
        "Average":70.33,
        "ARC":68.26,
        "HellaSwag":85.84,
        "MMLU":63.98,
        "TruthfulQA":63.08,
        "Winogrande":80.35,
        "GSM8K":60.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Novocoders\/Lotus-7B",
        "Average":70.32,
        "ARC":66.47,
        "HellaSwag":84.8,
        "MMLU":64.64,
        "TruthfulQA":55.57,
        "Winogrande":82.16,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"one-man-army\/una-neural-chat-v3-3-P1-OMA",
        "Average":70.32,
        "ARC":66.81,
        "HellaSwag":85.92,
        "MMLU":63.37,
        "TruthfulQA":64.35,
        "Winogrande":79.64,
        "GSM8K":61.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AtAndDev\/CapybaraMarcoroni-7B",
        "Average":70.32,
        "ARC":65.02,
        "HellaSwag":84.81,
        "MMLU":65.2,
        "TruthfulQA":57.07,
        "Winogrande":81.14,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RaduGabriel\/MUZD",
        "Average":70.32,
        "ARC":66.81,
        "HellaSwag":86.54,
        "MMLU":62.87,
        "TruthfulQA":65.73,
        "Winogrande":81.37,
        "GSM8K":58.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"VAGOsolutions\/SauerkrautLM-7b-LaserChat",
        "Average":70.32,
        "ARC":67.58,
        "HellaSwag":83.58,
        "MMLU":64.93,
        "TruthfulQA":56.08,
        "Winogrande":80.9,
        "GSM8K":68.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-34B-v1.5b",
        "Average":70.31,
        "ARC":63.91,
        "HellaSwag":84.43,
        "MMLU":76.26,
        "TruthfulQA":53.12,
        "Winogrande":81.29,
        "GSM8K":62.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Silicon-Maid-7B",
        "Average":70.31,
        "ARC":68.17,
        "HellaSwag":86.52,
        "MMLU":64.58,
        "TruthfulQA":61.64,
        "Winogrande":79.01,
        "GSM8K":61.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Asherah_7B",
        "Average":70.31,
        "ARC":68.17,
        "HellaSwag":86.05,
        "MMLU":63.92,
        "TruthfulQA":58.07,
        "Winogrande":78.77,
        "GSM8K":66.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chanwit\/flux-7b-v0.2",
        "Average":70.3,
        "ARC":66.55,
        "HellaSwag":86.12,
        "MMLU":65.38,
        "TruthfulQA":51.8,
        "Winogrande":79.32,
        "GSM8K":72.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eric111\/openchat-3.5-0106-128k-DPO",
        "Average":70.3,
        "ARC":68.09,
        "HellaSwag":83.82,
        "MMLU":64.74,
        "TruthfulQA":56.34,
        "Winogrande":81.53,
        "GSM8K":67.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"froggeric\/WestLake-10.7B-v2",
        "Average":70.28,
        "ARC":71.16,
        "HellaSwag":87.93,
        "MMLU":63.81,
        "TruthfulQA":64.91,
        "Winogrande":85.4,
        "GSM8K":48.45,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"APMIC\/caigun-lora-model-34B-v3",
        "Average":70.27,
        "ARC":66.89,
        "HellaSwag":84.77,
        "MMLU":75.41,
        "TruthfulQA":56.47,
        "Winogrande":83.58,
        "GSM8K":54.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Maylin-7b",
        "Average":70.26,
        "ARC":66.81,
        "HellaSwag":86.4,
        "MMLU":64.73,
        "TruthfulQA":60.24,
        "Winogrande":79.64,
        "GSM8K":63.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-Chupacabra-7B-v2.01-Slerp",
        "Average":70.26,
        "ARC":65.96,
        "HellaSwag":85.46,
        "MMLU":63.82,
        "TruthfulQA":56.16,
        "Winogrande":80.03,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"v1olet\/v1olet_merged_dpo_7B",
        "Average":70.26,
        "ARC":71.33,
        "HellaSwag":87.34,
        "MMLU":64.13,
        "TruthfulQA":63.37,
        "Winogrande":82.0,
        "GSM8K":53.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/MisterUkrainian",
        "Average":70.23,
        "ARC":67.83,
        "HellaSwag":86.32,
        "MMLU":62.53,
        "TruthfulQA":67.26,
        "Winogrande":80.51,
        "GSM8K":56.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/SynthIA-70B-v1.5",
        "Average":70.23,
        "ARC":69.37,
        "HellaSwag":86.97,
        "MMLU":69.16,
        "TruthfulQA":57.4,
        "Winogrande":83.66,
        "GSM8K":54.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.1",
        "Average":70.23,
        "ARC":64.68,
        "HellaSwag":83.49,
        "MMLU":74.94,
        "TruthfulQA":56.78,
        "Winogrande":81.29,
        "GSM8K":60.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ChaoticNeutrals\/InfinityNexus_9B",
        "Average":70.23,
        "ARC":68.69,
        "HellaSwag":86.28,
        "MMLU":64.49,
        "TruthfulQA":65.14,
        "Winogrande":80.82,
        "GSM8K":55.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":8.99,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.5",
        "Average":70.22,
        "ARC":64.76,
        "HellaSwag":83.46,
        "MMLU":75.01,
        "TruthfulQA":56.88,
        "Winogrande":81.29,
        "GSM8K":59.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/MetaMath-Chupacabra-7B-v2.01-Slerp",
        "Average":70.21,
        "ARC":66.13,
        "HellaSwag":85.46,
        "MMLU":63.92,
        "TruthfulQA":56.15,
        "Winogrande":79.48,
        "GSM8K":70.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rombodawg\/Everyone-LLM-7b-Base",
        "Average":70.21,
        "ARC":66.38,
        "HellaSwag":86.02,
        "MMLU":64.94,
        "TruthfulQA":57.89,
        "Winogrande":80.43,
        "GSM8K":65.58,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/MetaMath-Tulpar-7b-v2-Slerp",
        "Average":70.2,
        "ARC":65.61,
        "HellaSwag":85.16,
        "MMLU":63.49,
        "TruthfulQA":56.5,
        "Winogrande":79.48,
        "GSM8K":70.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"grimjim\/kukulemon-7B",
        "Average":70.2,
        "ARC":67.75,
        "HellaSwag":86.1,
        "MMLU":65.09,
        "TruthfulQA":61.99,
        "Winogrande":79.24,
        "GSM8K":61.03,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/OpenHermes-2.5-neural-chat-v3-2-Slerp",
        "Average":70.2,
        "ARC":67.49,
        "HellaSwag":85.42,
        "MMLU":64.13,
        "TruthfulQA":61.05,
        "Winogrande":80.03,
        "GSM8K":63.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rishiraj\/oswald-7b",
        "Average":70.19,
        "ARC":66.38,
        "HellaSwag":85.18,
        "MMLU":65.34,
        "TruthfulQA":54.07,
        "Winogrande":80.9,
        "GSM8K":69.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hfl\/chinese-mixtral-instruct",
        "Average":70.19,
        "ARC":67.75,
        "HellaSwag":85.67,
        "MMLU":71.53,
        "TruthfulQA":57.46,
        "Winogrande":83.11,
        "GSM8K":55.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Luna_7B",
        "Average":70.17,
        "ARC":68.86,
        "HellaSwag":86.28,
        "MMLU":64.06,
        "TruthfulQA":58.09,
        "Winogrande":79.08,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/ToppyLake-Bagel-7B-slerp",
        "Average":70.14,
        "ARC":67.66,
        "HellaSwag":85.7,
        "MMLU":64.87,
        "TruthfulQA":61.74,
        "Winogrande":83.19,
        "GSM8K":57.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"invalid-coder\/Starling-LM-7B-beta-laser-dpo",
        "Average":70.14,
        "ARC":67.41,
        "HellaSwag":83.38,
        "MMLU":65.29,
        "TruthfulQA":55.47,
        "Winogrande":81.37,
        "GSM8K":67.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_Gony_v0.2",
        "Average":70.13,
        "ARC":68.86,
        "HellaSwag":86.61,
        "MMLU":70.33,
        "TruthfulQA":59.46,
        "Winogrande":82.4,
        "GSM8K":53.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Stopwolf\/Tito-7B-slerp",
        "Average":70.13,
        "ARC":68.09,
        "HellaSwag":86.38,
        "MMLU":64.01,
        "TruthfulQA":57.01,
        "Winogrande":81.69,
        "GSM8K":63.61,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Newton-OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "Average":70.13,
        "ARC":68.77,
        "HellaSwag":85.0,
        "MMLU":65.06,
        "TruthfulQA":56.84,
        "Winogrande":80.11,
        "GSM8K":64.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-RAW-2301",
        "Average":70.12,
        "ARC":66.04,
        "HellaSwag":84.7,
        "MMLU":74.89,
        "TruthfulQA":56.89,
        "Winogrande":81.14,
        "GSM8K":57.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "Average":70.11,
        "ARC":64.59,
        "HellaSwag":85.39,
        "MMLU":64.27,
        "TruthfulQA":55.14,
        "Winogrande":79.64,
        "GSM8K":71.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-34B-v1.4",
        "Average":70.11,
        "ARC":64.59,
        "HellaSwag":83.37,
        "MMLU":75.02,
        "TruthfulQA":56.79,
        "Winogrande":81.22,
        "GSM8K":59.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"upstage\/SOLAR-0-70b-16bit",
        "Average":70.11,
        "ARC":71.08,
        "HellaSwag":87.89,
        "MMLU":70.58,
        "TruthfulQA":62.25,
        "Winogrande":83.58,
        "GSM8K":45.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":70.0,
        "Model Sha":252.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/Lonepino-11B",
        "Average":70.1,
        "ARC":68.26,
        "HellaSwag":84.57,
        "MMLU":63.76,
        "TruthfulQA":63.45,
        "Winogrande":78.93,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jsfs11\/HighdensityRPMerge-7B",
        "Average":70.1,
        "ARC":67.41,
        "HellaSwag":86.58,
        "MMLU":64.73,
        "TruthfulQA":60.44,
        "Winogrande":79.4,
        "GSM8K":62.02,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Prima-LelantaclesV6.5-7b",
        "Average":70.09,
        "ARC":67.75,
        "HellaSwag":85.7,
        "MMLU":63.12,
        "TruthfulQA":62.12,
        "Winogrande":82.48,
        "GSM8K":59.36,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/Westuccine-7B-slerp",
        "Average":70.08,
        "ARC":69.37,
        "HellaSwag":87.34,
        "MMLU":63.8,
        "TruthfulQA":69.34,
        "Winogrande":82.08,
        "GSM8K":48.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.4",
        "Average":70.08,
        "ARC":63.65,
        "HellaSwag":83.3,
        "MMLU":74.93,
        "TruthfulQA":57.26,
        "Winogrande":80.43,
        "GSM8K":60.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-Tulpar-7b-v2-Slerp",
        "Average":70.07,
        "ARC":65.96,
        "HellaSwag":85.11,
        "MMLU":63.37,
        "TruthfulQA":56.44,
        "Winogrande":79.08,
        "GSM8K":70.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.3",
        "Average":70.06,
        "ARC":63.74,
        "HellaSwag":83.3,
        "MMLU":75.08,
        "TruthfulQA":57.31,
        "Winogrande":80.66,
        "GSM8K":60.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GritLM\/GritLM-8x7B",
        "Average":70.06,
        "ARC":67.83,
        "HellaSwag":86.42,
        "MMLU":71.48,
        "TruthfulQA":49.37,
        "Winogrande":82.79,
        "GSM8K":62.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ICBU-NPU\/FashionGPT-70B-V1.1",
        "Average":70.05,
        "ARC":71.76,
        "HellaSwag":88.2,
        "MMLU":70.99,
        "TruthfulQA":65.26,
        "Winogrande":82.64,
        "GSM8K":41.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.4",
        "Average":70.04,
        "ARC":63.65,
        "HellaSwag":83.3,
        "MMLU":75.11,
        "TruthfulQA":57.29,
        "Winogrande":80.58,
        "GSM8K":60.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/OpenMia-Indo-Engineering",
        "Average":70.03,
        "ARC":67.15,
        "HellaSwag":85.01,
        "MMLU":62.86,
        "TruthfulQA":57.94,
        "Winogrande":82.32,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/OpenMia-Indo-Engineering-7b",
        "Average":70.03,
        "ARC":67.15,
        "HellaSwag":85.01,
        "MMLU":62.86,
        "TruthfulQA":57.94,
        "Winogrande":82.32,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/Distilled-HermesChat-7B",
        "Average":70.02,
        "ARC":67.49,
        "HellaSwag":85.21,
        "MMLU":65.22,
        "TruthfulQA":54.77,
        "Winogrande":80.11,
        "GSM8K":67.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.2",
        "Average":70.01,
        "ARC":64.68,
        "HellaSwag":83.49,
        "MMLU":74.84,
        "TruthfulQA":56.76,
        "Winogrande":81.37,
        "GSM8K":58.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RaduGabriel\/MUZ",
        "Average":70.01,
        "ARC":66.38,
        "HellaSwag":86.38,
        "MMLU":63.03,
        "TruthfulQA":64.18,
        "Winogrande":81.77,
        "GSM8K":58.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/RolePlayLake-7B-Toxic",
        "Average":70.0,
        "ARC":66.98,
        "HellaSwag":84.86,
        "MMLU":63.79,
        "TruthfulQA":56.54,
        "Winogrande":82.24,
        "GSM8K":65.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/WestLake_Noromaid_OpenHermes_neural-chat",
        "Average":70.0,
        "ARC":67.58,
        "HellaSwag":86.13,
        "MMLU":64.72,
        "TruthfulQA":55.47,
        "Winogrande":80.43,
        "GSM8K":65.66,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Inv\/MoeMoE-2x7b",
        "Average":69.98,
        "ARC":66.47,
        "HellaSwag":84.31,
        "MMLU":62.7,
        "TruthfulQA":61.65,
        "Winogrande":79.87,
        "GSM8K":64.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Code-Mistral-7B",
        "Average":69.97,
        "ARC":64.59,
        "HellaSwag":85.29,
        "MMLU":65.0,
        "TruthfulQA":54.64,
        "Winogrande":82.24,
        "GSM8K":68.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"flemmingmiguel\/Mistrality-7B",
        "Average":69.97,
        "ARC":66.55,
        "HellaSwag":85.82,
        "MMLU":64.63,
        "TruthfulQA":56.8,
        "Winogrande":79.32,
        "GSM8K":66.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Solstice-11B-v1",
        "Average":69.97,
        "ARC":70.56,
        "HellaSwag":87.39,
        "MMLU":65.98,
        "TruthfulQA":61.98,
        "Winogrande":83.11,
        "GSM8K":50.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":11.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_46-7B-dare_ties",
        "Average":69.96,
        "ARC":67.24,
        "HellaSwag":86.4,
        "MMLU":62.17,
        "TruthfulQA":65.17,
        "Winogrande":79.48,
        "GSM8K":59.29,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eurdem\/megatron_1.1_MoE_2x7B",
        "Average":69.94,
        "ARC":65.53,
        "HellaSwag":84.52,
        "MMLU":65.02,
        "TruthfulQA":51.58,
        "Winogrande":81.53,
        "GSM8K":71.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.1",
        "Average":69.94,
        "ARC":66.21,
        "HellaSwag":82.99,
        "MMLU":65.17,
        "TruthfulQA":54.22,
        "Winogrande":81.37,
        "GSM8K":69.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GritLM\/GritLM-8x7B",
        "Average":69.93,
        "ARC":67.75,
        "HellaSwag":86.52,
        "MMLU":71.42,
        "TruthfulQA":49.47,
        "Winogrande":82.79,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "Average":69.92,
        "ARC":64.59,
        "HellaSwag":85.37,
        "MMLU":64.29,
        "TruthfulQA":55.14,
        "Winogrande":79.08,
        "GSM8K":71.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/MedleyMD",
        "Average":69.89,
        "ARC":66.47,
        "HellaSwag":86.06,
        "MMLU":65.1,
        "TruthfulQA":52.46,
        "Winogrande":80.27,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_3.m2",
        "Average":69.89,
        "ARC":67.41,
        "HellaSwag":86.88,
        "MMLU":63.9,
        "TruthfulQA":64.62,
        "Winogrande":80.35,
        "GSM8K":56.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Pallas-0.3",
        "Average":69.88,
        "ARC":63.57,
        "HellaSwag":83.36,
        "MMLU":75.09,
        "TruthfulQA":57.32,
        "Winogrande":80.19,
        "GSM8K":59.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Ba2han\/BruinsV2-OpHermesNeu-11B",
        "Average":69.88,
        "ARC":68.09,
        "HellaSwag":84.7,
        "MMLU":64.19,
        "TruthfulQA":62.76,
        "Winogrande":79.48,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Nexusflow\/Starling-LM-7B-beta",
        "Average":69.88,
        "ARC":67.24,
        "HellaSwag":83.47,
        "MMLU":65.14,
        "TruthfulQA":55.47,
        "Winogrande":81.29,
        "GSM8K":66.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":217.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Salesforce\/xLAM-v0.1-r",
        "Average":69.88,
        "ARC":67.58,
        "HellaSwag":84.59,
        "MMLU":69.95,
        "TruthfulQA":57.77,
        "Winogrande":80.98,
        "GSM8K":58.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SherlockAssistant\/Mistral-7B-Instruct-Ukrainian",
        "Average":69.87,
        "ARC":67.41,
        "HellaSwag":85.81,
        "MMLU":62.87,
        "TruthfulQA":64.95,
        "Winogrande":81.85,
        "GSM8K":56.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Q",
        "Average":69.86,
        "ARC":66.89,
        "HellaSwag":85.14,
        "MMLU":77.66,
        "TruthfulQA":53.03,
        "Winogrande":82.48,
        "GSM8K":53.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-3",
        "Average":69.83,
        "ARC":66.89,
        "HellaSwag":85.26,
        "MMLU":63.07,
        "TruthfulQA":63.01,
        "Winogrande":79.64,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ResplendentAI\/Persephone_7B",
        "Average":69.83,
        "ARC":66.72,
        "HellaSwag":85.59,
        "MMLU":63.23,
        "TruthfulQA":67.51,
        "Winogrande":82.32,
        "GSM8K":53.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2.02",
        "Average":69.82,
        "ARC":67.66,
        "HellaSwag":83.9,
        "MMLU":61.98,
        "TruthfulQA":64.06,
        "Winogrande":79.4,
        "GSM8K":61.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/A0119",
        "Average":69.82,
        "ARC":64.25,
        "HellaSwag":84.74,
        "MMLU":73.1,
        "TruthfulQA":57.96,
        "Winogrande":81.45,
        "GSM8K":57.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sumo43\/SOLAR-10.7B-Instruct-DPO-v1.0",
        "Average":69.81,
        "ARC":73.12,
        "HellaSwag":89.77,
        "MMLU":64.21,
        "TruthfulQA":73.27,
        "Winogrande":81.93,
        "GSM8K":36.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"localfultonextractor\/Erosumika-7B-v3",
        "Average":69.8,
        "ARC":67.49,
        "HellaSwag":85.69,
        "MMLU":64.15,
        "TruthfulQA":62.12,
        "Winogrande":82.79,
        "GSM8K":56.56,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jeiku\/Eros_Prodigadigm_7B",
        "Average":69.8,
        "ARC":67.24,
        "HellaSwag":85.63,
        "MMLU":63.04,
        "TruthfulQA":68.68,
        "Winogrande":80.9,
        "GSM8K":53.3,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-M-v1.1",
        "Average":69.79,
        "ARC":67.15,
        "HellaSwag":84.76,
        "MMLU":74.5,
        "TruthfulQA":54.8,
        "Winogrande":82.87,
        "GSM8K":54.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Stanta-Lelemon-Maid-7B",
        "Average":69.79,
        "ARC":67.58,
        "HellaSwag":86.03,
        "MMLU":64.79,
        "TruthfulQA":59.58,
        "Winogrande":79.64,
        "GSM8K":61.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-neural-chat-7b-v3-2-Slerp",
        "Average":69.79,
        "ARC":65.7,
        "HellaSwag":84.51,
        "MMLU":63.5,
        "TruthfulQA":55.23,
        "Winogrande":79.95,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"icefog72\/IceTeaRP-7b",
        "Average":69.76,
        "ARC":66.98,
        "HellaSwag":86.13,
        "MMLU":63.97,
        "TruthfulQA":62.44,
        "Winogrande":78.85,
        "GSM8K":60.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm2-20b",
        "Average":69.75,
        "ARC":62.97,
        "HellaSwag":83.21,
        "MMLU":67.58,
        "TruthfulQA":51.27,
        "Winogrande":85.56,
        "GSM8K":67.93,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":38.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seyf1elislam\/WestKunai-Hermes-10.7b-test",
        "Average":69.75,
        "ARC":68.09,
        "HellaSwag":87.1,
        "MMLU":64.43,
        "TruthfulQA":64.28,
        "Winogrande":82.72,
        "GSM8K":51.86,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-70b-3.1.2",
        "Average":69.74,
        "ARC":70.14,
        "HellaSwag":86.88,
        "MMLU":69.72,
        "TruthfulQA":59.19,
        "Winogrande":83.11,
        "GSM8K":49.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/NinjaDolphin-7B",
        "Average":69.74,
        "ARC":65.61,
        "HellaSwag":85.35,
        "MMLU":64.43,
        "TruthfulQA":54.94,
        "Winogrande":80.27,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/ChatHercules-2.5-Mistral-7B-DPO",
        "Average":69.73,
        "ARC":66.04,
        "HellaSwag":85.4,
        "MMLU":65.17,
        "TruthfulQA":52.3,
        "Winogrande":81.93,
        "GSM8K":67.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/MathDolphin-7B",
        "Average":69.73,
        "ARC":65.87,
        "HellaSwag":85.49,
        "MMLU":65.02,
        "TruthfulQA":52.92,
        "Winogrande":81.22,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Prima-LelantaclesV7-experimentalv2-7b",
        "Average":69.72,
        "ARC":68.09,
        "HellaSwag":85.87,
        "MMLU":62.87,
        "TruthfulQA":68.14,
        "Winogrande":81.14,
        "GSM8K":52.24,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/oswald-4x7b",
        "Average":69.72,
        "ARC":65.78,
        "HellaSwag":85.29,
        "MMLU":64.49,
        "TruthfulQA":57.39,
        "Winogrande":79.16,
        "GSM8K":66.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-M-v1.3",
        "Average":69.71,
        "ARC":62.54,
        "HellaSwag":83.95,
        "MMLU":75.36,
        "TruthfulQA":56.03,
        "Winogrande":81.14,
        "GSM8K":59.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/SlimMelodicMaid",
        "Average":69.7,
        "ARC":67.15,
        "HellaSwag":86.01,
        "MMLU":64.75,
        "TruthfulQA":60.88,
        "Winogrande":78.61,
        "GSM8K":60.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-34b-v0.2",
        "Average":69.7,
        "ARC":68.77,
        "HellaSwag":83.72,
        "MMLU":76.45,
        "TruthfulQA":59.26,
        "Winogrande":83.82,
        "GSM8K":46.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":35.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Kool-Aid_7B",
        "Average":69.69,
        "ARC":67.49,
        "HellaSwag":86.13,
        "MMLU":63.82,
        "TruthfulQA":65.12,
        "Winogrande":81.37,
        "GSM8K":54.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"viethq188\/Rabbit-7B-DPO-Chat",
        "Average":69.69,
        "ARC":70.31,
        "HellaSwag":87.43,
        "MMLU":60.5,
        "TruthfulQA":62.18,
        "Winogrande":79.16,
        "GSM8K":58.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mahiatlinux\/MasherAI-v6.1-7B-checkpoint3",
        "Average":69.67,
        "ARC":63.74,
        "HellaSwag":84.07,
        "MMLU":63.67,
        "TruthfulQA":56.2,
        "Winogrande":82.4,
        "GSM8K":67.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.5",
        "Average":69.67,
        "ARC":66.72,
        "HellaSwag":83.53,
        "MMLU":65.36,
        "TruthfulQA":52.15,
        "Winogrande":82.08,
        "GSM8K":68.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/una-cybertron-7b-v2-bf16",
        "Average":69.67,
        "ARC":68.26,
        "HellaSwag":85.85,
        "MMLU":63.23,
        "TruthfulQA":64.63,
        "Winogrande":80.98,
        "GSM8K":55.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":117.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kidyu\/Moza-7B-v1.0",
        "Average":69.66,
        "ARC":66.55,
        "HellaSwag":83.45,
        "MMLU":62.77,
        "TruthfulQA":65.16,
        "Winogrande":77.51,
        "GSM8K":62.55,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.3",
        "Average":69.66,
        "ARC":65.96,
        "HellaSwag":85.29,
        "MMLU":64.35,
        "TruthfulQA":57.8,
        "Winogrande":78.3,
        "GSM8K":66.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/average-dolphin-8x7B",
        "Average":69.64,
        "ARC":68.6,
        "HellaSwag":85.99,
        "MMLU":70.84,
        "TruthfulQA":54.51,
        "Winogrande":81.37,
        "GSM8K":56.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Argetsu",
        "Average":69.64,
        "ARC":67.06,
        "HellaSwag":86.32,
        "MMLU":65.55,
        "TruthfulQA":56.46,
        "Winogrande":79.16,
        "GSM8K":63.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.6",
        "Average":69.64,
        "ARC":66.55,
        "HellaSwag":83.22,
        "MMLU":65.19,
        "TruthfulQA":51.9,
        "Winogrande":81.22,
        "GSM8K":69.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/mixtralmerge-8x7B-rebalanced-test",
        "Average":69.61,
        "ARC":68.17,
        "HellaSwag":85.76,
        "MMLU":70.47,
        "TruthfulQA":53.75,
        "Winogrande":81.29,
        "GSM8K":58.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"icefog72\/Kunokukulemonchini-7b",
        "Average":69.61,
        "ARC":66.72,
        "HellaSwag":86.31,
        "MMLU":64.11,
        "TruthfulQA":61.89,
        "Winogrande":78.45,
        "GSM8K":60.2,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Steelskull\/Lumosia-MoE-4x10.7",
        "Average":69.61,
        "ARC":68.34,
        "HellaSwag":87.13,
        "MMLU":64.38,
        "TruthfulQA":63.81,
        "Winogrande":82.95,
        "GSM8K":51.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":36.1,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK_gony",
        "Average":69.61,
        "ARC":69.11,
        "HellaSwag":86.78,
        "MMLU":69.43,
        "TruthfulQA":56.74,
        "Winogrande":81.53,
        "GSM8K":54.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.11",
        "Average":69.59,
        "ARC":66.21,
        "HellaSwag":83.28,
        "MMLU":65.25,
        "TruthfulQA":52.92,
        "Winogrande":81.45,
        "GSM8K":68.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-RAW-2901",
        "Average":69.59,
        "ARC":64.93,
        "HellaSwag":84.98,
        "MMLU":73.7,
        "TruthfulQA":55.09,
        "Winogrande":79.32,
        "GSM8K":59.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-ai\/Pandora-13B-v1",
        "Average":69.59,
        "ARC":67.06,
        "HellaSwag":87.53,
        "MMLU":63.65,
        "TruthfulQA":65.77,
        "Winogrande":80.51,
        "GSM8K":52.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/orthorus-125b-moe",
        "Average":69.58,
        "ARC":67.66,
        "HellaSwag":85.52,
        "MMLU":68.94,
        "TruthfulQA":56.27,
        "Winogrande":82.32,
        "GSM8K":56.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":125.35,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openaccess-ai-collective\/DPOpenHermes-7B-v2",
        "Average":69.58,
        "ARC":66.64,
        "HellaSwag":85.22,
        "MMLU":63.64,
        "TruthfulQA":59.22,
        "Winogrande":79.16,
        "GSM8K":63.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Tippy-Toppy-7b",
        "Average":69.58,
        "ARC":66.89,
        "HellaSwag":85.88,
        "MMLU":65.49,
        "TruthfulQA":55.7,
        "Winogrande":78.85,
        "GSM8K":64.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0306",
        "Average":69.57,
        "ARC":66.04,
        "HellaSwag":83.47,
        "MMLU":80.04,
        "TruthfulQA":53.05,
        "Winogrande":78.22,
        "GSM8K":56.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/WizardDolphin-7B",
        "Average":69.56,
        "ARC":64.68,
        "HellaSwag":85.86,
        "MMLU":62.75,
        "TruthfulQA":59.28,
        "Winogrande":78.53,
        "GSM8K":66.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_17-7B-dare_ties",
        "Average":69.54,
        "ARC":66.64,
        "HellaSwag":86.04,
        "MMLU":65.07,
        "TruthfulQA":53.18,
        "Winogrande":81.93,
        "GSM8K":64.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FoxEngineAi\/Mega-Destroyer-8x7B",
        "Average":69.54,
        "ARC":71.76,
        "HellaSwag":86.47,
        "MMLU":70.11,
        "TruthfulQA":72.12,
        "Winogrande":82.79,
        "GSM8K":33.97,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":46.7,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Weyaxi\/Qwen-72B-Llama",
        "Average":69.53,
        "ARC":64.85,
        "HellaSwag":83.27,
        "MMLU":73.66,
        "TruthfulQA":57.6,
        "Winogrande":81.53,
        "GSM8K":56.25,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.4",
        "Average":69.52,
        "ARC":66.64,
        "HellaSwag":83.23,
        "MMLU":65.22,
        "TruthfulQA":51.71,
        "Winogrande":81.69,
        "GSM8K":68.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Smaug-2-72B",
        "Average":69.51,
        "ARC":67.92,
        "HellaSwag":86.37,
        "MMLU":77.73,
        "TruthfulQA":64.9,
        "Winogrande":81.61,
        "GSM8K":38.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_38-7B-dare_ties",
        "Average":69.5,
        "ARC":71.67,
        "HellaSwag":86.35,
        "MMLU":58.3,
        "TruthfulQA":73.14,
        "Winogrande":82.0,
        "GSM8K":45.56,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/CognitiveFusion-4x7B-bf16-MoE",
        "Average":69.5,
        "ARC":67.41,
        "HellaSwag":86.16,
        "MMLU":65.14,
        "TruthfulQA":67.05,
        "Winogrande":78.69,
        "GSM8K":52.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/una-cybertron-7b-v1-fp16",
        "Average":69.49,
        "ARC":68.43,
        "HellaSwag":85.42,
        "MMLU":63.34,
        "TruthfulQA":63.28,
        "Winogrande":81.37,
        "GSM8K":55.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azazelle\/Silicon-Medley",
        "Average":69.49,
        "ARC":67.24,
        "HellaSwag":86.21,
        "MMLU":64.51,
        "TruthfulQA":61.34,
        "Winogrande":79.24,
        "GSM8K":58.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/openchat-spin-slimorca-iter0",
        "Average":69.49,
        "ARC":67.15,
        "HellaSwag":83.61,
        "MMLU":64.45,
        "TruthfulQA":56.87,
        "Winogrande":81.37,
        "GSM8K":63.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_17-7B-dare_ties",
        "Average":69.47,
        "ARC":66.72,
        "HellaSwag":85.98,
        "MMLU":65.03,
        "TruthfulQA":53.17,
        "Winogrande":82.0,
        "GSM8K":63.91,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/ExtremeDolphin-MoE",
        "Average":69.46,
        "ARC":65.1,
        "HellaSwag":86.07,
        "MMLU":63.76,
        "TruthfulQA":57.28,
        "Winogrande":78.69,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DopeorNope\/You_can_cry_Snowman-13B",
        "Average":69.46,
        "ARC":69.11,
        "HellaSwag":86.3,
        "MMLU":63.77,
        "TruthfulQA":70.24,
        "Winogrande":80.27,
        "GSM8K":47.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":13.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/openchat-3.5-0106-laser",
        "Average":69.46,
        "ARC":66.04,
        "HellaSwag":83.18,
        "MMLU":65.11,
        "TruthfulQA":52.08,
        "Winogrande":81.45,
        "GSM8K":68.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MayaPH\/GodziLLa2-70B",
        "Average":69.46,
        "ARC":71.42,
        "HellaSwag":87.53,
        "MMLU":69.88,
        "TruthfulQA":61.54,
        "Winogrande":83.19,
        "GSM8K":43.21,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":35.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tushar310\/MisGemma-7B",
        "Average":69.45,
        "ARC":66.89,
        "HellaSwag":85.73,
        "MMLU":64.44,
        "TruthfulQA":62.22,
        "Winogrande":79.16,
        "GSM8K":58.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tushar310\/MisGemma-7B",
        "Average":69.44,
        "ARC":66.89,
        "HellaSwag":85.7,
        "MMLU":64.48,
        "TruthfulQA":62.22,
        "Winogrande":79.48,
        "GSM8K":57.85,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/saulgoodman-2x7b-alpha1",
        "Average":69.43,
        "ARC":66.21,
        "HellaSwag":85.36,
        "MMLU":64.95,
        "TruthfulQA":60.06,
        "Winogrande":79.24,
        "GSM8K":60.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-34B",
        "Average":69.42,
        "ARC":64.59,
        "HellaSwag":85.69,
        "MMLU":76.35,
        "TruthfulQA":56.23,
        "Winogrande":83.03,
        "GSM8K":50.64,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1219.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openchat\/openchat-3.5-0106-gemma",
        "Average":69.42,
        "ARC":64.68,
        "HellaSwag":81.08,
        "MMLU":64.69,
        "TruthfulQA":54.93,
        "Winogrande":78.3,
        "GSM8K":72.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/yi-34b-200k-rawrr-dpo-2",
        "Average":69.42,
        "ARC":64.68,
        "HellaSwag":84.74,
        "MMLU":75.96,
        "TruthfulQA":46.15,
        "Winogrande":83.19,
        "GSM8K":61.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChuckMcSneed\/WinterGoddess-1.4x-70b-32k",
        "Average":69.4,
        "ARC":71.16,
        "HellaSwag":89.12,
        "MMLU":66.42,
        "TruthfulQA":63.87,
        "Winogrande":82.56,
        "GSM8K":43.29,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rishiraj\/oswald-2x7b",
        "Average":69.4,
        "ARC":66.47,
        "HellaSwag":85.46,
        "MMLU":65.2,
        "TruthfulQA":60.06,
        "Winogrande":79.4,
        "GSM8K":59.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/Bald-Eagle-7B",
        "Average":69.39,
        "ARC":64.51,
        "HellaSwag":84.79,
        "MMLU":64.39,
        "TruthfulQA":54.65,
        "Winogrande":80.98,
        "GSM8K":67.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/saulgoodman-7b-alpha1",
        "Average":69.38,
        "ARC":65.7,
        "HellaSwag":85.5,
        "MMLU":65.19,
        "TruthfulQA":61.13,
        "Winogrande":79.01,
        "GSM8K":59.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Sina-Thor-7b-Merge",
        "Average":69.38,
        "ARC":66.21,
        "HellaSwag":85.69,
        "MMLU":65.17,
        "TruthfulQA":50.01,
        "Winogrande":80.51,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Average":69.38,
        "ARC":65.44,
        "HellaSwag":87.1,
        "MMLU":71.78,
        "TruthfulQA":51.08,
        "Winogrande":84.14,
        "GSM8K":56.71,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.0,
        "Model Sha":99.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Sensualize-Mixtral-bf16",
        "Average":69.37,
        "ARC":70.14,
        "HellaSwag":86.6,
        "MMLU":70.89,
        "TruthfulQA":54.17,
        "Winogrande":82.4,
        "GSM8K":52.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/SynthIQ-7b",
        "Average":69.37,
        "ARC":65.87,
        "HellaSwag":85.82,
        "MMLU":64.75,
        "TruthfulQA":57.0,
        "Winogrande":78.69,
        "GSM8K":64.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.3",
        "Average":69.36,
        "ARC":65.96,
        "HellaSwag":83.15,
        "MMLU":65.46,
        "TruthfulQA":52.38,
        "Winogrande":81.53,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"viethq188\/Rabbit-7B-v2-DPO-Chat",
        "Average":69.36,
        "ARC":66.13,
        "HellaSwag":85.18,
        "MMLU":62.92,
        "TruthfulQA":67.06,
        "Winogrande":79.24,
        "GSM8K":55.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cstr\/Spaetzle-v12-7b",
        "Average":69.36,
        "ARC":65.96,
        "HellaSwag":86.16,
        "MMLU":63.48,
        "TruthfulQA":57.84,
        "Winogrande":80.03,
        "GSM8K":62.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/ThetaWave-7B",
        "Average":69.35,
        "ARC":67.49,
        "HellaSwag":86.01,
        "MMLU":62.26,
        "TruthfulQA":65.26,
        "Winogrande":79.01,
        "GSM8K":56.1,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_2-7B-slerp",
        "Average":69.34,
        "ARC":66.89,
        "HellaSwag":85.52,
        "MMLU":65.22,
        "TruthfulQA":54.53,
        "Winogrande":82.4,
        "GSM8K":61.49,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-deepseek-67b-v15-base",
        "Average":69.34,
        "ARC":66.3,
        "HellaSwag":86.03,
        "MMLU":70.97,
        "TruthfulQA":52.31,
        "Winogrande":83.58,
        "GSM8K":56.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":67.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Stopwolf\/Bumbar-7B-slerp",
        "Average":69.34,
        "ARC":66.21,
        "HellaSwag":83.96,
        "MMLU":63.98,
        "TruthfulQA":57.81,
        "Winogrande":80.03,
        "GSM8K":64.06,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mayacinka\/West-Ramen-7Bx4",
        "Average":69.33,
        "ARC":67.58,
        "HellaSwag":85.52,
        "MMLU":62.69,
        "TruthfulQA":61.0,
        "Winogrande":81.22,
        "GSM8K":58.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"gagan3012\/MetaModel_moe_multilingualv1",
        "Average":69.33,
        "ARC":67.58,
        "HellaSwag":84.72,
        "MMLU":63.77,
        "TruthfulQA":61.21,
        "Winogrande":77.35,
        "GSM8K":61.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-RAW-2301-LoRA",
        "Average":69.31,
        "ARC":65.96,
        "HellaSwag":83.89,
        "MMLU":74.76,
        "TruthfulQA":57.08,
        "Winogrande":78.69,
        "GSM8K":55.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/openchat-3.5-0106-32k",
        "Average":69.3,
        "ARC":66.04,
        "HellaSwag":82.93,
        "MMLU":65.04,
        "TruthfulQA":51.9,
        "Winogrande":81.77,
        "GSM8K":68.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openchat\/openchat-3.5-0106",
        "Average":69.3,
        "ARC":66.04,
        "HellaSwag":82.93,
        "MMLU":65.04,
        "TruthfulQA":51.9,
        "Winogrande":81.77,
        "GSM8K":68.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":295.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Jaume\/openchat-3.5-0106-mod-gpt5",
        "Average":69.3,
        "ARC":66.04,
        "HellaSwag":82.93,
        "MMLU":65.04,
        "TruthfulQA":51.9,
        "Winogrande":81.77,
        "GSM8K":68.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Platypus2-70B-instruct",
        "Average":69.3,
        "ARC":71.84,
        "HellaSwag":87.94,
        "MMLU":70.48,
        "TruthfulQA":62.26,
        "Winogrande":82.72,
        "GSM8K":40.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":173.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saucam\/mistral-orpo-beta-NeuralBeagle14-7B-dare-ties",
        "Average":69.3,
        "ARC":66.72,
        "HellaSwag":85.98,
        "MMLU":64.63,
        "TruthfulQA":53.87,
        "Winogrande":81.22,
        "GSM8K":63.38,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-34B-200K-rawrr1-LORA-DPO-experimental-r3",
        "Average":69.29,
        "ARC":64.85,
        "HellaSwag":84.77,
        "MMLU":76.0,
        "TruthfulQA":45.35,
        "Winogrande":83.11,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Open_Neural_Monarch_Maidv0.1",
        "Average":69.28,
        "ARC":67.66,
        "HellaSwag":85.94,
        "MMLU":65.02,
        "TruthfulQA":56.39,
        "Winogrande":79.32,
        "GSM8K":61.33,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Mistral-7B-Instruct_v0.2_UNA-TheBeagle-7b-v1",
        "Average":69.27,
        "ARC":67.83,
        "HellaSwag":85.94,
        "MMLU":61.94,
        "TruthfulQA":65.64,
        "Winogrande":80.35,
        "GSM8K":53.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.8",
        "Average":69.26,
        "ARC":65.78,
        "HellaSwag":83.05,
        "MMLU":65.16,
        "TruthfulQA":52.26,
        "Winogrande":81.61,
        "GSM8K":67.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Hermes-low-tune-3",
        "Average":69.25,
        "ARC":66.21,
        "HellaSwag":84.99,
        "MMLU":63.74,
        "TruthfulQA":57.94,
        "Winogrande":78.77,
        "GSM8K":63.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vishnukv\/WestSeverusJaskier-OpenOrca",
        "Average":69.24,
        "ARC":62.88,
        "HellaSwag":84.75,
        "MMLU":64.33,
        "TruthfulQA":53.9,
        "Winogrande":82.48,
        "GSM8K":67.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/BeagleLake-7B-Toxic",
        "Average":69.24,
        "ARC":65.19,
        "HellaSwag":83.83,
        "MMLU":62.82,
        "TruthfulQA":57.67,
        "Winogrande":82.32,
        "GSM8K":63.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jpechg\/Sour-Marcoro-12.5B",
        "Average":69.23,
        "ARC":67.92,
        "HellaSwag":83.7,
        "MMLU":65.85,
        "TruthfulQA":68.17,
        "Winogrande":82.08,
        "GSM8K":47.69,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_41-7B-dare_ties",
        "Average":69.23,
        "ARC":65.61,
        "HellaSwag":85.7,
        "MMLU":64.57,
        "TruthfulQA":58.02,
        "Winogrande":81.06,
        "GSM8K":60.42,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"weezywitasneezy\/OxytocinErosEngineeringF1-7B-slerp",
        "Average":69.22,
        "ARC":67.15,
        "HellaSwag":86.0,
        "MMLU":64.73,
        "TruthfulQA":54.54,
        "Winogrande":81.14,
        "GSM8K":61.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/BagelToppyLake-7B-slerp",
        "Average":69.22,
        "ARC":67.15,
        "HellaSwag":84.79,
        "MMLU":64.31,
        "TruthfulQA":62.15,
        "Winogrande":81.85,
        "GSM8K":55.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/KunoMaid-7B-slerp",
        "Average":69.21,
        "ARC":68.0,
        "HellaSwag":86.34,
        "MMLU":64.82,
        "TruthfulQA":55.19,
        "Winogrande":79.24,
        "GSM8K":61.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AGI-0\/ThetaWave-7B-v0.1",
        "Average":69.2,
        "ARC":65.96,
        "HellaSwag":85.72,
        "MMLU":63.07,
        "TruthfulQA":63.27,
        "Winogrande":81.53,
        "GSM8K":55.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LHC88\/LaseredHermes-7B-v1",
        "Average":69.2,
        "ARC":66.98,
        "HellaSwag":85.22,
        "MMLU":63.6,
        "TruthfulQA":59.01,
        "Winogrande":78.3,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Jaume\/openchat-3.5-0106-mod-gpt5",
        "Average":69.19,
        "ARC":65.87,
        "HellaSwag":82.93,
        "MMLU":65.12,
        "TruthfulQA":51.93,
        "Winogrande":81.53,
        "GSM8K":67.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"llmixer\/BigWeave-v12-90b",
        "Average":69.19,
        "ARC":68.09,
        "HellaSwag":87.7,
        "MMLU":69.41,
        "TruthfulQA":61.35,
        "Winogrande":81.22,
        "GSM8K":47.38,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":87.8,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.7",
        "Average":69.19,
        "ARC":65.78,
        "HellaSwag":83.0,
        "MMLU":65.1,
        "TruthfulQA":52.05,
        "Winogrande":81.37,
        "GSM8K":67.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/openchat-spin-slimorca-iter1",
        "Average":69.18,
        "ARC":67.32,
        "HellaSwag":83.86,
        "MMLU":62.64,
        "TruthfulQA":58.76,
        "Winogrande":79.4,
        "GSM8K":63.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PistachioAlt\/Synatra-MCS-7B-v0.3-RP-Slerp",
        "Average":69.18,
        "ARC":66.64,
        "HellaSwag":84.97,
        "MMLU":63.61,
        "TruthfulQA":53.93,
        "Winogrande":79.72,
        "GSM8K":66.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freecs\/ThetaWave-7B-v0.1",
        "Average":69.17,
        "ARC":66.3,
        "HellaSwag":85.4,
        "MMLU":63.47,
        "TruthfulQA":60.24,
        "Winogrande":80.19,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.3",
        "Average":69.17,
        "ARC":64.76,
        "HellaSwag":83.17,
        "MMLU":74.66,
        "TruthfulQA":55.43,
        "Winogrande":80.9,
        "GSM8K":56.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/Xwin-LM-70B-V0.1_Limarpv3",
        "Average":69.16,
        "ARC":70.82,
        "HellaSwag":86.97,
        "MMLU":69.28,
        "TruthfulQA":57.15,
        "Winogrande":81.77,
        "GSM8K":48.98,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-34b-200K-rawrr-v2-run-0902-LoRA",
        "Average":69.15,
        "ARC":64.68,
        "HellaSwag":84.5,
        "MMLU":75.76,
        "TruthfulQA":46.66,
        "Winogrande":81.14,
        "GSM8K":62.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_12-7B-slerp",
        "Average":69.13,
        "ARC":66.64,
        "HellaSwag":85.89,
        "MMLU":64.94,
        "TruthfulQA":52.55,
        "Winogrande":81.69,
        "GSM8K":63.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-l2-70b-2.2.1",
        "Average":69.13,
        "ARC":69.71,
        "HellaSwag":87.95,
        "MMLU":69.79,
        "TruthfulQA":59.49,
        "Winogrande":82.95,
        "GSM8K":44.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/piano-medley-7b",
        "Average":69.1,
        "ARC":67.58,
        "HellaSwag":85.36,
        "MMLU":64.49,
        "TruthfulQA":61.42,
        "Winogrande":79.16,
        "GSM8K":56.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LHC88\/LaseredHermes-7B-v1",
        "Average":69.09,
        "ARC":66.89,
        "HellaSwag":85.21,
        "MMLU":63.58,
        "TruthfulQA":59.09,
        "Winogrande":78.45,
        "GSM8K":61.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/West-Maid-7B",
        "Average":69.09,
        "ARC":67.24,
        "HellaSwag":86.44,
        "MMLU":64.85,
        "TruthfulQA":51.0,
        "Winogrande":82.72,
        "GSM8K":62.32,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/openchat-nectar-0.14",
        "Average":69.09,
        "ARC":65.61,
        "HellaSwag":83.02,
        "MMLU":64.58,
        "TruthfulQA":50.09,
        "Winogrande":82.0,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"itsliupeng\/Mixtral-8x7B-v0.1-top3",
        "Average":69.09,
        "ARC":67.41,
        "HellaSwag":86.63,
        "MMLU":71.98,
        "TruthfulQA":48.58,
        "Winogrande":82.4,
        "GSM8K":57.54,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/Optimus-7B",
        "Average":69.09,
        "ARC":65.44,
        "HellaSwag":85.41,
        "MMLU":63.61,
        "TruthfulQA":55.79,
        "Winogrande":78.77,
        "GSM8K":65.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":12.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-RawEmerald-7B",
        "Average":69.09,
        "ARC":66.89,
        "HellaSwag":85.75,
        "MMLU":63.23,
        "TruthfulQA":57.58,
        "Winogrande":78.22,
        "GSM8K":62.85,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/FettuccineLake-DPO-7B-slerp",
        "Average":69.09,
        "ARC":67.92,
        "HellaSwag":86.37,
        "MMLU":63.24,
        "TruthfulQA":68.64,
        "Winogrande":80.58,
        "GSM8K":47.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"liminerity\/Blurstral-7b-slerp",
        "Average":69.08,
        "ARC":66.3,
        "HellaSwag":85.38,
        "MMLU":65.18,
        "TruthfulQA":53.4,
        "Winogrande":81.37,
        "GSM8K":62.85,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/loyal-piano-m7-cdpo",
        "Average":69.08,
        "ARC":67.15,
        "HellaSwag":85.39,
        "MMLU":64.52,
        "TruthfulQA":61.53,
        "Winogrande":79.4,
        "GSM8K":56.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"diffnamehard\/Mistral-CatMacaroni-slerp-gradient",
        "Average":69.08,
        "ARC":65.53,
        "HellaSwag":85.66,
        "MMLU":61.53,
        "TruthfulQA":64.1,
        "Winogrande":80.03,
        "GSM8K":57.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freeCS-dot-org\/ThetaZero-7B-1",
        "Average":69.07,
        "ARC":67.49,
        "HellaSwag":85.69,
        "MMLU":63.03,
        "TruthfulQA":62.48,
        "Winogrande":79.87,
        "GSM8K":55.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_12-7B-slerp",
        "Average":69.05,
        "ARC":66.64,
        "HellaSwag":85.9,
        "MMLU":65.06,
        "TruthfulQA":52.55,
        "Winogrande":81.53,
        "GSM8K":62.62,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/Neural-una-cybertron-7b",
        "Average":69.05,
        "ARC":69.03,
        "HellaSwag":84.51,
        "MMLU":62.79,
        "TruthfulQA":64.99,
        "Winogrande":80.66,
        "GSM8K":52.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"feeltheAGI\/Maverick-Math-7B",
        "Average":69.05,
        "ARC":65.27,
        "HellaSwag":84.54,
        "MMLU":62.59,
        "TruthfulQA":55.97,
        "Winogrande":79.72,
        "GSM8K":66.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/HerculeanSea-upd-7b-128k",
        "Average":69.03,
        "ARC":66.13,
        "HellaSwag":85.89,
        "MMLU":64.48,
        "TruthfulQA":55.54,
        "Winogrande":81.22,
        "GSM8K":60.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_v3_70b",
        "Average":69.02,
        "ARC":71.25,
        "HellaSwag":87.85,
        "MMLU":70.18,
        "TruthfulQA":61.27,
        "Winogrande":82.72,
        "GSM8K":40.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vihangd\/smartsolmix-4x10.7b-v1",
        "Average":69.01,
        "ARC":64.93,
        "HellaSwag":85.13,
        "MMLU":66.1,
        "TruthfulQA":55.03,
        "Winogrande":83.43,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":36.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chargoddard\/loyal-piano-m7-cdpo",
        "Average":69.0,
        "ARC":67.06,
        "HellaSwag":85.42,
        "MMLU":64.54,
        "TruthfulQA":61.54,
        "Winogrande":79.08,
        "GSM8K":56.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/servile-harpsichord-cdpo",
        "Average":68.98,
        "ARC":67.32,
        "HellaSwag":85.18,
        "MMLU":64.54,
        "TruthfulQA":60.61,
        "Winogrande":79.16,
        "GSM8K":57.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/Monarch-7B-SFT",
        "Average":68.98,
        "ARC":63.74,
        "HellaSwag":83.58,
        "MMLU":64.11,
        "TruthfulQA":54.25,
        "Winogrande":79.79,
        "GSM8K":68.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Mixtral_13B_Chat",
        "Average":68.98,
        "ARC":67.41,
        "HellaSwag":85.87,
        "MMLU":64.54,
        "TruthfulQA":58.98,
        "Winogrande":80.43,
        "GSM8K":56.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ignos\/LeoScorpius-GreenNode-Platypus-7B-v1",
        "Average":68.96,
        "ARC":66.04,
        "HellaSwag":86.53,
        "MMLU":62.06,
        "TruthfulQA":52.78,
        "Winogrande":82.16,
        "GSM8K":64.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-RawRuby-7B",
        "Average":68.95,
        "ARC":66.89,
        "HellaSwag":85.53,
        "MMLU":63.46,
        "TruthfulQA":57.09,
        "Winogrande":78.69,
        "GSM8K":62.02,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HanNayeoniee\/LHK_44",
        "Average":68.95,
        "ARC":66.55,
        "HellaSwag":84.86,
        "MMLU":65.37,
        "TruthfulQA":59.58,
        "Winogrande":80.9,
        "GSM8K":56.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"uproai\/Rose-2x7B",
        "Average":68.93,
        "ARC":65.27,
        "HellaSwag":85.7,
        "MMLU":64.37,
        "TruthfulQA":49.32,
        "Winogrande":79.79,
        "GSM8K":69.14,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-PressurizedRuby-7B",
        "Average":68.93,
        "ARC":66.89,
        "HellaSwag":85.4,
        "MMLU":63.33,
        "TruthfulQA":56.91,
        "Winogrande":78.77,
        "GSM8K":62.24,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/MegaDolphin-120b",
        "Average":68.91,
        "ARC":69.03,
        "HellaSwag":87.8,
        "MMLU":69.26,
        "TruthfulQA":59.28,
        "Winogrande":81.85,
        "GSM8K":46.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":120.32,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/ConfigurableHermes-7B",
        "Average":68.89,
        "ARC":66.04,
        "HellaSwag":84.31,
        "MMLU":62.44,
        "TruthfulQA":61.71,
        "Winogrande":77.43,
        "GSM8K":61.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat-3.5-1210",
        "Average":68.89,
        "ARC":64.93,
        "HellaSwag":84.92,
        "MMLU":64.62,
        "TruthfulQA":52.15,
        "Winogrande":80.74,
        "GSM8K":65.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":271.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-una-cybertron-v2-bf16-Ties",
        "Average":68.88,
        "ARC":65.02,
        "HellaSwag":83.68,
        "MMLU":62.58,
        "TruthfulQA":55.52,
        "Winogrande":77.27,
        "GSM8K":69.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/Monarch-7B-SFT",
        "Average":68.88,
        "ARC":63.82,
        "HellaSwag":83.63,
        "MMLU":64.2,
        "TruthfulQA":54.26,
        "Winogrande":79.95,
        "GSM8K":67.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dfurman\/Mixtral-8x7B-peft-v0.1",
        "Average":68.87,
        "ARC":67.24,
        "HellaSwag":86.03,
        "MMLU":68.59,
        "TruthfulQA":59.54,
        "Winogrande":80.43,
        "GSM8K":51.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/distilabled_Chikuma_10.7B",
        "Average":68.87,
        "ARC":66.38,
        "HellaSwag":85.14,
        "MMLU":64.7,
        "TruthfulQA":59.2,
        "Winogrande":79.4,
        "GSM8K":58.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-DesolatingRuby-7B",
        "Average":68.86,
        "ARC":66.89,
        "HellaSwag":85.46,
        "MMLU":63.38,
        "TruthfulQA":57.05,
        "Winogrande":78.45,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"giraffe176\/WestLake_Noromaid_OpenHermes_neural-chatv0.1",
        "Average":68.86,
        "ARC":66.72,
        "HellaSwag":85.37,
        "MMLU":64.67,
        "TruthfulQA":51.5,
        "Winogrande":79.72,
        "GSM8K":65.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-SharpEmerald-7B",
        "Average":68.86,
        "ARC":66.72,
        "HellaSwag":85.4,
        "MMLU":63.21,
        "TruthfulQA":56.52,
        "Winogrande":78.53,
        "GSM8K":62.77,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/FT",
        "Average":68.85,
        "ARC":63.05,
        "HellaSwag":82.78,
        "MMLU":69.69,
        "TruthfulQA":59.88,
        "Winogrande":79.64,
        "GSM8K":58.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Average":68.85,
        "ARC":65.36,
        "HellaSwag":85.23,
        "MMLU":62.96,
        "TruthfulQA":59.78,
        "Winogrande":78.06,
        "GSM8K":61.71,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":24.15,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/openchat-spin-slimorca-iter2",
        "Average":68.85,
        "ARC":68.0,
        "HellaSwag":83.97,
        "MMLU":64.39,
        "TruthfulQA":59.0,
        "Winogrande":77.98,
        "GSM8K":59.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/openchat-spin-slimorca-iter3",
        "Average":68.85,
        "ARC":68.0,
        "HellaSwag":83.97,
        "MMLU":64.39,
        "TruthfulQA":59.0,
        "Winogrande":77.98,
        "GSM8K":59.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/kellemar-DPO-7B-d",
        "Average":68.84,
        "ARC":66.89,
        "HellaSwag":85.16,
        "MMLU":62.77,
        "TruthfulQA":56.88,
        "Winogrande":79.32,
        "GSM8K":62.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mixtral_7bx4_moe",
        "Average":68.83,
        "ARC":65.27,
        "HellaSwag":85.28,
        "MMLU":62.84,
        "TruthfulQA":59.85,
        "Winogrande":77.66,
        "GSM8K":62.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIDC-ai-business\/Marcoroni-70B-v1",
        "Average":68.83,
        "ARC":73.55,
        "HellaSwag":87.62,
        "MMLU":70.67,
        "TruthfulQA":64.41,
        "Winogrande":83.43,
        "GSM8K":33.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-PolishedRuby-7B",
        "Average":68.82,
        "ARC":66.72,
        "HellaSwag":85.39,
        "MMLU":63.21,
        "TruthfulQA":56.8,
        "Winogrande":78.61,
        "GSM8K":62.17,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eurdem\/megatron_v1",
        "Average":68.82,
        "ARC":65.96,
        "HellaSwag":84.8,
        "MMLU":65.02,
        "TruthfulQA":60.32,
        "Winogrande":79.79,
        "GSM8K":57.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"giraffe176\/Open_Maid_Samantha_Hermes_Orca",
        "Average":68.81,
        "ARC":66.81,
        "HellaSwag":85.83,
        "MMLU":64.58,
        "TruthfulQA":53.91,
        "Winogrande":80.35,
        "GSM8K":61.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AiMavenAi\/AiMaven-SmartDawg-7b",
        "Average":68.81,
        "ARC":67.92,
        "HellaSwag":87.16,
        "MMLU":62.69,
        "TruthfulQA":58.86,
        "Winogrande":79.01,
        "GSM8K":57.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/FT",
        "Average":68.81,
        "ARC":63.14,
        "HellaSwag":82.78,
        "MMLU":69.5,
        "TruthfulQA":59.8,
        "Winogrande":79.4,
        "GSM8K":58.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Technoculture\/Medmerge-tulu-70b",
        "Average":68.81,
        "ARC":67.41,
        "HellaSwag":87.46,
        "MMLU":70.1,
        "TruthfulQA":47.89,
        "Winogrande":83.43,
        "GSM8K":56.56,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vanillaOVO\/correction_1",
        "Average":68.8,
        "ARC":71.16,
        "HellaSwag":88.59,
        "MMLU":63.51,
        "TruthfulQA":65.92,
        "Winogrande":87.85,
        "GSM8K":35.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Snorkel-Mistral-PairRM-DPO-openchat-3.5-0106-laser",
        "Average":68.8,
        "ARC":67.32,
        "HellaSwag":85.11,
        "MMLU":63.23,
        "TruthfulQA":61.69,
        "Winogrande":79.87,
        "GSM8K":55.57,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"martyn\/solar-megamerge-dare-10.7b-v1",
        "Average":68.79,
        "ARC":66.13,
        "HellaSwag":85.3,
        "MMLU":66.03,
        "TruthfulQA":54.33,
        "Winogrande":82.95,
        "GSM8K":58.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Kunocchini-7b",
        "Average":68.78,
        "ARC":67.49,
        "HellaSwag":86.85,
        "MMLU":63.89,
        "TruthfulQA":68.62,
        "Winogrande":77.98,
        "GSM8K":47.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Epiculous\/Crunchy-onion",
        "Average":68.75,
        "ARC":67.15,
        "HellaSwag":86.19,
        "MMLU":70.02,
        "TruthfulQA":63.88,
        "Winogrande":73.24,
        "GSM8K":52.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":46.7,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HanNayeoniee\/LHK",
        "Average":68.74,
        "ARC":66.38,
        "HellaSwag":84.49,
        "MMLU":65.13,
        "TruthfulQA":59.12,
        "Winogrande":80.98,
        "GSM8K":56.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/limb",
        "Average":68.73,
        "ARC":63.48,
        "HellaSwag":83.07,
        "MMLU":72.25,
        "TruthfulQA":58.37,
        "Winogrande":79.79,
        "GSM8K":55.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A11P",
        "Average":68.73,
        "ARC":62.54,
        "HellaSwag":82.53,
        "MMLU":70.56,
        "TruthfulQA":56.44,
        "Winogrande":79.87,
        "GSM8K":60.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TokenBender\/pic_7B_mistral_Full_v0.2",
        "Average":68.72,
        "ARC":65.36,
        "HellaSwag":84.03,
        "MMLU":64.51,
        "TruthfulQA":59.2,
        "Winogrande":79.48,
        "GSM8K":59.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/OpenHermes-2.5-neural-chat-7b-v3-2-7B",
        "Average":68.71,
        "ARC":66.38,
        "HellaSwag":84.11,
        "MMLU":62.84,
        "TruthfulQA":63.59,
        "Winogrande":78.53,
        "GSM8K":56.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":23.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-ShatteredRuby-7B",
        "Average":68.7,
        "ARC":66.21,
        "HellaSwag":85.38,
        "MMLU":63.29,
        "TruthfulQA":56.99,
        "Winogrande":78.61,
        "GSM8K":61.71,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-Ruby-7B",
        "Average":68.68,
        "ARC":67.24,
        "HellaSwag":85.22,
        "MMLU":63.21,
        "TruthfulQA":56.49,
        "Winogrande":77.98,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-Ruby-7B-Fixed",
        "Average":68.68,
        "ARC":67.24,
        "HellaSwag":85.22,
        "MMLU":63.21,
        "TruthfulQA":56.49,
        "Winogrande":77.98,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pinkyponky\/SOLAR-10.7B-dpo-instruct-tuned-v0.1",
        "Average":68.68,
        "ARC":65.19,
        "HellaSwag":86.09,
        "MMLU":66.25,
        "TruthfulQA":51.81,
        "Winogrande":83.98,
        "GSM8K":58.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"twodgirl\/Nimue-7B",
        "Average":68.68,
        "ARC":63.74,
        "HellaSwag":82.74,
        "MMLU":64.64,
        "TruthfulQA":50.89,
        "Winogrande":83.27,
        "GSM8K":66.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Yi-34B-AEZAKMI-v1",
        "Average":68.67,
        "ARC":64.33,
        "HellaSwag":84.31,
        "MMLU":73.91,
        "TruthfulQA":55.73,
        "Winogrande":80.82,
        "GSM8K":52.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/loyal-piano-m7",
        "Average":68.67,
        "ARC":66.72,
        "HellaSwag":85.03,
        "MMLU":64.43,
        "TruthfulQA":60.03,
        "Winogrande":79.08,
        "GSM8K":56.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/openchat-3.5-1210-starling-slerp",
        "Average":68.67,
        "ARC":63.91,
        "HellaSwag":85.27,
        "MMLU":65.05,
        "TruthfulQA":49.92,
        "Winogrande":80.82,
        "GSM8K":67.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-Platypus-MistralM7-7B",
        "Average":68.66,
        "ARC":64.16,
        "HellaSwag":85.16,
        "MMLU":61.29,
        "TruthfulQA":59.99,
        "Winogrande":81.53,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-HardRuby-7B",
        "Average":68.65,
        "ARC":66.55,
        "HellaSwag":85.41,
        "MMLU":63.46,
        "TruthfulQA":56.94,
        "Winogrande":78.3,
        "GSM8K":61.26,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/Quintellect-10.7B",
        "Average":68.65,
        "ARC":65.02,
        "HellaSwag":84.48,
        "MMLU":63.28,
        "TruthfulQA":59.57,
        "Winogrande":79.01,
        "GSM8K":60.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A12P",
        "Average":68.64,
        "ARC":64.42,
        "HellaSwag":82.32,
        "MMLU":69.97,
        "TruthfulQA":62.22,
        "Winogrande":79.64,
        "GSM8K":53.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mncai\/agiin-13.6B-v0.0",
        "Average":68.63,
        "ARC":69.45,
        "HellaSwag":86.59,
        "MMLU":61.94,
        "TruthfulQA":67.4,
        "Winogrande":78.69,
        "GSM8K":47.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-ShinyEmerald-7B",
        "Average":68.63,
        "ARC":66.21,
        "HellaSwag":85.37,
        "MMLU":63.36,
        "TruthfulQA":56.65,
        "Winogrande":78.37,
        "GSM8K":61.79,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/spicyboros-70b-2.2",
        "Average":68.62,
        "ARC":70.73,
        "HellaSwag":87.58,
        "MMLU":70.32,
        "TruthfulQA":58.31,
        "Winogrande":83.82,
        "GSM8K":40.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.8-experiment26-7b-preview",
        "Average":68.6,
        "ARC":64.51,
        "HellaSwag":83.79,
        "MMLU":63.24,
        "TruthfulQA":54.87,
        "Winogrande":81.61,
        "GSM8K":63.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/dolphin-2.8-experiment26-7b",
        "Average":68.6,
        "ARC":64.51,
        "HellaSwag":83.79,
        "MMLU":63.24,
        "TruthfulQA":54.87,
        "Winogrande":81.61,
        "GSM8K":63.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luqmanxyz\/Maya_Hermes-2.5-Mistral-7B",
        "Average":68.6,
        "ARC":66.3,
        "HellaSwag":85.07,
        "MMLU":63.23,
        "TruthfulQA":55.89,
        "Winogrande":78.85,
        "GSM8K":62.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/MixtralRPChat-ZLoss",
        "Average":68.59,
        "ARC":68.6,
        "HellaSwag":86.1,
        "MMLU":70.44,
        "TruthfulQA":53.85,
        "Winogrande":82.0,
        "GSM8K":50.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/aegolius-acadicus-34b-v3",
        "Average":68.59,
        "ARC":67.66,
        "HellaSwag":85.54,
        "MMLU":62.13,
        "TruthfulQA":63.33,
        "Winogrande":78.69,
        "GSM8K":54.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LHC88\/DPOpenHermes-7B-v2-PerfLaser",
        "Average":68.58,
        "ARC":66.38,
        "HellaSwag":84.58,
        "MMLU":62.77,
        "TruthfulQA":59.07,
        "Winogrande":78.61,
        "GSM8K":60.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/InnerILLM-OpenPipe-Nous-Yarn-Mistral-optimized-1228-7B-slerp",
        "Average":68.58,
        "ARC":65.78,
        "HellaSwag":85.21,
        "MMLU":64.95,
        "TruthfulQA":53.51,
        "Winogrande":80.58,
        "GSM8K":61.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/InnerILLM-0x00d0-7B-slerp",
        "Average":68.58,
        "ARC":65.78,
        "HellaSwag":85.21,
        "MMLU":64.95,
        "TruthfulQA":53.51,
        "Winogrande":80.58,
        "GSM8K":61.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"brucethemoose\/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
        "Average":68.57,
        "ARC":64.93,
        "HellaSwag":84.99,
        "MMLU":75.37,
        "TruthfulQA":52.84,
        "Winogrande":79.24,
        "GSM8K":54.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_007",
        "Average":68.56,
        "ARC":71.08,
        "HellaSwag":87.65,
        "MMLU":69.04,
        "TruthfulQA":63.12,
        "Winogrande":83.35,
        "GSM8K":37.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uproai\/RosMistral-2x7B",
        "Average":68.56,
        "ARC":66.21,
        "HellaSwag":85.54,
        "MMLU":65.35,
        "TruthfulQA":52.87,
        "Winogrande":79.24,
        "GSM8K":62.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CohereForAI\/c4ai-command-r-v01",
        "Average":68.54,
        "ARC":65.53,
        "HellaSwag":87.0,
        "MMLU":68.2,
        "TruthfulQA":52.32,
        "Winogrande":81.53,
        "GSM8K":56.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"CohereForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":34.98,
        "Model Sha":780.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sequelbox\/SpellBlade",
        "Average":68.54,
        "ARC":69.28,
        "HellaSwag":87.31,
        "MMLU":70.5,
        "TruthfulQA":47.1,
        "Winogrande":83.19,
        "GSM8K":53.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/HerculeanSea-7b-128k",
        "Average":68.53,
        "ARC":66.21,
        "HellaSwag":85.8,
        "MMLU":64.28,
        "TruthfulQA":55.77,
        "Winogrande":80.74,
        "GSM8K":58.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"shahzebnaveed\/StarlingHermes-2.5-Mistral-7B-slerp",
        "Average":68.53,
        "ARC":66.04,
        "HellaSwag":85.18,
        "MMLU":64.72,
        "TruthfulQA":49.56,
        "Winogrande":79.72,
        "GSM8K":65.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_009",
        "Average":68.53,
        "ARC":71.59,
        "HellaSwag":87.7,
        "MMLU":69.43,
        "TruthfulQA":60.72,
        "Winogrande":82.32,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/stealth-v1.3",
        "Average":68.53,
        "ARC":65.19,
        "HellaSwag":84.44,
        "MMLU":62.7,
        "TruthfulQA":59.12,
        "Winogrande":78.61,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-PrimordialSapphire-7B",
        "Average":68.52,
        "ARC":65.87,
        "HellaSwag":85.51,
        "MMLU":63.11,
        "TruthfulQA":57.25,
        "Winogrande":78.22,
        "GSM8K":61.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-Sapphire-7B",
        "Average":68.52,
        "ARC":66.3,
        "HellaSwag":85.34,
        "MMLU":63.32,
        "TruthfulQA":56.09,
        "Winogrande":78.14,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2.04",
        "Average":68.52,
        "ARC":66.3,
        "HellaSwag":85.7,
        "MMLU":60.94,
        "TruthfulQA":67.76,
        "Winogrande":78.93,
        "GSM8K":51.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freecs\/ThetaWave-7B-v0",
        "Average":68.49,
        "ARC":68.52,
        "HellaSwag":85.35,
        "MMLU":61.07,
        "TruthfulQA":61.56,
        "Winogrande":79.64,
        "GSM8K":54.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Pasta-PrimaMaid-7b",
        "Average":68.48,
        "ARC":67.92,
        "HellaSwag":86.18,
        "MMLU":63.31,
        "TruthfulQA":66.47,
        "Winogrande":77.9,
        "GSM8K":49.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/Sonya-7B",
        "Average":68.48,
        "ARC":64.59,
        "HellaSwag":85.11,
        "MMLU":62.72,
        "TruthfulQA":61.22,
        "Winogrande":77.74,
        "GSM8K":59.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Instruct-v0.2-Seraph-7B",
        "Average":68.48,
        "ARC":64.76,
        "HellaSwag":84.2,
        "MMLU":62.9,
        "TruthfulQA":65.39,
        "Winogrande":79.16,
        "GSM8K":54.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Average":68.47,
        "ARC":66.38,
        "HellaSwag":86.46,
        "MMLU":71.88,
        "TruthfulQA":46.81,
        "Winogrande":81.69,
        "GSM8K":57.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1464.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/SystemConfigHermes-7B",
        "Average":68.47,
        "ARC":65.19,
        "HellaSwag":84.41,
        "MMLU":61.89,
        "TruthfulQA":60.11,
        "Winogrande":77.74,
        "GSM8K":61.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LoSboccacc\/orthogonal-2x7B-v2-base",
        "Average":68.47,
        "ARC":66.89,
        "HellaSwag":85.69,
        "MMLU":62.65,
        "TruthfulQA":66.8,
        "Winogrande":77.35,
        "GSM8K":51.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_101",
        "Average":68.46,
        "ARC":68.69,
        "HellaSwag":86.42,
        "MMLU":69.92,
        "TruthfulQA":58.85,
        "Winogrande":82.08,
        "GSM8K":44.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tenyx\/TenyxChat-7B-v1",
        "Average":68.46,
        "ARC":65.61,
        "HellaSwag":85.55,
        "MMLU":64.81,
        "TruthfulQA":51.28,
        "Winogrande":80.51,
        "GSM8K":63.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/V0202",
        "Average":68.46,
        "ARC":66.55,
        "HellaSwag":82.75,
        "MMLU":86.32,
        "TruthfulQA":50.89,
        "Winogrande":78.37,
        "GSM8K":45.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/Mixtral-8x7B-Holodeck-v1",
        "Average":68.45,
        "ARC":66.55,
        "HellaSwag":86.78,
        "MMLU":71.67,
        "TruthfulQA":48.28,
        "Winogrande":81.22,
        "GSM8K":56.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mistral_AI_v2",
        "Average":68.44,
        "ARC":65.44,
        "HellaSwag":85.61,
        "MMLU":63.44,
        "TruthfulQA":62.63,
        "Winogrande":80.35,
        "GSM8K":53.15,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ZoidBB\/Jovian-10.7B-v1.0",
        "Average":68.42,
        "ARC":67.41,
        "HellaSwag":86.4,
        "MMLU":65.66,
        "TruthfulQA":52.0,
        "Winogrande":81.85,
        "GSM8K":57.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"alykassem\/ds_diasum_md_mixtral",
        "Average":68.42,
        "ARC":66.3,
        "HellaSwag":85.45,
        "MMLU":69.51,
        "TruthfulQA":55.72,
        "Winogrande":80.35,
        "GSM8K":53.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Average":68.42,
        "ARC":66.04,
        "HellaSwag":86.49,
        "MMLU":71.82,
        "TruthfulQA":46.78,
        "Winogrande":81.93,
        "GSM8K":57.47,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1464.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/distilabeled-Hermes-2.5-Mistral-7B",
        "Average":68.42,
        "ARC":66.3,
        "HellaSwag":85.15,
        "MMLU":63.5,
        "TruthfulQA":55.75,
        "Winogrande":78.93,
        "GSM8K":60.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvilasuero\/NeuralHermes-2.5-Mistral-7B-distilabel",
        "Average":68.4,
        "ARC":65.78,
        "HellaSwag":84.97,
        "MMLU":63.63,
        "TruthfulQA":55.86,
        "Winogrande":78.69,
        "GSM8K":61.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Code-Mistral-7B",
        "Average":68.4,
        "ARC":63.57,
        "HellaSwag":83.71,
        "MMLU":63.38,
        "TruthfulQA":51.81,
        "Winogrande":81.22,
        "GSM8K":66.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/agiin-13.6B-v0.1",
        "Average":68.4,
        "ARC":69.45,
        "HellaSwag":86.64,
        "MMLU":61.15,
        "TruthfulQA":67.97,
        "Winogrande":78.69,
        "GSM8K":46.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.78,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xDAN-AI\/xDAN-L1-Chat-RL-v1",
        "Average":68.38,
        "ARC":66.3,
        "HellaSwag":85.81,
        "MMLU":63.21,
        "TruthfulQA":56.7,
        "Winogrande":78.85,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":59.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Llama",
        "Average":68.37,
        "ARC":67.83,
        "HellaSwag":85.35,
        "MMLU":78.26,
        "TruthfulQA":53.46,
        "Winogrande":82.87,
        "GSM8K":42.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"budecosystem\/genz-70b",
        "Average":68.35,
        "ARC":71.42,
        "HellaSwag":87.99,
        "MMLU":70.78,
        "TruthfulQA":62.66,
        "Winogrande":83.5,
        "GSM8K":33.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":70.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/zen_moe",
        "Average":68.34,
        "ARC":63.82,
        "HellaSwag":85.05,
        "MMLU":64.75,
        "TruthfulQA":50.03,
        "Winogrande":81.06,
        "GSM8K":65.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Dumb-Maidlet",
        "Average":68.34,
        "ARC":66.81,
        "HellaSwag":86.06,
        "MMLU":65.17,
        "TruthfulQA":50.7,
        "Winogrande":80.19,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ZoidBB\/Jovian-10.7B-v1.0",
        "Average":68.34,
        "ARC":67.06,
        "HellaSwag":86.39,
        "MMLU":65.5,
        "TruthfulQA":52.0,
        "Winogrande":81.45,
        "GSM8K":57.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/ColorShadow-7B",
        "Average":68.34,
        "ARC":67.83,
        "HellaSwag":85.15,
        "MMLU":61.69,
        "TruthfulQA":59.56,
        "Winogrande":80.58,
        "GSM8K":55.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/kellemar-DPO-7B-v1.01",
        "Average":68.32,
        "ARC":65.78,
        "HellaSwag":85.04,
        "MMLU":63.24,
        "TruthfulQA":55.54,
        "Winogrande":78.69,
        "GSM8K":61.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Llama-Q-FastChat",
        "Average":68.31,
        "ARC":66.13,
        "HellaSwag":85.25,
        "MMLU":78.37,
        "TruthfulQA":53.62,
        "Winogrande":82.16,
        "GSM8K":44.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Falkor-8x7B-MoE",
        "Average":68.31,
        "ARC":66.3,
        "HellaSwag":85.03,
        "MMLU":64.13,
        "TruthfulQA":53.5,
        "Winogrande":80.19,
        "GSM8K":60.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Hermes-low-tune-3.1",
        "Average":68.31,
        "ARC":65.44,
        "HellaSwag":84.6,
        "MMLU":64.13,
        "TruthfulQA":53.59,
        "Winogrande":78.61,
        "GSM8K":63.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":null,
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"jeiku\/NarrativeNexus_7B",
        "Average":68.3,
        "ARC":66.13,
        "HellaSwag":85.74,
        "MMLU":63.17,
        "TruthfulQA":63.95,
        "Winogrande":79.01,
        "GSM8K":51.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-2",
        "Average":68.29,
        "ARC":67.49,
        "HellaSwag":83.92,
        "MMLU":63.55,
        "TruthfulQA":59.68,
        "Winogrande":79.95,
        "GSM8K":55.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":52.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Prima-LelantaclesV4-7b-16k-bf16",
        "Average":68.28,
        "ARC":66.04,
        "HellaSwag":85.07,
        "MMLU":64.7,
        "TruthfulQA":54.76,
        "Winogrande":80.27,
        "GSM8K":58.83,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.4",
        "Average":68.28,
        "ARC":63.31,
        "HellaSwag":82.74,
        "MMLU":74.32,
        "TruthfulQA":55.25,
        "Winogrande":80.58,
        "GSM8K":53.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/RP-Coder-SM3",
        "Average":68.28,
        "ARC":65.61,
        "HellaSwag":84.22,
        "MMLU":63.34,
        "TruthfulQA":54.11,
        "Winogrande":82.56,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/e.star.7.b",
        "Average":68.28,
        "ARC":63.91,
        "HellaSwag":86.02,
        "MMLU":63.44,
        "TruthfulQA":54.91,
        "Winogrande":80.19,
        "GSM8K":61.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/Xwin-LM-70B-V0.1_Jannie",
        "Average":68.26,
        "ARC":71.16,
        "HellaSwag":86.86,
        "MMLU":69.56,
        "TruthfulQA":60.14,
        "Winogrande":81.06,
        "GSM8K":40.79,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/kellemar-DPO-7B",
        "Average":68.26,
        "ARC":66.04,
        "HellaSwag":85.21,
        "MMLU":63.42,
        "TruthfulQA":55.55,
        "Winogrande":78.93,
        "GSM8K":60.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/RP-Coder-SM3",
        "Average":68.25,
        "ARC":65.78,
        "HellaSwag":84.21,
        "MMLU":63.28,
        "TruthfulQA":54.12,
        "Winogrande":82.16,
        "GSM8K":59.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Eclipse-7B",
        "Average":68.25,
        "ARC":62.54,
        "HellaSwag":84.19,
        "MMLU":64.92,
        "TruthfulQA":53.37,
        "Winogrande":84.29,
        "GSM8K":60.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Walmart-the-bag\/WordWoven-13B",
        "Average":68.25,
        "ARC":66.13,
        "HellaSwag":85.81,
        "MMLU":64.06,
        "TruthfulQA":54.45,
        "Winogrande":78.93,
        "GSM8K":60.12,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"elinas\/chronos007-70b",
        "Average":68.25,
        "ARC":70.14,
        "HellaSwag":87.52,
        "MMLU":69.33,
        "TruthfulQA":57.65,
        "Winogrande":82.24,
        "GSM8K":42.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama2_70b_mmlu",
        "Average":68.24,
        "ARC":65.61,
        "HellaSwag":87.37,
        "MMLU":71.89,
        "TruthfulQA":49.15,
        "Winogrande":82.4,
        "GSM8K":52.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"hydra-project\/ChatHercules-2.5-Mistral-7B",
        "Average":68.24,
        "ARC":65.1,
        "HellaSwag":84.61,
        "MMLU":65.35,
        "TruthfulQA":47.52,
        "Winogrande":81.85,
        "GSM8K":64.97,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decapoda-research\/Antares-11b-v1",
        "Average":68.24,
        "ARC":64.51,
        "HellaSwag":84.85,
        "MMLU":65.96,
        "TruthfulQA":52.84,
        "Winogrande":82.95,
        "GSM8K":58.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/kellemar-DPO-7B",
        "Average":68.23,
        "ARC":66.21,
        "HellaSwag":85.25,
        "MMLU":63.38,
        "TruthfulQA":55.53,
        "Winogrande":78.37,
        "GSM8K":60.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/NeuralHermes-2.5-Mistral-7B",
        "Average":68.22,
        "ARC":66.55,
        "HellaSwag":84.9,
        "MMLU":63.32,
        "TruthfulQA":54.93,
        "Winogrande":78.3,
        "GSM8K":61.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":140.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"martyn\/mixtral-megamerge-dare-8x7b-v2",
        "Average":68.2,
        "ARC":66.47,
        "HellaSwag":86.11,
        "MMLU":69.14,
        "TruthfulQA":53.81,
        "Winogrande":79.79,
        "GSM8K":53.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"maldv\/eleusis-7b-alpha",
        "Average":68.2,
        "ARC":64.93,
        "HellaSwag":84.87,
        "MMLU":64.1,
        "TruthfulQA":54.34,
        "Winogrande":79.16,
        "GSM8K":61.79,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/C0322-reft",
        "Average":68.2,
        "ARC":64.42,
        "HellaSwag":83.74,
        "MMLU":79.5,
        "TruthfulQA":59.77,
        "Winogrande":78.45,
        "GSM8K":43.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"CohereForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vistagi\/Mixtral-8x7b-v0.1-dpo",
        "Average":68.18,
        "ARC":66.55,
        "HellaSwag":86.4,
        "MMLU":71.65,
        "TruthfulQA":46.74,
        "Winogrande":81.53,
        "GSM8K":56.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vistagi\/Mixtral-8x7b-v0.1-sft",
        "Average":68.18,
        "ARC":66.55,
        "HellaSwag":86.4,
        "MMLU":71.65,
        "TruthfulQA":46.74,
        "Winogrande":81.53,
        "GSM8K":56.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OrionStarAI\/OrionStar-Yi-34B-Chat-Llama",
        "Average":68.17,
        "ARC":64.93,
        "HellaSwag":84.34,
        "MMLU":73.67,
        "TruthfulQA":53.35,
        "Winogrande":78.85,
        "GSM8K":53.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Sensualize-Solar-10.7B",
        "Average":68.17,
        "ARC":65.02,
        "HellaSwag":84.55,
        "MMLU":65.27,
        "TruthfulQA":53.63,
        "Winogrande":83.98,
        "GSM8K":56.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/Chikuma_10.7B",
        "Average":68.17,
        "ARC":65.7,
        "HellaSwag":84.31,
        "MMLU":64.81,
        "TruthfulQA":57.01,
        "Winogrande":79.56,
        "GSM8K":57.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FredrikBL\/test-dare",
        "Average":68.16,
        "ARC":64.59,
        "HellaSwag":84.87,
        "MMLU":64.43,
        "TruthfulQA":52.69,
        "Winogrande":81.29,
        "GSM8K":61.11,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v3_1-yi-34b",
        "Average":68.16,
        "ARC":65.36,
        "HellaSwag":84.24,
        "MMLU":74.37,
        "TruthfulQA":56.06,
        "Winogrande":82.08,
        "GSM8K":46.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-llama2-70b-v10.1-bf16",
        "Average":68.16,
        "ARC":61.86,
        "HellaSwag":83.13,
        "MMLU":67.41,
        "TruthfulQA":56.18,
        "Winogrande":80.11,
        "GSM8K":60.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":70.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/AZG",
        "Average":68.16,
        "ARC":62.88,
        "HellaSwag":82.02,
        "MMLU":70.29,
        "TruthfulQA":53.84,
        "Winogrande":79.95,
        "GSM8K":59.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/CapybaraHermes-2.5-Mistral-7B",
        "Average":68.14,
        "ARC":65.78,
        "HellaSwag":85.45,
        "MMLU":63.13,
        "TruthfulQA":56.91,
        "Winogrande":78.3,
        "GSM8K":59.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":51.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LoSboccacc\/orthogonal-2x7B-base",
        "Average":68.13,
        "ARC":66.89,
        "HellaSwag":85.54,
        "MMLU":62.49,
        "TruthfulQA":66.0,
        "Winogrande":77.03,
        "GSM8K":50.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/Marcoroni-neural-chat-7B-v2_gsm8k_merged",
        "Average":68.13,
        "ARC":65.78,
        "HellaSwag":85.26,
        "MMLU":64.26,
        "TruthfulQA":53.18,
        "Winogrande":78.93,
        "GSM8K":61.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Fredithefish\/OpenZephyrChat",
        "Average":68.12,
        "ARC":64.85,
        "HellaSwag":85.08,
        "MMLU":64.92,
        "TruthfulQA":48.24,
        "Winogrande":81.06,
        "GSM8K":64.59,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mistral-7B-DPO",
        "Average":68.1,
        "ARC":65.7,
        "HellaSwag":84.94,
        "MMLU":63.25,
        "TruthfulQA":55.78,
        "Winogrande":78.45,
        "GSM8K":60.5,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":137.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mncai\/agiin-11.1B-v0.0",
        "Average":68.1,
        "ARC":67.32,
        "HellaSwag":86.35,
        "MMLU":64.99,
        "TruthfulQA":67.67,
        "Winogrande":78.85,
        "GSM8K":43.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-LoRA",
        "Average":68.1,
        "ARC":67.15,
        "HellaSwag":85.37,
        "MMLU":78.46,
        "TruthfulQA":53.32,
        "Winogrande":83.66,
        "GSM8K":40.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mistral-7B-DPO",
        "Average":68.1,
        "ARC":66.04,
        "HellaSwag":84.95,
        "MMLU":63.36,
        "TruthfulQA":55.75,
        "Winogrande":78.06,
        "GSM8K":60.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":137.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Voldemort-10B",
        "Average":68.08,
        "ARC":64.42,
        "HellaSwag":84.25,
        "MMLU":62.87,
        "TruthfulQA":59.92,
        "Winogrande":77.03,
        "GSM8K":59.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"GreenNode\/Merged-DPO-7B",
        "Average":68.06,
        "ARC":68.94,
        "HellaSwag":87.75,
        "MMLU":55.35,
        "TruthfulQA":72.76,
        "Winogrande":78.37,
        "GSM8K":45.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Isaak-Carter\/JOSIE_Beta-4-7B-slerp",
        "Average":68.06,
        "ARC":63.57,
        "HellaSwag":84.1,
        "MMLU":63.73,
        "TruthfulQA":55.93,
        "Winogrande":79.32,
        "GSM8K":61.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/xDAN-SlimOrca",
        "Average":68.04,
        "ARC":65.61,
        "HellaSwag":85.7,
        "MMLU":63.67,
        "TruthfulQA":57.68,
        "Winogrande":77.66,
        "GSM8K":57.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"DenisTheDev\/Blitz-AI-MOE-v0.4",
        "Average":68.04,
        "ARC":66.3,
        "HellaSwag":85.59,
        "MMLU":64.24,
        "TruthfulQA":53.55,
        "Winogrande":78.45,
        "GSM8K":60.12,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Hermes-low-tune-2",
        "Average":68.04,
        "ARC":65.61,
        "HellaSwag":84.47,
        "MMLU":63.69,
        "TruthfulQA":53.18,
        "Winogrande":77.74,
        "GSM8K":63.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"llmixer\/BigWeave-v20-110b",
        "Average":68.03,
        "ARC":68.17,
        "HellaSwag":88.54,
        "MMLU":70.51,
        "TruthfulQA":62.47,
        "Winogrande":82.08,
        "GSM8K":36.39,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":110.05,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"deepnight-research\/lil-c3po",
        "Average":68.03,
        "ARC":65.02,
        "HellaSwag":84.45,
        "MMLU":62.36,
        "TruthfulQA":68.73,
        "Winogrande":79.16,
        "GSM8K":48.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cris177\/DesivoMerge0.1",
        "Average":68.01,
        "ARC":65.87,
        "HellaSwag":85.39,
        "MMLU":64.35,
        "TruthfulQA":55.36,
        "Winogrande":78.53,
        "GSM8K":58.53,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/OpenMia-Indo-Mistral-7b-v3-refined",
        "Average":68.0,
        "ARC":64.42,
        "HellaSwag":84.22,
        "MMLU":62.64,
        "TruthfulQA":53.95,
        "Winogrande":81.53,
        "GSM8K":61.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/OpenMia-Indo-Mistral-7b-v3-refined",
        "Average":68.0,
        "ARC":64.42,
        "HellaSwag":84.22,
        "MMLU":62.64,
        "TruthfulQA":53.95,
        "Winogrande":81.53,
        "GSM8K":61.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"joowon99\/SOLAR-10.7B-ko_alpaca",
        "Average":67.98,
        "ARC":64.16,
        "HellaSwag":82.62,
        "MMLU":65.71,
        "TruthfulQA":55.95,
        "Winogrande":81.06,
        "GSM8K":58.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HIT-SCIR\/huozi3",
        "Average":67.97,
        "ARC":65.02,
        "HellaSwag":86.0,
        "MMLU":70.61,
        "TruthfulQA":49.45,
        "Winogrande":82.16,
        "GSM8K":54.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.91,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/openchat-3.5-Infinity",
        "Average":67.95,
        "ARC":62.63,
        "HellaSwag":84.05,
        "MMLU":64.65,
        "TruthfulQA":51.99,
        "Winogrande":80.11,
        "GSM8K":64.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-dpo-7b-v0.1",
        "Average":67.95,
        "ARC":66.72,
        "HellaSwag":84.16,
        "MMLU":64.24,
        "TruthfulQA":64.05,
        "Winogrande":80.9,
        "GSM8K":47.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/SystemHermes-2-7B",
        "Average":67.92,
        "ARC":65.02,
        "HellaSwag":84.05,
        "MMLU":63.16,
        "TruthfulQA":56.42,
        "Winogrande":77.35,
        "GSM8K":61.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-exp2-0.1",
        "Average":67.92,
        "ARC":62.97,
        "HellaSwag":82.11,
        "MMLU":74.66,
        "TruthfulQA":55.24,
        "Winogrande":79.79,
        "GSM8K":52.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Liangmingxin\/ThetaWave-7B-sft",
        "Average":67.92,
        "ARC":63.14,
        "HellaSwag":84.42,
        "MMLU":63.78,
        "TruthfulQA":59.74,
        "Winogrande":79.64,
        "GSM8K":56.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freecs\/Zero-7B-test-2",
        "Average":67.91,
        "ARC":66.13,
        "HellaSwag":84.77,
        "MMLU":62.98,
        "TruthfulQA":59.95,
        "Winogrande":80.03,
        "GSM8K":53.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Prima-Pastacles-7b",
        "Average":67.91,
        "ARC":66.04,
        "HellaSwag":85.83,
        "MMLU":64.21,
        "TruthfulQA":56.69,
        "Winogrande":79.64,
        "GSM8K":55.04,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Ryu-4x7B-MoE-bf16",
        "Average":67.9,
        "ARC":66.47,
        "HellaSwag":83.1,
        "MMLU":63.89,
        "TruthfulQA":64.96,
        "Winogrande":79.24,
        "GSM8K":49.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Echidna-7b-128k",
        "Average":67.88,
        "ARC":66.13,
        "HellaSwag":85.18,
        "MMLU":63.04,
        "TruthfulQA":56.07,
        "Winogrande":80.03,
        "GSM8K":56.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/solarized-18B-dpo",
        "Average":67.88,
        "ARC":68.34,
        "HellaSwag":87.79,
        "MMLU":63.89,
        "TruthfulQA":66.49,
        "Winogrande":80.51,
        "GSM8K":40.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":17.93,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Llama-Q-v2",
        "Average":67.88,
        "ARC":61.09,
        "HellaSwag":85.09,
        "MMLU":76.59,
        "TruthfulQA":52.65,
        "Winogrande":82.79,
        "GSM8K":49.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Einstein-openchat-7B",
        "Average":67.87,
        "ARC":65.1,
        "HellaSwag":83.57,
        "MMLU":64.01,
        "TruthfulQA":54.51,
        "Winogrande":79.16,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Average":67.87,
        "ARC":67.32,
        "HellaSwag":87.33,
        "MMLU":69.83,
        "TruthfulQA":44.92,
        "Winogrande":83.74,
        "GSM8K":54.06,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":68.98,
        "Model Sha":788.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"martyn\/mixtral-megamerge-dare-8x7b-v2",
        "Average":67.87,
        "ARC":66.47,
        "HellaSwag":86.05,
        "MMLU":69.08,
        "TruthfulQA":53.82,
        "Winogrande":79.32,
        "GSM8K":52.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openagi-project\/OpenAGI-7B-v0.1",
        "Average":67.87,
        "ARC":68.26,
        "HellaSwag":85.06,
        "MMLU":61.6,
        "TruthfulQA":59.4,
        "Winogrande":79.79,
        "GSM8K":53.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/MiaLatte-Indo-Mistral-7b",
        "Average":67.86,
        "ARC":66.55,
        "HellaSwag":85.23,
        "MMLU":63.93,
        "TruthfulQA":56.04,
        "Winogrande":80.35,
        "GSM8K":55.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-200k-Q-FastChat",
        "Average":67.85,
        "ARC":64.93,
        "HellaSwag":84.46,
        "MMLU":77.13,
        "TruthfulQA":48.38,
        "Winogrande":80.74,
        "GSM8K":51.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Hermes-low-tune-2",
        "Average":67.85,
        "ARC":65.27,
        "HellaSwag":84.41,
        "MMLU":63.63,
        "TruthfulQA":53.12,
        "Winogrande":78.22,
        "GSM8K":62.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-180B",
        "Average":67.85,
        "ARC":69.45,
        "HellaSwag":88.86,
        "MMLU":70.5,
        "TruthfulQA":45.47,
        "Winogrande":86.9,
        "GSM8K":45.94,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":179.52,
        "Model Sha":1073.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Shiki-m7",
        "Average":67.85,
        "ARC":65.53,
        "HellaSwag":85.3,
        "MMLU":63.57,
        "TruthfulQA":65.45,
        "Winogrande":77.74,
        "GSM8K":49.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051615\/A0305a",
        "Average":67.85,
        "ARC":61.35,
        "HellaSwag":80.4,
        "MMLU":75.66,
        "TruthfulQA":51.74,
        "Winogrande":77.66,
        "GSM8K":60.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/Nyxene-v2-11B",
        "Average":67.84,
        "ARC":67.41,
        "HellaSwag":84.54,
        "MMLU":65.26,
        "TruthfulQA":55.62,
        "Winogrande":79.56,
        "GSM8K":54.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/OpenHermes-2.5-neural-chat-7b-v3-1-7B",
        "Average":67.84,
        "ARC":66.55,
        "HellaSwag":84.47,
        "MMLU":63.34,
        "TruthfulQA":61.22,
        "Winogrande":78.37,
        "GSM8K":53.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freecs\/Zero-7B-test-1",
        "Average":67.83,
        "ARC":66.13,
        "HellaSwag":84.62,
        "MMLU":63.12,
        "TruthfulQA":58.97,
        "Winogrande":79.64,
        "GSM8K":54.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ldahee\/SLAL-0.1",
        "Average":67.83,
        "ARC":57.94,
        "HellaSwag":80.14,
        "MMLU":65.99,
        "TruthfulQA":54.22,
        "Winogrande":85.56,
        "GSM8K":63.15,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":26.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-Gemma-7b",
        "Average":67.83,
        "ARC":59.98,
        "HellaSwag":81.91,
        "MMLU":63.76,
        "TruthfulQA":61.0,
        "Winogrande":76.64,
        "GSM8K":63.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Swisslex\/Mixtral-Orca-v0.1",
        "Average":67.82,
        "ARC":69.71,
        "HellaSwag":88.88,
        "MMLU":66.06,
        "TruthfulQA":63.85,
        "Winogrande":81.14,
        "GSM8K":37.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/NarutoDolphin-10B",
        "Average":67.82,
        "ARC":63.82,
        "HellaSwag":84.17,
        "MMLU":62.85,
        "TruthfulQA":59.13,
        "Winogrande":77.51,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/NarutoDolphin-7B",
        "Average":67.82,
        "ARC":63.82,
        "HellaSwag":84.17,
        "MMLU":62.85,
        "TruthfulQA":59.13,
        "Winogrande":77.51,
        "GSM8K":59.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_BioMedical",
        "Average":67.81,
        "ARC":65.44,
        "HellaSwag":85.2,
        "MMLU":63.17,
        "TruthfulQA":62.24,
        "Winogrande":79.72,
        "GSM8K":51.1,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-Mixtral-8x7B",
        "Average":67.8,
        "ARC":68.86,
        "HellaSwag":86.01,
        "MMLU":66.69,
        "TruthfulQA":57.2,
        "Winogrande":80.51,
        "GSM8K":47.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Open_Maid_Samantha_Hermes_Orca_dare_tiesv0.1",
        "Average":67.8,
        "ARC":65.87,
        "HellaSwag":85.48,
        "MMLU":64.5,
        "TruthfulQA":51.92,
        "Winogrande":80.35,
        "GSM8K":58.68,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/stealth-rag-v1.1",
        "Average":67.79,
        "ARC":62.12,
        "HellaSwag":83.83,
        "MMLU":64.06,
        "TruthfulQA":49.64,
        "Winogrande":79.32,
        "GSM8K":67.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xwin-LM\/Xwin-Math-70B-V1.0",
        "Average":67.78,
        "ARC":64.51,
        "HellaSwag":84.88,
        "MMLU":66.2,
        "TruthfulQA":51.58,
        "Winogrande":81.53,
        "GSM8K":58.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kimou605\/shadow-clown-BioMistral-7B-SLERP",
        "Average":67.78,
        "ARC":64.76,
        "HellaSwag":84.55,
        "MMLU":61.93,
        "TruthfulQA":62.4,
        "Winogrande":80.66,
        "GSM8K":52.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/DistilHermes-2.5-Mistral-7B",
        "Average":67.76,
        "ARC":65.87,
        "HellaSwag":84.78,
        "MMLU":63.65,
        "TruthfulQA":54.24,
        "Winogrande":78.22,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B",
        "Average":67.76,
        "ARC":66.81,
        "HellaSwag":83.52,
        "MMLU":62.68,
        "TruthfulQA":52.31,
        "Winogrande":79.08,
        "GSM8K":62.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RatanRohith\/MistralBeagle-RS-7B-V0.1",
        "Average":67.75,
        "ARC":69.45,
        "HellaSwag":84.62,
        "MMLU":63.07,
        "TruthfulQA":69.78,
        "Winogrande":81.69,
        "GSM8K":37.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"liminerity\/Blur-7b-v1.2",
        "Average":67.74,
        "ARC":65.36,
        "HellaSwag":83.88,
        "MMLU":63.45,
        "TruthfulQA":60.3,
        "Winogrande":80.58,
        "GSM8K":52.84,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Q-bert\/Bumblebee-7B",
        "Average":67.73,
        "ARC":63.4,
        "HellaSwag":84.16,
        "MMLU":64.0,
        "TruthfulQA":50.96,
        "Winogrande":78.22,
        "GSM8K":65.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051612\/B0122",
        "Average":67.73,
        "ARC":67.92,
        "HellaSwag":84.92,
        "MMLU":81.53,
        "TruthfulQA":58.2,
        "Winogrande":80.82,
        "GSM8K":32.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/Nyxene-11B",
        "Average":67.72,
        "ARC":68.34,
        "HellaSwag":84.54,
        "MMLU":65.09,
        "TruthfulQA":57.5,
        "Winogrande":79.08,
        "GSM8K":51.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"eldogbbhed\/NeuralKrishnaMathWizard-7B",
        "Average":67.7,
        "ARC":63.05,
        "HellaSwag":85.12,
        "MMLU":61.78,
        "TruthfulQA":49.06,
        "Winogrande":78.06,
        "GSM8K":69.14,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/dolphin-2.8-experiment26-7b",
        "Average":67.69,
        "ARC":63.65,
        "HellaSwag":83.7,
        "MMLU":62.31,
        "TruthfulQA":55.1,
        "Winogrande":78.77,
        "GSM8K":62.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PetroGPT\/Voldemort-10B-DPO",
        "Average":67.69,
        "ARC":65.7,
        "HellaSwag":84.79,
        "MMLU":62.82,
        "TruthfulQA":61.33,
        "Winogrande":77.27,
        "GSM8K":54.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PetroGPT\/Voldemort-10B-DPO",
        "Average":67.68,
        "ARC":66.04,
        "HellaSwag":84.84,
        "MMLU":62.88,
        "TruthfulQA":61.44,
        "Winogrande":77.03,
        "GSM8K":53.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Euryale-1.3-L2-70B",
        "Average":67.66,
        "ARC":70.82,
        "HellaSwag":87.92,
        "MMLU":70.39,
        "TruthfulQA":59.85,
        "Winogrande":82.79,
        "GSM8K":34.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":39.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eurdem\/Megatron-Mx",
        "Average":67.65,
        "ARC":66.89,
        "HellaSwag":84.98,
        "MMLU":62.08,
        "TruthfulQA":59.95,
        "Winogrande":79.01,
        "GSM8K":52.99,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SeaLLMs\/SeaLLM-7B-v2",
        "Average":67.65,
        "ARC":61.86,
        "HellaSwag":82.34,
        "MMLU":62.15,
        "TruthfulQA":51.15,
        "Winogrande":79.72,
        "GSM8K":68.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.38,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rombodawg\/Everyone-Coder-4x7b-Base",
        "Average":67.65,
        "ARC":64.51,
        "HellaSwag":84.76,
        "MMLU":64.35,
        "TruthfulQA":49.19,
        "Winogrande":79.16,
        "GSM8K":63.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":24.15,
        "Model Sha":40.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"localfultonextractor\/Erosumika-7B-v2",
        "Average":67.64,
        "ARC":65.61,
        "HellaSwag":86.29,
        "MMLU":62.51,
        "TruthfulQA":69.0,
        "Winogrande":77.27,
        "GSM8K":45.19,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"freeCS-dot-org\/OpenAGI-testing-truthyDPO-1",
        "Average":67.64,
        "ARC":67.32,
        "HellaSwag":85.99,
        "MMLU":63.12,
        "TruthfulQA":71.12,
        "Winogrande":81.22,
        "GSM8K":37.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mrfakename\/NeuralOrca-7B-v1",
        "Average":67.64,
        "ARC":65.27,
        "HellaSwag":85.07,
        "MMLU":63.68,
        "TruthfulQA":54.58,
        "Winogrande":78.77,
        "GSM8K":58.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/DPOpenHermes-7B",
        "Average":67.63,
        "ARC":65.96,
        "HellaSwag":85.9,
        "MMLU":63.98,
        "TruthfulQA":56.92,
        "Winogrande":78.22,
        "GSM8K":54.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eric111\/Mistral-7B-Instruct-v0.2_openchat-3.5-0106",
        "Average":67.63,
        "ARC":65.7,
        "HellaSwag":84.58,
        "MMLU":63.23,
        "TruthfulQA":58.89,
        "Winogrande":79.32,
        "GSM8K":54.06,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JaeyeonKang\/CCK-v2.0-DPO",
        "Average":67.62,
        "ARC":65.87,
        "HellaSwag":86.81,
        "MMLU":62.1,
        "TruthfulQA":69.33,
        "Winogrande":82.16,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-NeuralHermes-2.5-Mistral-7B-Linear",
        "Average":67.6,
        "ARC":62.8,
        "HellaSwag":84.21,
        "MMLU":63.43,
        "TruthfulQA":48.57,
        "Winogrande":76.8,
        "GSM8K":69.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fangloveskari\/ORCA_LLaMA_70B_QLoRA",
        "Average":67.6,
        "ARC":72.27,
        "HellaSwag":87.74,
        "MMLU":70.23,
        "TruthfulQA":63.37,
        "Winogrande":83.66,
        "GSM8K":28.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":52.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/Nyxene-v1-11B",
        "Average":67.58,
        "ARC":67.49,
        "HellaSwag":84.52,
        "MMLU":65.12,
        "TruthfulQA":57.28,
        "Winogrande":79.01,
        "GSM8K":52.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openaccess-ai-collective\/DPOpenHermes-7B",
        "Average":67.58,
        "ARC":65.7,
        "HellaSwag":85.96,
        "MMLU":63.89,
        "TruthfulQA":56.95,
        "Winogrande":78.61,
        "GSM8K":54.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nonetrix\/sillyrp-7b",
        "Average":67.58,
        "ARC":64.93,
        "HellaSwag":85.26,
        "MMLU":64.2,
        "TruthfulQA":54.28,
        "Winogrande":77.66,
        "GSM8K":59.14,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"r2rss\/Malachite-7b-v0",
        "Average":67.58,
        "ARC":67.75,
        "HellaSwag":83.66,
        "MMLU":63.54,
        "TruthfulQA":64.49,
        "Winogrande":81.22,
        "GSM8K":44.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"dozzke\/hermorca",
        "Average":67.57,
        "ARC":63.74,
        "HellaSwag":84.4,
        "MMLU":64.28,
        "TruthfulQA":57.69,
        "Winogrande":76.87,
        "GSM8K":58.45,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SeaLLMs\/SeaLLM-7B-v2",
        "Average":67.57,
        "ARC":62.03,
        "HellaSwag":82.32,
        "MMLU":61.89,
        "TruthfulQA":51.11,
        "Winogrande":79.08,
        "GSM8K":68.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-14b",
        "Average":67.57,
        "ARC":58.45,
        "HellaSwag":80.72,
        "MMLU":68.45,
        "TruthfulQA":54.89,
        "Winogrande":75.14,
        "GSM8K":67.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.17,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fangloveskari\/Platypus_QLoRA_LLaMA_70b",
        "Average":67.57,
        "ARC":72.1,
        "HellaSwag":87.46,
        "MMLU":71.02,
        "TruthfulQA":61.18,
        "Winogrande":82.87,
        "GSM8K":30.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rombodawg\/Everyone-Coder-4x7b-Base",
        "Average":67.56,
        "ARC":64.51,
        "HellaSwag":84.81,
        "MMLU":64.27,
        "TruthfulQA":49.16,
        "Winogrande":79.16,
        "GSM8K":63.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":24.15,
        "Model Sha":40.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_Chat_X_128k",
        "Average":67.54,
        "ARC":65.27,
        "HellaSwag":85.27,
        "MMLU":63.98,
        "TruthfulQA":57.23,
        "Winogrande":80.58,
        "GSM8K":52.92,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-neural-chat-7b-v3-2-Ties",
        "Average":67.54,
        "ARC":63.48,
        "HellaSwag":82.34,
        "MMLU":62.25,
        "TruthfulQA":52.06,
        "Winogrande":76.87,
        "GSM8K":68.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bongchoi\/MoMo-70B-LoRA-V1.1",
        "Average":67.53,
        "ARC":66.64,
        "HellaSwag":87.16,
        "MMLU":66.76,
        "TruthfulQA":54.98,
        "Winogrande":83.35,
        "GSM8K":46.32,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"dozzke\/hermorca",
        "Average":67.53,
        "ARC":63.57,
        "HellaSwag":84.41,
        "MMLU":64.29,
        "TruthfulQA":57.63,
        "Winogrande":77.03,
        "GSM8K":58.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"argilla\/DistilabelBeagle14-7B",
        "Average":67.52,
        "ARC":71.08,
        "HellaSwag":87.0,
        "MMLU":61.27,
        "TruthfulQA":68.91,
        "Winogrande":80.74,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/NexoNimbus-MoE-2x7B",
        "Average":67.51,
        "ARC":66.81,
        "HellaSwag":85.66,
        "MMLU":64.51,
        "TruthfulQA":53.06,
        "Winogrande":81.53,
        "GSM8K":53.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"r2rss\/Malachite-7b-v0",
        "Average":67.5,
        "ARC":67.75,
        "HellaSwag":83.68,
        "MMLU":63.64,
        "TruthfulQA":64.54,
        "Winogrande":81.37,
        "GSM8K":44.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/kellemar-DPO-7B-c",
        "Average":67.5,
        "ARC":65.7,
        "HellaSwag":84.98,
        "MMLU":63.7,
        "TruthfulQA":54.08,
        "Winogrande":78.3,
        "GSM8K":58.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"grimjim\/Mistral-Starling-merge-trial1-7B",
        "Average":67.49,
        "ARC":66.13,
        "HellaSwag":84.67,
        "MMLU":64.12,
        "TruthfulQA":53.18,
        "Winogrande":80.43,
        "GSM8K":56.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"InferenceIllusionist\/Magic-Dolphin-7b",
        "Average":67.48,
        "ARC":65.78,
        "HellaSwag":85.61,
        "MMLU":64.64,
        "TruthfulQA":58.01,
        "Winogrande":79.64,
        "GSM8K":51.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"llmixer\/BigWeave-v6-90b",
        "Average":67.47,
        "ARC":65.36,
        "HellaSwag":87.21,
        "MMLU":68.04,
        "TruthfulQA":57.96,
        "Winogrande":81.69,
        "GSM8K":44.58,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":87.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/toten_gsm8k_merged_s",
        "Average":67.47,
        "ARC":65.27,
        "HellaSwag":84.7,
        "MMLU":62.83,
        "TruthfulQA":54.92,
        "Winogrande":77.9,
        "GSM8K":59.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ICBU-NPU\/FashionGPT-70B-V1",
        "Average":67.47,
        "ARC":71.08,
        "HellaSwag":87.32,
        "MMLU":70.7,
        "TruthfulQA":63.92,
        "Winogrande":83.66,
        "GSM8K":28.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/juanako-7b-UNA",
        "Average":67.46,
        "ARC":68.17,
        "HellaSwag":85.34,
        "MMLU":62.47,
        "TruthfulQA":65.13,
        "Winogrande":78.85,
        "GSM8K":44.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":23.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tourist800\/Mistral-7B-Merge-14-v0.2",
        "Average":67.46,
        "ARC":65.02,
        "HellaSwag":85.13,
        "MMLU":64.36,
        "TruthfulQA":54.15,
        "Winogrande":79.24,
        "GSM8K":56.86,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aloobun\/slerp_bun_mistral_7b_v2",
        "Average":67.45,
        "ARC":65.61,
        "HellaSwag":85.28,
        "MMLU":64.61,
        "TruthfulQA":48.1,
        "Winogrande":80.82,
        "GSM8K":60.27,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ValiantLabs\/Fireplace-34b",
        "Average":67.44,
        "ARC":71.25,
        "HellaSwag":82.72,
        "MMLU":47.01,
        "TruthfulQA":65.11,
        "Winogrande":79.56,
        "GSM8K":58.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Hermes-2-Pro-Mistral-7B",
        "Average":67.43,
        "ARC":63.99,
        "HellaSwag":82.75,
        "MMLU":62.12,
        "TruthfulQA":59.01,
        "Winogrande":75.45,
        "GSM8K":61.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":368.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/Samantha-1.1-70b",
        "Average":67.43,
        "ARC":68.77,
        "HellaSwag":87.46,
        "MMLU":68.6,
        "TruthfulQA":64.85,
        "Winogrande":83.27,
        "GSM8K":31.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/UNA-dolphin-2.6-mistral-7b-dpo-laser",
        "Average":67.43,
        "ARC":67.15,
        "HellaSwag":86.31,
        "MMLU":63.36,
        "TruthfulQA":64.15,
        "Winogrande":79.24,
        "GSM8K":44.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"DenisTheDev\/Blitz-AI-MOE-v0.7",
        "Average":67.42,
        "ARC":67.15,
        "HellaSwag":85.59,
        "MMLU":64.04,
        "TruthfulQA":55.56,
        "Winogrande":79.08,
        "GSM8K":53.07,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_ThoughtsProcess_1",
        "Average":67.42,
        "ARC":65.27,
        "HellaSwag":85.69,
        "MMLU":61.9,
        "TruthfulQA":67.34,
        "Winogrande":77.66,
        "GSM8K":46.63,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AI-B\/UTENA-7B-V3",
        "Average":67.42,
        "ARC":65.96,
        "HellaSwag":85.7,
        "MMLU":64.72,
        "TruthfulQA":53.64,
        "Winogrande":80.27,
        "GSM8K":54.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"unlicense",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nextai-team\/Moe-2x7b-QA-Code",
        "Average":67.42,
        "ARC":65.19,
        "HellaSwag":85.36,
        "MMLU":61.71,
        "TruthfulQA":65.23,
        "Winogrande":77.35,
        "GSM8K":49.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/StableBeluga2",
        "Average":67.42,
        "ARC":71.08,
        "HellaSwag":86.37,
        "MMLU":68.79,
        "TruthfulQA":59.44,
        "Winogrande":82.95,
        "GSM8K":35.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":880.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Praneeth\/StarMix-7B-slerp",
        "Average":67.41,
        "ARC":65.36,
        "HellaSwag":85.1,
        "MMLU":62.57,
        "TruthfulQA":57.81,
        "Winogrande":79.95,
        "GSM8K":53.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beowolx\/CodeNinja-1.0-OpenChat-7B",
        "Average":67.4,
        "ARC":63.48,
        "HellaSwag":83.65,
        "MMLU":63.77,
        "TruthfulQA":47.16,
        "Winogrande":79.79,
        "GSM8K":66.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":99.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/test_42_70b",
        "Average":67.38,
        "ARC":68.26,
        "HellaSwag":87.65,
        "MMLU":70.0,
        "TruthfulQA":48.76,
        "Winogrande":83.66,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/ThetaWave-7B-v0.2",
        "Average":67.38,
        "ARC":64.51,
        "HellaSwag":85.0,
        "MMLU":61.01,
        "TruthfulQA":59.95,
        "Winogrande":82.32,
        "GSM8K":51.48,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GOAT-AI\/GOAT-70B-Storytelling",
        "Average":67.38,
        "ARC":68.77,
        "HellaSwag":87.74,
        "MMLU":69.92,
        "TruthfulQA":53.53,
        "Winogrande":83.5,
        "GSM8K":40.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upstage\/Llama-2-70b-instruct",
        "Average":67.38,
        "ARC":70.9,
        "HellaSwag":87.48,
        "MMLU":69.8,
        "TruthfulQA":60.97,
        "Winogrande":82.87,
        "GSM8K":32.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":70.0,
        "Model Sha":63.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"charlesdedampierre\/TopicNeuralHermes-2.5-Mistral-7B",
        "Average":67.36,
        "ARC":67.06,
        "HellaSwag":85.44,
        "MMLU":63.66,
        "TruthfulQA":55.47,
        "Winogrande":78.3,
        "GSM8K":54.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Hermes-2-Pro-Mistral-7B",
        "Average":67.35,
        "ARC":64.16,
        "HellaSwag":82.73,
        "MMLU":62.21,
        "TruthfulQA":58.99,
        "Winogrande":75.61,
        "GSM8K":60.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":368.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-v3.0-11B",
        "Average":67.35,
        "ARC":64.08,
        "HellaSwag":85.32,
        "MMLU":66.18,
        "TruthfulQA":48.22,
        "Winogrande":84.21,
        "GSM8K":56.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Isotonic\/Hermes-2-Pro-Mixtral-4x7B",
        "Average":67.35,
        "ARC":64.25,
        "HellaSwag":82.7,
        "MMLU":62.26,
        "TruthfulQA":59.02,
        "Winogrande":75.45,
        "GSM8K":60.42,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/openchat_3.5-gpt-4-80k",
        "Average":67.35,
        "ARC":63.31,
        "HellaSwag":81.21,
        "MMLU":64.33,
        "TruthfulQA":54.34,
        "Winogrande":76.48,
        "GSM8K":64.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Bucharest-0.1",
        "Average":67.35,
        "ARC":65.36,
        "HellaSwag":85.45,
        "MMLU":66.1,
        "TruthfulQA":47.94,
        "Winogrande":82.16,
        "GSM8K":57.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Hertz\/Mistral-Hermes-2x7b",
        "Average":67.33,
        "ARC":65.19,
        "HellaSwag":85.27,
        "MMLU":63.71,
        "TruthfulQA":51.2,
        "Winogrande":79.32,
        "GSM8K":59.29,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Fewshot-Metamath-OrcaVicuna-Mistral",
        "Average":67.33,
        "ARC":59.64,
        "HellaSwag":81.82,
        "MMLU":61.69,
        "TruthfulQA":53.23,
        "Winogrande":78.45,
        "GSM8K":69.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/ColorShadow-7B-v3",
        "Average":67.29,
        "ARC":67.58,
        "HellaSwag":85.04,
        "MMLU":60.57,
        "TruthfulQA":62.88,
        "Winogrande":80.11,
        "GSM8K":47.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/NeuralHermes-2.5-Mistral-7B-laser",
        "Average":67.29,
        "ARC":66.38,
        "HellaSwag":85.09,
        "MMLU":63.43,
        "TruthfulQA":54.95,
        "Winogrande":78.14,
        "GSM8K":55.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":16.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/WestSenzu-Swap-7B",
        "Average":67.28,
        "ARC":68.34,
        "HellaSwag":85.7,
        "MMLU":64.14,
        "TruthfulQA":50.43,
        "Winogrande":82.48,
        "GSM8K":52.62,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"diffnamehard\/Mistral-CatMacaroni-slerp-uncensored",
        "Average":67.28,
        "ARC":64.25,
        "HellaSwag":84.09,
        "MMLU":62.66,
        "TruthfulQA":56.87,
        "Winogrande":79.72,
        "GSM8K":56.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.6-mistral-7b-dpo-laser",
        "Average":67.28,
        "ARC":66.3,
        "HellaSwag":85.73,
        "MMLU":63.16,
        "TruthfulQA":61.71,
        "Winogrande":79.16,
        "GSM8K":47.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":112.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/Samantha-1.11-70b",
        "Average":67.28,
        "ARC":70.05,
        "HellaSwag":87.55,
        "MMLU":67.82,
        "TruthfulQA":65.02,
        "Winogrande":83.27,
        "GSM8K":29.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Lunar_10.7B",
        "Average":67.25,
        "ARC":65.87,
        "HellaSwag":84.85,
        "MMLU":64.23,
        "TruthfulQA":53.51,
        "Winogrande":81.37,
        "GSM8K":53.68,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Lunar_10.7B",
        "Average":67.25,
        "ARC":65.87,
        "HellaSwag":84.85,
        "MMLU":64.23,
        "TruthfulQA":53.51,
        "Winogrande":81.37,
        "GSM8K":53.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_4.0",
        "Average":67.25,
        "ARC":64.93,
        "HellaSwag":84.04,
        "MMLU":62.82,
        "TruthfulQA":60.4,
        "Winogrande":80.27,
        "GSM8K":51.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mahiatlinux\/ShadowDolph-7B-v1",
        "Average":67.25,
        "ARC":69.2,
        "HellaSwag":85.0,
        "MMLU":58.95,
        "TruthfulQA":64.56,
        "Winogrande":80.43,
        "GSM8K":45.34,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Ana-v1-m7",
        "Average":67.24,
        "ARC":67.41,
        "HellaSwag":85.98,
        "MMLU":64.43,
        "TruthfulQA":55.03,
        "Winogrande":78.06,
        "GSM8K":52.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-Beta-Sapphire-7B",
        "Average":67.24,
        "ARC":65.78,
        "HellaSwag":85.76,
        "MMLU":64.28,
        "TruthfulQA":51.28,
        "Winogrande":79.64,
        "GSM8K":56.71,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Test157t\/Kunocchini-7b-128k-test",
        "Average":67.24,
        "ARC":66.98,
        "HellaSwag":85.62,
        "MMLU":61.27,
        "TruthfulQA":59.35,
        "Winogrande":77.9,
        "GSM8K":52.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"louisbrulenaudet\/Pearl-3x7B",
        "Average":67.23,
        "ARC":65.53,
        "HellaSwag":85.54,
        "MMLU":64.27,
        "TruthfulQA":52.17,
        "Winogrande":78.69,
        "GSM8K":57.16,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-10.7B-v1.5b",
        "Average":67.21,
        "ARC":65.36,
        "HellaSwag":85.33,
        "MMLU":66.24,
        "TruthfulQA":47.38,
        "Winogrande":82.79,
        "GSM8K":56.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.7,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.5",
        "Average":67.21,
        "ARC":63.48,
        "HellaSwag":82.21,
        "MMLU":74.31,
        "TruthfulQA":54.64,
        "Winogrande":79.64,
        "GSM8K":48.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/rawr",
        "Average":67.21,
        "ARC":63.99,
        "HellaSwag":84.86,
        "MMLU":64.7,
        "TruthfulQA":52.07,
        "Winogrande":79.56,
        "GSM8K":58.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.6-mistral-7b-dpo",
        "Average":67.2,
        "ARC":65.61,
        "HellaSwag":85.48,
        "MMLU":63.24,
        "TruthfulQA":61.47,
        "Winogrande":78.61,
        "GSM8K":48.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":55.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/neural-chat-7b-v3-1-OpenHermes-2.5-7B",
        "Average":67.19,
        "ARC":66.13,
        "HellaSwag":84.09,
        "MMLU":63.22,
        "TruthfulQA":61.23,
        "Winogrande":77.58,
        "GSM8K":50.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/Hermes-low-tune",
        "Average":67.18,
        "ARC":63.99,
        "HellaSwag":83.75,
        "MMLU":63.6,
        "TruthfulQA":51.37,
        "Winogrande":77.9,
        "GSM8K":62.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ICBU-NPU\/FashionGPT-70B-V1.2",
        "Average":67.17,
        "ARC":73.04,
        "HellaSwag":88.15,
        "MMLU":70.11,
        "TruthfulQA":65.15,
        "Winogrande":82.56,
        "GSM8K":24.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-recovered",
        "Average":67.16,
        "ARC":65.27,
        "HellaSwag":84.62,
        "MMLU":63.82,
        "TruthfulQA":52.91,
        "Winogrande":78.06,
        "GSM8K":58.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/laser-dolphin-mixtral-2x7b-dpo",
        "Average":67.16,
        "ARC":65.96,
        "HellaSwag":85.8,
        "MMLU":63.17,
        "TruthfulQA":60.76,
        "Winogrande":79.01,
        "GSM8K":48.29,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":67.13,
        "ARC":63.82,
        "HellaSwag":84.9,
        "MMLU":64.67,
        "TruthfulQA":46.39,
        "Winogrande":80.58,
        "GSM8K":62.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":526.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/bagel-dpo-7b-v0.4",
        "Average":67.13,
        "ARC":67.58,
        "HellaSwag":84.3,
        "MMLU":61.95,
        "TruthfulQA":63.94,
        "Winogrande":78.14,
        "GSM8K":46.85,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lizpreciatior\/lzlv_70b_fp16_hf",
        "Average":67.13,
        "ARC":70.14,
        "HellaSwag":87.54,
        "MMLU":70.23,
        "TruthfulQA":60.49,
        "Winogrande":83.43,
        "GSM8K":30.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":68.98,
        "Model Sha":62.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_007_v2",
        "Average":67.13,
        "ARC":71.42,
        "HellaSwag":87.31,
        "MMLU":68.58,
        "TruthfulQA":62.65,
        "Winogrande":84.14,
        "GSM8K":28.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/MelangeB-70b",
        "Average":67.12,
        "ARC":71.67,
        "HellaSwag":87.5,
        "MMLU":70.03,
        "TruthfulQA":59.36,
        "Winogrande":83.5,
        "GSM8K":30.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Starling-LM-alpha-8x7B-MoE",
        "Average":67.11,
        "ARC":63.65,
        "HellaSwag":84.9,
        "MMLU":64.68,
        "TruthfulQA":46.39,
        "Winogrande":80.58,
        "GSM8K":62.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/smol-7b",
        "Average":67.11,
        "ARC":63.74,
        "HellaSwag":84.77,
        "MMLU":65.0,
        "TruthfulQA":46.17,
        "Winogrande":80.66,
        "GSM8K":62.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":22.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sophosympatheia\/Midnight-Rose-70B-v2.0.3",
        "Average":67.11,
        "ARC":70.65,
        "HellaSwag":87.5,
        "MMLU":69.64,
        "TruthfulQA":65.27,
        "Winogrande":81.22,
        "GSM8K":28.35,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decem\/Dionysus-Mistral-m3-v6",
        "Average":67.1,
        "ARC":63.14,
        "HellaSwag":84.51,
        "MMLU":62.82,
        "TruthfulQA":49.49,
        "Winogrande":78.45,
        "GSM8K":64.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nitral-AI\/Eris_PrimeV4.20-Vision-32k-7B",
        "Average":67.1,
        "ARC":64.93,
        "HellaSwag":84.8,
        "MMLU":63.71,
        "TruthfulQA":52.53,
        "Winogrande":79.48,
        "GSM8K":57.16,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ontocord\/Felix-8B",
        "Average":67.1,
        "ARC":65.02,
        "HellaSwag":84.61,
        "MMLU":61.05,
        "TruthfulQA":64.23,
        "Winogrande":75.93,
        "GSM8K":51.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/OpenHermes-2.5-Mistral-7B-mt-bench-DPO",
        "Average":67.1,
        "ARC":65.27,
        "HellaSwag":84.62,
        "MMLU":63.83,
        "TruthfulQA":52.91,
        "Winogrande":78.06,
        "GSM8K":57.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Starling-LM-7B-alpha-gpt-4-80k",
        "Average":67.1,
        "ARC":62.97,
        "HellaSwag":81.28,
        "MMLU":64.22,
        "TruthfulQA":54.35,
        "Winogrande":76.72,
        "GSM8K":63.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-corrupted",
        "Average":67.09,
        "ARC":65.27,
        "HellaSwag":84.58,
        "MMLU":63.74,
        "TruthfulQA":52.84,
        "Winogrande":78.06,
        "GSM8K":58.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"maldv\/winter-garden-7b-beta",
        "Average":67.09,
        "ARC":64.93,
        "HellaSwag":85.02,
        "MMLU":64.54,
        "TruthfulQA":50.82,
        "Winogrande":80.51,
        "GSM8K":56.71,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freecs\/ThetaWave-7B-v1",
        "Average":67.08,
        "ARC":66.89,
        "HellaSwag":84.91,
        "MMLU":61.62,
        "TruthfulQA":55.96,
        "Winogrande":80.43,
        "GSM8K":52.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_Instruct",
        "Average":67.07,
        "ARC":64.51,
        "HellaSwag":84.77,
        "MMLU":63.41,
        "TruthfulQA":61.9,
        "Winogrande":79.48,
        "GSM8K":48.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulilioaica\/Hugo-7B-slerp",
        "Average":67.07,
        "ARC":64.51,
        "HellaSwag":84.77,
        "MMLU":62.54,
        "TruthfulQA":57.13,
        "Winogrande":80.03,
        "GSM8K":53.45,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gqd\/mistral-merge-7b",
        "Average":67.07,
        "ARC":63.91,
        "HellaSwag":84.48,
        "MMLU":64.04,
        "TruthfulQA":53.73,
        "Winogrande":77.35,
        "GSM8K":58.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"unlicense",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_18-7B-dare_ties",
        "Average":67.06,
        "ARC":64.08,
        "HellaSwag":84.37,
        "MMLU":63.65,
        "TruthfulQA":52.17,
        "Winogrande":77.27,
        "GSM8K":60.8,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":67.05,
        "ARC":63.65,
        "HellaSwag":84.87,
        "MMLU":64.7,
        "TruthfulQA":46.32,
        "Winogrande":80.43,
        "GSM8K":62.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":526.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/Bageluccine-2-7B-slerp",
        "Average":67.05,
        "ARC":66.38,
        "HellaSwag":85.51,
        "MMLU":62.23,
        "TruthfulQA":65.57,
        "Winogrande":76.87,
        "GSM8K":45.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2",
        "Average":67.04,
        "ARC":65.19,
        "HellaSwag":83.39,
        "MMLU":63.6,
        "TruthfulQA":57.17,
        "Winogrande":78.14,
        "GSM8K":54.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":33.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
        "Average":67.03,
        "ARC":62.46,
        "HellaSwag":82.89,
        "MMLU":62.25,
        "TruthfulQA":50.15,
        "Winogrande":75.14,
        "GSM8K":69.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/franken-SOLAR-18B-v1.0",
        "Average":67.03,
        "ARC":65.53,
        "HellaSwag":86.45,
        "MMLU":63.72,
        "TruthfulQA":62.14,
        "Winogrande":78.53,
        "GSM8K":45.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":17.93,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"meta-math\/MetaMath-70B-V1.0",
        "Average":67.02,
        "ARC":68.0,
        "HellaSwag":86.85,
        "MMLU":69.31,
        "TruthfulQA":50.98,
        "Winogrande":82.32,
        "GSM8K":44.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_3.1_SFT",
        "Average":67.01,
        "ARC":61.86,
        "HellaSwag":81.32,
        "MMLU":64.51,
        "TruthfulQA":52.75,
        "Winogrande":80.19,
        "GSM8K":61.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-70B-v1.2b",
        "Average":67.0,
        "ARC":68.77,
        "HellaSwag":87.57,
        "MMLU":68.81,
        "TruthfulQA":57.69,
        "Winogrande":83.9,
        "GSM8K":35.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/Mixtral-SlimOrca-8x7B",
        "Average":66.97,
        "ARC":67.66,
        "HellaSwag":85.11,
        "MMLU":67.98,
        "TruthfulQA":54.98,
        "Winogrande":80.51,
        "GSM8K":45.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":50.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"chargoddard\/internlm2-7b-llama",
        "Average":66.94,
        "ARC":60.49,
        "HellaSwag":80.99,
        "MMLU":63.16,
        "TruthfulQA":54.25,
        "Winogrande":79.87,
        "GSM8K":62.85,
        "Type":"continuously pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.74,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/Misted-7B",
        "Average":66.94,
        "ARC":63.65,
        "HellaSwag":84.14,
        "MMLU":63.94,
        "TruthfulQA":52.0,
        "Winogrande":78.3,
        "GSM8K":59.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/neural-chat-7B-v3-2-GPTQ",
        "Average":66.93,
        "ARC":65.96,
        "HellaSwag":83.24,
        "MMLU":60.29,
        "TruthfulQA":59.79,
        "Winogrande":79.48,
        "GSM8K":52.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":9.59,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"maldv\/winter-garden-7b-alpha",
        "Average":66.91,
        "ARC":65.19,
        "HellaSwag":85.36,
        "MMLU":65.2,
        "TruthfulQA":50.94,
        "Winogrande":80.35,
        "GSM8K":54.44,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wolfeidau\/NeuralHermes-2.5-Mistral-7B",
        "Average":66.91,
        "ARC":68.26,
        "HellaSwag":85.46,
        "MMLU":63.31,
        "TruthfulQA":55.02,
        "Winogrande":78.37,
        "GSM8K":51.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"grimjim\/Mistral-Starling-merge-trial3-7B",
        "Average":66.9,
        "ARC":66.55,
        "HellaSwag":84.81,
        "MMLU":64.18,
        "TruthfulQA":52.85,
        "Winogrande":80.03,
        "GSM8K":52.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-70B-v1.2",
        "Average":66.9,
        "ARC":70.48,
        "HellaSwag":86.98,
        "MMLU":70.13,
        "TruthfulQA":58.64,
        "Winogrande":83.27,
        "GSM8K":31.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nlpguy\/ColorShadow-7B-v2",
        "Average":66.88,
        "ARC":67.15,
        "HellaSwag":84.69,
        "MMLU":60.34,
        "TruthfulQA":62.93,
        "Winogrande":78.85,
        "GSM8K":47.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"giraffe176\/Open_Hermes_Orca_Mistral-7B",
        "Average":66.87,
        "ARC":64.68,
        "HellaSwag":84.63,
        "MMLU":63.93,
        "TruthfulQA":53.34,
        "Winogrande":78.45,
        "GSM8K":56.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Liberated-Qwen1.5-14B",
        "Average":66.86,
        "ARC":57.94,
        "HellaSwag":80.65,
        "MMLU":68.83,
        "TruthfulQA":52.48,
        "Winogrande":74.74,
        "GSM8K":66.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/SystemHermes-7B",
        "Average":66.86,
        "ARC":64.76,
        "HellaSwag":83.68,
        "MMLU":63.23,
        "TruthfulQA":52.81,
        "Winogrande":77.82,
        "GSM8K":58.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Cartinoe5930\/MoE-Merging",
        "Average":66.84,
        "ARC":65.44,
        "HellaSwag":84.58,
        "MMLU":61.31,
        "TruthfulQA":57.83,
        "Winogrande":77.66,
        "GSM8K":54.21,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"macadeliccc\/polyglot-math-4x7b",
        "Average":66.84,
        "ARC":63.74,
        "HellaSwag":84.85,
        "MMLU":63.57,
        "TruthfulQA":53.78,
        "Winogrande":78.45,
        "GSM8K":56.63,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/DPOpenHermes-11B",
        "Average":66.83,
        "ARC":66.55,
        "HellaSwag":84.8,
        "MMLU":64.02,
        "TruthfulQA":57.34,
        "Winogrande":76.95,
        "GSM8K":51.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/YarnLake-Swap-7B",
        "Average":66.82,
        "ARC":65.27,
        "HellaSwag":85.17,
        "MMLU":64.78,
        "TruthfulQA":49.07,
        "Winogrande":81.45,
        "GSM8K":55.19,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-70B-v1.1",
        "Average":66.81,
        "ARC":70.05,
        "HellaSwag":87.12,
        "MMLU":70.34,
        "TruthfulQA":57.84,
        "Winogrande":83.66,
        "GSM8K":31.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Bucharest-0.2",
        "Average":66.81,
        "ARC":64.59,
        "HellaSwag":84.87,
        "MMLU":66.03,
        "TruthfulQA":45.3,
        "Winogrande":83.27,
        "GSM8K":56.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Frostwind-10.7B-v1",
        "Average":66.81,
        "ARC":63.99,
        "HellaSwag":85.36,
        "MMLU":64.49,
        "TruthfulQA":50.41,
        "Winogrande":83.82,
        "GSM8K":52.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.7,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/SpydazWeb_AI_BASE_128k",
        "Average":66.79,
        "ARC":65.19,
        "HellaSwag":84.62,
        "MMLU":63.81,
        "TruthfulQA":57.82,
        "Winogrande":79.24,
        "GSM8K":50.04,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dillfrescott\/sonya-medium-x8-MoE",
        "Average":66.76,
        "ARC":64.25,
        "HellaSwag":83.7,
        "MMLU":62.53,
        "TruthfulQA":60.15,
        "Winogrande":76.24,
        "GSM8K":53.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":69.92,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Frostwind-10.7B-v1",
        "Average":66.75,
        "ARC":64.16,
        "HellaSwag":85.38,
        "MMLU":64.64,
        "TruthfulQA":50.43,
        "Winogrande":83.74,
        "GSM8K":52.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.7,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v4-qwen1_5-14b",
        "Average":66.74,
        "ARC":57.34,
        "HellaSwag":79.84,
        "MMLU":67.92,
        "TruthfulQA":55.21,
        "Winogrande":73.64,
        "GSM8K":66.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.17,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-70B",
        "Average":66.72,
        "ARC":69.45,
        "HellaSwag":87.11,
        "MMLU":68.91,
        "TruthfulQA":59.79,
        "Winogrande":83.66,
        "GSM8K":31.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/laser-dolphin-mixtral-4x7b-dpo",
        "Average":66.71,
        "ARC":64.93,
        "HellaSwag":85.81,
        "MMLU":63.04,
        "TruthfulQA":63.77,
        "Winogrande":77.82,
        "GSM8K":44.88,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nextai-team\/Moe-3x7b-QA-Code-Inst",
        "Average":66.7,
        "ARC":64.25,
        "HellaSwag":84.6,
        "MMLU":62.15,
        "TruthfulQA":63.15,
        "Winogrande":77.43,
        "GSM8K":48.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-14B",
        "Average":66.7,
        "ARC":56.57,
        "HellaSwag":81.08,
        "MMLU":69.36,
        "TruthfulQA":52.06,
        "Winogrande":73.48,
        "GSM8K":67.63,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen2-beta-14B",
        "Average":66.7,
        "ARC":56.57,
        "HellaSwag":81.08,
        "MMLU":69.36,
        "TruthfulQA":52.06,
        "Winogrande":73.48,
        "GSM8K":67.63,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-Platypus-Mistral7B",
        "Average":66.69,
        "ARC":63.14,
        "HellaSwag":84.41,
        "MMLU":60.71,
        "TruthfulQA":51.85,
        "Winogrande":81.29,
        "GSM8K":58.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Liberated-Qwen1.5-14B",
        "Average":66.69,
        "ARC":57.94,
        "HellaSwag":80.56,
        "MMLU":68.81,
        "TruthfulQA":52.37,
        "Winogrande":74.59,
        "GSM8K":65.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"HIT-SCIR\/Chinese-Mixtral-8x7B",
        "Average":66.69,
        "ARC":63.57,
        "HellaSwag":85.98,
        "MMLU":70.95,
        "TruthfulQA":45.86,
        "Winogrande":82.08,
        "GSM8K":51.71,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.91,
        "Model Sha":42.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rombodawg\/EveryoneLLM-7b-Gemma-Base",
        "Average":66.69,
        "ARC":64.33,
        "HellaSwag":81.98,
        "MMLU":62.95,
        "TruthfulQA":50.38,
        "Winogrande":76.87,
        "GSM8K":63.61,
        "Type":"base merges and moerges",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"internlm\/internlm2-7b",
        "Average":66.68,
        "ARC":58.02,
        "HellaSwag":81.24,
        "MMLU":65.24,
        "TruthfulQA":48.73,
        "Winogrande":83.82,
        "GSM8K":63.0,
        "Type":"continuously pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yanolja\/Bookworm-10.7B-v0.4-DPO",
        "Average":66.66,
        "ARC":64.68,
        "HellaSwag":84.43,
        "MMLU":65.12,
        "TruthfulQA":52.38,
        "Winogrande":81.14,
        "GSM8K":52.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Isaak-Carter\/JOSIE_Beta-3-7B-slerp",
        "Average":66.66,
        "ARC":63.4,
        "HellaSwag":84.56,
        "MMLU":64.17,
        "TruthfulQA":48.8,
        "Winogrande":80.43,
        "GSM8K":58.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Hex-Macaroniac-7b",
        "Average":66.64,
        "ARC":65.53,
        "HellaSwag":84.68,
        "MMLU":62.43,
        "TruthfulQA":55.93,
        "Winogrande":78.3,
        "GSM8K":52.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-10.7b",
        "Average":66.63,
        "ARC":64.16,
        "HellaSwag":83.6,
        "MMLU":65.22,
        "TruthfulQA":46.59,
        "Winogrande":82.0,
        "GSM8K":58.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Badgids\/Gonzo-Chat-7B",
        "Average":66.63,
        "ARC":65.02,
        "HellaSwag":85.4,
        "MMLU":63.75,
        "TruthfulQA":60.23,
        "Winogrande":77.74,
        "GSM8K":47.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-LASER-0.6",
        "Average":66.62,
        "ARC":62.46,
        "HellaSwag":81.6,
        "MMLU":74.25,
        "TruthfulQA":54.39,
        "Winogrande":78.45,
        "GSM8K":48.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Einstein-v4-7B",
        "Average":66.62,
        "ARC":64.68,
        "HellaSwag":83.75,
        "MMLU":62.31,
        "TruthfulQA":55.15,
        "Winogrande":76.24,
        "GSM8K":57.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/NeuralHermes-2.5-Mistral-7B",
        "Average":66.62,
        "ARC":64.68,
        "HellaSwag":84.28,
        "MMLU":63.71,
        "TruthfulQA":52.23,
        "Winogrande":77.98,
        "GSM8K":56.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uni-tianyan\/Uni-TianYan",
        "Average":66.61,
        "ARC":72.1,
        "HellaSwag":87.4,
        "MMLU":69.91,
        "TruthfulQA":65.81,
        "Winogrande":82.32,
        "GSM8K":22.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":48.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardMath-7B-V1.1",
        "Average":66.61,
        "ARC":61.86,
        "HellaSwag":84.5,
        "MMLU":61.53,
        "TruthfulQA":47.04,
        "Winogrande":77.35,
        "GSM8K":67.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yanolja\/Bookworm-10.7B-v0.4-DPO",
        "Average":66.59,
        "ARC":64.76,
        "HellaSwag":84.4,
        "MMLU":64.96,
        "TruthfulQA":52.31,
        "Winogrande":80.9,
        "GSM8K":52.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Ba2han\/HermesStar-OrcaWind-Synth-11B",
        "Average":66.59,
        "ARC":65.27,
        "HellaSwag":83.69,
        "MMLU":65.31,
        "TruthfulQA":48.55,
        "Winogrande":80.11,
        "GSM8K":56.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decapoda-research\/Adrastea-7b-v1.0-dpo",
        "Average":66.59,
        "ARC":63.31,
        "HellaSwag":82.3,
        "MMLU":62.26,
        "TruthfulQA":53.1,
        "Winogrande":76.56,
        "GSM8K":62.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yhyu13\/LMCocktail-Mistral-7B-v1",
        "Average":66.58,
        "ARC":66.21,
        "HellaSwag":85.69,
        "MMLU":61.64,
        "TruthfulQA":61.37,
        "Winogrande":77.35,
        "GSM8K":47.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nlpguy\/StockFuseChat",
        "Average":66.58,
        "ARC":63.14,
        "HellaSwag":84.26,
        "MMLU":63.95,
        "TruthfulQA":45.57,
        "Winogrande":79.48,
        "GSM8K":63.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_AI_128k_bioMedical",
        "Average":66.58,
        "ARC":64.51,
        "HellaSwag":84.99,
        "MMLU":63.66,
        "TruthfulQA":58.69,
        "Winogrande":79.56,
        "GSM8K":48.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/NeuralPaca-7b",
        "Average":66.57,
        "ARC":62.8,
        "HellaSwag":83.01,
        "MMLU":63.02,
        "TruthfulQA":48.32,
        "Winogrande":81.69,
        "GSM8K":60.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NExtNewChattingAI\/shark_tank_ai_7b_v2",
        "Average":66.55,
        "ARC":67.75,
        "HellaSwag":87.06,
        "MMLU":58.79,
        "TruthfulQA":62.15,
        "Winogrande":78.45,
        "GSM8K":45.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"922CA\/Silicon-Monika-7b",
        "Average":66.55,
        "ARC":63.14,
        "HellaSwag":82.64,
        "MMLU":62.67,
        "TruthfulQA":52.14,
        "Winogrande":78.22,
        "GSM8K":60.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-10.7B-v1.5",
        "Average":66.55,
        "ARC":65.02,
        "HellaSwag":84.07,
        "MMLU":65.09,
        "TruthfulQA":47.43,
        "Winogrande":83.35,
        "GSM8K":54.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mahiatlinux\/MasherAI-v6-7B",
        "Average":66.55,
        "ARC":62.88,
        "HellaSwag":83.94,
        "MMLU":60.56,
        "TruthfulQA":62.56,
        "Winogrande":77.43,
        "GSM8K":51.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Locutusque\/OpenHercules-2.5-Mistral-7B",
        "Average":66.55,
        "ARC":64.25,
        "HellaSwag":84.84,
        "MMLU":64.21,
        "TruthfulQA":47.84,
        "Winogrande":78.93,
        "GSM8K":59.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NExtNewChattingAI\/shark_tank_ai_7b_v2",
        "Average":66.54,
        "ARC":67.58,
        "HellaSwag":87.02,
        "MMLU":58.88,
        "TruthfulQA":62.21,
        "Winogrande":78.69,
        "GSM8K":44.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"shahzebnaveed\/NeuralHermes-2.5-Mistral-7B",
        "Average":66.53,
        "ARC":64.85,
        "HellaSwag":84.29,
        "MMLU":63.81,
        "TruthfulQA":52.29,
        "Winogrande":77.98,
        "GSM8K":55.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Mocha-Sample-7b-ex",
        "Average":66.53,
        "ARC":64.76,
        "HellaSwag":84.35,
        "MMLU":62.2,
        "TruthfulQA":54.18,
        "Winogrande":77.11,
        "GSM8K":56.56,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FuseAI\/FuseChat-7B-VaRM",
        "Average":66.52,
        "ARC":62.88,
        "HellaSwag":84.25,
        "MMLU":63.71,
        "TruthfulQA":45.67,
        "Winogrande":79.16,
        "GSM8K":63.46,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":64.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/dpopenhermes-alpha-v0",
        "Average":66.52,
        "ARC":65.02,
        "HellaSwag":83.96,
        "MMLU":63.67,
        "TruthfulQA":51.75,
        "Winogrande":78.85,
        "GSM8K":55.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Eurdem\/Voltran-1.0-MoE-2x7B",
        "Average":66.51,
        "ARC":64.08,
        "HellaSwag":83.74,
        "MMLU":61.26,
        "TruthfulQA":57.48,
        "Winogrande":76.56,
        "GSM8K":55.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"soniox\/Soniox-7B-v1.0",
        "Average":66.5,
        "ARC":63.91,
        "HellaSwag":82.55,
        "MMLU":64.38,
        "TruthfulQA":53.84,
        "Winogrande":78.06,
        "GSM8K":56.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kevin009\/Llamafia",
        "Average":66.49,
        "ARC":66.13,
        "HellaSwag":82.08,
        "MMLU":61.81,
        "TruthfulQA":47.94,
        "Winogrande":80.11,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yanolja\/EEVE-Korean-Instruct-10.8B-v1.0",
        "Average":66.48,
        "ARC":64.85,
        "HellaSwag":83.04,
        "MMLU":64.23,
        "TruthfulQA":54.09,
        "Winogrande":81.93,
        "GSM8K":50.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-original-v2",
        "Average":66.47,
        "ARC":64.93,
        "HellaSwag":84.54,
        "MMLU":63.63,
        "TruthfulQA":52.4,
        "Winogrande":77.9,
        "GSM8K":55.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rombodawg\/Leaderboard-killer-MoE_4x7b",
        "Average":66.47,
        "ARC":63.65,
        "HellaSwag":81.97,
        "MMLU":64.9,
        "TruthfulQA":50.75,
        "Winogrande":75.37,
        "GSM8K":62.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Undi95\/C-Based-2x7B",
        "Average":66.47,
        "ARC":65.53,
        "HellaSwag":85.0,
        "MMLU":64.59,
        "TruthfulQA":50.16,
        "Winogrande":81.06,
        "GSM8K":52.46,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"v2ray\/LLaMA-2-Wizard-70B-QLoRA",
        "Average":66.47,
        "ARC":67.58,
        "HellaSwag":87.52,
        "MMLU":69.11,
        "TruthfulQA":61.79,
        "Winogrande":82.32,
        "GSM8K":30.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FuseAI\/OpenChat-3.5-7B-Solar",
        "Average":66.46,
        "ARC":62.97,
        "HellaSwag":84.19,
        "MMLU":63.94,
        "TruthfulQA":45.65,
        "Winogrande":79.48,
        "GSM8K":62.55,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/uncensored",
        "Average":66.46,
        "ARC":66.04,
        "HellaSwag":84.8,
        "MMLU":61.23,
        "TruthfulQA":59.14,
        "Winogrande":79.32,
        "GSM8K":48.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/A13",
        "Average":66.45,
        "ARC":61.09,
        "HellaSwag":81.7,
        "MMLU":69.62,
        "TruthfulQA":53.25,
        "Winogrande":80.35,
        "GSM8K":52.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"simonveitner\/Math-OpenHermes-2.5-Mistral-7B",
        "Average":66.42,
        "ARC":63.05,
        "HellaSwag":83.07,
        "MMLU":63.21,
        "TruthfulQA":50.91,
        "Winogrande":77.19,
        "GSM8K":61.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Yuma42\/KangalKhan-Beta-Ruby-7B",
        "Average":66.42,
        "ARC":64.51,
        "HellaSwag":85.57,
        "MMLU":64.2,
        "TruthfulQA":51.04,
        "Winogrande":79.16,
        "GSM8K":54.06,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Brillibits\/Instruct_Llama70B_Dolly15k",
        "Average":66.42,
        "ARC":68.34,
        "HellaSwag":87.21,
        "MMLU":69.52,
        "TruthfulQA":46.46,
        "Winogrande":84.29,
        "GSM8K":42.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maywell\/PiVoT-SOLAR-10.7B-RP",
        "Average":66.42,
        "ARC":65.1,
        "HellaSwag":81.83,
        "MMLU":64.26,
        "TruthfulQA":56.54,
        "Winogrande":76.95,
        "GSM8K":53.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":10.7,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yash21\/OpenMistral-MoE",
        "Average":66.42,
        "ARC":64.08,
        "HellaSwag":83.99,
        "MMLU":60.69,
        "TruthfulQA":54.57,
        "Winogrande":76.8,
        "GSM8K":58.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rxavier\/Taurus-7B-1.0",
        "Average":66.4,
        "ARC":63.57,
        "HellaSwag":83.64,
        "MMLU":63.5,
        "TruthfulQA":50.21,
        "Winogrande":78.14,
        "GSM8K":59.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rxavier\/Taurus-1.0-Mistral-7B",
        "Average":66.4,
        "ARC":63.57,
        "HellaSwag":83.64,
        "MMLU":63.5,
        "TruthfulQA":50.21,
        "Winogrande":78.14,
        "GSM8K":59.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FuseAI\/OpenChat-3.5-7B-Mixtral",
        "Average":66.4,
        "ARC":62.8,
        "HellaSwag":84.24,
        "MMLU":63.95,
        "TruthfulQA":45.68,
        "Winogrande":79.64,
        "GSM8K":62.09,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openaccess-ai-collective\/openhermes-2_5-dpo-no-robots",
        "Average":66.4,
        "ARC":64.93,
        "HellaSwag":84.3,
        "MMLU":63.86,
        "TruthfulQA":52.12,
        "Winogrande":77.9,
        "GSM8K":55.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FuseAI\/FuseChat-7B-Slerp",
        "Average":66.39,
        "ARC":62.63,
        "HellaSwag":84.17,
        "MMLU":63.9,
        "TruthfulQA":45.62,
        "Winogrande":79.48,
        "GSM8K":62.55,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cris177\/Orca-Hermes-7B-slerp",
        "Average":66.39,
        "ARC":64.08,
        "HellaSwag":84.44,
        "MMLU":63.56,
        "TruthfulQA":52.84,
        "Winogrande":77.9,
        "GSM8K":55.5,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"freeCS-dot-org\/OpenAGI-testing-intelDPO-2",
        "Average":66.36,
        "ARC":62.8,
        "HellaSwag":84.63,
        "MMLU":62.65,
        "TruthfulQA":58.28,
        "Winogrande":78.85,
        "GSM8K":50.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulilioaica\/MoEstral-2x2B",
        "Average":66.34,
        "ARC":65.1,
        "HellaSwag":84.82,
        "MMLU":61.62,
        "TruthfulQA":62.72,
        "Winogrande":78.37,
        "GSM8K":45.41,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-privatemix-base-ia",
        "Average":66.34,
        "ARC":62.8,
        "HellaSwag":84.85,
        "MMLU":60.54,
        "TruthfulQA":68.76,
        "Winogrande":77.03,
        "GSM8K":44.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/mixtral_8x7b_MonsterInstruct",
        "Average":66.34,
        "ARC":65.19,
        "HellaSwag":85.81,
        "MMLU":70.15,
        "TruthfulQA":48.47,
        "Winogrande":80.27,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cstr\/Spaetzle-v44-7b",
        "Average":66.34,
        "ARC":64.59,
        "HellaSwag":84.76,
        "MMLU":61.76,
        "TruthfulQA":54.45,
        "Winogrande":78.77,
        "GSM8K":53.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/CodeCalc-Mistral-7B",
        "Average":66.33,
        "ARC":61.95,
        "HellaSwag":83.64,
        "MMLU":62.78,
        "TruthfulQA":47.79,
        "Winogrande":78.3,
        "GSM8K":63.53,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"hydra-project\/OpenHyperion-2.5-Mistral-7B",
        "Average":66.32,
        "ARC":64.25,
        "HellaSwag":84.86,
        "MMLU":63.86,
        "TruthfulQA":49.92,
        "Winogrande":79.32,
        "GSM8K":55.72,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"snorkelai\/Snorkel-Mistral-PairRM-DPO",
        "Average":66.31,
        "ARC":66.04,
        "HellaSwag":85.64,
        "MMLU":60.83,
        "TruthfulQA":70.86,
        "Winogrande":77.74,
        "GSM8K":36.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":96.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel-70",
        "Average":66.31,
        "ARC":68.34,
        "HellaSwag":87.87,
        "MMLU":70.18,
        "TruthfulQA":57.47,
        "Winogrande":84.29,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel-70v1",
        "Average":66.31,
        "ARC":68.34,
        "HellaSwag":87.87,
        "MMLU":70.18,
        "TruthfulQA":57.47,
        "Winogrande":84.29,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel-70x",
        "Average":66.31,
        "ARC":68.34,
        "HellaSwag":87.87,
        "MMLU":70.18,
        "TruthfulQA":57.47,
        "Winogrande":84.29,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel70",
        "Average":66.31,
        "ARC":68.34,
        "HellaSwag":87.87,
        "MMLU":70.18,
        "TruthfulQA":57.47,
        "Winogrande":84.29,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel-70-x",
        "Average":66.31,
        "ARC":68.34,
        "HellaSwag":87.87,
        "MMLU":70.18,
        "TruthfulQA":57.47,
        "Winogrande":84.29,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FuseAI\/FuseChat-7B-TA",
        "Average":66.31,
        "ARC":62.54,
        "HellaSwag":84.22,
        "MMLU":63.96,
        "TruthfulQA":45.74,
        "Winogrande":79.4,
        "GSM8K":62.02,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Platypus2-70B",
        "Average":66.28,
        "ARC":70.65,
        "HellaSwag":87.15,
        "MMLU":70.08,
        "TruthfulQA":52.37,
        "Winogrande":84.37,
        "GSM8K":33.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":68.98,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Doctor-Shotgun\/mythospice-limarp-70b",
        "Average":66.27,
        "ARC":69.2,
        "HellaSwag":87.46,
        "MMLU":70.14,
        "TruthfulQA":55.86,
        "Winogrande":82.72,
        "GSM8K":32.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"agpl-3.0",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/Worldsim-Hermes-7B",
        "Average":66.26,
        "ARC":64.08,
        "HellaSwag":83.45,
        "MMLU":63.12,
        "TruthfulQA":51.52,
        "Winogrande":78.77,
        "GSM8K":56.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/megamarcoroni-120b",
        "Average":66.25,
        "ARC":72.01,
        "HellaSwag":88.94,
        "MMLU":69.88,
        "TruthfulQA":64.24,
        "Winogrande":80.9,
        "GSM8K":21.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":120.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/Marcoroni-neural-chat-7B-v2_gsm8k_quantized_mergedfloat_s",
        "Average":66.24,
        "ARC":64.08,
        "HellaSwag":84.12,
        "MMLU":61.14,
        "TruthfulQA":54.77,
        "Winogrande":76.95,
        "GSM8K":56.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/Hercules-Qwen1.5-14B",
        "Average":66.24,
        "ARC":56.23,
        "HellaSwag":80.6,
        "MMLU":68.73,
        "TruthfulQA":52.03,
        "Winogrande":73.88,
        "GSM8K":65.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xwin-LM\/Xwin-LM-70B-V0.1",
        "Average":66.2,
        "ARC":70.22,
        "HellaSwag":87.25,
        "MMLU":69.77,
        "TruthfulQA":59.86,
        "Winogrande":82.87,
        "GSM8K":27.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":209.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Test-Raw-Solar-v1",
        "Average":66.2,
        "ARC":63.23,
        "HellaSwag":84.82,
        "MMLU":65.52,
        "TruthfulQA":48.99,
        "Winogrande":84.06,
        "GSM8K":50.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"snorkelai\/Snorkel-Mistral-PairRM-DPO",
        "Average":66.18,
        "ARC":65.96,
        "HellaSwag":85.63,
        "MMLU":60.85,
        "TruthfulQA":70.91,
        "Winogrande":77.58,
        "GSM8K":36.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":96.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Doctor-Shotgun\/mythospice-70b",
        "Average":66.17,
        "ARC":69.28,
        "HellaSwag":87.53,
        "MMLU":70.1,
        "TruthfulQA":56.76,
        "Winogrande":83.27,
        "GSM8K":30.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beowolx\/MistralHermes-CodePro-7B-v1",
        "Average":66.17,
        "ARC":62.46,
        "HellaSwag":82.68,
        "MMLU":63.44,
        "TruthfulQA":49.67,
        "Winogrande":77.9,
        "GSM8K":60.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/llama-2-70b-fb16-orca-chat-10k",
        "Average":66.16,
        "ARC":68.09,
        "HellaSwag":87.07,
        "MMLU":69.21,
        "TruthfulQA":61.56,
        "Winogrande":84.14,
        "GSM8K":26.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Luminex-72B-v0.1",
        "Average":66.15,
        "ARC":43.43,
        "HellaSwag":86.66,
        "MMLU":73.36,
        "TruthfulQA":41.85,
        "Winogrande":76.16,
        "GSM8K":75.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e1",
        "Average":66.15,
        "ARC":62.71,
        "HellaSwag":85.3,
        "MMLU":60.6,
        "TruthfulQA":70.76,
        "Winogrande":77.11,
        "GSM8K":40.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/mistral-11b-slimorca",
        "Average":66.12,
        "ARC":64.25,
        "HellaSwag":83.81,
        "MMLU":63.66,
        "TruthfulQA":54.66,
        "Winogrande":77.98,
        "GSM8K":52.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_AI_base_128k",
        "Average":66.08,
        "ARC":65.1,
        "HellaSwag":84.05,
        "MMLU":63.36,
        "TruthfulQA":58.11,
        "Winogrande":79.24,
        "GSM8K":46.63,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eurdem\/megatron_v4_4x7B",
        "Average":66.08,
        "ARC":65.61,
        "HellaSwag":84.1,
        "MMLU":61.64,
        "TruthfulQA":60.51,
        "Winogrande":76.56,
        "GSM8K":48.07,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"amazingvince\/where-llambo-7b",
        "Average":66.08,
        "ARC":58.45,
        "HellaSwag":82.06,
        "MMLU":62.61,
        "TruthfulQA":49.61,
        "Winogrande":78.53,
        "GSM8K":65.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_13-7B-slerp",
        "Average":66.06,
        "ARC":63.82,
        "HellaSwag":84.95,
        "MMLU":64.9,
        "TruthfulQA":48.62,
        "Winogrande":79.87,
        "GSM8K":54.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/NeuralHermes-2.5-Mistral-7B",
        "Average":66.06,
        "ARC":67.58,
        "HellaSwag":85.69,
        "MMLU":63.43,
        "TruthfulQA":55.98,
        "Winogrande":77.98,
        "GSM8K":45.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-dpo-e3",
        "Average":66.06,
        "ARC":62.63,
        "HellaSwag":85.31,
        "MMLU":60.76,
        "TruthfulQA":70.59,
        "Winogrande":77.35,
        "GSM8K":39.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/llama-2-70b-Guanaco-QLoRA-fp16",
        "Average":66.05,
        "ARC":68.26,
        "HellaSwag":88.32,
        "MMLU":70.23,
        "TruthfulQA":55.69,
        "Winogrande":83.98,
        "GSM8K":29.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":70.0,
        "Model Sha":54.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_Uncensored",
        "Average":66.04,
        "ARC":63.82,
        "HellaSwag":84.07,
        "MMLU":61.96,
        "TruthfulQA":65.86,
        "Winogrande":78.69,
        "GSM8K":41.85,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seungduk\/KoSOLAR-10.7B-v0.1",
        "Average":66.04,
        "ARC":62.03,
        "HellaSwag":84.54,
        "MMLU":65.56,
        "TruthfulQA":45.03,
        "Winogrande":83.58,
        "GSM8K":55.5,
        "Type":"base merges and moerges",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Average":66.04,
        "ARC":61.95,
        "HellaSwag":84.6,
        "MMLU":65.48,
        "TruthfulQA":45.04,
        "Winogrande":83.66,
        "GSM8K":55.5,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":216.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"KatyTheCutie\/LemonadeRP-4.5.3",
        "Average":66.02,
        "ARC":65.1,
        "HellaSwag":84.72,
        "MMLU":64.39,
        "TruthfulQA":57.87,
        "Winogrande":77.74,
        "GSM8K":46.32,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Paradigm_Shift_7B",
        "Average":66.02,
        "ARC":67.92,
        "HellaSwag":83.69,
        "MMLU":59.49,
        "TruthfulQA":66.07,
        "Winogrande":78.69,
        "GSM8K":40.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TokenBender\/pic_7B_mistral_Full_v0.1",
        "Average":66.0,
        "ARC":63.91,
        "HellaSwag":83.7,
        "MMLU":63.3,
        "TruthfulQA":54.51,
        "Winogrande":77.9,
        "GSM8K":52.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s1ghhh\/medllama-2-70b-qlora-1.1",
        "Average":65.99,
        "ARC":69.03,
        "HellaSwag":87.17,
        "MMLU":71.04,
        "TruthfulQA":52.41,
        "Winogrande":84.21,
        "GSM8K":32.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0-hero\/Matter-0.1-7B-boost-DPO",
        "Average":65.99,
        "ARC":65.02,
        "HellaSwag":83.08,
        "MMLU":61.87,
        "TruthfulQA":60.29,
        "Winogrande":75.61,
        "GSM8K":50.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-dpo-e1",
        "Average":65.98,
        "ARC":62.46,
        "HellaSwag":85.23,
        "MMLU":60.67,
        "TruthfulQA":70.56,
        "Winogrande":76.95,
        "GSM8K":40.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/longcat-10.7B",
        "Average":65.98,
        "ARC":64.59,
        "HellaSwag":85.85,
        "MMLU":61.77,
        "TruthfulQA":61.42,
        "Winogrande":76.16,
        "GSM8K":46.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-72B-Chat",
        "Average":65.98,
        "ARC":68.26,
        "HellaSwag":86.47,
        "MMLU":77.46,
        "TruthfulQA":63.84,
        "Winogrande":78.93,
        "GSM8K":20.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":172.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nbeerbower\/Flammen-Trismegistus-7B",
        "Average":65.98,
        "ARC":63.99,
        "HellaSwag":84.79,
        "MMLU":62.45,
        "TruthfulQA":57.12,
        "Winogrande":76.48,
        "GSM8K":51.02,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/Bageluccine-7B-slerp",
        "Average":65.97,
        "ARC":65.1,
        "HellaSwag":85.06,
        "MMLU":61.75,
        "TruthfulQA":60.33,
        "Winogrande":77.35,
        "GSM8K":46.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nisten\/shqiponja-59b-v1",
        "Average":65.97,
        "ARC":70.05,
        "HellaSwag":84.06,
        "MMLU":75.54,
        "TruthfulQA":70.43,
        "Winogrande":80.27,
        "GSM8K":15.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":58.94,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e3",
        "Average":65.97,
        "ARC":62.54,
        "HellaSwag":85.34,
        "MMLU":60.54,
        "TruthfulQA":70.69,
        "Winogrande":77.35,
        "GSM8K":39.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-dpo-e2",
        "Average":65.97,
        "ARC":62.54,
        "HellaSwag":85.3,
        "MMLU":60.71,
        "TruthfulQA":70.54,
        "Winogrande":77.66,
        "GSM8K":39.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_51",
        "Average":65.96,
        "ARC":68.43,
        "HellaSwag":86.71,
        "MMLU":69.31,
        "TruthfulQA":57.18,
        "Winogrande":81.77,
        "GSM8K":32.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-72B-Chat",
        "Average":65.96,
        "ARC":68.52,
        "HellaSwag":86.42,
        "MMLU":77.44,
        "TruthfulQA":63.9,
        "Winogrande":79.08,
        "GSM8K":20.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":172.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dddsaty\/SOLAR_Merge_Adapter_DPO_Orca",
        "Average":65.96,
        "ARC":63.91,
        "HellaSwag":84.58,
        "MMLU":63.18,
        "TruthfulQA":51.49,
        "Winogrande":82.0,
        "GSM8K":50.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e2",
        "Average":65.95,
        "ARC":62.46,
        "HellaSwag":85.31,
        "MMLU":60.56,
        "TruthfulQA":70.77,
        "Winogrande":77.19,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_passthrough",
        "Average":65.94,
        "ARC":69.45,
        "HellaSwag":87.72,
        "MMLU":65.28,
        "TruthfulQA":67.65,
        "Winogrande":81.29,
        "GSM8K":24.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":21.2,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Zephyr_beta_32k_7B",
        "Average":65.93,
        "ARC":63.48,
        "HellaSwag":84.79,
        "MMLU":60.5,
        "TruthfulQA":68.99,
        "Winogrande":77.11,
        "GSM8K":40.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"liminerity\/Blured-Ties-7B",
        "Average":65.92,
        "ARC":63.99,
        "HellaSwag":83.56,
        "MMLU":63.19,
        "TruthfulQA":58.12,
        "Winogrande":79.72,
        "GSM8K":46.93,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/14B-DPO-alpha",
        "Average":65.91,
        "ARC":58.11,
        "HellaSwag":79.38,
        "MMLU":66.62,
        "TruthfulQA":54.15,
        "Winogrande":74.51,
        "GSM8K":62.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":14.0,
        "Model Sha":105.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yunconglong\/Mixtral_7Bx2_MoE_13B_DPO",
        "Average":65.89,
        "ARC":65.44,
        "HellaSwag":84.01,
        "MMLU":62.14,
        "TruthfulQA":61.76,
        "Winogrande":78.45,
        "GSM8K":43.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Mixtral-4x7B-DPO-RPChat",
        "Average":65.88,
        "ARC":64.59,
        "HellaSwag":85.36,
        "MMLU":63.57,
        "TruthfulQA":49.87,
        "Winogrande":78.77,
        "GSM8K":53.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":24.15,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Kazbek-7B",
        "Average":65.88,
        "ARC":65.1,
        "HellaSwag":85.2,
        "MMLU":63.41,
        "TruthfulQA":49.43,
        "Winogrande":80.9,
        "GSM8K":51.25,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RaduGabriel\/SirUkrainian2.0DPO",
        "Average":65.87,
        "ARC":63.91,
        "HellaSwag":83.52,
        "MMLU":61.17,
        "TruthfulQA":65.08,
        "Winogrande":79.64,
        "GSM8K":41.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-14B",
        "Average":65.86,
        "ARC":58.28,
        "HellaSwag":83.99,
        "MMLU":67.7,
        "TruthfulQA":49.43,
        "Winogrande":76.8,
        "GSM8K":58.98,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":14.17,
        "Model Sha":195.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-falcon-180b-v13-preview0",
        "Average":65.85,
        "ARC":65.1,
        "HellaSwag":86.19,
        "MMLU":64.6,
        "TruthfulQA":54.97,
        "Winogrande":82.64,
        "GSM8K":41.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":180.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"harshitv804\/MetaMath-Mistral-2x7B",
        "Average":65.84,
        "ARC":60.58,
        "HellaSwag":82.59,
        "MMLU":61.87,
        "TruthfulQA":44.8,
        "Winogrande":76.01,
        "GSM8K":69.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2.03-128k",
        "Average":65.83,
        "ARC":64.68,
        "HellaSwag":84.56,
        "MMLU":63.02,
        "TruthfulQA":51.16,
        "Winogrande":81.06,
        "GSM8K":50.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-summ-lora-tuned-8h",
        "Average":65.83,
        "ARC":63.05,
        "HellaSwag":85.17,
        "MMLU":60.39,
        "TruthfulQA":69.8,
        "Winogrande":77.35,
        "GSM8K":39.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"Replete-AI\/Mistral-11b-v0.1",
        "Average":65.8,
        "ARC":62.2,
        "HellaSwag":84.65,
        "MMLU":63.11,
        "TruthfulQA":59.23,
        "Winogrande":75.77,
        "GSM8K":49.81,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":11.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Replete-AI\/Mistral-Evolved-11b-v0.1",
        "Average":65.8,
        "ARC":62.2,
        "HellaSwag":84.65,
        "MMLU":63.11,
        "TruthfulQA":59.23,
        "Winogrande":75.77,
        "GSM8K":49.81,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.17,
        "Model Sha":28.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"macadeliccc\/laser-polyglot-4x7b",
        "Average":65.79,
        "ARC":64.16,
        "HellaSwag":84.98,
        "MMLU":63.88,
        "TruthfulQA":55.47,
        "Winogrande":77.82,
        "GSM8K":48.45,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-summ-lora-tuned",
        "Average":65.79,
        "ARC":62.8,
        "HellaSwag":85.19,
        "MMLU":60.58,
        "TruthfulQA":70.18,
        "Winogrande":77.19,
        "GSM8K":38.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"meta-math\/MetaMath-Mistral-7B",
        "Average":65.78,
        "ARC":60.67,
        "HellaSwag":82.58,
        "MMLU":61.95,
        "TruthfulQA":44.89,
        "Winogrande":75.77,
        "GSM8K":68.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0-hero\/Matter-0.1-7B-boost-DPO-preview",
        "Average":65.77,
        "ARC":64.59,
        "HellaSwag":82.87,
        "MMLU":62.02,
        "TruthfulQA":58.86,
        "Winogrande":75.85,
        "GSM8K":50.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kaitchup\/Maixtchup-4x7b",
        "Average":65.77,
        "ARC":62.54,
        "HellaSwag":83.83,
        "MMLU":61.28,
        "TruthfulQA":56.13,
        "Winogrande":76.01,
        "GSM8K":54.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sonthenguyen\/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-reversed_corrupted",
        "Average":65.76,
        "ARC":64.42,
        "HellaSwag":83.95,
        "MMLU":63.61,
        "TruthfulQA":51.65,
        "Winogrande":77.74,
        "GSM8K":53.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-math-ia3-pruned20",
        "Average":65.76,
        "ARC":63.05,
        "HellaSwag":84.42,
        "MMLU":60.55,
        "TruthfulQA":67.74,
        "Winogrande":76.87,
        "GSM8K":41.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_420",
        "Average":65.76,
        "ARC":70.14,
        "HellaSwag":87.73,
        "MMLU":70.35,
        "TruthfulQA":54.0,
        "Winogrande":83.74,
        "GSM8K":28.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FusionNet_passthrough_v0.1",
        "Average":65.74,
        "ARC":69.45,
        "HellaSwag":87.79,
        "MMLU":65.2,
        "TruthfulQA":67.67,
        "Winogrande":81.53,
        "GSM8K":22.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":21.2,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tokyotech-llm\/Swallow-70b-instruct-hf",
        "Average":65.74,
        "ARC":66.21,
        "HellaSwag":85.14,
        "MMLU":67.08,
        "TruthfulQA":48.0,
        "Winogrande":82.08,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":69.16,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest-merge",
        "Average":65.74,
        "ARC":63.65,
        "HellaSwag":84.41,
        "MMLU":59.98,
        "TruthfulQA":57.48,
        "Winogrande":77.74,
        "GSM8K":51.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-attention-sparsity-20",
        "Average":65.74,
        "ARC":62.88,
        "HellaSwag":84.84,
        "MMLU":60.81,
        "TruthfulQA":68.26,
        "Winogrande":77.9,
        "GSM8K":39.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_AI_128k_b",
        "Average":65.73,
        "ARC":64.08,
        "HellaSwag":84.68,
        "MMLU":63.76,
        "TruthfulQA":57.09,
        "Winogrande":79.16,
        "GSM8K":45.64,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nextai-team\/Moe-4x7b-reason-code-qa",
        "Average":65.73,
        "ARC":62.54,
        "HellaSwag":83.87,
        "MMLU":61.2,
        "TruthfulQA":56.12,
        "Winogrande":76.09,
        "GSM8K":54.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Plaban81\/Moe-4x7b-math-reason-code",
        "Average":65.73,
        "ARC":62.54,
        "HellaSwag":83.87,
        "MMLU":61.2,
        "TruthfulQA":56.12,
        "Winogrande":76.09,
        "GSM8K":54.59,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":24.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/dolphin-2.6-mistral-7b-dpo-orca-v2",
        "Average":65.72,
        "ARC":66.13,
        "HellaSwag":84.9,
        "MMLU":62.64,
        "TruthfulQA":62.39,
        "Winogrande":78.61,
        "GSM8K":39.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/llama-2-70b-dolphin-peft",
        "Average":65.72,
        "ARC":69.62,
        "HellaSwag":86.82,
        "MMLU":69.18,
        "TruthfulQA":57.43,
        "Winogrande":83.9,
        "GSM8K":27.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-v2-7b-selfplay-v0",
        "Average":65.72,
        "ARC":63.05,
        "HellaSwag":84.88,
        "MMLU":60.78,
        "TruthfulQA":68.14,
        "Winogrande":77.19,
        "GSM8K":40.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"grimjim\/Mistral-7B-Instruct-demi-merge-v0.2-7B",
        "Average":65.71,
        "ARC":63.91,
        "HellaSwag":84.89,
        "MMLU":63.69,
        "TruthfulQA":55.26,
        "Winogrande":78.53,
        "GSM8K":47.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mistralai\/Mistral-7B-Instruct-v0.2",
        "Average":65.71,
        "ARC":63.14,
        "HellaSwag":84.88,
        "MMLU":60.78,
        "TruthfulQA":68.26,
        "Winogrande":77.19,
        "GSM8K":40.03,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1600.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-spnf",
        "Average":65.7,
        "ARC":63.05,
        "HellaSwag":84.9,
        "MMLU":60.82,
        "TruthfulQA":68.34,
        "Winogrande":77.43,
        "GSM8K":39.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-math-ia3-pruned10",
        "Average":65.7,
        "ARC":63.14,
        "HellaSwag":84.71,
        "MMLU":60.72,
        "TruthfulQA":68.16,
        "Winogrande":77.35,
        "GSM8K":40.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Bucharest-0.3",
        "Average":65.69,
        "ARC":63.99,
        "HellaSwag":84.46,
        "MMLU":65.61,
        "TruthfulQA":46.19,
        "Winogrande":82.72,
        "GSM8K":51.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziniuli\/Mistral-7B-ReMax-v0.1",
        "Average":65.69,
        "ARC":63.31,
        "HellaSwag":84.98,
        "MMLU":60.76,
        "TruthfulQA":68.16,
        "Winogrande":77.35,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Corianas\/Neural-Mistral-7B",
        "Average":65.69,
        "ARC":63.4,
        "HellaSwag":85.59,
        "MMLU":60.92,
        "TruthfulQA":69.26,
        "Winogrande":77.43,
        "GSM8K":37.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/Mistral-7B-Instruct-v0.2-sp-v0",
        "Average":65.68,
        "ARC":63.05,
        "HellaSwag":84.84,
        "MMLU":60.75,
        "TruthfulQA":68.22,
        "Winogrande":77.11,
        "GSM8K":40.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/Mistral-7B-Instruct-v2-sp-v0.1",
        "Average":65.68,
        "ARC":63.05,
        "HellaSwag":84.84,
        "MMLU":60.75,
        "TruthfulQA":68.22,
        "Winogrande":77.11,
        "GSM8K":40.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"localfultonextractor\/Erosumika-7B-v3-0.2",
        "Average":65.65,
        "ARC":67.75,
        "HellaSwag":84.95,
        "MMLU":60.0,
        "TruthfulQA":55.77,
        "Winogrande":81.53,
        "GSM8K":43.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Einstein-v5-v0.2-7B",
        "Average":65.65,
        "ARC":60.92,
        "HellaSwag":80.99,
        "MMLU":61.02,
        "TruthfulQA":52.59,
        "Winogrande":78.69,
        "GSM8K":59.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC44\/Mistral-7B-private-spef",
        "Average":65.64,
        "ARC":63.23,
        "HellaSwag":84.93,
        "MMLU":60.8,
        "TruthfulQA":68.35,
        "Winogrande":77.27,
        "GSM8K":39.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"notbdq\/alooowso",
        "Average":65.63,
        "ARC":62.97,
        "HellaSwag":84.87,
        "MMLU":60.78,
        "TruthfulQA":68.18,
        "Winogrande":77.43,
        "GSM8K":39.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-v2-7b-selfplay-low-tmp",
        "Average":65.63,
        "ARC":63.05,
        "HellaSwag":84.91,
        "MMLU":60.76,
        "TruthfulQA":68.13,
        "Winogrande":77.35,
        "GSM8K":39.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziniuli\/Mistral-7B-ReMax-v0.1",
        "Average":65.63,
        "ARC":63.31,
        "HellaSwag":84.98,
        "MMLU":60.89,
        "TruthfulQA":68.11,
        "Winogrande":77.03,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-v2-7b-selfplay-v0-test",
        "Average":65.61,
        "ARC":62.97,
        "HellaSwag":84.86,
        "MMLU":60.64,
        "TruthfulQA":67.91,
        "Winogrande":77.58,
        "GSM8K":39.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Mistral-7B-Instruct-v0.2-2x7B-MoE",
        "Average":65.6,
        "ARC":62.97,
        "HellaSwag":84.88,
        "MMLU":60.74,
        "TruthfulQA":68.18,
        "Winogrande":77.43,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"v2ray\/LLaMA-2-Jannie-70B-QLoRA",
        "Average":65.6,
        "ARC":68.94,
        "HellaSwag":86.9,
        "MMLU":69.37,
        "TruthfulQA":53.67,
        "Winogrande":82.95,
        "GSM8K":31.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":70.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ENERGY-DRINK-LOVE\/SOLAR_merge2_dpo",
        "Average":65.6,
        "ARC":64.42,
        "HellaSwag":82.73,
        "MMLU":64.57,
        "TruthfulQA":51.28,
        "Winogrande":81.77,
        "GSM8K":48.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Camel-Platypus2-70B",
        "Average":65.59,
        "ARC":71.08,
        "HellaSwag":87.6,
        "MMLU":70.04,
        "TruthfulQA":58.09,
        "Winogrande":83.82,
        "GSM8K":22.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest-merge",
        "Average":65.58,
        "ARC":63.4,
        "HellaSwag":84.38,
        "MMLU":60.08,
        "TruthfulQA":57.57,
        "Winogrande":77.51,
        "GSM8K":50.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nonetrix\/pippafeet-11B-0.1",
        "Average":65.56,
        "ARC":63.65,
        "HellaSwag":82.25,
        "MMLU":65.03,
        "TruthfulQA":65.12,
        "Winogrande":81.53,
        "GSM8K":35.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.6,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/Mistral-7B-Instruct-v0.2-Selfplay-v0",
        "Average":65.56,
        "ARC":62.8,
        "HellaSwag":84.74,
        "MMLU":60.6,
        "TruthfulQA":67.35,
        "Winogrande":77.58,
        "GSM8K":40.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Yee-34B-200K-Chat",
        "Average":65.56,
        "ARC":65.61,
        "HellaSwag":84.33,
        "MMLU":74.91,
        "TruthfulQA":53.88,
        "Winogrande":79.79,
        "GSM8K":34.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ConvexAI\/Julianne-2x7B-bf16",
        "Average":65.55,
        "ARC":63.74,
        "HellaSwag":82.81,
        "MMLU":61.57,
        "TruthfulQA":55.91,
        "Winogrande":77.74,
        "GSM8K":51.55,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Delcos\/Velara-11B-V2",
        "Average":65.55,
        "ARC":63.82,
        "HellaSwag":85.85,
        "MMLU":63.62,
        "TruthfulQA":58.83,
        "Winogrande":77.82,
        "GSM8K":43.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":11.39,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-sparsity-20-v0.1",
        "Average":65.54,
        "ARC":62.29,
        "HellaSwag":84.9,
        "MMLU":60.63,
        "TruthfulQA":67.66,
        "Winogrande":77.66,
        "GSM8K":40.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/neural-chat-11b-v3-2",
        "Average":65.52,
        "ARC":66.64,
        "HellaSwag":82.12,
        "MMLU":62.37,
        "TruthfulQA":60.22,
        "Winogrande":79.64,
        "GSM8K":42.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Badgids\/Gonzo-Code-7B",
        "Average":65.51,
        "ARC":61.26,
        "HellaSwag":83.67,
        "MMLU":62.77,
        "TruthfulQA":56.7,
        "Winogrande":77.27,
        "GSM8K":51.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_42_70b",
        "Average":65.51,
        "ARC":68.26,
        "HellaSwag":87.65,
        "MMLU":70.0,
        "TruthfulQA":48.76,
        "Winogrande":83.66,
        "GSM8K":34.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pankajmathur\/Lima_Unchained_70b",
        "Average":65.51,
        "ARC":68.26,
        "HellaSwag":87.65,
        "MMLU":70.0,
        "TruthfulQA":48.76,
        "Winogrande":83.66,
        "GSM8K":34.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"notadib\/Mistral-7B-Instruct-v0.2-attention-sparsity-30",
        "Average":65.51,
        "ARC":62.97,
        "HellaSwag":84.71,
        "MMLU":60.49,
        "TruthfulQA":67.49,
        "Winogrande":77.98,
        "GSM8K":39.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jordiclive\/Llama-2-70b-oasst-1-200",
        "Average":65.5,
        "ARC":67.66,
        "HellaSwag":87.24,
        "MMLU":69.95,
        "TruthfulQA":51.28,
        "Winogrande":84.14,
        "GSM8K":32.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RaduGabriel\/SirUkrainian2.0",
        "Average":65.5,
        "ARC":63.65,
        "HellaSwag":83.26,
        "MMLU":61.22,
        "TruthfulQA":64.24,
        "Winogrande":79.64,
        "GSM8K":41.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"invalid-coder\/dolphin-2.1-mistral-7b-snr-laser",
        "Average":65.5,
        "ARC":63.82,
        "HellaSwag":84.78,
        "MMLU":63.63,
        "TruthfulQA":55.24,
        "Winogrande":78.3,
        "GSM8K":47.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-7b-v0.1",
        "Average":65.49,
        "ARC":63.91,
        "HellaSwag":83.14,
        "MMLU":64.56,
        "TruthfulQA":52.65,
        "Winogrande":80.58,
        "GSM8K":48.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-10.7B-v0.4",
        "Average":65.48,
        "ARC":64.93,
        "HellaSwag":82.47,
        "MMLU":62.5,
        "TruthfulQA":51.11,
        "Winogrande":81.85,
        "GSM8K":50.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":10.7,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"notadib\/Mistral-7B-Instruct-v0.2-attention-sparsity-10-v0.1",
        "Average":65.48,
        "ARC":63.05,
        "HellaSwag":84.88,
        "MMLU":60.84,
        "TruthfulQA":68.11,
        "Winogrande":77.11,
        "GSM8K":38.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/fiction.live-Kimiko-V2-70B-fp16",
        "Average":65.48,
        "ARC":67.66,
        "HellaSwag":87.65,
        "MMLU":69.82,
        "TruthfulQA":49.28,
        "Winogrande":83.9,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-sparsity-10",
        "Average":65.48,
        "ARC":62.88,
        "HellaSwag":84.85,
        "MMLU":60.87,
        "TruthfulQA":67.93,
        "Winogrande":77.51,
        "GSM8K":38.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest-merge-v0.1",
        "Average":65.47,
        "ARC":62.8,
        "HellaSwag":84.32,
        "MMLU":60.05,
        "TruthfulQA":58.53,
        "Winogrande":77.19,
        "GSM8K":49.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-180B",
        "Average":65.46,
        "ARC":69.2,
        "HellaSwag":88.89,
        "MMLU":69.59,
        "TruthfulQA":45.16,
        "Winogrande":86.74,
        "GSM8K":33.21,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":179.52,
        "Model Sha":1073.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_3.0",
        "Average":65.46,
        "ARC":62.46,
        "HellaSwag":84.02,
        "MMLU":61.91,
        "TruthfulQA":58.21,
        "Winogrande":80.19,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.3",
        "Average":65.44,
        "ARC":62.71,
        "HellaSwag":84.8,
        "MMLU":60.92,
        "TruthfulQA":67.56,
        "Winogrande":77.27,
        "GSM8K":39.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jingyeom\/KoSoLAR-10.7B-v0.2_1.3_dedup_p",
        "Average":65.43,
        "ARC":63.05,
        "HellaSwag":83.63,
        "MMLU":64.61,
        "TruthfulQA":52.69,
        "Winogrande":80.51,
        "GSM8K":48.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PistachioAlt\/Noromaid-Bagel-7B-Slerp",
        "Average":65.42,
        "ARC":64.51,
        "HellaSwag":84.58,
        "MMLU":64.3,
        "TruthfulQA":52.88,
        "Winogrande":79.4,
        "GSM8K":46.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.3-ft-step-15936",
        "Average":65.42,
        "ARC":62.54,
        "HellaSwag":82.14,
        "MMLU":62.58,
        "TruthfulQA":55.11,
        "Winogrande":75.77,
        "GSM8K":54.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-summ-ia3-pruned10",
        "Average":65.41,
        "ARC":63.05,
        "HellaSwag":84.88,
        "MMLU":59.67,
        "TruthfulQA":68.1,
        "Winogrande":77.51,
        "GSM8K":39.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Eurdem\/megatron_v3_2x7B",
        "Average":65.4,
        "ARC":66.38,
        "HellaSwag":83.71,
        "MMLU":61.53,
        "TruthfulQA":55.5,
        "Winogrande":79.08,
        "GSM8K":46.17,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"garage-bAInd\/Camel-Platypus2-70B",
        "Average":65.39,
        "ARC":70.14,
        "HellaSwag":87.71,
        "MMLU":69.83,
        "TruthfulQA":57.77,
        "Winogrande":82.95,
        "GSM8K":23.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenLemur\/lemur-70b-chat-v1",
        "Average":65.38,
        "ARC":66.98,
        "HellaSwag":85.73,
        "MMLU":65.99,
        "TruthfulQA":56.58,
        "Winogrande":81.69,
        "GSM8K":35.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":70.0,
        "Model Sha":69.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Mistroll-7B-v0.2-16bit",
        "Average":65.36,
        "ARC":62.2,
        "HellaSwag":84.85,
        "MMLU":60.37,
        "TruthfulQA":67.65,
        "Winogrande":76.87,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Mistral-Instruct-7B-v0.2-ChatAlpacaV2-4bit",
        "Average":65.34,
        "ARC":62.12,
        "HellaSwag":84.55,
        "MMLU":60.66,
        "TruthfulQA":67.29,
        "Winogrande":77.11,
        "GSM8K":40.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-7B-v2.03",
        "Average":65.34,
        "ARC":63.82,
        "HellaSwag":84.73,
        "MMLU":63.05,
        "TruthfulQA":48.53,
        "Winogrande":80.9,
        "GSM8K":51.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"01-ai\/Yi-34B-Chat",
        "Average":65.32,
        "ARC":65.44,
        "HellaSwag":84.16,
        "MMLU":74.9,
        "TruthfulQA":55.37,
        "Winogrande":80.11,
        "GSM8K":31.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":303.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Mistroll-7B-v0.3-16bit",
        "Average":65.3,
        "ARC":62.12,
        "HellaSwag":84.83,
        "MMLU":60.45,
        "TruthfulQA":67.65,
        "Winogrande":76.87,
        "GSM8K":39.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BarraHome\/Lucie-7B-v0.2-16bit",
        "Average":65.3,
        "ARC":62.12,
        "HellaSwag":84.83,
        "MMLU":60.45,
        "TruthfulQA":67.65,
        "Winogrande":76.87,
        "GSM8K":39.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"liuxiang886\/llama2-70B-qlora-gpt4",
        "Average":65.29,
        "ARC":70.31,
        "HellaSwag":86.39,
        "MMLU":69.29,
        "TruthfulQA":54.02,
        "Winogrande":82.87,
        "GSM8K":28.89,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":70.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FPHam\/Writing_Partner_Mistral_7B",
        "Average":65.29,
        "ARC":64.59,
        "HellaSwag":84.59,
        "MMLU":62.55,
        "TruthfulQA":48.55,
        "Winogrande":76.87,
        "GSM8K":54.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llm-agents\/tora-70b-v1.0",
        "Average":65.28,
        "ARC":67.58,
        "HellaSwag":85.82,
        "MMLU":69.13,
        "TruthfulQA":51.76,
        "Winogrande":82.16,
        "GSM8K":35.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/neural-chat-7b-v3-3-wizardmath-dare-me",
        "Average":65.28,
        "ARC":59.64,
        "HellaSwag":82.63,
        "MMLU":58.13,
        "TruthfulQA":62.6,
        "Winogrande":71.67,
        "GSM8K":57.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-sparsity-30-v0.1",
        "Average":65.28,
        "ARC":63.31,
        "HellaSwag":84.37,
        "MMLU":60.24,
        "TruthfulQA":66.28,
        "Winogrande":78.06,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"orangetin\/OpenHermes-Mixtral-8x7B",
        "Average":65.27,
        "ARC":63.91,
        "HellaSwag":84.14,
        "MMLU":64.29,
        "TruthfulQA":59.53,
        "Winogrande":74.03,
        "GSM8K":45.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ContextualAI\/Contextual_KTO_Mistral_PairRM",
        "Average":65.26,
        "ARC":64.76,
        "HellaSwag":85.52,
        "MMLU":60.28,
        "TruthfulQA":71.67,
        "Winogrande":75.53,
        "GSM8K":33.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/MadMix-v0.1",
        "Average":65.26,
        "ARC":64.93,
        "HellaSwag":84.37,
        "MMLU":64.37,
        "TruthfulQA":51.05,
        "Winogrande":77.19,
        "GSM8K":49.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AIGeekLabs\/radiantloom-mixtral-8x7b-fusion",
        "Average":65.24,
        "ARC":63.48,
        "HellaSwag":83.65,
        "MMLU":60.03,
        "TruthfulQA":54.76,
        "Winogrande":76.09,
        "GSM8K":53.45,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"simonveitner\/MathHermes-2.5-Mistral-7B",
        "Average":65.24,
        "ARC":64.76,
        "HellaSwag":84.19,
        "MMLU":63.59,
        "TruthfulQA":51.95,
        "Winogrande":77.66,
        "GSM8K":49.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Mistroll-7B-v0.1-16bit",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.81,
        "MMLU":60.34,
        "TruthfulQA":67.67,
        "Winogrande":76.8,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Wistral-7B-Instruct-v0.3",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.81,
        "MMLU":60.34,
        "TruthfulQA":67.67,
        "Winogrande":76.8,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Lucie-7b-3e-5",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.81,
        "MMLU":60.34,
        "TruthfulQA":67.67,
        "Winogrande":76.8,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Lucie-7b",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.81,
        "MMLU":60.34,
        "TruthfulQA":67.67,
        "Winogrande":76.8,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Wistral-7B-Instruct-v0.4",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.81,
        "MMLU":60.34,
        "TruthfulQA":67.67,
        "Winogrande":76.8,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/llama-2-70b-fb16-korean",
        "Average":65.23,
        "ARC":67.15,
        "HellaSwag":86.78,
        "MMLU":69.29,
        "TruthfulQA":56.5,
        "Winogrande":82.64,
        "GSM8K":29.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":68.98,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/Wistral-7B-Instruct-v0.3",
        "Average":65.23,
        "ARC":62.2,
        "HellaSwag":84.77,
        "MMLU":60.32,
        "TruthfulQA":67.62,
        "Winogrande":76.8,
        "GSM8K":39.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-summ-ia3-pruned20",
        "Average":65.23,
        "ARC":62.88,
        "HellaSwag":84.77,
        "MMLU":60.09,
        "TruthfulQA":67.84,
        "Winogrande":76.95,
        "GSM8K":38.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kwchoi\/DPO_mistral_7b_ultra_0129_1k",
        "Average":65.2,
        "ARC":64.16,
        "HellaSwag":85.54,
        "MMLU":61.04,
        "TruthfulQA":68.34,
        "Winogrande":77.19,
        "GSM8K":34.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/MiquMaid-v2-70B",
        "Average":65.19,
        "ARC":70.48,
        "HellaSwag":87.49,
        "MMLU":75.18,
        "TruthfulQA":57.62,
        "Winogrande":84.77,
        "GSM8K":15.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"csujeong\/Gemma-7B-Finetuning-JCS-Ko-Ins",
        "Average":65.18,
        "ARC":62.46,
        "HellaSwag":82.78,
        "MMLU":66.23,
        "TruthfulQA":48.6,
        "Winogrande":79.08,
        "GSM8K":51.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DreadPoor\/ToppyEvil-7B-slerp",
        "Average":65.16,
        "ARC":63.65,
        "HellaSwag":84.29,
        "MMLU":63.6,
        "TruthfulQA":46.06,
        "Winogrande":77.58,
        "GSM8K":55.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"cloudyu\/Mixtral_7Bx2_MoE_13B",
        "Average":65.14,
        "ARC":64.85,
        "HellaSwag":83.92,
        "MMLU":62.27,
        "TruthfulQA":57.55,
        "Winogrande":77.9,
        "GSM8K":44.35,
        "Type":"base merges and moerges",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amazingvince\/openhermes-7b-dpo",
        "Average":65.14,
        "ARC":65.78,
        "HellaSwag":84.94,
        "MMLU":63.66,
        "TruthfulQA":57.01,
        "Winogrande":77.51,
        "GSM8K":41.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Mistral-7B-Instruct-KhanAcademy-v0.2",
        "Average":65.11,
        "ARC":62.03,
        "HellaSwag":82.98,
        "MMLU":61.68,
        "TruthfulQA":64.22,
        "Winogrande":77.58,
        "GSM8K":42.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"KnutJaegersberg\/internlm-20b-llama",
        "Average":65.09,
        "ARC":61.35,
        "HellaSwag":82.08,
        "MMLU":61.59,
        "TruthfulQA":57.71,
        "Winogrande":76.72,
        "GSM8K":51.1,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BlueNipples\/SnowLotus-v2-10.7B",
        "Average":65.09,
        "ARC":64.76,
        "HellaSwag":85.28,
        "MMLU":64.1,
        "TruthfulQA":45.54,
        "Winogrande":82.08,
        "GSM8K":48.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Epiculous\/Fett-uccine-7B",
        "Average":65.08,
        "ARC":63.23,
        "HellaSwag":86.09,
        "MMLU":60.03,
        "TruthfulQA":69.47,
        "Winogrande":75.06,
        "GSM8K":36.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/fc-dolphin-2.6-mistral-7b-dpo-laser",
        "Average":65.04,
        "ARC":62.97,
        "HellaSwag":84.18,
        "MMLU":63.65,
        "TruthfulQA":57.75,
        "Winogrande":78.37,
        "GSM8K":43.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"invalid-coder\/dolphin-2.1-mistral-7b-snr-math-laser",
        "Average":65.03,
        "ARC":63.31,
        "HellaSwag":84.29,
        "MMLU":63.02,
        "TruthfulQA":54.75,
        "Winogrande":77.58,
        "GSM8K":47.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Sina-Loki-7b-Merge",
        "Average":65.03,
        "ARC":59.13,
        "HellaSwag":81.96,
        "MMLU":64.71,
        "TruthfulQA":53.84,
        "Winogrande":78.14,
        "GSM8K":52.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Tiger-7b-v0.1",
        "Average":65.02,
        "ARC":59.98,
        "HellaSwag":83.21,
        "MMLU":61.42,
        "TruthfulQA":61.03,
        "Winogrande":77.66,
        "GSM8K":46.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.2.1-mistral-7b",
        "Average":65.01,
        "ARC":63.23,
        "HellaSwag":83.8,
        "MMLU":63.16,
        "TruthfulQA":53.14,
        "Winogrande":78.61,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":177.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/DarkSapling-7B-v2.0",
        "Average":64.98,
        "ARC":64.16,
        "HellaSwag":85.1,
        "MMLU":64.37,
        "TruthfulQA":52.21,
        "Winogrande":78.61,
        "GSM8K":45.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/OpenOrca-Zephyr-7B",
        "Average":64.97,
        "ARC":64.08,
        "HellaSwag":83.82,
        "MMLU":62.46,
        "TruthfulQA":54.31,
        "Winogrande":78.93,
        "GSM8K":46.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-70b-gpt4-1.4.1",
        "Average":64.97,
        "ARC":70.39,
        "HellaSwag":87.82,
        "MMLU":70.31,
        "TruthfulQA":55.2,
        "Winogrande":83.58,
        "GSM8K":22.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":70.0,
        "Model Sha":48.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/Mistral-Instruct-Ukrainian-slerp",
        "Average":64.96,
        "ARC":62.03,
        "HellaSwag":84.35,
        "MMLU":61.35,
        "TruthfulQA":63.49,
        "Winogrande":76.87,
        "GSM8K":41.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Hermes-Instruct-7B-100K",
        "Average":64.96,
        "ARC":61.52,
        "HellaSwag":82.84,
        "MMLU":60.95,
        "TruthfulQA":63.62,
        "Winogrande":76.87,
        "GSM8K":43.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Mistral-7B-Instruct-v0.2-Neural-Story",
        "Average":64.96,
        "ARC":64.08,
        "HellaSwag":83.97,
        "MMLU":60.67,
        "TruthfulQA":66.89,
        "Winogrande":75.85,
        "GSM8K":38.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":22.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_Chat_X",
        "Average":64.94,
        "ARC":65.53,
        "HellaSwag":84.93,
        "MMLU":61.5,
        "TruthfulQA":56.15,
        "Winogrande":77.03,
        "GSM8K":44.5,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"LeroyDyer\/Mixtral_AI_128k",
        "Average":64.94,
        "ARC":63.23,
        "HellaSwag":84.62,
        "MMLU":64.24,
        "TruthfulQA":52.43,
        "Winogrande":79.56,
        "GSM8K":45.56,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"maldv\/winter-garden-7b-delta",
        "Average":64.93,
        "ARC":64.16,
        "HellaSwag":84.37,
        "MMLU":60.38,
        "TruthfulQA":67.95,
        "Winogrande":76.72,
        "GSM8K":36.01,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-2.2.1-mistral-7b",
        "Average":64.93,
        "ARC":63.31,
        "HellaSwag":83.76,
        "MMLU":63.17,
        "TruthfulQA":53.11,
        "Winogrande":78.14,
        "GSM8K":48.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bn22\/OpenHermes-2.5-Mistral-7B-MISALIGNED",
        "Average":64.92,
        "ARC":65.36,
        "HellaSwag":84.67,
        "MMLU":63.74,
        "TruthfulQA":52.85,
        "Winogrande":77.66,
        "GSM8K":45.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"localfultonextractor\/Erosumika-7B",
        "Average":64.92,
        "ARC":62.88,
        "HellaSwag":85.9,
        "MMLU":60.64,
        "TruthfulQA":67.59,
        "Winogrande":75.3,
        "GSM8K":37.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.6-mistral-7b",
        "Average":64.92,
        "ARC":63.05,
        "HellaSwag":84.05,
        "MMLU":63.2,
        "TruthfulQA":55.67,
        "Winogrande":77.66,
        "GSM8K":45.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":97.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Puffin-70B",
        "Average":64.91,
        "ARC":67.41,
        "HellaSwag":87.37,
        "MMLU":69.77,
        "TruthfulQA":46.77,
        "Winogrande":83.9,
        "GSM8K":34.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":70.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.6-mistral-7b",
        "Average":64.91,
        "ARC":62.88,
        "HellaSwag":84.06,
        "MMLU":63.19,
        "TruthfulQA":55.65,
        "Winogrande":77.58,
        "GSM8K":46.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":97.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Panda-7B-v0.1",
        "Average":64.89,
        "ARC":62.97,
        "HellaSwag":83.76,
        "MMLU":60.73,
        "TruthfulQA":66.97,
        "Winogrande":76.24,
        "GSM8K":38.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/Genstruct-10.7B",
        "Average":64.89,
        "ARC":60.84,
        "HellaSwag":82.81,
        "MMLU":60.27,
        "TruthfulQA":46.66,
        "Winogrande":76.8,
        "GSM8K":61.94,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jarradh\/llama2_70b_chat_uncensored",
        "Average":64.88,
        "ARC":68.43,
        "HellaSwag":86.77,
        "MMLU":68.76,
        "TruthfulQA":52.5,
        "Winogrande":82.56,
        "GSM8K":30.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":64.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"prhegde\/merge-aanaphi-phi2-orage-3b",
        "Average":64.87,
        "ARC":63.57,
        "HellaSwag":77.42,
        "MMLU":58.21,
        "TruthfulQA":53.47,
        "Winogrande":74.98,
        "GSM8K":61.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0-hero\/Matter-0.1-7B-DPO-preview",
        "Average":64.87,
        "ARC":62.71,
        "HellaSwag":82.99,
        "MMLU":62.7,
        "TruthfulQA":45.79,
        "Winogrande":78.85,
        "GSM8K":56.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TeeZee\/Kyllene-v1.0",
        "Average":64.86,
        "ARC":64.85,
        "HellaSwag":84.51,
        "MMLU":73.33,
        "TruthfulQA":57.89,
        "Winogrande":78.22,
        "GSM8K":30.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":56.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"krevas\/SOLAR-10.7B",
        "Average":64.86,
        "ARC":74.32,
        "HellaSwag":89.05,
        "MMLU":62.94,
        "TruthfulQA":80.33,
        "Winogrande":82.56,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/bagel-7b-v0.4",
        "Average":64.82,
        "ARC":63.57,
        "HellaSwag":82.67,
        "MMLU":62.25,
        "TruthfulQA":54.2,
        "Winogrande":78.93,
        "GSM8K":47.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"INSAIT-Institute\/BgGPT-7B-Instruct-v0.1",
        "Average":64.82,
        "ARC":60.24,
        "HellaSwag":81.6,
        "MMLU":59.66,
        "TruthfulQA":53.68,
        "Winogrande":77.03,
        "GSM8K":56.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.29,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Hermes-Instruct-7B-217K",
        "Average":64.81,
        "ARC":61.01,
        "HellaSwag":82.64,
        "MMLU":61.23,
        "TruthfulQA":61.81,
        "Winogrande":77.66,
        "GSM8K":44.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"runkai\/PascalHermes-2.5-Mistral-7B",
        "Average":64.81,
        "ARC":63.82,
        "HellaSwag":83.75,
        "MMLU":62.22,
        "TruthfulQA":53.72,
        "Winogrande":77.11,
        "GSM8K":48.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/DarkSapling-7B-v1.1",
        "Average":64.8,
        "ARC":63.48,
        "HellaSwag":85.09,
        "MMLU":64.47,
        "TruthfulQA":52.04,
        "Winogrande":78.53,
        "GSM8K":45.19,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NeuralNovel\/Ignis-7B-DPO",
        "Average":64.77,
        "ARC":66.3,
        "HellaSwag":84.85,
        "MMLU":58.99,
        "TruthfulQA":65.46,
        "Winogrande":79.95,
        "GSM8K":33.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yanolja\/KoSOLAR-10.7B-v0.3",
        "Average":64.76,
        "ARC":62.8,
        "HellaSwag":83.73,
        "MMLU":64.51,
        "TruthfulQA":44.57,
        "Winogrande":82.48,
        "GSM8K":50.49,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/Dykh-Tau-7B",
        "Average":64.76,
        "ARC":63.74,
        "HellaSwag":84.67,
        "MMLU":63.79,
        "TruthfulQA":47.25,
        "Winogrande":80.03,
        "GSM8K":49.05,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Tanuki-7B-v0.1",
        "Average":64.74,
        "ARC":62.8,
        "HellaSwag":83.14,
        "MMLU":60.54,
        "TruthfulQA":66.33,
        "Winogrande":75.85,
        "GSM8K":39.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/mistral-7b-v0.1-layla-v3",
        "Average":64.73,
        "ARC":61.77,
        "HellaSwag":83.41,
        "MMLU":64.26,
        "TruthfulQA":43.2,
        "Winogrande":79.72,
        "GSM8K":56.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v17.1-32k",
        "Average":64.73,
        "ARC":65.53,
        "HellaSwag":75.95,
        "MMLU":70.02,
        "TruthfulQA":42.14,
        "Winogrande":75.69,
        "GSM8K":59.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/OpenMia-Indo-Mistral-7b-v4",
        "Average":64.73,
        "ARC":64.16,
        "HellaSwag":82.84,
        "MMLU":61.08,
        "TruthfulQA":53.36,
        "Winogrande":79.08,
        "GSM8K":47.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"oh-yeontaek\/llama-2-70B-LoRA-assemble-v2",
        "Average":64.73,
        "ARC":71.84,
        "HellaSwag":86.89,
        "MMLU":69.37,
        "TruthfulQA":64.79,
        "Winogrande":81.22,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/HelpSteer-filtered-Solar-Instruct",
        "Average":64.73,
        "ARC":63.14,
        "HellaSwag":83.05,
        "MMLU":64.32,
        "TruthfulQA":46.23,
        "Winogrande":80.58,
        "GSM8K":51.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"giraffe176\/Open_Neural_Monarch_Maidv0.2",
        "Average":64.72,
        "ARC":63.31,
        "HellaSwag":82.6,
        "MMLU":64.21,
        "TruthfulQA":43.04,
        "Winogrande":79.08,
        "GSM8K":56.1,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/WizardLM-Math-70B-TIES-v0.1",
        "Average":64.72,
        "ARC":68.52,
        "HellaSwag":86.87,
        "MMLU":69.24,
        "TruthfulQA":53.61,
        "Winogrande":82.72,
        "GSM8K":27.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"agpl-3.0",
        "Available on the Hub":68.98,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SC99\/Mistral-7B-summ-ia3-tuned-8h",
        "Average":64.71,
        "ARC":61.18,
        "HellaSwag":85.14,
        "MMLU":59.89,
        "TruthfulQA":68.31,
        "Winogrande":77.11,
        "GSM8K":36.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"l3utterfly\/mistral-7b-v0.1-layla-v4",
        "Average":64.69,
        "ARC":62.29,
        "HellaSwag":83.36,
        "MMLU":64.32,
        "TruthfulQA":43.14,
        "Winogrande":79.56,
        "GSM8K":55.5,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-9b",
        "Average":64.69,
        "ARC":62.46,
        "HellaSwag":78.41,
        "MMLU":69.81,
        "TruthfulQA":52.78,
        "Winogrande":76.32,
        "GSM8K":48.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.83,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-7b-dare-0.85",
        "Average":64.69,
        "ARC":63.57,
        "HellaSwag":84.82,
        "MMLU":64.29,
        "TruthfulQA":50.66,
        "Winogrande":79.24,
        "GSM8K":45.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/Etheria-55b-v0.1",
        "Average":64.69,
        "ARC":65.1,
        "HellaSwag":81.93,
        "MMLU":73.66,
        "TruthfulQA":56.16,
        "Winogrande":76.09,
        "GSM8K":35.18,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":55.59,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e2",
        "Average":64.67,
        "ARC":61.43,
        "HellaSwag":83.64,
        "MMLU":61.03,
        "TruthfulQA":64.92,
        "Winogrande":76.72,
        "GSM8K":40.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Euryale-L2-70B",
        "Average":64.66,
        "ARC":68.94,
        "HellaSwag":87.07,
        "MMLU":68.84,
        "TruthfulQA":54.49,
        "Winogrande":82.08,
        "GSM8K":26.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":70.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Hermetic-Platypus-B-2x7B",
        "Average":64.65,
        "ARC":59.47,
        "HellaSwag":82.95,
        "MMLU":62.15,
        "TruthfulQA":61.49,
        "Winogrande":77.43,
        "GSM8K":44.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"smelborp\/MixtralOrochi8x7B",
        "Average":64.62,
        "ARC":70.31,
        "HellaSwag":86.1,
        "MMLU":70.13,
        "TruthfulQA":63.99,
        "Winogrande":79.87,
        "GSM8K":17.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Chop-7b",
        "Average":64.59,
        "ARC":63.74,
        "HellaSwag":83.04,
        "MMLU":62.04,
        "TruthfulQA":62.19,
        "Winogrande":76.8,
        "GSM8K":39.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Gecko-7B-v0.1",
        "Average":64.58,
        "ARC":61.35,
        "HellaSwag":83.36,
        "MMLU":61.05,
        "TruthfulQA":62.6,
        "Winogrande":77.58,
        "GSM8K":41.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e1",
        "Average":64.58,
        "ARC":60.84,
        "HellaSwag":83.37,
        "MMLU":60.86,
        "TruthfulQA":64.98,
        "Winogrande":77.03,
        "GSM8K":40.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/PiVoT-0.1-early",
        "Average":64.58,
        "ARC":62.46,
        "HellaSwag":82.97,
        "MMLU":61.02,
        "TruthfulQA":62.89,
        "Winogrande":73.72,
        "GSM8K":44.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vishnukv\/WestSeverusJaskier-dare-ties-7b-32k",
        "Average":64.57,
        "ARC":67.75,
        "HellaSwag":87.02,
        "MMLU":61.18,
        "TruthfulQA":73.05,
        "Winogrande":82.4,
        "GSM8K":16.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Hermetic-Platypus-C-2x7B",
        "Average":64.56,
        "ARC":59.3,
        "HellaSwag":82.75,
        "MMLU":62.24,
        "TruthfulQA":60.81,
        "Winogrande":78.14,
        "GSM8K":44.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"proto-llm\/uniwiz-7B-v0.2",
        "Average":64.56,
        "ARC":63.31,
        "HellaSwag":85.07,
        "MMLU":63.7,
        "TruthfulQA":59.91,
        "Winogrande":77.82,
        "GSM8K":37.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-70b-gpt4-m2.0",
        "Average":64.56,
        "ARC":70.05,
        "HellaSwag":87.83,
        "MMLU":70.67,
        "TruthfulQA":49.79,
        "Winogrande":83.58,
        "GSM8K":25.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":70.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mixtral-8x7b-v15.4",
        "Average":64.54,
        "ARC":66.47,
        "HellaSwag":71.81,
        "MMLU":70.01,
        "TruthfulQA":55.46,
        "Winogrande":71.67,
        "GSM8K":51.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e3",
        "Average":64.54,
        "ARC":61.18,
        "HellaSwag":83.72,
        "MMLU":60.93,
        "TruthfulQA":64.94,
        "Winogrande":76.95,
        "GSM8K":39.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/mistral-7b-zephyr-dpo",
        "Average":64.53,
        "ARC":63.74,
        "HellaSwag":85.79,
        "MMLU":61.98,
        "TruthfulQA":56.61,
        "Winogrande":78.22,
        "GSM8K":40.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/Mistral-7b-instruct-v0.2-summ-sft-bf16-e2",
        "Average":64.52,
        "ARC":60.67,
        "HellaSwag":83.55,
        "MMLU":60.81,
        "TruthfulQA":65.1,
        "Winogrande":77.58,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radiantloom\/radiantloom-mixtral-8x7b-fusion-dpo",
        "Average":64.52,
        "ARC":63.48,
        "HellaSwag":82.49,
        "MMLU":59.68,
        "TruthfulQA":55.2,
        "Winogrande":76.09,
        "GSM8K":50.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Llama-2-70B-fp16",
        "Average":64.52,
        "ARC":67.32,
        "HellaSwag":87.33,
        "MMLU":69.83,
        "TruthfulQA":44.92,
        "Winogrande":83.74,
        "GSM8K":33.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051610\/Q",
        "Average":64.52,
        "ARC":66.98,
        "HellaSwag":85.67,
        "MMLU":75.13,
        "TruthfulQA":59.36,
        "Winogrande":80.03,
        "GSM8K":19.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-sft-bf16-e3",
        "Average":64.51,
        "ARC":60.32,
        "HellaSwag":83.68,
        "MMLU":60.82,
        "TruthfulQA":65.22,
        "Winogrande":77.82,
        "GSM8K":39.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FinancialSupport\/saiga-7b",
        "Average":64.51,
        "ARC":63.14,
        "HellaSwag":83.14,
        "MMLU":61.66,
        "TruthfulQA":54.99,
        "Winogrande":79.01,
        "GSM8K":45.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/VerA-Etheria-55b",
        "Average":64.51,
        "ARC":64.25,
        "HellaSwag":81.46,
        "MMLU":73.51,
        "TruthfulQA":52.1,
        "Winogrande":75.93,
        "GSM8K":39.8,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":55.59,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upstage\/llama-65b-instruct",
        "Average":64.51,
        "ARC":68.86,
        "HellaSwag":86.43,
        "MMLU":64.77,
        "TruthfulQA":59.7,
        "Winogrande":81.06,
        "GSM8K":26.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":65.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/openchat-3.5-1210-32k",
        "Average":64.49,
        "ARC":64.68,
        "HellaSwag":84.06,
        "MMLU":61.59,
        "TruthfulQA":49.31,
        "Winogrande":79.16,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-7b-HerO",
        "Average":64.49,
        "ARC":63.23,
        "HellaSwag":83.52,
        "MMLU":63.3,
        "TruthfulQA":49.22,
        "Winogrande":78.37,
        "GSM8K":49.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/openchat-3.5-1210-32k-8x7b-MoE",
        "Average":64.48,
        "ARC":64.59,
        "HellaSwag":84.07,
        "MMLU":61.6,
        "TruthfulQA":49.32,
        "Winogrande":79.16,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-0-2",
        "Average":64.47,
        "ARC":62.2,
        "HellaSwag":82.19,
        "MMLU":65.57,
        "TruthfulQA":47.63,
        "Winogrande":78.22,
        "GSM8K":51.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-llama-65b-v8-bf16",
        "Average":64.47,
        "ARC":62.8,
        "HellaSwag":83.6,
        "MMLU":62.01,
        "TruthfulQA":55.09,
        "Winogrande":79.95,
        "GSM8K":43.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":65.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/llama2-70b-oasst-sft-v10",
        "Average":64.47,
        "ARC":67.06,
        "HellaSwag":86.38,
        "MMLU":67.7,
        "TruthfulQA":56.45,
        "Winogrande":82.0,
        "GSM8K":27.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/Mistral-7b-instruct-v0.2-summ-sft-lp-e1",
        "Average":64.46,
        "ARC":61.01,
        "HellaSwag":83.32,
        "MMLU":60.62,
        "TruthfulQA":64.66,
        "Winogrande":76.95,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kwchoi\/DPO_mistral_7b_ultra_0124_v1",
        "Average":64.45,
        "ARC":66.13,
        "HellaSwag":86.39,
        "MMLU":59.78,
        "TruthfulQA":69.45,
        "Winogrande":79.48,
        "GSM8K":25.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AbacusResearch\/haLLAwa2",
        "Average":64.44,
        "ARC":63.31,
        "HellaSwag":84.51,
        "MMLU":63.52,
        "TruthfulQA":47.38,
        "Winogrande":75.85,
        "GSM8K":52.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.0",
        "Average":64.44,
        "ARC":60.75,
        "HellaSwag":81.87,
        "MMLU":63.13,
        "TruthfulQA":51.49,
        "Winogrande":76.32,
        "GSM8K":53.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.37,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/Starling-LM-11B-alpha-v1",
        "Average":64.44,
        "ARC":62.2,
        "HellaSwag":83.24,
        "MMLU":64.03,
        "TruthfulQA":45.7,
        "Winogrande":80.51,
        "GSM8K":50.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hedronstone\/OpenHermes-7B-Reasoner",
        "Average":64.44,
        "ARC":63.14,
        "HellaSwag":82.73,
        "MMLU":62.62,
        "TruthfulQA":48.82,
        "Winogrande":75.85,
        "GSM8K":53.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hedronstone\/OpenHermes-7B-Symbolic",
        "Average":64.44,
        "ARC":63.14,
        "HellaSwag":82.73,
        "MMLU":62.62,
        "TruthfulQA":48.82,
        "Winogrande":75.85,
        "GSM8K":53.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Medilora\/medilora-mistral-7b",
        "Average":64.41,
        "ARC":61.69,
        "HellaSwag":83.13,
        "MMLU":62.22,
        "TruthfulQA":49.91,
        "Winogrande":77.66,
        "GSM8K":51.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NeuralNovel\/Ignis-7B-DPO-Laser",
        "Average":64.41,
        "ARC":65.19,
        "HellaSwag":84.57,
        "MMLU":58.56,
        "TruthfulQA":66.24,
        "Winogrande":80.43,
        "GSM8K":31.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elinas\/chronos-70b-v2",
        "Average":64.41,
        "ARC":68.09,
        "HellaSwag":86.5,
        "MMLU":68.28,
        "TruthfulQA":53.7,
        "Winogrande":81.22,
        "GSM8K":28.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":70.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MRAIRR\/mini_7B_dare_v1",
        "Average":64.4,
        "ARC":61.77,
        "HellaSwag":79.91,
        "MMLU":59.55,
        "TruthfulQA":54.64,
        "Winogrande":73.95,
        "GSM8K":56.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Yi-34B-200K-AEZAKMI-XLCTX-v3",
        "Average":64.39,
        "ARC":64.85,
        "HellaSwag":84.76,
        "MMLU":74.48,
        "TruthfulQA":37.14,
        "Winogrande":81.06,
        "GSM8K":44.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xxyyy123\/Mistral-dpo-v1",
        "Average":64.39,
        "ARC":63.48,
        "HellaSwag":83.59,
        "MMLU":63.35,
        "TruthfulQA":50.49,
        "Winogrande":79.32,
        "GSM8K":46.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Hermetic-Platypus-C-2x7B",
        "Average":64.39,
        "ARC":58.96,
        "HellaSwag":82.77,
        "MMLU":62.08,
        "TruthfulQA":60.87,
        "Winogrande":77.74,
        "GSM8K":43.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/gemma-orchid-7b-dpo",
        "Average":64.37,
        "ARC":62.88,
        "HellaSwag":80.95,
        "MMLU":61.41,
        "TruthfulQA":53.27,
        "Winogrande":77.51,
        "GSM8K":50.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mahiatlinux\/MasherAI-7B-v3",
        "Average":64.36,
        "ARC":63.99,
        "HellaSwag":82.19,
        "MMLU":64.04,
        "TruthfulQA":47.63,
        "Winogrande":81.14,
        "GSM8K":47.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_9B_instruct_v0.2",
        "Average":64.32,
        "ARC":61.01,
        "HellaSwag":82.77,
        "MMLU":60.54,
        "TruthfulQA":63.9,
        "Winogrande":78.14,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":8.99,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/m.star.7b",
        "Average":64.32,
        "ARC":60.15,
        "HellaSwag":80.96,
        "MMLU":58.28,
        "TruthfulQA":53.93,
        "Winogrande":78.53,
        "GSM8K":54.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/Phigments12",
        "Average":64.31,
        "ARC":62.63,
        "HellaSwag":77.1,
        "MMLU":58.43,
        "TruthfulQA":51.71,
        "Winogrande":74.66,
        "GSM8K":61.33,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"v1olet\/v1olet_merged_dpo_7B_v4",
        "Average":64.3,
        "ARC":66.98,
        "HellaSwag":84.09,
        "MMLU":59.02,
        "TruthfulQA":59.43,
        "Winogrande":81.06,
        "GSM8K":35.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Einstein-bagel-7B",
        "Average":64.3,
        "ARC":66.89,
        "HellaSwag":84.81,
        "MMLU":63.48,
        "TruthfulQA":63.33,
        "Winogrande":79.16,
        "GSM8K":28.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Elly_7B",
        "Average":64.29,
        "ARC":63.57,
        "HellaSwag":83.48,
        "MMLU":62.8,
        "TruthfulQA":56.27,
        "Winogrande":78.77,
        "GSM8K":40.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"google\/gemma-7b",
        "Average":64.29,
        "ARC":61.09,
        "HellaSwag":82.47,
        "MMLU":66.03,
        "TruthfulQA":44.91,
        "Winogrande":78.45,
        "GSM8K":52.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":2702.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/gemma-7b-experiment",
        "Average":64.29,
        "ARC":61.09,
        "HellaSwag":82.47,
        "MMLU":66.03,
        "TruthfulQA":44.91,
        "Winogrande":78.45,
        "GSM8K":52.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/PiVoT-10.7B-Mistral-v0.2",
        "Average":64.25,
        "ARC":63.31,
        "HellaSwag":81.68,
        "MMLU":59.86,
        "TruthfulQA":58.23,
        "Winogrande":80.03,
        "GSM8K":42.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Hermetic-Platypus-D-2x7B",
        "Average":64.24,
        "ARC":58.87,
        "HellaSwag":82.89,
        "MMLU":61.96,
        "TruthfulQA":61.02,
        "Winogrande":77.43,
        "GSM8K":43.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Grafted-Hermetic-Platypus-A-2x7B",
        "Average":64.23,
        "ARC":59.3,
        "HellaSwag":82.89,
        "MMLU":62.0,
        "TruthfulQA":61.08,
        "Winogrande":77.66,
        "GSM8K":42.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"manishiitg\/open-aditi-hi-v4",
        "Average":64.23,
        "ARC":60.15,
        "HellaSwag":81.84,
        "MMLU":61.32,
        "TruthfulQA":44.89,
        "Winogrande":79.95,
        "GSM8K":57.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/mistral-7b-v0.1-layla-v4-chatml",
        "Average":64.22,
        "ARC":62.03,
        "HellaSwag":83.4,
        "MMLU":63.74,
        "TruthfulQA":43.03,
        "Winogrande":79.32,
        "GSM8K":53.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/Mistral-7b-instruct-v0.2-summ-sft-bf16-e1",
        "Average":64.22,
        "ARC":60.58,
        "HellaSwag":83.32,
        "MMLU":60.79,
        "TruthfulQA":64.72,
        "Winogrande":76.72,
        "GSM8K":39.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_420_preview",
        "Average":64.22,
        "ARC":67.06,
        "HellaSwag":87.26,
        "MMLU":69.85,
        "TruthfulQA":44.57,
        "Winogrande":83.35,
        "GSM8K":33.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/titanbagel",
        "Average":64.21,
        "ARC":62.71,
        "HellaSwag":83.36,
        "MMLU":63.12,
        "TruthfulQA":52.49,
        "Winogrande":79.08,
        "GSM8K":44.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yanolja\/KoSOLAR-10.7B-v0.2",
        "Average":64.2,
        "ARC":61.35,
        "HellaSwag":82.63,
        "MMLU":64.85,
        "TruthfulQA":47.94,
        "Winogrande":80.74,
        "GSM8K":47.69,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.7,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Neuronovo\/neuronovo-7B-v0.1",
        "Average":64.19,
        "ARC":66.98,
        "HellaSwag":85.07,
        "MMLU":63.33,
        "TruthfulQA":53.95,
        "Winogrande":78.14,
        "GSM8K":37.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"222limin\/Liph-36-imatwarwithmyself",
        "Average":64.19,
        "ARC":62.37,
        "HellaSwag":77.16,
        "MMLU":58.14,
        "TruthfulQA":52.28,
        "Winogrande":75.3,
        "GSM8K":59.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Platyboros-Instruct-7B",
        "Average":64.19,
        "ARC":57.76,
        "HellaSwag":82.59,
        "MMLU":62.05,
        "TruthfulQA":60.92,
        "Winogrande":78.14,
        "GSM8K":43.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-70b-gpt4-2.0",
        "Average":64.14,
        "ARC":68.52,
        "HellaSwag":87.89,
        "MMLU":70.41,
        "TruthfulQA":49.79,
        "Winogrande":83.5,
        "GSM8K":24.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":70.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhishekchohan\/Yi-9B-Forest-DPO-v1.0",
        "Average":64.11,
        "ARC":59.81,
        "HellaSwag":78.6,
        "MMLU":70.02,
        "TruthfulQA":50.98,
        "Winogrande":76.87,
        "GSM8K":48.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":9.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Einstein-v3-7B",
        "Average":64.09,
        "ARC":62.29,
        "HellaSwag":83.01,
        "MMLU":63.32,
        "TruthfulQA":51.18,
        "Winogrande":79.95,
        "GSM8K":44.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/Liph.42",
        "Average":64.08,
        "ARC":62.29,
        "HellaSwag":77.12,
        "MMLU":58.2,
        "TruthfulQA":52.08,
        "Winogrande":74.98,
        "GSM8K":59.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibndias\/NeuralHermes-MoE-2x7B",
        "Average":64.08,
        "ARC":62.12,
        "HellaSwag":84.21,
        "MMLU":64.56,
        "TruthfulQA":43.61,
        "Winogrande":78.14,
        "GSM8K":51.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Mocha-Dare-7b-ex",
        "Average":64.08,
        "ARC":61.26,
        "HellaSwag":81.6,
        "MMLU":60.77,
        "TruthfulQA":53.44,
        "Winogrande":73.8,
        "GSM8K":53.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/Herculoid-2.0",
        "Average":64.08,
        "ARC":62.88,
        "HellaSwag":83.93,
        "MMLU":64.03,
        "TruthfulQA":49.61,
        "Winogrande":80.03,
        "GSM8K":43.97,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zelus82\/Obelix-Phi2",
        "Average":64.07,
        "ARC":61.77,
        "HellaSwag":76.76,
        "MMLU":58.19,
        "TruthfulQA":51.29,
        "Winogrande":74.9,
        "GSM8K":61.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MSL7\/Liph.42-slerp",
        "Average":64.05,
        "ARC":62.54,
        "HellaSwag":77.12,
        "MMLU":58.2,
        "TruthfulQA":52.05,
        "Winogrande":74.9,
        "GSM8K":59.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e1",
        "Average":64.05,
        "ARC":59.3,
        "HellaSwag":83.64,
        "MMLU":60.31,
        "TruthfulQA":66.33,
        "Winogrande":76.09,
        "GSM8K":38.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Mistral-Instruct-7B-v0.2-ChatAlpaca-DPO2",
        "Average":64.05,
        "ARC":61.86,
        "HellaSwag":83.71,
        "MMLU":59.19,
        "TruthfulQA":64.08,
        "Winogrande":78.45,
        "GSM8K":37.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"altomek\/CodeRosa-70B-AB1",
        "Average":64.04,
        "ARC":65.53,
        "HellaSwag":83.16,
        "MMLU":59.87,
        "TruthfulQA":49.85,
        "Winogrande":81.29,
        "GSM8K":44.5,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ibm\/merlinite-7b",
        "Average":64.0,
        "ARC":63.65,
        "HellaSwag":84.52,
        "MMLU":64.91,
        "TruthfulQA":50.15,
        "Winogrande":79.72,
        "GSM8K":41.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":88.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"NeuralNovel\/Mini-Mixtral-v0.2",
        "Average":64.0,
        "ARC":61.26,
        "HellaSwag":84.12,
        "MMLU":63.83,
        "TruthfulQA":50.36,
        "Winogrande":78.85,
        "GSM8K":45.56,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Enoch\/llama-65b-hf",
        "Average":63.99,
        "ARC":63.31,
        "HellaSwag":86.09,
        "MMLU":63.84,
        "TruthfulQA":43.43,
        "Winogrande":82.48,
        "GSM8K":44.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LLaMAForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Steelskull\/Aurora_base_test",
        "Average":63.98,
        "ARC":62.88,
        "HellaSwag":83.99,
        "MMLU":60.24,
        "TruthfulQA":67.84,
        "Winogrande":76.4,
        "GSM8K":32.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Fewshot-Metamath-Mistral",
        "Average":63.96,
        "ARC":57.76,
        "HellaSwag":80.59,
        "MMLU":58.05,
        "TruthfulQA":43.04,
        "Winogrande":76.01,
        "GSM8K":68.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder45\/Mistral-7b-instruct-v0.2-summ-sft-dpo-e3",
        "Average":63.95,
        "ARC":58.87,
        "HellaSwag":83.56,
        "MMLU":60.37,
        "TruthfulQA":66.26,
        "Winogrande":76.32,
        "GSM8K":38.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Gemma-10.2B-Coder",
        "Average":63.94,
        "ARC":58.7,
        "HellaSwag":82.04,
        "MMLU":61.96,
        "TruthfulQA":52.44,
        "Winogrande":78.37,
        "GSM8K":50.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.2,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/gemma-7b-ultrachat-sft",
        "Average":63.92,
        "ARC":61.26,
        "HellaSwag":80.82,
        "MMLU":64.16,
        "TruthfulQA":54.5,
        "Winogrande":78.14,
        "GSM8K":44.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Novocoders\/Mistral-NeuralDPO-v0.4-Laser",
        "Average":63.89,
        "ARC":66.89,
        "HellaSwag":85.23,
        "MMLU":63.47,
        "TruthfulQA":50.91,
        "Winogrande":80.27,
        "GSM8K":36.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"silvercoder67\/Mistral-7b-instruct-v0.2-summ-sft-e2m",
        "Average":63.86,
        "ARC":59.47,
        "HellaSwag":83.34,
        "MMLU":60.53,
        "TruthfulQA":63.78,
        "Winogrande":76.48,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cgato\/TheSpice-7b-FT-ExperimentalOrca",
        "Average":63.86,
        "ARC":62.63,
        "HellaSwag":84.26,
        "MMLU":63.33,
        "TruthfulQA":54.87,
        "Winogrande":79.87,
        "GSM8K":38.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Novocoders\/Mistral-NeuralDPO-v0.4",
        "Average":63.85,
        "ARC":66.04,
        "HellaSwag":85.18,
        "MMLU":63.57,
        "TruthfulQA":51.32,
        "Winogrande":80.11,
        "GSM8K":36.85,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Steelskull\/VerB-Etheria-55b",
        "Average":63.83,
        "ARC":65.96,
        "HellaSwag":81.48,
        "MMLU":73.78,
        "TruthfulQA":57.52,
        "Winogrande":75.45,
        "GSM8K":28.81,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":55.59,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zelus82\/Obelix-Phi2",
        "Average":63.83,
        "ARC":61.6,
        "HellaSwag":76.68,
        "MMLU":58.14,
        "TruthfulQA":50.79,
        "Winogrande":74.59,
        "GSM8K":61.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"openbmb\/UltraLM-65b",
        "Average":63.82,
        "ARC":67.06,
        "HellaSwag":84.98,
        "MMLU":63.48,
        "TruthfulQA":53.51,
        "Winogrande":81.14,
        "GSM8K":32.75,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":65.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Hermes-Instruct-7B-v0.2",
        "Average":63.82,
        "ARC":60.92,
        "HellaSwag":82.96,
        "MMLU":60.05,
        "TruthfulQA":61.01,
        "Winogrande":76.87,
        "GSM8K":41.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Medilora\/medilora-qwen-14b",
        "Average":63.81,
        "ARC":56.66,
        "HellaSwag":79.08,
        "MMLU":65.86,
        "TruthfulQA":47.75,
        "Winogrande":74.9,
        "GSM8K":58.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/14B",
        "Average":63.81,
        "ARC":56.66,
        "HellaSwag":79.08,
        "MMLU":65.86,
        "TruthfulQA":47.75,
        "Winogrande":74.9,
        "GSM8K":58.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":14.0,
        "Model Sha":279.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/CausalLM-Platypus-14B",
        "Average":63.8,
        "ARC":56.91,
        "HellaSwag":80.06,
        "MMLU":64.98,
        "TruthfulQA":47.57,
        "Winogrande":76.01,
        "GSM8K":57.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/mistral-inst-ppo",
        "Average":63.79,
        "ARC":62.37,
        "HellaSwag":83.2,
        "MMLU":60.86,
        "TruthfulQA":62.3,
        "Winogrande":76.95,
        "GSM8K":37.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-summ-ia3-tuned",
        "Average":63.79,
        "ARC":59.64,
        "HellaSwag":84.71,
        "MMLU":59.48,
        "TruthfulQA":68.6,
        "Winogrande":76.72,
        "GSM8K":33.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/mistral-7b-zephyr-sft",
        "Average":63.79,
        "ARC":62.29,
        "HellaSwag":84.88,
        "MMLU":62.29,
        "TruthfulQA":53.07,
        "Winogrande":77.98,
        "GSM8K":42.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jae24\/openhermes_dpo_norobot_0201",
        "Average":63.78,
        "ARC":62.03,
        "HellaSwag":83.4,
        "MMLU":62.4,
        "TruthfulQA":47.44,
        "Winogrande":78.22,
        "GSM8K":49.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Mewthree_7B",
        "Average":63.78,
        "ARC":65.78,
        "HellaSwag":85.74,
        "MMLU":62.56,
        "TruthfulQA":65.85,
        "Winogrande":78.85,
        "GSM8K":23.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mobidic\/solar-10b-platypus-lora",
        "Average":63.77,
        "ARC":62.2,
        "HellaSwag":84.16,
        "MMLU":63.23,
        "TruthfulQA":52.7,
        "Winogrande":82.56,
        "GSM8K":37.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheSkullery\/Aurora_19e_Test",
        "Average":63.76,
        "ARC":59.3,
        "HellaSwag":83.74,
        "MMLU":61.45,
        "TruthfulQA":47.46,
        "Winogrande":75.93,
        "GSM8K":54.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":10.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhishekchohan\/mistral-7B-med-merge",
        "Average":63.75,
        "ARC":64.51,
        "HellaSwag":82.96,
        "MMLU":57.84,
        "TruthfulQA":53.65,
        "Winogrande":78.61,
        "GSM8K":44.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"google\/gemma-7b",
        "Average":63.75,
        "ARC":61.09,
        "HellaSwag":82.2,
        "MMLU":64.56,
        "TruthfulQA":44.79,
        "Winogrande":79.01,
        "GSM8K":50.87,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":2702.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"avinash31d\/phi-2-slerp",
        "Average":63.74,
        "ARC":62.54,
        "HellaSwag":76.04,
        "MMLU":57.6,
        "TruthfulQA":49.15,
        "Winogrande":75.85,
        "GSM8K":61.26,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"N8Programs\/Thestral-v0.2",
        "Average":63.74,
        "ARC":62.71,
        "HellaSwag":82.49,
        "MMLU":62.73,
        "TruthfulQA":52.77,
        "Winogrande":75.77,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"fhai50032\/xLakeChat",
        "Average":63.72,
        "ARC":62.37,
        "HellaSwag":82.64,
        "MMLU":59.32,
        "TruthfulQA":52.96,
        "Winogrande":74.74,
        "GSM8K":50.27,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TigerResearch\/tigerbot-70b-base",
        "Average":63.71,
        "ARC":62.46,
        "HellaSwag":83.61,
        "MMLU":65.49,
        "TruthfulQA":52.76,
        "Winogrande":80.19,
        "GSM8K":37.76,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":68.95,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-SPIN-iter3",
        "Average":63.7,
        "ARC":66.13,
        "HellaSwag":85.85,
        "MMLU":61.51,
        "TruthfulQA":57.89,
        "Winogrande":76.64,
        "GSM8K":34.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/test_final",
        "Average":63.7,
        "ARC":66.13,
        "HellaSwag":85.85,
        "MMLU":61.51,
        "TruthfulQA":57.89,
        "Winogrande":76.64,
        "GSM8K":34.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-SOLAR-11b-v3.0",
        "Average":63.69,
        "ARC":62.29,
        "HellaSwag":84.93,
        "MMLU":65.48,
        "TruthfulQA":52.9,
        "Winogrande":82.87,
        "GSM8K":33.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Mocha-SR-7b-ex",
        "Average":63.69,
        "ARC":59.81,
        "HellaSwag":81.24,
        "MMLU":60.87,
        "TruthfulQA":54.72,
        "Winogrande":73.09,
        "GSM8K":52.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheSkullery\/Aurora_25e_Test",
        "Average":63.68,
        "ARC":59.64,
        "HellaSwag":84.29,
        "MMLU":61.7,
        "TruthfulQA":47.26,
        "Winogrande":76.64,
        "GSM8K":52.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":11.6,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rhysjones\/phi-2-orange-v2",
        "Average":63.67,
        "ARC":61.86,
        "HellaSwag":76.32,
        "MMLU":55.72,
        "TruthfulQA":54.84,
        "Winogrande":75.69,
        "GSM8K":57.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Delcos\/Starling-LM-11B-alpha",
        "Average":63.66,
        "ARC":62.97,
        "HellaSwag":84.85,
        "MMLU":63.83,
        "TruthfulQA":54.52,
        "Winogrande":77.82,
        "GSM8K":37.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":11.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/gpt4-alpaca-lora_mlp-65B-HF",
        "Average":63.66,
        "ARC":65.02,
        "HellaSwag":86.13,
        "MMLU":62.73,
        "TruthfulQA":59.16,
        "Winogrande":80.66,
        "GSM8K":28.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pandego\/my-first-blend",
        "Average":63.66,
        "ARC":69.37,
        "HellaSwag":83.03,
        "MMLU":53.91,
        "TruthfulQA":70.7,
        "Winogrande":79.32,
        "GSM8K":25.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/Mistral-Instruct-Ukrainian-SFT-DPO",
        "Average":63.64,
        "ARC":60.49,
        "HellaSwag":83.84,
        "MMLU":60.9,
        "TruthfulQA":57.91,
        "Winogrande":76.95,
        "GSM8K":41.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"pandego\/my-first-blend",
        "Average":63.64,
        "ARC":69.8,
        "HellaSwag":82.93,
        "MMLU":53.89,
        "TruthfulQA":70.68,
        "Winogrande":79.4,
        "GSM8K":25.17,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"monology\/openinstruct-mistral-7b",
        "Average":63.64,
        "ARC":59.73,
        "HellaSwag":82.77,
        "MMLU":60.55,
        "TruthfulQA":48.76,
        "Winogrande":79.56,
        "GSM8K":50.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Kaiju-A-57B",
        "Average":63.64,
        "ARC":58.79,
        "HellaSwag":80.95,
        "MMLU":72.66,
        "TruthfulQA":52.29,
        "Winogrande":78.77,
        "GSM8K":38.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":57.26,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/xLakeChat",
        "Average":63.64,
        "ARC":62.54,
        "HellaSwag":82.66,
        "MMLU":59.19,
        "TruthfulQA":53.02,
        "Winogrande":74.51,
        "GSM8K":49.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Epiculous\/Mika-7B",
        "Average":63.63,
        "ARC":63.48,
        "HellaSwag":85.44,
        "MMLU":59.85,
        "TruthfulQA":69.57,
        "Winogrande":74.9,
        "GSM8K":28.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v4-mistral-7b",
        "Average":63.61,
        "ARC":62.03,
        "HellaSwag":82.9,
        "MMLU":62.48,
        "TruthfulQA":53.84,
        "Winogrande":77.27,
        "GSM8K":43.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-code-mistral-7b-v1.0",
        "Average":63.6,
        "ARC":61.18,
        "HellaSwag":83.77,
        "MMLU":63.4,
        "TruthfulQA":47.9,
        "Winogrande":78.37,
        "GSM8K":47.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/higgs-llama-vicuna-ep25-70b",
        "Average":63.6,
        "ARC":62.29,
        "HellaSwag":86.07,
        "MMLU":64.25,
        "TruthfulQA":53.75,
        "Winogrande":80.66,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hercules-2.5-Mistral-7B",
        "Average":63.59,
        "ARC":62.03,
        "HellaSwag":83.79,
        "MMLU":63.49,
        "TruthfulQA":43.44,
        "Winogrande":79.72,
        "GSM8K":49.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/phigment6-slerp",
        "Average":63.58,
        "ARC":62.63,
        "HellaSwag":77.25,
        "MMLU":58.65,
        "TruthfulQA":50.49,
        "Winogrande":73.88,
        "GSM8K":58.61,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Mistral-NeuralDPO-v0.2",
        "Average":63.58,
        "ARC":67.06,
        "HellaSwag":85.01,
        "MMLU":62.68,
        "TruthfulQA":48.73,
        "Winogrande":81.29,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-7b",
        "Average":63.57,
        "ARC":56.06,
        "HellaSwag":77.36,
        "MMLU":61.29,
        "TruthfulQA":54.29,
        "Winogrande":72.38,
        "GSM8K":60.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dreamgen\/opus-v1.2-7b",
        "Average":63.56,
        "ARC":58.45,
        "HellaSwag":82.58,
        "MMLU":61.76,
        "TruthfulQA":60.34,
        "Winogrande":77.27,
        "GSM8K":40.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/test-test",
        "Average":63.54,
        "ARC":66.47,
        "HellaSwag":85.82,
        "MMLU":61.48,
        "TruthfulQA":57.75,
        "Winogrande":76.95,
        "GSM8K":32.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/Kaori-34B-v1",
        "Average":63.52,
        "ARC":64.51,
        "HellaSwag":79.65,
        "MMLU":70.19,
        "TruthfulQA":53.14,
        "Winogrande":76.95,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/test-test",
        "Average":63.52,
        "ARC":66.38,
        "HellaSwag":85.84,
        "MMLU":61.22,
        "TruthfulQA":57.82,
        "Winogrande":76.8,
        "GSM8K":33.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-SPIN-iter2",
        "Average":63.52,
        "ARC":66.38,
        "HellaSwag":85.84,
        "MMLU":61.22,
        "TruthfulQA":57.82,
        "Winogrande":76.8,
        "GSM8K":33.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Falkor-16b",
        "Average":63.52,
        "ARC":65.96,
        "HellaSwag":82.62,
        "MMLU":63.58,
        "TruthfulQA":62.77,
        "Winogrande":77.9,
        "GSM8K":28.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SUSTech\/SUS-Chat-72B",
        "Average":63.51,
        "ARC":66.3,
        "HellaSwag":84.96,
        "MMLU":76.7,
        "TruthfulQA":60.27,
        "Winogrande":83.43,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"alignment-handbook\/zephyr-7b-dpo-qlora",
        "Average":63.51,
        "ARC":63.65,
        "HellaSwag":85.35,
        "MMLU":63.82,
        "TruthfulQA":47.14,
        "Winogrande":79.01,
        "GSM8K":42.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_18B_instruct_v0.1",
        "Average":63.5,
        "ARC":56.91,
        "HellaSwag":81.36,
        "MMLU":60.52,
        "TruthfulQA":64.85,
        "Winogrande":77.03,
        "GSM8K":40.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":17.71,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"argilla\/notus-7b-v1",
        "Average":63.49,
        "ARC":64.59,
        "HellaSwag":84.83,
        "MMLU":63.04,
        "TruthfulQA":54.35,
        "Winogrande":79.56,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Einstein-v2-7B",
        "Average":63.48,
        "ARC":62.37,
        "HellaSwag":83.46,
        "MMLU":62.08,
        "TruthfulQA":50.52,
        "Winogrande":79.32,
        "GSM8K":43.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tuantran1632001\/Psyfighter2-Orca2-ties",
        "Average":63.48,
        "ARC":62.46,
        "HellaSwag":81.74,
        "MMLU":60.31,
        "TruthfulQA":55.4,
        "Winogrande":77.27,
        "GSM8K":43.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tuantran1632001\/Psyfighter2-Orca2-13B-ties",
        "Average":63.48,
        "ARC":62.46,
        "HellaSwag":81.74,
        "MMLU":60.31,
        "TruthfulQA":55.4,
        "Winogrande":77.27,
        "GSM8K":43.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/Kaori-34B-v1",
        "Average":63.47,
        "ARC":64.42,
        "HellaSwag":79.61,
        "MMLU":70.24,
        "TruthfulQA":53.17,
        "Winogrande":76.72,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest",
        "Average":63.47,
        "ARC":65.7,
        "HellaSwag":86.26,
        "MMLU":63.32,
        "TruthfulQA":53.32,
        "Winogrande":79.48,
        "GSM8K":32.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"delayedkarma\/NeuralHermes-2.5-Mistral-7B",
        "Average":63.47,
        "ARC":66.55,
        "HellaSwag":85.0,
        "MMLU":63.41,
        "TruthfulQA":53.83,
        "Winogrande":77.98,
        "GSM8K":34.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zelus82\/Obelix-Phi2-v0",
        "Average":63.46,
        "ARC":63.4,
        "HellaSwag":76.66,
        "MMLU":58.21,
        "TruthfulQA":48.78,
        "Winogrande":75.06,
        "GSM8K":58.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dreamgen\/opus-v1.2-7b",
        "Average":63.46,
        "ARC":58.45,
        "HellaSwag":82.55,
        "MMLU":61.79,
        "TruthfulQA":60.27,
        "Winogrande":77.11,
        "GSM8K":40.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Stopwolf\/Cerberus-7B-slerp",
        "Average":63.46,
        "ARC":69.54,
        "HellaSwag":87.33,
        "MMLU":63.25,
        "TruthfulQA":61.35,
        "Winogrande":81.29,
        "GSM8K":17.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AI-B\/UTENA-7B-NSFW-V2",
        "Average":63.45,
        "ARC":63.31,
        "HellaSwag":84.54,
        "MMLU":63.97,
        "TruthfulQA":47.81,
        "Winogrande":78.69,
        "GSM8K":42.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"unlicense",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"0-hero\/Matter-0.1-Slim-7B-C-DPO",
        "Average":63.44,
        "ARC":63.48,
        "HellaSwag":83.12,
        "MMLU":60.63,
        "TruthfulQA":46.53,
        "Winogrande":78.45,
        "GSM8K":48.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cgato\/Thespis-Krangled-7b-v2",
        "Average":63.44,
        "ARC":62.88,
        "HellaSwag":83.04,
        "MMLU":62.44,
        "TruthfulQA":53.02,
        "Winogrande":77.9,
        "GSM8K":41.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeroyDyer\/Mixtral_AI_Cyber_2.0",
        "Average":63.43,
        "ARC":60.75,
        "HellaSwag":82.5,
        "MMLU":60.03,
        "TruthfulQA":57.58,
        "Winogrande":77.74,
        "GSM8K":42.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xxyyy123\/Mistral7B_adaptor_v1",
        "Average":63.42,
        "ARC":62.97,
        "HellaSwag":83.81,
        "MMLU":63.56,
        "TruthfulQA":49.77,
        "Winogrande":79.16,
        "GSM8K":41.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-16B-v2.01",
        "Average":63.42,
        "ARC":65.36,
        "HellaSwag":82.92,
        "MMLU":63.27,
        "TruthfulQA":64.53,
        "Winogrande":79.08,
        "GSM8K":25.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0-hero\/Matter-0.1-7B",
        "Average":63.39,
        "ARC":61.77,
        "HellaSwag":82.14,
        "MMLU":62.42,
        "TruthfulQA":42.44,
        "Winogrande":77.82,
        "GSM8K":53.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llm-agents\/tora-70b-v1.0",
        "Average":63.39,
        "ARC":67.75,
        "HellaSwag":85.83,
        "MMLU":69.22,
        "TruthfulQA":51.79,
        "Winogrande":81.93,
        "GSM8K":23.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Mini_Synatra_SFT",
        "Average":63.39,
        "ARC":62.46,
        "HellaSwag":83.44,
        "MMLU":61.2,
        "TruthfulQA":53.67,
        "Winogrande":74.66,
        "GSM8K":44.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ozayezerceli\/Threnystril-2x7B-moe",
        "Average":63.37,
        "ARC":52.82,
        "HellaSwag":73.36,
        "MMLU":63.83,
        "TruthfulQA":52.71,
        "Winogrande":78.85,
        "GSM8K":58.68,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xxyyy123\/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
        "Average":63.37,
        "ARC":62.88,
        "HellaSwag":83.99,
        "MMLU":62.89,
        "TruthfulQA":50.55,
        "Winogrande":79.72,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/GALAXY-XB-v.03",
        "Average":63.37,
        "ARC":61.77,
        "HellaSwag":83.59,
        "MMLU":64.55,
        "TruthfulQA":44.19,
        "Winogrande":81.06,
        "GSM8K":45.03,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":15.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xDAN-AI\/xDAN-L1Mix-DeepThinking-v2",
        "Average":63.36,
        "ARC":62.37,
        "HellaSwag":82.32,
        "MMLU":59.69,
        "TruthfulQA":55.38,
        "Winogrande":76.4,
        "GSM8K":43.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liminerity\/Blur-7b-v1.22",
        "Average":63.35,
        "ARC":62.29,
        "HellaSwag":82.0,
        "MMLU":58.03,
        "TruthfulQA":68.01,
        "Winogrande":78.61,
        "GSM8K":31.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"malhajar\/Mistral-7B-v0.2-meditron-turkish",
        "Average":63.34,
        "ARC":59.56,
        "HellaSwag":81.79,
        "MMLU":60.35,
        "TruthfulQA":66.19,
        "Winogrande":76.24,
        "GSM8K":35.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama_9b_long",
        "Average":63.33,
        "ARC":60.07,
        "HellaSwag":78.67,
        "MMLU":70.53,
        "TruthfulQA":45.95,
        "Winogrande":76.64,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":9.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/OpenHermes-2.5-Code-290k-13B",
        "Average":63.33,
        "ARC":57.34,
        "HellaSwag":80.48,
        "MMLU":56.53,
        "TruthfulQA":52.5,
        "Winogrande":74.82,
        "GSM8K":58.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/Blur-7b-v1.22",
        "Average":63.3,
        "ARC":62.12,
        "HellaSwag":82.09,
        "MMLU":57.9,
        "TruthfulQA":67.96,
        "Winogrande":78.69,
        "GSM8K":31.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama_9b_long",
        "Average":63.3,
        "ARC":60.32,
        "HellaSwag":78.62,
        "MMLU":70.5,
        "TruthfulQA":45.91,
        "Winogrande":76.48,
        "GSM8K":47.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":9.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mobiuslabsgmbh\/aanaphi2-v0.1",
        "Average":63.28,
        "ARC":63.91,
        "HellaSwag":77.97,
        "MMLU":57.73,
        "TruthfulQA":51.56,
        "Winogrande":73.64,
        "GSM8K":54.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest-dpo",
        "Average":63.28,
        "ARC":65.02,
        "HellaSwag":86.31,
        "MMLU":63.05,
        "TruthfulQA":55.43,
        "Winogrande":79.56,
        "GSM8K":30.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e1",
        "Average":63.28,
        "ARC":60.15,
        "HellaSwag":82.59,
        "MMLU":58.92,
        "TruthfulQA":63.13,
        "Winogrande":77.11,
        "GSM8K":37.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vilm\/Quyen-Plus-v0.1",
        "Average":63.27,
        "ARC":55.72,
        "HellaSwag":78.52,
        "MMLU":60.45,
        "TruthfulQA":53.6,
        "Winogrande":71.27,
        "GSM8K":60.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Gecko-7B-v0.1-DPO",
        "Average":63.22,
        "ARC":56.74,
        "HellaSwag":82.38,
        "MMLU":60.42,
        "TruthfulQA":57.42,
        "Winogrande":77.35,
        "GSM8K":45.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0-hero\/Matter-0.1-7B-boost",
        "Average":63.22,
        "ARC":62.63,
        "HellaSwag":81.51,
        "MMLU":61.97,
        "TruthfulQA":54.7,
        "Winogrande":75.93,
        "GSM8K":42.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chanwit\/flux-base-optimized",
        "Average":63.22,
        "ARC":65.44,
        "HellaSwag":81.74,
        "MMLU":59.74,
        "TruthfulQA":50.02,
        "Winogrande":77.74,
        "GSM8K":44.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Aeryth-7B-v0.1",
        "Average":63.19,
        "ARC":60.32,
        "HellaSwag":83.53,
        "MMLU":60.97,
        "TruthfulQA":63.57,
        "Winogrande":74.66,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Deci\/DeciLM-7B-instruct",
        "Average":63.19,
        "ARC":61.01,
        "HellaSwag":82.37,
        "MMLU":60.24,
        "TruthfulQA":49.75,
        "Winogrande":79.72,
        "GSM8K":46.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"DeciLMForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.04,
        "Model Sha":94.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liuda1\/dm7b_sft_gpt88w_merge",
        "Average":63.18,
        "ARC":62.29,
        "HellaSwag":82.47,
        "MMLU":61.35,
        "TruthfulQA":53.33,
        "Winogrande":77.58,
        "GSM8K":42.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/kaori-34b-v3",
        "Average":63.18,
        "ARC":64.25,
        "HellaSwag":79.59,
        "MMLU":70.18,
        "TruthfulQA":52.37,
        "Winogrande":76.48,
        "GSM8K":36.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"01-ai\/Yi-34B-Chat",
        "Average":63.17,
        "ARC":65.1,
        "HellaSwag":84.08,
        "MMLU":74.87,
        "TruthfulQA":55.41,
        "Winogrande":79.79,
        "GSM8K":19.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.39,
        "Model Sha":303.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"01-ai\/Yi-9B",
        "Average":63.17,
        "ARC":61.18,
        "HellaSwag":78.82,
        "MMLU":70.06,
        "TruthfulQA":42.45,
        "Winogrande":77.51,
        "GSM8K":48.98,
        "Type":"continuously pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.83,
        "Model Sha":170.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jeiku\/Soulful_Bepis_7B",
        "Average":63.15,
        "ARC":63.82,
        "HellaSwag":80.69,
        "MMLU":62.53,
        "TruthfulQA":56.65,
        "Winogrande":76.16,
        "GSM8K":39.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e3",
        "Average":63.14,
        "ARC":59.98,
        "HellaSwag":82.76,
        "MMLU":59.48,
        "TruthfulQA":63.0,
        "Winogrande":76.24,
        "GSM8K":37.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decem\/Dionysus-Mistral-m3-v5",
        "Average":63.14,
        "ARC":59.56,
        "HellaSwag":80.99,
        "MMLU":61.18,
        "TruthfulQA":50.93,
        "Winogrande":75.14,
        "GSM8K":51.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/Mistral-7b-instruct-v0.2-summ-sft-lp-e1",
        "Average":63.13,
        "ARC":59.56,
        "HellaSwag":82.27,
        "MMLU":59.12,
        "TruthfulQA":63.26,
        "Winogrande":77.03,
        "GSM8K":37.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kiddyz\/testllm-c2",
        "Average":63.13,
        "ARC":60.58,
        "HellaSwag":81.91,
        "MMLU":61.2,
        "TruthfulQA":49.87,
        "Winogrande":77.82,
        "GSM8K":47.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chanwit\/flux-base-optimized",
        "Average":63.12,
        "ARC":65.53,
        "HellaSwag":81.76,
        "MMLU":59.84,
        "TruthfulQA":50.03,
        "Winogrande":77.35,
        "GSM8K":44.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kaitchup\/Maixtchup-4x7b-QLoRA-SFT-UltraChat",
        "Average":63.11,
        "ARC":60.92,
        "HellaSwag":83.23,
        "MMLU":60.78,
        "TruthfulQA":53.33,
        "Winogrande":77.19,
        "GSM8K":43.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"KnutJaegersberg\/Qwen-14B-Llamafied",
        "Average":63.09,
        "ARC":55.2,
        "HellaSwag":82.31,
        "MMLU":66.11,
        "TruthfulQA":45.6,
        "Winogrande":76.56,
        "GSM8K":52.77,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"saishf\/Fett-uccine-11B-Experiment",
        "Average":63.09,
        "ARC":63.14,
        "HellaSwag":85.39,
        "MMLU":59.72,
        "TruthfulQA":69.92,
        "Winogrande":74.59,
        "GSM8K":25.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"agpl-3.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tourist800\/mistral_2X7b",
        "Average":63.08,
        "ARC":63.4,
        "HellaSwag":83.77,
        "MMLU":61.18,
        "TruthfulQA":52.08,
        "Winogrande":77.9,
        "GSM8K":40.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tourist800\/Marcoro14-7B-slerp",
        "Average":63.08,
        "ARC":63.4,
        "HellaSwag":83.77,
        "MMLU":61.18,
        "TruthfulQA":52.08,
        "Winogrande":77.9,
        "GSM8K":40.18,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"INSAIT-Institute\/BgGPT-7B-Instruct-v0.2",
        "Average":63.08,
        "ARC":60.58,
        "HellaSwag":82.18,
        "MMLU":60.5,
        "TruthfulQA":54.63,
        "Winogrande":76.48,
        "GSM8K":44.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.29,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pinkyponky\/Mistral-7b-instruct-v0.2-summ-sft-e2",
        "Average":63.06,
        "ARC":59.47,
        "HellaSwag":82.72,
        "MMLU":59.48,
        "TruthfulQA":62.7,
        "Winogrande":76.64,
        "GSM8K":37.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-falcon-180b-v12-preview0",
        "Average":63.06,
        "ARC":62.29,
        "HellaSwag":83.8,
        "MMLU":55.92,
        "TruthfulQA":53.05,
        "Winogrande":82.08,
        "GSM8K":41.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":180.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maldv\/SHRDFU-7b-overbaked-lora",
        "Average":63.05,
        "ARC":64.33,
        "HellaSwag":83.46,
        "MMLU":62.42,
        "TruthfulQA":50.98,
        "Winogrande":78.69,
        "GSM8K":38.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalleorg\/OpenHermes-Yi-9B",
        "Average":63.05,
        "ARC":60.67,
        "HellaSwag":78.73,
        "MMLU":69.67,
        "TruthfulQA":42.25,
        "Winogrande":77.19,
        "GSM8K":49.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_15B_instruct_v0.1",
        "Average":63.04,
        "ARC":58.45,
        "HellaSwag":81.71,
        "MMLU":59.82,
        "TruthfulQA":63.43,
        "Winogrande":76.24,
        "GSM8K":38.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Novocoders\/Mistral-NeuralDPO-v0.6",
        "Average":63.04,
        "ARC":65.87,
        "HellaSwag":84.68,
        "MMLU":62.19,
        "TruthfulQA":48.22,
        "Winogrande":80.27,
        "GSM8K":37.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maywell\/PiVoT-MoE",
        "Average":63.04,
        "ARC":63.91,
        "HellaSwag":83.52,
        "MMLU":60.71,
        "TruthfulQA":54.64,
        "Winogrande":76.32,
        "GSM8K":39.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":36.1,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Airoboros-L2-70B-2.1-GPTQ",
        "Average":63.04,
        "ARC":70.39,
        "HellaSwag":86.54,
        "MMLU":68.89,
        "TruthfulQA":55.55,
        "Winogrande":81.61,
        "GSM8K":15.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":72.82,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/Blitz-v0.1",
        "Average":63.03,
        "ARC":55.2,
        "HellaSwag":82.5,
        "MMLU":61.33,
        "TruthfulQA":60.77,
        "Winogrande":77.43,
        "GSM8K":40.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-3.0-Mistral-7B-DPO",
        "Average":63.03,
        "ARC":60.67,
        "HellaSwag":83.95,
        "MMLU":62.71,
        "TruthfulQA":46.17,
        "Winogrande":79.32,
        "GSM8K":45.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v3-mistral-7b",
        "Average":62.95,
        "ARC":60.49,
        "HellaSwag":81.9,
        "MMLU":61.35,
        "TruthfulQA":50.31,
        "Winogrande":76.95,
        "GSM8K":46.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cgato\/Thespis-7b-v0.2-SFTTest-3Epoch",
        "Average":62.94,
        "ARC":63.23,
        "HellaSwag":84.39,
        "MMLU":62.59,
        "TruthfulQA":53.9,
        "Winogrande":77.51,
        "GSM8K":36.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-zephyr-code-functionary-7b",
        "Average":62.93,
        "ARC":61.52,
        "HellaSwag":83.88,
        "MMLU":64.71,
        "TruthfulQA":44.99,
        "Winogrande":78.69,
        "GSM8K":43.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/dolphin-2.6-mistral-7b-dpo-orca-v3",
        "Average":62.93,
        "ARC":66.3,
        "HellaSwag":84.53,
        "MMLU":62.36,
        "TruthfulQA":61.29,
        "Winogrande":77.58,
        "GSM8K":25.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-gemma-7b",
        "Average":62.93,
        "ARC":62.12,
        "HellaSwag":79.77,
        "MMLU":61.57,
        "TruthfulQA":49.41,
        "Winogrande":75.45,
        "GSM8K":49.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Inv\/Elbrus-7B",
        "Average":62.93,
        "ARC":63.99,
        "HellaSwag":83.96,
        "MMLU":63.06,
        "TruthfulQA":44.34,
        "Winogrande":79.72,
        "GSM8K":42.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mervinpraison\/tamil-large-language-model-7b-v1.0",
        "Average":62.92,
        "ARC":60.15,
        "HellaSwag":82.21,
        "MMLU":63.9,
        "TruthfulQA":45.09,
        "Winogrande":77.51,
        "GSM8K":48.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/AthenaImaniMaven",
        "Average":62.92,
        "ARC":62.8,
        "HellaSwag":84.56,
        "MMLU":59.1,
        "TruthfulQA":58.5,
        "Winogrande":77.43,
        "GSM8K":35.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/CollectiveCognition-v1.1-Mistral-7B",
        "Average":62.92,
        "ARC":62.12,
        "HellaSwag":84.17,
        "MMLU":62.35,
        "TruthfulQA":57.62,
        "Winogrande":75.37,
        "GSM8K":35.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nasiruddin15\/Mistral-grok-instract-2-7B-slerp",
        "Average":62.87,
        "ARC":62.8,
        "HellaSwag":83.03,
        "MMLU":61.04,
        "TruthfulQA":53.51,
        "Winogrande":76.95,
        "GSM8K":39.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/GALAXY-XB-v.01",
        "Average":62.87,
        "ARC":60.92,
        "HellaSwag":82.92,
        "MMLU":65.11,
        "TruthfulQA":43.67,
        "Winogrande":81.14,
        "GSM8K":43.44,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":17.71,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_18B_v0.1",
        "Average":62.86,
        "ARC":62.54,
        "HellaSwag":79.93,
        "MMLU":61.98,
        "TruthfulQA":57.32,
        "Winogrande":77.27,
        "GSM8K":38.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":17.71,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-spin-iter1",
        "Average":62.86,
        "ARC":65.87,
        "HellaSwag":85.44,
        "MMLU":60.95,
        "TruthfulQA":57.39,
        "Winogrande":76.64,
        "GSM8K":30.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-SPIN-iter1",
        "Average":62.86,
        "ARC":65.87,
        "HellaSwag":85.44,
        "MMLU":60.95,
        "TruthfulQA":57.39,
        "Winogrande":76.64,
        "GSM8K":30.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/test",
        "Average":62.86,
        "ARC":65.87,
        "HellaSwag":85.44,
        "MMLU":60.95,
        "TruthfulQA":57.39,
        "Winogrande":76.64,
        "GSM8K":30.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/AthenaImaniMaven",
        "Average":62.85,
        "ARC":62.63,
        "HellaSwag":84.65,
        "MMLU":59.05,
        "TruthfulQA":58.58,
        "Winogrande":77.19,
        "GSM8K":35.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aari1995\/germeo-7b-laser",
        "Average":62.82,
        "ARC":60.75,
        "HellaSwag":82.81,
        "MMLU":60.57,
        "TruthfulQA":53.83,
        "Winogrande":75.61,
        "GSM8K":43.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upaya07\/Birbal-7B-V1",
        "Average":62.82,
        "ARC":62.88,
        "HellaSwag":84.88,
        "MMLU":63.71,
        "TruthfulQA":45.46,
        "Winogrande":78.53,
        "GSM8K":41.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/MelangeA-70b",
        "Average":62.82,
        "ARC":71.25,
        "HellaSwag":87.3,
        "MMLU":70.56,
        "TruthfulQA":60.61,
        "Winogrande":81.53,
        "GSM8K":5.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":68.98,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/travel-mistral-7B-16b-base",
        "Average":62.82,
        "ARC":61.43,
        "HellaSwag":83.51,
        "MMLU":62.55,
        "TruthfulQA":53.23,
        "Winogrande":78.53,
        "GSM8K":37.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v17.3-32k",
        "Average":62.81,
        "ARC":64.51,
        "HellaSwag":66.96,
        "MMLU":70.0,
        "TruthfulQA":59.14,
        "Winogrande":68.11,
        "GSM8K":48.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_28B_instruct_v0.2",
        "Average":62.81,
        "ARC":58.19,
        "HellaSwag":80.52,
        "MMLU":60.53,
        "TruthfulQA":64.25,
        "Winogrande":74.9,
        "GSM8K":38.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":28.18,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vince62s\/phi-2-psy",
        "Average":62.8,
        "ARC":60.84,
        "HellaSwag":75.52,
        "MMLU":57.57,
        "TruthfulQA":48.22,
        "Winogrande":75.45,
        "GSM8K":59.21,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":15.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"gagan3012\/Multilingual-mistral",
        "Average":62.79,
        "ARC":62.29,
        "HellaSwag":81.76,
        "MMLU":61.38,
        "TruthfulQA":55.53,
        "Winogrande":75.53,
        "GSM8K":40.26,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-65b",
        "Average":62.79,
        "ARC":63.48,
        "HellaSwag":86.09,
        "MMLU":63.93,
        "TruthfulQA":43.43,
        "Winogrande":82.56,
        "GSM8K":37.23,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.29,
        "Model Sha":70.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Minami-su\/IA_14B",
        "Average":62.78,
        "ARC":62.37,
        "HellaSwag":80.7,
        "MMLU":68.08,
        "TruthfulQA":62.22,
        "Winogrande":74.35,
        "GSM8K":28.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/OpenCerebrum-1.0-7b-DPO",
        "Average":62.78,
        "ARC":62.71,
        "HellaSwag":84.33,
        "MMLU":62.59,
        "TruthfulQA":44.91,
        "Winogrande":80.11,
        "GSM8K":42.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/lr-experiment1-7B",
        "Average":62.77,
        "ARC":60.75,
        "HellaSwag":83.73,
        "MMLU":63.25,
        "TruthfulQA":44.07,
        "Winogrande":79.48,
        "GSM8K":45.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_28B_instruct_v0.1",
        "Average":62.77,
        "ARC":58.36,
        "HellaSwag":80.53,
        "MMLU":60.73,
        "TruthfulQA":64.17,
        "Winogrande":74.82,
        "GSM8K":37.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":28.18,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-Platypus-SOLAR",
        "Average":62.76,
        "ARC":61.86,
        "HellaSwag":84.18,
        "MMLU":53.72,
        "TruthfulQA":50.67,
        "Winogrande":82.4,
        "GSM8K":43.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/neural-chat-7b-v3-1-dare-0.85",
        "Average":62.74,
        "ARC":61.95,
        "HellaSwag":83.84,
        "MMLU":64.43,
        "TruthfulQA":44.9,
        "Winogrande":79.16,
        "GSM8K":42.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Ba2han\/Cucumber-7b-10k",
        "Average":62.74,
        "ARC":60.41,
        "HellaSwag":83.75,
        "MMLU":63.1,
        "TruthfulQA":50.97,
        "Winogrande":78.93,
        "GSM8K":39.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Faradaylab\/ARIA-70B-V3",
        "Average":62.73,
        "ARC":63.91,
        "HellaSwag":86.21,
        "MMLU":64.75,
        "TruthfulQA":51.32,
        "Winogrande":82.08,
        "GSM8K":28.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause",
        "Average":62.73,
        "ARC":61.26,
        "HellaSwag":83.4,
        "MMLU":63.91,
        "TruthfulQA":48.16,
        "Winogrande":79.79,
        "GSM8K":39.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cgato\/Thespis-CurtainCall-7b-v0.3",
        "Average":62.73,
        "ARC":64.25,
        "HellaSwag":82.93,
        "MMLU":62.24,
        "TruthfulQA":50.95,
        "Winogrande":78.61,
        "GSM8K":37.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mlinmg\/SG-Raccoon-Yi-200k-2.0",
        "Average":62.72,
        "ARC":62.54,
        "HellaSwag":80.26,
        "MMLU":73.29,
        "TruthfulQA":53.21,
        "Winogrande":76.32,
        "GSM8K":30.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":55.59,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.1",
        "Average":62.72,
        "ARC":59.47,
        "HellaSwag":80.75,
        "MMLU":60.56,
        "TruthfulQA":45.54,
        "Winogrande":76.48,
        "GSM8K":53.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.37,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Fredithefish\/MadMix-v0.2",
        "Average":62.72,
        "ARC":64.85,
        "HellaSwag":83.54,
        "MMLU":64.02,
        "TruthfulQA":55.79,
        "Winogrande":77.35,
        "GSM8K":30.78,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/BigOrca-2-XB",
        "Average":62.72,
        "ARC":61.6,
        "HellaSwag":83.64,
        "MMLU":60.85,
        "TruthfulQA":58.0,
        "Winogrande":77.27,
        "GSM8K":34.95,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":22.53,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Mistral-NeuralDPO",
        "Average":62.72,
        "ARC":66.04,
        "HellaSwag":84.69,
        "MMLU":63.92,
        "TruthfulQA":43.27,
        "Winogrande":79.64,
        "GSM8K":38.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"grayhacker91\/gemma-7b-open-platypus-commercial",
        "Average":62.71,
        "ARC":62.8,
        "HellaSwag":81.65,
        "MMLU":58.94,
        "TruthfulQA":53.54,
        "Winogrande":79.01,
        "GSM8K":40.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/experiment2-non-cause-v1",
        "Average":62.71,
        "ARC":61.52,
        "HellaSwag":83.71,
        "MMLU":63.79,
        "TruthfulQA":48.12,
        "Winogrande":79.32,
        "GSM8K":39.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/r-zephyr-7b-beta-qlora",
        "Average":62.7,
        "ARC":63.05,
        "HellaSwag":85.38,
        "MMLU":63.1,
        "TruthfulQA":46.32,
        "Winogrande":79.32,
        "GSM8K":39.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause-non",
        "Average":62.69,
        "ARC":61.09,
        "HellaSwag":83.72,
        "MMLU":64.13,
        "TruthfulQA":47.34,
        "Winogrande":79.48,
        "GSM8K":40.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hercules-2.0-Mistral-7B",
        "Average":62.69,
        "ARC":61.09,
        "HellaSwag":83.69,
        "MMLU":63.47,
        "TruthfulQA":43.97,
        "Winogrande":79.48,
        "GSM8K":44.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/internlm2-base-20b-llama",
        "Average":62.69,
        "ARC":63.05,
        "HellaSwag":82.11,
        "MMLU":63.97,
        "TruthfulQA":43.97,
        "Winogrande":78.22,
        "GSM8K":44.81,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"intervitens\/internlm2-base-20b-llama",
        "Average":62.69,
        "ARC":62.97,
        "HellaSwag":82.15,
        "MMLU":63.78,
        "TruthfulQA":44.11,
        "Winogrande":78.22,
        "GSM8K":44.88,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sr5434\/CodegebraGPT-10b",
        "Average":62.68,
        "ARC":59.81,
        "HellaSwag":83.42,
        "MMLU":60.2,
        "TruthfulQA":46.57,
        "Winogrande":80.98,
        "GSM8K":45.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/guanaco-65B-HF",
        "Average":62.67,
        "ARC":65.44,
        "HellaSwag":86.47,
        "MMLU":62.92,
        "TruthfulQA":52.81,
        "Winogrande":82.4,
        "GSM8K":26.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dball\/zephyr-7b-dpo-qlora-no-sft",
        "Average":62.67,
        "ARC":62.46,
        "HellaSwag":84.5,
        "MMLU":64.02,
        "TruthfulQA":44.25,
        "Winogrande":79.16,
        "GSM8K":41.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-XS-v1-3-yarn-128K",
        "Average":62.66,
        "ARC":61.09,
        "HellaSwag":82.95,
        "MMLU":62.15,
        "TruthfulQA":50.13,
        "Winogrande":74.43,
        "GSM8K":45.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.5",
        "Average":62.65,
        "ARC":62.63,
        "HellaSwag":83.77,
        "MMLU":62.16,
        "TruthfulQA":49.33,
        "Winogrande":75.14,
        "GSM8K":42.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AetherResearch\/Cerebrum-1.0-7b",
        "Average":62.63,
        "ARC":61.6,
        "HellaSwag":84.56,
        "MMLU":63.56,
        "TruthfulQA":46.49,
        "Winogrande":79.4,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":48.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/llama-2-70b-IA3-guanaco",
        "Average":62.61,
        "ARC":68.52,
        "HellaSwag":85.67,
        "MMLU":67.03,
        "TruthfulQA":43.47,
        "Winogrande":82.24,
        "GSM8K":28.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":70.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upaya07\/Birbal-7B-V1",
        "Average":62.6,
        "ARC":62.8,
        "HellaSwag":84.83,
        "MMLU":63.59,
        "TruthfulQA":45.34,
        "Winogrande":78.77,
        "GSM8K":40.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-70b-gpt4-2.0",
        "Average":62.6,
        "ARC":68.6,
        "HellaSwag":87.53,
        "MMLU":69.37,
        "TruthfulQA":48.52,
        "Winogrande":83.9,
        "GSM8K":17.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":70.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-v0.1-gpt-4-40k",
        "Average":62.59,
        "ARC":63.31,
        "HellaSwag":81.5,
        "MMLU":62.9,
        "TruthfulQA":54.89,
        "Winogrande":73.8,
        "GSM8K":39.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/VicUnlocked-alpaca-65B-QLoRA-fp16",
        "Average":62.58,
        "ARC":65.61,
        "HellaSwag":85.15,
        "MMLU":63.13,
        "TruthfulQA":52.47,
        "Winogrande":81.29,
        "GSM8K":27.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/mistralv1_gsm8k_merged_s",
        "Average":62.57,
        "ARC":62.03,
        "HellaSwag":83.95,
        "MMLU":61.66,
        "TruthfulQA":42.43,
        "Winogrande":77.66,
        "GSM8K":47.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bartowski\/internlm2-chat-20b-llama",
        "Average":62.56,
        "ARC":63.65,
        "HellaSwag":82.58,
        "MMLU":66.89,
        "TruthfulQA":48.74,
        "Winogrande":79.56,
        "GSM8K":33.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"L;l;a;m;a;F;o;r;C;a;u;s;a;l;L;M",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/gemma-7b-alpaca-52k-v0.1",
        "Average":62.56,
        "ARC":60.15,
        "HellaSwag":81.97,
        "MMLU":64.14,
        "TruthfulQA":46.7,
        "Winogrande":77.82,
        "GSM8K":44.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-Instruct-v0.2-gpt-4-80k",
        "Average":62.55,
        "ARC":58.02,
        "HellaSwag":78.89,
        "MMLU":60.96,
        "TruthfulQA":63.95,
        "Winogrande":74.66,
        "GSM8K":38.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Mistral-7B-Instruct-v0.2-gpt-4-80k",
        "Average":62.55,
        "ARC":58.02,
        "HellaSwag":78.89,
        "MMLU":60.96,
        "TruthfulQA":63.95,
        "Winogrande":74.66,
        "GSM8K":38.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kaist-ai\/mistral-orpo-beta",
        "Average":62.53,
        "ARC":61.18,
        "HellaSwag":84.03,
        "MMLU":63.26,
        "TruthfulQA":47.69,
        "Winogrande":79.24,
        "GSM8K":39.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v3_1-mistral-7b",
        "Average":62.53,
        "ARC":60.49,
        "HellaSwag":81.71,
        "MMLU":61.0,
        "TruthfulQA":49.51,
        "Winogrande":75.53,
        "GSM8K":46.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sr5434\/CodegebraGPT-10b",
        "Average":62.53,
        "ARC":59.56,
        "HellaSwag":83.45,
        "MMLU":60.07,
        "TruthfulQA":46.53,
        "Winogrande":81.06,
        "GSM8K":44.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-XS-v1-3-yarn-128K",
        "Average":62.49,
        "ARC":61.6,
        "HellaSwag":82.96,
        "MMLU":62.1,
        "TruthfulQA":50.2,
        "Winogrande":74.74,
        "GSM8K":43.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/GALAXY-XB-v.02",
        "Average":62.48,
        "ARC":60.67,
        "HellaSwag":83.27,
        "MMLU":64.99,
        "TruthfulQA":43.6,
        "Winogrande":80.27,
        "GSM8K":42.08,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":16.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mistral2-7b-v20.2-32k",
        "Average":62.46,
        "ARC":56.91,
        "HellaSwag":79.45,
        "MMLU":60.73,
        "TruthfulQA":53.18,
        "Winogrande":75.06,
        "GSM8K":49.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.3",
        "Average":62.44,
        "ARC":58.11,
        "HellaSwag":78.94,
        "MMLU":58.44,
        "TruthfulQA":47.21,
        "Winogrande":77.03,
        "GSM8K":54.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.37,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jikaixuan\/test_merged_model",
        "Average":62.42,
        "ARC":61.6,
        "HellaSwag":83.1,
        "MMLU":63.73,
        "TruthfulQA":48.65,
        "Winogrande":78.45,
        "GSM8K":38.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zardos\/Kant-Test-0.1-Mistral-7B",
        "Average":62.42,
        "ARC":62.37,
        "HellaSwag":82.84,
        "MMLU":63.38,
        "TruthfulQA":49.62,
        "Winogrande":78.3,
        "GSM8K":37.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-gemma-v0.1",
        "Average":62.41,
        "ARC":58.45,
        "HellaSwag":83.48,
        "MMLU":60.68,
        "TruthfulQA":52.07,
        "Winogrande":74.19,
        "GSM8K":45.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":106.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ChaoticNeutrals\/Bepis_9B",
        "Average":62.4,
        "ARC":62.54,
        "HellaSwag":80.12,
        "MMLU":62.84,
        "TruthfulQA":53.3,
        "Winogrande":76.48,
        "GSM8K":39.12,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":8.99,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"meta-llama\/Llama-2-70b-chat-hf",
        "Average":62.4,
        "ARC":64.59,
        "HellaSwag":85.88,
        "MMLU":63.91,
        "TruthfulQA":52.8,
        "Winogrande":80.51,
        "GSM8K":26.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":68.98,
        "Model Sha":2058.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SCE\/Mistral-7B-math-ia3-tuned",
        "Average":62.39,
        "ARC":57.25,
        "HellaSwag":80.79,
        "MMLU":59.83,
        "TruthfulQA":58.07,
        "Winogrande":76.56,
        "GSM8K":41.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-SPIN-iter0",
        "Average":62.37,
        "ARC":63.65,
        "HellaSwag":84.44,
        "MMLU":61.01,
        "TruthfulQA":50.48,
        "Winogrande":77.98,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/test0",
        "Average":62.37,
        "ARC":63.65,
        "HellaSwag":84.44,
        "MMLU":61.01,
        "TruthfulQA":50.48,
        "Winogrande":77.98,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"willyninja30\/ARIA-70B-French",
        "Average":62.37,
        "ARC":64.51,
        "HellaSwag":85.87,
        "MMLU":63.88,
        "TruthfulQA":52.8,
        "Winogrande":80.51,
        "GSM8K":26.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"gagan3012\/Multirial",
        "Average":62.37,
        "ARC":63.23,
        "HellaSwag":79.57,
        "MMLU":61.01,
        "TruthfulQA":54.7,
        "Winogrande":75.3,
        "GSM8K":40.41,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Qwen\/Qwen1.5-14B-Chat",
        "Average":62.37,
        "ARC":58.79,
        "HellaSwag":82.33,
        "MMLU":68.52,
        "TruthfulQA":60.38,
        "Winogrande":73.32,
        "GSM8K":30.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-qwen1.5-en-7b-dpo-v0.1",
        "Average":62.36,
        "ARC":54.35,
        "HellaSwag":76.04,
        "MMLU":61.21,
        "TruthfulQA":56.4,
        "Winogrande":72.06,
        "GSM8K":54.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hercules-3.0-Mistral-7B",
        "Average":62.36,
        "ARC":61.26,
        "HellaSwag":83.43,
        "MMLU":63.68,
        "TruthfulQA":43.42,
        "Winogrande":79.48,
        "GSM8K":42.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"karakuri-ai\/karakuri-lm-70b-chat-v0.1",
        "Average":62.36,
        "ARC":61.52,
        "HellaSwag":83.13,
        "MMLU":59.35,
        "TruthfulQA":51.39,
        "Winogrande":78.37,
        "GSM8K":40.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":69.2,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-1.2",
        "Average":62.36,
        "ARC":65.87,
        "HellaSwag":86.08,
        "MMLU":63.37,
        "TruthfulQA":52.72,
        "Winogrande":79.56,
        "GSM8K":26.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/zephyr-7b-alpha-dare-0.85",
        "Average":62.35,
        "ARC":61.18,
        "HellaSwag":83.67,
        "MMLU":64.3,
        "TruthfulQA":44.41,
        "Winogrande":78.45,
        "GSM8K":42.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Moko-SAMPLE",
        "Average":62.34,
        "ARC":61.09,
        "HellaSwag":83.85,
        "MMLU":64.57,
        "TruthfulQA":43.45,
        "Winogrande":79.16,
        "GSM8K":41.93,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"huseyinatahaninan\/phi-2-dpo",
        "Average":62.33,
        "ARC":63.05,
        "HellaSwag":76.36,
        "MMLU":58.46,
        "TruthfulQA":45.35,
        "Winogrande":74.03,
        "GSM8K":56.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Half-NSFW_Noromaid-7b",
        "Average":62.32,
        "ARC":62.8,
        "HellaSwag":84.82,
        "MMLU":63.76,
        "TruthfulQA":46.05,
        "Winogrande":78.06,
        "GSM8K":38.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"UCLA-AGI\/zephyr-7b-sft-full-SPIN-iter0",
        "Average":62.32,
        "ARC":63.57,
        "HellaSwag":84.43,
        "MMLU":61.28,
        "TruthfulQA":50.34,
        "Winogrande":77.98,
        "GSM8K":36.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-alpaca-sft",
        "Average":62.29,
        "ARC":61.69,
        "HellaSwag":83.56,
        "MMLU":61.65,
        "TruthfulQA":53.59,
        "Winogrande":77.19,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pinkyponky\/Mistral-7B-Instruct-sft-tuned-v0.2",
        "Average":62.29,
        "ARC":58.02,
        "HellaSwag":79.26,
        "MMLU":58.78,
        "TruthfulQA":50.45,
        "Winogrande":76.87,
        "GSM8K":50.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BlouseJury\/Mistral-7B-Discord-0.1-DPO",
        "Average":62.29,
        "ARC":63.23,
        "HellaSwag":83.27,
        "MMLU":62.62,
        "TruthfulQA":55.28,
        "Winogrande":78.93,
        "GSM8K":30.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fzzhang\/mistralv1_gsm8k_merged",
        "Average":62.28,
        "ARC":61.35,
        "HellaSwag":83.11,
        "MMLU":63.04,
        "TruthfulQA":39.55,
        "Winogrande":78.61,
        "GSM8K":47.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/finetuned-Mistral-7B-Instruct-v0.2-5000-v2.0",
        "Average":62.27,
        "ARC":59.3,
        "HellaSwag":82.65,
        "MMLU":58.45,
        "TruthfulQA":59.54,
        "Winogrande":77.66,
        "GSM8K":36.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Mistral-7B-Instruct-Aya-101",
        "Average":62.27,
        "ARC":59.13,
        "HellaSwag":83.2,
        "MMLU":61.96,
        "TruthfulQA":52.71,
        "Winogrande":77.51,
        "GSM8K":39.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vmajor\/Orca2-13B-selfmerge-39B",
        "Average":62.24,
        "ARC":60.84,
        "HellaSwag":79.84,
        "MMLU":60.32,
        "TruthfulQA":56.38,
        "Winogrande":76.87,
        "GSM8K":39.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"ms-pl",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vmajor\/Orca2-13B-selfmerge-26B",
        "Average":62.24,
        "ARC":60.84,
        "HellaSwag":79.84,
        "MMLU":60.32,
        "TruthfulQA":56.38,
        "Winogrande":76.87,
        "GSM8K":39.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"ms-pl",
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"0-hero\/Matter-0.1-Slim-7B-C",
        "Average":62.23,
        "ARC":61.35,
        "HellaSwag":81.76,
        "MMLU":61.45,
        "TruthfulQA":43.49,
        "Winogrande":77.98,
        "GSM8K":47.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/delta-4b-orange",
        "Average":62.23,
        "ARC":58.87,
        "HellaSwag":76.59,
        "MMLU":56.5,
        "TruthfulQA":56.82,
        "Winogrande":76.48,
        "GSM8K":48.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gmonsoon\/delta-4b-orange",
        "Average":62.23,
        "ARC":58.87,
        "HellaSwag":76.59,
        "MMLU":56.5,
        "TruthfulQA":56.82,
        "Winogrande":76.48,
        "GSM8K":48.14,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Frostwind-v2.1-m7",
        "Average":62.23,
        "ARC":61.77,
        "HellaSwag":83.77,
        "MMLU":63.83,
        "TruthfulQA":46.94,
        "Winogrande":78.69,
        "GSM8K":38.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/experiment2-cause-v1",
        "Average":62.22,
        "ARC":61.01,
        "HellaSwag":83.38,
        "MMLU":63.75,
        "TruthfulQA":47.2,
        "Winogrande":79.01,
        "GSM8K":38.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-6",
        "Average":62.2,
        "ARC":61.69,
        "HellaSwag":83.59,
        "MMLU":63.25,
        "TruthfulQA":46.27,
        "Winogrande":78.85,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-1",
        "Average":62.19,
        "ARC":62.12,
        "HellaSwag":83.6,
        "MMLU":63.46,
        "TruthfulQA":45.69,
        "Winogrande":79.16,
        "GSM8K":39.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-7B-v1.4",
        "Average":62.19,
        "ARC":60.41,
        "HellaSwag":82.87,
        "MMLU":60.98,
        "TruthfulQA":51.88,
        "Winogrande":74.82,
        "GSM8K":42.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-7",
        "Average":62.19,
        "ARC":61.95,
        "HellaSwag":83.54,
        "MMLU":63.13,
        "TruthfulQA":45.83,
        "Winogrande":79.4,
        "GSM8K":39.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"andysalerno\/rainbowfish-v7",
        "Average":62.18,
        "ARC":61.95,
        "HellaSwag":82.52,
        "MMLU":63.26,
        "TruthfulQA":49.78,
        "Winogrande":78.14,
        "GSM8K":37.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/bigstral-12b-32k",
        "Average":62.17,
        "ARC":59.98,
        "HellaSwag":84.1,
        "MMLU":59.14,
        "TruthfulQA":68.21,
        "Winogrande":74.66,
        "GSM8K":26.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":33.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/Mistral-Instruct-Ukrainian-SFT",
        "Average":62.17,
        "ARC":57.85,
        "HellaSwag":83.12,
        "MMLU":60.95,
        "TruthfulQA":54.14,
        "Winogrande":77.51,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-c-v1",
        "Average":62.16,
        "ARC":62.03,
        "HellaSwag":83.55,
        "MMLU":62.69,
        "TruthfulQA":45.82,
        "Winogrande":79.08,
        "GSM8K":39.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/Orca-2-13b-f16",
        "Average":62.14,
        "ARC":60.67,
        "HellaSwag":79.81,
        "MMLU":60.37,
        "TruthfulQA":56.41,
        "Winogrande":76.64,
        "GSM8K":38.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacaj\/phi-2-super",
        "Average":62.13,
        "ARC":61.86,
        "HellaSwag":76.6,
        "MMLU":58.41,
        "TruthfulQA":48.37,
        "Winogrande":73.01,
        "GSM8K":54.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":80.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liminerity\/Liph42",
        "Average":62.12,
        "ARC":62.03,
        "HellaSwag":75.87,
        "MMLU":57.37,
        "TruthfulQA":45.94,
        "Winogrande":74.59,
        "GSM8K":56.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v4-qwen1_5-7b",
        "Average":62.11,
        "ARC":54.44,
        "HellaSwag":76.11,
        "MMLU":60.43,
        "TruthfulQA":53.69,
        "Winogrande":71.27,
        "GSM8K":56.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/mistral-experiment-6-merge",
        "Average":62.1,
        "ARC":63.82,
        "HellaSwag":84.25,
        "MMLU":62.91,
        "TruthfulQA":44.99,
        "Winogrande":77.98,
        "GSM8K":38.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hercules-3.1-Mistral-7B",
        "Average":62.09,
        "ARC":61.18,
        "HellaSwag":83.55,
        "MMLU":63.65,
        "TruthfulQA":42.83,
        "Winogrande":79.01,
        "GSM8K":42.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenLemur\/lemur-70b-v1",
        "Average":62.07,
        "ARC":64.33,
        "HellaSwag":85.72,
        "MMLU":65.85,
        "TruthfulQA":44.78,
        "Winogrande":83.03,
        "GSM8K":28.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-5",
        "Average":62.07,
        "ARC":62.2,
        "HellaSwag":83.4,
        "MMLU":63.52,
        "TruthfulQA":45.46,
        "Winogrande":79.32,
        "GSM8K":38.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
        "Average":62.06,
        "ARC":61.69,
        "HellaSwag":83.85,
        "MMLU":64.43,
        "TruthfulQA":43.13,
        "Winogrande":78.93,
        "GSM8K":40.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andrijdavid\/Macaroni-v2-7b",
        "Average":62.05,
        "ARC":67.15,
        "HellaSwag":83.84,
        "MMLU":61.29,
        "TruthfulQA":67.07,
        "Winogrande":79.56,
        "GSM8K":13.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/solarized-13B-dpo",
        "Average":62.05,
        "ARC":62.71,
        "HellaSwag":81.82,
        "MMLU":59.12,
        "TruthfulQA":66.25,
        "Winogrande":76.01,
        "GSM8K":26.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Mistral-7b-v1.2",
        "Average":62.04,
        "ARC":57.51,
        "HellaSwag":79.61,
        "MMLU":58.04,
        "TruthfulQA":46.7,
        "Winogrande":75.37,
        "GSM8K":55.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.37,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"IDEA-CCNL\/Ziya2-13B-Base",
        "Average":62.04,
        "ARC":54.01,
        "HellaSwag":78.9,
        "MMLU":61.32,
        "TruthfulQA":42.74,
        "Winogrande":74.82,
        "GSM8K":60.42,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":13.0
    },
    {
        "T":"?",
        "Model":"Aeala\/Alpaca-elina-65b",
        "Average":62.03,
        "ARC":65.27,
        "HellaSwag":85.75,
        "MMLU":63.42,
        "TruthfulQA":47.32,
        "Winogrande":81.37,
        "GSM8K":29.04,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":65.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Mistral-7B-v0.1-gpt-4-80k",
        "Average":62.0,
        "ARC":62.8,
        "HellaSwag":81.05,
        "MMLU":63.21,
        "TruthfulQA":54.6,
        "Winogrande":74.03,
        "GSM8K":36.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-200K-Q",
        "Average":62.0,
        "ARC":63.91,
        "HellaSwag":83.52,
        "MMLU":75.19,
        "TruthfulQA":44.21,
        "Winogrande":81.06,
        "GSM8K":24.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"athirdpath\/Iambe-20b-DARE-v2",
        "Average":61.99,
        "ARC":62.8,
        "HellaSwag":84.53,
        "MMLU":60.45,
        "TruthfulQA":53.85,
        "Winogrande":77.03,
        "GSM8K":33.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/zephyr-beta-math",
        "Average":61.99,
        "ARC":56.66,
        "HellaSwag":81.26,
        "MMLU":57.24,
        "TruthfulQA":44.83,
        "Winogrande":75.53,
        "GSM8K":56.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-7B-v3.0",
        "Average":61.99,
        "ARC":62.46,
        "HellaSwag":83.79,
        "MMLU":63.9,
        "TruthfulQA":43.85,
        "Winogrande":77.9,
        "GSM8K":40.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Novocoders\/Mistral-NeuralDPO-v0.5",
        "Average":61.98,
        "ARC":65.44,
        "HellaSwag":84.66,
        "MMLU":62.56,
        "TruthfulQA":42.43,
        "Winogrande":80.27,
        "GSM8K":36.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/Orca-2-13b",
        "Average":61.98,
        "ARC":60.92,
        "HellaSwag":79.85,
        "MMLU":60.3,
        "TruthfulQA":56.42,
        "Winogrande":76.56,
        "GSM8K":37.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":642.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Mistral-7B-v0.1-gpt-4-60k",
        "Average":61.98,
        "ARC":62.88,
        "HellaSwag":80.78,
        "MMLU":62.87,
        "TruthfulQA":53.91,
        "Winogrande":73.72,
        "GSM8K":37.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-v0.1-gpt-4-60k",
        "Average":61.98,
        "ARC":62.88,
        "HellaSwag":80.78,
        "MMLU":62.87,
        "TruthfulQA":53.91,
        "Winogrande":73.72,
        "GSM8K":37.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KeyonZeng\/lion-zephyr-7b",
        "Average":61.98,
        "ARC":63.05,
        "HellaSwag":84.88,
        "MMLU":60.98,
        "TruthfulQA":58.78,
        "Winogrande":78.22,
        "GSM8K":25.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/MelangeC-70b",
        "Average":61.96,
        "ARC":71.67,
        "HellaSwag":87.6,
        "MMLU":70.37,
        "TruthfulQA":58.13,
        "Winogrande":83.98,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":68.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":61.95,
        "ARC":62.03,
        "HellaSwag":84.36,
        "MMLU":61.07,
        "TruthfulQA":57.45,
        "Winogrande":77.74,
        "GSM8K":29.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1396.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"01-ai\/Yi-9B-200K",
        "Average":61.94,
        "ARC":58.02,
        "HellaSwag":78.58,
        "MMLU":70.34,
        "TruthfulQA":40.63,
        "Winogrande":76.48,
        "GSM8K":47.61,
        "Type":"continuously pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.83,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-v0.1-gpt-4-20k",
        "Average":61.93,
        "ARC":62.71,
        "HellaSwag":81.73,
        "MMLU":62.85,
        "TruthfulQA":54.7,
        "Winogrande":72.93,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/zephyr-7b-truthy",
        "Average":61.93,
        "ARC":60.75,
        "HellaSwag":84.64,
        "MMLU":59.53,
        "TruthfulQA":63.31,
        "Winogrande":77.9,
        "GSM8K":25.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Faradaylab\/ARIA-70B-V2",
        "Average":61.93,
        "ARC":62.12,
        "HellaSwag":85.68,
        "MMLU":63.49,
        "TruthfulQA":49.8,
        "Winogrande":81.69,
        "GSM8K":28.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/dolphin-2.6-mistral-7b-dpo-orca",
        "Average":61.92,
        "ARC":66.04,
        "HellaSwag":84.62,
        "MMLU":62.28,
        "TruthfulQA":59.97,
        "Winogrande":78.3,
        "GSM8K":20.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/dolphin-2.6-mistral-7b-dpo-orca-v1",
        "Average":61.92,
        "ARC":66.04,
        "HellaSwag":84.62,
        "MMLU":62.28,
        "TruthfulQA":59.97,
        "Winogrande":78.3,
        "GSM8K":20.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-2.1-Mistral-7B",
        "Average":61.9,
        "ARC":59.9,
        "HellaSwag":83.3,
        "MMLU":61.46,
        "TruthfulQA":47.58,
        "Winogrande":79.01,
        "GSM8K":40.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-jondurbin-truthy-dpo",
        "Average":61.9,
        "ARC":60.75,
        "HellaSwag":83.89,
        "MMLU":63.65,
        "TruthfulQA":48.45,
        "Winogrande":77.98,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NeuralNovel\/Senzu-7B-v0.1-DPO",
        "Average":61.9,
        "ARC":66.72,
        "HellaSwag":84.34,
        "MMLU":62.12,
        "TruthfulQA":45.29,
        "Winogrande":79.95,
        "GSM8K":32.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"spmurrayzzz\/Mistral-Syndicate-7B",
        "Average":61.9,
        "ARC":60.84,
        "HellaSwag":82.91,
        "MMLU":60.83,
        "TruthfulQA":43.71,
        "Winogrande":78.61,
        "GSM8K":44.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-mistral-7b",
        "Average":61.88,
        "ARC":62.63,
        "HellaSwag":84.26,
        "MMLU":62.45,
        "TruthfulQA":51.83,
        "Winogrande":78.3,
        "GSM8K":31.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"andysalerno\/rainbowfish-7B-v10",
        "Average":61.88,
        "ARC":61.18,
        "HellaSwag":82.33,
        "MMLU":63.26,
        "TruthfulQA":49.45,
        "Winogrande":78.06,
        "GSM8K":37.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-2.0-Mistral-7B",
        "Average":61.88,
        "ARC":61.09,
        "HellaSwag":83.5,
        "MMLU":63.68,
        "TruthfulQA":41.97,
        "Winogrande":79.24,
        "GSM8K":41.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"proto-llm\/uniwiz-7B-v0.1",
        "Average":61.87,
        "ARC":61.77,
        "HellaSwag":84.16,
        "MMLU":64.16,
        "TruthfulQA":44.96,
        "Winogrande":78.85,
        "GSM8K":37.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Winterreise-m7",
        "Average":61.86,
        "ARC":61.26,
        "HellaSwag":83.84,
        "MMLU":63.85,
        "TruthfulQA":45.55,
        "Winogrande":79.08,
        "GSM8K":37.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-tak-stack-dpo",
        "Average":61.86,
        "ARC":61.18,
        "HellaSwag":83.98,
        "MMLU":64.32,
        "TruthfulQA":43.8,
        "Winogrande":79.32,
        "GSM8K":38.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-7b-v0.2",
        "Average":61.86,
        "ARC":62.12,
        "HellaSwag":84.92,
        "MMLU":63.1,
        "TruthfulQA":46.09,
        "Winogrande":78.22,
        "GSM8K":36.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AA051611\/A0118",
        "Average":61.84,
        "ARC":59.22,
        "HellaSwag":83.79,
        "MMLU":68.28,
        "TruthfulQA":55.79,
        "Winogrande":77.58,
        "GSM8K":26.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-3.0-Mixtral-3x7B",
        "Average":61.84,
        "ARC":60.67,
        "HellaSwag":83.28,
        "MMLU":63.22,
        "TruthfulQA":43.46,
        "Winogrande":79.01,
        "GSM8K":41.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/bagel-8x7b-v0.2",
        "Average":61.83,
        "ARC":68.26,
        "HellaSwag":86.32,
        "MMLU":70.4,
        "TruthfulQA":60.03,
        "Winogrande":81.29,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dfurman\/Mistral-7B-Instruct-v0.2",
        "Average":61.79,
        "ARC":60.15,
        "HellaSwag":82.79,
        "MMLU":60.07,
        "TruthfulQA":56.06,
        "Winogrande":76.87,
        "GSM8K":34.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-7b-v0.2",
        "Average":61.78,
        "ARC":62.03,
        "HellaSwag":84.97,
        "MMLU":62.99,
        "TruthfulQA":46.07,
        "Winogrande":78.37,
        "GSM8K":36.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jikaixuan\/test",
        "Average":61.76,
        "ARC":62.29,
        "HellaSwag":84.42,
        "MMLU":61.07,
        "TruthfulQA":57.51,
        "Winogrande":78.06,
        "GSM8K":27.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jikaixuan\/test_model",
        "Average":61.76,
        "ARC":62.29,
        "HellaSwag":84.42,
        "MMLU":61.07,
        "TruthfulQA":57.51,
        "Winogrande":78.06,
        "GSM8K":27.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-7B",
        "Average":61.76,
        "ARC":54.18,
        "HellaSwag":78.51,
        "MMLU":61.97,
        "TruthfulQA":51.08,
        "Winogrande":71.27,
        "GSM8K":53.53,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"spmurrayzzz\/Mistral-Syndicate-7B",
        "Average":61.74,
        "ARC":60.84,
        "HellaSwag":82.88,
        "MMLU":60.52,
        "TruthfulQA":43.73,
        "Winogrande":78.45,
        "GSM8K":44.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AIJUUD\/juud-Mistral-7B",
        "Average":61.72,
        "ARC":66.72,
        "HellaSwag":85.0,
        "MMLU":63.38,
        "TruthfulQA":54.12,
        "Winogrande":77.98,
        "GSM8K":23.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"huangyt\/Mistral-7B-v0.1-Open-Platypus_2.5w-r16-gate_up_down",
        "Average":61.71,
        "ARC":61.26,
        "HellaSwag":83.19,
        "MMLU":63.87,
        "TruthfulQA":45.44,
        "Winogrande":77.35,
        "GSM8K":39.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pansophic\/new_model_test2",
        "Average":61.7,
        "ARC":62.03,
        "HellaSwag":75.36,
        "MMLU":56.03,
        "TruthfulQA":46.54,
        "Winogrande":77.03,
        "GSM8K":53.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Metabird-7b-DPO",
        "Average":61.7,
        "ARC":65.96,
        "HellaSwag":86.29,
        "MMLU":64.46,
        "TruthfulQA":60.3,
        "Winogrande":81.37,
        "GSM8K":11.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/Mistral-v2-orpo",
        "Average":61.7,
        "ARC":60.92,
        "HellaSwag":83.45,
        "MMLU":63.66,
        "TruthfulQA":44.21,
        "Winogrande":78.37,
        "GSM8K":39.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"amu\/spin-phi2",
        "Average":61.68,
        "ARC":63.57,
        "HellaSwag":75.57,
        "MMLU":57.93,
        "TruthfulQA":46.22,
        "Winogrande":73.48,
        "GSM8K":53.3,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"fhai50032\/SamChat",
        "Average":61.68,
        "ARC":62.2,
        "HellaSwag":81.88,
        "MMLU":59.7,
        "TruthfulQA":52.89,
        "Winogrande":72.14,
        "GSM8K":41.24,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"amu\/spin-phi2",
        "Average":61.67,
        "ARC":63.14,
        "HellaSwag":75.56,
        "MMLU":57.08,
        "TruthfulQA":45.77,
        "Winogrande":74.19,
        "GSM8K":54.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoMist-7b",
        "Average":61.67,
        "ARC":65.87,
        "HellaSwag":83.55,
        "MMLU":62.32,
        "TruthfulQA":59.98,
        "Winogrande":78.06,
        "GSM8K":20.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/hyperion-medium-preview",
        "Average":61.67,
        "ARC":60.67,
        "HellaSwag":83.67,
        "MMLU":63.73,
        "TruthfulQA":42.93,
        "Winogrande":78.53,
        "GSM8K":40.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/NeuralHyperion-Medium-Preview",
        "Average":61.67,
        "ARC":60.67,
        "HellaSwag":83.67,
        "MMLU":63.73,
        "TruthfulQA":42.93,
        "Winogrande":78.53,
        "GSM8K":40.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NickyNicky\/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2",
        "Average":61.65,
        "ARC":60.49,
        "HellaSwag":82.07,
        "MMLU":62.34,
        "TruthfulQA":46.38,
        "Winogrande":78.45,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tcapelle\/gemma-7b-zephyr-sft",
        "Average":61.64,
        "ARC":61.43,
        "HellaSwag":80.73,
        "MMLU":60.33,
        "TruthfulQA":43.35,
        "Winogrande":74.19,
        "GSM8K":49.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/gemma-7b-zephyr-sft",
        "Average":61.64,
        "ARC":61.43,
        "HellaSwag":80.73,
        "MMLU":60.33,
        "TruthfulQA":43.35,
        "Winogrande":74.19,
        "GSM8K":49.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"andysalerno\/rainbowfish-v6",
        "Average":61.64,
        "ARC":61.95,
        "HellaSwag":82.51,
        "MMLU":62.79,
        "TruthfulQA":48.37,
        "Winogrande":77.9,
        "GSM8K":36.32,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"athirdpath\/Orca-2-13b-Alpaca-Uncensored",
        "Average":61.63,
        "ARC":61.09,
        "HellaSwag":79.27,
        "MMLU":60.13,
        "TruthfulQA":53.59,
        "Winogrande":77.43,
        "GSM8K":38.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tcapelle\/gemma-7b-zephyr-dpo",
        "Average":61.62,
        "ARC":60.84,
        "HellaSwag":80.44,
        "MMLU":60.6,
        "TruthfulQA":42.48,
        "Winogrande":75.37,
        "GSM8K":49.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/gemma-7b-zephyr-dpo",
        "Average":61.62,
        "ARC":60.84,
        "HellaSwag":80.44,
        "MMLU":60.6,
        "TruthfulQA":42.48,
        "Winogrande":75.37,
        "GSM8K":49.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/merlin1",
        "Average":61.6,
        "ARC":60.67,
        "HellaSwag":74.55,
        "MMLU":57.86,
        "TruthfulQA":48.35,
        "Winogrande":74.98,
        "GSM8K":53.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vankhoa\/test_phi2",
        "Average":61.6,
        "ARC":61.18,
        "HellaSwag":75.14,
        "MMLU":58.3,
        "TruthfulQA":44.44,
        "Winogrande":74.82,
        "GSM8K":55.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hiyouga\/Qwen-14B-Chat-LLaMAfied",
        "Average":61.6,
        "ARC":57.51,
        "HellaSwag":82.11,
        "MMLU":65.57,
        "TruthfulQA":51.99,
        "Winogrande":72.93,
        "GSM8K":39.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Llamix2-MLewd-4x13B",
        "Average":61.6,
        "ARC":61.01,
        "HellaSwag":83.17,
        "MMLU":56.32,
        "TruthfulQA":50.35,
        "Winogrande":75.37,
        "GSM8K":43.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":38.5,
        "Model Sha":55.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":61.59,
        "ARC":66.21,
        "HellaSwag":83.64,
        "MMLU":62.37,
        "TruthfulQA":59.65,
        "Winogrande":78.14,
        "GSM8K":19.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":531.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":61.59,
        "ARC":65.7,
        "HellaSwag":83.54,
        "MMLU":62.12,
        "TruthfulQA":59.48,
        "Winogrande":78.61,
        "GSM8K":20.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":531.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"athirdpath\/NSFW_DPO_Noromaid-7b",
        "Average":61.59,
        "ARC":62.63,
        "HellaSwag":84.5,
        "MMLU":63.34,
        "TruthfulQA":44.99,
        "Winogrande":78.22,
        "GSM8K":35.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":61.59,
        "ARC":62.46,
        "HellaSwag":84.35,
        "MMLU":60.7,
        "TruthfulQA":57.83,
        "Winogrande":77.11,
        "GSM8K":27.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1396.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Isaak-Carter\/J.O.S.I.E.3-Beta8-slerp",
        "Average":61.56,
        "ARC":60.41,
        "HellaSwag":83.66,
        "MMLU":62.35,
        "TruthfulQA":48.69,
        "Winogrande":78.14,
        "GSM8K":36.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Deci\/DeciLM-7B",
        "Average":61.55,
        "ARC":59.39,
        "HellaSwag":82.51,
        "MMLU":59.76,
        "TruthfulQA":40.33,
        "Winogrande":79.95,
        "GSM8K":47.38,
        "Type":"pretrained",
        "Architecture":"DeciLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.04,
        "Model Sha":214.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"tianlinliu0121\/zephyr-7b-dpo-full-beta-0.2",
        "Average":61.55,
        "ARC":61.77,
        "HellaSwag":84.04,
        "MMLU":61.79,
        "TruthfulQA":54.72,
        "Winogrande":76.95,
        "GSM8K":30.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/SamChat",
        "Average":61.55,
        "ARC":62.03,
        "HellaSwag":81.95,
        "MMLU":59.78,
        "TruthfulQA":52.9,
        "Winogrande":71.98,
        "GSM8K":40.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":61.54,
        "ARC":66.3,
        "HellaSwag":83.6,
        "MMLU":62.44,
        "TruthfulQA":59.54,
        "Winogrande":77.98,
        "GSM8K":19.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":531.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mistral2-7b-v20.1-32k",
        "Average":61.53,
        "ARC":53.5,
        "HellaSwag":77.76,
        "MMLU":59.76,
        "TruthfulQA":52.97,
        "Winogrande":75.06,
        "GSM8K":50.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"teknium\/OpenHermes-2.5-Mistral-7B",
        "Average":61.52,
        "ARC":64.93,
        "HellaSwag":84.18,
        "MMLU":63.64,
        "TruthfulQA":52.24,
        "Winogrande":78.06,
        "GSM8K":26.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":740.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/DarkSapling-7B-v1.0",
        "Average":61.52,
        "ARC":61.6,
        "HellaSwag":82.59,
        "MMLU":62.46,
        "TruthfulQA":45.09,
        "Winogrande":77.19,
        "GSM8K":40.18,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/SamCoder-TxC",
        "Average":61.52,
        "ARC":62.37,
        "HellaSwag":81.93,
        "MMLU":59.68,
        "TruthfulQA":52.37,
        "Winogrande":72.14,
        "GSM8K":40.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-3.0-Mistral-7B-alpha",
        "Average":61.52,
        "ARC":59.98,
        "HellaSwag":83.48,
        "MMLU":62.5,
        "TruthfulQA":42.82,
        "Winogrande":78.77,
        "GSM8K":41.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/Mistral-7B-OpenOrca-lora-merged",
        "Average":61.52,
        "ARC":61.77,
        "HellaSwag":83.61,
        "MMLU":64.34,
        "TruthfulQA":42.7,
        "Winogrande":78.53,
        "GSM8K":38.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"0-hero\/Matter-0.1-Slim-7B-preview",
        "Average":61.51,
        "ARC":59.98,
        "HellaSwag":80.66,
        "MMLU":61.53,
        "TruthfulQA":42.55,
        "Winogrande":77.35,
        "GSM8K":47.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"field2437\/phi-2-platypus-Commercial-lora",
        "Average":61.51,
        "ARC":60.41,
        "HellaSwag":75.12,
        "MMLU":58.03,
        "TruthfulQA":45.46,
        "Winogrande":74.59,
        "GSM8K":55.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"field2437\/phi-2-test",
        "Average":61.51,
        "ARC":60.41,
        "HellaSwag":75.12,
        "MMLU":58.03,
        "TruthfulQA":45.46,
        "Winogrande":74.59,
        "GSM8K":55.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/phi-2-logical-sft",
        "Average":61.5,
        "ARC":61.35,
        "HellaSwag":75.14,
        "MMLU":57.4,
        "TruthfulQA":44.39,
        "Winogrande":74.9,
        "GSM8K":55.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-7b-v0.1.1",
        "Average":61.49,
        "ARC":62.2,
        "HellaSwag":84.28,
        "MMLU":63.44,
        "TruthfulQA":44.3,
        "Winogrande":77.9,
        "GSM8K":36.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-gemma-v0.1",
        "Average":61.48,
        "ARC":57.94,
        "HellaSwag":82.91,
        "MMLU":58.98,
        "TruthfulQA":52.47,
        "Winogrande":72.53,
        "GSM8K":44.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":106.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/robin-65b-v2-fp16",
        "Average":61.48,
        "ARC":61.95,
        "HellaSwag":84.6,
        "MMLU":62.51,
        "TruthfulQA":52.31,
        "Winogrande":80.51,
        "GSM8K":26.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/fine-tune-mistral-long-merge",
        "Average":61.47,
        "ARC":62.88,
        "HellaSwag":83.62,
        "MMLU":63.39,
        "TruthfulQA":43.94,
        "Winogrande":78.93,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"walebadr\/Mistral-7B-v0.1-DPO",
        "Average":61.47,
        "ARC":61.26,
        "HellaSwag":83.94,
        "MMLU":63.76,
        "TruthfulQA":42.68,
        "Winogrande":78.77,
        "GSM8K":38.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Delta",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/DarkForest-20B-v1.2",
        "Average":61.46,
        "ARC":63.57,
        "HellaSwag":86.42,
        "MMLU":59.77,
        "TruthfulQA":56.31,
        "Winogrande":77.74,
        "GSM8K":24.94,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"teknium\/OpenHermes-2.5-Mistral-7B",
        "Average":61.45,
        "ARC":64.93,
        "HellaSwag":84.3,
        "MMLU":63.82,
        "TruthfulQA":52.31,
        "Winogrande":77.9,
        "GSM8K":25.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":740.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/SamCoder-TxC",
        "Average":61.44,
        "ARC":62.12,
        "HellaSwag":81.85,
        "MMLU":59.83,
        "TruthfulQA":52.39,
        "Winogrande":72.38,
        "GSM8K":40.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-qwen1.5-en-7b",
        "Average":61.44,
        "ARC":53.41,
        "HellaSwag":75.51,
        "MMLU":61.67,
        "TruthfulQA":51.96,
        "Winogrande":70.72,
        "GSM8K":55.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hyperion-1.5-Mistral-7B",
        "Average":61.43,
        "ARC":60.49,
        "HellaSwag":83.64,
        "MMLU":63.57,
        "TruthfulQA":41.78,
        "Winogrande":78.61,
        "GSM8K":40.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"andysalerno\/rainbowfish-7B-v9",
        "Average":61.42,
        "ARC":61.77,
        "HellaSwag":82.43,
        "MMLU":63.0,
        "TruthfulQA":48.82,
        "Winogrande":77.66,
        "GSM8K":34.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GritLM\/GritLM-7B",
        "Average":61.41,
        "ARC":58.11,
        "HellaSwag":80.97,
        "MMLU":60.29,
        "TruthfulQA":45.86,
        "Winogrande":78.22,
        "GSM8K":45.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":47.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Steelskull\/Aethora-7b-v1",
        "Average":61.41,
        "ARC":59.47,
        "HellaSwag":79.32,
        "MMLU":61.95,
        "TruthfulQA":54.87,
        "Winogrande":78.37,
        "GSM8K":34.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeuralNovel\/Ember-7B-v0.1",
        "Average":61.39,
        "ARC":68.43,
        "HellaSwag":85.52,
        "MMLU":64.1,
        "TruthfulQA":63.29,
        "Winogrande":82.32,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"osanseviero\/mistral-instruct-moe-experimental",
        "Average":61.39,
        "ARC":61.01,
        "HellaSwag":81.55,
        "MMLU":58.22,
        "TruthfulQA":60.4,
        "Winogrande":76.09,
        "GSM8K":31.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"zhengchenphd\/ICE-GRT",
        "Average":61.39,
        "ARC":62.88,
        "HellaSwag":86.14,
        "MMLU":57.34,
        "TruthfulQA":53.17,
        "Winogrande":77.11,
        "GSM8K":31.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-distilabel-truthy-dpo",
        "Average":61.39,
        "ARC":60.92,
        "HellaSwag":83.64,
        "MMLU":64.18,
        "TruthfulQA":45.12,
        "Winogrande":78.37,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/fine-tune-mistral-environment-merge",
        "Average":61.39,
        "ARC":62.63,
        "HellaSwag":83.66,
        "MMLU":63.88,
        "TruthfulQA":43.97,
        "Winogrande":78.93,
        "GSM8K":35.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"smelborp\/MixtralOrochi8x7B-Alt",
        "Average":61.38,
        "ARC":67.92,
        "HellaSwag":86.25,
        "MMLU":70.06,
        "TruthfulQA":64.03,
        "Winogrande":80.03,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-llama2-13b",
        "Average":61.36,
        "ARC":62.03,
        "HellaSwag":81.82,
        "MMLU":58.69,
        "TruthfulQA":55.66,
        "Winogrande":76.01,
        "GSM8K":33.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"tianlinliu0121\/zephyr-7b-dpo-full-beta-0.2",
        "Average":61.36,
        "ARC":61.86,
        "HellaSwag":83.98,
        "MMLU":61.85,
        "TruthfulQA":54.78,
        "Winogrande":76.95,
        "GSM8K":28.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.3-merged",
        "Average":61.34,
        "ARC":62.2,
        "HellaSwag":84.0,
        "MMLU":62.65,
        "TruthfulQA":59.24,
        "Winogrande":78.14,
        "GSM8K":21.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.4",
        "Average":61.34,
        "ARC":62.2,
        "HellaSwag":84.0,
        "MMLU":62.65,
        "TruthfulQA":59.24,
        "Winogrande":78.14,
        "GSM8K":21.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/alpaca-lora-65B-HF",
        "Average":61.33,
        "ARC":64.85,
        "HellaSwag":85.59,
        "MMLU":63.11,
        "TruthfulQA":45.15,
        "Winogrande":81.22,
        "GSM8K":28.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/phi-2",
        "Average":61.33,
        "ARC":61.09,
        "HellaSwag":75.11,
        "MMLU":58.11,
        "TruthfulQA":44.47,
        "Winogrande":74.35,
        "GSM8K":54.81,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":3016.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"walebadr\/Mistral-7B-v0.1-DPO",
        "Average":61.3,
        "ARC":60.32,
        "HellaSwag":83.69,
        "MMLU":64.01,
        "TruthfulQA":43.53,
        "Winogrande":79.01,
        "GSM8K":37.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deacon-20B",
        "Average":61.28,
        "ARC":60.75,
        "HellaSwag":81.74,
        "MMLU":60.7,
        "TruthfulQA":58.49,
        "Winogrande":76.8,
        "GSM8K":29.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":20.09,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.4",
        "Average":61.28,
        "ARC":62.29,
        "HellaSwag":83.91,
        "MMLU":62.7,
        "TruthfulQA":59.2,
        "Winogrande":77.35,
        "GSM8K":22.21,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/NeuralHyperion-2.0-Mistral-7B",
        "Average":61.27,
        "ARC":57.76,
        "HellaSwag":82.29,
        "MMLU":61.9,
        "TruthfulQA":45.5,
        "Winogrande":79.01,
        "GSM8K":41.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dball\/zephyr-7b-dpo-qlora",
        "Average":61.27,
        "ARC":63.82,
        "HellaSwag":84.92,
        "MMLU":62.28,
        "TruthfulQA":44.03,
        "Winogrande":78.61,
        "GSM8K":33.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NickyNicky\/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
        "Average":61.26,
        "ARC":60.58,
        "HellaSwag":83.34,
        "MMLU":61.53,
        "TruthfulQA":48.21,
        "Winogrande":77.74,
        "GSM8K":36.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"amu\/dpo-phi2",
        "Average":61.26,
        "ARC":61.69,
        "HellaSwag":75.13,
        "MMLU":58.1,
        "TruthfulQA":43.99,
        "Winogrande":74.19,
        "GSM8K":54.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Phi-2-DPO",
        "Average":61.25,
        "ARC":60.75,
        "HellaSwag":75.03,
        "MMLU":57.75,
        "TruthfulQA":44.46,
        "Winogrande":73.64,
        "GSM8K":55.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardLM-70B-V1.0",
        "Average":61.25,
        "ARC":65.44,
        "HellaSwag":84.41,
        "MMLU":64.05,
        "TruthfulQA":54.81,
        "Winogrande":80.82,
        "GSM8K":17.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":223.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/WikiHow-Mistral-Instruct-7B",
        "Average":61.25,
        "ARC":60.92,
        "HellaSwag":80.99,
        "MMLU":58.57,
        "TruthfulQA":62.16,
        "Winogrande":74.82,
        "GSM8K":30.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_3.5",
        "Average":61.24,
        "ARC":63.91,
        "HellaSwag":84.79,
        "MMLU":64.94,
        "TruthfulQA":46.38,
        "Winogrande":80.58,
        "GSM8K":26.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1078.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Minirecord\/Mini_DPO_test02",
        "Average":61.23,
        "ARC":59.73,
        "HellaSwag":83.89,
        "MMLU":61.9,
        "TruthfulQA":48.47,
        "Winogrande":78.37,
        "GSM8K":35.03,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"clowman\/openchat-mistral-7b-reproduce",
        "Average":61.23,
        "ARC":57.25,
        "HellaSwag":80.72,
        "MMLU":61.54,
        "TruthfulQA":55.81,
        "Winogrande":72.53,
        "GSM8K":39.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_3.5",
        "Average":61.22,
        "ARC":63.82,
        "HellaSwag":84.8,
        "MMLU":64.98,
        "TruthfulQA":46.39,
        "Winogrande":80.74,
        "GSM8K":26.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1078.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Mistral-Instruct-7B-v0.2-ChatAlpaca",
        "Average":61.21,
        "ARC":56.74,
        "HellaSwag":80.82,
        "MMLU":59.1,
        "TruthfulQA":55.86,
        "Winogrande":77.11,
        "GSM8K":37.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GritLM\/GritLM-7B",
        "Average":61.21,
        "ARC":58.11,
        "HellaSwag":80.91,
        "MMLU":60.02,
        "TruthfulQA":45.81,
        "Winogrande":77.82,
        "GSM8K":44.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":47.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-2.0",
        "Average":61.2,
        "ARC":66.64,
        "HellaSwag":86.66,
        "MMLU":63.18,
        "TruthfulQA":49.11,
        "Winogrande":80.74,
        "GSM8K":20.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/DarkForest-20B-v2.0",
        "Average":61.19,
        "ARC":63.74,
        "HellaSwag":86.32,
        "MMLU":59.79,
        "TruthfulQA":56.14,
        "Winogrande":77.9,
        "GSM8K":23.28,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":19.99,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggingface\/llama-65b",
        "Average":61.19,
        "ARC":63.48,
        "HellaSwag":86.09,
        "MMLU":63.93,
        "TruthfulQA":43.43,
        "Winogrande":82.56,
        "GSM8K":27.67,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/mistral-7b-slimorcaboros",
        "Average":61.18,
        "ARC":63.65,
        "HellaSwag":83.7,
        "MMLU":63.46,
        "TruthfulQA":55.81,
        "Winogrande":77.03,
        "GSM8K":23.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Liberated-Qwen1.5-7B",
        "Average":61.17,
        "ARC":52.05,
        "HellaSwag":76.59,
        "MMLU":61.25,
        "TruthfulQA":50.94,
        "Winogrande":72.14,
        "GSM8K":54.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-hermes-code-7b",
        "Average":61.16,
        "ARC":59.39,
        "HellaSwag":78.55,
        "MMLU":59.88,
        "TruthfulQA":51.26,
        "Winogrande":77.27,
        "GSM8K":40.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/jackalope-7b",
        "Average":61.16,
        "ARC":63.4,
        "HellaSwag":83.29,
        "MMLU":63.5,
        "TruthfulQA":50.06,
        "Winogrande":78.06,
        "GSM8K":28.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mrm8488\/mistral-7b-ft-h4-no_robots_instructions",
        "Average":61.16,
        "ARC":60.92,
        "HellaSwag":83.17,
        "MMLU":63.37,
        "TruthfulQA":43.63,
        "Winogrande":78.85,
        "GSM8K":37.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mrm8488\/mistral-7b-ft-h4-no_robots_instructions",
        "Average":61.16,
        "ARC":60.92,
        "HellaSwag":83.24,
        "MMLU":63.74,
        "TruthfulQA":43.64,
        "Winogrande":78.69,
        "GSM8K":36.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kwchoi\/DPO_mistral_7b_alpaca_0124_v1",
        "Average":61.15,
        "ARC":63.4,
        "HellaSwag":73.2,
        "MMLU":60.51,
        "TruthfulQA":66.76,
        "Winogrande":77.19,
        "GSM8K":25.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/PlatYi-34B-Llama-Q-v3",
        "Average":61.15,
        "ARC":64.33,
        "HellaSwag":84.88,
        "MMLU":74.98,
        "TruthfulQA":51.8,
        "Winogrande":84.21,
        "GSM8K":6.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":34.39,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-2.0",
        "Average":61.14,
        "ARC":66.81,
        "HellaSwag":86.66,
        "MMLU":63.41,
        "TruthfulQA":49.17,
        "Winogrande":80.27,
        "GSM8K":20.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Qwen1.5-8x7b-v0.1",
        "Average":61.14,
        "ARC":51.62,
        "HellaSwag":75.71,
        "MMLU":59.61,
        "TruthfulQA":55.78,
        "Winogrande":69.93,
        "GSM8K":54.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":38.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-openhermes-2.5-sft",
        "Average":61.14,
        "ARC":59.47,
        "HellaSwag":83.2,
        "MMLU":61.32,
        "TruthfulQA":48.52,
        "Winogrande":78.37,
        "GSM8K":35.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maldv\/SHRDFU-7b-beta",
        "Average":61.13,
        "ARC":66.38,
        "HellaSwag":85.03,
        "MMLU":60.29,
        "TruthfulQA":49.45,
        "Winogrande":77.74,
        "GSM8K":27.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/dolphin-2.1-mistral-7b",
        "Average":61.12,
        "ARC":64.42,
        "HellaSwag":84.92,
        "MMLU":63.32,
        "TruthfulQA":55.56,
        "Winogrande":77.74,
        "GSM8K":20.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.1",
        "Average":61.12,
        "ARC":59.64,
        "HellaSwag":81.52,
        "MMLU":60.57,
        "TruthfulQA":53.09,
        "Winogrande":76.8,
        "GSM8K":35.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Replete-AI\/Phi-Elothir",
        "Average":61.11,
        "ARC":59.56,
        "HellaSwag":75.63,
        "MMLU":58.45,
        "TruthfulQA":51.23,
        "Winogrande":73.88,
        "GSM8K":47.92,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":5.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/spin-phi2-1.5",
        "Average":61.11,
        "ARC":63.65,
        "HellaSwag":75.79,
        "MMLU":56.52,
        "TruthfulQA":46.4,
        "Winogrande":73.16,
        "GSM8K":51.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/spin-phi2-2",
        "Average":61.11,
        "ARC":63.65,
        "HellaSwag":75.79,
        "MMLU":56.52,
        "TruthfulQA":46.4,
        "Winogrande":73.16,
        "GSM8K":51.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zardos\/Kant-Test-0.1-Mistral-7B",
        "Average":61.1,
        "ARC":61.77,
        "HellaSwag":82.89,
        "MMLU":62.86,
        "TruthfulQA":49.4,
        "Winogrande":78.53,
        "GSM8K":31.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"l3utterfly\/phi-2-layla-v1",
        "Average":61.09,
        "ARC":60.84,
        "HellaSwag":75.0,
        "MMLU":57.85,
        "TruthfulQA":44.01,
        "Winogrande":74.19,
        "GSM8K":54.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pinkyponky\/Mistral-7B-Instruct-Sft-Tuned-V0.2",
        "Average":61.08,
        "ARC":57.34,
        "HellaSwag":78.95,
        "MMLU":57.9,
        "TruthfulQA":50.66,
        "Winogrande":76.16,
        "GSM8K":45.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aihub-app\/ZySec-7B-v1",
        "Average":61.08,
        "ARC":63.48,
        "HellaSwag":85.01,
        "MMLU":60.14,
        "TruthfulQA":56.49,
        "Winogrande":78.14,
        "GSM8K":23.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lole25\/phi-2-sft-lora-ultrachat",
        "Average":61.07,
        "ARC":61.26,
        "HellaSwag":74.86,
        "MMLU":57.26,
        "TruthfulQA":45.46,
        "Winogrande":74.19,
        "GSM8K":53.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Dans-DiscountModels\/Dans-07YahooAnswers-7b",
        "Average":61.07,
        "ARC":61.52,
        "HellaSwag":83.69,
        "MMLU":63.52,
        "TruthfulQA":41.84,
        "Winogrande":78.53,
        "GSM8K":37.3,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-v0.1-raw-80k",
        "Average":61.07,
        "ARC":61.52,
        "HellaSwag":83.57,
        "MMLU":63.67,
        "TruthfulQA":43.02,
        "Winogrande":78.53,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TencentARC\/Mistral_Pro_8B_v0.1",
        "Average":61.06,
        "ARC":62.2,
        "HellaSwag":82.13,
        "MMLU":61.74,
        "TruthfulQA":49.32,
        "Winogrande":76.8,
        "GSM8K":34.19,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":62.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause-qLoRa",
        "Average":61.05,
        "ARC":60.41,
        "HellaSwag":82.76,
        "MMLU":62.15,
        "TruthfulQA":47.13,
        "Winogrande":78.85,
        "GSM8K":35.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause",
        "Average":61.05,
        "ARC":60.41,
        "HellaSwag":82.76,
        "MMLU":62.15,
        "TruthfulQA":47.13,
        "Winogrande":78.85,
        "GSM8K":35.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kimwooglae\/AISquare-Instruct-SOLAR-10.7b-v0.5.31",
        "Average":61.05,
        "ARC":60.67,
        "HellaSwag":84.2,
        "MMLU":52.86,
        "TruthfulQA":51.35,
        "Winogrande":82.95,
        "GSM8K":34.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gmonsoon\/Delta-4B-Base",
        "Average":61.04,
        "ARC":58.62,
        "HellaSwag":76.29,
        "MMLU":59.06,
        "TruthfulQA":51.74,
        "Winogrande":73.64,
        "GSM8K":46.93,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/delta-4B-super",
        "Average":61.04,
        "ARC":58.62,
        "HellaSwag":76.29,
        "MMLU":59.06,
        "TruthfulQA":51.74,
        "Winogrande":73.64,
        "GSM8K":46.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"venkycs\/ZySec-7B-Adapter",
        "Average":61.04,
        "ARC":63.48,
        "HellaSwag":85.0,
        "MMLU":60.22,
        "TruthfulQA":56.49,
        "Winogrande":78.14,
        "GSM8K":22.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KeyonZeng\/philion-2",
        "Average":61.02,
        "ARC":61.6,
        "HellaSwag":75.06,
        "MMLU":58.12,
        "TruthfulQA":44.47,
        "Winogrande":74.27,
        "GSM8K":52.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/OpenCerebrum-1.0-7b-SFT",
        "Average":61.01,
        "ARC":60.07,
        "HellaSwag":83.25,
        "MMLU":62.71,
        "TruthfulQA":41.45,
        "Winogrande":79.16,
        "GSM8K":39.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-hermes-code-7b",
        "Average":61.01,
        "ARC":59.39,
        "HellaSwag":78.59,
        "MMLU":59.95,
        "TruthfulQA":51.33,
        "Winogrande":77.51,
        "GSM8K":39.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-2.1-mistral-7b",
        "Average":61.0,
        "ARC":63.99,
        "HellaSwag":85.0,
        "MMLU":63.44,
        "TruthfulQA":55.57,
        "Winogrande":77.9,
        "GSM8K":20.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Mistral-7B-v0.1-activity-fine-tuned-v5",
        "Average":60.98,
        "ARC":60.07,
        "HellaSwag":83.3,
        "MMLU":64.09,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Cartinoe5930\/Llama2_init_Mistral",
        "Average":60.98,
        "ARC":60.07,
        "HellaSwag":83.3,
        "MMLU":64.09,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.91,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Mistral-7B-v0.1-activity-fine-tuned-v2",
        "Average":60.98,
        "ARC":60.07,
        "HellaSwag":83.3,
        "MMLU":64.09,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Mistral-7B-v0.1-activity-fine-tuned-v3",
        "Average":60.98,
        "ARC":60.07,
        "HellaSwag":83.3,
        "MMLU":64.09,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Mistral-7B-v0.1-gpt-4-20k",
        "Average":60.98,
        "ARC":60.07,
        "HellaSwag":83.3,
        "MMLU":64.09,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Average":60.97,
        "ARC":59.98,
        "HellaSwag":83.31,
        "MMLU":64.16,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.83,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3048.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Ichsan2895\/Merak-7B-v5-PROTOTYPE1",
        "Average":60.96,
        "ARC":62.2,
        "HellaSwag":82.07,
        "MMLU":60.97,
        "TruthfulQA":45.41,
        "Winogrande":77.9,
        "GSM8K":37.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_dmbr03_32_sig",
        "Average":60.95,
        "ARC":59.98,
        "HellaSwag":83.22,
        "MMLU":61.22,
        "TruthfulQA":47.9,
        "Winogrande":78.06,
        "GSM8K":35.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Pallas-0.5-frankenmerge",
        "Average":60.95,
        "ARC":61.77,
        "HellaSwag":80.36,
        "MMLU":67.62,
        "TruthfulQA":54.07,
        "Winogrande":77.74,
        "GSM8K":24.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":36.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-falcon-40b-v16.1-4k",
        "Average":60.94,
        "ARC":60.58,
        "HellaSwag":83.86,
        "MMLU":56.05,
        "TruthfulQA":50.57,
        "Winogrande":77.82,
        "GSM8K":36.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":41.35,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Mistralpaca-7B",
        "Average":60.94,
        "ARC":62.03,
        "HellaSwag":83.44,
        "MMLU":59.5,
        "TruthfulQA":53.17,
        "Winogrande":74.35,
        "GSM8K":33.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Reverb\/Mistral-7B-LoreWeaver",
        "Average":60.93,
        "ARC":59.98,
        "HellaSwag":83.29,
        "MMLU":64.12,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-moloras-7b",
        "Average":60.93,
        "ARC":59.98,
        "HellaSwag":83.29,
        "MMLU":64.12,
        "TruthfulQA":42.15,
        "Winogrande":78.37,
        "GSM8K":37.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"andysalerno\/mistral-sft-v3",
        "Average":60.93,
        "ARC":61.35,
        "HellaSwag":82.23,
        "MMLU":63.4,
        "TruthfulQA":48.49,
        "Winogrande":77.66,
        "GSM8K":32.45,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rizla\/rizla55b",
        "Average":60.93,
        "ARC":60.32,
        "HellaSwag":80.42,
        "MMLU":63.54,
        "TruthfulQA":55.59,
        "Winogrande":78.85,
        "GSM8K":26.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nd-4.0",
        "Available on the Hub":55.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_nucleus09_32_sig",
        "Average":60.93,
        "ARC":59.73,
        "HellaSwag":83.14,
        "MMLU":61.42,
        "TruthfulQA":46.37,
        "Winogrande":78.06,
        "GSM8K":36.85,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"huseyinatahaninan\/phi-2-instruction",
        "Average":60.92,
        "ARC":61.35,
        "HellaSwag":74.73,
        "MMLU":57.77,
        "TruthfulQA":44.96,
        "Winogrande":74.19,
        "GSM8K":52.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v17.1-32k",
        "Average":60.92,
        "ARC":55.55,
        "HellaSwag":77.95,
        "MMLU":58.29,
        "TruthfulQA":56.06,
        "Winogrande":74.98,
        "GSM8K":42.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/openchat-3.5-0106-11b",
        "Average":60.91,
        "ARC":63.65,
        "HellaSwag":78.64,
        "MMLU":62.54,
        "TruthfulQA":48.07,
        "Winogrande":78.06,
        "GSM8K":34.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upstage\/llama-30b-instruct-2048",
        "Average":60.91,
        "ARC":64.93,
        "HellaSwag":84.94,
        "MMLU":61.9,
        "TruthfulQA":56.3,
        "Winogrande":79.56,
        "GSM8K":17.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":103.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HiTZ\/alpaca-lora-65b-en-pt-es-ca",
        "Average":60.89,
        "ARC":65.02,
        "HellaSwag":84.88,
        "MMLU":62.19,
        "TruthfulQA":46.06,
        "Winogrande":80.51,
        "GSM8K":26.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":65.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AIJUUD\/juud-Mistral-7B-dpo",
        "Average":60.89,
        "ARC":66.81,
        "HellaSwag":84.89,
        "MMLU":63.03,
        "TruthfulQA":53.51,
        "Winogrande":78.3,
        "GSM8K":18.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-Instruct-v0.2-gpt-4-80k-base_lora",
        "Average":60.86,
        "ARC":59.47,
        "HellaSwag":79.7,
        "MMLU":58.5,
        "TruthfulQA":68.32,
        "Winogrande":70.32,
        "GSM8K":28.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"huseyinatahaninan\/phi-2-instruction",
        "Average":60.86,
        "ARC":61.09,
        "HellaSwag":74.68,
        "MMLU":57.81,
        "TruthfulQA":45.1,
        "Winogrande":74.82,
        "GSM8K":51.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_dmbr05_32_sig",
        "Average":60.85,
        "ARC":59.9,
        "HellaSwag":83.28,
        "MMLU":60.86,
        "TruthfulQA":49.69,
        "Winogrande":77.19,
        "GSM8K":34.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-dolphin-sft",
        "Average":60.84,
        "ARC":57.25,
        "HellaSwag":83.01,
        "MMLU":62.59,
        "TruthfulQA":48.91,
        "Winogrande":77.51,
        "GSM8K":35.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/SlimOpenOrca-Mistral-7B",
        "Average":60.84,
        "ARC":62.97,
        "HellaSwag":83.49,
        "MMLU":62.3,
        "TruthfulQA":57.39,
        "Winogrande":77.43,
        "GSM8K":21.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Einstein-7B",
        "Average":60.81,
        "ARC":61.6,
        "HellaSwag":84.35,
        "MMLU":62.87,
        "TruthfulQA":42.55,
        "Winogrande":77.51,
        "GSM8K":36.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"linlinlin\/zephy_SFT_Hermes",
        "Average":60.8,
        "ARC":60.32,
        "HellaSwag":83.37,
        "MMLU":63.81,
        "TruthfulQA":42.17,
        "Winogrande":78.06,
        "GSM8K":37.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/llmdo-Mistral-7B-case-c",
        "Average":60.8,
        "ARC":60.92,
        "HellaSwag":82.92,
        "MMLU":61.8,
        "TruthfulQA":44.69,
        "Winogrande":78.61,
        "GSM8K":35.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"CalderaAI\/30B-Epsilon",
        "Average":60.8,
        "ARC":63.05,
        "HellaSwag":83.59,
        "MMLU":56.89,
        "TruthfulQA":59.03,
        "Winogrande":77.66,
        "GSM8K":24.56,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"awnr\/Mistral-7B-v0.1-half-naive-A",
        "Average":60.79,
        "ARC":60.32,
        "HellaSwag":83.22,
        "MMLU":64.16,
        "TruthfulQA":42.28,
        "Winogrande":77.9,
        "GSM8K":36.85,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-dolphin-orca-platypus-samantha-7b",
        "Average":60.79,
        "ARC":64.33,
        "HellaSwag":84.4,
        "MMLU":63.72,
        "TruthfulQA":52.52,
        "Winogrande":78.37,
        "GSM8K":21.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-m2.0",
        "Average":60.79,
        "ARC":65.02,
        "HellaSwag":86.35,
        "MMLU":64.37,
        "TruthfulQA":46.66,
        "Winogrande":80.19,
        "GSM8K":22.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishekchohan\/mistral-7B-forest-v0.1",
        "Average":60.79,
        "ARC":60.58,
        "HellaSwag":83.13,
        "MMLU":63.69,
        "TruthfulQA":43.7,
        "Winogrande":78.06,
        "GSM8K":35.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_mbr_32_sig",
        "Average":60.79,
        "ARC":59.64,
        "HellaSwag":83.1,
        "MMLU":61.43,
        "TruthfulQA":46.31,
        "Winogrande":78.14,
        "GSM8K":36.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_kmmbr_32_sig",
        "Average":60.78,
        "ARC":58.96,
        "HellaSwag":82.84,
        "MMLU":61.39,
        "TruthfulQA":46.2,
        "Winogrande":77.74,
        "GSM8K":37.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"l3utterfly\/phi-2-layla-v1-chatml",
        "Average":60.77,
        "ARC":60.41,
        "HellaSwag":74.58,
        "MMLU":56.62,
        "TruthfulQA":44.21,
        "Winogrande":74.27,
        "GSM8K":54.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddyEA\/openbuddy-llama-30b-v7.1-bf16",
        "Average":60.76,
        "ARC":62.37,
        "HellaSwag":82.29,
        "MMLU":58.18,
        "TruthfulQA":52.6,
        "Winogrande":77.51,
        "GSM8K":31.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-six-in-one-7b",
        "Average":60.76,
        "ARC":62.97,
        "HellaSwag":84.6,
        "MMLU":63.29,
        "TruthfulQA":57.77,
        "Winogrande":77.51,
        "GSM8K":18.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MetaIX\/GPT4-X-Alpasta-30b",
        "Average":60.76,
        "ARC":63.05,
        "HellaSwag":83.56,
        "MMLU":57.71,
        "TruthfulQA":51.52,
        "Winogrande":78.22,
        "GSM8K":30.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":64.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Mistral-NeuralDPO-v0.3",
        "Average":60.75,
        "ARC":61.6,
        "HellaSwag":83.15,
        "MMLU":61.6,
        "TruthfulQA":45.31,
        "Winogrande":77.98,
        "GSM8K":34.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Yhyu13\/oasst-rlhf-2-llama-30b-7k-steps-hf",
        "Average":60.74,
        "ARC":61.35,
        "HellaSwag":83.8,
        "MMLU":57.89,
        "TruthfulQA":51.18,
        "Winogrande":78.77,
        "GSM8K":31.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/merlin1.3",
        "Average":60.74,
        "ARC":59.98,
        "HellaSwag":75.19,
        "MMLU":57.66,
        "TruthfulQA":46.77,
        "Winogrande":75.93,
        "GSM8K":48.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Venomia-m7",
        "Average":60.74,
        "ARC":63.14,
        "HellaSwag":84.0,
        "MMLU":60.06,
        "TruthfulQA":49.08,
        "Winogrande":75.77,
        "GSM8K":32.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-platypus-SOLAR-10.7B-v1.0",
        "Average":60.71,
        "ARC":62.54,
        "HellaSwag":84.15,
        "MMLU":61.95,
        "TruthfulQA":51.91,
        "Winogrande":83.11,
        "GSM8K":20.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddyEA\/openbuddy-llama-30b-v7.1-bf16",
        "Average":60.71,
        "ARC":62.46,
        "HellaSwag":82.3,
        "MMLU":58.15,
        "TruthfulQA":52.57,
        "Winogrande":77.82,
        "GSM8K":30.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"duoqi\/Nanbeige-16B-Base-Llama",
        "Average":60.7,
        "ARC":56.48,
        "HellaSwag":78.97,
        "MMLU":63.34,
        "TruthfulQA":42.6,
        "Winogrande":75.77,
        "GSM8K":47.01,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":15.83,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v17.1-32k",
        "Average":60.69,
        "ARC":55.38,
        "HellaSwag":78.0,
        "MMLU":58.08,
        "TruthfulQA":56.07,
        "Winogrande":75.22,
        "GSM8K":41.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-m2.0",
        "Average":60.68,
        "ARC":65.1,
        "HellaSwag":86.34,
        "MMLU":64.32,
        "TruthfulQA":46.63,
        "Winogrande":80.11,
        "GSM8K":21.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-1.4-peft",
        "Average":60.67,
        "ARC":65.78,
        "HellaSwag":85.83,
        "MMLU":62.27,
        "TruthfulQA":52.45,
        "Winogrande":79.64,
        "GSM8K":18.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":65.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"jondurbin\/airoboros-65b-gpt4-1.4",
        "Average":60.67,
        "ARC":65.78,
        "HellaSwag":85.83,
        "MMLU":62.27,
        "TruthfulQA":52.45,
        "Winogrande":79.64,
        "GSM8K":18.04,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tijmen2\/cosmosage_v2",
        "Average":60.66,
        "ARC":59.73,
        "HellaSwag":80.9,
        "MMLU":59.57,
        "TruthfulQA":50.98,
        "Winogrande":75.93,
        "GSM8K":36.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TeeZee\/2xbagel-dpo-34b-v0.2",
        "Average":60.66,
        "ARC":65.27,
        "HellaSwag":79.35,
        "MMLU":73.64,
        "TruthfulQA":67.15,
        "Winogrande":76.4,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":56.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulilioaica\/Collin-7B-dare",
        "Average":60.65,
        "ARC":65.87,
        "HellaSwag":82.08,
        "MMLU":51.86,
        "TruthfulQA":65.2,
        "Winogrande":77.9,
        "GSM8K":21.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-slimorca-sft",
        "Average":60.63,
        "ARC":58.53,
        "HellaSwag":83.16,
        "MMLU":60.71,
        "TruthfulQA":50.18,
        "Winogrande":78.93,
        "GSM8K":32.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-1-0",
        "Average":60.63,
        "ARC":60.41,
        "HellaSwag":83.08,
        "MMLU":62.94,
        "TruthfulQA":41.82,
        "Winogrande":78.69,
        "GSM8K":36.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-2-0",
        "Average":60.63,
        "ARC":60.41,
        "HellaSwag":83.08,
        "MMLU":62.94,
        "TruthfulQA":41.82,
        "Winogrande":78.69,
        "GSM8K":36.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-0-0",
        "Average":60.63,
        "ARC":60.41,
        "HellaSwag":83.08,
        "MMLU":62.94,
        "TruthfulQA":41.82,
        "Winogrande":78.69,
        "GSM8K":36.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/merlin1.5",
        "Average":60.62,
        "ARC":59.56,
        "HellaSwag":74.63,
        "MMLU":56.59,
        "TruthfulQA":48.03,
        "Winogrande":74.66,
        "GSM8K":50.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/orpo-lora-phi2",
        "Average":60.62,
        "ARC":60.32,
        "HellaSwag":74.58,
        "MMLU":58.12,
        "TruthfulQA":44.5,
        "Winogrande":73.72,
        "GSM8K":52.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"0-hero\/Matter-0.1-Slim-7B-B",
        "Average":60.61,
        "ARC":60.75,
        "HellaSwag":81.55,
        "MMLU":61.01,
        "TruthfulQA":41.91,
        "Winogrande":77.82,
        "GSM8K":40.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Zephyrus-L1-33B",
        "Average":60.61,
        "ARC":64.51,
        "HellaSwag":84.15,
        "MMLU":57.37,
        "TruthfulQA":53.87,
        "Winogrande":80.19,
        "GSM8K":23.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistral-7B-alpaca-1-epoch",
        "Average":60.61,
        "ARC":61.77,
        "HellaSwag":82.66,
        "MMLU":63.09,
        "TruthfulQA":43.35,
        "Winogrande":77.9,
        "GSM8K":34.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"csujeong\/Mistral-7B-Finetuning-Insurance-16R",
        "Average":60.6,
        "ARC":60.84,
        "HellaSwag":83.44,
        "MMLU":63.61,
        "TruthfulQA":43.11,
        "Winogrande":78.45,
        "GSM8K":34.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/OpenMia-Indo-Mistral-7b-v2",
        "Average":60.6,
        "ARC":60.32,
        "HellaSwag":83.11,
        "MMLU":62.7,
        "TruthfulQA":44.35,
        "Winogrande":78.3,
        "GSM8K":34.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-1.4",
        "Average":60.59,
        "ARC":65.53,
        "HellaSwag":85.77,
        "MMLU":61.95,
        "TruthfulQA":52.43,
        "Winogrande":79.79,
        "GSM8K":18.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Walmart-the-bag\/Influxient-4x13B",
        "Average":60.57,
        "ARC":61.26,
        "HellaSwag":83.42,
        "MMLU":57.25,
        "TruthfulQA":54.1,
        "Winogrande":74.35,
        "GSM8K":33.06,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":38.5,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-7B-v0.3-dpo",
        "Average":60.55,
        "ARC":62.8,
        "HellaSwag":82.58,
        "MMLU":61.46,
        "TruthfulQA":56.46,
        "Winogrande":76.24,
        "GSM8K":23.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-2.2.1-mistral-7b",
        "Average":60.54,
        "ARC":63.48,
        "HellaSwag":83.86,
        "MMLU":63.28,
        "TruthfulQA":53.17,
        "Winogrande":78.37,
        "GSM8K":21.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/OpenMia-Indo-Mistral-7b",
        "Average":60.54,
        "ARC":59.64,
        "HellaSwag":83.18,
        "MMLU":62.75,
        "TruthfulQA":45.26,
        "Winogrande":77.82,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/kalomaze-stuff",
        "Average":60.53,
        "ARC":59.64,
        "HellaSwag":83.55,
        "MMLU":63.41,
        "TruthfulQA":41.64,
        "Winogrande":78.61,
        "GSM8K":36.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Mistral-11B-TestBench9",
        "Average":60.52,
        "ARC":64.08,
        "HellaSwag":84.24,
        "MMLU":64.0,
        "TruthfulQA":56.19,
        "Winogrande":78.45,
        "GSM8K":16.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/WizardLM-70B-V1.0-GPTQ",
        "Average":60.5,
        "ARC":63.82,
        "HellaSwag":83.85,
        "MMLU":63.68,
        "TruthfulQA":54.54,
        "Winogrande":78.61,
        "GSM8K":18.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":72.82,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"prince-canuma\/Damysus-2.7B-Chat",
        "Average":60.49,
        "ARC":59.81,
        "HellaSwag":74.52,
        "MMLU":56.33,
        "TruthfulQA":46.74,
        "Winogrande":74.9,
        "GSM8K":50.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"traversaal-ai\/traversaal-2.5-Mistral-7B",
        "Average":60.48,
        "ARC":66.21,
        "HellaSwag":85.02,
        "MMLU":63.24,
        "TruthfulQA":54.0,
        "Winogrande":77.9,
        "GSM8K":16.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Dolphin2.1-OpenOrca-7B",
        "Average":60.47,
        "ARC":63.91,
        "HellaSwag":84.26,
        "MMLU":62.66,
        "TruthfulQA":53.84,
        "Winogrande":78.22,
        "GSM8K":19.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"InnerI\/A-I-0xtom-7B-slerp",
        "Average":60.46,
        "ARC":58.19,
        "HellaSwag":77.64,
        "MMLU":58.74,
        "TruthfulQA":54.78,
        "Winogrande":73.24,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/Mistral-7B-Alpaca-52k-v0.1",
        "Average":60.46,
        "ARC":60.92,
        "HellaSwag":82.13,
        "MMLU":63.41,
        "TruthfulQA":41.5,
        "Winogrande":77.35,
        "GSM8K":37.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-metamathqa-sft",
        "Average":60.46,
        "ARC":58.45,
        "HellaSwag":80.44,
        "MMLU":61.28,
        "TruthfulQA":44.73,
        "Winogrande":77.66,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Stellaris-internlm2-20b-r512",
        "Average":60.46,
        "ARC":63.82,
        "HellaSwag":84.0,
        "MMLU":66.34,
        "TruthfulQA":49.51,
        "Winogrande":84.45,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"TehVenom\/oasst-sft-6-llama-33b-xor-MERGED-16bit",
        "Average":60.45,
        "ARC":61.52,
        "HellaSwag":83.5,
        "MMLU":57.43,
        "TruthfulQA":50.7,
        "Winogrande":79.08,
        "GSM8K":30.48,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":33.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/Instruct_Mistral-7B-v0.1_Dolly15K",
        "Average":60.45,
        "ARC":59.39,
        "HellaSwag":82.62,
        "MMLU":62.71,
        "TruthfulQA":43.56,
        "Winogrande":79.32,
        "GSM8K":35.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause-non-qLoRa",
        "Average":60.44,
        "ARC":60.32,
        "HellaSwag":82.92,
        "MMLU":62.3,
        "TruthfulQA":45.47,
        "Winogrande":78.06,
        "GSM8K":33.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/experiment2-cause-non",
        "Average":60.44,
        "ARC":60.32,
        "HellaSwag":82.92,
        "MMLU":62.3,
        "TruthfulQA":45.47,
        "Winogrande":78.06,
        "GSM8K":33.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_dmbr10_32_sig",
        "Average":60.43,
        "ARC":58.62,
        "HellaSwag":82.57,
        "MMLU":61.35,
        "TruthfulQA":44.34,
        "Winogrande":77.9,
        "GSM8K":37.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/mistral_dmbr20_32_sig",
        "Average":60.43,
        "ARC":58.7,
        "HellaSwag":82.54,
        "MMLU":61.41,
        "TruthfulQA":44.75,
        "Winogrande":77.58,
        "GSM8K":37.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aeala\/GPT4-x-AlpacaDente-30b",
        "Average":60.43,
        "ARC":62.12,
        "HellaSwag":82.78,
        "MMLU":56.19,
        "TruthfulQA":52.68,
        "Winogrande":78.69,
        "GSM8K":30.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pansophic\/m17",
        "Average":60.42,
        "ARC":59.64,
        "HellaSwag":74.41,
        "MMLU":56.12,
        "TruthfulQA":46.62,
        "Winogrande":75.93,
        "GSM8K":49.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardMath-70B-V1.0",
        "Average":60.42,
        "ARC":68.17,
        "HellaSwag":86.49,
        "MMLU":68.89,
        "TruthfulQA":52.69,
        "Winogrande":82.32,
        "GSM8K":3.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":115.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aivince\/alpaca_mistral-7b-v0.2",
        "Average":60.41,
        "ARC":60.92,
        "HellaSwag":83.28,
        "MMLU":61.82,
        "TruthfulQA":42.66,
        "Winogrande":79.16,
        "GSM8K":34.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardMath-70B-V1.0",
        "Average":60.41,
        "ARC":67.92,
        "HellaSwag":86.46,
        "MMLU":68.92,
        "TruthfulQA":52.77,
        "Winogrande":82.32,
        "GSM8K":4.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":115.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/delta-4B-scientific",
        "Average":60.41,
        "ARC":59.39,
        "HellaSwag":74.1,
        "MMLU":57.56,
        "TruthfulQA":48.39,
        "Winogrande":75.93,
        "GSM8K":47.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Xenon1\/Xenon-4",
        "Average":60.39,
        "ARC":60.15,
        "HellaSwag":83.07,
        "MMLU":60.08,
        "TruthfulQA":61.31,
        "Winogrande":77.03,
        "GSM8K":20.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/SlimOrca-13B",
        "Average":60.39,
        "ARC":60.15,
        "HellaSwag":81.4,
        "MMLU":57.04,
        "TruthfulQA":49.37,
        "Winogrande":74.43,
        "GSM8K":39.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-mistral-7b-dare-0.85",
        "Average":60.39,
        "ARC":63.31,
        "HellaSwag":84.93,
        "MMLU":64.22,
        "TruthfulQA":50.68,
        "Winogrande":79.32,
        "GSM8K":19.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pansophic\/m2",
        "Average":60.39,
        "ARC":61.26,
        "HellaSwag":75.28,
        "MMLU":54.73,
        "TruthfulQA":48.17,
        "Winogrande":74.19,
        "GSM8K":48.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Dolphin2.1-OpenOrca-7B",
        "Average":60.38,
        "ARC":64.16,
        "HellaSwag":84.25,
        "MMLU":62.7,
        "TruthfulQA":53.83,
        "Winogrande":77.66,
        "GSM8K":19.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"liminerity\/Mistral-quiet-star",
        "Average":60.37,
        "ARC":61.18,
        "HellaSwag":84.59,
        "MMLU":62.03,
        "TruthfulQA":45.1,
        "Winogrande":77.11,
        "GSM8K":32.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcel\/phi-2-openhermes-30k",
        "Average":60.37,
        "ARC":61.01,
        "HellaSwag":74.72,
        "MMLU":57.17,
        "TruthfulQA":45.38,
        "Winogrande":74.9,
        "GSM8K":49.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/Mistral-7B-SlimOrca",
        "Average":60.37,
        "ARC":62.54,
        "HellaSwag":83.86,
        "MMLU":62.77,
        "TruthfulQA":54.23,
        "Winogrande":77.43,
        "GSM8K":21.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EmbeddedLLM\/Mistral-7B-Merge-14-v0.3-ft-step-9984",
        "Average":60.37,
        "ARC":62.54,
        "HellaSwag":82.18,
        "MMLU":62.92,
        "TruthfulQA":53.7,
        "Winogrande":75.61,
        "GSM8K":25.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Obrolin\/Kesehatan-7B-v0.1",
        "Average":60.37,
        "ARC":60.32,
        "HellaSwag":82.54,
        "MMLU":59.94,
        "TruthfulQA":50.68,
        "Winogrande":76.48,
        "GSM8K":32.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Mistral-7bx2-48layers_v1.2",
        "Average":60.36,
        "ARC":56.31,
        "HellaSwag":77.83,
        "MMLU":57.91,
        "TruthfulQA":46.12,
        "Winogrande":74.19,
        "GSM8K":49.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/merlin1.2",
        "Average":60.36,
        "ARC":59.22,
        "HellaSwag":74.19,
        "MMLU":56.45,
        "TruthfulQA":46.24,
        "Winogrande":74.98,
        "GSM8K":51.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"Weyaxi\/Mistral-7B-v0.2-hf-duplicate",
        "Average":60.34,
        "ARC":60.49,
        "HellaSwag":82.94,
        "MMLU":63.42,
        "TruthfulQA":41.8,
        "Winogrande":78.69,
        "GSM8K":34.72,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chrischain\/SatoshiNv5",
        "Average":60.34,
        "ARC":60.49,
        "HellaSwag":82.94,
        "MMLU":63.42,
        "TruthfulQA":41.8,
        "Winogrande":78.69,
        "GSM8K":34.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"unsloth\/mistral-7b-v0.2",
        "Average":60.34,
        "ARC":60.49,
        "HellaSwag":82.94,
        "MMLU":63.42,
        "TruthfulQA":41.8,
        "Winogrande":78.69,
        "GSM8K":34.72,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/InnerI-AI-sn6-7B-slerp",
        "Average":60.32,
        "ARC":58.36,
        "HellaSwag":77.58,
        "MMLU":58.82,
        "TruthfulQA":54.7,
        "Winogrande":72.93,
        "GSM8K":39.5,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BlouseJury\/Mistral-7B-Discord-0.1",
        "Average":60.28,
        "ARC":60.24,
        "HellaSwag":83.13,
        "MMLU":62.82,
        "TruthfulQA":44.1,
        "Winogrande":78.93,
        "GSM8K":32.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Xenon1\/Xenon-3",
        "Average":60.27,
        "ARC":58.87,
        "HellaSwag":83.39,
        "MMLU":59.79,
        "TruthfulQA":61.99,
        "Winogrande":77.51,
        "GSM8K":20.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"diffnamehard\/Psyfighter2-Noromaid-ties-Capybara-13B",
        "Average":60.27,
        "ARC":62.29,
        "HellaSwag":83.87,
        "MMLU":56.59,
        "TruthfulQA":51.44,
        "Winogrande":77.03,
        "GSM8K":30.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_3.5",
        "Average":60.26,
        "ARC":62.46,
        "HellaSwag":83.96,
        "MMLU":62.89,
        "TruthfulQA":45.43,
        "Winogrande":81.06,
        "GSM8K":25.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1078.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-0-1",
        "Average":60.26,
        "ARC":60.84,
        "HellaSwag":83.05,
        "MMLU":62.72,
        "TruthfulQA":41.43,
        "Winogrande":78.85,
        "GSM8K":34.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/SlimOpenOrca-Mistral-7B-v2",
        "Average":60.25,
        "ARC":62.88,
        "HellaSwag":83.41,
        "MMLU":62.05,
        "TruthfulQA":56.65,
        "Winogrande":77.58,
        "GSM8K":18.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Mistral-11B-TestBench11",
        "Average":60.25,
        "ARC":64.42,
        "HellaSwag":83.93,
        "MMLU":63.82,
        "TruthfulQA":56.68,
        "Winogrande":77.74,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"prince-canuma\/Damysus-2.7B-Chat",
        "Average":60.25,
        "ARC":59.13,
        "HellaSwag":74.36,
        "MMLU":56.34,
        "TruthfulQA":46.45,
        "Winogrande":75.06,
        "GSM8K":50.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/wendigo-14b-alpha4",
        "Average":60.25,
        "ARC":59.3,
        "HellaSwag":79.65,
        "MMLU":59.85,
        "TruthfulQA":54.98,
        "Winogrande":74.74,
        "GSM8K":32.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pansophic\/m16",
        "Average":60.25,
        "ARC":59.81,
        "HellaSwag":74.82,
        "MMLU":56.31,
        "TruthfulQA":47.11,
        "Winogrande":75.14,
        "GSM8K":48.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/smartyplats-7b-v2",
        "Average":60.24,
        "ARC":57.94,
        "HellaSwag":80.76,
        "MMLU":58.16,
        "TruthfulQA":50.26,
        "Winogrande":75.53,
        "GSM8K":38.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pansophic\/m3",
        "Average":60.23,
        "ARC":60.41,
        "HellaSwag":74.49,
        "MMLU":56.51,
        "TruthfulQA":44.98,
        "Winogrande":76.72,
        "GSM8K":48.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lilloukas\/GPlatty-30B",
        "Average":60.23,
        "ARC":65.78,
        "HellaSwag":84.79,
        "MMLU":63.49,
        "TruthfulQA":52.45,
        "Winogrande":80.98,
        "GSM8K":13.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/form1",
        "Average":60.23,
        "ARC":58.79,
        "HellaSwag":75.25,
        "MMLU":56.83,
        "TruthfulQA":45.85,
        "Winogrande":74.9,
        "GSM8K":49.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"argilla\/notus-7b-v1",
        "Average":60.22,
        "ARC":64.59,
        "HellaSwag":84.78,
        "MMLU":63.03,
        "TruthfulQA":54.37,
        "Winogrande":79.4,
        "GSM8K":15.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SicariusSicariiStuff\/Tenebra_30B_Alpha01_FP16",
        "Average":60.18,
        "ARC":64.51,
        "HellaSwag":84.79,
        "MMLU":54.29,
        "TruthfulQA":54.22,
        "Winogrande":78.61,
        "GSM8K":24.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":32.53,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Average":60.17,
        "ARC":64.08,
        "HellaSwag":83.99,
        "MMLU":62.24,
        "TruthfulQA":53.05,
        "Winogrande":77.74,
        "GSM8K":19.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":632.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/SOLAR-10.7B-Instruct-v1.0-128k",
        "Average":60.16,
        "ARC":65.96,
        "HellaSwag":84.35,
        "MMLU":57.63,
        "TruthfulQA":65.42,
        "Winogrande":80.51,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/merlin1.4",
        "Average":60.15,
        "ARC":59.3,
        "HellaSwag":74.5,
        "MMLU":56.34,
        "TruthfulQA":47.36,
        "Winogrande":74.98,
        "GSM8K":48.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-65b-gpt4-1.3",
        "Average":60.15,
        "ARC":66.13,
        "HellaSwag":85.99,
        "MMLU":63.89,
        "TruthfulQA":51.32,
        "Winogrande":79.95,
        "GSM8K":13.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Eric111\/Yarn-Mistral-7b-128k-DPO",
        "Average":60.15,
        "ARC":60.84,
        "HellaSwag":82.99,
        "MMLU":63.09,
        "TruthfulQA":43.55,
        "Winogrande":78.3,
        "GSM8K":32.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-zephyr-6x7b-lora",
        "Average":60.13,
        "ARC":61.01,
        "HellaSwag":82.8,
        "MMLU":60.09,
        "TruthfulQA":48.84,
        "Winogrande":77.03,
        "GSM8K":31.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/wendigo-14b-alpha3",
        "Average":60.1,
        "ARC":59.39,
        "HellaSwag":79.51,
        "MMLU":59.72,
        "TruthfulQA":55.12,
        "Winogrande":74.74,
        "GSM8K":32.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MexIvanov\/zephyr-python-ru-merged",
        "Average":60.1,
        "ARC":56.06,
        "HellaSwag":82.06,
        "MMLU":60.2,
        "TruthfulQA":52.81,
        "Winogrande":76.95,
        "GSM8K":32.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/CollectiveCognition-v1-Mistral-7B",
        "Average":60.1,
        "ARC":62.37,
        "HellaSwag":85.5,
        "MMLU":62.76,
        "TruthfulQA":54.48,
        "Winogrande":77.58,
        "GSM8K":17.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MexIvanov\/zephyr-python-ru",
        "Average":60.08,
        "ARC":56.14,
        "HellaSwag":82.03,
        "MMLU":60.18,
        "TruthfulQA":52.8,
        "Winogrande":76.8,
        "GSM8K":32.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/ccy0-2g7e-wqsa-0",
        "Average":60.07,
        "ARC":58.19,
        "HellaSwag":82.19,
        "MMLU":59.59,
        "TruthfulQA":49.99,
        "Winogrande":78.22,
        "GSM8K":32.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistral-7B-alpaca-case-3-2",
        "Average":60.07,
        "ARC":62.2,
        "HellaSwag":83.19,
        "MMLU":62.19,
        "TruthfulQA":40.91,
        "Winogrande":77.03,
        "GSM8K":34.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-zephyr-6x7b",
        "Average":60.06,
        "ARC":60.75,
        "HellaSwag":82.8,
        "MMLU":60.03,
        "TruthfulQA":48.84,
        "Winogrande":77.03,
        "GSM8K":30.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":35.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jingyeom\/freeze_KoSoLAR-10.7B-v0.2_1.4_dedup",
        "Average":60.06,
        "ARC":58.45,
        "HellaSwag":81.26,
        "MMLU":64.83,
        "TruthfulQA":44.5,
        "Winogrande":79.08,
        "GSM8K":32.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-1-1",
        "Average":60.06,
        "ARC":60.92,
        "HellaSwag":82.87,
        "MMLU":62.87,
        "TruthfulQA":41.1,
        "Winogrande":78.37,
        "GSM8K":34.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/llama-30b-2048-instruct-PL-lora_unload",
        "Average":60.03,
        "ARC":63.82,
        "HellaSwag":84.7,
        "MMLU":61.49,
        "TruthfulQA":52.49,
        "Winogrande":79.79,
        "GSM8K":17.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/Metis-0.1",
        "Average":60.02,
        "ARC":60.15,
        "HellaSwag":82.85,
        "MMLU":61.42,
        "TruthfulQA":45.24,
        "Winogrande":77.27,
        "GSM8K":33.21,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/groot2",
        "Average":60.02,
        "ARC":59.04,
        "HellaSwag":73.88,
        "MMLU":56.38,
        "TruthfulQA":47.41,
        "Winogrande":75.93,
        "GSM8K":47.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Delcos\/Velara",
        "Average":60.01,
        "ARC":58.96,
        "HellaSwag":82.83,
        "MMLU":59.45,
        "TruthfulQA":44.7,
        "Winogrande":73.8,
        "GSM8K":40.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":11.39,
        "Model Sha":9.0
    },
    {
        "T":"?",
        "Model":"ehartford\/WizardLM-33B-V1.0-Uncensored",
        "Average":59.99,
        "ARC":63.65,
        "HellaSwag":83.84,
        "MMLU":59.36,
        "TruthfulQA":56.8,
        "Winogrande":77.66,
        "GSM8K":18.65,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/zephyr-dpo-v2",
        "Average":59.99,
        "ARC":57.85,
        "HellaSwag":82.72,
        "MMLU":58.61,
        "TruthfulQA":56.16,
        "Winogrande":74.35,
        "GSM8K":30.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"feeltheAGI\/mistral-maths7B",
        "Average":59.99,
        "ARC":52.05,
        "HellaSwag":74.77,
        "MMLU":54.54,
        "TruthfulQA":57.3,
        "Winogrande":72.45,
        "GSM8K":48.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-70b-Instruct-hf",
        "Average":59.98,
        "ARC":55.03,
        "HellaSwag":77.24,
        "MMLU":56.4,
        "TruthfulQA":50.44,
        "Winogrande":74.51,
        "GSM8K":46.25,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":189.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jebcarter\/psyonic-cetacean-20B",
        "Average":59.97,
        "ARC":63.57,
        "HellaSwag":86.2,
        "MMLU":59.66,
        "TruthfulQA":57.55,
        "Winogrande":78.14,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.99,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"0-hero\/Matter-0.1-Slim-7B-A",
        "Average":59.96,
        "ARC":60.49,
        "HellaSwag":81.33,
        "MMLU":60.68,
        "TruthfulQA":41.79,
        "Winogrande":77.35,
        "GSM8K":38.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Novocode7b",
        "Average":59.96,
        "ARC":58.79,
        "HellaSwag":80.51,
        "MMLU":56.5,
        "TruthfulQA":62.77,
        "Winogrande":78.14,
        "GSM8K":23.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/zephyr-7b-beta-gpt-4-80k",
        "Average":59.95,
        "ARC":60.84,
        "HellaSwag":79.08,
        "MMLU":60.67,
        "TruthfulQA":58.4,
        "Winogrande":74.03,
        "GSM8K":26.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Zenith-7B-dpo-v1",
        "Average":59.95,
        "ARC":60.75,
        "HellaSwag":82.97,
        "MMLU":60.55,
        "TruthfulQA":60.71,
        "Winogrande":77.51,
        "GSM8K":17.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ericpolewski\/AIRIC-The-Mistral",
        "Average":59.95,
        "ARC":59.98,
        "HellaSwag":82.98,
        "MMLU":60.67,
        "TruthfulQA":48.24,
        "Winogrande":76.95,
        "GSM8K":30.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Novocode7b-v3",
        "Average":59.94,
        "ARC":57.51,
        "HellaSwag":81.17,
        "MMLU":61.91,
        "TruthfulQA":48.29,
        "Winogrande":74.51,
        "GSM8K":36.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cookinai\/Blitz-v0.2",
        "Average":59.93,
        "ARC":59.04,
        "HellaSwag":83.0,
        "MMLU":62.96,
        "TruthfulQA":42.71,
        "Winogrande":78.3,
        "GSM8K":33.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Xenon1\/Xenon-2",
        "Average":59.93,
        "ARC":57.51,
        "HellaSwag":83.28,
        "MMLU":60.25,
        "TruthfulQA":60.92,
        "Winogrande":78.22,
        "GSM8K":19.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xriminact\/TarsChattyBasev0.0",
        "Average":59.92,
        "ARC":64.93,
        "HellaSwag":84.57,
        "MMLU":58.04,
        "TruthfulQA":61.71,
        "Winogrande":78.61,
        "GSM8K":11.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/Starling-LM-11B-alpha",
        "Average":59.92,
        "ARC":61.26,
        "HellaSwag":81.99,
        "MMLU":61.5,
        "TruthfulQA":41.53,
        "Winogrande":78.06,
        "GSM8K":35.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":59.9,
        "ARC":64.25,
        "HellaSwag":82.49,
        "MMLU":60.79,
        "TruthfulQA":56.4,
        "Winogrande":77.35,
        "GSM8K":18.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":531.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/Yi-6B-Infinity-Chat",
        "Average":59.83,
        "ARC":56.57,
        "HellaSwag":77.66,
        "MMLU":64.05,
        "TruthfulQA":50.75,
        "Winogrande":73.95,
        "GSM8K":36.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":6.06,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/samantha-1.2-mistral-7b",
        "Average":59.83,
        "ARC":64.08,
        "HellaSwag":85.08,
        "MMLU":63.91,
        "TruthfulQA":50.4,
        "Winogrande":78.53,
        "GSM8K":16.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/llama-30b-instruct-2048-PL-lora",
        "Average":59.82,
        "ARC":63.31,
        "HellaSwag":84.66,
        "MMLU":61.66,
        "TruthfulQA":53.35,
        "Winogrande":79.08,
        "GSM8K":16.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jilp00\/Hermes-2-SOLAR-10.7B-Symbolic",
        "Average":59.81,
        "ARC":61.69,
        "HellaSwag":82.57,
        "MMLU":65.06,
        "TruthfulQA":54.85,
        "Winogrande":80.74,
        "GSM8K":13.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardMath-70B-V1.0",
        "Average":59.81,
        "ARC":67.49,
        "HellaSwag":86.03,
        "MMLU":68.44,
        "TruthfulQA":52.23,
        "Winogrande":81.77,
        "GSM8K":2.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":70.0,
        "Model Sha":115.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Zenith-7B-dpo",
        "Average":59.8,
        "ARC":60.92,
        "HellaSwag":82.94,
        "MMLU":60.54,
        "TruthfulQA":60.5,
        "Winogrande":77.27,
        "GSM8K":16.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dball\/zephyr-7b-sft-qlora",
        "Average":59.8,
        "ARC":59.73,
        "HellaSwag":82.49,
        "MMLU":61.9,
        "TruthfulQA":42.32,
        "Winogrande":78.22,
        "GSM8K":34.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"theNovaAI\/Supernova-experimental",
        "Average":59.79,
        "ARC":63.05,
        "HellaSwag":83.66,
        "MMLU":56.59,
        "TruthfulQA":49.37,
        "Winogrande":77.35,
        "GSM8K":28.73,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kimwooglae\/AISquare-Instruct-SOLAR-10.7b-v0.5.32",
        "Average":59.79,
        "ARC":61.86,
        "HellaSwag":84.66,
        "MMLU":63.13,
        "TruthfulQA":51.19,
        "Winogrande":82.79,
        "GSM8K":15.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/mistral-7b-sft-beta",
        "Average":59.78,
        "ARC":57.42,
        "HellaSwag":82.23,
        "MMLU":61.42,
        "TruthfulQA":43.58,
        "Winogrande":77.58,
        "GSM8K":36.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Zenith-7B-dpo-v1",
        "Average":59.78,
        "ARC":60.49,
        "HellaSwag":82.95,
        "MMLU":60.39,
        "TruthfulQA":60.6,
        "Winogrande":77.27,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CorticalStack\/mistral-7b-openhermes-sft",
        "Average":59.78,
        "ARC":60.58,
        "HellaSwag":82.01,
        "MMLU":60.95,
        "TruthfulQA":46.31,
        "Winogrande":77.58,
        "GSM8K":31.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"neovalle\/H4rmoniousAnthea",
        "Average":59.76,
        "ARC":65.87,
        "HellaSwag":84.09,
        "MMLU":63.67,
        "TruthfulQA":55.08,
        "Winogrande":76.87,
        "GSM8K":12.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/bun_mistral_7b_v2",
        "Average":59.76,
        "ARC":59.9,
        "HellaSwag":82.65,
        "MMLU":61.77,
        "TruthfulQA":40.67,
        "Winogrande":78.3,
        "GSM8K":35.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Llama-2-70B-chat-GPTQ",
        "Average":59.75,
        "ARC":62.63,
        "HellaSwag":84.81,
        "MMLU":62.74,
        "TruthfulQA":50.98,
        "Winogrande":78.69,
        "GSM8K":18.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":72.82,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/Orca-2-13b-SFT-v4",
        "Average":59.75,
        "ARC":59.22,
        "HellaSwag":79.58,
        "MMLU":60.23,
        "TruthfulQA":51.15,
        "Winogrande":80.03,
        "GSM8K":28.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"crumb\/apricot-wildflower-20",
        "Average":59.74,
        "ARC":59.64,
        "HellaSwag":81.76,
        "MMLU":63.38,
        "TruthfulQA":41.76,
        "Winogrande":77.9,
        "GSM8K":33.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistral-7B-alpaca-case-2-2",
        "Average":59.73,
        "ARC":63.48,
        "HellaSwag":83.27,
        "MMLU":62.11,
        "TruthfulQA":45.17,
        "Winogrande":77.51,
        "GSM8K":26.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-thoughts-mistral-7b",
        "Average":59.72,
        "ARC":58.96,
        "HellaSwag":80.71,
        "MMLU":60.11,
        "TruthfulQA":49.91,
        "Winogrande":77.82,
        "GSM8K":30.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Mistral-7B-AEZAKMI-v2",
        "Average":59.69,
        "ARC":58.11,
        "HellaSwag":82.53,
        "MMLU":59.89,
        "TruthfulQA":51.5,
        "Winogrande":73.64,
        "GSM8K":32.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"joey00072\/ToxicHermes-2.5-Mistral-7B",
        "Average":59.69,
        "ARC":64.59,
        "HellaSwag":83.75,
        "MMLU":63.67,
        "TruthfulQA":50.84,
        "Winogrande":77.9,
        "GSM8K":17.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sarahlintang\/mistral-indo-7b",
        "Average":59.68,
        "ARC":61.09,
        "HellaSwag":81.19,
        "MMLU":62.99,
        "TruthfulQA":42.34,
        "Winogrande":78.37,
        "GSM8K":32.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Tiger-DPO",
        "Average":59.66,
        "ARC":48.21,
        "HellaSwag":81.82,
        "MMLU":59.85,
        "TruthfulQA":50.76,
        "Winogrande":76.32,
        "GSM8K":41.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NECOUDBFM\/Jellyfish",
        "Average":59.65,
        "ARC":63.31,
        "HellaSwag":83.19,
        "MMLU":58.6,
        "TruthfulQA":53.32,
        "Winogrande":75.85,
        "GSM8K":23.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-RP-Orca-2-7b-v0.1",
        "Average":59.65,
        "ARC":57.68,
        "HellaSwag":77.37,
        "MMLU":56.1,
        "TruthfulQA":52.52,
        "Winogrande":74.59,
        "GSM8K":39.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Orca-2-13B-no_robots",
        "Average":59.63,
        "ARC":59.13,
        "HellaSwag":79.57,
        "MMLU":60.28,
        "TruthfulQA":51.17,
        "Winogrande":80.35,
        "GSM8K":27.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Yarn-Mistral-7b-64k",
        "Average":59.63,
        "ARC":59.9,
        "HellaSwag":82.51,
        "MMLU":62.96,
        "TruthfulQA":41.86,
        "Winogrande":77.27,
        "GSM8K":33.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-2",
        "Average":59.63,
        "ARC":58.53,
        "HellaSwag":79.4,
        "MMLU":56.14,
        "TruthfulQA":49.59,
        "Winogrande":75.3,
        "GSM8K":38.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"G-reen\/EXPERIMENT-DPO-m7b2-2-merged",
        "Average":59.63,
        "ARC":59.47,
        "HellaSwag":82.47,
        "MMLU":62.31,
        "TruthfulQA":40.11,
        "Winogrande":78.3,
        "GSM8K":35.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sequelbox\/DiamondForce",
        "Average":59.63,
        "ARC":62.12,
        "HellaSwag":83.43,
        "MMLU":58.1,
        "TruthfulQA":46.46,
        "Winogrande":79.01,
        "GSM8K":28.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/SynthIA-7B-v1.5",
        "Average":59.59,
        "ARC":62.71,
        "HellaSwag":83.37,
        "MMLU":63.48,
        "TruthfulQA":51.32,
        "Winogrande":79.24,
        "GSM8K":17.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Test157t\/Kunocchini-1.2-7b-longtext",
        "Average":59.57,
        "ARC":59.9,
        "HellaSwag":82.51,
        "MMLU":63.05,
        "TruthfulQA":41.72,
        "Winogrande":77.35,
        "GSM8K":32.9,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistralai-case-2-1",
        "Average":59.57,
        "ARC":60.92,
        "HellaSwag":82.54,
        "MMLU":62.54,
        "TruthfulQA":41.49,
        "Winogrande":78.3,
        "GSM8K":31.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"nisten\/BigCodeLlama-92b",
        "Average":59.57,
        "ARC":54.78,
        "HellaSwag":77.84,
        "MMLU":55.4,
        "TruthfulQA":51.34,
        "Winogrande":73.09,
        "GSM8K":44.96,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":92.08,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/Mistral-7B-Holodeck-1",
        "Average":59.56,
        "ARC":60.24,
        "HellaSwag":82.53,
        "MMLU":62.67,
        "TruthfulQA":41.53,
        "Winogrande":76.72,
        "GSM8K":33.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ValiantLabs\/ShiningValiantXS",
        "Average":59.56,
        "ARC":58.96,
        "HellaSwag":81.93,
        "MMLU":56.75,
        "TruthfulQA":48.7,
        "Winogrande":76.95,
        "GSM8K":34.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maywell\/Synatra-RP-Orca-2-7b-v0.1",
        "Average":59.55,
        "ARC":57.42,
        "HellaSwag":77.31,
        "MMLU":56.12,
        "TruthfulQA":52.55,
        "Winogrande":74.43,
        "GSM8K":39.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm-20b",
        "Average":59.55,
        "ARC":60.49,
        "HellaSwag":82.13,
        "MMLU":61.85,
        "TruthfulQA":52.61,
        "Winogrande":76.72,
        "GSM8K":23.5,
        "Type":"pretrained",
        "Architecture":"InternLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":72.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BlouseJury\/Mistral-7B-Discord-0.2",
        "Average":59.55,
        "ARC":60.58,
        "HellaSwag":82.49,
        "MMLU":62.82,
        "TruthfulQA":42.73,
        "Winogrande":77.74,
        "GSM8K":30.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/mistral_7b_HalfEpoch_DolphinCoder",
        "Average":59.55,
        "ARC":61.69,
        "HellaSwag":82.38,
        "MMLU":61.44,
        "TruthfulQA":45.51,
        "Winogrande":75.77,
        "GSM8K":30.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/cloudymixtral7Bx2-nectar-0.2",
        "Average":59.54,
        "ARC":67.49,
        "HellaSwag":80.83,
        "MMLU":65.14,
        "TruthfulQA":68.7,
        "Winogrande":73.88,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xriminact\/TarsMeta",
        "Average":59.54,
        "ARC":52.9,
        "HellaSwag":78.2,
        "MMLU":52.63,
        "TruthfulQA":47.88,
        "Winogrande":72.77,
        "GSM8K":52.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andysalerno\/cloudymixtral7Bx2-nectar-0.2",
        "Average":59.53,
        "ARC":67.49,
        "HellaSwag":80.77,
        "MMLU":65.09,
        "TruthfulQA":68.73,
        "Winogrande":73.95,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"perlthoughts\/Chupacabra-v3",
        "Average":59.52,
        "ARC":66.21,
        "HellaSwag":81.29,
        "MMLU":59.36,
        "TruthfulQA":57.85,
        "Winogrande":77.43,
        "GSM8K":15.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"G-reen\/EXPERIMENT-DPO-m7b2-1-merged",
        "Average":59.52,
        "ARC":59.47,
        "HellaSwag":82.42,
        "MMLU":62.21,
        "TruthfulQA":40.01,
        "Winogrande":78.3,
        "GSM8K":34.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"zhengchenphd\/Mistral-Plus-7B",
        "Average":59.52,
        "ARC":62.2,
        "HellaSwag":84.24,
        "MMLU":63.63,
        "TruthfulQA":35.8,
        "Winogrande":77.74,
        "GSM8K":33.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/WizardLM-30B-fp16",
        "Average":59.51,
        "ARC":62.54,
        "HellaSwag":83.28,
        "MMLU":59.03,
        "TruthfulQA":52.49,
        "Winogrande":77.51,
        "GSM8K":22.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":10.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/gpt4-alpaca-lora-30b-HF",
        "Average":59.51,
        "ARC":64.85,
        "HellaSwag":85.72,
        "MMLU":58.51,
        "TruthfulQA":52.24,
        "Winogrande":80.19,
        "GSM8K":15.54,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-alpha",
        "Average":59.5,
        "ARC":61.01,
        "HellaSwag":84.04,
        "MMLU":61.39,
        "TruthfulQA":57.9,
        "Winogrande":78.61,
        "GSM8K":14.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1062.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/HelpSteer-filtered-7B",
        "Average":59.49,
        "ARC":59.56,
        "HellaSwag":83.32,
        "MMLU":63.52,
        "TruthfulQA":41.11,
        "Winogrande":76.01,
        "GSM8K":33.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"diffnamehard\/Psyfighter2-Noromaid-ties-13B",
        "Average":59.47,
        "ARC":61.86,
        "HellaSwag":84.58,
        "MMLU":57.04,
        "TruthfulQA":50.66,
        "Winogrande":75.37,
        "GSM8K":27.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Evillain\/StarDust_20B_v0.2",
        "Average":59.46,
        "ARC":61.01,
        "HellaSwag":83.76,
        "MMLU":59.29,
        "TruthfulQA":51.43,
        "Winogrande":77.27,
        "GSM8K":24.03,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FelixChao\/Gemma-10.2B",
        "Average":59.45,
        "ARC":58.36,
        "HellaSwag":80.35,
        "MMLU":58.44,
        "TruthfulQA":39.46,
        "Winogrande":76.87,
        "GSM8K":43.21,
        "Type":"base merges and moerges",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.2,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"LLMs\/WizardLM-30B-V1.0",
        "Average":59.45,
        "ARC":62.54,
        "HellaSwag":83.27,
        "MMLU":59.05,
        "TruthfulQA":52.49,
        "Winogrande":77.51,
        "GSM8K":21.83,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":30.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Yarn-Mistral-7b-128k",
        "Average":59.42,
        "ARC":59.64,
        "HellaSwag":82.5,
        "MMLU":63.02,
        "TruthfulQA":41.78,
        "Winogrande":76.95,
        "GSM8K":32.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":554.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/mistral_7b_HalfEpoch_DolphinCoder",
        "Average":59.4,
        "ARC":61.77,
        "HellaSwag":82.26,
        "MMLU":61.75,
        "TruthfulQA":45.46,
        "Winogrande":75.53,
        "GSM8K":29.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"hywu\/Camelidae-8x13B",
        "Average":59.4,
        "ARC":61.18,
        "HellaSwag":82.73,
        "MMLU":57.21,
        "TruthfulQA":43.37,
        "Winogrande":77.35,
        "GSM8K":34.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-XS-v1.1",
        "Average":59.39,
        "ARC":63.91,
        "HellaSwag":84.06,
        "MMLU":63.07,
        "TruthfulQA":49.92,
        "Winogrande":79.16,
        "GSM8K":16.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"FredrikBL\/test-ties",
        "Average":59.38,
        "ARC":58.53,
        "HellaSwag":81.66,
        "MMLU":61.7,
        "TruthfulQA":41.14,
        "Winogrande":76.87,
        "GSM8K":36.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"deepseek-ai\/deepseek-llm-7b-chat",
        "Average":59.38,
        "ARC":55.8,
        "HellaSwag":79.38,
        "MMLU":51.75,
        "TruthfulQA":47.98,
        "Winogrande":74.82,
        "GSM8K":46.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":61.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/openchat-3.5-0106-128k",
        "Average":59.38,
        "ARC":64.25,
        "HellaSwag":77.31,
        "MMLU":57.58,
        "TruthfulQA":46.5,
        "Winogrande":77.66,
        "GSM8K":32.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/mistral-7b-grok",
        "Average":59.37,
        "ARC":58.7,
        "HellaSwag":81.88,
        "MMLU":61.55,
        "TruthfulQA":42.07,
        "Winogrande":77.66,
        "GSM8K":34.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/motans1",
        "Average":59.37,
        "ARC":58.62,
        "HellaSwag":73.42,
        "MMLU":56.94,
        "TruthfulQA":46.1,
        "Winogrande":74.11,
        "GSM8K":47.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-thoughts-mistral-7b-v1.0",
        "Average":59.36,
        "ARC":58.53,
        "HellaSwag":81.25,
        "MMLU":54.95,
        "TruthfulQA":48.09,
        "Winogrande":78.14,
        "GSM8K":35.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-0",
        "Average":59.35,
        "ARC":57.51,
        "HellaSwag":79.64,
        "MMLU":58.02,
        "TruthfulQA":48.8,
        "Winogrande":77.82,
        "GSM8K":34.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/OpenAssistant-SFT-7-Llama-30B-HF",
        "Average":59.34,
        "ARC":60.58,
        "HellaSwag":82.17,
        "MMLU":57.93,
        "TruthfulQA":46.94,
        "Winogrande":78.61,
        "GSM8K":29.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EleutherAI\/llemma_34b",
        "Average":59.34,
        "ARC":55.29,
        "HellaSwag":75.08,
        "MMLU":58.93,
        "TruthfulQA":40.31,
        "Winogrande":75.53,
        "GSM8K":50.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":74.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/SynthIA-7B-v1.3",
        "Average":59.34,
        "ARC":62.12,
        "HellaSwag":83.45,
        "MMLU":62.65,
        "TruthfulQA":51.37,
        "Winogrande":78.85,
        "GSM8K":17.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":140.0
    },
    {
        "T":"?",
        "Model":"bavest\/fin-llama-33b-merged",
        "Average":59.33,
        "ARC":65.02,
        "HellaSwag":86.2,
        "MMLU":58.73,
        "TruthfulQA":49.75,
        "Winogrande":80.03,
        "GSM8K":16.22,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":33.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhanushreddy29\/BrokenKeyboardMerge",
        "Average":59.33,
        "ARC":59.73,
        "HellaSwag":81.25,
        "MMLU":58.36,
        "TruthfulQA":52.0,
        "Winogrande":78.69,
        "GSM8K":25.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"manishiitg\/open-aditi-hi-v2",
        "Average":59.31,
        "ARC":59.39,
        "HellaSwag":82.01,
        "MMLU":61.41,
        "TruthfulQA":45.84,
        "Winogrande":77.19,
        "GSM8K":30.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Walmart-the-bag\/MysticFusion-13B",
        "Average":59.31,
        "ARC":61.35,
        "HellaSwag":84.43,
        "MMLU":57.29,
        "TruthfulQA":51.98,
        "Winogrande":76.01,
        "GSM8K":24.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/Cerebrum-1.0-10.7B",
        "Average":59.3,
        "ARC":60.92,
        "HellaSwag":82.92,
        "MMLU":63.84,
        "TruthfulQA":46.2,
        "Winogrande":77.66,
        "GSM8K":24.26,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ariellee\/SuperPlatty-30B",
        "Average":59.3,
        "ARC":65.78,
        "HellaSwag":83.95,
        "MMLU":62.57,
        "TruthfulQA":53.52,
        "Winogrande":80.35,
        "GSM8K":9.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SuperAGI\/SAM",
        "Average":59.3,
        "ARC":59.39,
        "HellaSwag":82.31,
        "MMLU":62.15,
        "TruthfulQA":52.64,
        "Winogrande":76.4,
        "GSM8K":22.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-llm-7b-chat",
        "Average":59.27,
        "ARC":55.72,
        "HellaSwag":79.38,
        "MMLU":51.77,
        "TruthfulQA":47.92,
        "Winogrande":74.9,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":61.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Norquinal\/Mistral-7B-claude-instruct",
        "Average":59.27,
        "ARC":63.23,
        "HellaSwag":84.99,
        "MMLU":63.84,
        "TruthfulQA":47.47,
        "Winogrande":78.14,
        "GSM8K":17.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Venomia-1.1-m7",
        "Average":59.27,
        "ARC":58.45,
        "HellaSwag":83.04,
        "MMLU":56.39,
        "TruthfulQA":47.21,
        "Winogrande":74.43,
        "GSM8K":36.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mergedlm\/zephyrnotus-11b-alpha",
        "Average":59.26,
        "ARC":61.35,
        "HellaSwag":82.8,
        "MMLU":60.67,
        "TruthfulQA":57.22,
        "Winogrande":76.4,
        "GSM8K":17.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-7B-v0.3-RP",
        "Average":59.26,
        "ARC":62.2,
        "HellaSwag":82.29,
        "MMLU":60.8,
        "TruthfulQA":52.64,
        "Winogrande":76.48,
        "GSM8K":21.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BlueNipples\/TimeCrystal-l2-13B",
        "Average":59.26,
        "ARC":61.18,
        "HellaSwag":83.71,
        "MMLU":56.46,
        "TruthfulQA":51.3,
        "Winogrande":75.37,
        "GSM8K":27.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/Aika-7B",
        "Average":59.25,
        "ARC":65.36,
        "HellaSwag":81.49,
        "MMLU":53.91,
        "TruthfulQA":51.22,
        "Winogrande":77.74,
        "GSM8K":25.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wannaphong\/han-llm-7b-v3",
        "Average":59.25,
        "ARC":58.7,
        "HellaSwag":81.79,
        "MMLU":59.59,
        "TruthfulQA":43.12,
        "Winogrande":77.11,
        "GSM8K":35.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.27,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/Dr_Samantha_7b_mistral",
        "Average":59.25,
        "ARC":60.41,
        "HellaSwag":83.65,
        "MMLU":63.14,
        "TruthfulQA":41.37,
        "Winogrande":75.45,
        "GSM8K":31.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Corianas\/NearalMistral-2x7B",
        "Average":59.24,
        "ARC":57.42,
        "HellaSwag":77.67,
        "MMLU":56.46,
        "TruthfulQA":57.03,
        "Winogrande":75.22,
        "GSM8K":31.61,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gaodrew\/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
        "Average":59.22,
        "ARC":61.52,
        "HellaSwag":84.06,
        "MMLU":60.23,
        "TruthfulQA":51.05,
        "Winogrande":80.82,
        "GSM8K":17.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Xenon1\/Xenon-1",
        "Average":59.21,
        "ARC":55.29,
        "HellaSwag":81.56,
        "MMLU":61.22,
        "TruthfulQA":56.68,
        "Winogrande":78.69,
        "GSM8K":21.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-7B",
        "Average":59.19,
        "ARC":51.37,
        "HellaSwag":78.47,
        "MMLU":59.84,
        "TruthfulQA":47.79,
        "Winogrande":72.69,
        "GSM8K":44.96,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":337.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigostral-7b-chat",
        "Average":59.18,
        "ARC":62.63,
        "HellaSwag":84.34,
        "MMLU":63.53,
        "TruthfulQA":49.24,
        "Winogrande":78.61,
        "GSM8K":16.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Borealis-10.7B-DPO",
        "Average":59.18,
        "ARC":57.94,
        "HellaSwag":81.21,
        "MMLU":60.74,
        "TruthfulQA":46.37,
        "Winogrande":75.45,
        "GSM8K":33.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.7,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/UltraQwen-7B",
        "Average":59.17,
        "ARC":51.71,
        "HellaSwag":77.93,
        "MMLU":59.16,
        "TruthfulQA":48.2,
        "Winogrande":73.95,
        "GSM8K":44.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/PiVoT-0.1-Evil-a",
        "Average":59.16,
        "ARC":59.64,
        "HellaSwag":81.48,
        "MMLU":58.94,
        "TruthfulQA":39.23,
        "Winogrande":75.3,
        "GSM8K":40.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"FPHam\/Karen_TheEditor_V2_STRICT_Mistral_7B",
        "Average":59.13,
        "ARC":59.56,
        "HellaSwag":81.79,
        "MMLU":59.56,
        "TruthfulQA":49.36,
        "Winogrande":74.35,
        "GSM8K":30.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/Mistral-v0.1-PeanutButter-v0.0.0-7B",
        "Average":59.09,
        "ARC":62.2,
        "HellaSwag":84.1,
        "MMLU":64.14,
        "TruthfulQA":46.94,
        "Winogrande":78.69,
        "GSM8K":18.5,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-1",
        "Average":59.09,
        "ARC":57.17,
        "HellaSwag":79.47,
        "MMLU":56.41,
        "TruthfulQA":53.11,
        "Winogrande":76.32,
        "GSM8K":32.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-7B-0.4-DPO",
        "Average":59.08,
        "ARC":62.29,
        "HellaSwag":84.32,
        "MMLU":63.2,
        "TruthfulQA":42.28,
        "Winogrande":76.95,
        "GSM8K":25.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/finetuned-Mistral-5000-v1.0",
        "Average":59.08,
        "ARC":59.9,
        "HellaSwag":82.37,
        "MMLU":61.68,
        "TruthfulQA":41.17,
        "Winogrande":78.3,
        "GSM8K":31.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":59.08,
        "ARC":62.03,
        "HellaSwag":84.53,
        "MMLU":61.06,
        "TruthfulQA":57.44,
        "Winogrande":78.06,
        "GSM8K":11.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1396.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"osanseviero\/mistral-instruct-slerp",
        "Average":59.08,
        "ARC":57.42,
        "HellaSwag":78.34,
        "MMLU":55.19,
        "TruthfulQA":57.61,
        "Winogrande":75.14,
        "GSM8K":30.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wannaphong\/han-llm-7b-v2",
        "Average":59.06,
        "ARC":58.79,
        "HellaSwag":81.75,
        "MMLU":59.93,
        "TruthfulQA":42.38,
        "Winogrande":77.98,
        "GSM8K":33.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.27,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/openchat_3.5-16k",
        "Average":59.03,
        "ARC":63.31,
        "HellaSwag":83.58,
        "MMLU":61.9,
        "TruthfulQA":43.47,
        "Winogrande":80.11,
        "GSM8K":21.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"garage-bAInd\/Platypus-30B",
        "Average":59.03,
        "ARC":64.59,
        "HellaSwag":84.26,
        "MMLU":64.23,
        "TruthfulQA":45.35,
        "Winogrande":81.37,
        "GSM8K":14.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ValiantLabs\/Esper-70b",
        "Average":59.03,
        "ARC":56.48,
        "HellaSwag":77.72,
        "MMLU":55.91,
        "TruthfulQA":45.98,
        "Winogrande":73.48,
        "GSM8K":44.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lilloukas\/Platypus-30B",
        "Average":59.03,
        "ARC":64.59,
        "HellaSwag":84.24,
        "MMLU":64.19,
        "TruthfulQA":45.35,
        "Winogrande":81.37,
        "GSM8K":14.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/orca_mini_v3_13B-GPTQ",
        "Average":59.01,
        "ARC":61.95,
        "HellaSwag":81.56,
        "MMLU":56.1,
        "TruthfulQA":49.22,
        "Winogrande":75.77,
        "GSM8K":29.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.23,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/zephyr-alpha-Nebula-v2-7B",
        "Average":59.01,
        "ARC":58.62,
        "HellaSwag":83.05,
        "MMLU":56.68,
        "TruthfulQA":58.28,
        "Winogrande":73.56,
        "GSM8K":23.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ShenaoZ\/0001_dpo_iter_2",
        "Average":59.01,
        "ARC":60.41,
        "HellaSwag":84.52,
        "MMLU":60.02,
        "TruthfulQA":53.11,
        "Winogrande":77.19,
        "GSM8K":18.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"unaidedelf87777\/wizard-mistral-v0.1",
        "Average":59.01,
        "ARC":61.77,
        "HellaSwag":83.51,
        "MMLU":63.99,
        "TruthfulQA":47.46,
        "Winogrande":78.3,
        "GSM8K":19.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/Mistral-12.25B-v0.2",
        "Average":59.01,
        "ARC":58.87,
        "HellaSwag":81.77,
        "MMLU":63.22,
        "TruthfulQA":40.44,
        "Winogrande":77.66,
        "GSM8K":32.07,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alignment-handbook\/zephyr-7b-sft-qlora",
        "Average":59.0,
        "ARC":60.07,
        "HellaSwag":82.36,
        "MMLU":61.65,
        "TruthfulQA":38.88,
        "Winogrande":76.8,
        "GSM8K":34.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-6",
        "Average":58.99,
        "ARC":57.34,
        "HellaSwag":78.86,
        "MMLU":58.21,
        "TruthfulQA":49.44,
        "Winogrande":76.87,
        "GSM8K":33.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ramachaitanya22\/mistral-7B-finetune-health-fitness",
        "Average":58.98,
        "ARC":59.13,
        "HellaSwag":82.65,
        "MMLU":61.93,
        "TruthfulQA":42.07,
        "Winogrande":77.03,
        "GSM8K":31.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"ehartford\/samantha-1.1-llama-33b",
        "Average":58.98,
        "ARC":67.83,
        "HellaSwag":85.55,
        "MMLU":58.79,
        "TruthfulQA":61.19,
        "Winogrande":76.48,
        "GSM8K":4.02,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"osanseviero\/mistral-instruct-frankenmerge",
        "Average":58.96,
        "ARC":58.19,
        "HellaSwag":83.26,
        "MMLU":59.53,
        "TruthfulQA":66.48,
        "Winogrande":75.06,
        "GSM8K":11.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Dans-DiscountModels\/Mistral-7b-FFT-Test3",
        "Average":58.96,
        "ARC":60.24,
        "HellaSwag":82.36,
        "MMLU":62.2,
        "TruthfulQA":44.36,
        "Winogrande":77.82,
        "GSM8K":26.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Hercules-1.0-Mistral-7B",
        "Average":58.95,
        "ARC":57.08,
        "HellaSwag":81.13,
        "MMLU":58.98,
        "TruthfulQA":49.47,
        "Winogrande":77.19,
        "GSM8K":29.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/rezephyr-dpo",
        "Average":58.95,
        "ARC":57.59,
        "HellaSwag":81.75,
        "MMLU":60.55,
        "TruthfulQA":44.32,
        "Winogrande":77.03,
        "GSM8K":32.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-XS-v1.0",
        "Average":58.95,
        "ARC":61.43,
        "HellaSwag":83.82,
        "MMLU":64.1,
        "TruthfulQA":47.12,
        "Winogrande":78.93,
        "GSM8K":18.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-7B-0.4-DPO",
        "Average":58.93,
        "ARC":62.2,
        "HellaSwag":84.41,
        "MMLU":63.14,
        "TruthfulQA":42.34,
        "Winogrande":76.95,
        "GSM8K":24.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-70b-hf",
        "Average":58.93,
        "ARC":56.74,
        "HellaSwag":78.21,
        "MMLU":59.67,
        "TruthfulQA":39.79,
        "Winogrande":75.22,
        "GSM8K":43.97,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":290.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Henk717\/chronoboros-33B",
        "Average":58.92,
        "ARC":63.91,
        "HellaSwag":85.0,
        "MMLU":59.44,
        "TruthfulQA":49.83,
        "Winogrande":80.35,
        "GSM8K":15.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"akjindal53244\/Mistral-7B-v0.1-Open-Platypus",
        "Average":58.92,
        "ARC":62.37,
        "HellaSwag":85.08,
        "MMLU":63.79,
        "TruthfulQA":47.33,
        "Winogrande":77.66,
        "GSM8K":17.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mwitiderrick\/SwahiliInstruct-v0.1",
        "Average":58.92,
        "ARC":57.59,
        "HellaSwag":80.92,
        "MMLU":57.0,
        "TruthfulQA":58.08,
        "Winogrande":74.66,
        "GSM8K":25.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"upstage\/llama-30b-instruct",
        "Average":58.91,
        "ARC":62.46,
        "HellaSwag":86.23,
        "MMLU":59.37,
        "TruthfulQA":52.78,
        "Winogrande":80.51,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArtMindia\/artmindia3k",
        "Average":58.91,
        "ARC":59.98,
        "HellaSwag":82.99,
        "MMLU":60.99,
        "TruthfulQA":41.61,
        "Winogrande":76.8,
        "GSM8K":31.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/Mistral-7B-OpenOrca-1k",
        "Average":58.9,
        "ARC":62.97,
        "HellaSwag":84.66,
        "MMLU":62.2,
        "TruthfulQA":52.96,
        "Winogrande":78.61,
        "GSM8K":11.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-5",
        "Average":58.89,
        "ARC":56.57,
        "HellaSwag":79.04,
        "MMLU":55.73,
        "TruthfulQA":50.0,
        "Winogrande":76.4,
        "GSM8K":35.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/zephyr-7b-beta-MultiLoRA-mmlu-merged",
        "Average":58.89,
        "ARC":57.94,
        "HellaSwag":81.43,
        "MMLU":58.57,
        "TruthfulQA":51.98,
        "Winogrande":76.64,
        "GSM8K":26.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Cinder-Phi-2-V1-F16-gguf",
        "Average":58.86,
        "ARC":58.28,
        "HellaSwag":74.04,
        "MMLU":54.46,
        "TruthfulQA":44.5,
        "Winogrande":74.66,
        "GSM8K":47.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/manticore-30b-chat-pyg-alpha",
        "Average":58.86,
        "ARC":64.16,
        "HellaSwag":84.38,
        "MMLU":57.49,
        "TruthfulQA":51.57,
        "Winogrande":79.48,
        "GSM8K":16.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":32.53,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-code-mistral-7b-v1.0",
        "Average":58.85,
        "ARC":60.58,
        "HellaSwag":83.75,
        "MMLU":62.98,
        "TruthfulQA":47.9,
        "Winogrande":78.69,
        "GSM8K":19.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"qblocks\/mistral_7b_norobots",
        "Average":58.85,
        "ARC":58.96,
        "HellaSwag":80.57,
        "MMLU":57.66,
        "TruthfulQA":41.91,
        "Winogrande":75.61,
        "GSM8K":38.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Henk717\/airochronos-33B",
        "Average":58.84,
        "ARC":64.42,
        "HellaSwag":85.21,
        "MMLU":59.79,
        "TruthfulQA":50.59,
        "Winogrande":79.32,
        "GSM8K":13.72,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Mistral-11B-SynthIAirOmniMix",
        "Average":58.84,
        "ARC":62.46,
        "HellaSwag":83.13,
        "MMLU":63.47,
        "TruthfulQA":55.69,
        "Winogrande":76.4,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/mistral_11B_instruct_v0.1",
        "Average":58.84,
        "ARC":53.75,
        "HellaSwag":74.64,
        "MMLU":58.93,
        "TruthfulQA":63.64,
        "Winogrande":73.56,
        "GSM8K":28.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/Nebula-v2-7B",
        "Average":58.82,
        "ARC":58.7,
        "HellaSwag":83.06,
        "MMLU":57.61,
        "TruthfulQA":46.72,
        "Winogrande":75.14,
        "GSM8K":31.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/scarlett-33b",
        "Average":58.81,
        "ARC":67.75,
        "HellaSwag":85.48,
        "MMLU":58.98,
        "TruthfulQA":61.05,
        "Winogrande":76.8,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":33.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TeeZee\/GALAXY_v03_slimorca_1_epoch_50k_DPO_1_epoch_30k",
        "Average":58.79,
        "ARC":65.27,
        "HellaSwag":85.62,
        "MMLU":65.61,
        "TruthfulQA":53.46,
        "Winogrande":82.72,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":15.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Dans-DiscountModels\/Mistral-7b-FFT-Test3",
        "Average":58.79,
        "ARC":60.41,
        "HellaSwag":82.31,
        "MMLU":62.45,
        "TruthfulQA":44.33,
        "Winogrande":77.58,
        "GSM8K":25.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"freeCS-dot-org\/Zero-7B-test-3",
        "Average":58.77,
        "ARC":64.25,
        "HellaSwag":79.85,
        "MMLU":53.49,
        "TruthfulQA":58.3,
        "Winogrande":76.32,
        "GSM8K":20.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-13b-v0.3",
        "Average":58.77,
        "ARC":62.8,
        "HellaSwag":84.42,
        "MMLU":56.86,
        "TruthfulQA":50.73,
        "Winogrande":74.74,
        "GSM8K":23.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama-30b",
        "Average":58.77,
        "ARC":64.25,
        "HellaSwag":83.64,
        "MMLU":58.23,
        "TruthfulQA":53.2,
        "Winogrande":77.43,
        "GSM8K":15.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/OpenHermes-Gemma-7B",
        "Average":58.76,
        "ARC":57.0,
        "HellaSwag":76.3,
        "MMLU":55.74,
        "TruthfulQA":53.14,
        "Winogrande":72.69,
        "GSM8K":37.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Henk717\/airochronos-33B",
        "Average":58.75,
        "ARC":64.25,
        "HellaSwag":85.2,
        "MMLU":59.83,
        "TruthfulQA":50.56,
        "Winogrande":79.08,
        "GSM8K":13.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-m-7b-3.1.2",
        "Average":58.75,
        "ARC":61.86,
        "HellaSwag":83.51,
        "MMLU":61.91,
        "TruthfulQA":53.75,
        "Winogrande":77.58,
        "GSM8K":13.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Novocoders\/Mistral-NeuralDPO-v0.7",
        "Average":58.74,
        "ARC":65.87,
        "HellaSwag":84.4,
        "MMLU":57.6,
        "TruthfulQA":39.91,
        "Winogrande":79.56,
        "GSM8K":25.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/dromedary-65b-lora-HF",
        "Average":58.73,
        "ARC":61.6,
        "HellaSwag":82.53,
        "MMLU":63.08,
        "TruthfulQA":38.82,
        "Winogrande":78.93,
        "GSM8K":27.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":65.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ausboss\/llama-30b-supercot",
        "Average":58.73,
        "ARC":64.85,
        "HellaSwag":85.08,
        "MMLU":56.56,
        "TruthfulQA":53.96,
        "Winogrande":80.03,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":126.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openbmb\/UltraLM-13b-v2.0",
        "Average":58.72,
        "ARC":62.63,
        "HellaSwag":81.49,
        "MMLU":56.17,
        "TruthfulQA":49.48,
        "Winogrande":76.48,
        "GSM8K":26.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
        "Average":58.72,
        "ARC":61.01,
        "HellaSwag":84.31,
        "MMLU":64.34,
        "TruthfulQA":44.87,
        "Winogrande":78.85,
        "GSM8K":18.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aeala\/GPT4-x-AlpacaDente2-30b",
        "Average":58.71,
        "ARC":60.58,
        "HellaSwag":81.81,
        "MMLU":56.63,
        "TruthfulQA":48.38,
        "Winogrande":78.14,
        "GSM8K":26.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yanolja\/EEVE-Korean-Instruct-2.8B-v1.0",
        "Average":58.71,
        "ARC":58.28,
        "HellaSwag":72.42,
        "MMLU":53.35,
        "TruthfulQA":48.32,
        "Winogrande":74.82,
        "GSM8K":45.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.82,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bhenrym14\/mistral-7b-platypus-fp16",
        "Average":58.71,
        "ARC":63.05,
        "HellaSwag":84.15,
        "MMLU":64.11,
        "TruthfulQA":45.07,
        "Winogrande":78.53,
        "GSM8K":17.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hfl\/chinese-mixtral",
        "Average":58.69,
        "ARC":67.58,
        "HellaSwag":85.34,
        "MMLU":70.38,
        "TruthfulQA":46.86,
        "Winogrande":82.0,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jilp00\/Nous-Hermes-2-SOLAR-10.7B-v1.1",
        "Average":58.69,
        "ARC":63.99,
        "HellaSwag":82.72,
        "MMLU":65.85,
        "TruthfulQA":56.97,
        "Winogrande":81.22,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Dolphin-Nebula-7B",
        "Average":58.69,
        "ARC":55.2,
        "HellaSwag":78.57,
        "MMLU":53.44,
        "TruthfulQA":57.97,
        "Winogrande":73.88,
        "GSM8K":33.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont2",
        "Average":58.67,
        "ARC":60.32,
        "HellaSwag":82.88,
        "MMLU":59.79,
        "TruthfulQA":42.36,
        "Winogrande":76.56,
        "GSM8K":30.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/72B-preview-canary-llamafied-qwen-llamafy-unbias-qkv",
        "Average":58.67,
        "ARC":53.07,
        "HellaSwag":63.13,
        "MMLU":67.39,
        "TruthfulQA":57.62,
        "Winogrande":75.14,
        "GSM8K":35.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/Mistral-v0.1-PeanutButter-v0.0.2-7B",
        "Average":58.66,
        "ARC":61.77,
        "HellaSwag":84.11,
        "MMLU":64.38,
        "TruthfulQA":45.92,
        "Winogrande":78.37,
        "GSM8K":17.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/Orca-2-13b",
        "Average":58.64,
        "ARC":60.67,
        "HellaSwag":79.81,
        "MMLU":60.37,
        "TruthfulQA":56.41,
        "Winogrande":76.64,
        "GSM8K":17.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":642.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/falcon-40b-openassistant-peft",
        "Average":58.63,
        "ARC":62.63,
        "HellaSwag":85.59,
        "MMLU":57.77,
        "TruthfulQA":51.02,
        "Winogrande":81.45,
        "GSM8K":13.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":40.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/SOLAR-Platypus-10.7B-v1",
        "Average":58.62,
        "ARC":61.69,
        "HellaSwag":84.23,
        "MMLU":60.37,
        "TruthfulQA":51.58,
        "Winogrande":82.79,
        "GSM8K":11.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EllieS\/zephyr-7b-dpo-lora-pubmedqa-ultrafeedback",
        "Average":58.62,
        "ARC":60.49,
        "HellaSwag":83.13,
        "MMLU":60.58,
        "TruthfulQA":44.79,
        "Winogrande":76.24,
        "GSM8K":26.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/QuantumLM-70B-hf",
        "Average":58.61,
        "ARC":59.47,
        "HellaSwag":83.02,
        "MMLU":62.25,
        "TruthfulQA":53.39,
        "Winogrande":78.77,
        "GSM8K":14.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":68.98,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-7b-v1",
        "Average":58.61,
        "ARC":61.26,
        "HellaSwag":84.1,
        "MMLU":63.46,
        "TruthfulQA":46.34,
        "Winogrande":79.16,
        "GSM8K":17.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/koOpenChat-sft",
        "Average":58.61,
        "ARC":59.81,
        "HellaSwag":78.73,
        "MMLU":61.32,
        "TruthfulQA":51.24,
        "Winogrande":76.4,
        "GSM8K":24.18,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gradientputri\/MegaMix-T1-13B",
        "Average":58.61,
        "ARC":61.35,
        "HellaSwag":83.44,
        "MMLU":58.49,
        "TruthfulQA":48.19,
        "Winogrande":76.09,
        "GSM8K":24.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/alignment-handbook-zephyr-7b_ppo_5e7step_51",
        "Average":58.59,
        "ARC":59.73,
        "HellaSwag":82.52,
        "MMLU":59.76,
        "TruthfulQA":41.46,
        "Winogrande":77.19,
        "GSM8K":30.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-2.0-mistral-7b",
        "Average":58.58,
        "ARC":59.22,
        "HellaSwag":80.26,
        "MMLU":56.9,
        "TruthfulQA":61.09,
        "Winogrande":75.37,
        "GSM8K":18.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"S4sch\/zephyr-neural-chat-frankenmerge11b",
        "Average":58.57,
        "ARC":61.52,
        "HellaSwag":84.09,
        "MMLU":61.51,
        "TruthfulQA":60.63,
        "Winogrande":76.24,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"hfl\/chinese-mixtral",
        "Average":58.57,
        "ARC":67.49,
        "HellaSwag":85.25,
        "MMLU":70.31,
        "TruthfulQA":46.75,
        "Winogrande":81.61,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"umd-zhou-lab\/claude2-alpaca-13B",
        "Average":58.57,
        "ARC":61.18,
        "HellaSwag":84.21,
        "MMLU":55.93,
        "TruthfulQA":45.02,
        "Winogrande":76.8,
        "GSM8K":28.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"?",
        "Model":"lmsys\/vicuna-33b-v1.3",
        "Average":58.54,
        "ARC":62.12,
        "HellaSwag":83.0,
        "MMLU":59.22,
        "TruthfulQA":56.16,
        "Winogrande":77.03,
        "GSM8K":13.72,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":33.0,
        "Model Sha":278.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/72B-preview-canary-llamafied-qwen-llamafy-unbias-qkv",
        "Average":58.54,
        "ARC":52.56,
        "HellaSwag":62.99,
        "MMLU":67.45,
        "TruthfulQA":57.61,
        "Winogrande":75.14,
        "GSM8K":35.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":72.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gradientputri\/MegaMix-A1-13B",
        "Average":58.52,
        "ARC":61.6,
        "HellaSwag":83.49,
        "MMLU":58.26,
        "TruthfulQA":47.48,
        "Winogrande":76.16,
        "GSM8K":24.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NeverSleep\/Noromaid-13b-v0.2",
        "Average":58.51,
        "ARC":60.92,
        "HellaSwag":84.04,
        "MMLU":57.67,
        "TruthfulQA":52.58,
        "Winogrande":74.11,
        "GSM8K":21.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-ReMM-L2-Chat-20B",
        "Average":58.49,
        "ARC":62.46,
        "HellaSwag":85.62,
        "MMLU":59.13,
        "TruthfulQA":55.63,
        "Winogrande":77.19,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"manishiitg\/open-aditi-hi-v1",
        "Average":58.49,
        "ARC":58.79,
        "HellaSwag":81.38,
        "MMLU":58.51,
        "TruthfulQA":42.34,
        "Winogrande":76.48,
        "GSM8K":33.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/Wizard-Vicuna-30B-Uncensored-GPTQ",
        "Average":58.47,
        "ARC":61.09,
        "HellaSwag":82.4,
        "MMLU":56.46,
        "TruthfulQA":49.9,
        "Winogrande":77.66,
        "GSM8K":23.28,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":534.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Intel\/neural-chat-7b-v3",
        "Average":58.46,
        "ARC":67.15,
        "HellaSwag":83.29,
        "MMLU":62.26,
        "TruthfulQA":58.77,
        "Winogrande":78.06,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":63.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"posicube\/Llama2-chat-AYB-13B",
        "Average":58.45,
        "ARC":63.4,
        "HellaSwag":84.79,
        "MMLU":59.34,
        "TruthfulQA":55.62,
        "Winogrande":76.24,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/trurl-2-13b-pl-instruct_unload",
        "Average":58.44,
        "ARC":59.9,
        "HellaSwag":79.99,
        "MMLU":78.66,
        "TruthfulQA":45.56,
        "Winogrande":74.35,
        "GSM8K":12.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/X-MythoChronos-13B",
        "Average":58.43,
        "ARC":59.73,
        "HellaSwag":83.39,
        "MMLU":56.5,
        "TruthfulQA":53.55,
        "Winogrande":74.43,
        "GSM8K":22.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ZySec-AI\/ZySec-7B",
        "Average":58.41,
        "ARC":57.51,
        "HellaSwag":79.73,
        "MMLU":58.65,
        "TruthfulQA":51.11,
        "Winogrande":74.51,
        "GSM8K":28.96,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CalderaAI\/30B-Lazarus",
        "Average":58.4,
        "ARC":64.93,
        "HellaSwag":84.27,
        "MMLU":56.47,
        "TruthfulQA":58.65,
        "Winogrande":78.37,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":119.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-PersonalityEngine-30b",
        "Average":58.39,
        "ARC":63.48,
        "HellaSwag":84.37,
        "MMLU":58.99,
        "TruthfulQA":46.98,
        "Winogrande":80.98,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"codemateai\/CodeMate-v0.1",
        "Average":58.39,
        "ARC":55.55,
        "HellaSwag":78.03,
        "MMLU":55.31,
        "TruthfulQA":48.64,
        "Winogrande":72.61,
        "GSM8K":40.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Cartinoe5930\/iDUS-8layers",
        "Average":58.38,
        "ARC":59.3,
        "HellaSwag":81.34,
        "MMLU":63.22,
        "TruthfulQA":40.62,
        "Winogrande":76.24,
        "GSM8K":29.57,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/SynthIA-7B-v1.3-dare-0.85",
        "Average":58.38,
        "ARC":61.01,
        "HellaSwag":83.5,
        "MMLU":64.49,
        "TruthfulQA":43.77,
        "Winogrande":78.93,
        "GSM8K":18.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Uncensored-Frank-33B",
        "Average":58.38,
        "ARC":62.12,
        "HellaSwag":83.3,
        "MMLU":57.57,
        "TruthfulQA":54.03,
        "Winogrande":76.56,
        "GSM8K":16.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"g-ronimo\/phi-2-OpenHermes-2.5",
        "Average":58.38,
        "ARC":59.81,
        "HellaSwag":74.85,
        "MMLU":55.51,
        "TruthfulQA":43.86,
        "Winogrande":75.06,
        "GSM8K":41.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/alignment-handbook-zephyr-7b_ppo_5e7step_102",
        "Average":58.37,
        "ARC":59.22,
        "HellaSwag":82.45,
        "MMLU":59.62,
        "TruthfulQA":41.56,
        "Winogrande":77.03,
        "GSM8K":30.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"posicube\/Llama-chat-AY-13B",
        "Average":58.34,
        "ARC":62.8,
        "HellaSwag":83.23,
        "MMLU":60.01,
        "TruthfulQA":55.95,
        "Winogrande":75.93,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/test-case-3",
        "Average":58.34,
        "ARC":57.76,
        "HellaSwag":79.56,
        "MMLU":56.77,
        "TruthfulQA":49.22,
        "Winogrande":75.93,
        "GSM8K":30.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/SynthIA-v1.3-Nebula-v2-7B",
        "Average":58.33,
        "ARC":59.39,
        "HellaSwag":82.77,
        "MMLU":57.57,
        "TruthfulQA":50.62,
        "Winogrande":74.74,
        "GSM8K":24.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"g-ronimo\/phi-2-OpenHermes-2.5-v2",
        "Average":58.33,
        "ARC":58.45,
        "HellaSwag":74.57,
        "MMLU":56.43,
        "TruthfulQA":44.89,
        "Winogrande":75.22,
        "GSM8K":40.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kwchoi\/DPO_mistral_v01_7b_ultra_0131_1k_1epoch",
        "Average":58.32,
        "ARC":55.97,
        "HellaSwag":76.78,
        "MMLU":55.97,
        "TruthfulQA":57.94,
        "Winogrande":73.4,
        "GSM8K":29.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-7b-v2",
        "Average":58.31,
        "ARC":61.95,
        "HellaSwag":83.83,
        "MMLU":61.74,
        "TruthfulQA":46.63,
        "Winogrande":78.45,
        "GSM8K":17.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont1",
        "Average":58.29,
        "ARC":60.24,
        "HellaSwag":82.28,
        "MMLU":60.61,
        "TruthfulQA":40.55,
        "Winogrande":77.11,
        "GSM8K":28.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/30B-Lazarus-instruct-PL-lora_unload",
        "Average":58.29,
        "ARC":62.8,
        "HellaSwag":84.13,
        "MMLU":56.87,
        "TruthfulQA":55.49,
        "Winogrande":79.08,
        "GSM8K":11.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"concedo\/Vicuzard-30B-Uncensored",
        "Average":58.26,
        "ARC":62.97,
        "HellaSwag":83.68,
        "MMLU":58.16,
        "TruthfulQA":52.27,
        "Winogrande":77.11,
        "GSM8K":15.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
        "Average":58.24,
        "ARC":60.75,
        "HellaSwag":84.24,
        "MMLU":63.66,
        "TruthfulQA":44.94,
        "Winogrande":78.69,
        "GSM8K":17.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TriadParty\/deepmoney-34b-200k-base",
        "Average":58.21,
        "ARC":63.99,
        "HellaSwag":83.87,
        "MMLU":74.04,
        "TruthfulQA":45.93,
        "Winogrande":81.45,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":34.0,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-1.4",
        "Average":58.2,
        "ARC":64.42,
        "HellaSwag":85.13,
        "MMLU":59.53,
        "TruthfulQA":50.47,
        "Winogrande":77.9,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/mistral-7b-platypus1k",
        "Average":58.19,
        "ARC":61.6,
        "HellaSwag":82.93,
        "MMLU":63.16,
        "TruthfulQA":46.96,
        "Winogrande":78.14,
        "GSM8K":16.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Riiid\/sheep-duck-llama-2-13b",
        "Average":58.19,
        "ARC":63.14,
        "HellaSwag":84.52,
        "MMLU":59.89,
        "TruthfulQA":55.48,
        "Winogrande":76.95,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Secbone\/llama-33B-instructed",
        "Average":58.18,
        "ARC":64.59,
        "HellaSwag":86.17,
        "MMLU":60.5,
        "TruthfulQA":44.12,
        "Winogrande":79.32,
        "GSM8K":14.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":33.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"42MARU\/sitebunny-13b",
        "Average":58.17,
        "ARC":63.14,
        "HellaSwag":83.64,
        "MMLU":59.91,
        "TruthfulQA":56.21,
        "Winogrande":76.72,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-TotSirocco-7b",
        "Average":58.16,
        "ARC":62.2,
        "HellaSwag":84.28,
        "MMLU":63.8,
        "TruthfulQA":46.04,
        "Winogrande":79.48,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"martyn\/llama-megamerge-dare-13b",
        "Average":58.15,
        "ARC":60.58,
        "HellaSwag":83.0,
        "MMLU":54.91,
        "TruthfulQA":45.76,
        "Winogrande":76.16,
        "GSM8K":28.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-TotSirocco-7b",
        "Average":58.15,
        "ARC":62.03,
        "HellaSwag":84.23,
        "MMLU":64.19,
        "TruthfulQA":46.49,
        "Winogrande":78.69,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rizla\/rizla54",
        "Average":58.15,
        "ARC":58.19,
        "HellaSwag":78.74,
        "MMLU":61.29,
        "TruthfulQA":53.26,
        "Winogrande":76.8,
        "GSM8K":20.62,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":53.58,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/Mistral-7B-OpenOrca-lora",
        "Average":58.14,
        "ARC":61.95,
        "HellaSwag":83.62,
        "MMLU":64.16,
        "TruthfulQA":42.74,
        "Winogrande":79.08,
        "GSM8K":17.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Technoculture\/Medchator-2x7b",
        "Average":58.13,
        "ARC":57.59,
        "HellaSwag":78.14,
        "MMLU":56.13,
        "TruthfulQA":48.77,
        "Winogrande":75.3,
        "GSM8K":32.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.07,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"caisarl76\/mistral-guanaco1k-ep2",
        "Average":58.13,
        "ARC":60.07,
        "HellaSwag":82.76,
        "MMLU":61.5,
        "TruthfulQA":54.4,
        "Winogrande":78.06,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"caisarl76\/Mistral-7B-guanaco1k-ep2",
        "Average":58.13,
        "ARC":60.07,
        "HellaSwag":82.76,
        "MMLU":61.5,
        "TruthfulQA":54.4,
        "Winogrande":78.06,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wannaphong\/han-llm-7b-v1",
        "Average":58.13,
        "ARC":58.19,
        "HellaSwag":81.58,
        "MMLU":58.99,
        "TruthfulQA":40.97,
        "Winogrande":77.27,
        "GSM8K":31.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.27,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-1.8-L2-13B",
        "Average":58.12,
        "ARC":63.48,
        "HellaSwag":84.12,
        "MMLU":58.57,
        "TruthfulQA":52.86,
        "Winogrande":76.4,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/2x-LoRA-Assemble-13B",
        "Average":58.1,
        "ARC":63.65,
        "HellaSwag":83.47,
        "MMLU":59.82,
        "TruthfulQA":55.94,
        "Winogrande":76.48,
        "GSM8K":9.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Cartinoe5930\/SOLAR-DUS-implement",
        "Average":58.1,
        "ARC":59.56,
        "HellaSwag":81.18,
        "MMLU":63.68,
        "TruthfulQA":40.72,
        "Winogrande":76.48,
        "GSM8K":26.99,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
        "Average":58.09,
        "ARC":62.46,
        "HellaSwag":83.66,
        "MMLU":57.82,
        "TruthfulQA":50.94,
        "Winogrande":78.37,
        "GSM8K":15.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-33b-instruct",
        "Average":58.08,
        "ARC":63.05,
        "HellaSwag":85.0,
        "MMLU":58.32,
        "TruthfulQA":52.1,
        "Winogrande":78.85,
        "GSM8K":11.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":33.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-40b",
        "Average":58.07,
        "ARC":61.86,
        "HellaSwag":85.28,
        "MMLU":56.89,
        "TruthfulQA":41.65,
        "Winogrande":81.29,
        "GSM8K":21.46,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":40.0,
        "Model Sha":2395.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mncai\/Mistral-7B-openplatypus-1k",
        "Average":58.07,
        "ARC":60.15,
        "HellaSwag":84.25,
        "MMLU":59.84,
        "TruthfulQA":49.86,
        "Winogrande":76.87,
        "GSM8K":17.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TencentARC\/LLaMA-Pro-8B-Instruct",
        "Average":58.06,
        "ARC":52.99,
        "HellaSwag":76.98,
        "MMLU":52.58,
        "TruthfulQA":49.43,
        "Winogrande":72.22,
        "GSM8K":44.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":8.36,
        "Model Sha":57.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"camel-ai\/CAMEL-33B-Combined-Data",
        "Average":58.06,
        "ARC":62.97,
        "HellaSwag":83.83,
        "MMLU":58.98,
        "TruthfulQA":50.21,
        "Winogrande":78.3,
        "GSM8K":14.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":33.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"scb10x\/typhoon-7b",
        "Average":58.05,
        "ARC":58.53,
        "HellaSwag":81.55,
        "MMLU":59.54,
        "TruthfulQA":40.52,
        "Winogrande":76.56,
        "GSM8K":31.61,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":72.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Mistral-11B-v0.1",
        "Average":58.05,
        "ARC":59.56,
        "HellaSwag":81.17,
        "MMLU":63.56,
        "TruthfulQA":40.67,
        "Winogrande":76.64,
        "GSM8K":26.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/hippogriff-30b-chat",
        "Average":58.05,
        "ARC":64.51,
        "HellaSwag":85.2,
        "MMLU":59.09,
        "TruthfulQA":48.42,
        "Winogrande":80.82,
        "GSM8K":10.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":30.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/airoboros-m-7b-3.1.2-dare-0.85",
        "Average":58.03,
        "ARC":61.09,
        "HellaSwag":83.57,
        "MMLU":64.05,
        "TruthfulQA":43.64,
        "Winogrande":78.37,
        "GSM8K":17.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-70b-Python-hf",
        "Average":58.0,
        "ARC":55.12,
        "HellaSwag":78.48,
        "MMLU":56.17,
        "TruthfulQA":41.78,
        "Winogrande":73.01,
        "GSM8K":43.44,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":68.98,
        "Model Sha":101.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Luban-Marcoroni-13B",
        "Average":57.98,
        "ARC":63.65,
        "HellaSwag":82.92,
        "MMLU":58.7,
        "TruthfulQA":55.55,
        "Winogrande":77.03,
        "GSM8K":10.01,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/Mistral-10.7B-v0.2",
        "Average":57.96,
        "ARC":58.28,
        "HellaSwag":80.92,
        "MMLU":63.44,
        "TruthfulQA":40.39,
        "Winogrande":77.35,
        "GSM8K":27.37,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/samantha-mistral-7b",
        "Average":57.96,
        "ARC":63.4,
        "HellaSwag":84.1,
        "MMLU":61.36,
        "TruthfulQA":46.08,
        "Winogrande":76.8,
        "GSM8K":16.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-SOLAR-11b-v4.0",
        "Average":57.95,
        "ARC":63.65,
        "HellaSwag":84.75,
        "MMLU":65.13,
        "TruthfulQA":51.63,
        "Winogrande":82.56,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"martyn\/llama2-megamerge-dare-13b-v2",
        "Average":57.94,
        "ARC":59.39,
        "HellaSwag":80.93,
        "MMLU":55.26,
        "TruthfulQA":47.27,
        "Winogrande":75.53,
        "GSM8K":29.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Luban-Marcoroni-13B-v3",
        "Average":57.94,
        "ARC":63.74,
        "HellaSwag":82.88,
        "MMLU":58.64,
        "TruthfulQA":55.56,
        "Winogrande":76.87,
        "GSM8K":9.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Stellaris-internlm2-20b-r256",
        "Average":57.93,
        "ARC":61.09,
        "HellaSwag":82.22,
        "MMLU":66.01,
        "TruthfulQA":51.81,
        "Winogrande":85.24,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Llamix2-Xwin-MoE-4x13B",
        "Average":57.93,
        "ARC":60.41,
        "HellaSwag":82.96,
        "MMLU":56.24,
        "TruthfulQA":39.63,
        "Winogrande":75.14,
        "GSM8K":33.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":38.5,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ericpolewski\/ASTS-PFAF",
        "Average":57.93,
        "ARC":61.26,
        "HellaSwag":82.94,
        "MMLU":58.96,
        "TruthfulQA":43.74,
        "Winogrande":76.87,
        "GSM8K":23.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Luban-Marcoroni-13B-v2",
        "Average":57.92,
        "ARC":63.48,
        "HellaSwag":82.89,
        "MMLU":58.72,
        "TruthfulQA":55.56,
        "Winogrande":76.95,
        "GSM8K":9.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/blockchainlabs_7B_merged_test2_4_prune",
        "Average":57.91,
        "ARC":60.58,
        "HellaSwag":77.74,
        "MMLU":52.27,
        "TruthfulQA":59.03,
        "Winogrande":76.4,
        "GSM8K":21.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"caisarl76\/Mistral-7B-OpenOrca-Guanaco-accu16",
        "Average":57.91,
        "ARC":59.73,
        "HellaSwag":83.08,
        "MMLU":61.29,
        "TruthfulQA":50.81,
        "Winogrande":76.56,
        "GSM8K":16.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"oh-yeontaek\/llama-2-13B-LoRA-assemble",
        "Average":57.91,
        "ARC":63.57,
        "HellaSwag":83.51,
        "MMLU":59.82,
        "TruthfulQA":55.96,
        "Winogrande":76.16,
        "GSM8K":8.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aeala\/Enterredaas-33b",
        "Average":57.9,
        "ARC":60.92,
        "HellaSwag":84.18,
        "MMLU":58.3,
        "TruthfulQA":49.02,
        "Winogrande":78.77,
        "GSM8K":16.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":33.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Cinder-Phi-2-STEM-2.94B-Test",
        "Average":57.9,
        "ARC":57.08,
        "HellaSwag":72.21,
        "MMLU":53.87,
        "TruthfulQA":46.46,
        "Winogrande":75.61,
        "GSM8K":42.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.94,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Gille\/StrangeMerges_48-7B-dare_ties",
        "Average":57.89,
        "ARC":60.92,
        "HellaSwag":80.13,
        "MMLU":49.51,
        "TruthfulQA":65.55,
        "Winogrande":75.85,
        "GSM8K":15.39,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/Wizard-Vicuna-30B-Uncensored",
        "Average":57.89,
        "ARC":62.12,
        "HellaSwag":83.45,
        "MMLU":58.24,
        "TruthfulQA":50.81,
        "Winogrande":78.45,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Wizard-Vicuna-30B-Uncensored-fp16",
        "Average":57.89,
        "ARC":62.12,
        "HellaSwag":83.45,
        "MMLU":58.24,
        "TruthfulQA":50.81,
        "Winogrande":78.45,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"arlineka\/Brunhilde-13b-v1",
        "Average":57.88,
        "ARC":61.09,
        "HellaSwag":83.58,
        "MMLU":55.32,
        "TruthfulQA":51.98,
        "Winogrande":75.22,
        "GSM8K":20.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"posicube\/Llama2-chat-AYT-13B",
        "Average":57.88,
        "ARC":63.31,
        "HellaSwag":83.53,
        "MMLU":59.67,
        "TruthfulQA":55.8,
        "Winogrande":76.09,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/bubo-bubo-13b",
        "Average":57.86,
        "ARC":61.43,
        "HellaSwag":83.14,
        "MMLU":58.18,
        "TruthfulQA":47.62,
        "Winogrande":76.16,
        "GSM8K":20.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aeala\/VicUnlocked-alpaca-30b",
        "Average":57.86,
        "ARC":61.86,
        "HellaSwag":83.79,
        "MMLU":57.64,
        "TruthfulQA":51.03,
        "Winogrande":78.22,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/Chat-AYB-Nova-13B",
        "Average":57.84,
        "ARC":62.97,
        "HellaSwag":84.28,
        "MMLU":58.58,
        "TruthfulQA":51.28,
        "Winogrande":77.58,
        "GSM8K":12.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"souvik0306\/mistral_7b_2epoch_norobots",
        "Average":57.84,
        "ARC":61.01,
        "HellaSwag":83.37,
        "MMLU":63.96,
        "TruthfulQA":42.62,
        "Winogrande":79.08,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kwchoi\/DPO_mistral_v01_7b_ultra_0130_1k",
        "Average":57.83,
        "ARC":57.17,
        "HellaSwag":79.16,
        "MMLU":55.85,
        "TruthfulQA":55.62,
        "Winogrande":72.85,
        "GSM8K":26.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-7b-selfplay-v0",
        "Average":57.82,
        "ARC":54.69,
        "HellaSwag":75.69,
        "MMLU":55.4,
        "TruthfulQA":56.28,
        "Winogrande":73.64,
        "GSM8K":31.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/Noromaid-Aeryth-7B",
        "Average":57.82,
        "ARC":56.74,
        "HellaSwag":78.62,
        "MMLU":57.29,
        "TruthfulQA":65.66,
        "Winogrande":71.82,
        "GSM8K":16.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-V2-Delta-fp16",
        "Average":57.81,
        "ARC":62.46,
        "HellaSwag":83.45,
        "MMLU":59.04,
        "TruthfulQA":55.25,
        "Winogrande":73.88,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Sao10K\/Stheno-v2-Delta-fp16",
        "Average":57.81,
        "ARC":62.46,
        "HellaSwag":83.45,
        "MMLU":59.04,
        "TruthfulQA":55.25,
        "Winogrande":73.88,
        "GSM8K":12.81,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Stellaris-internlm2-20b-r128",
        "Average":57.76,
        "ARC":61.26,
        "HellaSwag":81.75,
        "MMLU":65.67,
        "TruthfulQA":52.5,
        "Winogrande":85.24,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/ChatAYT-Lora-Assamble-Marcoroni",
        "Average":57.76,
        "ARC":62.46,
        "HellaSwag":83.05,
        "MMLU":58.72,
        "TruthfulQA":56.12,
        "Winogrande":77.35,
        "GSM8K":8.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-llama2-13b-v8.1-fp16",
        "Average":57.76,
        "ARC":55.97,
        "HellaSwag":79.79,
        "MMLU":54.95,
        "TruthfulQA":51.16,
        "Winogrande":74.35,
        "GSM8K":30.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":63.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/OpenOrcaxOpenChat-Preview2-13B",
        "Average":57.76,
        "ARC":62.37,
        "HellaSwag":82.96,
        "MMLU":58.68,
        "TruthfulQA":51.23,
        "Winogrande":77.19,
        "GSM8K":14.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":102.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-L2-Chat-13B",
        "Average":57.75,
        "ARC":62.03,
        "HellaSwag":84.19,
        "MMLU":58.75,
        "TruthfulQA":52.84,
        "Winogrande":77.43,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Pwen-14B-Chat-20_30",
        "Average":57.74,
        "ARC":56.14,
        "HellaSwag":79.78,
        "MMLU":60.01,
        "TruthfulQA":47.02,
        "Winogrande":76.48,
        "GSM8K":26.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ai-business\/Luban-13B",
        "Average":57.73,
        "ARC":63.05,
        "HellaSwag":82.8,
        "MMLU":58.73,
        "TruthfulQA":55.53,
        "Winogrande":76.56,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kabster\/Bio-Mistralv2-Squared",
        "Average":57.73,
        "ARC":63.31,
        "HellaSwag":84.02,
        "MMLU":60.08,
        "TruthfulQA":60.98,
        "Winogrande":77.9,
        "GSM8K":0.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-1.2",
        "Average":57.69,
        "ARC":64.42,
        "HellaSwag":84.93,
        "MMLU":60.35,
        "TruthfulQA":49.18,
        "Winogrande":77.51,
        "GSM8K":9.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Alpacino30b",
        "Average":57.67,
        "ARC":62.71,
        "HellaSwag":85.04,
        "MMLU":58.48,
        "TruthfulQA":44.23,
        "Winogrande":79.79,
        "GSM8K":15.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":68.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/mistral_7b_DolphinCoder",
        "Average":57.67,
        "ARC":59.73,
        "HellaSwag":81.64,
        "MMLU":59.87,
        "TruthfulQA":43.95,
        "Winogrande":74.59,
        "GSM8K":26.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/mistral_7b_DolphinCoder",
        "Average":57.67,
        "ARC":59.73,
        "HellaSwag":81.64,
        "MMLU":59.87,
        "TruthfulQA":43.95,
        "Winogrande":74.59,
        "GSM8K":26.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kabster\/Bio-Mistralv2-Squared",
        "Average":57.66,
        "ARC":62.97,
        "HellaSwag":84.02,
        "MMLU":60.08,
        "TruthfulQA":60.99,
        "Winogrande":77.74,
        "GSM8K":0.15,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Llama-2-13b-chat-hf-activity-fine-tuned-v4",
        "Average":57.64,
        "ARC":59.22,
        "HellaSwag":81.67,
        "MMLU":54.51,
        "TruthfulQA":43.82,
        "Winogrande":75.06,
        "GSM8K":31.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"boomerchan\/magpie-13b",
        "Average":57.64,
        "ARC":63.31,
        "HellaSwag":84.25,
        "MMLU":58.15,
        "TruthfulQA":49.15,
        "Winogrande":76.48,
        "GSM8K":14.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/zephyr-7b-sft-full-spin-peft-iter1",
        "Average":57.63,
        "ARC":57.94,
        "HellaSwag":80.78,
        "MMLU":60.23,
        "TruthfulQA":41.8,
        "Winogrande":76.24,
        "GSM8K":28.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/zephyr-7b-sft-full-spin-peft-iter2",
        "Average":57.63,
        "ARC":58.02,
        "HellaSwag":80.77,
        "MMLU":60.22,
        "TruthfulQA":41.79,
        "Winogrande":76.48,
        "GSM8K":28.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-math-7b-base",
        "Average":57.61,
        "ARC":52.22,
        "HellaSwag":69.49,
        "MMLU":57.25,
        "TruthfulQA":40.71,
        "Winogrande":66.77,
        "GSM8K":59.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/mistral-7b-v0.1-layla-v2",
        "Average":57.6,
        "ARC":56.31,
        "HellaSwag":79.76,
        "MMLU":50.81,
        "TruthfulQA":51.57,
        "Winogrande":75.77,
        "GSM8K":31.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Orca-2-13B-GPTQ",
        "Average":57.6,
        "ARC":59.81,
        "HellaSwag":79.12,
        "MMLU":59.35,
        "TruthfulQA":55.14,
        "Winogrande":76.64,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.24,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ab24g21\/LaterLlamaV2",
        "Average":57.6,
        "ARC":59.04,
        "HellaSwag":81.82,
        "MMLU":54.53,
        "TruthfulQA":44.15,
        "Winogrande":76.09,
        "GSM8K":29.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"steve-cse\/MelloGPT",
        "Average":57.59,
        "ARC":53.84,
        "HellaSwag":76.12,
        "MMLU":55.99,
        "TruthfulQA":55.61,
        "Winogrande":73.88,
        "GSM8K":30.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":10.0
    },
    {
        "T":"?",
        "Model":"l3utterfly\/mistral-7b-v0.1-layla-v1",
        "Average":57.56,
        "ARC":60.15,
        "HellaSwag":83.25,
        "MMLU":60.31,
        "TruthfulQA":48.9,
        "Winogrande":75.93,
        "GSM8K":16.83,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PotatoOff\/Michel-13B",
        "Average":57.56,
        "ARC":61.26,
        "HellaSwag":83.21,
        "MMLU":55.05,
        "TruthfulQA":50.43,
        "Winogrande":75.22,
        "GSM8K":20.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alignment-handbook\/zephyr-7b-sft-full",
        "Average":57.56,
        "ARC":57.68,
        "HellaSwag":80.82,
        "MMLU":60.31,
        "TruthfulQA":41.71,
        "Winogrande":76.09,
        "GSM8K":28.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"splm\/zephyr-7b-sft-full-spin-peft-iter0",
        "Average":57.55,
        "ARC":57.94,
        "HellaSwag":80.77,
        "MMLU":60.26,
        "TruthfulQA":41.79,
        "Winogrande":76.24,
        "GSM8K":28.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/PsyMedRP-v1-20B",
        "Average":57.54,
        "ARC":60.49,
        "HellaSwag":83.94,
        "MMLU":56.68,
        "TruthfulQA":54.45,
        "Winogrande":74.82,
        "GSM8K":14.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ab24g21\/llama-2-new",
        "Average":57.54,
        "ARC":58.7,
        "HellaSwag":81.54,
        "MMLU":54.59,
        "TruthfulQA":44.58,
        "Winogrande":76.09,
        "GSM8K":29.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/tulu-30B-fp16",
        "Average":57.53,
        "ARC":59.98,
        "HellaSwag":83.4,
        "MMLU":56.1,
        "TruthfulQA":45.14,
        "Winogrande":80.82,
        "GSM8K":19.71,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"timpal0l\/Mistral-7B-v0.1-flashback-v2",
        "Average":57.53,
        "ARC":57.17,
        "HellaSwag":80.74,
        "MMLU":59.98,
        "TruthfulQA":40.66,
        "Winogrande":77.19,
        "GSM8K":29.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
        "Average":57.52,
        "ARC":59.64,
        "HellaSwag":82.7,
        "MMLU":58.3,
        "TruthfulQA":56.0,
        "Winogrande":75.37,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alignment-handbook\/zephyr-7b-sft-full",
        "Average":57.52,
        "ARC":58.11,
        "HellaSwag":80.83,
        "MMLU":60.2,
        "TruthfulQA":41.74,
        "Winogrande":76.24,
        "GSM8K":27.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/mistral_7b_3Epoch_DolphinCoder",
        "Average":57.51,
        "ARC":59.22,
        "HellaSwag":82.32,
        "MMLU":57.91,
        "TruthfulQA":43.7,
        "Winogrande":75.69,
        "GSM8K":26.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-gemma-7b-v18.1-4k",
        "Average":57.49,
        "ARC":54.86,
        "HellaSwag":75.68,
        "MMLU":55.56,
        "TruthfulQA":50.08,
        "Winogrande":68.82,
        "GSM8K":39.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jilp00\/SOLAR-10.7B-tutored",
        "Average":57.49,
        "ARC":62.29,
        "HellaSwag":82.24,
        "MMLU":65.09,
        "TruthfulQA":55.13,
        "Winogrande":80.19,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-1.3",
        "Average":57.49,
        "ARC":63.82,
        "HellaSwag":85.09,
        "MMLU":58.94,
        "TruthfulQA":45.33,
        "Winogrande":79.01,
        "GSM8K":12.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xriminact\/TarsChattyBasev0.2",
        "Average":57.47,
        "ARC":52.22,
        "HellaSwag":77.78,
        "MMLU":47.99,
        "TruthfulQA":43.79,
        "Winogrande":69.46,
        "GSM8K":53.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Unholy-v1-12L-13B",
        "Average":57.47,
        "ARC":63.57,
        "HellaSwag":83.75,
        "MMLU":58.08,
        "TruthfulQA":51.09,
        "Winogrande":77.27,
        "GSM8K":11.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":37.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/7B_ppo_phiRM_2GPU_3e-7step_4000",
        "Average":57.46,
        "ARC":57.25,
        "HellaSwag":80.24,
        "MMLU":60.06,
        "TruthfulQA":41.48,
        "Winogrande":76.32,
        "GSM8K":29.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-AdventurousWinds-7b",
        "Average":57.46,
        "ARC":61.01,
        "HellaSwag":83.47,
        "MMLU":63.69,
        "TruthfulQA":42.65,
        "Winogrande":78.22,
        "GSM8K":15.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/autotrain-xva0j-mixtral8x7b",
        "Average":57.45,
        "ARC":62.8,
        "HellaSwag":84.44,
        "MMLU":67.27,
        "TruthfulQA":50.13,
        "Winogrande":74.59,
        "GSM8K":5.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-33b-gpt4-1.3",
        "Average":57.43,
        "ARC":63.91,
        "HellaSwag":85.04,
        "MMLU":58.53,
        "TruthfulQA":45.36,
        "Winogrande":78.69,
        "GSM8K":13.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MXLewd-L2-20B",
        "Average":57.43,
        "ARC":63.23,
        "HellaSwag":85.33,
        "MMLU":57.36,
        "TruthfulQA":51.65,
        "Winogrande":76.09,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-llama2-luban-orca-platypus-13b",
        "Average":57.42,
        "ARC":62.54,
        "HellaSwag":82.76,
        "MMLU":59.23,
        "TruthfulQA":54.66,
        "Winogrande":77.11,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalleorg\/TruthfulQwen1.5-4B",
        "Average":57.41,
        "ARC":47.1,
        "HellaSwag":71.32,
        "MMLU":56.04,
        "TruthfulQA":50.6,
        "Winogrande":66.85,
        "GSM8K":52.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"hfl\/chinese-alpaca-2-13b",
        "Average":57.41,
        "ARC":58.7,
        "HellaSwag":79.76,
        "MMLU":55.12,
        "TruthfulQA":50.22,
        "Winogrande":75.61,
        "GSM8K":25.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":83.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SkunkworksAI\/Mistralic-7B-1",
        "Average":57.4,
        "ARC":60.84,
        "HellaSwag":82.29,
        "MMLU":60.8,
        "TruthfulQA":52.38,
        "Winogrande":77.03,
        "GSM8K":11.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.11,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xenon1\/Zenith-7B",
        "Average":57.39,
        "ARC":56.31,
        "HellaSwag":81.11,
        "MMLU":61.3,
        "TruthfulQA":55.76,
        "Winogrande":77.82,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Tiger-7B-v0.1-LaserRMT-Math-5-10-15-Neural-DPO",
        "Average":57.36,
        "ARC":39.42,
        "HellaSwag":82.58,
        "MMLU":61.63,
        "TruthfulQA":48.16,
        "Winogrande":77.19,
        "GSM8K":35.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chargoddard\/llama-polyglot-13b",
        "Average":57.36,
        "ARC":59.81,
        "HellaSwag":81.27,
        "MMLU":55.04,
        "TruthfulQA":48.71,
        "Winogrande":76.72,
        "GSM8K":22.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gordicaleksa\/YugoGPT",
        "Average":57.35,
        "ARC":58.11,
        "HellaSwag":81.45,
        "MMLU":60.68,
        "TruthfulQA":36.6,
        "Winogrande":76.56,
        "GSM8K":30.71,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"allenai\/digital-socrates-13b",
        "Average":57.34,
        "ARC":58.36,
        "HellaSwag":80.14,
        "MMLU":57.01,
        "TruthfulQA":44.47,
        "Winogrande":74.59,
        "GSM8K":29.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/VicUnlocked-30B-LoRA-HF",
        "Average":57.33,
        "ARC":59.73,
        "HellaSwag":84.02,
        "MMLU":57.81,
        "TruthfulQA":48.54,
        "Winogrande":79.48,
        "GSM8K":14.4,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"jondurbin\/airoboros-33b-gpt4",
        "Average":57.32,
        "ARC":63.74,
        "HellaSwag":84.87,
        "MMLU":58.54,
        "TruthfulQA":47.06,
        "Winogrande":77.03,
        "GSM8K":12.66,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/BrainDerp2",
        "Average":57.32,
        "ARC":60.92,
        "HellaSwag":81.94,
        "MMLU":58.9,
        "TruthfulQA":57.19,
        "Winogrande":75.93,
        "GSM8K":9.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":57.31,
        "ARC":62.37,
        "HellaSwag":82.99,
        "MMLU":59.38,
        "TruthfulQA":52.2,
        "Winogrande":75.77,
        "GSM8K":11.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adonlee\/LLaMA_2_13B_SFT_v0",
        "Average":57.31,
        "ARC":62.03,
        "HellaSwag":83.8,
        "MMLU":58.39,
        "TruthfulQA":49.92,
        "Winogrande":77.27,
        "GSM8K":12.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maldv\/electric-mist-7b",
        "Average":57.3,
        "ARC":61.18,
        "HellaSwag":82.56,
        "MMLU":59.71,
        "TruthfulQA":45.37,
        "Winogrande":71.51,
        "GSM8K":23.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"codellama\/CodeLlama-34b-Instruct-hf",
        "Average":57.29,
        "ARC":54.27,
        "HellaSwag":76.92,
        "MMLU":55.54,
        "TruthfulQA":44.44,
        "Winogrande":74.59,
        "GSM8K":37.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":262.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/OpenOrca-Platypus2-13B",
        "Average":57.28,
        "ARC":62.8,
        "HellaSwag":83.15,
        "MMLU":59.39,
        "TruthfulQA":53.08,
        "Winogrande":76.24,
        "GSM8K":9.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":226.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/LLaMA2-13B-Estopia",
        "Average":57.27,
        "ARC":62.12,
        "HellaSwag":82.53,
        "MMLU":54.99,
        "TruthfulQA":54.18,
        "Winogrande":75.85,
        "GSM8K":13.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Mistral-7B-Instruct-v0.1-gpt-4-80k",
        "Average":57.27,
        "ARC":55.12,
        "HellaSwag":74.79,
        "MMLU":56.13,
        "TruthfulQA":57.51,
        "Winogrande":72.61,
        "GSM8K":27.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/2x-LoRA-Assemble-Nova-13B",
        "Average":57.26,
        "ARC":62.63,
        "HellaSwag":83.24,
        "MMLU":58.64,
        "TruthfulQA":51.88,
        "Winogrande":76.95,
        "GSM8K":10.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID-SFT-DPO-MixQV2-SOLIDRejected-SFTChosen-Zephyr-7b-beta",
        "Average":57.26,
        "ARC":58.96,
        "HellaSwag":79.82,
        "MMLU":60.14,
        "TruthfulQA":52.36,
        "Winogrande":73.24,
        "GSM8K":19.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-ReMM-L2-Chat-20B-Inverted",
        "Average":57.25,
        "ARC":61.69,
        "HellaSwag":85.32,
        "MMLU":58.0,
        "TruthfulQA":53.77,
        "Winogrande":75.61,
        "GSM8K":9.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nisten\/bigdoc-c34b-instruct-tf32",
        "Average":57.24,
        "ARC":54.44,
        "HellaSwag":76.91,
        "MMLU":55.62,
        "TruthfulQA":44.46,
        "Winogrande":74.43,
        "GSM8K":37.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-3.0",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/Giraffe-13b-32k-v3",
        "Average":57.24,
        "ARC":59.04,
        "HellaSwag":79.59,
        "MMLU":55.01,
        "TruthfulQA":46.68,
        "Winogrande":76.95,
        "GSM8K":26.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pankajmathur\/orca_mini_v3_13b",
        "Average":57.24,
        "ARC":63.14,
        "HellaSwag":82.35,
        "MMLU":56.52,
        "TruthfulQA":51.81,
        "Winogrande":76.48,
        "GSM8K":13.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_v3_13b",
        "Average":57.24,
        "ARC":63.14,
        "HellaSwag":82.35,
        "MMLU":56.52,
        "TruthfulQA":51.81,
        "Winogrande":76.48,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-Chat-v2-13B",
        "Average":57.23,
        "ARC":61.86,
        "HellaSwag":83.81,
        "MMLU":57.0,
        "TruthfulQA":54.51,
        "Winogrande":75.77,
        "GSM8K":10.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IkariDev\/Athena-v4",
        "Average":57.23,
        "ARC":62.54,
        "HellaSwag":84.19,
        "MMLU":57.33,
        "TruthfulQA":50.87,
        "Winogrande":76.48,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/LLaMA2-13B-Estopia",
        "Average":57.21,
        "ARC":62.29,
        "HellaSwag":82.51,
        "MMLU":55.12,
        "TruthfulQA":54.14,
        "Winogrande":75.77,
        "GSM8K":13.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/mistral_7b_2EPOCH_DolphinCoder",
        "Average":57.17,
        "ARC":60.75,
        "HellaSwag":81.15,
        "MMLU":59.37,
        "TruthfulQA":44.65,
        "Winogrande":73.24,
        "GSM8K":23.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-llama2-hermes-orca-platypus-13b",
        "Average":57.17,
        "ARC":60.92,
        "HellaSwag":83.5,
        "MMLU":59.39,
        "TruthfulQA":54.29,
        "Winogrande":75.22,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-33b-2.1",
        "Average":57.16,
        "ARC":63.65,
        "HellaSwag":84.97,
        "MMLU":57.37,
        "TruthfulQA":52.17,
        "Winogrande":78.22,
        "GSM8K":6.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-m2.0",
        "Average":57.16,
        "ARC":64.68,
        "HellaSwag":84.95,
        "MMLU":57.77,
        "TruthfulQA":47.44,
        "Winogrande":77.74,
        "GSM8K":10.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistral-7B-alpaca-case-0-2",
        "Average":57.15,
        "ARC":61.69,
        "HellaSwag":81.74,
        "MMLU":60.0,
        "TruthfulQA":43.56,
        "Winogrande":76.95,
        "GSM8K":18.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/BrainDerp3",
        "Average":57.13,
        "ARC":60.92,
        "HellaSwag":82.1,
        "MMLU":58.91,
        "TruthfulQA":57.18,
        "Winogrande":75.61,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Doctor-Shotgun\/CalliopeDS-v2-L2-13B",
        "Average":57.12,
        "ARC":62.8,
        "HellaSwag":84.14,
        "MMLU":56.14,
        "TruthfulQA":51.06,
        "Winogrande":76.01,
        "GSM8K":12.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gradientputri\/MegaMix-S1-13B",
        "Average":57.12,
        "ARC":62.46,
        "HellaSwag":83.65,
        "MMLU":57.88,
        "TruthfulQA":44.52,
        "Winogrande":75.85,
        "GSM8K":18.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/BrainDerp",
        "Average":57.11,
        "ARC":60.75,
        "HellaSwag":82.1,
        "MMLU":58.81,
        "TruthfulQA":56.9,
        "Winogrande":75.85,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID-SFT-WoDPO-MixQV2-Zephyr-7b-beta",
        "Average":57.1,
        "ARC":59.73,
        "HellaSwag":81.72,
        "MMLU":60.47,
        "TruthfulQA":53.77,
        "Winogrande":74.66,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-v2.2-L2-13B",
        "Average":57.1,
        "ARC":61.26,
        "HellaSwag":84.16,
        "MMLU":56.22,
        "TruthfulQA":51.35,
        "Winogrande":75.61,
        "GSM8K":14.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IkariDev\/Athena-v3",
        "Average":57.09,
        "ARC":61.69,
        "HellaSwag":84.34,
        "MMLU":57.87,
        "TruthfulQA":51.26,
        "Winogrande":75.77,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/vicuna-33b-coder",
        "Average":57.07,
        "ARC":60.41,
        "HellaSwag":83.27,
        "MMLU":57.17,
        "TruthfulQA":51.79,
        "Winogrande":76.87,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":33.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Emerhyst-20B",
        "Average":57.07,
        "ARC":61.69,
        "HellaSwag":84.98,
        "MMLU":56.98,
        "TruthfulQA":54.16,
        "Winogrande":76.09,
        "GSM8K":8.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DangFutures\/BIG_DANG_BOT",
        "Average":57.06,
        "ARC":60.32,
        "HellaSwag":82.02,
        "MMLU":70.02,
        "TruthfulQA":49.07,
        "Winogrande":80.9,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Cinder-Phi-2-Test-1",
        "Average":57.05,
        "ARC":57.34,
        "HellaSwag":72.6,
        "MMLU":50.81,
        "TruthfulQA":45.23,
        "Winogrande":73.8,
        "GSM8K":42.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"circulus\/Llama-2-13b-orca-v1",
        "Average":57.05,
        "ARC":62.03,
        "HellaSwag":82.27,
        "MMLU":57.71,
        "TruthfulQA":49.61,
        "Winogrande":76.87,
        "GSM8K":13.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/StableBeluga-13B",
        "Average":57.05,
        "ARC":62.03,
        "HellaSwag":82.27,
        "MMLU":57.71,
        "TruthfulQA":49.61,
        "Winogrande":76.87,
        "GSM8K":13.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":114.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-4B",
        "Average":57.05,
        "ARC":48.46,
        "HellaSwag":71.58,
        "MMLU":56.52,
        "TruthfulQA":47.27,
        "Winogrande":66.22,
        "GSM8K":52.24,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.95,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TeeZee\/GALAXY_v03_slimorca_1_epoch_50k",
        "Average":57.04,
        "ARC":62.71,
        "HellaSwag":84.58,
        "MMLU":65.17,
        "TruthfulQA":47.3,
        "Winogrande":82.48,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":15.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-m2.0",
        "Average":57.03,
        "ARC":63.4,
        "HellaSwag":85.19,
        "MMLU":57.46,
        "TruthfulQA":48.15,
        "Winogrande":78.37,
        "GSM8K":9.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BioMistral\/BioMistral-7B-DARE",
        "Average":57.03,
        "ARC":58.28,
        "HellaSwag":79.87,
        "MMLU":57.34,
        "TruthfulQA":55.61,
        "Winogrande":76.09,
        "GSM8K":15.01,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/zephyr-beta-Nebula-v2-7B",
        "Average":57.03,
        "ARC":56.57,
        "HellaSwag":82.53,
        "MMLU":56.4,
        "TruthfulQA":58.68,
        "Winogrande":70.48,
        "GSM8K":17.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-2.0",
        "Average":57.02,
        "ARC":63.91,
        "HellaSwag":85.67,
        "MMLU":57.95,
        "TruthfulQA":45.54,
        "Winogrande":77.98,
        "GSM8K":11.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/wendigo-14b-alpha2",
        "Average":57.02,
        "ARC":56.66,
        "HellaSwag":77.19,
        "MMLU":58.0,
        "TruthfulQA":53.71,
        "Winogrande":73.64,
        "GSM8K":22.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WebraftAI\/synapsellm-7b-mistral-v0.3-preview",
        "Average":57.01,
        "ARC":53.84,
        "HellaSwag":74.86,
        "MMLU":54.81,
        "TruthfulQA":55.03,
        "Winogrande":74.59,
        "GSM8K":28.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MisterRid\/wendigo-14b-alpha1",
        "Average":57.01,
        "ARC":56.48,
        "HellaSwag":77.2,
        "MMLU":57.83,
        "TruthfulQA":53.76,
        "Winogrande":73.01,
        "GSM8K":23.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-2.0",
        "Average":57.01,
        "ARC":63.82,
        "HellaSwag":85.65,
        "MMLU":58.44,
        "TruthfulQA":45.57,
        "Winogrande":77.9,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yulan-team\/YuLan-Chat-2-13b-fp16",
        "Average":57.01,
        "ARC":59.04,
        "HellaSwag":80.66,
        "MMLU":56.72,
        "TruthfulQA":52.18,
        "Winogrande":79.64,
        "GSM8K":13.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kno10\/ende-chat-0.0.4",
        "Average":57.01,
        "ARC":56.57,
        "HellaSwag":79.63,
        "MMLU":55.22,
        "TruthfulQA":51.19,
        "Winogrande":75.93,
        "GSM8K":23.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-v2-L2-13B",
        "Average":56.99,
        "ARC":61.95,
        "HellaSwag":84.0,
        "MMLU":56.14,
        "TruthfulQA":50.81,
        "Winogrande":75.85,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"inswave\/AISquare-Instruct-llama2-koen-13b-v0.9.24",
        "Average":56.98,
        "ARC":55.63,
        "HellaSwag":81.35,
        "MMLU":51.76,
        "TruthfulQA":53.0,
        "Winogrande":76.95,
        "GSM8K":23.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.16,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/OpenOrca-Platypus2-13B-GPTQ",
        "Average":56.98,
        "ARC":62.54,
        "HellaSwag":82.67,
        "MMLU":58.56,
        "TruthfulQA":51.93,
        "Winogrande":76.8,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":16.24,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/GenAI-Nova-13B",
        "Average":56.98,
        "ARC":62.29,
        "HellaSwag":83.27,
        "MMLU":59.47,
        "TruthfulQA":51.79,
        "Winogrande":77.35,
        "GSM8K":7.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-33b-gpt4-m2.0",
        "Average":56.97,
        "ARC":63.14,
        "HellaSwag":85.19,
        "MMLU":57.28,
        "TruthfulQA":48.07,
        "Winogrande":78.45,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":33.0,
        "Model Sha":6.0
    },
    {
        "T":"?",
        "Model":"huggyllama\/llama-30b",
        "Average":56.96,
        "ARC":61.43,
        "HellaSwag":84.73,
        "MMLU":58.45,
        "TruthfulQA":42.27,
        "Winogrande":80.03,
        "GSM8K":14.86,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radiantloom\/radintloom-mistral-7b-fusion-dpo",
        "Average":56.95,
        "ARC":63.14,
        "HellaSwag":83.68,
        "MMLU":63.42,
        "TruthfulQA":51.14,
        "Winogrande":79.95,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yhyu13\/llama-30B-hf-openassitant",
        "Average":56.94,
        "ARC":61.26,
        "HellaSwag":84.73,
        "MMLU":58.47,
        "TruthfulQA":42.27,
        "Winogrande":80.03,
        "GSM8K":14.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":30.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggingface\/llama-30b",
        "Average":56.94,
        "ARC":61.26,
        "HellaSwag":84.73,
        "MMLU":58.47,
        "TruthfulQA":42.27,
        "Winogrande":80.03,
        "GSM8K":14.86,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":32.53,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"hon9kon9ize\/CantoneseLLM-6B-preview202402",
        "Average":56.93,
        "ARC":55.63,
        "HellaSwag":75.8,
        "MMLU":63.07,
        "TruthfulQA":42.26,
        "Winogrande":74.11,
        "GSM8K":30.71,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/UndiMix-v4-13B",
        "Average":56.93,
        "ARC":61.95,
        "HellaSwag":83.88,
        "MMLU":56.9,
        "TruthfulQA":48.96,
        "Winogrande":76.16,
        "GSM8K":13.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rombodawg\/LosslessMegaCoder-llama2-13b-mini",
        "Average":56.92,
        "ARC":60.58,
        "HellaSwag":81.26,
        "MMLU":57.92,
        "TruthfulQA":48.89,
        "Winogrande":76.95,
        "GSM8K":15.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andreaskoepf\/llama2-13b-megacode2_min100",
        "Average":56.92,
        "ARC":60.58,
        "HellaSwag":81.26,
        "MMLU":57.92,
        "TruthfulQA":48.89,
        "Winogrande":76.95,
        "GSM8K":15.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"circulus\/Llama-2-13b-orca-v1",
        "Average":56.91,
        "ARC":62.2,
        "HellaSwag":82.32,
        "MMLU":57.67,
        "TruthfulQA":49.6,
        "Winogrande":76.8,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Emerald-13B",
        "Average":56.89,
        "ARC":62.29,
        "HellaSwag":83.69,
        "MMLU":55.7,
        "TruthfulQA":50.94,
        "Winogrande":75.93,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lamhieu\/ghost-7b-v0.9.0",
        "Average":56.89,
        "ARC":53.07,
        "HellaSwag":77.93,
        "MMLU":55.09,
        "TruthfulQA":47.79,
        "Winogrande":73.72,
        "GSM8K":33.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-Mistral-13B",
        "Average":56.89,
        "ARC":62.2,
        "HellaSwag":83.82,
        "MMLU":55.43,
        "TruthfulQA":53.32,
        "Winogrande":74.51,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/Instruct_Yi-6B_Dolly15K",
        "Average":56.85,
        "ARC":54.86,
        "HellaSwag":75.87,
        "MMLU":63.37,
        "TruthfulQA":42.84,
        "Winogrande":74.9,
        "GSM8K":29.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/OpenOrcaxOpenChat-Preview2-13B-GPTQ",
        "Average":56.84,
        "ARC":61.26,
        "HellaSwag":82.14,
        "MMLU":57.85,
        "TruthfulQA":50.22,
        "Winogrande":77.11,
        "GSM8K":12.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":16.24,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dsvv-cair\/alpaca-cleaned-llama-30b-bf16",
        "Average":56.82,
        "ARC":61.77,
        "HellaSwag":85.06,
        "MMLU":57.52,
        "TruthfulQA":51.49,
        "Winogrande":77.35,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-Orca-2-7b",
        "Average":56.81,
        "ARC":55.2,
        "HellaSwag":77.08,
        "MMLU":56.02,
        "TruthfulQA":43.72,
        "Winogrande":75.53,
        "GSM8K":33.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID_SFT-WoDPO-WoMixQ",
        "Average":56.8,
        "ARC":59.64,
        "HellaSwag":81.69,
        "MMLU":60.1,
        "TruthfulQA":55.25,
        "Winogrande":74.66,
        "GSM8K":9.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TIGER-Lab\/TIGERScore-13B",
        "Average":56.79,
        "ARC":59.04,
        "HellaSwag":82.79,
        "MMLU":55.07,
        "TruthfulQA":40.38,
        "Winogrande":74.74,
        "GSM8K":28.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.02,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Llama-2-13b-hf-gpt-4-80k",
        "Average":56.79,
        "ARC":60.84,
        "HellaSwag":79.88,
        "MMLU":55.56,
        "TruthfulQA":49.83,
        "Winogrande":72.85,
        "GSM8K":21.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/Orca-2-13b-SFT_v5",
        "Average":56.77,
        "ARC":59.22,
        "HellaSwag":80.09,
        "MMLU":60.19,
        "TruthfulQA":51.84,
        "Winogrande":80.9,
        "GSM8K":8.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-IA3-v3",
        "Average":56.74,
        "ARC":62.54,
        "HellaSwag":82.1,
        "MMLU":58.67,
        "TruthfulQA":46.96,
        "Winogrande":77.82,
        "GSM8K":12.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Orca-Nova-13B",
        "Average":56.72,
        "ARC":62.37,
        "HellaSwag":82.47,
        "MMLU":57.44,
        "TruthfulQA":45.97,
        "Winogrande":77.58,
        "GSM8K":14.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-v2.1-L2-13B",
        "Average":56.71,
        "ARC":61.43,
        "HellaSwag":83.92,
        "MMLU":55.95,
        "TruthfulQA":50.3,
        "Winogrande":75.93,
        "GSM8K":12.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/OpenOrcaxOpenChat-Preview2-13B",
        "Average":56.7,
        "ARC":62.71,
        "HellaSwag":81.99,
        "MMLU":57.51,
        "TruthfulQA":47.45,
        "Winogrande":76.8,
        "GSM8K":13.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":102.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B-200K",
        "Average":56.69,
        "ARC":53.58,
        "HellaSwag":75.58,
        "MMLU":64.65,
        "TruthfulQA":41.74,
        "Winogrande":74.27,
        "GSM8K":30.33,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":166.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/k2s3_test_24001",
        "Average":56.68,
        "ARC":55.72,
        "HellaSwag":80.69,
        "MMLU":54.6,
        "TruthfulQA":43.57,
        "Winogrande":75.69,
        "GSM8K":29.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/k2s3_test_24001",
        "Average":56.67,
        "ARC":55.8,
        "HellaSwag":80.59,
        "MMLU":54.42,
        "TruthfulQA":43.62,
        "Winogrande":75.69,
        "GSM8K":29.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test3_sft_4bit",
        "Average":56.66,
        "ARC":61.52,
        "HellaSwag":83.89,
        "MMLU":64.79,
        "TruthfulQA":47.83,
        "Winogrande":81.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID-SFT-DPO-MixQV2-SOLIDChosen-SFTRejected-Zephyr-7b-beta",
        "Average":56.66,
        "ARC":60.75,
        "HellaSwag":83.68,
        "MMLU":59.42,
        "TruthfulQA":58.1,
        "Winogrande":76.32,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/SOLAR-13B-Instruct-v1.0",
        "Average":56.65,
        "ARC":57.25,
        "HellaSwag":78.03,
        "MMLU":55.75,
        "TruthfulQA":61.99,
        "Winogrande":70.24,
        "GSM8K":16.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":12.48,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-IA3",
        "Average":56.65,
        "ARC":62.12,
        "HellaSwag":82.1,
        "MMLU":58.84,
        "TruthfulQA":47.88,
        "Winogrande":77.11,
        "GSM8K":11.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/storytime-13b",
        "Average":56.64,
        "ARC":62.03,
        "HellaSwag":83.96,
        "MMLU":57.48,
        "TruthfulQA":52.5,
        "Winogrande":75.53,
        "GSM8K":8.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ZoidBB\/unraveled-7b-a1",
        "Average":56.63,
        "ARC":59.81,
        "HellaSwag":82.8,
        "MMLU":63.39,
        "TruthfulQA":42.23,
        "Winogrande":77.19,
        "GSM8K":14.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/duplicitous-slurpbeast-13b",
        "Average":56.62,
        "ARC":62.12,
        "HellaSwag":83.92,
        "MMLU":57.53,
        "TruthfulQA":52.33,
        "Winogrande":75.06,
        "GSM8K":8.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Amethyst-13B",
        "Average":56.62,
        "ARC":62.63,
        "HellaSwag":83.17,
        "MMLU":55.91,
        "TruthfulQA":52.43,
        "Winogrande":74.74,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Amethyst-13B-Mistral",
        "Average":56.62,
        "ARC":62.63,
        "HellaSwag":83.17,
        "MMLU":55.91,
        "TruthfulQA":52.43,
        "Winogrande":74.74,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BELLE-2\/BELLE-Llama2-13B-chat-0.4M",
        "Average":56.62,
        "ARC":60.67,
        "HellaSwag":82.31,
        "MMLU":55.94,
        "TruthfulQA":50.85,
        "Winogrande":75.53,
        "GSM8K":14.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Clover3-17B",
        "Average":56.61,
        "ARC":59.9,
        "HellaSwag":81.18,
        "MMLU":60.47,
        "TruthfulQA":40.72,
        "Winogrande":78.61,
        "GSM8K":18.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":16.84,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elinas\/chronos-33b",
        "Average":56.59,
        "ARC":62.2,
        "HellaSwag":83.48,
        "MMLU":55.87,
        "TruthfulQA":46.67,
        "Winogrande":78.3,
        "GSM8K":13.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/LlongOrca-13B-16k",
        "Average":56.59,
        "ARC":62.46,
        "HellaSwag":82.75,
        "MMLU":55.54,
        "TruthfulQA":50.11,
        "Winogrande":76.4,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/llama2-13b-megacode2-oasst",
        "Average":56.59,
        "ARC":60.67,
        "HellaSwag":81.93,
        "MMLU":57.38,
        "TruthfulQA":47.85,
        "Winogrande":76.16,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Brouz\/Slerpeno",
        "Average":56.59,
        "ARC":61.69,
        "HellaSwag":84.1,
        "MMLU":56.77,
        "TruthfulQA":48.05,
        "Winogrande":76.4,
        "GSM8K":12.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NovoCode\/Novocode7b-v2",
        "Average":56.57,
        "ARC":61.01,
        "HellaSwag":84.12,
        "MMLU":64.05,
        "TruthfulQA":42.21,
        "Winogrande":79.87,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/NyakuraV2.1-m7",
        "Average":56.57,
        "ARC":58.62,
        "HellaSwag":81.89,
        "MMLU":58.46,
        "TruthfulQA":45.01,
        "Winogrande":72.77,
        "GSM8K":22.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/duplicitous-mammal-13b",
        "Average":56.57,
        "ARC":61.69,
        "HellaSwag":83.79,
        "MMLU":57.5,
        "TruthfulQA":52.27,
        "Winogrande":75.06,
        "GSM8K":9.1,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/OpenRP-13B",
        "Average":56.57,
        "ARC":62.12,
        "HellaSwag":82.6,
        "MMLU":57.5,
        "TruthfulQA":48.29,
        "Winogrande":76.01,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fangzhaoz\/pearl7B_tuneonGSM8K",
        "Average":56.56,
        "ARC":55.63,
        "HellaSwag":73.31,
        "MMLU":44.95,
        "TruthfulQA":54.16,
        "Winogrande":71.35,
        "GSM8K":39.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MM-ReMM-L2-20B",
        "Average":56.55,
        "ARC":60.84,
        "HellaSwag":85.18,
        "MMLU":56.45,
        "TruthfulQA":53.33,
        "Winogrande":75.77,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sauce1337\/BerrySauce-L2-13b",
        "Average":56.55,
        "ARC":62.29,
        "HellaSwag":83.78,
        "MMLU":57.1,
        "TruthfulQA":48.3,
        "Winogrande":76.09,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bn22\/DolphinMini-Mistral-7B",
        "Average":56.53,
        "ARC":61.18,
        "HellaSwag":84.25,
        "MMLU":61.94,
        "TruthfulQA":52.34,
        "Winogrande":79.32,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pansophic\/new_model_test3",
        "Average":56.52,
        "ARC":51.79,
        "HellaSwag":78.61,
        "MMLU":49.14,
        "TruthfulQA":46.89,
        "Winogrande":70.48,
        "GSM8K":42.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewdBoros-L2-13B",
        "Average":56.51,
        "ARC":62.54,
        "HellaSwag":83.9,
        "MMLU":56.57,
        "TruthfulQA":48.14,
        "Winogrande":76.95,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-IA3-v4",
        "Average":56.49,
        "ARC":61.43,
        "HellaSwag":81.84,
        "MMLU":59.02,
        "TruthfulQA":48.64,
        "Winogrande":77.19,
        "GSM8K":10.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/EnsembleV5-Nova-13B",
        "Average":56.49,
        "ARC":62.71,
        "HellaSwag":82.55,
        "MMLU":56.79,
        "TruthfulQA":49.86,
        "Winogrande":76.24,
        "GSM8K":10.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/EnsembleV5-Nova-13B",
        "Average":56.49,
        "ARC":62.71,
        "HellaSwag":82.55,
        "MMLU":56.79,
        "TruthfulQA":49.86,
        "Winogrande":76.24,
        "GSM8K":10.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/mythalion-13b",
        "Average":56.48,
        "ARC":61.26,
        "HellaSwag":83.81,
        "MMLU":56.53,
        "TruthfulQA":46.56,
        "Winogrande":77.43,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":125.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jingyeom\/SOLAR_KO_1.3_deup",
        "Average":56.47,
        "ARC":55.97,
        "HellaSwag":79.97,
        "MMLU":55.88,
        "TruthfulQA":47.55,
        "Winogrande":76.87,
        "GSM8K":22.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-code-mistral-7b-v2.0",
        "Average":56.47,
        "ARC":52.47,
        "HellaSwag":75.61,
        "MMLU":51.31,
        "TruthfulQA":52.05,
        "Winogrande":71.43,
        "GSM8K":35.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/WizardLM-30B-Uncensored",
        "Average":56.46,
        "ARC":60.24,
        "HellaSwag":82.93,
        "MMLU":56.8,
        "TruthfulQA":51.57,
        "Winogrande":74.35,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SciPhi\/SciPhi-Self-RAG-Mistral-7B-32k",
        "Average":56.46,
        "ARC":57.34,
        "HellaSwag":80.44,
        "MMLU":60.81,
        "TruthfulQA":45.63,
        "Winogrande":74.82,
        "GSM8K":19.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":79.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"royallab\/Pygmalion-2-13b-SuperCOT",
        "Average":56.46,
        "ARC":63.23,
        "HellaSwag":83.68,
        "MMLU":54.9,
        "TruthfulQA":53.14,
        "Winogrande":77.51,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jefferylovely\/AiMaven-Orca2",
        "Average":56.45,
        "ARC":54.69,
        "HellaSwag":79.0,
        "MMLU":54.61,
        "TruthfulQA":53.43,
        "Winogrande":74.35,
        "GSM8K":22.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-Inverted-L2-13B",
        "Average":56.44,
        "ARC":59.3,
        "HellaSwag":82.9,
        "MMLU":56.45,
        "TruthfulQA":52.04,
        "Winogrande":74.74,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Nova-13B",
        "Average":56.44,
        "ARC":62.71,
        "HellaSwag":82.57,
        "MMLU":57.98,
        "TruthfulQA":51.34,
        "Winogrande":77.27,
        "GSM8K":6.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deita-4b",
        "Average":56.43,
        "ARC":46.08,
        "HellaSwag":71.81,
        "MMLU":55.46,
        "TruthfulQA":50.23,
        "Winogrande":66.14,
        "GSM8K":48.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.95,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-L2-13B",
        "Average":56.43,
        "ARC":61.01,
        "HellaSwag":83.95,
        "MMLU":56.33,
        "TruthfulQA":50.18,
        "Winogrande":75.14,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NeuralNovel\/Senzu-7B-v0.1",
        "Average":56.4,
        "ARC":58.19,
        "HellaSwag":81.98,
        "MMLU":63.2,
        "TruthfulQA":40.2,
        "Winogrande":76.64,
        "GSM8K":18.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Mythical-Destroyer-L2-13B",
        "Average":56.39,
        "ARC":58.7,
        "HellaSwag":82.0,
        "MMLU":57.66,
        "TruthfulQA":56.35,
        "Winogrande":74.66,
        "GSM8K":8.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yeen214\/llama2_7b_merge_orcafamily",
        "Average":56.38,
        "ARC":56.91,
        "HellaSwag":81.17,
        "MMLU":51.49,
        "TruthfulQA":49.68,
        "Winogrande":75.93,
        "GSM8K":23.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-AdventurousWinds-Mk2-7b",
        "Average":56.38,
        "ARC":58.19,
        "HellaSwag":83.48,
        "MMLU":61.8,
        "TruthfulQA":43.56,
        "Winogrande":76.32,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-v2.4-13B",
        "Average":56.37,
        "ARC":61.69,
        "HellaSwag":83.83,
        "MMLU":55.1,
        "TruthfulQA":53.34,
        "Winogrande":74.51,
        "GSM8K":9.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-code-mistral-7b-v2.0",
        "Average":56.37,
        "ARC":52.3,
        "HellaSwag":75.61,
        "MMLU":51.28,
        "TruthfulQA":52.05,
        "Winogrande":71.35,
        "GSM8K":35.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-l2-13b-2.2.1",
        "Average":56.36,
        "ARC":60.92,
        "HellaSwag":83.77,
        "MMLU":56.47,
        "TruthfulQA":49.42,
        "Winogrande":76.01,
        "GSM8K":11.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v3.1",
        "Average":56.36,
        "ARC":59.81,
        "HellaSwag":82.8,
        "MMLU":56.76,
        "TruthfulQA":44.45,
        "Winogrande":76.24,
        "GSM8K":18.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Kabster\/BioMistral-Zephyr-Beta-SLERP",
        "Average":56.35,
        "ARC":62.12,
        "HellaSwag":84.13,
        "MMLU":60.63,
        "TruthfulQA":54.6,
        "Winogrande":76.64,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bartowski\/internlm2-math-20b-llama",
        "Average":56.35,
        "ARC":59.98,
        "HellaSwag":81.64,
        "MMLU":65.07,
        "TruthfulQA":52.9,
        "Winogrande":76.4,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":19.86,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Darewin-7B-v2",
        "Average":56.34,
        "ARC":62.63,
        "HellaSwag":78.28,
        "MMLU":53.01,
        "TruthfulQA":50.99,
        "Winogrande":73.95,
        "GSM8K":19.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Doctor-Shotgun\/CalliopeDS-L2-13B",
        "Average":56.34,
        "ARC":60.49,
        "HellaSwag":83.38,
        "MMLU":55.8,
        "TruthfulQA":51.32,
        "Winogrande":77.03,
        "GSM8K":10.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"agpl-3.0",
        "Available on the Hub":13.02,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"iGenius-AI-Team\/LLAMA-13B-test-finetuning",
        "Average":56.34,
        "ARC":58.02,
        "HellaSwag":82.36,
        "MMLU":54.27,
        "TruthfulQA":44.14,
        "Winogrande":76.72,
        "GSM8K":22.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v4-qwen1_5-4b",
        "Average":56.34,
        "ARC":46.08,
        "HellaSwag":70.8,
        "MMLU":55.11,
        "TruthfulQA":47.29,
        "Winogrande":67.64,
        "GSM8K":51.1,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoMix-L2-13b",
        "Average":56.31,
        "ARC":61.09,
        "HellaSwag":83.86,
        "MMLU":55.42,
        "TruthfulQA":52.08,
        "Winogrande":75.45,
        "GSM8K":9.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/mistral-7b_open_platypus",
        "Average":56.29,
        "ARC":55.8,
        "HellaSwag":82.13,
        "MMLU":59.76,
        "TruthfulQA":48.87,
        "Winogrande":78.61,
        "GSM8K":12.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-IA3-v2.1",
        "Average":56.29,
        "ARC":62.29,
        "HellaSwag":82.09,
        "MMLU":57.91,
        "TruthfulQA":47.03,
        "Winogrande":77.43,
        "GSM8K":10.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Uncensored-Jordan-13B",
        "Average":56.27,
        "ARC":57.42,
        "HellaSwag":82.7,
        "MMLU":55.75,
        "TruthfulQA":50.51,
        "Winogrande":76.16,
        "GSM8K":15.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-code-mistral-orca-7b-v1.0",
        "Average":56.24,
        "ARC":59.64,
        "HellaSwag":82.25,
        "MMLU":61.33,
        "TruthfulQA":48.45,
        "Winogrande":77.51,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/StableBeluga-13B-instruct-PL-lora_unload",
        "Average":56.24,
        "ARC":60.92,
        "HellaSwag":82.13,
        "MMLU":56.99,
        "TruthfulQA":48.64,
        "Winogrande":76.56,
        "GSM8K":12.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r8_a16",
        "Average":56.23,
        "ARC":59.73,
        "HellaSwag":82.3,
        "MMLU":55.73,
        "TruthfulQA":37.95,
        "Winogrande":77.11,
        "GSM8K":24.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KatyTheCutie\/EstopianMaid-13B",
        "Average":56.2,
        "ARC":60.49,
        "HellaSwag":83.49,
        "MMLU":56.18,
        "TruthfulQA":52.35,
        "Winogrande":75.53,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"arlineka\/Brunhilde-13b",
        "Average":56.2,
        "ARC":60.49,
        "HellaSwag":83.49,
        "MMLU":56.18,
        "TruthfulQA":52.35,
        "Winogrande":75.53,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-6B-200K-AEZAKMI-v2-rawrr1-DPO",
        "Average":56.2,
        "ARC":52.47,
        "HellaSwag":77.04,
        "MMLU":62.57,
        "TruthfulQA":47.15,
        "Winogrande":71.03,
        "GSM8K":26.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoLogic-L2-13b",
        "Average":56.19,
        "ARC":61.01,
        "HellaSwag":83.93,
        "MMLU":55.7,
        "TruthfulQA":48.64,
        "Winogrande":76.09,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-11B-Testbench",
        "Average":56.17,
        "ARC":57.34,
        "HellaSwag":78.66,
        "MMLU":55.56,
        "TruthfulQA":51.97,
        "Winogrande":75.77,
        "GSM8K":17.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":11.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Azazelle\/Moko-DARE",
        "Average":56.16,
        "ARC":60.58,
        "HellaSwag":82.08,
        "MMLU":61.94,
        "TruthfulQA":52.17,
        "Winogrande":75.14,
        "GSM8K":5.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v19.1-4k",
        "Average":56.16,
        "ARC":53.41,
        "HellaSwag":74.58,
        "MMLU":57.29,
        "TruthfulQA":48.25,
        "Winogrande":69.93,
        "GSM8K":33.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v5-4b",
        "Average":56.16,
        "ARC":46.76,
        "HellaSwag":71.87,
        "MMLU":55.04,
        "TruthfulQA":47.51,
        "Winogrande":67.4,
        "GSM8K":48.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r128_a16",
        "Average":56.16,
        "ARC":59.9,
        "HellaSwag":82.31,
        "MMLU":55.59,
        "TruthfulQA":38.22,
        "Winogrande":77.03,
        "GSM8K":23.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-1.2-L2-13B",
        "Average":56.15,
        "ARC":60.75,
        "HellaSwag":83.67,
        "MMLU":56.27,
        "TruthfulQA":50.32,
        "Winogrande":74.98,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/Orca-2-13b-SFT-v6",
        "Average":56.15,
        "ARC":60.41,
        "HellaSwag":80.46,
        "MMLU":59.51,
        "TruthfulQA":54.01,
        "Winogrande":77.43,
        "GSM8K":5.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-13b",
        "Average":56.14,
        "ARC":57.0,
        "HellaSwag":80.89,
        "MMLU":54.38,
        "TruthfulQA":40.43,
        "Winogrande":76.87,
        "GSM8K":27.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/SpeechlessV1-Nova-13B",
        "Average":56.14,
        "ARC":61.77,
        "HellaSwag":82.68,
        "MMLU":57.75,
        "TruthfulQA":51.44,
        "Winogrande":77.43,
        "GSM8K":5.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r32_a16",
        "Average":56.14,
        "ARC":59.9,
        "HellaSwag":82.33,
        "MMLU":55.67,
        "TruthfulQA":38.3,
        "Winogrande":77.03,
        "GSM8K":23.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HenryJJ\/Instruct_Yi-6B_Dolly_CodeAlpaca",
        "Average":56.11,
        "ARC":53.16,
        "HellaSwag":75.3,
        "MMLU":63.06,
        "TruthfulQA":41.42,
        "Winogrande":75.37,
        "GSM8K":28.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WhoTookMyAmogusNickname\/NewHope_HF_not_official",
        "Average":56.11,
        "ARC":61.09,
        "HellaSwag":84.03,
        "MMLU":55.73,
        "TruthfulQA":44.96,
        "Winogrande":74.98,
        "GSM8K":15.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Austism\/chronos-hermes-13b-v2",
        "Average":56.1,
        "ARC":60.32,
        "HellaSwag":83.21,
        "MMLU":55.05,
        "TruthfulQA":50.91,
        "Winogrande":75.37,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/Nebula-7B",
        "Average":56.1,
        "ARC":59.3,
        "HellaSwag":83.46,
        "MMLU":57.0,
        "TruthfulQA":45.56,
        "Winogrande":76.4,
        "GSM8K":14.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r8_a4",
        "Average":56.1,
        "ARC":59.9,
        "HellaSwag":82.47,
        "MMLU":55.47,
        "TruthfulQA":38.04,
        "Winogrande":77.03,
        "GSM8K":23.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kaist-ai\/prometheus-13b-v1.0",
        "Average":56.09,
        "ARC":53.24,
        "HellaSwag":80.75,
        "MMLU":51.49,
        "TruthfulQA":45.66,
        "Winogrande":73.72,
        "GSM8K":31.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":95.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e4",
        "Average":56.08,
        "ARC":60.07,
        "HellaSwag":82.45,
        "MMLU":55.37,
        "TruthfulQA":38.52,
        "Winogrande":76.95,
        "GSM8K":23.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/BigMaid-20B-v1.0",
        "Average":56.07,
        "ARC":61.35,
        "HellaSwag":85.26,
        "MMLU":57.15,
        "TruthfulQA":55.29,
        "Winogrande":75.3,
        "GSM8K":2.05,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":19.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augtoma\/qCammel-13",
        "Average":56.05,
        "ARC":60.84,
        "HellaSwag":83.66,
        "MMLU":56.73,
        "TruthfulQA":47.54,
        "Winogrande":76.16,
        "GSM8K":11.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/g8s-preview",
        "Average":56.04,
        "ARC":49.74,
        "HellaSwag":72.27,
        "MMLU":54.85,
        "TruthfulQA":52.49,
        "Winogrande":67.48,
        "GSM8K":39.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r2_a4",
        "Average":56.03,
        "ARC":59.98,
        "HellaSwag":82.37,
        "MMLU":55.42,
        "TruthfulQA":38.14,
        "Winogrande":76.56,
        "GSM8K":23.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"The-Face-Of-Goonery\/Huginn-13b-v1.2",
        "Average":56.03,
        "ARC":60.92,
        "HellaSwag":83.56,
        "MMLU":55.33,
        "TruthfulQA":51.97,
        "Winogrande":75.22,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-SLERP-L2-13B",
        "Average":56.03,
        "ARC":60.92,
        "HellaSwag":83.56,
        "MMLU":55.33,
        "TruthfulQA":51.97,
        "Winogrande":75.22,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/carl-33b",
        "Average":56.03,
        "ARC":64.59,
        "HellaSwag":85.27,
        "MMLU":58.38,
        "TruthfulQA":45.32,
        "Winogrande":76.24,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":33.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WebraftAI\/synapsellm-7b-mistral-v0.5-preview",
        "Average":56.03,
        "ARC":52.73,
        "HellaSwag":76.51,
        "MMLU":54.67,
        "TruthfulQA":55.16,
        "Winogrande":74.35,
        "GSM8K":22.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-MoE-A2.7B",
        "Average":56.03,
        "ARC":54.86,
        "HellaSwag":79.39,
        "MMLU":62.54,
        "TruthfulQA":50.09,
        "Winogrande":72.3,
        "GSM8K":16.98,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.32,
        "Model Sha":122.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vilm\/Quyen-v0.1",
        "Average":56.02,
        "ARC":48.21,
        "HellaSwag":72.49,
        "MMLU":52.88,
        "TruthfulQA":51.53,
        "Winogrande":65.11,
        "GSM8K":45.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/neural-chat-7b-v3-1-Nebula-v2-7B",
        "Average":56.01,
        "ARC":61.77,
        "HellaSwag":80.21,
        "MMLU":59.07,
        "TruthfulQA":58.56,
        "Winogrande":71.82,
        "GSM8K":4.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoMax-L2-13b",
        "Average":56.0,
        "ARC":60.92,
        "HellaSwag":83.56,
        "MMLU":55.33,
        "TruthfulQA":51.97,
        "Winogrande":75.22,
        "GSM8K":9.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":217.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Minami-su\/Qwen1.5-7B-Chat_llamafy",
        "Average":56.0,
        "ARC":57.59,
        "HellaSwag":78.52,
        "MMLU":61.18,
        "TruthfulQA":57.59,
        "Winogrande":66.46,
        "GSM8K":14.63,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/huginnv1.2",
        "Average":55.98,
        "ARC":62.37,
        "HellaSwag":84.28,
        "MMLU":57.02,
        "TruthfulQA":47.81,
        "Winogrande":75.22,
        "GSM8K":9.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-Llama2-13b",
        "Average":55.97,
        "ARC":61.52,
        "HellaSwag":83.29,
        "MMLU":55.11,
        "TruthfulQA":50.38,
        "Winogrande":75.45,
        "GSM8K":10.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.0,
        "Model Sha":289.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/Samantha-1.11-13b",
        "Average":55.97,
        "ARC":60.84,
        "HellaSwag":82.99,
        "MMLU":55.96,
        "TruthfulQA":47.72,
        "Winogrande":76.01,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/LongQLoRA-Vicuna-13b-8k",
        "Average":55.96,
        "ARC":56.4,
        "HellaSwag":81.05,
        "MMLU":53.68,
        "TruthfulQA":47.07,
        "Winogrande":74.51,
        "GSM8K":23.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-gemma-7b-v19.1-4k",
        "Average":55.95,
        "ARC":55.29,
        "HellaSwag":71.07,
        "MMLU":53.32,
        "TruthfulQA":49.21,
        "Winogrande":67.48,
        "GSM8K":39.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r2_a64",
        "Average":55.95,
        "ARC":60.07,
        "HellaSwag":82.0,
        "MMLU":55.18,
        "TruthfulQA":37.41,
        "Winogrande":76.87,
        "GSM8K":24.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Walter-SOLAR-11B",
        "Average":55.95,
        "ARC":60.41,
        "HellaSwag":84.86,
        "MMLU":64.99,
        "TruthfulQA":44.88,
        "Winogrande":79.56,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID-SFT-DPO-MixQV3-SOLIDChosen-SFTRejected-Zephyr-7b-beta",
        "Average":55.93,
        "ARC":59.56,
        "HellaSwag":82.53,
        "MMLU":59.6,
        "TruthfulQA":57.58,
        "Winogrande":74.9,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Nous-Hermes-13B-Code",
        "Average":55.93,
        "ARC":61.18,
        "HellaSwag":83.21,
        "MMLU":55.13,
        "TruthfulQA":50.56,
        "Winogrande":75.14,
        "GSM8K":10.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/Chat-AYB-Platypus2-13B",
        "Average":55.93,
        "ARC":60.49,
        "HellaSwag":84.03,
        "MMLU":57.83,
        "TruthfulQA":54.52,
        "Winogrande":75.77,
        "GSM8K":2.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WebraftAI\/synapsellm-7b-mistral-v0.4-preview2",
        "Average":55.93,
        "ARC":52.99,
        "HellaSwag":74.54,
        "MMLU":54.6,
        "TruthfulQA":53.79,
        "Winogrande":73.95,
        "GSM8K":25.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WebraftAI\/synapsellm-7b-mistral-v0.5-preview2",
        "Average":55.93,
        "ARC":52.22,
        "HellaSwag":75.54,
        "MMLU":51.64,
        "TruthfulQA":55.47,
        "Winogrande":73.09,
        "GSM8K":27.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r2_a16",
        "Average":55.92,
        "ARC":59.73,
        "HellaSwag":82.38,
        "MMLU":55.27,
        "TruthfulQA":38.66,
        "Winogrande":76.64,
        "GSM8K":22.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r32_a4",
        "Average":55.91,
        "ARC":59.81,
        "HellaSwag":82.42,
        "MMLU":55.56,
        "TruthfulQA":38.13,
        "Winogrande":76.87,
        "GSM8K":22.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r128_a4",
        "Average":55.91,
        "ARC":59.9,
        "HellaSwag":82.43,
        "MMLU":55.44,
        "TruthfulQA":38.05,
        "Winogrande":76.8,
        "GSM8K":22.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sauce1337\/AppleSauce-L2-13b",
        "Average":55.91,
        "ARC":61.01,
        "HellaSwag":83.61,
        "MMLU":57.07,
        "TruthfulQA":47.81,
        "Winogrande":75.93,
        "GSM8K":10.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-13B-v1.2",
        "Average":55.9,
        "ARC":61.26,
        "HellaSwag":82.93,
        "MMLU":56.47,
        "TruthfulQA":47.27,
        "Winogrande":76.48,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yanolja\/EEVE-Korean-2.8B-v1.0",
        "Average":55.9,
        "ARC":57.25,
        "HellaSwag":72.15,
        "MMLU":51.62,
        "TruthfulQA":44.27,
        "Winogrande":73.72,
        "GSM8K":36.39,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.82,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openBuddy\/openbuddy-llama2-34b-v11.1-bf16",
        "Average":55.88,
        "ARC":50.0,
        "HellaSwag":71.19,
        "MMLU":55.71,
        "TruthfulQA":53.01,
        "Winogrande":70.8,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":33.53,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-codellama2-34b-v11.1-bf16",
        "Average":55.88,
        "ARC":50.0,
        "HellaSwag":71.19,
        "MMLU":55.71,
        "TruthfulQA":53.01,
        "Winogrande":70.8,
        "GSM8K":34.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":34.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-tutor-13b-ep3",
        "Average":55.88,
        "ARC":57.34,
        "HellaSwag":81.51,
        "MMLU":57.02,
        "TruthfulQA":52.99,
        "Winogrande":74.35,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/tutor-model-13b-ep3",
        "Average":55.88,
        "ARC":57.34,
        "HellaSwag":81.51,
        "MMLU":57.02,
        "TruthfulQA":52.99,
        "Winogrande":74.35,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama2-13b-v1.2",
        "Average":55.87,
        "ARC":60.67,
        "HellaSwag":80.46,
        "MMLU":56.51,
        "TruthfulQA":51.03,
        "Winogrande":74.82,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Radiantloom\/radintloom-mistral-7b-fusion",
        "Average":55.86,
        "ARC":62.03,
        "HellaSwag":82.26,
        "MMLU":63.82,
        "TruthfulQA":47.19,
        "Winogrande":79.87,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/Synatra-V0.1-7B-Instruct",
        "Average":55.86,
        "ARC":55.29,
        "HellaSwag":76.63,
        "MMLU":55.29,
        "TruthfulQA":55.76,
        "Winogrande":72.77,
        "GSM8K":19.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maywell\/Synatra-V0.1-7B",
        "Average":55.86,
        "ARC":55.29,
        "HellaSwag":76.63,
        "MMLU":55.29,
        "TruthfulQA":55.76,
        "Winogrande":72.77,
        "GSM8K":19.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/Newton-7B",
        "Average":55.85,
        "ARC":63.99,
        "HellaSwag":81.72,
        "MMLU":62.78,
        "TruthfulQA":44.36,
        "Winogrande":78.85,
        "GSM8K":3.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_attn_only",
        "Average":55.85,
        "ARC":60.75,
        "HellaSwag":82.09,
        "MMLU":55.52,
        "TruthfulQA":38.16,
        "Winogrande":75.85,
        "GSM8K":22.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/7B-DPO-alpha",
        "Average":55.84,
        "ARC":50.85,
        "HellaSwag":73.0,
        "MMLU":63.39,
        "TruthfulQA":57.58,
        "Winogrande":67.56,
        "GSM8K":22.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":7.0,
        "Model Sha":57.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janhq\/Mistral-7B-Instruct-v0.2-DARE",
        "Average":55.84,
        "ARC":61.95,
        "HellaSwag":75.62,
        "MMLU":49.99,
        "TruthfulQA":54.36,
        "Winogrande":74.98,
        "GSM8K":18.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-13b",
        "Average":55.83,
        "ARC":61.26,
        "HellaSwag":82.13,
        "MMLU":56.25,
        "TruthfulQA":46.67,
        "Winogrande":76.32,
        "GSM8K":12.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"feidfoe\/Metamath-reproduce-7b",
        "Average":55.81,
        "ARC":47.18,
        "HellaSwag":73.65,
        "MMLU":42.94,
        "TruthfulQA":41.58,
        "Winogrande":71.35,
        "GSM8K":58.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/very-test",
        "Average":55.8,
        "ARC":63.91,
        "HellaSwag":81.71,
        "MMLU":62.89,
        "TruthfulQA":44.28,
        "Winogrande":78.69,
        "GSM8K":3.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-OpenOrca_5w",
        "Average":55.8,
        "ARC":61.01,
        "HellaSwag":82.82,
        "MMLU":56.09,
        "TruthfulQA":44.87,
        "Winogrande":77.74,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abacusai\/Fewshot-Metamath-OrcaVicuna-Mistral-10B",
        "Average":55.79,
        "ARC":56.4,
        "HellaSwag":78.12,
        "MMLU":59.52,
        "TruthfulQA":50.98,
        "Winogrande":76.48,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pansophic\/rocket-3B",
        "Average":55.77,
        "ARC":50.6,
        "HellaSwag":76.69,
        "MMLU":47.1,
        "TruthfulQA":55.82,
        "Winogrande":67.96,
        "GSM8K":36.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":2.8,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-Llama2-13b",
        "Average":55.75,
        "ARC":61.26,
        "HellaSwag":83.26,
        "MMLU":55.04,
        "TruthfulQA":50.41,
        "Winogrande":75.37,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.0,
        "Model Sha":289.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Stable-Platypus2-13B",
        "Average":55.75,
        "ARC":62.71,
        "HellaSwag":82.29,
        "MMLU":58.3,
        "TruthfulQA":52.52,
        "Winogrande":76.87,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":13.02,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lu-vae\/llama2-13B-sharegpt4-orca-openplatypus-8w",
        "Average":55.75,
        "ARC":62.8,
        "HellaSwag":84.04,
        "MMLU":55.13,
        "TruthfulQA":45.66,
        "Winogrande":75.14,
        "GSM8K":11.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/mistral-experiment-6",
        "Average":55.75,
        "ARC":55.8,
        "HellaSwag":81.45,
        "MMLU":55.57,
        "TruthfulQA":45.69,
        "Winogrande":73.8,
        "GSM8K":22.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Telugu-LLM-Labs\/Indic-gemma-7b-finetuned-sft-Navarasa-2.0",
        "Average":55.74,
        "ARC":54.61,
        "HellaSwag":74.35,
        "MMLU":54.15,
        "TruthfulQA":49.59,
        "Winogrande":69.61,
        "GSM8K":32.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abhaykoul\/vortex2",
        "Average":55.74,
        "ARC":50.68,
        "HellaSwag":76.72,
        "MMLU":47.11,
        "TruthfulQA":55.83,
        "Winogrande":67.64,
        "GSM8K":36.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PulsarAI\/CollectiveCognition-v1.1-Nebula-7B",
        "Average":55.72,
        "ARC":58.11,
        "HellaSwag":82.39,
        "MMLU":57.03,
        "TruthfulQA":53.53,
        "Winogrande":73.72,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v3.1",
        "Average":55.71,
        "ARC":60.15,
        "HellaSwag":82.84,
        "MMLU":56.84,
        "TruthfulQA":44.38,
        "Winogrande":76.24,
        "GSM8K":13.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-1.1-L2-13B",
        "Average":55.71,
        "ARC":60.75,
        "HellaSwag":83.64,
        "MMLU":56.39,
        "TruthfulQA":50.3,
        "Winogrande":75.22,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lu-vae\/llama2-13b-sharegpt4-test",
        "Average":55.69,
        "ARC":58.02,
        "HellaSwag":82.65,
        "MMLU":55.99,
        "TruthfulQA":48.27,
        "Winogrande":76.09,
        "GSM8K":13.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r128_a64",
        "Average":55.69,
        "ARC":59.04,
        "HellaSwag":82.27,
        "MMLU":55.54,
        "TruthfulQA":37.2,
        "Winogrande":76.72,
        "GSM8K":23.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Average":55.69,
        "ARC":59.39,
        "HellaSwag":82.13,
        "MMLU":55.77,
        "TruthfulQA":37.38,
        "Winogrande":76.64,
        "GSM8K":22.82,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":527.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v3.2",
        "Average":55.68,
        "ARC":59.64,
        "HellaSwag":82.68,
        "MMLU":56.68,
        "TruthfulQA":44.49,
        "Winogrande":76.95,
        "GSM8K":13.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama2-13b",
        "Average":55.68,
        "ARC":59.13,
        "HellaSwag":81.99,
        "MMLU":55.49,
        "TruthfulQA":51.57,
        "Winogrande":74.66,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5",
        "Average":55.67,
        "ARC":59.22,
        "HellaSwag":82.41,
        "MMLU":55.67,
        "TruthfulQA":37.65,
        "Winogrande":76.95,
        "GSM8K":22.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-13b-fast",
        "Average":55.67,
        "ARC":55.89,
        "HellaSwag":80.73,
        "MMLU":54.4,
        "TruthfulQA":40.31,
        "Winogrande":77.19,
        "GSM8K":25.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-hermes-coig-lite-13b",
        "Average":55.65,
        "ARC":59.47,
        "HellaSwag":82.28,
        "MMLU":55.18,
        "TruthfulQA":47.6,
        "Winogrande":78.61,
        "GSM8K":10.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/U-Amethyst-20B",
        "Average":55.65,
        "ARC":62.2,
        "HellaSwag":83.11,
        "MMLU":55.88,
        "TruthfulQA":53.2,
        "Winogrande":74.19,
        "GSM8K":5.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.99,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Enno-Ai\/ennodata-13b-8bit-raw-15epoch",
        "Average":55.65,
        "ARC":61.6,
        "HellaSwag":82.2,
        "MMLU":57.55,
        "TruthfulQA":53.58,
        "Winogrande":77.51,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Uncensored-Frank-13B",
        "Average":55.64,
        "ARC":61.6,
        "HellaSwag":82.62,
        "MMLU":54.55,
        "TruthfulQA":48.34,
        "Winogrande":74.74,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"The-Face-Of-Goonery\/Huginn-V5-10.7B",
        "Average":55.62,
        "ARC":63.31,
        "HellaSwag":78.8,
        "MMLU":54.22,
        "TruthfulQA":44.52,
        "Winogrande":73.72,
        "GSM8K":19.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/a",
        "Average":55.61,
        "ARC":63.48,
        "HellaSwag":86.49,
        "MMLU":56.76,
        "TruthfulQA":44.55,
        "Winogrande":82.4,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r32_a64",
        "Average":55.61,
        "ARC":58.96,
        "HellaSwag":82.31,
        "MMLU":55.23,
        "TruthfulQA":37.41,
        "Winogrande":76.72,
        "GSM8K":23.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TFLai\/Nova-13B-50-step",
        "Average":55.61,
        "ARC":61.6,
        "HellaSwag":82.31,
        "MMLU":57.27,
        "TruthfulQA":51.53,
        "Winogrande":76.56,
        "GSM8K":4.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/ANIMA-Phi-Neptune-Mistral-7B-v4",
        "Average":55.61,
        "ARC":55.46,
        "HellaSwag":77.63,
        "MMLU":53.12,
        "TruthfulQA":59.01,
        "Winogrande":73.48,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Abhaykoul\/HelpingAI-3B",
        "Average":55.59,
        "ARC":50.6,
        "HellaSwag":76.64,
        "MMLU":46.82,
        "TruthfulQA":55.62,
        "Winogrande":67.8,
        "GSM8K":36.09,
        "Type":"pretrained",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"defog\/sqlcoder-34b-alpha",
        "Average":55.59,
        "ARC":54.18,
        "HellaSwag":75.93,
        "MMLU":54.42,
        "TruthfulQA":40.63,
        "Winogrande":73.48,
        "GSM8K":34.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":34.0,
        "Model Sha":162.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/StableBeluga-7B-activity-fine-tuned-v2",
        "Average":55.58,
        "ARC":56.23,
        "HellaSwag":79.06,
        "MMLU":52.54,
        "TruthfulQA":50.01,
        "Winogrande":75.53,
        "GSM8K":20.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Stable-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":55.56,
        "ARC":62.29,
        "HellaSwag":82.46,
        "MMLU":57.09,
        "TruthfulQA":51.41,
        "Winogrande":76.56,
        "GSM8K":3.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/ANIMA-Phi-Neptune-Mistral-7B",
        "Average":55.54,
        "ARC":55.97,
        "HellaSwag":76.22,
        "MMLU":52.89,
        "TruthfulQA":59.76,
        "Winogrande":73.48,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"artistic-2.0",
        "Available on the Hub":7.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"internlm\/internlm-20b-chat",
        "Average":55.53,
        "ARC":55.38,
        "HellaSwag":78.58,
        "MMLU":58.53,
        "TruthfulQA":43.22,
        "Winogrande":78.77,
        "GSM8K":18.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-dolphin_5w",
        "Average":55.53,
        "ARC":60.67,
        "HellaSwag":82.69,
        "MMLU":56.23,
        "TruthfulQA":44.41,
        "Winogrande":77.35,
        "GSM8K":11.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-hermes-coig-lite-13b",
        "Average":55.51,
        "ARC":59.56,
        "HellaSwag":82.26,
        "MMLU":55.3,
        "TruthfulQA":47.56,
        "Winogrande":78.53,
        "GSM8K":9.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augmxnt\/shisa-gamma-7b-v1",
        "Average":55.5,
        "ARC":53.16,
        "HellaSwag":77.3,
        "MMLU":55.23,
        "TruthfulQA":50.73,
        "Winogrande":73.88,
        "GSM8K":22.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-Inverted-1.2-L2-13B",
        "Average":55.5,
        "ARC":59.39,
        "HellaSwag":83.01,
        "MMLU":55.77,
        "TruthfulQA":51.22,
        "Winogrande":74.66,
        "GSM8K":8.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kingbri\/airolima-chronos-grad-l2-13B",
        "Average":55.5,
        "ARC":59.56,
        "HellaSwag":83.5,
        "MMLU":55.78,
        "TruthfulQA":44.67,
        "Winogrande":75.85,
        "GSM8K":13.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/UndiMix-v1-13b",
        "Average":55.5,
        "ARC":59.47,
        "HellaSwag":82.45,
        "MMLU":55.83,
        "TruthfulQA":49.78,
        "Winogrande":75.45,
        "GSM8K":10.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kingbri\/chronolima-airo-grad-l2-13B",
        "Average":55.5,
        "ARC":59.56,
        "HellaSwag":83.47,
        "MMLU":55.8,
        "TruthfulQA":44.58,
        "Winogrande":75.61,
        "GSM8K":13.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v3.2",
        "Average":55.49,
        "ARC":59.47,
        "HellaSwag":82.6,
        "MMLU":56.82,
        "TruthfulQA":44.51,
        "Winogrande":76.09,
        "GSM8K":13.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Suprit\/Zhongjing-LLaMA-base",
        "Average":55.47,
        "ARC":55.12,
        "HellaSwag":79.72,
        "MMLU":48.23,
        "TruthfulQA":48.88,
        "Winogrande":74.82,
        "GSM8K":26.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r8_a64",
        "Average":55.45,
        "ARC":59.56,
        "HellaSwag":82.18,
        "MMLU":55.32,
        "TruthfulQA":37.08,
        "Winogrande":76.16,
        "GSM8K":22.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-1-2",
        "Average":55.42,
        "ARC":62.03,
        "HellaSwag":81.3,
        "MMLU":62.95,
        "TruthfulQA":46.81,
        "Winogrande":77.74,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-13b-v1.5",
        "Average":55.41,
        "ARC":57.08,
        "HellaSwag":81.24,
        "MMLU":56.67,
        "TruthfulQA":51.51,
        "Winogrande":74.66,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":172.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dddsaty\/Open_Ko_SOLAR_DPO_Merge_v0.1",
        "Average":55.41,
        "ARC":55.12,
        "HellaSwag":78.18,
        "MMLU":54.19,
        "TruthfulQA":40.17,
        "Winogrande":75.69,
        "GSM8K":29.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/model_007_13b_v2",
        "Average":55.41,
        "ARC":61.95,
        "HellaSwag":82.48,
        "MMLU":57.32,
        "TruthfulQA":53.5,
        "Winogrande":75.85,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Expert68\/llama2_13b_instructed_version2",
        "Average":55.41,
        "ARC":60.07,
        "HellaSwag":84.05,
        "MMLU":55.61,
        "TruthfulQA":46.12,
        "Winogrande":75.61,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-13B",
        "Average":55.41,
        "ARC":59.98,
        "HellaSwag":81.86,
        "MMLU":56.11,
        "TruthfulQA":47.41,
        "Winogrande":76.09,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Enno-Ai\/ennodata-raw-pankajmathur-13b-peft",
        "Average":55.4,
        "ARC":61.95,
        "HellaSwag":82.21,
        "MMLU":57.44,
        "TruthfulQA":53.57,
        "Winogrande":75.93,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
        "Average":55.4,
        "ARC":59.13,
        "HellaSwag":80.64,
        "MMLU":56.12,
        "TruthfulQA":51.29,
        "Winogrande":74.66,
        "GSM8K":10.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-orca-platypus-coig-lite-2k-0.6e-13b",
        "Average":55.4,
        "ARC":59.9,
        "HellaSwag":80.76,
        "MMLU":58.34,
        "TruthfulQA":47.97,
        "Winogrande":77.9,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pleisto\/yuren-13b-chatml",
        "Average":55.39,
        "ARC":53.07,
        "HellaSwag":78.03,
        "MMLU":56.34,
        "TruthfulQA":42.32,
        "Winogrande":74.43,
        "GSM8K":28.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-30b-chat",
        "Average":55.38,
        "ARC":58.7,
        "HellaSwag":82.54,
        "MMLU":51.16,
        "TruthfulQA":52.42,
        "Winogrande":75.3,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":30.0,
        "Model Sha":195.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llm-agents\/tora-13b-v1.0",
        "Average":55.37,
        "ARC":58.96,
        "HellaSwag":82.31,
        "MMLU":54.59,
        "TruthfulQA":40.22,
        "Winogrande":75.37,
        "GSM8K":20.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/minotaur-llama2-13b-qlora",
        "Average":55.37,
        "ARC":60.07,
        "HellaSwag":82.42,
        "MMLU":55.87,
        "TruthfulQA":45.57,
        "Winogrande":76.24,
        "GSM8K":12.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SicariusSicariiStuff\/Tinybra_13B",
        "Average":55.36,
        "ARC":55.72,
        "HellaSwag":80.99,
        "MMLU":54.37,
        "TruthfulQA":49.14,
        "Winogrande":73.8,
        "GSM8K":18.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gaodrew\/gaodrew-gorgonzola-13b",
        "Average":55.35,
        "ARC":53.84,
        "HellaSwag":78.86,
        "MMLU":71.54,
        "TruthfulQA":42.58,
        "Winogrande":75.3,
        "GSM8K":10.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Luban-Platypus2-13B-QLora-0.80-epoch",
        "Average":55.34,
        "ARC":60.24,
        "HellaSwag":82.22,
        "MMLU":58.03,
        "TruthfulQA":55.26,
        "Winogrande":75.37,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/SthenoWriter-L2-13B",
        "Average":55.33,
        "ARC":62.29,
        "HellaSwag":83.28,
        "MMLU":56.14,
        "TruthfulQA":44.72,
        "Winogrande":74.35,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"minlik\/chinese-alpaca-33b-merged",
        "Average":55.33,
        "ARC":59.3,
        "HellaSwag":78.43,
        "MMLU":57.69,
        "TruthfulQA":52.45,
        "Winogrande":76.09,
        "GSM8K":8.04,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":33.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PulsarAI\/2x-LoRA-Assemble-Platypus2-13B",
        "Average":55.33,
        "ARC":60.58,
        "HellaSwag":82.56,
        "MMLU":58.25,
        "TruthfulQA":54.77,
        "Winogrande":74.9,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"codellama\/CodeLlama-34b-hf",
        "Average":55.33,
        "ARC":54.1,
        "HellaSwag":75.82,
        "MMLU":55.02,
        "TruthfulQA":39.11,
        "Winogrande":73.56,
        "GSM8K":34.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":160.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ArianAskari\/SOLID-SFT-DPO-MixQV3-SOLIDRejected-SFTChosen-Zephyr-7b-beta",
        "Average":55.31,
        "ARC":59.3,
        "HellaSwag":81.34,
        "MMLU":60.23,
        "TruthfulQA":49.76,
        "Winogrande":75.53,
        "GSM8K":5.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/llama-2-13b-Guanaco-QLoRA",
        "Average":55.31,
        "ARC":61.09,
        "HellaSwag":82.99,
        "MMLU":55.47,
        "TruthfulQA":44.12,
        "Winogrande":77.19,
        "GSM8K":10.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r128_a256",
        "Average":55.31,
        "ARC":59.73,
        "HellaSwag":82.08,
        "MMLU":54.81,
        "TruthfulQA":37.82,
        "Winogrande":76.32,
        "GSM8K":21.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ResplendentAI\/Obscura_32k_7B",
        "Average":55.3,
        "ARC":55.29,
        "HellaSwag":78.0,
        "MMLU":49.13,
        "TruthfulQA":63.03,
        "Winogrande":69.06,
        "GSM8K":17.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/mistral-se-inst-ppo",
        "Average":55.3,
        "ARC":56.31,
        "HellaSwag":79.49,
        "MMLU":60.91,
        "TruthfulQA":51.34,
        "Winogrande":78.14,
        "GSM8K":5.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xwin-LM\/Xwin-LM-13B-V0.1",
        "Average":55.29,
        "ARC":62.54,
        "HellaSwag":82.8,
        "MMLU":56.53,
        "TruthfulQA":45.96,
        "Winogrande":74.27,
        "GSM8K":9.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-34b-hf",
        "Average":55.28,
        "ARC":54.18,
        "HellaSwag":75.82,
        "MMLU":54.92,
        "TruthfulQA":39.11,
        "Winogrande":73.32,
        "GSM8K":34.34,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":160.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-OpenOrca_20w",
        "Average":55.28,
        "ARC":59.9,
        "HellaSwag":82.51,
        "MMLU":56.3,
        "TruthfulQA":43.14,
        "Winogrande":77.19,
        "GSM8K":12.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-llama2-13b-v11.1-bf16",
        "Average":55.28,
        "ARC":51.79,
        "HellaSwag":76.23,
        "MMLU":56.13,
        "TruthfulQA":49.7,
        "Winogrande":73.48,
        "GSM8K":24.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elinas\/chronos-13b-v2",
        "Average":55.25,
        "ARC":58.7,
        "HellaSwag":82.52,
        "MMLU":53.39,
        "TruthfulQA":50.55,
        "Winogrande":75.06,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/SOLAR-Platypus-10.7B-v2",
        "Average":55.25,
        "ARC":59.39,
        "HellaSwag":83.57,
        "MMLU":59.93,
        "TruthfulQA":43.15,
        "Winogrande":81.45,
        "GSM8K":4.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":10.73,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/CreativityEngine",
        "Average":55.25,
        "ARC":59.3,
        "HellaSwag":82.42,
        "MMLU":53.55,
        "TruthfulQA":52.46,
        "Winogrande":74.19,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beaugogh\/Llama2-13b-sharegpt4",
        "Average":55.25,
        "ARC":61.77,
        "HellaSwag":84.53,
        "MMLU":55.21,
        "TruthfulQA":45.94,
        "Winogrande":75.22,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"teknium\/OpenHermes-13B",
        "Average":55.24,
        "ARC":59.81,
        "HellaSwag":82.24,
        "MMLU":56.35,
        "TruthfulQA":46.01,
        "Winogrande":75.45,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/vicuna-13b-v1.5-PL-lora_unload",
        "Average":55.24,
        "ARC":56.91,
        "HellaSwag":81.22,
        "MMLU":56.06,
        "TruthfulQA":49.76,
        "Winogrande":75.22,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shareAI\/llama2-13b-Chinese-chat",
        "Average":55.22,
        "ARC":60.58,
        "HellaSwag":82.19,
        "MMLU":55.45,
        "TruthfulQA":45.11,
        "Winogrande":76.64,
        "GSM8K":11.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":39.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":55.22,
        "ARC":60.84,
        "HellaSwag":82.56,
        "MMLU":56.42,
        "TruthfulQA":53.32,
        "Winogrande":75.93,
        "GSM8K":2.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/Chronorctypus-Limarobormes-13b",
        "Average":55.22,
        "ARC":59.9,
        "HellaSwag":82.75,
        "MMLU":58.45,
        "TruthfulQA":51.9,
        "Winogrande":74.43,
        "GSM8K":3.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-3.0",
        "Average":55.21,
        "ARC":59.81,
        "HellaSwag":83.71,
        "MMLU":54.86,
        "TruthfulQA":47.79,
        "Winogrande":76.16,
        "GSM8K":8.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Mythical-Destroyer-V2-L2-13B",
        "Average":55.2,
        "ARC":59.3,
        "HellaSwag":82.66,
        "MMLU":57.39,
        "TruthfulQA":57.09,
        "Winogrande":74.74,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/minotaur-13b-fixed",
        "Average":55.19,
        "ARC":59.04,
        "HellaSwag":81.66,
        "MMLU":50.1,
        "TruthfulQA":50.36,
        "Winogrande":76.87,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decem\/Dionysus-Mistral-n1-v1",
        "Average":55.18,
        "ARC":60.24,
        "HellaSwag":81.6,
        "MMLU":59.32,
        "TruthfulQA":47.94,
        "Winogrande":71.35,
        "GSM8K":10.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"IkariDev\/Athnete-13B",
        "Average":55.17,
        "ARC":62.12,
        "HellaSwag":84.36,
        "MMLU":57.58,
        "TruthfulQA":51.05,
        "Winogrande":75.93,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"qblocks\/zephyr_7b_norobots",
        "Average":55.16,
        "ARC":56.48,
        "HellaSwag":79.64,
        "MMLU":55.52,
        "TruthfulQA":44.6,
        "Winogrande":74.11,
        "GSM8K":20.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-7B-Chat",
        "Average":55.15,
        "ARC":55.89,
        "HellaSwag":78.56,
        "MMLU":61.65,
        "TruthfulQA":53.54,
        "Winogrande":67.72,
        "GSM8K":13.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":100.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-LoRa",
        "Average":55.15,
        "ARC":60.75,
        "HellaSwag":82.09,
        "MMLU":58.77,
        "TruthfulQA":45.15,
        "Winogrande":77.03,
        "GSM8K":7.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-c34b-2.2.1",
        "Average":55.15,
        "ARC":54.69,
        "HellaSwag":76.84,
        "MMLU":55.43,
        "TruthfulQA":51.36,
        "Winogrande":72.53,
        "GSM8K":20.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dfurman\/Llama-2-13B-Instruct-v0.2",
        "Average":55.14,
        "ARC":60.58,
        "HellaSwag":81.96,
        "MMLU":55.46,
        "TruthfulQA":45.71,
        "Winogrande":77.82,
        "GSM8K":9.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/WizardLM-1.0-Uncensored-Llama2-13b",
        "Average":55.14,
        "ARC":55.72,
        "HellaSwag":80.34,
        "MMLU":55.4,
        "TruthfulQA":51.44,
        "Winogrande":74.66,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-2-13b-instruct",
        "Average":55.14,
        "ARC":61.18,
        "HellaSwag":83.25,
        "MMLU":55.92,
        "TruthfulQA":51.08,
        "Winogrande":77.35,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/athene-noctua-13b",
        "Average":55.13,
        "ARC":57.17,
        "HellaSwag":81.52,
        "MMLU":55.91,
        "TruthfulQA":47.49,
        "Winogrande":73.4,
        "GSM8K":15.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-7B-Chat",
        "Average":55.13,
        "ARC":55.89,
        "HellaSwag":78.56,
        "MMLU":61.7,
        "TruthfulQA":53.65,
        "Winogrande":67.8,
        "GSM8K":13.19,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.72,
        "Model Sha":100.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CalderaAI\/13B-Legerdemain-L2",
        "Average":55.13,
        "ARC":61.26,
        "HellaSwag":83.26,
        "MMLU":56.0,
        "TruthfulQA":41.99,
        "Winogrande":75.22,
        "GSM8K":13.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-2-13b",
        "Average":55.12,
        "ARC":60.32,
        "HellaSwag":82.37,
        "MMLU":56.02,
        "TruthfulQA":42.22,
        "Winogrande":78.06,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":69.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"totally-not-an-llm\/PuddleJumper-13b",
        "Average":55.11,
        "ARC":58.7,
        "HellaSwag":81.18,
        "MMLU":58.25,
        "TruthfulQA":56.44,
        "Winogrande":72.77,
        "GSM8K":3.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/WizardLM-1.0-Uncensored-Llama2-13b",
        "Average":55.1,
        "ARC":55.8,
        "HellaSwag":80.41,
        "MMLU":55.59,
        "TruthfulQA":51.42,
        "Winogrande":74.11,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lamhieu\/ghost-7b-v0.9.1",
        "Average":55.1,
        "ARC":55.38,
        "HellaSwag":77.03,
        "MMLU":54.78,
        "TruthfulQA":43.96,
        "Winogrande":72.53,
        "GSM8K":26.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/Llama-2-13b-FINETUNE4",
        "Average":55.09,
        "ARC":58.7,
        "HellaSwag":81.93,
        "MMLU":57.21,
        "TruthfulQA":43.26,
        "Winogrande":76.95,
        "GSM8K":12.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/llama2-13b-orca-8k-3319",
        "Average":55.09,
        "ARC":60.75,
        "HellaSwag":81.91,
        "MMLU":57.06,
        "TruthfulQA":42.64,
        "Winogrande":77.19,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":131.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-llama2-dolphin-orca-platypus-13b",
        "Average":55.09,
        "ARC":59.64,
        "HellaSwag":82.65,
        "MMLU":57.9,
        "TruthfulQA":43.44,
        "Winogrande":77.19,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FlagAlpha\/Llama2-Chinese-13b-Chat",
        "Average":55.07,
        "ARC":55.97,
        "HellaSwag":82.05,
        "MMLU":54.74,
        "TruthfulQA":48.9,
        "Winogrande":76.16,
        "GSM8K":12.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":264.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jphme\/Llama-2-13b-chat-german",
        "Average":55.07,
        "ARC":57.85,
        "HellaSwag":81.66,
        "MMLU":54.45,
        "TruthfulQA":46.32,
        "Winogrande":76.48,
        "GSM8K":13.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"royallab\/PsyOrca2-13b-DARE",
        "Average":55.07,
        "ARC":60.58,
        "HellaSwag":83.83,
        "MMLU":55.69,
        "TruthfulQA":53.27,
        "Winogrande":74.9,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-dolphin_20w",
        "Average":55.06,
        "ARC":59.56,
        "HellaSwag":82.55,
        "MMLU":55.89,
        "TruthfulQA":42.67,
        "Winogrande":77.27,
        "GSM8K":12.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Python-Code-33B",
        "Average":55.06,
        "ARC":56.31,
        "HellaSwag":81.01,
        "MMLU":54.22,
        "TruthfulQA":44.39,
        "Winogrande":75.22,
        "GSM8K":19.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":33.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MayaPH\/GodziLLa-30B",
        "Average":55.05,
        "ARC":61.52,
        "HellaSwag":82.13,
        "MMLU":54.21,
        "TruthfulQA":55.91,
        "Winogrande":76.16,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":30.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardLM-13B-V1.1",
        "Average":55.05,
        "ARC":60.24,
        "HellaSwag":81.39,
        "MMLU":50.92,
        "TruthfulQA":54.56,
        "Winogrande":75.06,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":73.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"seb-c\/Psydestroyer-20B",
        "Average":55.04,
        "ARC":60.32,
        "HellaSwag":85.17,
        "MMLU":55.56,
        "TruthfulQA":54.83,
        "Winogrande":74.27,
        "GSM8K":0.08,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":19.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/llama-2-16b-nastychat",
        "Average":55.04,
        "ARC":57.42,
        "HellaSwag":80.59,
        "MMLU":55.99,
        "TruthfulQA":53.45,
        "Winogrande":74.66,
        "GSM8K":8.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":16.19,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r32_a256",
        "Average":55.04,
        "ARC":60.15,
        "HellaSwag":81.98,
        "MMLU":54.99,
        "TruthfulQA":36.75,
        "Winogrande":76.48,
        "GSM8K":19.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"royallab\/PsyOrca2-13b-DARE",
        "Average":55.03,
        "ARC":60.32,
        "HellaSwag":83.85,
        "MMLU":55.62,
        "TruthfulQA":53.33,
        "Winogrande":74.59,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"augmxnt\/shisa-7b-v1",
        "Average":55.01,
        "ARC":56.14,
        "HellaSwag":78.63,
        "MMLU":23.12,
        "TruthfulQA":52.49,
        "Winogrande":78.06,
        "GSM8K":41.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.96,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"duliadotio\/dulia-13b-8k-alpha",
        "Average":55.0,
        "ARC":60.67,
        "HellaSwag":82.0,
        "MMLU":56.87,
        "TruthfulQA":42.59,
        "Winogrande":77.19,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Aspik101\/Redmond-Puffin-13B-instruct-PL-lora_unload",
        "Average":55.0,
        "ARC":60.92,
        "HellaSwag":82.43,
        "MMLU":55.61,
        "TruthfulQA":44.26,
        "Winogrande":75.69,
        "GSM8K":11.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v3.2_super",
        "Average":54.99,
        "ARC":59.81,
        "HellaSwag":82.5,
        "MMLU":55.9,
        "TruthfulQA":42.3,
        "Winogrande":75.93,
        "GSM8K":13.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziqingyang\/chinese-alpaca-2-13b",
        "Average":54.99,
        "ARC":58.7,
        "HellaSwag":79.74,
        "MMLU":55.1,
        "TruthfulQA":50.22,
        "Winogrande":75.69,
        "GSM8K":10.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"prithivida\/Asimov-7B-v1",
        "Average":54.98,
        "ARC":59.04,
        "HellaSwag":80.04,
        "MMLU":56.35,
        "TruthfulQA":51.15,
        "Winogrande":73.95,
        "GSM8K":9.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e6",
        "Average":54.98,
        "ARC":58.87,
        "HellaSwag":81.9,
        "MMLU":55.03,
        "TruthfulQA":36.03,
        "Winogrande":76.72,
        "GSM8K":21.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-13b-v1.5-16k",
        "Average":54.97,
        "ARC":56.74,
        "HellaSwag":80.37,
        "MMLU":55.28,
        "TruthfulQA":51.96,
        "Winogrande":72.38,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":218.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LLMs\/WizardLM-13B-V1.0",
        "Average":54.97,
        "ARC":57.25,
        "HellaSwag":80.88,
        "MMLU":52.92,
        "TruthfulQA":50.55,
        "Winogrande":74.11,
        "GSM8K":14.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Medusa-7B-bf16",
        "Average":54.96,
        "ARC":60.58,
        "HellaSwag":79.98,
        "MMLU":57.71,
        "TruthfulQA":55.74,
        "Winogrande":73.95,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Hippolyta-7B-bf16",
        "Average":54.96,
        "ARC":60.58,
        "HellaSwag":79.98,
        "MMLU":57.71,
        "TruthfulQA":55.74,
        "Winogrande":73.95,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mistralai\/Mistral-7B-Instruct-v0.1",
        "Average":54.96,
        "ARC":54.52,
        "HellaSwag":75.63,
        "MMLU":55.38,
        "TruthfulQA":56.28,
        "Winogrande":73.72,
        "GSM8K":14.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1382.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maldv\/electric-sheep-7b-alpha",
        "Average":54.94,
        "ARC":54.86,
        "HellaSwag":76.43,
        "MMLU":50.45,
        "TruthfulQA":48.26,
        "Winogrande":70.32,
        "GSM8K":29.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WebraftAI\/synapsellm-7b-mistral-v0.4-preview3",
        "Average":54.94,
        "ARC":51.28,
        "HellaSwag":74.83,
        "MMLU":52.93,
        "TruthfulQA":52.35,
        "Winogrande":73.48,
        "GSM8K":24.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"FPHam\/Sydney_Overthinker_13b_HF",
        "Average":54.94,
        "ARC":58.96,
        "HellaSwag":80.85,
        "MMLU":51.28,
        "TruthfulQA":45.7,
        "Winogrande":73.95,
        "GSM8K":18.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Llama-2-13b-chat-hf-gpt-4-80k-base_lora",
        "Average":54.93,
        "ARC":55.38,
        "HellaSwag":75.69,
        "MMLU":53.99,
        "TruthfulQA":50.93,
        "Winogrande":69.85,
        "GSM8K":23.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/wizardLM-13B-1.0-fp16",
        "Average":54.93,
        "ARC":57.25,
        "HellaSwag":80.88,
        "MMLU":52.9,
        "TruthfulQA":50.55,
        "Winogrande":74.11,
        "GSM8K":13.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/Yi-6B-200K-AEZAKMI-v2",
        "Average":54.93,
        "ARC":52.99,
        "HellaSwag":71.2,
        "MMLU":63.0,
        "TruthfulQA":46.79,
        "Winogrande":70.48,
        "GSM8K":25.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"adamo1139\/Mistral-7B-AEZAKMI-v1",
        "Average":54.92,
        "ARC":58.87,
        "HellaSwag":82.01,
        "MMLU":58.72,
        "TruthfulQA":53.54,
        "Winogrande":75.69,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"digitous\/13B-Chimera",
        "Average":54.92,
        "ARC":57.59,
        "HellaSwag":81.5,
        "MMLU":49.86,
        "TruthfulQA":52.59,
        "Winogrande":77.27,
        "GSM8K":10.69,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"meta-llama\/Llama-2-13b-chat-hf",
        "Average":54.91,
        "ARC":59.04,
        "HellaSwag":81.94,
        "MMLU":54.64,
        "TruthfulQA":44.12,
        "Winogrande":74.51,
        "GSM8K":15.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":921.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepse\/CodeUp-Llama-2-13b-chat-hf",
        "Average":54.91,
        "ARC":59.04,
        "HellaSwag":81.93,
        "MMLU":54.63,
        "TruthfulQA":44.12,
        "Winogrande":74.51,
        "GSM8K":15.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail++",
        "Available on the Hub":13.0,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NewstaR\/Morningstar-13b-hf",
        "Average":54.91,
        "ARC":59.04,
        "HellaSwag":81.93,
        "MMLU":54.63,
        "TruthfulQA":44.12,
        "Winogrande":74.51,
        "GSM8K":15.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Qwen1.5-7B-Dutch-Chat-Sft-Bf16",
        "Average":54.91,
        "ARC":54.27,
        "HellaSwag":75.53,
        "MMLU":61.98,
        "TruthfulQA":47.26,
        "Winogrande":68.67,
        "GSM8K":21.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.72,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Kimiko-v2-13B-fp16",
        "Average":54.91,
        "ARC":61.01,
        "HellaSwag":83.32,
        "MMLU":55.17,
        "TruthfulQA":40.65,
        "Winogrande":76.8,
        "GSM8K":12.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"The-Face-Of-Goonery\/Huginn-13b-FP16",
        "Average":54.89,
        "ARC":60.58,
        "HellaSwag":82.53,
        "MMLU":53.71,
        "TruthfulQA":54.46,
        "Winogrande":73.72,
        "GSM8K":4.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Platypus2-13B",
        "Average":54.89,
        "ARC":61.26,
        "HellaSwag":82.56,
        "MMLU":56.7,
        "TruthfulQA":44.86,
        "Winogrande":76.87,
        "GSM8K":7.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":13.02,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
        "Average":54.88,
        "ARC":58.53,
        "HellaSwag":82.27,
        "MMLU":55.9,
        "TruthfulQA":40.26,
        "Winogrande":76.95,
        "GSM8K":15.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/LewdEngine",
        "Average":54.88,
        "ARC":60.49,
        "HellaSwag":83.08,
        "MMLU":54.84,
        "TruthfulQA":43.63,
        "Winogrande":74.9,
        "GSM8K":12.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aboros98\/lilo2",
        "Average":54.87,
        "ARC":51.88,
        "HellaSwag":72.2,
        "MMLU":46.15,
        "TruthfulQA":47.02,
        "Winogrande":66.06,
        "GSM8K":45.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikael110\/llama-2-13b-guanaco-fp16",
        "Average":54.86,
        "ARC":60.92,
        "HellaSwag":83.18,
        "MMLU":54.58,
        "TruthfulQA":44.0,
        "Winogrande":74.9,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/manticore-13b",
        "Average":54.86,
        "ARC":58.7,
        "HellaSwag":81.63,
        "MMLU":50.84,
        "TruthfulQA":49.17,
        "Winogrande":76.64,
        "GSM8K":12.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":115.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Redmond-Puffin-13B",
        "Average":54.86,
        "ARC":60.41,
        "HellaSwag":83.2,
        "MMLU":55.36,
        "TruthfulQA":42.12,
        "Winogrande":76.64,
        "GSM8K":11.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.0,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
        "Average":54.86,
        "ARC":59.81,
        "HellaSwag":82.69,
        "MMLU":56.96,
        "TruthfulQA":52.92,
        "Winogrande":74.43,
        "GSM8K":2.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CausalLM\/7B",
        "Average":54.86,
        "ARC":50.0,
        "HellaSwag":74.58,
        "MMLU":61.79,
        "TruthfulQA":50.13,
        "Winogrande":69.69,
        "GSM8K":22.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"wtfpl",
        "Available on the Hub":7.0,
        "Model Sha":128.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r8_a256",
        "Average":54.85,
        "ARC":59.81,
        "HellaSwag":81.79,
        "MMLU":53.22,
        "TruthfulQA":38.04,
        "Winogrande":76.09,
        "GSM8K":20.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JunchengXie\/Mistral-7B-Instruct-v0.1-gpt-4-80k-base_lora",
        "Average":54.84,
        "ARC":53.67,
        "HellaSwag":73.58,
        "MMLU":54.89,
        "TruthfulQA":56.81,
        "Winogrande":72.38,
        "GSM8K":17.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sail\/Sailor-7B-Chat",
        "Average":54.81,
        "ARC":52.3,
        "HellaSwag":75.01,
        "MMLU":56.24,
        "TruthfulQA":44.09,
        "Winogrande":70.8,
        "GSM8K":30.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Code-13B",
        "Average":54.81,
        "ARC":57.34,
        "HellaSwag":83.28,
        "MMLU":53.17,
        "TruthfulQA":42.46,
        "Winogrande":73.56,
        "GSM8K":19.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/Samantha-1.11-CodeLlama-34b",
        "Average":54.8,
        "ARC":56.57,
        "HellaSwag":75.47,
        "MMLU":53.51,
        "TruthfulQA":50.46,
        "Winogrande":73.48,
        "GSM8K":19.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":33.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/llama-13b-FINETUNE3",
        "Average":54.79,
        "ARC":59.3,
        "HellaSwag":81.53,
        "MMLU":57.46,
        "TruthfulQA":41.63,
        "Winogrande":76.72,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Ensemble5-Platypus2-13B-QLora-0.80-epoch",
        "Average":54.76,
        "ARC":59.73,
        "HellaSwag":82.66,
        "MMLU":56.94,
        "TruthfulQA":52.92,
        "Winogrande":74.43,
        "GSM8K":1.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardLM-13B-V1.2",
        "Average":54.76,
        "ARC":59.04,
        "HellaSwag":82.21,
        "MMLU":54.64,
        "TruthfulQA":47.27,
        "Winogrande":71.9,
        "GSM8K":13.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":214.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Redmond-Puffin-13B",
        "Average":54.74,
        "ARC":60.49,
        "HellaSwag":83.21,
        "MMLU":54.95,
        "TruthfulQA":42.08,
        "Winogrande":76.48,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":13.0,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"The-Face-Of-Goonery\/Chronos-Beluga-v2-13bfp16",
        "Average":54.74,
        "ARC":60.75,
        "HellaSwag":81.94,
        "MMLU":54.08,
        "TruthfulQA":53.23,
        "Winogrande":73.8,
        "GSM8K":4.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/TekniumAiroboros-Nebula-7B",
        "Average":54.74,
        "ARC":57.17,
        "HellaSwag":81.72,
        "MMLU":55.25,
        "TruthfulQA":51.64,
        "Winogrande":73.24,
        "GSM8K":9.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":54.74,
        "ARC":60.32,
        "HellaSwag":83.72,
        "MMLU":55.74,
        "TruthfulQA":52.18,
        "Winogrande":75.53,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CalderaAI\/13B-Thorns-l2",
        "Average":54.72,
        "ARC":62.88,
        "HellaSwag":83.57,
        "MMLU":56.95,
        "TruthfulQA":49.52,
        "Winogrande":74.51,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Medusa-13b",
        "Average":54.72,
        "ARC":58.19,
        "HellaSwag":81.35,
        "MMLU":57.39,
        "TruthfulQA":51.24,
        "Winogrande":73.32,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-13b-instruct",
        "Average":54.72,
        "ARC":58.36,
        "HellaSwag":82.2,
        "MMLU":55.65,
        "TruthfulQA":42.4,
        "Winogrande":75.22,
        "GSM8K":14.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/Giraffe-beta-13b-32k",
        "Average":54.69,
        "ARC":55.63,
        "HellaSwag":80.42,
        "MMLU":53.61,
        "TruthfulQA":42.58,
        "Winogrande":74.59,
        "GSM8K":21.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/LLaMA2-13B-Psyfighter2",
        "Average":54.66,
        "ARC":60.07,
        "HellaSwag":84.02,
        "MMLU":55.07,
        "TruthfulQA":53.0,
        "Winogrande":74.35,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"arlineka\/Brunhilde-13b-v3",
        "Average":54.65,
        "ARC":60.15,
        "HellaSwag":84.02,
        "MMLU":55.03,
        "TruthfulQA":52.99,
        "Winogrande":74.27,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-34b-v1.9",
        "Average":54.64,
        "ARC":54.27,
        "HellaSwag":75.2,
        "MMLU":56.12,
        "TruthfulQA":43.92,
        "Winogrande":73.56,
        "GSM8K":24.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
        "Average":54.64,
        "ARC":57.25,
        "HellaSwag":81.73,
        "MMLU":55.72,
        "TruthfulQA":41.53,
        "Winogrande":77.58,
        "GSM8K":14.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Secbone\/llama-2-13B-instructed",
        "Average":54.63,
        "ARC":59.39,
        "HellaSwag":83.88,
        "MMLU":55.57,
        "TruthfulQA":46.89,
        "Winogrande":74.03,
        "GSM8K":8.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
        "Average":54.63,
        "ARC":58.7,
        "HellaSwag":81.66,
        "MMLU":53.87,
        "TruthfulQA":43.02,
        "Winogrande":76.72,
        "GSM8K":13.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pansophic\/new_model_test",
        "Average":54.63,
        "ARC":52.56,
        "HellaSwag":73.65,
        "MMLU":46.02,
        "TruthfulQA":51.25,
        "Winogrande":66.38,
        "GSM8K":37.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"aihub-app\/ZySec-8B-v2",
        "Average":54.63,
        "ARC":53.07,
        "HellaSwag":76.3,
        "MMLU":54.55,
        "TruthfulQA":47.05,
        "Winogrande":68.75,
        "GSM8K":28.05,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ZySec-AI\/ZySec-7B-v2",
        "Average":54.63,
        "ARC":53.07,
        "HellaSwag":76.3,
        "MMLU":54.55,
        "TruthfulQA":47.05,
        "Winogrande":68.75,
        "GSM8K":28.05,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/UltraLM-13B-fp16",
        "Average":54.62,
        "ARC":57.59,
        "HellaSwag":80.2,
        "MMLU":51.85,
        "TruthfulQA":51.56,
        "Winogrande":75.85,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Chat-Stheno-L2-13B",
        "Average":54.61,
        "ARC":58.45,
        "HellaSwag":80.96,
        "MMLU":54.8,
        "TruthfulQA":43.31,
        "Winogrande":75.37,
        "GSM8K":14.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
        "Average":54.61,
        "ARC":60.41,
        "HellaSwag":82.58,
        "MMLU":55.86,
        "TruthfulQA":43.61,
        "Winogrande":76.72,
        "GSM8K":8.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":54.6,
        "ARC":59.9,
        "HellaSwag":83.29,
        "MMLU":56.69,
        "TruthfulQA":51.08,
        "Winogrande":75.22,
        "GSM8K":1.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-qwen1.5-14b-v20.1-32k",
        "Average":54.59,
        "ARC":56.91,
        "HellaSwag":74.57,
        "MMLU":66.72,
        "TruthfulQA":54.28,
        "Winogrande":75.06,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Samantha-Nebula-7B",
        "Average":54.58,
        "ARC":57.0,
        "HellaSwag":82.25,
        "MMLU":54.21,
        "TruthfulQA":49.58,
        "Winogrande":73.09,
        "GSM8K":11.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BAAI\/Aquila2-34B",
        "Average":54.57,
        "ARC":52.47,
        "HellaSwag":81.9,
        "MMLU":76.03,
        "TruthfulQA":40.85,
        "Winogrande":75.53,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ankhamun\/xxxI-Ixxx",
        "Average":54.56,
        "ARC":54.18,
        "HellaSwag":72.55,
        "MMLU":52.02,
        "TruthfulQA":54.42,
        "Winogrande":70.24,
        "GSM8K":23.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gaodrew\/OpenOrca-Platypus2-13B-thera-1250",
        "Average":54.56,
        "ARC":59.22,
        "HellaSwag":81.02,
        "MMLU":57.04,
        "TruthfulQA":48.43,
        "Winogrande":73.09,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/Orca-2-7b",
        "Average":54.55,
        "ARC":54.1,
        "HellaSwag":76.19,
        "MMLU":56.37,
        "TruthfulQA":52.45,
        "Winogrande":73.48,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":200.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KoboldAI\/LLaMA2-13B-Holomax",
        "Average":54.52,
        "ARC":60.49,
        "HellaSwag":82.86,
        "MMLU":54.67,
        "TruthfulQA":42.97,
        "Winogrande":74.66,
        "GSM8K":11.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-all-hal-13b-ep3",
        "Average":54.51,
        "ARC":48.63,
        "HellaSwag":80.28,
        "MMLU":56.4,
        "TruthfulQA":42.75,
        "Winogrande":73.16,
        "GSM8K":25.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/LLaMA2-13B-Tiefighter",
        "Average":54.51,
        "ARC":59.9,
        "HellaSwag":84.0,
        "MMLU":54.98,
        "TruthfulQA":53.02,
        "Winogrande":74.51,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":66.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chansung\/gpt4-alpaca-lora-13b-decapoda-1024",
        "Average":54.51,
        "ARC":59.39,
        "HellaSwag":81.87,
        "MMLU":47.75,
        "TruthfulQA":52.59,
        "Winogrande":77.35,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/Mistral-7B-length-100000",
        "Average":54.5,
        "ARC":51.71,
        "HellaSwag":78.32,
        "MMLU":55.75,
        "TruthfulQA":44.95,
        "Winogrande":76.72,
        "GSM8K":19.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
        "Average":54.5,
        "ARC":59.22,
        "HellaSwag":81.52,
        "MMLU":54.94,
        "TruthfulQA":42.83,
        "Winogrande":76.87,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BAAI\/Aquila2-34B",
        "Average":54.5,
        "ARC":52.65,
        "HellaSwag":81.99,
        "MMLU":76.02,
        "TruthfulQA":40.8,
        "Winogrande":75.06,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2-13B-LoRa",
        "Average":54.48,
        "ARC":60.67,
        "HellaSwag":82.5,
        "MMLU":56.34,
        "TruthfulQA":43.91,
        "Winogrande":75.93,
        "GSM8K":7.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"hywu\/Camelidae-8x7B",
        "Average":54.47,
        "ARC":55.63,
        "HellaSwag":79.18,
        "MMLU":50.1,
        "TruthfulQA":42.86,
        "Winogrande":76.24,
        "GSM8K":22.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Limarp-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":54.46,
        "ARC":60.49,
        "HellaSwag":82.76,
        "MMLU":56.52,
        "TruthfulQA":44.14,
        "Winogrande":76.8,
        "GSM8K":6.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/Llama-2-13b-FINETUNE4_TEST2",
        "Average":54.46,
        "ARC":58.45,
        "HellaSwag":81.7,
        "MMLU":56.61,
        "TruthfulQA":40.19,
        "Winogrande":76.64,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KeyonZeng\/lion-gemma-2b",
        "Average":54.46,
        "ARC":51.11,
        "HellaSwag":73.47,
        "MMLU":57.15,
        "TruthfulQA":47.92,
        "Winogrande":70.8,
        "GSM8K":26.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Radu1999\/Mister",
        "Average":54.46,
        "ARC":61.69,
        "HellaSwag":71.74,
        "MMLU":43.53,
        "TruthfulQA":65.85,
        "Winogrande":75.22,
        "GSM8K":8.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CallComply\/zephyr-7b-beta-128k",
        "Average":54.45,
        "ARC":58.28,
        "HellaSwag":81.0,
        "MMLU":53.57,
        "TruthfulQA":46.1,
        "Winogrande":74.74,
        "GSM8K":13.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bhenrym14\/airophin-13b-pntk-16k-fp16",
        "Average":54.44,
        "ARC":61.18,
        "HellaSwag":82.86,
        "MMLU":55.19,
        "TruthfulQA":43.2,
        "Winogrande":76.16,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Qwen1.5-7B-Dutch-Chat-Sft",
        "Average":54.44,
        "ARC":50.68,
        "HellaSwag":73.49,
        "MMLU":60.47,
        "TruthfulQA":43.89,
        "Winogrande":68.75,
        "GSM8K":29.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Medorca-2x7b",
        "Average":54.43,
        "ARC":54.1,
        "HellaSwag":76.04,
        "MMLU":53.3,
        "TruthfulQA":48.04,
        "Winogrande":74.51,
        "GSM8K":20.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.07,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/MT7Bi-alpha-dpo-v0.2",
        "Average":54.4,
        "ARC":54.69,
        "HellaSwag":75.89,
        "MMLU":52.82,
        "TruthfulQA":45.48,
        "Winogrande":71.59,
        "GSM8K":25.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NekoPunchBBB\/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
        "Average":54.4,
        "ARC":57.51,
        "HellaSwag":82.49,
        "MMLU":54.83,
        "TruthfulQA":43.81,
        "Winogrande":77.27,
        "GSM8K":10.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KeyonZeng\/lion-gemma-7b-cn-v2",
        "Average":54.39,
        "ARC":51.79,
        "HellaSwag":73.86,
        "MMLU":55.2,
        "TruthfulQA":47.99,
        "Winogrande":68.75,
        "GSM8K":28.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE1_17w-r16",
        "Average":54.37,
        "ARC":57.25,
        "HellaSwag":82.27,
        "MMLU":56.16,
        "TruthfulQA":39.75,
        "Winogrande":77.43,
        "GSM8K":13.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
        "Average":54.35,
        "ARC":59.73,
        "HellaSwag":81.06,
        "MMLU":54.53,
        "TruthfulQA":38.64,
        "Winogrande":78.14,
        "GSM8K":14.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xriminact\/TarsDolly",
        "Average":54.35,
        "ARC":59.3,
        "HellaSwag":81.85,
        "MMLU":56.26,
        "TruthfulQA":42.29,
        "Winogrande":76.24,
        "GSM8K":10.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xwin-LM\/XwinCoder-34B",
        "Average":54.35,
        "ARC":51.02,
        "HellaSwag":74.02,
        "MMLU":49.53,
        "TruthfulQA":43.82,
        "Winogrande":68.35,
        "GSM8K":39.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":24.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/orca_mini_v3_7B-GPTQ",
        "Average":54.35,
        "ARC":54.52,
        "HellaSwag":78.53,
        "MMLU":51.85,
        "TruthfulQA":51.2,
        "Winogrande":74.66,
        "GSM8K":15.31,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":9.05,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/Llama-2-13b-hf-instruct-pl-lora_unload",
        "Average":54.34,
        "ARC":59.47,
        "HellaSwag":82.16,
        "MMLU":54.83,
        "TruthfulQA":41.45,
        "Winogrande":76.24,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-13b-instruct",
        "Average":54.34,
        "ARC":57.94,
        "HellaSwag":81.32,
        "MMLU":47.62,
        "TruthfulQA":50.23,
        "Winogrande":77.11,
        "GSM8K":11.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":13.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"1TuanPham\/T-Llama",
        "Average":54.34,
        "ARC":54.18,
        "HellaSwag":76.48,
        "MMLU":47.98,
        "TruthfulQA":46.47,
        "Winogrande":71.27,
        "GSM8K":29.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.85,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"anhnv125\/llama-op-v4",
        "Average":54.34,
        "ARC":61.52,
        "HellaSwag":79.21,
        "MMLU":57.01,
        "TruthfulQA":42.72,
        "Winogrande":75.93,
        "GSM8K":9.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
        "Average":54.32,
        "ARC":58.7,
        "HellaSwag":81.89,
        "MMLU":56.08,
        "TruthfulQA":38.95,
        "Winogrande":77.35,
        "GSM8K":12.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"garage-bAInd\/Camel-Platypus2-13B",
        "Average":54.32,
        "ARC":60.75,
        "HellaSwag":83.61,
        "MMLU":56.51,
        "TruthfulQA":49.6,
        "Winogrande":75.37,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-Open-Platypus_2.5w",
        "Average":54.32,
        "ARC":59.56,
        "HellaSwag":82.46,
        "MMLU":56.06,
        "TruthfulQA":42.45,
        "Winogrande":76.8,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"StudentLLM\/Alpagasus-2-13b-QLoRA-merged",
        "Average":54.31,
        "ARC":61.09,
        "HellaSwag":82.46,
        "MMLU":55.27,
        "TruthfulQA":38.53,
        "Winogrande":77.35,
        "GSM8K":11.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/bigyi-15b",
        "Average":54.29,
        "ARC":56.06,
        "HellaSwag":75.9,
        "MMLU":64.6,
        "TruthfulQA":37.33,
        "Winogrande":70.24,
        "GSM8K":21.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":15.06,
        "Model Sha":10.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/WizardLM-13B-V1.1-GPTQ",
        "Average":54.28,
        "ARC":58.53,
        "HellaSwag":80.66,
        "MMLU":49.59,
        "TruthfulQA":54.35,
        "Winogrande":74.43,
        "GSM8K":8.11,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/wizard-mega-13b",
        "Average":54.27,
        "ARC":57.34,
        "HellaSwag":81.09,
        "MMLU":50.59,
        "TruthfulQA":50.22,
        "Winogrande":76.32,
        "GSM8K":10.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":105.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-13b-v1.3",
        "Average":54.27,
        "ARC":54.61,
        "HellaSwag":80.41,
        "MMLU":52.88,
        "TruthfulQA":52.14,
        "Winogrande":74.82,
        "GSM8K":10.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":188.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mwitiderrick\/SwahiliInstruct-v0.2",
        "Average":54.25,
        "ARC":55.2,
        "HellaSwag":78.22,
        "MMLU":50.3,
        "TruthfulQA":57.08,
        "Winogrande":73.24,
        "GSM8K":11.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"layoric\/llama-2-13b-code-alpaca",
        "Average":54.25,
        "ARC":60.84,
        "HellaSwag":82.14,
        "MMLU":55.93,
        "TruthfulQA":38.27,
        "Winogrande":76.4,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.85,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/13B-HyperMantis",
        "Average":54.25,
        "ARC":58.53,
        "HellaSwag":82.2,
        "MMLU":50.61,
        "TruthfulQA":47.5,
        "Winogrande":76.24,
        "GSM8K":10.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"sethuiyer\/OpenDolphinHermes_Llama2_7B",
        "Average":54.24,
        "ARC":55.03,
        "HellaSwag":78.74,
        "MMLU":52.25,
        "TruthfulQA":46.1,
        "Winogrande":73.16,
        "GSM8K":20.17,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"totally-not-an-llm\/EverythingLM-13b-V3-peft",
        "Average":54.24,
        "ARC":58.36,
        "HellaSwag":81.03,
        "MMLU":54.7,
        "TruthfulQA":52.98,
        "Winogrande":72.85,
        "GSM8K":5.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":12.85,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2-13B-IA3",
        "Average":54.23,
        "ARC":61.09,
        "HellaSwag":82.65,
        "MMLU":56.32,
        "TruthfulQA":38.35,
        "Winogrande":75.69,
        "GSM8K":11.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gmonsoon\/Delta-4B-notso-base",
        "Average":54.23,
        "ARC":57.59,
        "HellaSwag":76.1,
        "MMLU":57.26,
        "TruthfulQA":54.31,
        "Winogrande":76.09,
        "GSM8K":4.02,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/llama-2-13b-hf-platypus",
        "Average":54.22,
        "ARC":58.87,
        "HellaSwag":82.14,
        "MMLU":54.98,
        "TruthfulQA":42.84,
        "Winogrande":77.11,
        "GSM8K":9.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NekoPunchBBB\/Llama-2-13b-hf_Open-Platypus",
        "Average":54.22,
        "ARC":58.87,
        "HellaSwag":82.14,
        "MMLU":54.98,
        "TruthfulQA":42.84,
        "Winogrande":77.11,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FPHam\/Free_Sydney_13b_HF",
        "Average":54.22,
        "ARC":59.39,
        "HellaSwag":81.4,
        "MMLU":53.73,
        "TruthfulQA":45.63,
        "Winogrande":76.01,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"budecosystem\/genz-13b-v2",
        "Average":54.2,
        "ARC":55.97,
        "HellaSwag":79.98,
        "MMLU":54.3,
        "TruthfulQA":48.09,
        "Winogrande":74.59,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"StudentLLM\/Alpagasus-2-13b-QLoRA-merged",
        "Average":54.2,
        "ARC":60.84,
        "HellaSwag":82.43,
        "MMLU":55.55,
        "TruthfulQA":38.65,
        "Winogrande":76.87,
        "GSM8K":10.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/llama2-13b-math1.2",
        "Average":54.19,
        "ARC":56.91,
        "HellaSwag":80.71,
        "MMLU":53.21,
        "TruthfulQA":48.25,
        "Winogrande":74.74,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"totally-not-an-llm\/PuddleJumper-13b-V2",
        "Average":54.19,
        "ARC":57.0,
        "HellaSwag":81.06,
        "MMLU":58.3,
        "TruthfulQA":52.66,
        "Winogrande":72.45,
        "GSM8K":3.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/llama2-13b-math1.1",
        "Average":54.18,
        "ARC":57.25,
        "HellaSwag":80.74,
        "MMLU":53.56,
        "TruthfulQA":48.43,
        "Winogrande":74.43,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE1_17w-r4",
        "Average":54.18,
        "ARC":56.74,
        "HellaSwag":82.27,
        "MMLU":56.18,
        "TruthfulQA":39.65,
        "Winogrande":77.03,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
        "Average":54.16,
        "ARC":59.13,
        "HellaSwag":82.13,
        "MMLU":54.98,
        "TruthfulQA":44.23,
        "Winogrande":76.4,
        "GSM8K":8.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Metharme-13b-Merged",
        "Average":54.15,
        "ARC":59.9,
        "HellaSwag":81.12,
        "MMLU":47.18,
        "TruthfulQA":51.18,
        "Winogrande":76.8,
        "GSM8K":8.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/llama2-13b-math1.1",
        "Average":54.14,
        "ARC":56.83,
        "HellaSwag":80.69,
        "MMLU":53.43,
        "TruthfulQA":48.48,
        "Winogrande":74.74,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/Wizard-Vicuna-13B-Uncensored",
        "Average":54.14,
        "ARC":58.96,
        "HellaSwag":81.95,
        "MMLU":47.92,
        "TruthfulQA":51.69,
        "Winogrande":75.69,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Wizard-Vicuna-13B-Uncensored-HF",
        "Average":54.14,
        "ARC":58.96,
        "HellaSwag":81.95,
        "MMLU":47.92,
        "TruthfulQA":51.69,
        "Winogrande":75.69,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":204.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
        "Average":54.14,
        "ARC":59.98,
        "HellaSwag":82.43,
        "MMLU":55.41,
        "TruthfulQA":39.9,
        "Winogrande":76.56,
        "GSM8K":10.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xriminact\/TarsChattyBasev0.1",
        "Average":54.14,
        "ARC":59.98,
        "HellaSwag":82.41,
        "MMLU":55.75,
        "TruthfulQA":41.41,
        "Winogrande":75.85,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-orca-platypus-coig-lite-4k-0.5e-13b",
        "Average":54.13,
        "ARC":58.02,
        "HellaSwag":80.15,
        "MMLU":57.26,
        "TruthfulQA":48.04,
        "Winogrande":75.45,
        "GSM8K":5.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/manticore-13b-chat-pyg",
        "Average":54.13,
        "ARC":58.53,
        "HellaSwag":81.96,
        "MMLU":48.76,
        "TruthfulQA":48.76,
        "Winogrande":77.19,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CalderaAI\/13B-BlueMethod",
        "Average":54.12,
        "ARC":59.64,
        "HellaSwag":82.07,
        "MMLU":50.34,
        "TruthfulQA":47.74,
        "Winogrande":77.11,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"hfl\/chinese-alpaca-2-13b-16k",
        "Average":54.12,
        "ARC":55.03,
        "HellaSwag":77.41,
        "MMLU":51.28,
        "TruthfulQA":46.5,
        "Winogrande":73.4,
        "GSM8K":21.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
        "Average":54.12,
        "ARC":57.17,
        "HellaSwag":82.26,
        "MMLU":55.89,
        "TruthfulQA":39.93,
        "Winogrande":76.56,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/autotrain-ixpiv-6kj1e",
        "Average":54.11,
        "ARC":61.69,
        "HellaSwag":82.54,
        "MMLU":58.61,
        "TruthfulQA":45.72,
        "Winogrande":76.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IkariDev\/Athena-v1",
        "Average":54.11,
        "ARC":60.07,
        "HellaSwag":82.64,
        "MMLU":55.61,
        "TruthfulQA":46.58,
        "Winogrande":74.82,
        "GSM8K":4.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chickencaesar\/llama2-platypus-llama2-chat-13B-hf",
        "Average":54.11,
        "ARC":62.97,
        "HellaSwag":82.75,
        "MMLU":56.86,
        "TruthfulQA":42.93,
        "Winogrande":76.32,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/Guanaco-13B-Uncensored",
        "Average":54.1,
        "ARC":59.56,
        "HellaSwag":82.7,
        "MMLU":53.65,
        "TruthfulQA":43.26,
        "Winogrande":76.32,
        "GSM8K":9.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/llama-2-13b-Beluga-QLoRA",
        "Average":54.09,
        "ARC":59.22,
        "HellaSwag":81.92,
        "MMLU":56.67,
        "TruthfulQA":48.23,
        "Winogrande":77.19,
        "GSM8K":1.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B",
        "Average":54.08,
        "ARC":55.55,
        "HellaSwag":76.57,
        "MMLU":64.11,
        "TruthfulQA":41.96,
        "Winogrande":74.19,
        "GSM8K":12.13,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":355.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
        "Average":54.08,
        "ARC":59.3,
        "HellaSwag":81.2,
        "MMLU":55.58,
        "TruthfulQA":38.13,
        "Winogrande":76.8,
        "GSM8K":13.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/StableBeluga1-Delta",
        "Average":54.08,
        "ARC":68.17,
        "HellaSwag":85.88,
        "MMLU":64.83,
        "TruthfulQA":55.81,
        "Winogrande":49.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":65.29,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bhenrym14\/airophin-v2-13b-PI-8k-fp16",
        "Average":54.07,
        "ARC":60.58,
        "HellaSwag":82.96,
        "MMLU":56.75,
        "TruthfulQA":40.14,
        "Winogrande":76.64,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
        "Average":54.06,
        "ARC":57.68,
        "HellaSwag":81.91,
        "MMLU":54.95,
        "TruthfulQA":41.31,
        "Winogrande":76.48,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-L2-13B-PIPPA",
        "Average":54.06,
        "ARC":59.73,
        "HellaSwag":83.12,
        "MMLU":54.1,
        "TruthfulQA":49.94,
        "Winogrande":74.51,
        "GSM8K":2.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/ReMM-L2-13B",
        "Average":54.06,
        "ARC":59.73,
        "HellaSwag":83.1,
        "MMLU":54.11,
        "TruthfulQA":49.94,
        "Winogrande":74.51,
        "GSM8K":2.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/llama2-13b-math1.2",
        "Average":54.05,
        "ARC":57.08,
        "HellaSwag":80.61,
        "MMLU":53.05,
        "TruthfulQA":48.3,
        "Winogrande":74.27,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/Llama-2-13b-FINETUNE4_compare8k2",
        "Average":54.05,
        "ARC":58.28,
        "HellaSwag":81.39,
        "MMLU":56.87,
        "TruthfulQA":39.86,
        "Winogrande":76.01,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/airoboros-13B-HF",
        "Average":54.05,
        "ARC":58.28,
        "HellaSwag":81.05,
        "MMLU":50.03,
        "TruthfulQA":51.57,
        "Winogrande":76.24,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/Mistral-7B-attention-100000",
        "Average":54.05,
        "ARC":52.99,
        "HellaSwag":78.54,
        "MMLU":54.79,
        "TruthfulQA":45.37,
        "Winogrande":75.61,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-13b",
        "Average":54.04,
        "ARC":56.57,
        "HellaSwag":82.11,
        "MMLU":50.44,
        "TruthfulQA":51.5,
        "Winogrande":75.3,
        "GSM8K":8.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl",
        "Available on the Hub":13.0,
        "Model Sha":422.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"msy127\/mnsim-dpo-peftmerged-2-eos",
        "Average":54.04,
        "ARC":55.63,
        "HellaSwag":77.82,
        "MMLU":51.25,
        "TruthfulQA":46.37,
        "Winogrande":76.24,
        "GSM8K":16.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.16,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/Huginn-v3-13b",
        "Average":54.04,
        "ARC":60.67,
        "HellaSwag":82.34,
        "MMLU":52.32,
        "TruthfulQA":50.62,
        "Winogrande":73.64,
        "GSM8K":4.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/Huginn-13b-v4.5",
        "Average":54.04,
        "ARC":60.67,
        "HellaSwag":82.34,
        "MMLU":52.32,
        "TruthfulQA":50.62,
        "Winogrande":73.64,
        "GSM8K":4.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/Huginn-13b-V4",
        "Average":54.04,
        "ARC":60.67,
        "HellaSwag":82.34,
        "MMLU":52.32,
        "TruthfulQA":50.62,
        "Winogrande":73.64,
        "GSM8K":4.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b",
        "Average":54.02,
        "ARC":58.28,
        "HellaSwag":81.05,
        "MMLU":50.03,
        "TruthfulQA":51.57,
        "Winogrande":76.24,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":106.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B",
        "Average":54.02,
        "ARC":55.55,
        "HellaSwag":76.42,
        "MMLU":63.85,
        "TruthfulQA":41.86,
        "Winogrande":73.8,
        "GSM8K":12.66,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":355.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/llama-13b-pretrained",
        "Average":54.02,
        "ARC":56.31,
        "HellaSwag":79.32,
        "MMLU":47.03,
        "TruthfulQA":48.42,
        "Winogrande":76.95,
        "GSM8K":16.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
        "Average":54.02,
        "ARC":57.17,
        "HellaSwag":82.15,
        "MMLU":54.88,
        "TruthfulQA":40.23,
        "Winogrande":76.32,
        "GSM8K":13.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
        "Average":54.01,
        "ARC":57.34,
        "HellaSwag":81.24,
        "MMLU":55.64,
        "TruthfulQA":55.98,
        "Winogrande":73.88,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nvidia\/OpenMath-Mistral-7B-v0.1-hf",
        "Average":54.0,
        "ARC":59.39,
        "HellaSwag":81.78,
        "MMLU":59.34,
        "TruthfulQA":46.13,
        "Winogrande":77.27,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/based-30b",
        "Average":54.0,
        "ARC":63.91,
        "HellaSwag":85.67,
        "MMLU":58.28,
        "TruthfulQA":35.7,
        "Winogrande":80.11,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":32.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-orca-platypus-coig-lite-4k-0.6e-13b",
        "Average":53.99,
        "ARC":58.79,
        "HellaSwag":79.93,
        "MMLU":56.77,
        "TruthfulQA":48.29,
        "Winogrande":75.93,
        "GSM8K":4.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
        "Average":53.99,
        "ARC":56.06,
        "HellaSwag":81.89,
        "MMLU":55.04,
        "TruthfulQA":40.12,
        "Winogrande":76.56,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/gpt4-alpaca-lora-13B-HF",
        "Average":53.98,
        "ARC":59.56,
        "HellaSwag":82.09,
        "MMLU":47.48,
        "TruthfulQA":48.96,
        "Winogrande":76.72,
        "GSM8K":9.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/webMistral-7B",
        "Average":53.97,
        "ARC":59.04,
        "HellaSwag":80.89,
        "MMLU":59.0,
        "TruthfulQA":39.71,
        "Winogrande":76.32,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardMath-13B-V1.0",
        "Average":53.97,
        "ARC":60.07,
        "HellaSwag":82.01,
        "MMLU":54.8,
        "TruthfulQA":42.7,
        "Winogrande":71.9,
        "GSM8K":12.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openaccess-ai-collective\/minotaur-13b",
        "Average":53.97,
        "ARC":56.4,
        "HellaSwag":79.13,
        "MMLU":49.61,
        "TruthfulQA":49.62,
        "Winogrande":76.56,
        "GSM8K":12.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v2_w",
        "Average":53.96,
        "ARC":57.34,
        "HellaSwag":81.23,
        "MMLU":50.17,
        "TruthfulQA":50.7,
        "Winogrande":75.93,
        "GSM8K":8.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_v2",
        "Average":53.96,
        "ARC":57.17,
        "HellaSwag":81.14,
        "MMLU":50.58,
        "TruthfulQA":49.54,
        "Winogrande":76.24,
        "GSM8K":9.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/MT7Bi-alpha-dpo",
        "Average":53.96,
        "ARC":55.03,
        "HellaSwag":75.45,
        "MMLU":52.63,
        "TruthfulQA":43.81,
        "Winogrande":71.03,
        "GSM8K":25.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/Llama-2-13b-FINETUNE4_TEST3",
        "Average":53.95,
        "ARC":59.04,
        "HellaSwag":81.65,
        "MMLU":56.37,
        "TruthfulQA":39.98,
        "Winogrande":75.45,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Weyaxi\/Platypus-Nebula-v2-7B",
        "Average":53.95,
        "ARC":55.38,
        "HellaSwag":83.02,
        "MMLU":56.07,
        "TruthfulQA":46.94,
        "Winogrande":72.22,
        "GSM8K":10.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
        "Average":53.95,
        "ARC":57.42,
        "HellaSwag":82.42,
        "MMLU":55.57,
        "TruthfulQA":39.19,
        "Winogrande":77.03,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
        "Average":53.94,
        "ARC":58.36,
        "HellaSwag":82.33,
        "MMLU":56.14,
        "TruthfulQA":39.51,
        "Winogrande":76.4,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/MedMerge-6-7b-alpha-dpo",
        "Average":53.94,
        "ARC":54.27,
        "HellaSwag":75.6,
        "MMLU":52.65,
        "TruthfulQA":43.94,
        "Winogrande":71.03,
        "GSM8K":26.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Qwen1.5-7B-Dutch-Chat-Dpo",
        "Average":53.94,
        "ARC":50.77,
        "HellaSwag":74.24,
        "MMLU":60.7,
        "TruthfulQA":42.37,
        "Winogrande":68.11,
        "GSM8K":27.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Voicelab\/trurl-2-13b-academic",
        "Average":53.94,
        "ARC":57.94,
        "HellaSwag":79.55,
        "MMLU":55.2,
        "TruthfulQA":43.46,
        "Winogrande":76.56,
        "GSM8K":10.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jingyeom\/KoSoLAR-10.7B-v0.2_1.4_dedup",
        "Average":53.93,
        "ARC":60.07,
        "HellaSwag":82.18,
        "MMLU":61.3,
        "TruthfulQA":45.38,
        "Winogrande":74.66,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Pwen-7B-Chat-20_30",
        "Average":53.93,
        "ARC":51.45,
        "HellaSwag":73.99,
        "MMLU":62.08,
        "TruthfulQA":47.01,
        "Winogrande":68.43,
        "GSM8K":20.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"euclaise\/Ferret-7B",
        "Average":53.93,
        "ARC":62.29,
        "HellaSwag":81.31,
        "MMLU":60.27,
        "TruthfulQA":40.01,
        "Winogrande":77.66,
        "GSM8K":2.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/llama-2-13b-chat-platypus",
        "Average":53.92,
        "ARC":53.84,
        "HellaSwag":80.67,
        "MMLU":54.44,
        "TruthfulQA":46.23,
        "Winogrande":76.01,
        "GSM8K":12.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bhenrym14\/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
        "Average":53.92,
        "ARC":60.58,
        "HellaSwag":82.97,
        "MMLU":52.1,
        "TruthfulQA":46.1,
        "Winogrande":73.64,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":32.53,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_Fintune_1_17w",
        "Average":53.91,
        "ARC":59.47,
        "HellaSwag":81.0,
        "MMLU":54.31,
        "TruthfulQA":38.17,
        "Winogrande":77.27,
        "GSM8K":13.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoBoros-13b",
        "Average":53.9,
        "ARC":58.19,
        "HellaSwag":81.75,
        "MMLU":50.13,
        "TruthfulQA":48.93,
        "Winogrande":75.77,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/MaxiCPM-3x3B-Test",
        "Average":53.9,
        "ARC":45.99,
        "HellaSwag":71.74,
        "MMLU":52.88,
        "TruthfulQA":41.06,
        "Winogrande":66.85,
        "GSM8K":44.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sail\/Sailor-7B",
        "Average":53.88,
        "ARC":49.83,
        "HellaSwag":76.21,
        "MMLU":54.65,
        "TruthfulQA":40.08,
        "Winogrande":69.14,
        "GSM8K":33.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/llama-2-13b-QLoRA",
        "Average":53.87,
        "ARC":58.02,
        "HellaSwag":82.33,
        "MMLU":55.8,
        "TruthfulQA":46.23,
        "Winogrande":77.58,
        "GSM8K":3.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4-1.4-fp16",
        "Average":53.87,
        "ARC":59.64,
        "HellaSwag":83.22,
        "MMLU":47.56,
        "TruthfulQA":48.82,
        "Winogrande":76.24,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4-1.4",
        "Average":53.87,
        "ARC":59.64,
        "HellaSwag":83.22,
        "MMLU":47.56,
        "TruthfulQA":48.82,
        "Winogrande":76.24,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"euclaise\/Ferret-7B",
        "Average":53.87,
        "ARC":62.29,
        "HellaSwag":81.33,
        "MMLU":60.09,
        "TruthfulQA":39.94,
        "Winogrande":77.51,
        "GSM8K":2.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"euclaise\/Ferret_7B",
        "Average":53.87,
        "ARC":62.29,
        "HellaSwag":81.33,
        "MMLU":60.09,
        "TruthfulQA":39.94,
        "Winogrande":77.51,
        "GSM8K":2.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"?",
        "Model":"zyh3826\/llama2-13b-ft-openllm-leaderboard-v1",
        "Average":53.86,
        "ARC":59.64,
        "HellaSwag":83.14,
        "MMLU":60.93,
        "TruthfulQA":40.72,
        "Winogrande":77.35,
        "GSM8K":1.36,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
        "Average":53.86,
        "ARC":55.38,
        "HellaSwag":81.92,
        "MMLU":55.28,
        "TruthfulQA":40.76,
        "Winogrande":76.09,
        "GSM8K":13.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/WizardLM-13B-V1.2-PL-lora_unload",
        "Average":53.86,
        "ARC":58.53,
        "HellaSwag":81.1,
        "MMLU":55.15,
        "TruthfulQA":46.18,
        "Winogrande":71.03,
        "GSM8K":11.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Gryphe\/MythoLogic-13b",
        "Average":53.85,
        "ARC":58.45,
        "HellaSwag":81.56,
        "MMLU":49.36,
        "TruthfulQA":49.47,
        "Winogrande":75.61,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/platypus-2-22b-relora",
        "Average":53.83,
        "ARC":57.68,
        "HellaSwag":82.44,
        "MMLU":55.33,
        "TruthfulQA":43.61,
        "Winogrande":77.35,
        "GSM8K":6.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":21.83,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Envoid\/Libra-19B",
        "Average":53.83,
        "ARC":60.58,
        "HellaSwag":82.04,
        "MMLU":55.57,
        "TruthfulQA":48.41,
        "Winogrande":76.32,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":19.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sail\/Sailor-7B",
        "Average":53.82,
        "ARC":49.83,
        "HellaSwag":76.21,
        "MMLU":54.84,
        "TruthfulQA":40.12,
        "Winogrande":69.38,
        "GSM8K":32.52,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
        "Average":53.8,
        "ARC":58.62,
        "HellaSwag":82.56,
        "MMLU":55.84,
        "TruthfulQA":42.09,
        "Winogrande":76.64,
        "GSM8K":7.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general",
        "Average":53.78,
        "ARC":53.33,
        "HellaSwag":77.41,
        "MMLU":51.04,
        "TruthfulQA":50.33,
        "Winogrande":72.14,
        "GSM8K":18.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Weyaxi\/test-help-steer-filtered-orig",
        "Average":53.77,
        "ARC":57.59,
        "HellaSwag":80.42,
        "MMLU":57.24,
        "TruthfulQA":41.1,
        "Winogrande":76.64,
        "GSM8K":9.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KeyonZeng\/lion-gemma-7b-cn",
        "Average":53.77,
        "ARC":50.6,
        "HellaSwag":73.21,
        "MMLU":55.72,
        "TruthfulQA":46.98,
        "Winogrande":68.11,
        "GSM8K":27.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NekoPunchBBB\/Llama-2-13b-hf_Open-Platypus-8bit-att",
        "Average":53.75,
        "ARC":57.51,
        "HellaSwag":82.14,
        "MMLU":54.56,
        "TruthfulQA":42.21,
        "Winogrande":76.56,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Kimiko-13B-fp16",
        "Average":53.75,
        "ARC":59.22,
        "HellaSwag":82.35,
        "MMLU":55.85,
        "TruthfulQA":39.55,
        "Winogrande":76.72,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NobodyExistsOnTheInternet\/GiftedConvo13bLoraNoEconsE4",
        "Average":53.74,
        "ARC":59.9,
        "HellaSwag":84.11,
        "MMLU":54.67,
        "TruthfulQA":41.94,
        "Winogrande":74.03,
        "GSM8K":7.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
        "Average":53.74,
        "ARC":58.53,
        "HellaSwag":82.47,
        "MMLU":53.9,
        "TruthfulQA":37.92,
        "Winogrande":76.8,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ShadowFall09\/tyc_test1",
        "Average":53.74,
        "ARC":55.46,
        "HellaSwag":79.29,
        "MMLU":46.58,
        "TruthfulQA":52.05,
        "Winogrande":74.43,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ShadowFall09\/FANNO",
        "Average":53.74,
        "ARC":55.46,
        "HellaSwag":79.29,
        "MMLU":46.58,
        "TruthfulQA":52.05,
        "Winogrande":74.43,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2-13B-QLoRa",
        "Average":53.74,
        "ARC":57.51,
        "HellaSwag":82.55,
        "MMLU":57.34,
        "TruthfulQA":43.38,
        "Winogrande":76.64,
        "GSM8K":5.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zarafusionex-1.2-l2-7b",
        "Average":53.73,
        "ARC":56.66,
        "HellaSwag":79.16,
        "MMLU":51.94,
        "TruthfulQA":51.29,
        "Winogrande":74.74,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
        "Average":53.71,
        "ARC":57.25,
        "HellaSwag":81.49,
        "MMLU":55.9,
        "TruthfulQA":39.79,
        "Winogrande":75.77,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
        "Average":53.71,
        "ARC":57.25,
        "HellaSwag":81.79,
        "MMLU":53.96,
        "TruthfulQA":39.66,
        "Winogrande":77.82,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kz919\/mistral-7b-sft-open-orca-flan-50k",
        "Average":53.7,
        "ARC":58.79,
        "HellaSwag":81.92,
        "MMLU":55.72,
        "TruthfulQA":37.49,
        "Winogrande":77.98,
        "GSM8K":10.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/vicuna-13b-v1.3-PL-lora_unload",
        "Average":53.7,
        "ARC":54.86,
        "HellaSwag":80.41,
        "MMLU":52.2,
        "TruthfulQA":49.62,
        "Winogrande":76.09,
        "GSM8K":9.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gaodrew\/gaodrew-gorgonzola-13b",
        "Average":53.7,
        "ARC":50.94,
        "HellaSwag":77.65,
        "MMLU":68.93,
        "TruthfulQA":40.63,
        "Winogrande":75.45,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
        "Average":53.69,
        "ARC":55.72,
        "HellaSwag":81.55,
        "MMLU":53.9,
        "TruthfulQA":41.89,
        "Winogrande":77.19,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-huangyt_FINETUNE2_3w",
        "Average":53.69,
        "ARC":58.62,
        "HellaSwag":82.32,
        "MMLU":54.25,
        "TruthfulQA":38.17,
        "Winogrande":76.8,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mixtral-8x7b-v16.2-32k",
        "Average":53.69,
        "ARC":34.39,
        "HellaSwag":81.72,
        "MMLU":71.33,
        "TruthfulQA":56.65,
        "Winogrande":77.82,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BramVanroy\/Llama-2-13b-chat-dutch",
        "Average":53.69,
        "ARC":59.3,
        "HellaSwag":81.45,
        "MMLU":55.82,
        "TruthfulQA":38.23,
        "Winogrande":76.64,
        "GSM8K":10.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4-1.1",
        "Average":53.68,
        "ARC":59.04,
        "HellaSwag":83.05,
        "MMLU":49.41,
        "TruthfulQA":46.62,
        "Winogrande":75.77,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
        "Average":53.68,
        "ARC":56.23,
        "HellaSwag":81.98,
        "MMLU":55.87,
        "TruthfulQA":39.76,
        "Winogrande":76.72,
        "GSM8K":11.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"shareAI\/bimoGPT-llama2-13b",
        "Average":53.68,
        "ARC":58.79,
        "HellaSwag":82.08,
        "MMLU":55.6,
        "TruthfulQA":37.82,
        "Winogrande":76.48,
        "GSM8K":11.3,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abideen\/gemma-7b-openhermes",
        "Average":53.67,
        "ARC":51.28,
        "HellaSwag":71.93,
        "MMLU":53.56,
        "TruthfulQA":47.18,
        "Winogrande":68.19,
        "GSM8K":29.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":8.54,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TaylorAI\/Flash-Llama-13B",
        "Average":53.67,
        "ARC":59.3,
        "HellaSwag":82.15,
        "MMLU":55.67,
        "TruthfulQA":37.39,
        "Winogrande":76.64,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Average":53.67,
        "ARC":59.3,
        "HellaSwag":82.15,
        "MMLU":55.67,
        "TruthfulQA":37.39,
        "Winogrande":76.64,
        "GSM8K":10.84,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":57.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NewstaR\/Starlight-13B",
        "Average":53.67,
        "ARC":59.3,
        "HellaSwag":82.15,
        "MMLU":55.67,
        "TruthfulQA":37.39,
        "Winogrande":76.64,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"robinsmits\/Qwen1.5-7B-Dutch-Chat",
        "Average":53.66,
        "ARC":53.92,
        "HellaSwag":76.03,
        "MMLU":62.38,
        "TruthfulQA":45.34,
        "Winogrande":68.82,
        "GSM8K":15.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.72,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
        "Average":53.66,
        "ARC":55.8,
        "HellaSwag":82.27,
        "MMLU":55.63,
        "TruthfulQA":38.15,
        "Winogrande":77.43,
        "GSM8K":12.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chargoddard\/llama2-22b-blocktriangular",
        "Average":53.65,
        "ARC":58.28,
        "HellaSwag":82.69,
        "MMLU":54.53,
        "TruthfulQA":39.23,
        "Winogrande":75.93,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":22.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4",
        "Average":53.64,
        "ARC":59.39,
        "HellaSwag":83.29,
        "MMLU":47.89,
        "TruthfulQA":47.65,
        "Winogrande":75.77,
        "GSM8K":7.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":17.0
    },
    {
        "T":"?",
        "Model":"chargoddard\/llama2-22b",
        "Average":53.64,
        "ARC":58.53,
        "HellaSwag":82.55,
        "MMLU":54.68,
        "TruthfulQA":39.84,
        "Winogrande":76.32,
        "GSM8K":9.93,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":22.0,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/platypus2-22b-relora",
        "Average":53.64,
        "ARC":57.51,
        "HellaSwag":82.36,
        "MMLU":54.94,
        "TruthfulQA":43.62,
        "Winogrande":77.11,
        "GSM8K":6.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":21.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NobodyExistsOnTheInternet\/PuffedLIMA13bQLORA",
        "Average":53.63,
        "ARC":59.9,
        "HellaSwag":84.39,
        "MMLU":53.68,
        "TruthfulQA":39.9,
        "Winogrande":75.22,
        "GSM8K":8.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/deacon-13b",
        "Average":53.63,
        "ARC":57.85,
        "HellaSwag":82.63,
        "MMLU":55.25,
        "TruthfulQA":39.33,
        "Winogrande":76.32,
        "GSM8K":10.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
        "Average":53.62,
        "ARC":59.04,
        "HellaSwag":81.15,
        "MMLU":53.0,
        "TruthfulQA":40.16,
        "Winogrande":76.48,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/llama2-13b-FINETUNE3_TEST2",
        "Average":53.62,
        "ARC":54.69,
        "HellaSwag":81.48,
        "MMLU":56.8,
        "TruthfulQA":39.93,
        "Winogrande":76.24,
        "GSM8K":12.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-agents\/tora-13b-v1.0",
        "Average":53.62,
        "ARC":58.96,
        "HellaSwag":82.31,
        "MMLU":54.73,
        "TruthfulQA":40.25,
        "Winogrande":75.61,
        "GSM8K":9.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/MistralInstructLongish",
        "Average":53.62,
        "ARC":60.75,
        "HellaSwag":81.86,
        "MMLU":60.49,
        "TruthfulQA":40.55,
        "Winogrande":76.56,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/internlm2-base-7b-llama",
        "Average":53.62,
        "ARC":54.35,
        "HellaSwag":79.47,
        "MMLU":54.05,
        "TruthfulQA":43.23,
        "Winogrande":71.43,
        "GSM8K":19.18,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NobodyExistsOnTheInternet\/PuffedConvo13bLoraE4",
        "Average":53.62,
        "ARC":59.81,
        "HellaSwag":84.39,
        "MMLU":53.62,
        "TruthfulQA":39.87,
        "Winogrande":75.22,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/Llama-2-13b-FINETUNE4_TEST",
        "Average":53.62,
        "ARC":54.78,
        "HellaSwag":81.52,
        "MMLU":56.03,
        "TruthfulQA":39.14,
        "Winogrande":77.03,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/Nous-Hermes-13b-pl-lora_unload",
        "Average":53.61,
        "ARC":57.08,
        "HellaSwag":81.49,
        "MMLU":49.17,
        "TruthfulQA":48.3,
        "Winogrande":76.4,
        "GSM8K":9.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Python-Code-13B",
        "Average":53.61,
        "ARC":58.79,
        "HellaSwag":81.66,
        "MMLU":54.78,
        "TruthfulQA":42.83,
        "Winogrande":74.03,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Menouar\/phi-2-basic-maths",
        "Average":53.6,
        "ARC":55.8,
        "HellaSwag":71.15,
        "MMLU":47.27,
        "TruthfulQA":41.4,
        "Winogrande":75.3,
        "GSM8K":30.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BramVanroy\/llama2-13b-ft-mc4_nl_cleaned_tiny",
        "Average":53.6,
        "ARC":59.3,
        "HellaSwag":82.04,
        "MMLU":54.67,
        "TruthfulQA":38.03,
        "Winogrande":77.27,
        "GSM8K":10.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/WizardLM-1.0-Uncensored-CodeLlama-34b",
        "Average":53.59,
        "ARC":56.4,
        "HellaSwag":75.45,
        "MMLU":54.51,
        "TruthfulQA":43.06,
        "Winogrande":72.45,
        "GSM8K":19.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":33.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
        "Average":53.58,
        "ARC":54.35,
        "HellaSwag":82.13,
        "MMLU":55.33,
        "TruthfulQA":39.6,
        "Winogrande":77.19,
        "GSM8K":12.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/tulu-13B-fp16",
        "Average":53.58,
        "ARC":53.92,
        "HellaSwag":80.66,
        "MMLU":53.19,
        "TruthfulQA":43.84,
        "Winogrande":75.61,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"codellama\/CodeLlama-34b-Python-hf",
        "Average":53.58,
        "ARC":50.43,
        "HellaSwag":76.36,
        "MMLU":49.11,
        "TruthfulQA":41.37,
        "Winogrande":71.9,
        "GSM8K":32.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":93.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Tess-7B-v2.0",
        "Average":53.57,
        "ARC":55.89,
        "HellaSwag":76.66,
        "MMLU":52.05,
        "TruthfulQA":44.33,
        "Winogrande":67.64,
        "GSM8K":24.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
        "Average":53.57,
        "ARC":58.96,
        "HellaSwag":81.94,
        "MMLU":55.0,
        "TruthfulQA":40.26,
        "Winogrande":76.56,
        "GSM8K":8.72,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/StableBeluga-7B",
        "Average":53.56,
        "ARC":56.31,
        "HellaSwag":79.14,
        "MMLU":52.71,
        "TruthfulQA":50.19,
        "Winogrande":75.22,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":129.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"circulus\/Llama-2-7b-orca-v1",
        "Average":53.56,
        "ARC":56.31,
        "HellaSwag":79.14,
        "MMLU":52.71,
        "TruthfulQA":50.19,
        "Winogrande":75.22,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ericpolewski\/TacoBeLLM",
        "Average":53.56,
        "ARC":58.53,
        "HellaSwag":81.9,
        "MMLU":56.97,
        "TruthfulQA":46.06,
        "Winogrande":76.64,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.02,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-llama-13b",
        "Average":53.56,
        "ARC":55.55,
        "HellaSwag":77.11,
        "MMLU":52.16,
        "TruthfulQA":52.23,
        "Winogrande":69.93,
        "GSM8K":14.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"google\/gemma-7b-it",
        "Average":53.56,
        "ARC":51.45,
        "HellaSwag":71.96,
        "MMLU":53.52,
        "TruthfulQA":47.29,
        "Winogrande":67.96,
        "GSM8K":29.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":1018.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yam-peleg\/gemma-7b-it-experiment",
        "Average":53.56,
        "ARC":51.45,
        "HellaSwag":71.96,
        "MMLU":53.52,
        "TruthfulQA":47.29,
        "Winogrande":67.96,
        "GSM8K":29.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-llama-13b-2-epochs",
        "Average":53.55,
        "ARC":57.94,
        "HellaSwag":82.4,
        "MMLU":48.56,
        "TruthfulQA":47.27,
        "Winogrande":76.87,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/guanaco-13B-HF",
        "Average":53.54,
        "ARC":57.85,
        "HellaSwag":83.84,
        "MMLU":48.28,
        "TruthfulQA":46.73,
        "Winogrande":75.85,
        "GSM8K":8.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/tableBeluga-7B-instruct-pl-lora_unload",
        "Average":53.54,
        "ARC":56.23,
        "HellaSwag":79.12,
        "MMLU":52.7,
        "TruthfulQA":50.19,
        "Winogrande":75.22,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aabbhishekk\/llama2-7b-function-calling-slerp",
        "Average":53.53,
        "ARC":55.46,
        "HellaSwag":79.5,
        "MMLU":50.32,
        "TruthfulQA":40.32,
        "Winogrande":75.22,
        "GSM8K":20.39,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chargoddard\/llama2-22b-blocktriangular",
        "Average":53.53,
        "ARC":58.53,
        "HellaSwag":82.59,
        "MMLU":54.64,
        "TruthfulQA":39.3,
        "Winogrande":76.32,
        "GSM8K":9.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":22.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/poorx32124",
        "Average":53.53,
        "ARC":53.16,
        "HellaSwag":73.58,
        "MMLU":52.88,
        "TruthfulQA":50.26,
        "Winogrande":69.38,
        "GSM8K":21.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama-13b",
        "Average":53.53,
        "ARC":58.96,
        "HellaSwag":79.71,
        "MMLU":49.1,
        "TruthfulQA":49.59,
        "Winogrande":75.61,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-Open_Platypus_and_ccp_2.6w",
        "Average":53.52,
        "ARC":58.96,
        "HellaSwag":82.51,
        "MMLU":56.12,
        "TruthfulQA":40.07,
        "Winogrande":76.64,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
        "Average":53.52,
        "ARC":55.03,
        "HellaSwag":81.97,
        "MMLU":56.64,
        "TruthfulQA":38.07,
        "Winogrande":77.19,
        "GSM8K":12.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/NEBULA-XB-v1.0",
        "Average":53.52,
        "ARC":56.66,
        "HellaSwag":81.78,
        "MMLU":60.98,
        "TruthfulQA":44.03,
        "Winogrande":77.66,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":23.82,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"budecosystem\/code-millenials-34b",
        "Average":53.51,
        "ARC":49.83,
        "HellaSwag":75.09,
        "MMLU":49.28,
        "TruthfulQA":45.37,
        "Winogrande":69.06,
        "GSM8K":32.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Inv\/MoECPM-Untrained-4x2b",
        "Average":53.51,
        "ARC":46.76,
        "HellaSwag":72.58,
        "MMLU":53.21,
        "TruthfulQA":38.41,
        "Winogrande":65.51,
        "GSM8K":44.58,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.79,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IGeniusDev\/llama13B-quant8-testv1-openorca-customdataset",
        "Average":53.5,
        "ARC":60.49,
        "HellaSwag":82.97,
        "MMLU":54.44,
        "TruthfulQA":37.34,
        "Winogrande":75.69,
        "GSM8K":10.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-13b-chat",
        "Average":53.5,
        "ARC":58.62,
        "HellaSwag":80.85,
        "MMLU":47.76,
        "TruthfulQA":48.73,
        "Winogrande":76.72,
        "GSM8K":8.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v13",
        "Average":53.5,
        "ARC":52.3,
        "HellaSwag":75.09,
        "MMLU":56.34,
        "TruthfulQA":50.81,
        "Winogrande":71.74,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama-13b-v1.2",
        "Average":53.49,
        "ARC":56.74,
        "HellaSwag":80.34,
        "MMLU":48.9,
        "TruthfulQA":51.0,
        "Winogrande":75.93,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
        "Average":53.48,
        "ARC":55.8,
        "HellaSwag":81.74,
        "MMLU":55.09,
        "TruthfulQA":39.12,
        "Winogrande":76.32,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_v3_7b",
        "Average":53.47,
        "ARC":56.91,
        "HellaSwag":79.64,
        "MMLU":52.37,
        "TruthfulQA":50.51,
        "Winogrande":74.27,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pankajmathur\/orca_mini_v3_7b",
        "Average":53.47,
        "ARC":56.91,
        "HellaSwag":79.64,
        "MMLU":52.37,
        "TruthfulQA":50.51,
        "Winogrande":74.27,
        "GSM8K":7.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mncai\/Llama2-7B-guanaco-dolphin-500",
        "Average":53.47,
        "ARC":56.74,
        "HellaSwag":81.62,
        "MMLU":48.68,
        "TruthfulQA":46.93,
        "Winogrande":74.11,
        "GSM8K":12.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama2-13b-chat",
        "Average":53.46,
        "ARC":57.51,
        "HellaSwag":77.94,
        "MMLU":52.56,
        "TruthfulQA":48.18,
        "Winogrande":74.74,
        "GSM8K":9.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
        "Average":53.44,
        "ARC":55.8,
        "HellaSwag":82.1,
        "MMLU":55.33,
        "TruthfulQA":39.82,
        "Winogrande":76.24,
        "GSM8K":11.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
        "Average":53.43,
        "ARC":57.94,
        "HellaSwag":81.19,
        "MMLU":53.43,
        "TruthfulQA":40.48,
        "Winogrande":76.72,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"stabilityai\/stablelm-zephyr-3b",
        "Average":53.43,
        "ARC":46.08,
        "HellaSwag":74.16,
        "MMLU":46.17,
        "TruthfulQA":46.49,
        "Winogrande":65.51,
        "GSM8K":42.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.8,
        "Model Sha":226.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Average":53.42,
        "ARC":53.84,
        "HellaSwag":77.05,
        "MMLU":53.57,
        "TruthfulQA":44.06,
        "Winogrande":74.98,
        "GSM8K":17.06,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zarafusionex-1.1-l2-7b",
        "Average":53.41,
        "ARC":56.14,
        "HellaSwag":79.34,
        "MMLU":52.1,
        "TruthfulQA":50.66,
        "Winogrande":74.43,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"?",
        "Model":"quantumaikr\/QuantumLM",
        "Average":53.41,
        "ARC":55.8,
        "HellaSwag":79.74,
        "MMLU":54.17,
        "TruthfulQA":46.71,
        "Winogrande":74.19,
        "GSM8K":9.86,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/samantha-mistral-instruct-7b",
        "Average":53.4,
        "ARC":53.5,
        "HellaSwag":75.14,
        "MMLU":51.72,
        "TruthfulQA":58.81,
        "Winogrande":70.4,
        "GSM8K":10.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-30b-instruct",
        "Average":53.4,
        "ARC":58.45,
        "HellaSwag":84.31,
        "MMLU":49.15,
        "TruthfulQA":38.05,
        "Winogrande":75.14,
        "GSM8K":15.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":30.0,
        "Model Sha":98.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aeala\/GPT4-x-Alpasta-13b",
        "Average":53.38,
        "ARC":58.53,
        "HellaSwag":79.92,
        "MMLU":46.03,
        "TruthfulQA":53.06,
        "Winogrande":73.95,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
        "Average":53.38,
        "ARC":55.89,
        "HellaSwag":81.38,
        "MMLU":53.77,
        "TruthfulQA":40.25,
        "Winogrande":76.72,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NobodyExistsOnTheInternet\/GiftedConvo13bLoraNoEcons",
        "Average":53.35,
        "ARC":59.39,
        "HellaSwag":83.19,
        "MMLU":55.15,
        "TruthfulQA":40.56,
        "Winogrande":74.03,
        "GSM8K":7.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
        "Average":53.35,
        "ARC":56.4,
        "HellaSwag":81.93,
        "MMLU":53.63,
        "TruthfulQA":39.23,
        "Winogrande":76.95,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-2.1",
        "Average":53.34,
        "ARC":59.47,
        "HellaSwag":82.47,
        "MMLU":54.83,
        "TruthfulQA":44.65,
        "Winogrande":75.06,
        "GSM8K":3.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
        "Average":53.32,
        "ARC":58.36,
        "HellaSwag":81.1,
        "MMLU":54.53,
        "TruthfulQA":37.02,
        "Winogrande":76.64,
        "GSM8K":12.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Llama-2-7b-chat-hf-activity-fine-tuned-v4",
        "Average":53.3,
        "ARC":54.27,
        "HellaSwag":78.1,
        "MMLU":48.44,
        "TruthfulQA":45.77,
        "Winogrande":73.95,
        "GSM8K":19.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/vicuna-13b-v1.3.0-GPTQ",
        "Average":53.29,
        "ARC":54.35,
        "HellaSwag":79.47,
        "MMLU":51.97,
        "TruthfulQA":50.88,
        "Winogrande":74.66,
        "GSM8K":8.42,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/vicuna-13B-1.1-HF",
        "Average":53.29,
        "ARC":52.73,
        "HellaSwag":80.13,
        "MMLU":51.94,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pillowtalks-ai\/delta13b",
        "Average":53.29,
        "ARC":52.73,
        "HellaSwag":80.13,
        "MMLU":51.94,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kevinpro\/Vicuna-13B-CoT",
        "Average":53.29,
        "ARC":52.73,
        "HellaSwag":80.13,
        "MMLU":51.94,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eachadea\/vicuna-13b-1.1",
        "Average":53.29,
        "ARC":52.73,
        "HellaSwag":80.13,
        "MMLU":51.94,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":136.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-13b-v1.1",
        "Average":53.28,
        "ARC":52.73,
        "HellaSwag":80.14,
        "MMLU":51.9,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":97.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-13b-delta-v1.1",
        "Average":53.28,
        "ARC":52.73,
        "HellaSwag":80.14,
        "MMLU":51.9,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":409.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Vicuna-13B-CoT-fp16",
        "Average":53.28,
        "ARC":52.73,
        "HellaSwag":80.14,
        "MMLU":51.9,
        "TruthfulQA":52.08,
        "Winogrande":74.19,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Llama-2-13B-GPTQ",
        "Average":53.26,
        "ARC":59.13,
        "HellaSwag":81.48,
        "MMLU":54.45,
        "TruthfulQA":37.07,
        "Winogrande":76.16,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":16.23,
        "Model Sha":116.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AdaptLLM\/finance-chat",
        "Average":53.26,
        "ARC":53.75,
        "HellaSwag":76.6,
        "MMLU":50.16,
        "TruthfulQA":44.54,
        "Winogrande":75.69,
        "GSM8K":18.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":50.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/MiniCPM-2B-Base-v2",
        "Average":53.24,
        "ARC":45.99,
        "HellaSwag":72.22,
        "MMLU":52.63,
        "TruthfulQA":40.27,
        "Winogrande":66.38,
        "GSM8K":41.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/MiniCPM-2B-Base-v3",
        "Average":53.24,
        "ARC":47.01,
        "HellaSwag":73.12,
        "MMLU":52.42,
        "TruthfulQA":41.82,
        "Winogrande":66.14,
        "GSM8K":38.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
        "Average":53.23,
        "ARC":56.31,
        "HellaSwag":81.43,
        "MMLU":55.3,
        "TruthfulQA":39.11,
        "Winogrande":76.8,
        "GSM8K":10.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/airoboros-2.1-llama-2-13B-QLoRa",
        "Average":53.23,
        "ARC":59.73,
        "HellaSwag":82.91,
        "MMLU":54.77,
        "TruthfulQA":45.14,
        "Winogrande":74.03,
        "GSM8K":2.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Llama-2-7b-chat-hf-activity-fine-tuned-v4",
        "Average":53.23,
        "ARC":54.35,
        "HellaSwag":78.12,
        "MMLU":48.42,
        "TruthfulQA":45.83,
        "Winogrande":73.32,
        "GSM8K":19.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"liminerity\/mm4-3b",
        "Average":53.22,
        "ARC":44.8,
        "HellaSwag":70.41,
        "MMLU":50.9,
        "TruthfulQA":43.2,
        "Winogrande":66.22,
        "GSM8K":43.82,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/Mistral-7B-loss-100000",
        "Average":53.22,
        "ARC":51.79,
        "HellaSwag":77.16,
        "MMLU":53.94,
        "TruthfulQA":40.93,
        "Winogrande":76.95,
        "GSM8K":18.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severus27\/BeingWell_llama2_7b",
        "Average":53.22,
        "ARC":54.95,
        "HellaSwag":78.27,
        "MMLU":47.46,
        "TruthfulQA":45.93,
        "Winogrande":74.19,
        "GSM8K":18.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Medtulu-2x7b",
        "Average":53.21,
        "ARC":54.61,
        "HellaSwag":75.68,
        "MMLU":49.12,
        "TruthfulQA":50.04,
        "Winogrande":72.85,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.07,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-13b_10e5_r2_a256",
        "Average":53.2,
        "ARC":58.02,
        "HellaSwag":80.99,
        "MMLU":52.71,
        "TruthfulQA":36.36,
        "Winogrande":74.74,
        "GSM8K":16.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE2_TEST_2.2w",
        "Average":53.2,
        "ARC":56.23,
        "HellaSwag":82.7,
        "MMLU":55.35,
        "TruthfulQA":39.55,
        "Winogrande":76.72,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AllyArc\/llama_allyarc",
        "Average":53.2,
        "ARC":54.35,
        "HellaSwag":78.24,
        "MMLU":48.28,
        "TruthfulQA":47.97,
        "Winogrande":72.3,
        "GSM8K":18.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"macadeliccc\/Mistral-7B-v0.2-OpenHermes",
        "Average":53.2,
        "ARC":55.8,
        "HellaSwag":81.61,
        "MMLU":60.0,
        "TruthfulQA":43.09,
        "Winogrande":78.69,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"meta-math\/MetaMath-Llemma-7B",
        "Average":53.19,
        "ARC":46.5,
        "HellaSwag":61.69,
        "MMLU":47.66,
        "TruthfulQA":39.61,
        "Winogrande":62.75,
        "GSM8K":60.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
        "Average":53.18,
        "ARC":54.78,
        "HellaSwag":81.4,
        "MMLU":54.73,
        "TruthfulQA":41.02,
        "Winogrande":76.64,
        "GSM8K":10.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pharaouk\/fusedyi",
        "Average":53.18,
        "ARC":55.03,
        "HellaSwag":76.6,
        "MMLU":63.43,
        "TruthfulQA":49.29,
        "Winogrande":72.69,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.91,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zarafusionix-l2-7b",
        "Average":53.18,
        "ARC":55.55,
        "HellaSwag":79.4,
        "MMLU":51.21,
        "TruthfulQA":51.05,
        "Winogrande":74.66,
        "GSM8K":7.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/WizardLM-13B-V1-1-SuperHOT-8K-fp16",
        "Average":53.16,
        "ARC":58.62,
        "HellaSwag":81.07,
        "MMLU":48.32,
        "TruthfulQA":54.19,
        "Winogrande":76.01,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Athena-Platypus2-13B-QLora-0.80-epoch",
        "Average":53.16,
        "ARC":56.66,
        "HellaSwag":80.56,
        "MMLU":55.43,
        "TruthfulQA":53.62,
        "Winogrande":72.61,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
        "Average":53.15,
        "ARC":58.96,
        "HellaSwag":82.46,
        "MMLU":54.62,
        "TruthfulQA":47.71,
        "Winogrande":75.14,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Enno-Ai\/vigogne2-enno-13b-sft-lora-4bit",
        "Average":53.15,
        "ARC":62.03,
        "HellaSwag":82.65,
        "MMLU":54.11,
        "TruthfulQA":42.98,
        "Winogrande":76.95,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Airoboros-L2-13B-2.1-GPTQ",
        "Average":53.14,
        "ARC":58.96,
        "HellaSwag":81.72,
        "MMLU":53.16,
        "TruthfulQA":44.68,
        "Winogrande":74.35,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":16.23,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
        "Average":53.14,
        "ARC":59.04,
        "HellaSwag":82.33,
        "MMLU":55.36,
        "TruthfulQA":35.75,
        "Winogrande":76.32,
        "GSM8K":10.01,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/llama-13b-pretrained-sft-do2",
        "Average":53.12,
        "ARC":58.96,
        "HellaSwag":80.32,
        "MMLU":47.25,
        "TruthfulQA":47.41,
        "Winogrande":75.53,
        "GSM8K":9.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/MLewd-L2-13B",
        "Average":53.12,
        "ARC":58.28,
        "HellaSwag":82.32,
        "MMLU":54.67,
        "TruthfulQA":48.66,
        "Winogrande":73.48,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jjaaaww\/posi_13b",
        "Average":53.12,
        "ARC":59.64,
        "HellaSwag":82.52,
        "MMLU":56.56,
        "TruthfulQA":42.14,
        "Winogrande":76.24,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/llama-13b-pretrained-sft-epoch-1",
        "Average":53.11,
        "ARC":57.25,
        "HellaSwag":79.99,
        "MMLU":45.52,
        "TruthfulQA":44.45,
        "Winogrande":77.58,
        "GSM8K":13.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/manticore-13b-chat-pyg-GPTQ",
        "Average":53.11,
        "ARC":57.85,
        "HellaSwag":81.07,
        "MMLU":47.56,
        "TruthfulQA":47.77,
        "Winogrande":75.93,
        "GSM8K":8.49,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":33.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/MistralLite-summ-sft-e1",
        "Average":53.11,
        "ARC":59.56,
        "HellaSwag":81.42,
        "MMLU":52.34,
        "TruthfulQA":41.79,
        "Winogrande":77.11,
        "GSM8K":6.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/InnerIAI-chat-7b-grok",
        "Average":53.11,
        "ARC":52.13,
        "HellaSwag":75.38,
        "MMLU":53.86,
        "TruthfulQA":46.56,
        "Winogrande":72.3,
        "GSM8K":18.42,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama2_7b_mmlu",
        "Average":53.1,
        "ARC":56.14,
        "HellaSwag":79.13,
        "MMLU":60.04,
        "TruthfulQA":40.95,
        "Winogrande":74.43,
        "GSM8K":7.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/llama2-13b-FINETUNE3_TEST",
        "Average":53.09,
        "ARC":53.67,
        "HellaSwag":79.66,
        "MMLU":54.48,
        "TruthfulQA":40.22,
        "Winogrande":75.93,
        "GSM8K":14.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Cartinoe5930\/TIES-Merging",
        "Average":53.08,
        "ARC":58.11,
        "HellaSwag":75.74,
        "MMLU":51.57,
        "TruthfulQA":41.25,
        "Winogrande":72.38,
        "GSM8K":19.41,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
        "Average":53.06,
        "ARC":57.76,
        "HellaSwag":80.78,
        "MMLU":54.32,
        "TruthfulQA":40.8,
        "Winogrande":76.72,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Telugu-LLM-Labs\/Telugu-Llama2-7B-v0-Instruct",
        "Average":53.04,
        "ARC":53.41,
        "HellaSwag":78.35,
        "MMLU":47.79,
        "TruthfulQA":43.29,
        "Winogrande":74.19,
        "GSM8K":21.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/FINETUNE3_TEST4",
        "Average":53.02,
        "ARC":55.63,
        "HellaSwag":81.31,
        "MMLU":52.13,
        "TruthfulQA":41.14,
        "Winogrande":76.72,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Open-Orca\/LlongOrca-7B-16k",
        "Average":53.02,
        "ARC":57.51,
        "HellaSwag":79.44,
        "MMLU":49.35,
        "TruthfulQA":49.84,
        "Winogrande":74.51,
        "GSM8K":7.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/google-gemma-7b-it-dpo-v1",
        "Average":53.02,
        "ARC":51.54,
        "HellaSwag":71.58,
        "MMLU":53.24,
        "TruthfulQA":46.85,
        "Winogrande":67.25,
        "GSM8K":27.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"liminerity\/dhbacmes-3b-slerp",
        "Average":53.02,
        "ARC":45.22,
        "HellaSwag":70.77,
        "MMLU":52.94,
        "TruthfulQA":40.41,
        "Winogrande":65.11,
        "GSM8K":43.67,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-gpt4-1.4.1",
        "Average":53.02,
        "ARC":59.13,
        "HellaSwag":82.78,
        "MMLU":55.62,
        "TruthfulQA":40.27,
        "Winogrande":73.32,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Walter-Mistral-7B",
        "Average":53.0,
        "ARC":58.87,
        "HellaSwag":83.43,
        "MMLU":58.65,
        "TruthfulQA":39.93,
        "Winogrande":77.03,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/llama-13b-pretrained-dropout",
        "Average":52.99,
        "ARC":56.4,
        "HellaSwag":79.34,
        "MMLU":46.59,
        "TruthfulQA":48.6,
        "Winogrande":75.22,
        "GSM8K":11.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AdaptLLM\/medicine-chat",
        "Average":52.99,
        "ARC":53.75,
        "HellaSwag":76.11,
        "MMLU":49.98,
        "TruthfulQA":43.46,
        "Winogrande":75.69,
        "GSM8K":18.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hamxea\/Llama-2-7b-chat-hf-activity-fine-tuned-v3",
        "Average":52.99,
        "ARC":53.33,
        "HellaSwag":78.1,
        "MMLU":48.31,
        "TruthfulQA":45.7,
        "Winogrande":73.48,
        "GSM8K":19.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/Huginn-19b-prototype",
        "Average":52.99,
        "ARC":59.22,
        "HellaSwag":81.03,
        "MMLU":55.73,
        "TruthfulQA":41.15,
        "Winogrande":76.4,
        "GSM8K":4.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":19.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"heegyu\/LIMA2-13b-hf",
        "Average":52.98,
        "ARC":60.24,
        "HellaSwag":83.69,
        "MMLU":53.17,
        "TruthfulQA":41.81,
        "Winogrande":73.24,
        "GSM8K":5.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xzuyn\/Alpacino-SuperCOT-13B",
        "Average":52.97,
        "ARC":58.36,
        "HellaSwag":81.69,
        "MMLU":47.89,
        "TruthfulQA":45.42,
        "Winogrande":76.95,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-chat-hf-gpt-4-80k",
        "Average":52.97,
        "ARC":54.78,
        "HellaSwag":74.63,
        "MMLU":48.77,
        "TruthfulQA":48.45,
        "Winogrande":72.85,
        "GSM8K":18.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Code-290k-13B",
        "Average":52.96,
        "ARC":56.06,
        "HellaSwag":81.55,
        "MMLU":51.99,
        "TruthfulQA":37.65,
        "Winogrande":72.69,
        "GSM8K":17.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"allenai\/digital-socrates-7b",
        "Average":52.95,
        "ARC":54.44,
        "HellaSwag":75.99,
        "MMLU":51.41,
        "TruthfulQA":44.88,
        "Winogrande":73.09,
        "GSM8K":17.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zaraxe-l2-7b",
        "Average":52.95,
        "ARC":57.17,
        "HellaSwag":79.34,
        "MMLU":51.0,
        "TruthfulQA":49.11,
        "Winogrande":73.48,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sethuiyer\/Dr_Samantha-7b",
        "Average":52.95,
        "ARC":53.84,
        "HellaSwag":77.95,
        "MMLU":47.94,
        "TruthfulQA":45.58,
        "Winogrande":73.56,
        "GSM8K":18.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
        "Average":52.94,
        "ARC":58.45,
        "HellaSwag":81.97,
        "MMLU":55.02,
        "TruthfulQA":35.85,
        "Winogrande":75.69,
        "GSM8K":10.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"project-baize\/baize-v2-13b",
        "Average":52.94,
        "ARC":56.91,
        "HellaSwag":79.29,
        "MMLU":49.72,
        "TruthfulQA":47.88,
        "Winogrande":74.9,
        "GSM8K":8.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/MultiLoRA-mmlu",
        "Average":52.93,
        "ARC":52.39,
        "HellaSwag":77.21,
        "MMLU":49.73,
        "TruthfulQA":50.2,
        "Winogrande":72.22,
        "GSM8K":15.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-llama2-13b-v11-bf16",
        "Average":52.93,
        "ARC":52.99,
        "HellaSwag":75.38,
        "MMLU":51.36,
        "TruthfulQA":47.94,
        "Winogrande":71.03,
        "GSM8K":18.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-100step-flan-v2",
        "Average":52.92,
        "ARC":53.24,
        "HellaSwag":78.43,
        "MMLU":48.43,
        "TruthfulQA":45.66,
        "Winogrande":72.3,
        "GSM8K":19.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NLUHOPOE\/Mistral-7B-random-100000",
        "Average":52.92,
        "ARC":53.75,
        "HellaSwag":78.6,
        "MMLU":53.41,
        "TruthfulQA":43.16,
        "Winogrande":75.61,
        "GSM8K":12.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"BioMistral\/BioMistral-7B-TIES",
        "Average":52.91,
        "ARC":55.46,
        "HellaSwag":79.59,
        "MMLU":56.29,
        "TruthfulQA":52.2,
        "Winogrande":73.72,
        "GSM8K":0.23,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nkpz\/llama2-22b-chat-wizard-uncensored",
        "Average":52.9,
        "ARC":56.23,
        "HellaSwag":80.39,
        "MMLU":53.62,
        "TruthfulQA":45.76,
        "Winogrande":70.24,
        "GSM8K":11.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":21.83,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pe-nlp\/llama-2-13b-platypus-vicuna-wizard",
        "Average":52.9,
        "ARC":61.26,
        "HellaSwag":82.31,
        "MMLU":55.21,
        "TruthfulQA":41.91,
        "Winogrande":75.77,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"clibrain\/Llama-2-13b-ft-instruct-es",
        "Average":52.89,
        "ARC":59.39,
        "HellaSwag":81.51,
        "MMLU":54.31,
        "TruthfulQA":37.81,
        "Winogrande":75.77,
        "GSM8K":8.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AdaptLLM\/law-chat",
        "Average":52.88,
        "ARC":53.41,
        "HellaSwag":76.16,
        "MMLU":50.24,
        "TruthfulQA":43.53,
        "Winogrande":75.45,
        "GSM8K":18.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wei123602\/llama2-13b-fintune2-4E",
        "Average":52.88,
        "ARC":55.89,
        "HellaSwag":80.95,
        "MMLU":53.73,
        "TruthfulQA":42.72,
        "Winogrande":73.09,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-100step-flan",
        "Average":52.88,
        "ARC":52.9,
        "HellaSwag":78.44,
        "MMLU":48.4,
        "TruthfulQA":45.67,
        "Winogrande":72.38,
        "GSM8K":19.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CHIH-HUNG\/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
        "Average":52.88,
        "ARC":55.97,
        "HellaSwag":81.53,
        "MMLU":54.42,
        "TruthfulQA":40.72,
        "Winogrande":75.06,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ContextualAI\/archangel_sft-kto_llama13b",
        "Average":52.87,
        "ARC":56.14,
        "HellaSwag":80.8,
        "MMLU":47.84,
        "TruthfulQA":39.42,
        "Winogrande":76.16,
        "GSM8K":16.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"Yhyu13\/chimera-inst-chat-13b-hf",
        "Average":52.86,
        "ARC":55.38,
        "HellaSwag":78.93,
        "MMLU":50.6,
        "TruthfulQA":50.12,
        "Winogrande":73.95,
        "GSM8K":8.19,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Telugu-LLM-Labs\/Telugu-Llama2-7B-v0-Instruct",
        "Average":52.86,
        "ARC":53.58,
        "HellaSwag":78.33,
        "MMLU":47.63,
        "TruthfulQA":43.26,
        "Winogrande":73.95,
        "GSM8K":20.39,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"stabilityai\/japanese-stablelm-instruct-gamma-7b",
        "Average":52.82,
        "ARC":50.68,
        "HellaSwag":78.68,
        "MMLU":54.82,
        "TruthfulQA":39.77,
        "Winogrande":73.72,
        "GSM8K":19.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoder2-15b",
        "Average":52.79,
        "ARC":47.35,
        "HellaSwag":64.09,
        "MMLU":51.35,
        "TruthfulQA":37.87,
        "Winogrande":63.85,
        "GSM8K":52.24,
        "Type":"pretrained",
        "Architecture":"Starcoder2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":15.96,
        "Model Sha":472.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mosaicml\/mpt-30b",
        "Average":52.77,
        "ARC":55.97,
        "HellaSwag":82.42,
        "MMLU":48.0,
        "TruthfulQA":38.42,
        "Winogrande":74.9,
        "GSM8K":16.91,
        "Type":"pretrained",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":30.0,
        "Model Sha":336.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Llama2-13B-no_robots-alpaca-lora",
        "Average":52.77,
        "ARC":58.87,
        "HellaSwag":82.43,
        "MMLU":53.11,
        "TruthfulQA":40.46,
        "Winogrande":75.3,
        "GSM8K":6.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chargoddard\/ypotryll-22b-epoch2-qlora",
        "Average":52.75,
        "ARC":59.22,
        "HellaSwag":80.66,
        "MMLU":54.52,
        "TruthfulQA":40.42,
        "Winogrande":76.32,
        "GSM8K":5.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":22.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/wizard-vicuna-13B-HF",
        "Average":52.75,
        "ARC":54.69,
        "HellaSwag":79.18,
        "MMLU":48.88,
        "TruthfulQA":49.62,
        "Winogrande":74.82,
        "GSM8K":9.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_v2_13b",
        "Average":52.75,
        "ARC":55.12,
        "HellaSwag":79.69,
        "MMLU":50.07,
        "TruthfulQA":52.56,
        "Winogrande":72.69,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-200step-flan-v2",
        "Average":52.75,
        "ARC":52.65,
        "HellaSwag":78.04,
        "MMLU":48.51,
        "TruthfulQA":45.42,
        "Winogrande":72.93,
        "GSM8K":18.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"totally-not-an-llm\/EverythingLM-13b-V2-16k",
        "Average":52.75,
        "ARC":58.7,
        "HellaSwag":80.88,
        "MMLU":49.69,
        "TruthfulQA":47.37,
        "Winogrande":73.01,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"junelee\/wizard-vicuna-13b",
        "Average":52.73,
        "ARC":54.69,
        "HellaSwag":79.18,
        "MMLU":48.88,
        "TruthfulQA":49.62,
        "Winogrande":74.82,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-13b-fast-instruct",
        "Average":52.72,
        "ARC":57.51,
        "HellaSwag":81.82,
        "MMLU":54.52,
        "TruthfulQA":43.82,
        "Winogrande":75.93,
        "GSM8K":2.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openchat\/openchat_8192",
        "Average":52.72,
        "ARC":59.56,
        "HellaSwag":81.44,
        "MMLU":46.26,
        "TruthfulQA":46.7,
        "Winogrande":74.98,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":220.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-7B-v1.2",
        "Average":52.71,
        "ARC":54.35,
        "HellaSwag":79.29,
        "MMLU":49.33,
        "TruthfulQA":48.92,
        "Winogrande":73.56,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"?",
        "Model":"PocketDoc\/Dans-PersonalityEngine-13b",
        "Average":52.71,
        "ARC":58.45,
        "HellaSwag":82.3,
        "MMLU":47.58,
        "TruthfulQA":41.12,
        "Winogrande":77.51,
        "GSM8K":9.33,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nnethercott\/orca-open_hermes-llava-v1.5-7b-dpo",
        "Average":52.71,
        "ARC":53.07,
        "HellaSwag":77.11,
        "MMLU":51.03,
        "TruthfulQA":47.6,
        "Winogrande":71.9,
        "GSM8K":15.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"meta-math\/MetaMath-13B-V1.0",
        "Average":52.71,
        "ARC":49.49,
        "HellaSwag":76.48,
        "MMLU":47.74,
        "TruthfulQA":41.58,
        "Winogrande":72.45,
        "GSM8K":28.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-hf-gpt-4-80k",
        "Average":52.71,
        "ARC":55.55,
        "HellaSwag":77.27,
        "MMLU":46.75,
        "TruthfulQA":48.63,
        "Winogrande":74.03,
        "GSM8K":14.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Yehoon\/yehoon_llama2",
        "Average":52.71,
        "ARC":54.78,
        "HellaSwag":78.98,
        "MMLU":51.29,
        "TruthfulQA":49.17,
        "Winogrande":74.74,
        "GSM8K":7.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/mcq-hal-vicuna-13b-v1.5",
        "Average":52.7,
        "ARC":55.97,
        "HellaSwag":80.72,
        "MMLU":52.85,
        "TruthfulQA":45.03,
        "Winogrande":72.77,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Capybara-7B",
        "Average":52.7,
        "ARC":55.29,
        "HellaSwag":80.73,
        "MMLU":48.72,
        "TruthfulQA":51.13,
        "Winogrande":73.32,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HyperbeeAI\/Tulpar-7b-v0",
        "Average":52.69,
        "ARC":56.31,
        "HellaSwag":79.01,
        "MMLU":52.55,
        "TruthfulQA":51.68,
        "Winogrande":73.88,
        "GSM8K":2.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Capybara-7B",
        "Average":52.69,
        "ARC":55.2,
        "HellaSwag":80.76,
        "MMLU":48.8,
        "TruthfulQA":51.07,
        "Winogrande":73.4,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/CodeEngine",
        "Average":52.68,
        "ARC":58.36,
        "HellaSwag":82.27,
        "MMLU":54.18,
        "TruthfulQA":45.18,
        "Winogrande":74.59,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/mcq-vicuna-13b-v1.5",
        "Average":52.68,
        "ARC":56.66,
        "HellaSwag":81.09,
        "MMLU":53.3,
        "TruthfulQA":43.99,
        "Winogrande":73.01,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mixtral-8x7b-v16.1-32k",
        "Average":52.68,
        "ARC":29.1,
        "HellaSwag":82.27,
        "MMLU":71.37,
        "TruthfulQA":55.97,
        "Winogrande":77.35,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/Mistral-Trismegistus-7B",
        "Average":52.66,
        "ARC":54.1,
        "HellaSwag":77.91,
        "MMLU":54.49,
        "TruthfulQA":49.36,
        "Winogrande":70.17,
        "GSM8K":9.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":176.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-gpt4-m2.0",
        "Average":52.66,
        "ARC":59.22,
        "HellaSwag":81.02,
        "MMLU":53.73,
        "TruthfulQA":39.7,
        "Winogrande":73.64,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeoLM\/leo-hessianai-13b",
        "Average":52.65,
        "ARC":57.25,
        "HellaSwag":81.94,
        "MMLU":53.65,
        "TruthfulQA":38.03,
        "Winogrande":76.09,
        "GSM8K":8.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-200step-flan",
        "Average":52.62,
        "ARC":52.47,
        "HellaSwag":78.02,
        "MMLU":48.42,
        "TruthfulQA":45.47,
        "Winogrande":72.69,
        "GSM8K":18.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v13.1",
        "Average":52.62,
        "ARC":52.56,
        "HellaSwag":75.73,
        "MMLU":56.68,
        "TruthfulQA":50.44,
        "Winogrande":71.59,
        "GSM8K":8.72,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"heegyu\/LIMA-13b-hf",
        "Average":52.61,
        "ARC":57.42,
        "HellaSwag":81.68,
        "MMLU":48.72,
        "TruthfulQA":41.76,
        "Winogrande":77.19,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LinkSoul\/Chinese-Llama-2-7b",
        "Average":52.59,
        "ARC":52.99,
        "HellaSwag":75.64,
        "MMLU":50.74,
        "TruthfulQA":48.94,
        "Winogrande":72.77,
        "GSM8K":14.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.0,
        "Model Sha":302.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/japanese-stablelm-base-gamma-7b",
        "Average":52.59,
        "ARC":50.34,
        "HellaSwag":77.47,
        "MMLU":54.75,
        "TruthfulQA":41.2,
        "Winogrande":73.95,
        "GSM8K":17.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/Mistral-7B-SFT",
        "Average":52.58,
        "ARC":46.5,
        "HellaSwag":75.69,
        "MMLU":51.04,
        "TruthfulQA":52.02,
        "Winogrande":72.77,
        "GSM8K":17.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/MiniCPM-2B-Base",
        "Average":52.56,
        "ARC":46.08,
        "HellaSwag":70.52,
        "MMLU":52.61,
        "TruthfulQA":41.39,
        "Winogrande":65.9,
        "GSM8K":38.89,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/MiniCPM-3B-Bacchus",
        "Average":52.55,
        "ARC":43.52,
        "HellaSwag":70.45,
        "MMLU":50.49,
        "TruthfulQA":43.52,
        "Winogrande":66.85,
        "GSM8K":40.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"frank098\/Wizard-Vicuna-13B-juniper",
        "Average":52.55,
        "ARC":55.89,
        "HellaSwag":79.75,
        "MMLU":44.99,
        "TruthfulQA":54.72,
        "Winogrande":72.69,
        "GSM8K":7.28,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wahaha1987\/llama_13b_sharegpt94k_fastchat",
        "Average":52.55,
        "ARC":53.75,
        "HellaSwag":79.47,
        "MMLU":51.5,
        "TruthfulQA":49.54,
        "Winogrande":72.61,
        "GSM8K":8.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/mcq-vicuna-13b-v1.5",
        "Average":52.55,
        "ARC":56.23,
        "HellaSwag":81.15,
        "MMLU":53.38,
        "TruthfulQA":44.08,
        "Winogrande":72.93,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-codellama-34b-v1.0",
        "Average":52.53,
        "ARC":52.47,
        "HellaSwag":74.13,
        "MMLU":53.47,
        "TruthfulQA":47.14,
        "Winogrande":73.24,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-dolphin-orca-platypus-34b",
        "Average":52.53,
        "ARC":52.47,
        "HellaSwag":74.13,
        "MMLU":53.47,
        "TruthfulQA":47.14,
        "Winogrande":73.24,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-10-attention-sparsity",
        "Average":52.52,
        "ARC":52.9,
        "HellaSwag":78.18,
        "MMLU":48.1,
        "TruthfulQA":45.4,
        "Winogrande":71.43,
        "GSM8K":19.11,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/MiniCPM-3B-Hercules-v2.0",
        "Average":52.52,
        "ARC":43.26,
        "HellaSwag":71.11,
        "MMLU":51.82,
        "TruthfulQA":40.37,
        "Winogrande":66.46,
        "GSM8K":42.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-34b-v2.0",
        "Average":52.51,
        "ARC":54.35,
        "HellaSwag":75.65,
        "MMLU":54.67,
        "TruthfulQA":45.21,
        "Winogrande":73.56,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lvkaokao\/llama2-7b-hf-chat-lora-v2",
        "Average":52.5,
        "ARC":55.03,
        "HellaSwag":78.81,
        "MMLU":51.35,
        "TruthfulQA":44.05,
        "Winogrande":74.9,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-gpt4-2.0",
        "Average":52.49,
        "ARC":59.04,
        "HellaSwag":82.82,
        "MMLU":54.71,
        "TruthfulQA":36.47,
        "Winogrande":74.19,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liuda1\/Mistral-7B-golden",
        "Average":52.49,
        "ARC":60.75,
        "HellaSwag":44.42,
        "MMLU":59.29,
        "TruthfulQA":53.51,
        "Winogrande":76.64,
        "GSM8K":20.32,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-13b-longlora-32k-ft",
        "Average":52.49,
        "ARC":59.47,
        "HellaSwag":82.61,
        "MMLU":52.13,
        "TruthfulQA":37.44,
        "Winogrande":75.53,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"genaicore3434\/MistralLite-summ-sft-e1",
        "Average":52.48,
        "ARC":57.59,
        "HellaSwag":80.66,
        "MMLU":52.28,
        "TruthfulQA":40.85,
        "Winogrande":76.16,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lvkaokao\/llama2-7b-hf-chat-lora-v3",
        "Average":52.48,
        "ARC":57.25,
        "HellaSwag":78.62,
        "MMLU":50.57,
        "TruthfulQA":50.62,
        "Winogrande":76.32,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-10-sparsity",
        "Average":52.48,
        "ARC":53.16,
        "HellaSwag":78.26,
        "MMLU":48.18,
        "TruthfulQA":45.29,
        "Winogrande":71.59,
        "GSM8K":18.42,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beaugogh\/Llama2-7b-openorca-mc-v2",
        "Average":52.47,
        "ARC":55.55,
        "HellaSwag":81.26,
        "MMLU":48.3,
        "TruthfulQA":51.49,
        "Winogrande":72.85,
        "GSM8K":5.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lizhuang144\/llama_mirror_13b_v1.0",
        "Average":52.46,
        "ARC":57.59,
        "HellaSwag":80.53,
        "MMLU":48.0,
        "TruthfulQA":44.54,
        "Winogrande":76.64,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-2-7b-chat",
        "Average":52.45,
        "ARC":55.63,
        "HellaSwag":78.71,
        "MMLU":50.98,
        "TruthfulQA":47.21,
        "Winogrande":74.43,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yys\/gemma-7B-it-firefly",
        "Average":52.45,
        "ARC":48.29,
        "HellaSwag":71.59,
        "MMLU":52.99,
        "TruthfulQA":42.25,
        "Winogrande":67.88,
        "GSM8K":31.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ausboss\/llama-13b-supercot",
        "Average":52.44,
        "ARC":56.06,
        "HellaSwag":81.71,
        "MMLU":45.36,
        "TruthfulQA":48.55,
        "Winogrande":75.77,
        "GSM8K":7.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"camel-ai\/CAMEL-13B-Combined-Data",
        "Average":52.44,
        "ARC":55.63,
        "HellaSwag":79.25,
        "MMLU":49.74,
        "TruthfulQA":47.42,
        "Winogrande":75.45,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-PileOfSets-Mk1-llama-13b-merged",
        "Average":52.43,
        "ARC":58.79,
        "HellaSwag":81.79,
        "MMLU":48.12,
        "TruthfulQA":41.24,
        "Winogrande":76.16,
        "GSM8K":8.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-300step-flan-v2",
        "Average":52.41,
        "ARC":52.56,
        "HellaSwag":77.76,
        "MMLU":48.51,
        "TruthfulQA":45.14,
        "Winogrande":72.53,
        "GSM8K":17.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
        "Average":52.41,
        "ARC":54.52,
        "HellaSwag":79.36,
        "MMLU":55.15,
        "TruthfulQA":54.32,
        "Winogrande":71.11,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zararp-l2-7b",
        "Average":52.39,
        "ARC":56.31,
        "HellaSwag":79.19,
        "MMLU":51.36,
        "TruthfulQA":51.26,
        "Winogrande":74.51,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Unbabel\/TowerInstruct-7B-v0.1",
        "Average":52.39,
        "ARC":55.46,
        "HellaSwag":79.0,
        "MMLU":46.88,
        "TruthfulQA":42.59,
        "Winogrande":73.95,
        "GSM8K":16.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.74,
        "Model Sha":52.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Alpacino13b",
        "Average":52.39,
        "ARC":58.53,
        "HellaSwag":81.31,
        "MMLU":47.92,
        "TruthfulQA":41.66,
        "Winogrande":76.95,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"The-Face-Of-Goonery\/Huginn-22b-Prototype",
        "Average":52.36,
        "ARC":57.68,
        "HellaSwag":80.69,
        "MMLU":49.81,
        "TruthfulQA":52.11,
        "Winogrande":71.59,
        "GSM8K":2.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":21.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deita-2b",
        "Average":52.35,
        "ARC":44.71,
        "HellaSwag":70.39,
        "MMLU":52.79,
        "TruthfulQA":39.61,
        "Winogrande":65.27,
        "GSM8K":41.32,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.01,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"totally-not-an-llm\/EverythingLM-13b-16k",
        "Average":52.33,
        "ARC":56.57,
        "HellaSwag":80.58,
        "MMLU":50.18,
        "TruthfulQA":47.46,
        "Winogrande":72.77,
        "GSM8K":6.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":33.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BioMistral\/BioMistral-7B",
        "Average":52.33,
        "ARC":54.27,
        "HellaSwag":79.09,
        "MMLU":55.56,
        "TruthfulQA":51.61,
        "Winogrande":73.48,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":315.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"beaugogh\/Llama2-7b-openorca-mc-v2-dpo",
        "Average":52.32,
        "ARC":54.78,
        "HellaSwag":81.48,
        "MMLU":47.2,
        "TruthfulQA":53.13,
        "Winogrande":72.85,
        "GSM8K":4.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-atom-13b-v9-bf16",
        "Average":52.31,
        "ARC":51.19,
        "HellaSwag":75.99,
        "MMLU":49.33,
        "TruthfulQA":48.66,
        "Winogrande":73.32,
        "GSM8K":15.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4-1.2",
        "Average":52.31,
        "ARC":58.36,
        "HellaSwag":81.61,
        "MMLU":48.84,
        "TruthfulQA":47.54,
        "Winogrande":73.64,
        "GSM8K":3.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eachadea\/vicuna-13b",
        "Average":52.3,
        "ARC":51.71,
        "HellaSwag":79.94,
        "MMLU":50.84,
        "TruthfulQA":52.68,
        "Winogrande":71.03,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"prithivida\/Asimov-7B-v2",
        "Average":52.29,
        "ARC":54.27,
        "HellaSwag":78.72,
        "MMLU":52.59,
        "TruthfulQA":45.44,
        "Winogrande":71.82,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mmlu-merged",
        "Average":52.29,
        "ARC":51.11,
        "HellaSwag":76.75,
        "MMLU":49.39,
        "TruthfulQA":48.49,
        "Winogrande":71.98,
        "GSM8K":16.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ericpolewski\/Palworld-SME-13b",
        "Average":52.28,
        "ARC":55.55,
        "HellaSwag":80.81,
        "MMLU":53.64,
        "TruthfulQA":46.67,
        "Winogrande":74.82,
        "GSM8K":2.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-3.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mncai\/Llama2-7B-guanaco-1k",
        "Average":52.28,
        "ARC":55.12,
        "HellaSwag":80.53,
        "MMLU":47.93,
        "TruthfulQA":47.69,
        "Winogrande":74.82,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-441step-flan-v2",
        "Average":52.28,
        "ARC":52.13,
        "HellaSwag":77.63,
        "MMLU":48.52,
        "TruthfulQA":45.02,
        "Winogrande":72.53,
        "GSM8K":17.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nnethercott\/llava-v1.5-7b-hf-vicuna",
        "Average":52.28,
        "ARC":52.65,
        "HellaSwag":76.09,
        "MMLU":51.68,
        "TruthfulQA":45.86,
        "Winogrande":72.06,
        "GSM8K":15.31,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nnethercott\/llava-v1.5-7b_vicuna",
        "Average":52.28,
        "ARC":52.65,
        "HellaSwag":76.09,
        "MMLU":51.68,
        "TruthfulQA":45.86,
        "Winogrande":72.06,
        "GSM8K":15.31,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TFLai\/Platypus2-13B-QLoRA-0.80-epoch",
        "Average":52.27,
        "ARC":57.76,
        "HellaSwag":81.63,
        "MMLU":55.63,
        "TruthfulQA":39.7,
        "Winogrande":75.93,
        "GSM8K":2.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"oh-yeontaek\/llama-2-7B-LoRA-assemble",
        "Average":52.26,
        "ARC":57.34,
        "HellaSwag":78.81,
        "MMLU":50.75,
        "TruthfulQA":53.18,
        "Winogrande":73.48,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-temporal-sharegpt",
        "Average":52.26,
        "ARC":53.5,
        "HellaSwag":75.82,
        "MMLU":50.79,
        "TruthfulQA":44.75,
        "Winogrande":72.69,
        "GSM8K":16.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-200step-merged",
        "Average":52.26,
        "ARC":52.05,
        "HellaSwag":77.38,
        "MMLU":48.65,
        "TruthfulQA":44.6,
        "Winogrande":71.9,
        "GSM8K":18.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kalisai\/Nusantara-7b-Indo-Chat",
        "Average":52.25,
        "ARC":48.55,
        "HellaSwag":72.84,
        "MMLU":52.03,
        "TruthfulQA":45.63,
        "Winogrande":69.53,
        "GSM8K":24.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.72,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"beaugogh\/Llama2-7b-openorca-mc-v1",
        "Average":52.24,
        "ARC":55.63,
        "HellaSwag":80.17,
        "MMLU":48.44,
        "TruthfulQA":51.62,
        "Winogrande":73.48,
        "GSM8K":4.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zararp-1.1-l2-7b",
        "Average":52.22,
        "ARC":56.48,
        "HellaSwag":78.85,
        "MMLU":51.49,
        "TruthfulQA":51.99,
        "Winogrande":73.4,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"LTC-AI-Labs\/L2-7b-Hermes-Synthia",
        "Average":52.21,
        "ARC":51.02,
        "HellaSwag":79.12,
        "MMLU":47.88,
        "TruthfulQA":46.77,
        "Winogrande":74.51,
        "GSM8K":13.95,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-20-attention-sparsity",
        "Average":52.19,
        "ARC":53.41,
        "HellaSwag":77.91,
        "MMLU":47.49,
        "TruthfulQA":45.84,
        "Winogrande":70.72,
        "GSM8K":17.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Nous-Hermes-13B-SuperHOT-8K-fp16",
        "Average":52.18,
        "ARC":55.29,
        "HellaSwag":81.87,
        "MMLU":48.23,
        "TruthfulQA":51.19,
        "Winogrande":75.3,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-llama-13b-1000-steps",
        "Average":52.18,
        "ARC":58.11,
        "HellaSwag":81.52,
        "MMLU":48.65,
        "TruthfulQA":35.99,
        "Winogrande":77.51,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HyperbeeAI\/Tulpar-7b-v1",
        "Average":52.16,
        "ARC":57.0,
        "HellaSwag":79.69,
        "MMLU":51.33,
        "TruthfulQA":51.83,
        "Winogrande":72.45,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
        "Average":52.15,
        "ARC":57.0,
        "HellaSwag":80.32,
        "MMLU":47.08,
        "TruthfulQA":53.46,
        "Winogrande":74.35,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-1.3-L2-13B",
        "Average":52.15,
        "ARC":56.83,
        "HellaSwag":81.7,
        "MMLU":52.79,
        "TruthfulQA":50.23,
        "Winogrande":71.11,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"xxyyy123\/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
        "Average":52.13,
        "ARC":57.17,
        "HellaSwag":79.57,
        "MMLU":50.24,
        "TruthfulQA":52.51,
        "Winogrande":72.93,
        "GSM8K":0.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"StudentLLM\/Alpagasus-2-13B-QLoRA-pipeline",
        "Average":52.13,
        "ARC":58.28,
        "HellaSwag":80.98,
        "MMLU":54.14,
        "TruthfulQA":34.21,
        "Winogrande":75.93,
        "GSM8K":9.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v16.3-32k",
        "Average":52.13,
        "ARC":26.45,
        "HellaSwag":80.83,
        "MMLU":71.99,
        "TruthfulQA":56.39,
        "Winogrande":77.11,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Biomimicry-AI\/ANIMA-Nectar-v2",
        "Average":52.13,
        "ARC":53.24,
        "HellaSwag":76.63,
        "MMLU":54.21,
        "TruthfulQA":49.04,
        "Winogrande":74.11,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xwin-LM\/Xwin-LM-7B-V0.1",
        "Average":52.08,
        "ARC":56.57,
        "HellaSwag":79.4,
        "MMLU":49.98,
        "TruthfulQA":47.89,
        "Winogrande":73.32,
        "GSM8K":5.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-v1.5",
        "Average":52.06,
        "ARC":53.24,
        "HellaSwag":77.39,
        "MMLU":51.04,
        "TruthfulQA":50.34,
        "Winogrande":72.14,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":207.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/llama2-7b-layla",
        "Average":52.05,
        "ARC":54.18,
        "HellaSwag":79.34,
        "MMLU":49.7,
        "TruthfulQA":46.5,
        "Winogrande":74.11,
        "GSM8K":8.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/L2-7b-Beluga-WVG-Test",
        "Average":52.04,
        "ARC":53.75,
        "HellaSwag":78.38,
        "MMLU":51.57,
        "TruthfulQA":45.76,
        "Winogrande":74.9,
        "GSM8K":7.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lvkaokao\/llama2-7b-hf-chat-lora",
        "Average":52.03,
        "ARC":55.72,
        "HellaSwag":78.75,
        "MMLU":47.99,
        "TruthfulQA":43.11,
        "Winogrande":75.85,
        "GSM8K":10.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-2-7b-instruct",
        "Average":52.02,
        "ARC":56.23,
        "HellaSwag":79.97,
        "MMLU":47.17,
        "TruthfulQA":49.51,
        "Winogrande":75.45,
        "GSM8K":3.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/mistral-7B-alpaca-case-1-2",
        "Average":52.01,
        "ARC":57.34,
        "HellaSwag":79.31,
        "MMLU":56.02,
        "TruthfulQA":44.58,
        "Winogrande":74.82,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-20-sparsity",
        "Average":52.01,
        "ARC":52.47,
        "HellaSwag":77.91,
        "MMLU":47.27,
        "TruthfulQA":45.88,
        "Winogrande":70.72,
        "GSM8K":17.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"haonan-li\/bactrian-x-llama-13b-merged",
        "Average":52.0,
        "ARC":56.4,
        "HellaSwag":79.33,
        "MMLU":48.4,
        "TruthfulQA":48.38,
        "Winogrande":73.95,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-v1.5",
        "Average":51.99,
        "ARC":53.24,
        "HellaSwag":77.39,
        "MMLU":50.82,
        "TruthfulQA":50.33,
        "Winogrande":72.06,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":207.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Qwen-LLaMAfied-7B-Chat",
        "Average":51.99,
        "ARC":50.94,
        "HellaSwag":83.47,
        "MMLU":53.52,
        "TruthfulQA":46.09,
        "Winogrande":73.16,
        "GSM8K":4.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":7.0,
        "Model Sha":101.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-mistral-7b-v13-base",
        "Average":51.99,
        "ARC":52.9,
        "HellaSwag":76.12,
        "MMLU":57.54,
        "TruthfulQA":52.82,
        "Winogrande":71.35,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-general-temporal-merged",
        "Average":51.98,
        "ARC":52.47,
        "HellaSwag":75.83,
        "MMLU":49.09,
        "TruthfulQA":47.06,
        "Winogrande":73.16,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"davzoku\/frankencria-llama2-11b-v1.3-m.1",
        "Average":51.96,
        "ARC":52.82,
        "HellaSwag":77.5,
        "MMLU":48.0,
        "TruthfulQA":46.87,
        "Winogrande":71.59,
        "GSM8K":15.01,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":9.98,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/spicyboros-7b-2.2",
        "Average":51.95,
        "ARC":56.57,
        "HellaSwag":80.09,
        "MMLU":48.47,
        "TruthfulQA":47.22,
        "Winogrande":74.51,
        "GSM8K":4.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xxyyy123\/10k_v1_lora_qkvo_rank28_v2",
        "Average":51.95,
        "ARC":55.38,
        "HellaSwag":79.21,
        "MMLU":50.5,
        "TruthfulQA":52.75,
        "Winogrande":73.24,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"pe-nlp\/llama-2-13b-vicuna-wizard",
        "Average":51.94,
        "ARC":57.76,
        "HellaSwag":82.16,
        "MMLU":54.68,
        "TruthfulQA":41.11,
        "Winogrande":74.98,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chinoll\/Yi-6b-200k-dpo",
        "Average":51.93,
        "ARC":43.09,
        "HellaSwag":74.53,
        "MMLU":64.0,
        "TruthfulQA":45.51,
        "Winogrande":73.09,
        "GSM8K":11.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"chinoll\/Yi-7b-dpo",
        "Average":51.93,
        "ARC":43.09,
        "HellaSwag":74.53,
        "MMLU":64.0,
        "TruthfulQA":45.51,
        "Winogrande":73.09,
        "GSM8K":11.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"indischepartij\/MiniCPM-3B-OpenHermes-2.5-v2",
        "Average":51.91,
        "ARC":47.44,
        "HellaSwag":72.0,
        "MMLU":53.06,
        "TruthfulQA":42.28,
        "Winogrande":65.43,
        "GSM8K":31.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.01,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-llama-2-7b",
        "Average":51.87,
        "ARC":55.12,
        "HellaSwag":78.94,
        "MMLU":48.34,
        "TruthfulQA":49.01,
        "Winogrande":74.03,
        "GSM8K":5.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "mit"
        ],
        "Available on the Hub":6.74,
        "Model Sha":64.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-zephyr-7b-v14.1",
        "Average":51.86,
        "ARC":52.13,
        "HellaSwag":75.02,
        "MMLU":56.21,
        "TruthfulQA":49.84,
        "Winogrande":73.24,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ashercn97\/manatee-7b",
        "Average":51.84,
        "ARC":54.52,
        "HellaSwag":78.95,
        "MMLU":49.26,
        "TruthfulQA":46.77,
        "Winogrande":74.51,
        "GSM8K":7.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"migtissera\/Synthia-7B",
        "Average":51.83,
        "ARC":56.14,
        "HellaSwag":78.6,
        "MMLU":50.35,
        "TruthfulQA":45.03,
        "Winogrande":74.27,
        "GSM8K":6.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Medusa-1.1-L2-7B",
        "Average":51.8,
        "ARC":56.48,
        "HellaSwag":78.57,
        "MMLU":51.56,
        "TruthfulQA":47.7,
        "Winogrande":75.06,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-30-attention-sparsity",
        "Average":51.8,
        "ARC":53.41,
        "HellaSwag":76.87,
        "MMLU":47.04,
        "TruthfulQA":45.02,
        "Winogrande":71.03,
        "GSM8K":17.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elliotthwang\/Elliott-Chinese-LLaMa-GPTQ",
        "Average":51.79,
        "ARC":51.02,
        "HellaSwag":75.23,
        "MMLU":49.58,
        "TruthfulQA":45.09,
        "Winogrande":72.61,
        "GSM8K":17.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":53.9,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Stheno-Mix-L2-20B",
        "Average":51.79,
        "ARC":57.76,
        "HellaSwag":79.63,
        "MMLU":52.51,
        "TruthfulQA":51.8,
        "Winogrande":68.98,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":20.63,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"umd-zhou-lab\/recycled-wizardlm-7b-v2.0",
        "Average":51.79,
        "ARC":54.95,
        "HellaSwag":77.85,
        "MMLU":45.79,
        "TruthfulQA":48.29,
        "Winogrande":71.51,
        "GSM8K":12.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-13b-gpt4-1.3",
        "Average":51.76,
        "ARC":58.53,
        "HellaSwag":81.6,
        "MMLU":46.96,
        "TruthfulQA":45.29,
        "Winogrande":75.85,
        "GSM8K":2.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LLMNewbie\/vic_critT_20pr",
        "Average":51.75,
        "ARC":51.62,
        "HellaSwag":76.39,
        "MMLU":47.66,
        "TruthfulQA":51.93,
        "Winogrande":74.27,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":10.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Llama-2-7b-chat-hf-gpt-3.5-80k",
        "Average":51.75,
        "ARC":52.05,
        "HellaSwag":73.89,
        "MMLU":48.19,
        "TruthfulQA":44.35,
        "Winogrande":71.98,
        "GSM8K":20.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/llama-2-7b-miniguanaco",
        "Average":51.74,
        "ARC":50.0,
        "HellaSwag":76.96,
        "MMLU":48.05,
        "TruthfulQA":42.84,
        "Winogrande":73.48,
        "GSM8K":19.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lazycuber\/L2-7b-Orca-WVG-Test",
        "Average":51.72,
        "ARC":54.86,
        "HellaSwag":78.25,
        "MMLU":51.13,
        "TruthfulQA":43.68,
        "Winogrande":74.35,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Azure99\/blossom-v2-llama2-7b",
        "Average":51.71,
        "ARC":54.1,
        "HellaSwag":78.57,
        "MMLU":51.66,
        "TruthfulQA":46.84,
        "Winogrande":74.35,
        "GSM8K":4.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TheSkullery\/Aurora_22e_Test",
        "Average":51.71,
        "ARC":44.8,
        "HellaSwag":64.97,
        "MMLU":62.27,
        "TruthfulQA":50.91,
        "Winogrande":77.9,
        "GSM8K":9.4,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.04,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jphme\/em_german_leo_mistral",
        "Average":51.69,
        "ARC":52.82,
        "HellaSwag":78.03,
        "MMLU":50.03,
        "TruthfulQA":50.19,
        "Winogrande":73.48,
        "GSM8K":5.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":61.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"haoranxu\/ALMA-13B-Pretrain",
        "Average":51.68,
        "ARC":56.91,
        "HellaSwag":80.15,
        "MMLU":50.31,
        "TruthfulQA":37.44,
        "Winogrande":76.4,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-ziya-13b",
        "Average":51.67,
        "ARC":55.38,
        "HellaSwag":78.47,
        "MMLU":45.18,
        "TruthfulQA":49.29,
        "Winogrande":74.82,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"TencentARC\/LLaMA-Pro-8B",
        "Average":51.67,
        "ARC":53.75,
        "HellaSwag":77.91,
        "MMLU":47.49,
        "TruthfulQA":38.86,
        "Winogrande":74.19,
        "GSM8K":17.82,
        "Type":"continuously pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":8.36,
        "Model Sha":165.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/llama_ppo_1e6_new_tokenizerstep_8000",
        "Average":51.67,
        "ARC":54.78,
        "HellaSwag":78.64,
        "MMLU":46.63,
        "TruthfulQA":41.06,
        "Winogrande":74.03,
        "GSM8K":14.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/L2-7b-Base-test-WVG",
        "Average":51.66,
        "ARC":54.27,
        "HellaSwag":77.81,
        "MMLU":51.07,
        "TruthfulQA":46.28,
        "Winogrande":73.56,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rombodawg\/LosslessMegaCoder-llama2-7b-mini",
        "Average":51.66,
        "ARC":53.5,
        "HellaSwag":77.38,
        "MMLU":49.72,
        "TruthfulQA":45.77,
        "Winogrande":74.03,
        "GSM8K":9.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/llama_sft_longer",
        "Average":51.64,
        "ARC":54.78,
        "HellaSwag":78.58,
        "MMLU":46.87,
        "TruthfulQA":40.82,
        "Winogrande":73.88,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hongzoh\/Yi-6B_Open-Platypus-v2",
        "Average":51.64,
        "ARC":49.91,
        "HellaSwag":72.18,
        "MMLU":57.59,
        "TruthfulQA":42.34,
        "Winogrande":71.98,
        "GSM8K":15.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Average":51.64,
        "ARC":52.3,
        "HellaSwag":77.63,
        "MMLU":23.12,
        "TruthfulQA":42.4,
        "Winogrande":78.53,
        "GSM8K":35.86,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.96,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elliotthwang\/Elliott-Chinese-LLaMa-GPTQ-V1.0",
        "Average":51.64,
        "ARC":50.68,
        "HellaSwag":75.36,
        "MMLU":49.33,
        "TruthfulQA":44.7,
        "Winogrande":72.38,
        "GSM8K":17.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":53.9,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheBloke\/stable-vicuna-13B-HF",
        "Average":51.64,
        "ARC":53.33,
        "HellaSwag":78.5,
        "MMLU":50.29,
        "TruthfulQA":48.38,
        "Winogrande":75.22,
        "GSM8K":4.09,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":13.0,
        "Model Sha":96.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/Platypus2xOpenOrca-13B-LoRa-v2",
        "Average":51.61,
        "ARC":58.62,
        "HellaSwag":81.17,
        "MMLU":50.23,
        "TruthfulQA":43.43,
        "Winogrande":76.16,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/llama_ppo_1e6step_4000",
        "Average":51.61,
        "ARC":54.44,
        "HellaSwag":78.66,
        "MMLU":46.74,
        "TruthfulQA":41.24,
        "Winogrande":74.19,
        "GSM8K":14.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rufjdk5480\/llama-7b-ludwig-alpaca",
        "Average":51.6,
        "ARC":54.01,
        "HellaSwag":78.73,
        "MMLU":45.8,
        "TruthfulQA":41.91,
        "Winogrande":74.27,
        "GSM8K":14.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhinand\/tamil-llama-13b-instruct-v0.1",
        "Average":51.59,
        "ARC":54.52,
        "HellaSwag":79.35,
        "MMLU":50.37,
        "TruthfulQA":41.22,
        "Winogrande":76.56,
        "GSM8K":7.51,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-v1.5-16k",
        "Average":51.58,
        "ARC":54.69,
        "HellaSwag":77.32,
        "MMLU":49.51,
        "TruthfulQA":50.41,
        "Winogrande":71.11,
        "GSM8K":6.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":82.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Envoid\/Yousei-22B",
        "Average":51.56,
        "ARC":55.89,
        "HellaSwag":78.55,
        "MMLU":52.31,
        "TruthfulQA":50.68,
        "Winogrande":71.51,
        "GSM8K":0.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":21.83,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-MysteryModel-13b",
        "Average":51.54,
        "ARC":57.0,
        "HellaSwag":80.35,
        "MMLU":52.06,
        "TruthfulQA":45.0,
        "Winogrande":74.82,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lvkaokao\/llama2-7b-hf-instruction-lora",
        "Average":51.54,
        "ARC":55.38,
        "HellaSwag":78.57,
        "MMLU":49.39,
        "TruthfulQA":41.83,
        "Winogrande":74.19,
        "GSM8K":9.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-c34b-2.1",
        "Average":51.52,
        "ARC":54.69,
        "HellaSwag":76.45,
        "MMLU":55.08,
        "TruthfulQA":46.15,
        "Winogrande":68.43,
        "GSM8K":8.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeneZC\/MiniChat-2-3B",
        "Average":51.49,
        "ARC":44.88,
        "HellaSwag":67.69,
        "MMLU":47.59,
        "TruthfulQA":49.64,
        "Winogrande":66.46,
        "GSM8K":32.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-deepseek-10b-v17.1-4k",
        "Average":51.48,
        "ARC":54.35,
        "HellaSwag":76.93,
        "MMLU":53.17,
        "TruthfulQA":45.96,
        "Winogrande":74.03,
        "GSM8K":4.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":10.55,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-math-7b-instruct",
        "Average":51.48,
        "ARC":53.58,
        "HellaSwag":71.53,
        "MMLU":56.55,
        "TruthfulQA":40.38,
        "Winogrande":65.98,
        "GSM8K":20.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elliotthwang\/Elliott-Chinese-LLaMa-GPTQ-V2.0",
        "Average":51.47,
        "ARC":50.77,
        "HellaSwag":75.36,
        "MMLU":49.41,
        "TruthfulQA":44.7,
        "Winogrande":72.61,
        "GSM8K":16.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/vicuna-7b-v1.5-PL-lora_unload",
        "Average":51.46,
        "ARC":53.5,
        "HellaSwag":76.74,
        "MMLU":49.69,
        "TruthfulQA":49.68,
        "Winogrande":71.98,
        "GSM8K":7.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-tutor-7b-ep3",
        "Average":51.45,
        "ARC":52.13,
        "HellaSwag":78.07,
        "MMLU":51.32,
        "TruthfulQA":52.3,
        "Winogrande":71.19,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Pwen-VL-Chat-20_30",
        "Average":51.45,
        "ARC":50.17,
        "HellaSwag":72.21,
        "MMLU":56.34,
        "TruthfulQA":42.52,
        "Winogrande":68.35,
        "GSM8K":19.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"amazon\/MistralLite",
        "Average":51.45,
        "ARC":59.56,
        "HellaSwag":81.84,
        "MMLU":50.93,
        "TruthfulQA":37.87,
        "Winogrande":77.43,
        "GSM8K":1.06,
        "Type":"",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":417.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frank098\/WizardLM_13B_juniper",
        "Average":51.45,
        "ARC":55.38,
        "HellaSwag":77.2,
        "MMLU":45.46,
        "TruthfulQA":51.5,
        "Winogrande":71.11,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama2_7b_zh",
        "Average":51.44,
        "ARC":52.05,
        "HellaSwag":74.88,
        "MMLU":60.69,
        "TruthfulQA":42.86,
        "Winogrande":71.74,
        "GSM8K":6.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tlphams\/zoyllm-7b-slimorca",
        "Average":51.44,
        "ARC":50.6,
        "HellaSwag":72.12,
        "MMLU":48.78,
        "TruthfulQA":49.13,
        "Winogrande":67.32,
        "GSM8K":20.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"camel-ai\/CAMEL-13B-Role-Playing-Data",
        "Average":51.42,
        "ARC":54.95,
        "HellaSwag":79.25,
        "MMLU":46.61,
        "TruthfulQA":46.35,
        "Winogrande":74.03,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-v1.5-16k",
        "Average":51.42,
        "ARC":54.18,
        "HellaSwag":77.31,
        "MMLU":49.3,
        "TruthfulQA":50.35,
        "Winogrande":71.03,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":82.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hiyouga\/Baichuan2-7B-Chat-LLaMAfied",
        "Average":51.42,
        "ARC":52.47,
        "HellaSwag":74.04,
        "MMLU":53.88,
        "TruthfulQA":48.04,
        "Winogrande":69.14,
        "GSM8K":10.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nkpz\/llama2-22b-daydreamer-v3",
        "Average":51.39,
        "ARC":56.06,
        "HellaSwag":80.07,
        "MMLU":52.49,
        "TruthfulQA":42.43,
        "Winogrande":73.48,
        "GSM8K":3.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":22.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hpcai-tech\/Colossal-LLaMA-2-7b-base",
        "Average":51.39,
        "ARC":53.5,
        "HellaSwag":70.5,
        "MMLU":54.4,
        "TruthfulQA":50.19,
        "Winogrande":70.01,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Open-Orca\/OpenOrca-Preview1-13B",
        "Average":51.38,
        "ARC":54.95,
        "HellaSwag":78.19,
        "MMLU":50.12,
        "TruthfulQA":49.05,
        "Winogrande":71.03,
        "GSM8K":4.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":148.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/kuchiki-1.1-l2-7b",
        "Average":51.36,
        "ARC":54.18,
        "HellaSwag":78.0,
        "MMLU":48.14,
        "TruthfulQA":49.96,
        "Winogrande":73.16,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggingface\/llama-13b",
        "Average":51.36,
        "ARC":56.23,
        "HellaSwag":80.93,
        "MMLU":47.67,
        "TruthfulQA":39.48,
        "Winogrande":76.24,
        "GSM8K":7.58,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/L2-7b-Hermes-WVG-Test",
        "Average":51.35,
        "ARC":54.95,
        "HellaSwag":78.48,
        "MMLU":48.36,
        "TruthfulQA":45.72,
        "Winogrande":74.74,
        "GSM8K":5.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-13b",
        "Average":51.33,
        "ARC":56.14,
        "HellaSwag":80.92,
        "MMLU":47.61,
        "TruthfulQA":39.48,
        "Winogrande":76.24,
        "GSM8K":7.58,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":130.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/kuchiki-l2-7b",
        "Average":51.33,
        "ARC":54.35,
        "HellaSwag":78.44,
        "MMLU":47.74,
        "TruthfulQA":49.88,
        "Winogrande":73.09,
        "GSM8K":4.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jordiclive\/gpt4all-alpaca-oa-codealpaca-lora-13b",
        "Average":51.33,
        "ARC":56.14,
        "HellaSwag":80.93,
        "MMLU":47.66,
        "TruthfulQA":39.48,
        "Winogrande":76.16,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"selfrag\/selfrag_llama2_7b",
        "Average":51.3,
        "ARC":51.45,
        "HellaSwag":78.48,
        "MMLU":52.0,
        "TruthfulQA":41.73,
        "Winogrande":73.16,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"leonarad\/hope_for",
        "Average":51.3,
        "ARC":51.28,
        "HellaSwag":74.74,
        "MMLU":51.56,
        "TruthfulQA":40.73,
        "Winogrande":72.61,
        "GSM8K":16.91,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tap-M\/Luna-AI-Llama2-Uncensored",
        "Average":51.29,
        "ARC":54.35,
        "HellaSwag":78.6,
        "MMLU":46.7,
        "TruthfulQA":45.5,
        "Winogrande":72.77,
        "GSM8K":9.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.0,
        "Model Sha":126.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zarablend-l2-7b",
        "Average":51.29,
        "ARC":54.44,
        "HellaSwag":78.62,
        "MMLU":47.61,
        "TruthfulQA":49.38,
        "Winogrande":73.32,
        "GSM8K":4.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/finetuned-llama2-chat-5000-v2.0",
        "Average":51.28,
        "ARC":52.05,
        "HellaSwag":76.13,
        "MMLU":46.33,
        "TruthfulQA":45.18,
        "Winogrande":72.3,
        "GSM8K":15.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/Rhino-Mistral-7B",
        "Average":51.27,
        "ARC":48.12,
        "HellaSwag":71.42,
        "MMLU":48.95,
        "TruthfulQA":45.9,
        "Winogrande":71.11,
        "GSM8K":22.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hyunseoki\/ko-en-llama2-13b",
        "Average":51.27,
        "ARC":58.19,
        "HellaSwag":81.89,
        "MMLU":52.02,
        "TruthfulQA":39.96,
        "Winogrande":74.82,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/OpenHermes-7B",
        "Average":51.26,
        "ARC":56.14,
        "HellaSwag":78.32,
        "MMLU":48.62,
        "TruthfulQA":45.0,
        "Winogrande":74.51,
        "GSM8K":5.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Norquinal\/llama-2-7b-claude-chat-rp",
        "Average":51.25,
        "ARC":54.95,
        "HellaSwag":80.05,
        "MMLU":47.03,
        "TruthfulQA":43.47,
        "Winogrande":74.74,
        "GSM8K":7.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zarablend-1.1-l2-7b",
        "Average":51.25,
        "ARC":54.86,
        "HellaSwag":78.58,
        "MMLU":47.89,
        "TruthfulQA":49.0,
        "Winogrande":72.61,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/L2-7b-Synthia-WVG-Test",
        "Average":51.25,
        "ARC":55.97,
        "HellaSwag":77.89,
        "MMLU":49.48,
        "TruthfulQA":44.11,
        "Winogrande":74.11,
        "GSM8K":5.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airoboros-l2-7b-2.2.1",
        "Average":51.22,
        "ARC":55.03,
        "HellaSwag":80.06,
        "MMLU":47.64,
        "TruthfulQA":44.65,
        "Winogrande":73.8,
        "GSM8K":6.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Harshvir\/Llama-2-7B-physics",
        "Average":51.22,
        "ARC":52.9,
        "HellaSwag":77.71,
        "MMLU":48.83,
        "TruthfulQA":48.93,
        "Winogrande":71.9,
        "GSM8K":7.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ncsgobubble\/Llama-7B-rollercoaster_v2",
        "Average":51.2,
        "ARC":52.82,
        "HellaSwag":78.22,
        "MMLU":49.8,
        "TruthfulQA":43.62,
        "Winogrande":73.16,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Joseph717171\/Tess-10.7B-v2.0",
        "Average":51.18,
        "ARC":55.12,
        "HellaSwag":74.4,
        "MMLU":50.09,
        "TruthfulQA":44.63,
        "Winogrande":65.27,
        "GSM8K":17.59,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"klyang\/MentaLLaMA-chat-7B",
        "Average":51.17,
        "ARC":52.82,
        "HellaSwag":76.1,
        "MMLU":47.51,
        "TruthfulQA":44.02,
        "Winogrande":70.4,
        "GSM8K":16.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/koala-13B-HF",
        "Average":51.16,
        "ARC":52.99,
        "HellaSwag":77.59,
        "MMLU":45.32,
        "TruthfulQA":50.23,
        "Winogrande":74.03,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":41.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"leonarad\/hope_for_7b_1.0v",
        "Average":51.16,
        "ARC":50.43,
        "HellaSwag":76.44,
        "MMLU":49.68,
        "TruthfulQA":38.66,
        "Winogrande":75.22,
        "GSM8K":16.53,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"moondriller\/llama2-13B-eugeneparkthebest",
        "Average":51.15,
        "ARC":53.41,
        "HellaSwag":79.25,
        "MMLU":48.28,
        "TruthfulQA":44.42,
        "Winogrande":73.32,
        "GSM8K":8.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.16,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"64bits\/LexPodLM-13B",
        "Average":51.14,
        "ARC":57.76,
        "HellaSwag":81.04,
        "MMLU":48.38,
        "TruthfulQA":43.48,
        "Winogrande":76.16,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":64.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FlagAlpha\/Llama2-Chinese-7b-Chat",
        "Average":51.13,
        "ARC":52.39,
        "HellaSwag":77.52,
        "MMLU":47.72,
        "TruthfulQA":46.87,
        "Winogrande":74.27,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":202.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BelalTab\/finetuned-llama2-2048-v3.0",
        "Average":51.13,
        "ARC":49.83,
        "HellaSwag":77.09,
        "MMLU":46.69,
        "TruthfulQA":46.21,
        "Winogrande":72.06,
        "GSM8K":14.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/vicuna-7b-v1.3-attention-sparsity-10",
        "Average":51.13,
        "ARC":52.22,
        "HellaSwag":77.05,
        "MMLU":47.93,
        "TruthfulQA":46.87,
        "Winogrande":69.53,
        "GSM8K":13.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ericpolewski\/AIRIC-The-Intern",
        "Average":51.13,
        "ARC":52.73,
        "HellaSwag":77.07,
        "MMLU":51.92,
        "TruthfulQA":52.67,
        "Winogrande":70.88,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":20.09,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Average":51.13,
        "ARC":55.03,
        "HellaSwag":79.9,
        "MMLU":53.73,
        "TruthfulQA":40.48,
        "Winogrande":74.74,
        "GSM8K":2.88,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":25.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/doctorLLM",
        "Average":51.12,
        "ARC":52.9,
        "HellaSwag":79.76,
        "MMLU":46.47,
        "TruthfulQA":42.52,
        "Winogrande":71.59,
        "GSM8K":13.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"totally-not-an-llm\/EverythingLM-13b-V3-16k",
        "Average":51.11,
        "ARC":58.19,
        "HellaSwag":80.12,
        "MMLU":50.48,
        "TruthfulQA":45.18,
        "Winogrande":70.72,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-2-7b",
        "Average":51.11,
        "ARC":54.01,
        "HellaSwag":78.23,
        "MMLU":49.11,
        "TruthfulQA":43.78,
        "Winogrande":75.14,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":51.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/finetuned-llama2-chat-5000-v1.0-squad",
        "Average":51.09,
        "ARC":50.94,
        "HellaSwag":76.61,
        "MMLU":46.43,
        "TruthfulQA":44.45,
        "Winogrande":71.98,
        "GSM8K":16.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"umd-zhou-lab\/recycled-alpaca-7b-v2.0",
        "Average":51.09,
        "ARC":54.18,
        "HellaSwag":77.98,
        "MMLU":46.79,
        "TruthfulQA":45.4,
        "Winogrande":71.35,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/llama2guanacotest",
        "Average":51.08,
        "ARC":51.62,
        "HellaSwag":77.55,
        "MMLU":48.49,
        "TruthfulQA":43.88,
        "Winogrande":73.16,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/Samantha-1.11-7b",
        "Average":51.07,
        "ARC":55.03,
        "HellaSwag":79.12,
        "MMLU":40.51,
        "TruthfulQA":50.37,
        "Winogrande":74.19,
        "GSM8K":7.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Wanfq\/FuseLLM-7B",
        "Average":51.07,
        "ARC":53.24,
        "HellaSwag":78.72,
        "MMLU":47.93,
        "TruthfulQA":38.17,
        "Winogrande":74.03,
        "GSM8K":14.33,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"deepseek-ai\/deepseek-moe-16b-base",
        "Average":51.07,
        "ARC":53.24,
        "HellaSwag":79.77,
        "MMLU":46.31,
        "TruthfulQA":36.08,
        "Winogrande":73.72,
        "GSM8K":17.29,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.38,
        "Model Sha":68.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HWERI\/Llama2-7b-sharegpt4",
        "Average":51.05,
        "ARC":55.72,
        "HellaSwag":80.94,
        "MMLU":47.47,
        "TruthfulQA":48.34,
        "Winogrande":71.19,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beaugogh\/Llama2-7b-sharegpt4",
        "Average":51.05,
        "ARC":55.72,
        "HellaSwag":80.94,
        "MMLU":47.47,
        "TruthfulQA":48.34,
        "Winogrande":71.19,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"heegyu\/WizardVicuna2-13b-hf",
        "Average":51.05,
        "ARC":55.38,
        "HellaSwag":79.14,
        "MMLU":48.46,
        "TruthfulQA":42.43,
        "Winogrande":73.48,
        "GSM8K":7.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"minghaowu\/phi-2-OpenHermes-2.5",
        "Average":51.05,
        "ARC":56.48,
        "HellaSwag":73.88,
        "MMLU":54.8,
        "TruthfulQA":48.1,
        "Winogrande":73.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikael110\/llama-2-7b-guanaco-fp16",
        "Average":51.04,
        "ARC":54.86,
        "HellaSwag":79.65,
        "MMLU":46.38,
        "TruthfulQA":43.83,
        "Winogrande":75.22,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziqingyang\/chinese-llama-2-13b",
        "Average":51.04,
        "ARC":55.8,
        "HellaSwag":79.53,
        "MMLU":53.01,
        "TruthfulQA":38.24,
        "Winogrande":75.69,
        "GSM8K":3.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-math-7b-instruct",
        "Average":51.03,
        "ARC":53.41,
        "HellaSwag":71.5,
        "MMLU":55.97,
        "TruthfulQA":40.16,
        "Winogrande":65.75,
        "GSM8K":19.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":58.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wang7776\/vicuna-7b-v1.3-sparsity-10",
        "Average":51.02,
        "ARC":51.45,
        "HellaSwag":76.98,
        "MMLU":47.95,
        "TruthfulQA":46.88,
        "Winogrande":69.77,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Llama-2-7b-chat-hf-30-sparsity",
        "Average":51.02,
        "ARC":52.47,
        "HellaSwag":76.58,
        "MMLU":45.57,
        "TruthfulQA":44.82,
        "Winogrande":69.61,
        "GSM8K":17.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lorinma\/yi6B_Vicuna",
        "Average":51.02,
        "ARC":46.16,
        "HellaSwag":69.3,
        "MMLU":58.43,
        "TruthfulQA":48.11,
        "Winogrande":65.67,
        "GSM8K":18.42,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Delcos\/Mistral-Pygmalion-7b",
        "Average":51.02,
        "ARC":54.44,
        "HellaSwag":78.48,
        "MMLU":49.23,
        "TruthfulQA":41.82,
        "Winogrande":75.3,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/llama2-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general",
        "Average":50.98,
        "ARC":53.16,
        "HellaSwag":78.59,
        "MMLU":46.89,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":14.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Norquinal\/llama-2-7b-claude-chat",
        "Average":50.98,
        "ARC":54.44,
        "HellaSwag":80.66,
        "MMLU":46.74,
        "TruthfulQA":41.39,
        "Winogrande":74.9,
        "GSM8K":7.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AlekseyKorshuk\/vic15-exp-syn-fight-cp3838",
        "Average":50.97,
        "ARC":51.79,
        "HellaSwag":75.79,
        "MMLU":50.23,
        "TruthfulQA":49.61,
        "Winogrande":71.82,
        "GSM8K":6.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Average":50.97,
        "ARC":53.07,
        "HellaSwag":78.59,
        "MMLU":46.87,
        "TruthfulQA":38.76,
        "Winogrande":74.03,
        "GSM8K":14.48,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":1263.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"formulae\/Dorflan",
        "Average":50.96,
        "ARC":54.44,
        "HellaSwag":75.78,
        "MMLU":51.36,
        "TruthfulQA":51.17,
        "Winogrande":72.61,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/base_7b",
        "Average":50.95,
        "ARC":53.16,
        "HellaSwag":78.59,
        "MMLU":46.78,
        "TruthfulQA":38.74,
        "Winogrande":73.88,
        "GSM8K":14.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maldv\/SHRDFU-7b-delta",
        "Average":50.95,
        "ARC":54.18,
        "HellaSwag":77.55,
        "MMLU":55.95,
        "TruthfulQA":46.74,
        "Winogrande":71.27,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/llama-2-7b-instruct-peft",
        "Average":50.94,
        "ARC":51.19,
        "HellaSwag":78.92,
        "MMLU":46.63,
        "TruthfulQA":48.5,
        "Winogrande":74.43,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/LLaMa-2-PeanutButter_v18_B-7B",
        "Average":50.94,
        "ARC":54.61,
        "HellaSwag":81.0,
        "MMLU":47.07,
        "TruthfulQA":41.93,
        "Winogrande":74.51,
        "GSM8K":6.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"davzoku\/cria-llama2-7b-v1.3",
        "Average":50.93,
        "ARC":52.73,
        "HellaSwag":78.58,
        "MMLU":48.3,
        "TruthfulQA":45.58,
        "Winogrande":71.9,
        "GSM8K":8.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-100step-v2",
        "Average":50.89,
        "ARC":52.65,
        "HellaSwag":78.25,
        "MMLU":48.47,
        "TruthfulQA":45.18,
        "Winogrande":72.3,
        "GSM8K":8.49,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"deepseek-ai\/deepseek-coder-7b-instruct-v1.5",
        "Average":50.89,
        "ARC":48.55,
        "HellaSwag":72.35,
        "MMLU":50.45,
        "TruthfulQA":46.73,
        "Winogrande":66.85,
        "GSM8K":20.39,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.91,
        "Model Sha":71.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-7b",
        "Average":50.87,
        "ARC":55.12,
        "HellaSwag":77.4,
        "MMLU":49.27,
        "TruthfulQA":43.64,
        "Winogrande":73.64,
        "GSM8K":6.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Covasna-0.1",
        "Average":50.87,
        "ARC":48.81,
        "HellaSwag":70.07,
        "MMLU":61.9,
        "TruthfulQA":52.64,
        "Winogrande":70.8,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":41.6,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-Llama2-13b-v1.0",
        "Average":50.85,
        "ARC":51.45,
        "HellaSwag":78.57,
        "MMLU":50.99,
        "TruthfulQA":45.17,
        "Winogrande":74.35,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.26,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-13b-2.1",
        "Average":50.84,
        "ARC":55.12,
        "HellaSwag":80.24,
        "MMLU":50.89,
        "TruthfulQA":44.62,
        "Winogrande":71.9,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/Guanaco-Vicuna-7B-L2",
        "Average":50.83,
        "ARC":53.24,
        "HellaSwag":78.89,
        "MMLU":46.77,
        "TruthfulQA":42.75,
        "Winogrande":75.37,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Rijgersberg\/GEITje-7B-chat-v2",
        "Average":50.79,
        "ARC":50.34,
        "HellaSwag":74.13,
        "MMLU":49.0,
        "TruthfulQA":43.55,
        "Winogrande":71.51,
        "GSM8K":16.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tyson0420\/stack_llama_fil_ai",
        "Average":50.79,
        "ARC":53.5,
        "HellaSwag":78.63,
        "MMLU":46.23,
        "TruthfulQA":38.72,
        "Winogrande":74.82,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama2-13b-pretrain",
        "Average":50.77,
        "ARC":53.92,
        "HellaSwag":79.1,
        "MMLU":51.25,
        "TruthfulQA":36.24,
        "Winogrande":75.53,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/LLaMa-2-PeanutButter_v10-7B",
        "Average":50.75,
        "ARC":55.29,
        "HellaSwag":81.69,
        "MMLU":46.97,
        "TruthfulQA":43.78,
        "Winogrande":70.88,
        "GSM8K":5.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"meta-llama\/Llama-2-7b-chat-hf",
        "Average":50.74,
        "ARC":52.9,
        "HellaSwag":78.55,
        "MMLU":48.32,
        "TruthfulQA":45.57,
        "Winogrande":71.74,
        "GSM8K":7.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":3252.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-timedial-unit-080082",
        "Average":50.74,
        "ARC":52.82,
        "HellaSwag":76.07,
        "MMLU":50.47,
        "TruthfulQA":43.54,
        "Winogrande":73.72,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tyson0420\/stack_llama_fil_ai",
        "Average":50.74,
        "ARC":53.75,
        "HellaSwag":78.59,
        "MMLU":46.5,
        "TruthfulQA":38.7,
        "Winogrande":74.74,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"declare-lab\/starling-7B",
        "Average":50.73,
        "ARC":51.02,
        "HellaSwag":76.77,
        "MMLU":47.75,
        "TruthfulQA":48.18,
        "Winogrande":70.56,
        "GSM8K":10.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"davzoku\/frankencria-llama2-12.5b-v1.3-m.2",
        "Average":50.72,
        "ARC":55.03,
        "HellaSwag":79.17,
        "MMLU":46.16,
        "TruthfulQA":50.31,
        "Winogrande":70.24,
        "GSM8K":3.41,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":12.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-timedial-unit-080091",
        "Average":50.71,
        "ARC":52.82,
        "HellaSwag":76.1,
        "MMLU":50.58,
        "TruthfulQA":43.4,
        "Winogrande":73.72,
        "GSM8K":7.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Replete-AI\/Phi-5B-Test",
        "Average":50.71,
        "ARC":54.61,
        "HellaSwag":67.6,
        "MMLU":54.31,
        "TruthfulQA":45.66,
        "Winogrande":71.98,
        "GSM8K":10.08,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":5.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/doctorLLM10k",
        "Average":50.7,
        "ARC":54.95,
        "HellaSwag":79.94,
        "MMLU":44.4,
        "TruthfulQA":44.76,
        "Winogrande":70.01,
        "GSM8K":10.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-sparsity-20",
        "Average":50.7,
        "ARC":52.65,
        "HellaSwag":76.71,
        "MMLU":47.27,
        "TruthfulQA":47.22,
        "Winogrande":69.06,
        "GSM8K":11.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tyson0420\/stack_llama-clang",
        "Average":50.69,
        "ARC":54.1,
        "HellaSwag":78.93,
        "MMLU":45.97,
        "TruthfulQA":38.65,
        "Winogrande":74.11,
        "GSM8K":12.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"revolutionarybukhari\/Llama-2-7b-chat-finetune-AUTOMATE",
        "Average":50.68,
        "ARC":53.07,
        "HellaSwag":75.59,
        "MMLU":48.8,
        "TruthfulQA":44.73,
        "Winogrande":73.24,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tyson0420\/stack_llama_full",
        "Average":50.68,
        "ARC":54.27,
        "HellaSwag":78.76,
        "MMLU":45.55,
        "TruthfulQA":40.26,
        "Winogrande":73.48,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"psyche\/kollama2-7b-v2",
        "Average":50.66,
        "ARC":53.33,
        "HellaSwag":78.5,
        "MMLU":43.61,
        "TruthfulQA":46.37,
        "Winogrande":75.61,
        "GSM8K":6.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Llama-2-7b-hf-llama2-raw-80k",
        "Average":50.65,
        "ARC":53.41,
        "HellaSwag":78.62,
        "MMLU":46.26,
        "TruthfulQA":38.82,
        "Winogrande":74.66,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vonjack\/Qwen-LLaMAfied-HFTok-7B-Chat",
        "Average":50.64,
        "ARC":50.51,
        "HellaSwag":83.65,
        "MMLU":51.53,
        "TruthfulQA":44.23,
        "Winogrande":71.43,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-7b_10e4",
        "Average":50.63,
        "ARC":53.84,
        "HellaSwag":78.46,
        "MMLU":46.76,
        "TruthfulQA":38.29,
        "Winogrande":73.48,
        "GSM8K":12.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/vicuna-7b-v1.3-attention-sparsity-20",
        "Average":50.63,
        "ARC":52.3,
        "HellaSwag":77.05,
        "MMLU":47.39,
        "TruthfulQA":46.62,
        "Winogrande":69.22,
        "GSM8K":11.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LTC-AI-Labs\/L2-7b-Base-WVG-Uncensored",
        "Average":50.63,
        "ARC":53.24,
        "HellaSwag":79.13,
        "MMLU":46.65,
        "TruthfulQA":42.59,
        "Winogrande":75.14,
        "GSM8K":7.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"XuanXuanXuanXuan\/Llama-2-7b-hf-gpt-3.5-80k",
        "Average":50.63,
        "ARC":53.84,
        "HellaSwag":75.75,
        "MMLU":46.0,
        "TruthfulQA":41.42,
        "Winogrande":72.14,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DopeorNope\/LaOT",
        "Average":50.62,
        "ARC":55.63,
        "HellaSwag":78.96,
        "MMLU":50.3,
        "TruthfulQA":44.72,
        "Winogrande":74.11,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-hf-gpt-3.5-80k",
        "Average":50.62,
        "ARC":53.84,
        "HellaSwag":75.77,
        "MMLU":45.98,
        "TruthfulQA":41.42,
        "Winogrande":72.06,
        "GSM8K":14.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zarakiquemparte\/zaraxls-l2-7b",
        "Average":50.61,
        "ARC":54.44,
        "HellaSwag":78.94,
        "MMLU":50.39,
        "TruthfulQA":46.51,
        "Winogrande":73.16,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/doctorLLM5k",
        "Average":50.6,
        "ARC":52.47,
        "HellaSwag":79.66,
        "MMLU":44.68,
        "TruthfulQA":43.14,
        "Winogrande":69.53,
        "GSM8K":14.1,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/ANIMA-Nectar-v3",
        "Average":50.58,
        "ARC":49.49,
        "HellaSwag":75.99,
        "MMLU":53.34,
        "TruthfulQA":46.16,
        "Winogrande":73.72,
        "GSM8K":4.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Voicelab\/trurl-2-7b",
        "Average":50.58,
        "ARC":53.41,
        "HellaSwag":75.29,
        "MMLU":50.0,
        "TruthfulQA":45.42,
        "Winogrande":72.22,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"guardrail\/llama-2-7b-guanaco-instruct-sharded",
        "Average":50.58,
        "ARC":53.75,
        "HellaSwag":78.69,
        "MMLU":46.65,
        "TruthfulQA":43.93,
        "Winogrande":72.61,
        "GSM8K":7.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maximuslee07\/llama-2-7b-rockwell-final",
        "Average":50.55,
        "ARC":52.73,
        "HellaSwag":79.1,
        "MMLU":47.88,
        "TruthfulQA":47.21,
        "Winogrande":68.43,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"decruz07\/llama-2-7b-miniguanaco",
        "Average":50.55,
        "ARC":49.06,
        "HellaSwag":75.59,
        "MMLU":46.14,
        "TruthfulQA":43.73,
        "Winogrande":72.61,
        "GSM8K":16.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-mmlu-val-mcq-7b-ep2",
        "Average":50.55,
        "ARC":53.33,
        "HellaSwag":77.73,
        "MMLU":46.85,
        "TruthfulQA":43.87,
        "Winogrande":71.27,
        "GSM8K":10.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lazycuber\/L2-7b-Guanaco-Uncensored",
        "Average":50.55,
        "ARC":50.6,
        "HellaSwag":76.99,
        "MMLU":48.93,
        "TruthfulQA":43.42,
        "Winogrande":75.37,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Rijgersberg\/GEITje-7B",
        "Average":50.53,
        "ARC":44.8,
        "HellaSwag":75.31,
        "MMLU":50.1,
        "TruthfulQA":40.45,
        "Winogrande":72.38,
        "GSM8K":20.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/trurl-2-7b-pl-instruct_unload",
        "Average":50.52,
        "ARC":53.16,
        "HellaSwag":74.64,
        "MMLU":49.89,
        "TruthfulQA":45.74,
        "Winogrande":72.3,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Technoculture\/mtor-2x7b",
        "Average":50.5,
        "ARC":55.2,
        "HellaSwag":73.6,
        "MMLU":51.83,
        "TruthfulQA":48.06,
        "Winogrande":70.64,
        "GSM8K":3.64,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"922-CA\/monika-ddlc-7b-v1",
        "Average":50.49,
        "ARC":54.95,
        "HellaSwag":76.78,
        "MMLU":45.61,
        "TruthfulQA":43.94,
        "Winogrande":72.85,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jilp00\/OpenHermes-Symbolic-Mistral-7B",
        "Average":50.46,
        "ARC":54.86,
        "HellaSwag":72.55,
        "MMLU":61.8,
        "TruthfulQA":45.35,
        "Winogrande":66.22,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Nekochu\/Luminia-13B-v3",
        "Average":50.46,
        "ARC":52.47,
        "HellaSwag":76.08,
        "MMLU":53.6,
        "TruthfulQA":43.74,
        "Winogrande":72.61,
        "GSM8K":4.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardCoder-Python-34B-V1.0",
        "Average":50.46,
        "ARC":52.13,
        "HellaSwag":74.78,
        "MMLU":49.15,
        "TruthfulQA":48.85,
        "Winogrande":68.35,
        "GSM8K":9.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":742.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jilp00\/OpenHermes-Symbolic-Mistral-7B",
        "Average":50.45,
        "ARC":54.78,
        "HellaSwag":72.56,
        "MMLU":61.96,
        "TruthfulQA":45.28,
        "Winogrande":66.22,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lazycuber\/L2-7b-Base-Guanaco-Uncensored",
        "Average":50.45,
        "ARC":52.22,
        "HellaSwag":79.08,
        "MMLU":46.63,
        "TruthfulQA":42.97,
        "Winogrande":74.51,
        "GSM8K":7.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openthaigpt\/openthaigpt-1.0.0-beta-13b-chat-hf",
        "Average":50.45,
        "ARC":53.58,
        "HellaSwag":79.09,
        "MMLU":51.13,
        "TruthfulQA":44.16,
        "Winogrande":73.88,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/MistralLite-11B",
        "Average":50.43,
        "ARC":57.68,
        "HellaSwag":79.54,
        "MMLU":50.09,
        "TruthfulQA":38.27,
        "Winogrande":76.64,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"chavinlo\/gpt4-x-alpaca",
        "Average":50.41,
        "ARC":52.82,
        "HellaSwag":79.59,
        "MMLU":48.19,
        "TruthfulQA":48.88,
        "Winogrande":70.17,
        "GSM8K":2.81,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":478.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
        "Average":50.4,
        "ARC":53.67,
        "HellaSwag":78.21,
        "MMLU":45.9,
        "TruthfulQA":46.13,
        "Winogrande":73.8,
        "GSM8K":4.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-dpo",
        "Average":50.38,
        "ARC":53.67,
        "HellaSwag":78.79,
        "MMLU":46.78,
        "TruthfulQA":43.97,
        "Winogrande":71.74,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ConvexAI\/Pelican-9b-v0.1",
        "Average":50.38,
        "ARC":47.95,
        "HellaSwag":66.22,
        "MMLU":62.85,
        "TruthfulQA":50.61,
        "Winogrande":74.66,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":9.86,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NewstaR\/Koss-7B-chat",
        "Average":50.37,
        "ARC":53.67,
        "HellaSwag":78.79,
        "MMLU":46.72,
        "TruthfulQA":43.97,
        "Winogrande":71.74,
        "GSM8K":7.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-delta-v1.1",
        "Average":50.37,
        "ARC":53.67,
        "HellaSwag":77.5,
        "MMLU":45.61,
        "TruthfulQA":48.95,
        "Winogrande":70.96,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":202.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Ejafa\/vicuna_7B_vanilla_1.1",
        "Average":50.37,
        "ARC":53.67,
        "HellaSwag":77.46,
        "MMLU":45.63,
        "TruthfulQA":48.94,
        "Winogrande":70.96,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eachadea\/vicuna-7b-1.1",
        "Average":50.37,
        "ARC":53.67,
        "HellaSwag":77.46,
        "MMLU":45.63,
        "TruthfulQA":48.94,
        "Winogrande":70.96,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":108.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"joehuangx\/spatial-vicuna-7b-v1.5-LoRA",
        "Average":50.36,
        "ARC":50.77,
        "HellaSwag":74.63,
        "MMLU":48.13,
        "TruthfulQA":49.36,
        "Winogrande":72.38,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-timedial",
        "Average":50.35,
        "ARC":52.9,
        "HellaSwag":76.29,
        "MMLU":50.47,
        "TruthfulQA":41.6,
        "Winogrande":73.56,
        "GSM8K":7.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ValiantLabs\/Fireplace-13b",
        "Average":50.34,
        "ARC":47.7,
        "HellaSwag":69.61,
        "MMLU":43.56,
        "TruthfulQA":48.24,
        "Winogrande":67.17,
        "GSM8K":25.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/vicuna-7b-v1.3-attention-sparsity-30",
        "Average":50.33,
        "ARC":51.02,
        "HellaSwag":76.41,
        "MMLU":46.83,
        "TruthfulQA":46.06,
        "Winogrande":69.3,
        "GSM8K":12.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-chat-hf-gpt-3.5-80k-base_lora",
        "Average":50.3,
        "ARC":51.45,
        "HellaSwag":69.38,
        "MMLU":48.37,
        "TruthfulQA":46.62,
        "Winogrande":67.4,
        "GSM8K":18.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"willnguyen\/lacda-2-7B-chat-v0.1",
        "Average":50.29,
        "ARC":53.07,
        "HellaSwag":77.57,
        "MMLU":46.03,
        "TruthfulQA":44.57,
        "Winogrande":74.19,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beomi\/Yi-Ko-6B",
        "Average":50.27,
        "ARC":48.89,
        "HellaSwag":74.48,
        "MMLU":55.72,
        "TruthfulQA":37.09,
        "Winogrande":72.93,
        "GSM8K":12.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.18,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rishiraj\/smol-3b",
        "Average":50.27,
        "ARC":46.33,
        "HellaSwag":68.23,
        "MMLU":46.33,
        "TruthfulQA":50.73,
        "Winogrande":65.35,
        "GSM8K":24.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.02,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"starmpcc\/Asclepius-Llama2-13B",
        "Average":50.25,
        "ARC":55.89,
        "HellaSwag":79.66,
        "MMLU":52.38,
        "TruthfulQA":40.76,
        "Winogrande":72.69,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/tulu-7B-fp16",
        "Average":50.24,
        "ARC":50.17,
        "HellaSwag":77.04,
        "MMLU":47.63,
        "TruthfulQA":41.61,
        "Winogrande":73.8,
        "GSM8K":11.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/Llama-2-7b-hf-instruct-pl-lora_unload",
        "Average":50.23,
        "ARC":53.75,
        "HellaSwag":78.34,
        "MMLU":46.8,
        "TruthfulQA":42.34,
        "Winogrande":73.95,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeneZC\/MiniChat-1.5-3B",
        "Average":50.23,
        "ARC":46.5,
        "HellaSwag":68.28,
        "MMLU":46.67,
        "TruthfulQA":50.71,
        "Winogrande":65.04,
        "GSM8K":24.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":32.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TheSkullery\/Aurora-V2-DLEC",
        "Average":50.23,
        "ARC":47.7,
        "HellaSwag":69.46,
        "MMLU":52.68,
        "TruthfulQA":51.99,
        "Winogrande":69.61,
        "GSM8K":9.93,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.13,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"vishesht27\/22-Neuro_Model",
        "Average":50.23,
        "ARC":49.15,
        "HellaSwag":62.31,
        "MMLU":62.01,
        "TruthfulQA":60.23,
        "Winogrande":66.54,
        "GSM8K":1.14,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"conceptofmind\/LLongMA-2-13b-16k",
        "Average":50.22,
        "ARC":54.27,
        "HellaSwag":79.63,
        "MMLU":50.97,
        "TruthfulQA":37.71,
        "Winogrande":72.77,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kashif\/stack-llama-2",
        "Average":50.21,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":10.01,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Korabbit\/Llama-2-7b-chat-hf-afr-200step-v2",
        "Average":50.21,
        "ARC":51.79,
        "HellaSwag":77.41,
        "MMLU":48.55,
        "TruthfulQA":43.69,
        "Winogrande":71.9,
        "GSM8K":7.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elliotthwang\/elliott_Llama-2-7b-hf",
        "Average":50.2,
        "ARC":53.16,
        "HellaSwag":78.33,
        "MMLU":47.09,
        "TruthfulQA":42.11,
        "Winogrande":73.64,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"leonarad\/hope_for_7b_1.1v",
        "Average":50.19,
        "ARC":49.49,
        "HellaSwag":75.08,
        "MMLU":48.49,
        "TruthfulQA":40.26,
        "Winogrande":73.64,
        "GSM8K":14.18,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RatanRohith\/SRBOSGPT-7B-slerp",
        "Average":50.19,
        "ARC":49.15,
        "HellaSwag":62.28,
        "MMLU":61.95,
        "TruthfulQA":60.23,
        "Winogrande":66.54,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"edor\/Platypus2-mini-7B",
        "Average":50.18,
        "ARC":53.33,
        "HellaSwag":78.81,
        "MMLU":45.58,
        "TruthfulQA":42.0,
        "Winogrande":75.14,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hongzoh\/Yi-6B_Open-Orca",
        "Average":50.18,
        "ARC":51.19,
        "HellaSwag":69.6,
        "MMLU":58.06,
        "TruthfulQA":38.63,
        "Winogrande":70.4,
        "GSM8K":13.19,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-7b_10e5",
        "Average":50.17,
        "ARC":53.84,
        "HellaSwag":78.32,
        "MMLU":46.16,
        "TruthfulQA":38.97,
        "Winogrande":73.16,
        "GSM8K":10.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"haoranxu\/ALMA-13B",
        "Average":50.16,
        "ARC":56.83,
        "HellaSwag":80.29,
        "MMLU":49.92,
        "TruthfulQA":37.57,
        "Winogrande":76.32,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/llama-2-7b-hf-guanaco-1k",
        "Average":50.13,
        "ARC":51.62,
        "HellaSwag":76.73,
        "MMLU":47.45,
        "TruthfulQA":44.79,
        "Winogrande":72.77,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-hf-guanaco",
        "Average":50.12,
        "ARC":52.47,
        "HellaSwag":78.75,
        "MMLU":45.33,
        "TruthfulQA":43.9,
        "Winogrande":74.19,
        "GSM8K":6.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyPixel\/elm-test",
        "Average":50.09,
        "ARC":53.16,
        "HellaSwag":78.98,
        "MMLU":47.04,
        "TruthfulQA":39.51,
        "Winogrande":74.35,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"conceptofmind\/LLongMA-2-13b-16k",
        "Average":50.09,
        "ARC":54.27,
        "HellaSwag":79.66,
        "MMLU":50.86,
        "TruthfulQA":37.68,
        "Winogrande":72.61,
        "GSM8K":5.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/Llama-2-7B-32K-Instruct",
        "Average":50.02,
        "ARC":51.11,
        "HellaSwag":78.51,
        "MMLU":46.11,
        "TruthfulQA":44.86,
        "Winogrande":73.88,
        "GSM8K":5.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":160.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-guanaco",
        "Average":50.02,
        "ARC":50.51,
        "HellaSwag":76.72,
        "MMLU":48.03,
        "TruthfulQA":43.36,
        "Winogrande":72.93,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dhmeltzer\/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
        "Average":50.0,
        "ARC":53.75,
        "HellaSwag":78.76,
        "MMLU":46.02,
        "TruthfulQA":43.31,
        "Winogrande":73.48,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"stabilityai\/stablelm-2-zephyr-1_6b",
        "Average":49.99,
        "ARC":43.69,
        "HellaSwag":69.3,
        "MMLU":42.03,
        "TruthfulQA":45.11,
        "Winogrande":64.48,
        "GSM8K":35.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.64,
        "Model Sha":150.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
        "Average":49.98,
        "ARC":54.1,
        "HellaSwag":78.74,
        "MMLU":45.44,
        "TruthfulQA":43.4,
        "Winogrande":73.64,
        "GSM8K":4.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/Buttocks-7B-v1.1",
        "Average":49.97,
        "ARC":54.61,
        "HellaSwag":75.61,
        "MMLU":50.22,
        "TruthfulQA":44.72,
        "Winogrande":68.9,
        "GSM8K":5.76,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TeeZee\/Buttocks-7B-v1.0",
        "Average":49.97,
        "ARC":54.61,
        "HellaSwag":75.61,
        "MMLU":50.22,
        "TruthfulQA":44.72,
        "Winogrande":68.9,
        "GSM8K":5.76,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"garage-bAInd\/Platypus2-7B",
        "Average":49.97,
        "ARC":55.2,
        "HellaSwag":78.84,
        "MMLU":49.83,
        "TruthfulQA":40.64,
        "Winogrande":73.48,
        "GSM8K":1.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":6.74,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RoversX\/llama-2-7b-hf-small-shards-Samantha-V1-SFT",
        "Average":49.96,
        "ARC":53.16,
        "HellaSwag":77.71,
        "MMLU":43.47,
        "TruthfulQA":45.28,
        "Winogrande":73.8,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/belal-finetuned-llama2-1024-v2.2",
        "Average":49.96,
        "ARC":52.65,
        "HellaSwag":77.81,
        "MMLU":44.65,
        "TruthfulQA":40.02,
        "Winogrande":74.11,
        "GSM8K":10.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-7b",
        "Average":49.96,
        "ARC":51.19,
        "HellaSwag":75.4,
        "MMLU":47.47,
        "TruthfulQA":42.06,
        "Winogrande":71.67,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyPixel\/lima-test",
        "Average":49.96,
        "ARC":53.07,
        "HellaSwag":78.88,
        "MMLU":46.42,
        "TruthfulQA":39.4,
        "Winogrande":74.03,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Uncensored-Jordan-7B",
        "Average":49.95,
        "ARC":51.28,
        "HellaSwag":77.37,
        "MMLU":45.69,
        "TruthfulQA":47.5,
        "Winogrande":71.11,
        "GSM8K":6.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mrm8488\/llama-2-coder-7b",
        "Average":49.95,
        "ARC":54.01,
        "HellaSwag":78.35,
        "MMLU":46.25,
        "TruthfulQA":38.49,
        "Winogrande":75.45,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":48.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_llama2-7b_10e6",
        "Average":49.92,
        "ARC":53.41,
        "HellaSwag":78.03,
        "MMLU":46.07,
        "TruthfulQA":38.78,
        "Winogrande":73.01,
        "GSM8K":10.24,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llm-agents\/tora-code-34b-v1.0",
        "Average":49.92,
        "ARC":50.26,
        "HellaSwag":75.48,
        "MMLU":46.65,
        "TruthfulQA":39.62,
        "Winogrande":67.72,
        "GSM8K":19.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-deepseekcoder-33b-v16.1-32k",
        "Average":49.91,
        "ARC":45.05,
        "HellaSwag":60.79,
        "MMLU":43.24,
        "TruthfulQA":44.49,
        "Winogrande":62.19,
        "GSM8K":43.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/Reyna-CoT-4B-v0.1",
        "Average":49.91,
        "ARC":44.71,
        "HellaSwag":71.12,
        "MMLU":55.9,
        "TruthfulQA":43.09,
        "Winogrande":67.72,
        "GSM8K":16.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.95,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lodrick-the-lafted\/Winged-Lagomorph-2x13B",
        "Average":49.9,
        "ARC":47.95,
        "HellaSwag":69.39,
        "MMLU":44.5,
        "TruthfulQA":44.54,
        "Winogrande":67.4,
        "GSM8K":25.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":21.51,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PeanutJar\/LLaMa-2-PeanutButter_v18_A-7B",
        "Average":49.88,
        "ARC":53.16,
        "HellaSwag":78.11,
        "MMLU":45.54,
        "TruthfulQA":40.37,
        "Winogrande":74.9,
        "GSM8K":7.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wenge-research\/yayi-7b-llama2",
        "Average":49.88,
        "ARC":54.78,
        "HellaSwag":77.94,
        "MMLU":41.35,
        "TruthfulQA":44.02,
        "Winogrande":74.51,
        "GSM8K":6.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyPixel\/testmodel2",
        "Average":49.88,
        "ARC":53.24,
        "HellaSwag":78.78,
        "MMLU":46.61,
        "TruthfulQA":39.17,
        "Winogrande":73.8,
        "GSM8K":7.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lajonbot\/Llama-2-7b-chat-hf-instruct-pl-lora_unload",
        "Average":49.86,
        "ARC":52.99,
        "HellaSwag":77.49,
        "MMLU":47.12,
        "TruthfulQA":42.61,
        "Winogrande":72.06,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-chat-hf-gpt-4-80k-base_lora",
        "Average":49.86,
        "ARC":52.56,
        "HellaSwag":71.37,
        "MMLU":48.34,
        "TruthfulQA":48.22,
        "Winogrande":66.61,
        "GSM8K":12.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/MultiLoRA-llama2-mmlu",
        "Average":49.82,
        "ARC":52.22,
        "HellaSwag":77.59,
        "MMLU":42.61,
        "TruthfulQA":40.93,
        "Winogrande":73.8,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psyche\/kollama2-7b",
        "Average":49.81,
        "ARC":53.24,
        "HellaSwag":78.78,
        "MMLU":42.31,
        "TruthfulQA":44.56,
        "Winogrande":73.95,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kodonho\/Solar-M-SakuraSolar-Mixed",
        "Average":49.81,
        "ARC":45.9,
        "HellaSwag":58.56,
        "MMLU":64.51,
        "TruthfulQA":59.62,
        "Winogrande":70.24,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyPixel\/testmodel-3",
        "Average":49.79,
        "ARC":53.24,
        "HellaSwag":78.72,
        "MMLU":46.57,
        "TruthfulQA":38.75,
        "Winogrande":73.88,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardMath-7B-V1.0",
        "Average":49.78,
        "ARC":54.1,
        "HellaSwag":79.55,
        "MMLU":45.97,
        "TruthfulQA":43.65,
        "Winogrande":72.69,
        "GSM8K":2.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":47.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"elyza\/ELYZA-japanese-Llama-2-7b-instruct",
        "Average":49.78,
        "ARC":53.16,
        "HellaSwag":78.25,
        "MMLU":47.07,
        "TruthfulQA":39.08,
        "Winogrande":73.24,
        "GSM8K":7.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/vicuna-7b-v1.3",
        "Average":49.78,
        "ARC":50.43,
        "HellaSwag":76.92,
        "MMLU":48.14,
        "TruthfulQA":47.01,
        "Winogrande":70.48,
        "GSM8K":5.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":121.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"undi95\/llama2-to-mistral-diff",
        "Average":49.78,
        "ARC":53.41,
        "HellaSwag":78.56,
        "MMLU":46.43,
        "TruthfulQA":38.71,
        "Winogrande":74.03,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-v4",
        "Average":49.78,
        "ARC":53.41,
        "HellaSwag":78.56,
        "MMLU":46.43,
        "TruthfulQA":38.71,
        "Winogrande":74.03,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
        "Average":49.77,
        "ARC":51.79,
        "HellaSwag":76.41,
        "MMLU":49.58,
        "TruthfulQA":40.33,
        "Winogrande":73.4,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wenge-research\/yayi-7b-llama2",
        "Average":49.75,
        "ARC":55.03,
        "HellaSwag":77.84,
        "MMLU":40.92,
        "TruthfulQA":44.02,
        "Winogrande":73.72,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/LongQLoRA-Llama2-7b-8k",
        "Average":49.75,
        "ARC":52.47,
        "HellaSwag":78.11,
        "MMLU":45.37,
        "TruthfulQA":38.94,
        "Winogrande":72.06,
        "GSM8K":11.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"wang7776\/Mistral-7B-Instruct-v0.2-sparsity-30",
        "Average":49.74,
        "ARC":51.11,
        "HellaSwag":75.72,
        "MMLU":46.54,
        "TruthfulQA":45.53,
        "Winogrande":68.98,
        "GSM8K":10.54,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/llama-2-7b-hf_open-platypus",
        "Average":49.73,
        "ARC":51.45,
        "HellaSwag":78.63,
        "MMLU":43.6,
        "TruthfulQA":43.71,
        "Winogrande":74.43,
        "GSM8K":6.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bongchoi\/test-llama2-7b",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.86,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yeen214\/test_llama2_7b",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.86,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NewstaR\/Starlight-7B",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-v4",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TaylorAI\/Flash-Llama-7B",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibranze\/araproje-llama2-7b-hf",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-v2",
        "Average":49.73,
        "ARC":53.07,
        "HellaSwag":78.57,
        "MMLU":46.8,
        "TruthfulQA":38.75,
        "Winogrande":74.03,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"davzoku\/cria-llama2-7b-v1.3_peft",
        "Average":49.72,
        "ARC":51.45,
        "HellaSwag":77.35,
        "MMLU":46.47,
        "TruthfulQA":45.52,
        "Winogrande":70.8,
        "GSM8K":6.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ToolBench\/ToolLLaMA-7b-LoRA",
        "Average":49.72,
        "ARC":52.99,
        "HellaSwag":78.62,
        "MMLU":46.87,
        "TruthfulQA":38.67,
        "Winogrande":74.35,
        "GSM8K":6.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vitruv\/vitruv_1",
        "Average":49.71,
        "ARC":49.91,
        "HellaSwag":76.05,
        "MMLU":48.21,
        "TruthfulQA":41.23,
        "Winogrande":71.59,
        "GSM8K":11.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
        "Average":49.71,
        "ARC":53.67,
        "HellaSwag":78.09,
        "MMLU":45.63,
        "TruthfulQA":41.72,
        "Winogrande":73.56,
        "GSM8K":5.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-ac-hal-13b-ep3",
        "Average":49.7,
        "ARC":48.46,
        "HellaSwag":80.78,
        "MMLU":56.17,
        "TruthfulQA":39.32,
        "Winogrande":73.48,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/belal-finetuned-llama2-v1.0",
        "Average":49.7,
        "ARC":52.82,
        "HellaSwag":77.75,
        "MMLU":43.51,
        "TruthfulQA":39.09,
        "Winogrande":74.35,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mixed-datasets",
        "Average":49.7,
        "ARC":51.71,
        "HellaSwag":76.44,
        "MMLU":50.13,
        "TruthfulQA":39.57,
        "Winogrande":73.24,
        "GSM8K":7.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abdulrahman-nuzha\/finetuned-llama-v2.0",
        "Average":49.67,
        "ARC":53.16,
        "HellaSwag":77.75,
        "MMLU":43.69,
        "TruthfulQA":39.08,
        "Winogrande":74.43,
        "GSM8K":9.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"georgesung\/llama2_7b_chat_uncensored",
        "Average":49.67,
        "ARC":53.58,
        "HellaSwag":78.66,
        "MMLU":44.49,
        "TruthfulQA":41.34,
        "Winogrande":74.11,
        "GSM8K":5.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":285.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shibing624\/chinese-alpaca-plus-13b-hf",
        "Average":49.66,
        "ARC":53.16,
        "HellaSwag":73.51,
        "MMLU":48.81,
        "TruthfulQA":45.32,
        "Winogrande":75.06,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceH4\/starchat-beta",
        "Average":49.66,
        "ARC":52.47,
        "HellaSwag":80.59,
        "MMLU":42.85,
        "TruthfulQA":47.22,
        "Winogrande":69.69,
        "GSM8K":5.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":15.52,
        "Model Sha":256.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"togethercomputer\/Llama-2-7B-32K-Instruct",
        "Average":49.65,
        "ARC":51.37,
        "HellaSwag":78.47,
        "MMLU":45.53,
        "TruthfulQA":45.01,
        "Winogrande":72.85,
        "GSM8K":4.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":160.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TaylorAI\/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
        "Average":49.64,
        "ARC":52.47,
        "HellaSwag":79.08,
        "MMLU":47.58,
        "TruthfulQA":37.14,
        "Winogrande":74.74,
        "GSM8K":6.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-7b-2.1",
        "Average":49.64,
        "ARC":54.44,
        "HellaSwag":78.68,
        "MMLU":44.45,
        "TruthfulQA":43.95,
        "Winogrande":74.11,
        "GSM8K":2.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/longchat-13b-16k",
        "Average":49.64,
        "ARC":53.58,
        "HellaSwag":77.67,
        "MMLU":45.24,
        "TruthfulQA":47.07,
        "Winogrande":70.09,
        "GSM8K":4.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":131.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"clibrain\/Llama-2-7b-ft-instruct-es",
        "Average":49.63,
        "ARC":53.67,
        "HellaSwag":77.83,
        "MMLU":46.58,
        "TruthfulQA":38.82,
        "Winogrande":75.22,
        "GSM8K":5.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jondurbin\/airocoder-34b-2.1",
        "Average":49.61,
        "ARC":54.18,
        "HellaSwag":73.84,
        "MMLU":50.67,
        "TruthfulQA":40.7,
        "Winogrande":69.93,
        "GSM8K":8.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/autotrain-8kfjk-b3gva",
        "Average":49.59,
        "ARC":50.0,
        "HellaSwag":70.79,
        "MMLU":51.09,
        "TruthfulQA":43.49,
        "Winogrande":63.38,
        "GSM8K":18.8,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"malhajar\/meditron-7b-chat",
        "Average":49.59,
        "ARC":50.77,
        "HellaSwag":75.37,
        "MMLU":40.49,
        "TruthfulQA":48.56,
        "Winogrande":73.16,
        "GSM8K":9.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"gywy\/llama2-13b-chinese-v2",
        "Average":49.58,
        "ARC":53.92,
        "HellaSwag":74.64,
        "MMLU":49.74,
        "TruthfulQA":45.43,
        "Winogrande":71.59,
        "GSM8K":2.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sia-ai\/llama-2-7b-1-percent-open-orca-1000-steps-v0",
        "Average":49.56,
        "ARC":51.28,
        "HellaSwag":78.75,
        "MMLU":44.68,
        "TruthfulQA":45.83,
        "Winogrande":74.11,
        "GSM8K":2.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dotvignesh\/perry-7b",
        "Average":49.55,
        "ARC":51.79,
        "HellaSwag":76.43,
        "MMLU":46.18,
        "TruthfulQA":40.08,
        "Winogrande":72.53,
        "GSM8K":10.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CalderaAI\/13B-Ouroboros",
        "Average":49.54,
        "ARC":57.42,
        "HellaSwag":82.11,
        "MMLU":51.43,
        "TruthfulQA":47.99,
        "Winogrande":57.85,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-7b-gpt4-1.4.1",
        "Average":49.54,
        "ARC":55.12,
        "HellaSwag":79.6,
        "MMLU":45.17,
        "TruthfulQA":40.29,
        "Winogrande":74.27,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/autotrain-8kfjk-b3gva",
        "Average":49.54,
        "ARC":50.17,
        "HellaSwag":70.84,
        "MMLU":51.15,
        "TruthfulQA":43.43,
        "Winogrande":63.46,
        "GSM8K":18.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jb723\/llama2-ko-7B-model",
        "Average":49.52,
        "ARC":56.31,
        "HellaSwag":79.51,
        "MMLU":45.71,
        "TruthfulQA":40.98,
        "Winogrande":72.06,
        "GSM8K":2.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llama-anon\/instruct-13b",
        "Average":49.52,
        "ARC":56.14,
        "HellaSwag":80.27,
        "MMLU":47.89,
        "TruthfulQA":36.97,
        "Winogrande":73.56,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"quantumaikr\/QuantumLM-7B",
        "Average":49.51,
        "ARC":50.26,
        "HellaSwag":76.1,
        "MMLU":45.27,
        "TruthfulQA":46.25,
        "Winogrande":71.51,
        "GSM8K":7.66,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/tamil-llama-13b-base-v0.1",
        "Average":49.5,
        "ARC":52.82,
        "HellaSwag":79.95,
        "MMLU":52.05,
        "TruthfulQA":36.56,
        "Winogrande":75.61,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/zephyr-7b-beta-lora-mmlu-merged",
        "Average":49.49,
        "ARC":52.82,
        "HellaSwag":76.12,
        "MMLU":37.82,
        "TruthfulQA":44.6,
        "Winogrande":71.35,
        "GSM8K":14.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JCX-kcuf\/Llama-2-7b-hf-llama2-chat-80k",
        "Average":49.49,
        "ARC":53.84,
        "HellaSwag":74.65,
        "MMLU":46.36,
        "TruthfulQA":39.06,
        "Winogrande":71.03,
        "GSM8K":11.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rombodawg\/Everyone-Coder-33b-Base",
        "Average":49.48,
        "ARC":45.99,
        "HellaSwag":61.71,
        "MMLU":44.05,
        "TruthfulQA":42.26,
        "Winogrande":63.06,
        "GSM8K":39.8,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":33.34,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FreedomIntelligence\/AceGPT-7B",
        "Average":49.47,
        "ARC":53.58,
        "HellaSwag":77.54,
        "MMLU":43.0,
        "TruthfulQA":38.75,
        "Winogrande":72.77,
        "GSM8K":11.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
        "Average":49.47,
        "ARC":52.82,
        "HellaSwag":79.63,
        "MMLU":39.83,
        "TruthfulQA":52.55,
        "Winogrande":71.82,
        "GSM8K":0.15,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sambanovasystems\/SambaLingo-Thai-Chat",
        "Average":49.45,
        "ARC":52.73,
        "HellaSwag":78.42,
        "MMLU":43.95,
        "TruthfulQA":40.84,
        "Winogrande":72.22,
        "GSM8K":8.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.95,
        "Model Sha":33.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"adamo1139\/LWM-7B-1M-1000000ctx-AEZAKMI-3_1-1702",
        "Average":49.42,
        "ARC":51.19,
        "HellaSwag":77.08,
        "MMLU":43.12,
        "TruthfulQA":44.19,
        "Winogrande":72.06,
        "GSM8K":8.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/Guanaco-7B-Uncensored",
        "Average":49.35,
        "ARC":52.13,
        "HellaSwag":78.77,
        "MMLU":43.42,
        "TruthfulQA":44.45,
        "Winogrande":73.09,
        "GSM8K":4.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-temporal-without-mctaco-1",
        "Average":49.35,
        "ARC":49.49,
        "HellaSwag":75.93,
        "MMLU":47.47,
        "TruthfulQA":39.95,
        "Winogrande":71.35,
        "GSM8K":11.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rameshm\/llama-2-13b-mathgpt-v4",
        "Average":49.35,
        "ARC":50.94,
        "HellaSwag":75.56,
        "MMLU":43.78,
        "TruthfulQA":41.96,
        "Winogrande":69.14,
        "GSM8K":14.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ceadar-ie\/FinanceConnect-13B",
        "Average":49.34,
        "ARC":55.12,
        "HellaSwag":77.73,
        "MMLU":52.08,
        "TruthfulQA":37.68,
        "Winogrande":71.82,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.02,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"haoranxu\/ALMA-13B-R",
        "Average":49.32,
        "ARC":55.55,
        "HellaSwag":79.45,
        "MMLU":49.52,
        "TruthfulQA":36.09,
        "Winogrande":75.3,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.02,
        "Model Sha":63.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-openllama-13b-v7-fp16",
        "Average":49.31,
        "ARC":47.61,
        "HellaSwag":72.24,
        "MMLU":47.74,
        "TruthfulQA":48.73,
        "Winogrande":69.69,
        "GSM8K":9.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qualis2006\/llama-2-7b-int4-python-code-18k",
        "Average":49.3,
        "ARC":52.13,
        "HellaSwag":78.55,
        "MMLU":46.25,
        "TruthfulQA":37.69,
        "Winogrande":74.98,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OdiaGenAI\/odia_llama2_7B_base",
        "Average":49.3,
        "ARC":50.77,
        "HellaSwag":75.94,
        "MMLU":46.1,
        "TruthfulQA":37.27,
        "Winogrande":70.8,
        "GSM8K":14.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/mistral-tutor-model-7b-ep3",
        "Average":49.29,
        "ARC":49.32,
        "HellaSwag":76.93,
        "MMLU":49.07,
        "TruthfulQA":47.73,
        "Winogrande":72.69,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"LeoLM\/leo-hessianai-7b-chat",
        "Average":49.29,
        "ARC":52.56,
        "HellaSwag":77.61,
        "MMLU":45.58,
        "TruthfulQA":44.89,
        "Winogrande":69.93,
        "GSM8K":5.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-7b-chat",
        "Average":49.27,
        "ARC":52.47,
        "HellaSwag":78.35,
        "MMLU":39.51,
        "TruthfulQA":44.52,
        "Winogrande":73.16,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"heegyu\/LIMA2-7b-hf",
        "Average":49.27,
        "ARC":53.24,
        "HellaSwag":80.6,
        "MMLU":43.22,
        "TruthfulQA":44.74,
        "Winogrande":69.93,
        "GSM8K":3.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"TehVenom\/Pygmalion-Vicuna-1.1-7b",
        "Average":49.25,
        "ARC":52.82,
        "HellaSwag":78.66,
        "MMLU":43.61,
        "TruthfulQA":42.21,
        "Winogrande":71.98,
        "GSM8K":6.22,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dhmeltzer\/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
        "Average":49.22,
        "ARC":53.41,
        "HellaSwag":77.9,
        "MMLU":43.56,
        "TruthfulQA":40.81,
        "Winogrande":74.59,
        "GSM8K":5.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/YaYi-30b-EverythingLM",
        "Average":49.19,
        "ARC":37.97,
        "HellaSwag":61.05,
        "MMLU":69.63,
        "TruthfulQA":49.74,
        "Winogrande":62.83,
        "GSM8K":13.95,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"venkycs\/llama-v2-7b-32kC-Security",
        "Average":49.19,
        "ARC":49.83,
        "HellaSwag":77.33,
        "MMLU":44.41,
        "TruthfulQA":47.96,
        "Winogrande":71.74,
        "GSM8K":3.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.61,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wahaha1987\/llama_7b_sharegpt94k_fastchat",
        "Average":49.19,
        "ARC":53.24,
        "HellaSwag":76.94,
        "MMLU":44.64,
        "TruthfulQA":45.34,
        "Winogrande":70.64,
        "GSM8K":4.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-RetroRodeo-13b",
        "Average":49.15,
        "ARC":53.84,
        "HellaSwag":79.63,
        "MMLU":48.93,
        "TruthfulQA":38.73,
        "Winogrande":73.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/vicuna-7B-physics",
        "Average":49.15,
        "ARC":49.49,
        "HellaSwag":75.88,
        "MMLU":46.58,
        "TruthfulQA":49.31,
        "Winogrande":69.38,
        "GSM8K":4.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-7b-fast-instruct",
        "Average":49.15,
        "ARC":53.75,
        "HellaSwag":77.55,
        "MMLU":46.85,
        "TruthfulQA":38.84,
        "Winogrande":71.59,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Unbabel\/TowerBase-7B-v0.1",
        "Average":49.11,
        "ARC":51.02,
        "HellaSwag":77.68,
        "MMLU":43.48,
        "TruthfulQA":37.29,
        "Winogrande":72.06,
        "GSM8K":13.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.74,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WhiteRabbitNeo\/WhiteRabbitNeo-13B-v1",
        "Average":49.11,
        "ARC":48.55,
        "HellaSwag":68.7,
        "MMLU":43.04,
        "TruthfulQA":44.58,
        "Winogrande":67.4,
        "GSM8K":22.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":341.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"whiterabbitneo\/WhiteRabbitNeo-13B",
        "Average":49.11,
        "ARC":48.55,
        "HellaSwag":68.7,
        "MMLU":43.04,
        "TruthfulQA":44.58,
        "Winogrande":67.4,
        "GSM8K":22.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/scarlett-7b",
        "Average":49.09,
        "ARC":57.17,
        "HellaSwag":80.27,
        "MMLU":36.11,
        "TruthfulQA":48.52,
        "Winogrande":72.14,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"itsliupeng\/llama2_7b_code",
        "Average":49.05,
        "ARC":52.13,
        "HellaSwag":75.71,
        "MMLU":48.05,
        "TruthfulQA":38.76,
        "Winogrande":71.51,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hiyouga\/Baichuan2-7B-Base-LLaMAfied",
        "Average":48.99,
        "ARC":49.57,
        "HellaSwag":73.45,
        "MMLU":54.86,
        "TruthfulQA":37.54,
        "Winogrande":70.72,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-mmlu-val-only-correct-mcq-7b-ep2",
        "Average":48.96,
        "ARC":52.99,
        "HellaSwag":77.67,
        "MMLU":47.92,
        "TruthfulQA":43.17,
        "Winogrande":71.9,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-agents\/tora-code-34b-v1.0",
        "Average":48.95,
        "ARC":50.43,
        "HellaSwag":75.54,
        "MMLU":46.78,
        "TruthfulQA":39.66,
        "Winogrande":68.19,
        "GSM8K":13.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"martyn\/mistral-megamerge-dare-7b",
        "Average":48.93,
        "ARC":55.29,
        "HellaSwag":70.48,
        "MMLU":43.05,
        "TruthfulQA":51.08,
        "Winogrande":67.09,
        "GSM8K":6.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAGOsolutions\/SauerkrautLM-Gemma-2b",
        "Average":48.92,
        "ARC":48.72,
        "HellaSwag":71.41,
        "MMLU":42.9,
        "TruthfulQA":35.77,
        "Winogrande":67.96,
        "GSM8K":26.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PotatoOff\/HamSter-0.2",
        "Average":48.91,
        "ARC":50.09,
        "HellaSwag":73.65,
        "MMLU":50.39,
        "TruthfulQA":49.63,
        "Winogrande":69.69,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xzuyn\/MedicWizard-7B",
        "Average":48.88,
        "ARC":53.5,
        "HellaSwag":78.39,
        "MMLU":44.61,
        "TruthfulQA":41.32,
        "Winogrande":70.56,
        "GSM8K":4.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziqingyang\/chinese-alpaca-2-7b",
        "Average":48.85,
        "ARC":49.57,
        "HellaSwag":72.62,
        "MMLU":46.5,
        "TruthfulQA":48.63,
        "Winogrande":70.01,
        "GSM8K":5.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"openchat\/opencoderplus",
        "Average":48.84,
        "ARC":50.6,
        "HellaSwag":78.22,
        "MMLU":42.73,
        "TruthfulQA":50.72,
        "Winogrande":66.14,
        "GSM8K":4.62,
        "Type":"",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":104.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dhmeltzer\/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
        "Average":48.82,
        "ARC":54.35,
        "HellaSwag":78.06,
        "MMLU":45.35,
        "TruthfulQA":37.11,
        "Winogrande":73.4,
        "GSM8K":4.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-v3",
        "Average":48.81,
        "ARC":52.22,
        "HellaSwag":76.78,
        "MMLU":45.89,
        "TruthfulQA":38.38,
        "Winogrande":73.4,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-all-hal-7b-ep3",
        "Average":48.75,
        "ARC":45.48,
        "HellaSwag":77.21,
        "MMLU":51.54,
        "TruthfulQA":44.83,
        "Winogrande":71.03,
        "GSM8K":2.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"EleutherAI\/llemma_7b",
        "Average":48.75,
        "ARC":46.16,
        "HellaSwag":62.98,
        "MMLU":47.87,
        "TruthfulQA":38.88,
        "Winogrande":63.3,
        "GSM8K":33.28,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":75.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/komodo-7b-chat",
        "Average":48.74,
        "ARC":51.45,
        "HellaSwag":77.05,
        "MMLU":44.63,
        "TruthfulQA":40.05,
        "Winogrande":74.43,
        "GSM8K":4.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.76,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/vicuna-7b-v1.3-instruct-pl-lora_unload",
        "Average":48.74,
        "ARC":48.04,
        "HellaSwag":76.28,
        "MMLU":47.42,
        "TruthfulQA":44.4,
        "Winogrande":70.09,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"LeoLM\/leo-hessianai-7b-chat-bilingual",
        "Average":48.72,
        "ARC":51.02,
        "HellaSwag":76.03,
        "MMLU":44.68,
        "TruthfulQA":47.16,
        "Winogrande":70.72,
        "GSM8K":2.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GOAT-AI\/GOAT-7B-Community",
        "Average":48.71,
        "ARC":48.81,
        "HellaSwag":74.63,
        "MMLU":49.58,
        "TruthfulQA":42.48,
        "Winogrande":72.3,
        "GSM8K":4.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-7b",
        "Average":48.7,
        "ARC":52.22,
        "HellaSwag":76.42,
        "MMLU":44.6,
        "TruthfulQA":37.92,
        "Winogrande":72.69,
        "GSM8K":8.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":68.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheTravellingEngineer\/llama2-7b-chat-hf-v3",
        "Average":48.65,
        "ARC":51.96,
        "HellaSwag":76.7,
        "MMLU":45.36,
        "TruthfulQA":38.31,
        "Winogrande":73.56,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fblgit\/una-llama-7b",
        "Average":48.64,
        "ARC":53.67,
        "HellaSwag":80.07,
        "MMLU":37.37,
        "TruthfulQA":38.01,
        "Winogrande":72.93,
        "GSM8K":9.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dominguesm\/canarim-7b",
        "Average":48.63,
        "ARC":51.96,
        "HellaSwag":77.52,
        "MMLU":40.92,
        "TruthfulQA":40.03,
        "Winogrande":71.43,
        "GSM8K":9.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PocketDoc\/Dans-CreepingSenseOfDoom",
        "Average":48.58,
        "ARC":53.33,
        "HellaSwag":78.9,
        "MMLU":48.09,
        "TruthfulQA":37.84,
        "Winogrande":73.32,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4-1.1",
        "Average":48.57,
        "ARC":54.61,
        "HellaSwag":80.15,
        "MMLU":39.25,
        "TruthfulQA":41.22,
        "Winogrande":73.09,
        "GSM8K":3.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/GML-Mistral-merged-v1",
        "Average":48.54,
        "ARC":43.77,
        "HellaSwag":57.89,
        "MMLU":64.13,
        "TruthfulQA":51.58,
        "Winogrande":73.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/student-model-13b-ep3",
        "Average":48.52,
        "ARC":46.5,
        "HellaSwag":80.36,
        "MMLU":57.06,
        "TruthfulQA":35.0,
        "Winogrande":72.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-13b-ep3",
        "Average":48.52,
        "ARC":46.5,
        "HellaSwag":80.36,
        "MMLU":57.06,
        "TruthfulQA":35.0,
        "Winogrande":72.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rinna\/youri-7b-chat",
        "Average":48.51,
        "ARC":51.19,
        "HellaSwag":76.09,
        "MMLU":46.06,
        "TruthfulQA":41.17,
        "Winogrande":75.06,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-agents\/tora-7b-v1.0",
        "Average":48.5,
        "ARC":52.47,
        "HellaSwag":78.68,
        "MMLU":45.9,
        "TruthfulQA":37.9,
        "Winogrande":73.56,
        "GSM8K":2.5,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yash21\/Mistral-Quantum-dpo",
        "Average":48.5,
        "ARC":43.43,
        "HellaSwag":57.76,
        "MMLU":64.29,
        "TruthfulQA":51.49,
        "Winogrande":74.03,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Pygmalion-13b-Merged",
        "Average":48.49,
        "ARC":56.48,
        "HellaSwag":80.02,
        "MMLU":42.93,
        "TruthfulQA":35.86,
        "Winogrande":75.53,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TheBloke\/Llama-2-7B-GPTQ",
        "Average":48.48,
        "ARC":52.05,
        "HellaSwag":77.59,
        "MMLU":43.99,
        "TruthfulQA":39.32,
        "Winogrande":72.93,
        "GSM8K":5.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":9.05,
        "Model Sha":77.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/WizardLM-13B-Uncensored",
        "Average":48.48,
        "ARC":50.94,
        "HellaSwag":76.64,
        "MMLU":43.96,
        "TruthfulQA":46.73,
        "Winogrande":70.56,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cognitivecomputations\/yayi2-30b-llama",
        "Average":48.46,
        "ARC":35.67,
        "HellaSwag":53.37,
        "MMLU":70.6,
        "TruthfulQA":49.08,
        "Winogrande":63.14,
        "GSM8K":18.88,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.4,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"medalpaca\/medalpaca-7b",
        "Average":48.45,
        "ARC":54.1,
        "HellaSwag":80.42,
        "MMLU":41.47,
        "TruthfulQA":40.46,
        "Winogrande":71.19,
        "GSM8K":3.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":7.0,
        "Model Sha":56.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/vicuna-7B-chemical",
        "Average":48.42,
        "ARC":49.83,
        "HellaSwag":74.42,
        "MMLU":44.1,
        "TruthfulQA":51.7,
        "Winogrande":67.17,
        "GSM8K":3.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4-1.4",
        "Average":48.4,
        "ARC":53.92,
        "HellaSwag":80.33,
        "MMLU":38.61,
        "TruthfulQA":41.05,
        "Winogrande":72.77,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-7b-gpt4-2.0",
        "Average":48.38,
        "ARC":52.9,
        "HellaSwag":78.53,
        "MMLU":45.09,
        "TruthfulQA":39.45,
        "Winogrande":71.11,
        "GSM8K":3.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"?",
        "Model":"AlpinDale\/pygmalion-instruct",
        "Average":48.37,
        "ARC":52.56,
        "HellaSwag":77.65,
        "MMLU":35.94,
        "TruthfulQA":42.13,
        "Winogrande":72.06,
        "GSM8K":9.86,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LLMs\/AlpacaGPT4-7B-elina",
        "Average":48.35,
        "ARC":55.03,
        "HellaSwag":78.79,
        "MMLU":37.5,
        "TruthfulQA":41.53,
        "Winogrande":72.69,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Monero\/WizardLM-13b-OpenAssistant-Uncensored",
        "Average":48.32,
        "ARC":48.55,
        "HellaSwag":76.03,
        "MMLU":43.15,
        "TruthfulQA":49.4,
        "Winogrande":69.77,
        "GSM8K":3.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Juniplayground\/Mist_LLaMA-2-7B-1024_V3",
        "Average":48.31,
        "ARC":51.37,
        "HellaSwag":77.74,
        "MMLU":41.34,
        "TruthfulQA":41.21,
        "Winogrande":73.32,
        "GSM8K":4.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Herry443\/Mistral-7B-KNUT-ref-en",
        "Average":48.27,
        "ARC":38.99,
        "HellaSwag":70.7,
        "MMLU":23.12,
        "TruthfulQA":48.93,
        "Winogrande":63.46,
        "GSM8K":44.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/Wizard-Vicuna-7B-Uncensored",
        "Average":48.27,
        "ARC":53.41,
        "HellaSwag":78.85,
        "MMLU":37.09,
        "TruthfulQA":43.48,
        "Winogrande":72.22,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Wizard-Vicuna-7B-Uncensored-HF",
        "Average":48.27,
        "ARC":53.41,
        "HellaSwag":78.85,
        "MMLU":37.09,
        "TruthfulQA":43.48,
        "Winogrande":72.22,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mayacinka\/frankencup-dpo",
        "Average":48.26,
        "ARC":42.66,
        "HellaSwag":60.55,
        "MMLU":62.21,
        "TruthfulQA":50.72,
        "Winogrande":73.4,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"voidful\/phi-1_5_chat",
        "Average":48.26,
        "ARC":51.02,
        "HellaSwag":63.39,
        "MMLU":39.35,
        "TruthfulQA":45.79,
        "Winogrande":68.75,
        "GSM8K":21.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Nexusflow\/NexusRaven-V2-13B",
        "Average":48.21,
        "ARC":45.14,
        "HellaSwag":67.4,
        "MMLU":44.88,
        "TruthfulQA":44.54,
        "Winogrande":66.38,
        "GSM8K":20.92,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":395.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AtAndDev\/Ogno-Monarch-Neurotic-9B-Passthrough",
        "Average":48.17,
        "ARC":46.25,
        "HellaSwag":56.06,
        "MMLU":62.92,
        "TruthfulQA":51.03,
        "Winogrande":72.77,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/3BigReasonCinder",
        "Average":48.16,
        "ARC":41.72,
        "HellaSwag":65.16,
        "MMLU":44.79,
        "TruthfulQA":44.76,
        "Winogrande":64.96,
        "GSM8K":27.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mctaco",
        "Average":48.02,
        "ARC":45.65,
        "HellaSwag":75.65,
        "MMLU":49.27,
        "TruthfulQA":43.12,
        "Winogrande":69.93,
        "GSM8K":4.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/multimaster-7b",
        "Average":48.01,
        "ARC":41.04,
        "HellaSwag":75.0,
        "MMLU":46.93,
        "TruthfulQA":44.98,
        "Winogrande":68.35,
        "GSM8K":11.75,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"titan087\/OpenLlama13B-Guanaco",
        "Average":47.99,
        "ARC":51.19,
        "HellaSwag":75.24,
        "MMLU":43.76,
        "TruthfulQA":38.4,
        "Winogrande":71.74,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lmsys\/longchat-7b-v1.5-32k",
        "Average":47.95,
        "ARC":51.71,
        "HellaSwag":74.97,
        "MMLU":43.16,
        "TruthfulQA":44.42,
        "Winogrande":68.67,
        "GSM8K":4.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":55.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-l2-7b-gpt4-m2.0",
        "Average":47.95,
        "ARC":50.51,
        "HellaSwag":76.87,
        "MMLU":45.35,
        "TruthfulQA":41.34,
        "Winogrande":69.53,
        "GSM8K":4.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"LLMs\/Stable-Vicuna-13B",
        "Average":47.95,
        "ARC":53.41,
        "HellaSwag":78.57,
        "MMLU":50.37,
        "TruthfulQA":48.36,
        "Winogrande":56.99,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":13.0,
        "Model Sha":5.0
    },
    {
        "T":"?",
        "Model":"TigerResearch\/tigerbot-7b-base",
        "Average":47.93,
        "ARC":47.7,
        "HellaSwag":72.08,
        "MMLU":45.11,
        "TruthfulQA":42.27,
        "Winogrande":69.61,
        "GSM8K":10.84,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"itsliupeng\/openllama-7b-icl",
        "Average":47.93,
        "ARC":47.95,
        "HellaSwag":77.04,
        "MMLU":44.37,
        "TruthfulQA":37.06,
        "Winogrande":70.17,
        "GSM8K":10.99,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vibhorag101\/llama-2-7b-chat-hf-phr_mental_health-2048",
        "Average":47.92,
        "ARC":52.39,
        "HellaSwag":75.39,
        "MMLU":39.77,
        "TruthfulQA":42.89,
        "Winogrande":71.19,
        "GSM8K":5.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DevaMalla\/llama_7b_qlora_pds-eval",
        "Average":47.9,
        "ARC":53.92,
        "HellaSwag":78.13,
        "MMLU":32.98,
        "TruthfulQA":45.6,
        "Winogrande":72.61,
        "GSM8K":4.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Uncensored-Frank-7B",
        "Average":47.9,
        "ARC":54.27,
        "HellaSwag":76.52,
        "MMLU":37.5,
        "TruthfulQA":43.86,
        "Winogrande":70.24,
        "GSM8K":5.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/vicuna-tutor-shishya-model-7b-ep3",
        "Average":47.9,
        "ARC":43.86,
        "HellaSwag":76.63,
        "MMLU":51.24,
        "TruthfulQA":43.53,
        "Winogrande":71.82,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-ac-hal-7b-ep3",
        "Average":47.89,
        "ARC":44.62,
        "HellaSwag":76.98,
        "MMLU":50.96,
        "TruthfulQA":43.03,
        "Winogrande":71.74,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"synapsoft\/Llama-2-7b-chat-hf-flan2022-1.2M",
        "Average":47.89,
        "ARC":49.57,
        "HellaSwag":76.25,
        "MMLU":45.99,
        "TruthfulQA":42.17,
        "Winogrande":71.82,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"allbyai\/ToRoLaMa-7b-v1.0",
        "Average":47.87,
        "ARC":51.71,
        "HellaSwag":73.82,
        "MMLU":45.34,
        "TruthfulQA":44.89,
        "Winogrande":70.09,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"webbigdata\/ALMA-7B-Ja-V2",
        "Average":47.85,
        "ARC":52.39,
        "HellaSwag":77.92,
        "MMLU":44.72,
        "TruthfulQA":38.66,
        "Winogrande":73.4,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azazelle\/Sina-Odin-7b-Merge",
        "Average":47.82,
        "ARC":52.82,
        "HellaSwag":68.86,
        "MMLU":45.54,
        "TruthfulQA":39.2,
        "Winogrande":72.22,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ConvexAI\/Pelican-9b-v0.1",
        "Average":47.8,
        "ARC":43.34,
        "HellaSwag":57.86,
        "MMLU":63.31,
        "TruthfulQA":50.63,
        "Winogrande":71.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/goims",
        "Average":47.8,
        "ARC":49.49,
        "HellaSwag":72.67,
        "MMLU":43.85,
        "TruthfulQA":44.8,
        "Winogrande":69.69,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-7b-8k-chat",
        "Average":47.78,
        "ARC":48.04,
        "HellaSwag":77.62,
        "MMLU":41.88,
        "TruthfulQA":43.68,
        "Winogrande":71.03,
        "GSM8K":4.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"h2m\/mhm-7b-v1.3-DPO-1",
        "Average":47.77,
        "ARC":49.57,
        "HellaSwag":68.1,
        "MMLU":45.76,
        "TruthfulQA":45.88,
        "Winogrande":62.04,
        "GSM8K":15.24,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bofenghuang\/vigogne-7b-instruct",
        "Average":47.76,
        "ARC":51.96,
        "HellaSwag":78.11,
        "MMLU":38.43,
        "TruthfulQA":42.47,
        "Winogrande":72.85,
        "GSM8K":2.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"quantumaikr\/KoreanLM-hf",
        "Average":47.73,
        "ARC":51.45,
        "HellaSwag":76.77,
        "MMLU":40.61,
        "TruthfulQA":44.34,
        "Winogrande":69.77,
        "GSM8K":3.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LeoLM\/leo-hessianai-7b",
        "Average":47.72,
        "ARC":51.96,
        "HellaSwag":75.84,
        "MMLU":42.85,
        "TruthfulQA":37.94,
        "Winogrande":72.14,
        "GSM8K":5.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4",
        "Average":47.7,
        "ARC":53.07,
        "HellaSwag":78.69,
        "MMLU":38.9,
        "TruthfulQA":40.72,
        "Winogrande":73.09,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/airoboros-7b-gpt4-fp16",
        "Average":47.7,
        "ARC":53.07,
        "HellaSwag":78.67,
        "MMLU":38.88,
        "TruthfulQA":40.73,
        "Winogrande":73.09,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"damerajee\/Gaja-v1.00",
        "Average":47.69,
        "ARC":52.82,
        "HellaSwag":76.31,
        "MMLU":40.83,
        "TruthfulQA":44.64,
        "Winogrande":70.64,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/phi-1_5",
        "Average":47.69,
        "ARC":52.9,
        "HellaSwag":63.79,
        "MMLU":43.89,
        "TruthfulQA":40.89,
        "Winogrande":72.22,
        "GSM8K":12.43,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.5,
        "Model Sha":1252.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"azale-ai\/DukunLM-7B-V1.0-Uncensored",
        "Average":47.68,
        "ARC":51.11,
        "HellaSwag":75.62,
        "MMLU":39.82,
        "TruthfulQA":43.95,
        "Winogrande":69.53,
        "GSM8K":6.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"elyza\/ELYZA-japanese-Llama-2-7b-fast",
        "Average":47.67,
        "ARC":51.88,
        "HellaSwag":75.46,
        "MMLU":44.34,
        "TruthfulQA":36.45,
        "Winogrande":71.59,
        "GSM8K":6.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jphme\/orca_mini_v2_ger_7b",
        "Average":47.65,
        "ARC":49.83,
        "HellaSwag":75.5,
        "MMLU":39.1,
        "TruthfulQA":45.74,
        "Winogrande":71.59,
        "GSM8K":4.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openthaigpt\/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
        "Average":47.65,
        "ARC":50.85,
        "HellaSwag":74.89,
        "MMLU":40.02,
        "TruthfulQA":47.23,
        "Winogrande":69.06,
        "GSM8K":3.87,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"keyfan\/vicuna-chinese-replication-v1.1",
        "Average":47.65,
        "ARC":42.83,
        "HellaSwag":71.47,
        "MMLU":47.47,
        "TruthfulQA":47.24,
        "Winogrande":67.4,
        "GSM8K":9.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"golaxy\/gowizardlm",
        "Average":47.64,
        "ARC":49.74,
        "HellaSwag":71.9,
        "MMLU":42.96,
        "TruthfulQA":47.66,
        "Winogrande":69.61,
        "GSM8K":3.94,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"teilomillet\/MiniMerlin-3B",
        "Average":47.63,
        "ARC":44.37,
        "HellaSwag":66.56,
        "MMLU":43.21,
        "TruthfulQA":47.07,
        "Winogrande":64.4,
        "GSM8K":20.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"project-baize\/baize-healthcare-lora-7B",
        "Average":47.62,
        "ARC":54.1,
        "HellaSwag":77.32,
        "MMLU":37.09,
        "TruthfulQA":39.96,
        "Winogrande":72.85,
        "GSM8K":4.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bigcode\/starcoderplus",
        "Average":47.61,
        "ARC":48.72,
        "HellaSwag":77.3,
        "MMLU":43.72,
        "TruthfulQA":37.85,
        "Winogrande":70.01,
        "GSM8K":8.04,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":210.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/gemma-2b-it-tamil-v0.1-alpha",
        "Average":47.6,
        "ARC":50.09,
        "HellaSwag":71.41,
        "MMLU":39.94,
        "TruthfulQA":42.63,
        "Winogrande":64.96,
        "GSM8K":16.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tensoic\/Kan-Llama-SFT-v0.5",
        "Average":47.56,
        "ARC":47.44,
        "HellaSwag":72.71,
        "MMLU":42.71,
        "TruthfulQA":47.44,
        "Winogrande":69.69,
        "GSM8K":5.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"s3nh\/nsfw-noromaid-mistral-instruct",
        "Average":47.49,
        "ARC":51.79,
        "HellaSwag":75.39,
        "MMLU":46.47,
        "TruthfulQA":33.49,
        "Winogrande":71.19,
        "GSM8K":6.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Neko-Institute-of-Science\/metharme-7b",
        "Average":47.48,
        "ARC":53.67,
        "HellaSwag":78.62,
        "MMLU":35.91,
        "TruthfulQA":39.16,
        "Winogrande":72.53,
        "GSM8K":5.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DevaMalla\/llama_7b_qlora_cds",
        "Average":47.43,
        "ARC":52.47,
        "HellaSwag":77.76,
        "MMLU":32.38,
        "TruthfulQA":46.14,
        "Winogrande":71.74,
        "GSM8K":4.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aiplanet\/effi-7b",
        "Average":47.42,
        "ARC":55.12,
        "HellaSwag":78.07,
        "MMLU":35.91,
        "TruthfulQA":39.71,
        "Winogrande":72.53,
        "GSM8K":3.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4-1.2",
        "Average":47.42,
        "ARC":52.13,
        "HellaSwag":78.14,
        "MMLU":38.64,
        "TruthfulQA":41.79,
        "Winogrande":71.67,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_v2_7b",
        "Average":47.41,
        "ARC":50.77,
        "HellaSwag":76.02,
        "MMLU":39.5,
        "TruthfulQA":43.86,
        "Winogrande":71.43,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b",
        "Average":47.4,
        "ARC":53.07,
        "HellaSwag":77.65,
        "MMLU":37.23,
        "TruthfulQA":43.39,
        "Winogrande":70.96,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-shishya-7b-ep3-v1",
        "Average":47.4,
        "ARC":45.9,
        "HellaSwag":76.36,
        "MMLU":50.04,
        "TruthfulQA":40.32,
        "Winogrande":71.74,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jxhong\/CAlign-alpaca-7b",
        "Average":47.39,
        "ARC":50.94,
        "HellaSwag":74.55,
        "MMLU":38.56,
        "TruthfulQA":46.89,
        "Winogrande":72.06,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-7b-8k-instruct",
        "Average":47.37,
        "ARC":45.9,
        "HellaSwag":74.47,
        "MMLU":41.97,
        "TruthfulQA":35.21,
        "Winogrande":65.98,
        "GSM8K":20.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/LLaMarada-7B-v0.1-16bit",
        "Average":47.35,
        "ARC":53.33,
        "HellaSwag":76.02,
        "MMLU":39.68,
        "TruthfulQA":37.13,
        "Winogrande":70.96,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/guanaco-7B-HF",
        "Average":47.34,
        "ARC":52.99,
        "HellaSwag":80.05,
        "MMLU":35.32,
        "TruthfulQA":39.2,
        "Winogrande":71.43,
        "GSM8K":5.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"h2m\/mhm-7b-v1.3",
        "Average":47.29,
        "ARC":47.53,
        "HellaSwag":65.31,
        "MMLU":45.74,
        "TruthfulQA":46.22,
        "Winogrande":62.27,
        "GSM8K":16.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_13b",
        "Average":47.26,
        "ARC":51.19,
        "HellaSwag":75.23,
        "MMLU":43.75,
        "TruthfulQA":38.08,
        "Winogrande":72.06,
        "GSM8K":3.26,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":452.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rufjdk5480\/mixtral-ko-qna-merged",
        "Average":47.24,
        "ARC":39.51,
        "HellaSwag":39.06,
        "MMLU":71.86,
        "TruthfulQA":48.61,
        "Winogrande":56.75,
        "GSM8K":27.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rufjdk5480\/gov-qna-ko-merged",
        "Average":47.24,
        "ARC":39.51,
        "HellaSwag":39.06,
        "MMLU":71.86,
        "TruthfulQA":48.61,
        "Winogrande":56.75,
        "GSM8K":27.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":46.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mosaicml\/mpt-7b-8k",
        "Average":47.24,
        "ARC":47.35,
        "HellaSwag":77.4,
        "MMLU":42.58,
        "TruthfulQA":36.65,
        "Winogrande":71.11,
        "GSM8K":8.34,
        "Type":"pretrained",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Undi95\/Mixtral-8x7B-MoE-RP-Story",
        "Average":47.23,
        "ARC":51.54,
        "HellaSwag":70.0,
        "MMLU":43.04,
        "TruthfulQA":41.53,
        "Winogrande":67.32,
        "GSM8K":9.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":46.7,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Cluj-Napoca-0.3",
        "Average":47.22,
        "ARC":49.23,
        "HellaSwag":70.2,
        "MMLU":46.67,
        "TruthfulQA":47.13,
        "Winogrande":70.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":25.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Shiki-v2-m7",
        "Average":47.21,
        "ARC":47.35,
        "HellaSwag":51.71,
        "MMLU":62.62,
        "TruthfulQA":61.98,
        "Winogrande":59.27,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/CodeLlama13B-Finetune-v1",
        "Average":47.19,
        "ARC":45.82,
        "HellaSwag":69.36,
        "MMLU":45.05,
        "TruthfulQA":44.97,
        "Winogrande":66.93,
        "GSM8K":10.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/gemma-2b-zephyr-sft",
        "Average":47.18,
        "ARC":49.74,
        "HellaSwag":72.38,
        "MMLU":41.37,
        "TruthfulQA":34.42,
        "Winogrande":66.93,
        "GSM8K":18.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mosaicml\/mpt-7b-8k-instruct",
        "Average":47.18,
        "ARC":45.48,
        "HellaSwag":74.41,
        "MMLU":42.11,
        "TruthfulQA":35.06,
        "Winogrande":65.51,
        "GSM8K":20.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"starmpcc\/Asclepius-Llama2-7B",
        "Average":47.15,
        "ARC":50.85,
        "HellaSwag":76.53,
        "MMLU":43.61,
        "TruthfulQA":43.31,
        "Winogrande":68.27,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"rinna\/youri-7b",
        "Average":47.11,
        "ARC":49.06,
        "HellaSwag":74.89,
        "MMLU":42.22,
        "TruthfulQA":36.03,
        "Winogrande":71.82,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"itsliupeng\/openllama-7b-base",
        "Average":47.09,
        "ARC":46.16,
        "HellaSwag":76.4,
        "MMLU":42.82,
        "TruthfulQA":36.65,
        "Winogrande":70.88,
        "GSM8K":9.63,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/LLaMA-2-7B-32K",
        "Average":47.07,
        "ARC":47.53,
        "HellaSwag":76.14,
        "MMLU":43.33,
        "TruthfulQA":39.23,
        "Winogrande":71.9,
        "GSM8K":4.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":512.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-gpt-3.5-turbo-100k-7b",
        "Average":47.05,
        "ARC":53.07,
        "HellaSwag":76.16,
        "MMLU":33.63,
        "TruthfulQA":45.07,
        "Winogrande":70.8,
        "GSM8K":3.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"vicgalleorg\/TruthfulQwen1.5-1.8B",
        "Average":47.02,
        "ARC":38.74,
        "HellaSwag":61.35,
        "MMLU":46.98,
        "TruthfulQA":40.58,
        "Winogrande":60.38,
        "GSM8K":34.12,
        "Type":"base merges and moerges",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"damerajee\/Gaja-vv1",
        "Average":47.02,
        "ARC":51.54,
        "HellaSwag":75.49,
        "MMLU":39.94,
        "TruthfulQA":42.32,
        "Winogrande":71.98,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"notstoic\/PygmalionCoT-7b",
        "Average":47.0,
        "ARC":51.45,
        "HellaSwag":76.92,
        "MMLU":33.35,
        "TruthfulQA":48.13,
        "Winogrande":68.9,
        "GSM8K":3.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"damerajee\/Gaja-v2.00",
        "Average":46.98,
        "ARC":51.79,
        "HellaSwag":75.79,
        "MMLU":40.69,
        "TruthfulQA":41.5,
        "Winogrande":71.9,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mncai\/chatdoctor",
        "Average":46.95,
        "ARC":53.75,
        "HellaSwag":78.54,
        "MMLU":35.95,
        "TruthfulQA":43.55,
        "Winogrande":69.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LLaMAForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":10.0
    },
    {
        "T":"?",
        "Model":"ausboss\/llama7b-wizardlm-unfiltered",
        "Average":46.94,
        "ARC":52.99,
        "HellaSwag":77.89,
        "MMLU":36.41,
        "TruthfulQA":37.75,
        "Winogrande":72.3,
        "GSM8K":4.32,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/dolphin-llama2-7b",
        "Average":46.94,
        "ARC":46.59,
        "HellaSwag":67.52,
        "MMLU":48.37,
        "TruthfulQA":49.72,
        "Winogrande":63.77,
        "GSM8K":5.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WhiteRabbitNeo\/WhiteRabbitNeo-33B-v1",
        "Average":46.93,
        "ARC":44.37,
        "HellaSwag":60.22,
        "MMLU":40.56,
        "TruthfulQA":41.68,
        "Winogrande":61.01,
        "GSM8K":33.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.0,
        "Model Sha":76.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/gemma-2b-zephyr-dpo",
        "Average":46.92,
        "ARC":49.66,
        "HellaSwag":72.23,
        "MMLU":41.13,
        "TruthfulQA":34.47,
        "Winogrande":66.54,
        "GSM8K":17.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"damerajee\/Gaja-v2.00-dpo",
        "Average":46.91,
        "ARC":51.71,
        "HellaSwag":75.87,
        "MMLU":40.79,
        "TruthfulQA":41.29,
        "Winogrande":71.59,
        "GSM8K":0.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4-1.3",
        "Average":46.91,
        "ARC":52.47,
        "HellaSwag":77.98,
        "MMLU":41.97,
        "TruthfulQA":35.73,
        "Winogrande":72.3,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stanford-oval\/Llama-2-7b-WikiChat-fused",
        "Average":46.81,
        "ARC":50.68,
        "HellaSwag":75.0,
        "MMLU":39.69,
        "TruthfulQA":46.36,
        "Winogrande":69.06,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-4B-Chat",
        "Average":46.79,
        "ARC":43.26,
        "HellaSwag":69.73,
        "MMLU":55.55,
        "TruthfulQA":44.79,
        "Winogrande":64.96,
        "GSM8K":2.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.95,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DevaMalla\/llama_7b_lora",
        "Average":46.77,
        "ARC":54.86,
        "HellaSwag":79.1,
        "MMLU":33.63,
        "TruthfulQA":34.74,
        "Winogrande":72.77,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"project-baize\/baize-v2-7b",
        "Average":46.72,
        "ARC":48.98,
        "HellaSwag":75.06,
        "MMLU":39.6,
        "TruthfulQA":41.39,
        "Winogrande":71.11,
        "GSM8K":4.17,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-dolphin-orca-platypus-13b",
        "Average":46.7,
        "ARC":44.8,
        "HellaSwag":68.6,
        "MMLU":44.03,
        "TruthfulQA":46.28,
        "Winogrande":66.93,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-platypus-13b",
        "Average":46.68,
        "ARC":46.16,
        "HellaSwag":68.88,
        "MMLU":44.55,
        "TruthfulQA":44.98,
        "Winogrande":66.14,
        "GSM8K":9.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.2-yi-34b-200k",
        "Average":46.67,
        "ARC":42.24,
        "HellaSwag":68.22,
        "MMLU":55.51,
        "TruthfulQA":45.94,
        "Winogrande":64.17,
        "GSM8K":3.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ehartford\/dolphin-2.2-yi-34b-200k",
        "Average":46.67,
        "ARC":42.15,
        "HellaSwag":68.18,
        "MMLU":55.47,
        "TruthfulQA":45.93,
        "Winogrande":64.56,
        "GSM8K":3.71,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":34.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt2-7b",
        "Average":46.65,
        "ARC":46.76,
        "HellaSwag":71.53,
        "MMLU":42.85,
        "TruthfulQA":47.85,
        "Winogrande":68.67,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sarvamai\/OpenHathi-7B-Hi-v0.1-Base",
        "Average":46.64,
        "ARC":49.49,
        "HellaSwag":74.34,
        "MMLU":41.38,
        "TruthfulQA":37.46,
        "Winogrande":71.27,
        "GSM8K":5.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":80.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-2-2",
        "Average":46.63,
        "ARC":51.45,
        "HellaSwag":65.86,
        "MMLU":51.77,
        "TruthfulQA":45.12,
        "Winogrande":65.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/llama-2-7b-small-model-new",
        "Average":46.62,
        "ARC":45.22,
        "HellaSwag":72.35,
        "MMLU":46.23,
        "TruthfulQA":42.46,
        "Winogrande":63.93,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DevaMalla\/llama_7b_qlora",
        "Average":46.61,
        "ARC":55.12,
        "HellaSwag":78.26,
        "MMLU":35.71,
        "TruthfulQA":33.98,
        "Winogrande":72.06,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Average":46.58,
        "ARC":46.59,
        "HellaSwag":75.94,
        "MMLU":45.23,
        "TruthfulQA":37.2,
        "Winogrande":71.19,
        "GSM8K":3.34,
        "Type":"pretrained",
        "Architecture":"StableLMEpochForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":2.8,
        "Model Sha":305.0
    },
    {
        "T":"?",
        "Model":"chavinlo\/alpaca-native",
        "Average":46.58,
        "ARC":52.3,
        "HellaSwag":77.09,
        "MMLU":41.6,
        "TruthfulQA":37.58,
        "Winogrande":69.46,
        "GSM8K":1.44,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":258.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-1.8B",
        "Average":46.55,
        "ARC":37.88,
        "HellaSwag":61.42,
        "MMLU":46.71,
        "TruthfulQA":39.43,
        "Winogrande":60.3,
        "GSM8K":33.59,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt2-13b",
        "Average":46.55,
        "ARC":48.38,
        "HellaSwag":71.78,
        "MMLU":44.5,
        "TruthfulQA":44.73,
        "Winogrande":67.88,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"google\/gemma-2b",
        "Average":46.51,
        "ARC":48.46,
        "HellaSwag":71.65,
        "MMLU":41.68,
        "TruthfulQA":33.13,
        "Winogrande":66.77,
        "GSM8K":17.36,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":615.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DevaMalla\/llama7b_alpaca_1gpu_bf16",
        "Average":46.49,
        "ARC":52.73,
        "HellaSwag":78.78,
        "MMLU":36.26,
        "TruthfulQA":33.71,
        "Winogrande":72.93,
        "GSM8K":4.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Pygmalion_AlpacaLora-7b",
        "Average":46.49,
        "ARC":53.24,
        "HellaSwag":76.92,
        "MMLU":35.92,
        "TruthfulQA":39.44,
        "Winogrande":72.22,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cognitivecomputations\/dolphin-2.2-yi-34b-200k",
        "Average":46.47,
        "ARC":42.06,
        "HellaSwag":68.13,
        "MMLU":55.35,
        "TruthfulQA":45.93,
        "Winogrande":64.25,
        "GSM8K":3.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":34.0,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"glenn2\/gemma-7b-lora-distilabel-intel-orca-dpo-pairs",
        "Average":46.47,
        "ARC":49.15,
        "HellaSwag":71.78,
        "MMLU":41.52,
        "TruthfulQA":33.1,
        "Winogrande":65.98,
        "GSM8K":17.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aloobun\/Synch-Qwen1.5-1.8B",
        "Average":46.43,
        "ARC":36.95,
        "HellaSwag":60.19,
        "MMLU":44.82,
        "TruthfulQA":41.44,
        "Winogrande":61.25,
        "GSM8K":33.97,
        "Type":"base merges and moerges",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0x7194633\/fialka-7B-v3",
        "Average":46.4,
        "ARC":48.55,
        "HellaSwag":71.05,
        "MMLU":43.06,
        "TruthfulQA":44.79,
        "Winogrande":69.46,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"glenn2\/gemma-2b-lora3",
        "Average":46.4,
        "ARC":47.27,
        "HellaSwag":71.83,
        "MMLU":38.04,
        "TruthfulQA":36.42,
        "Winogrande":67.25,
        "GSM8K":17.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jerryjalapeno\/nart-100k-7b",
        "Average":46.39,
        "ARC":54.1,
        "HellaSwag":78.47,
        "MMLU":34.98,
        "TruthfulQA":36.74,
        "Winogrande":70.48,
        "GSM8K":3.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt-7b",
        "Average":46.38,
        "ARC":48.81,
        "HellaSwag":73.79,
        "MMLU":43.03,
        "TruthfulQA":41.0,
        "Winogrande":69.77,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"huggyllama\/llama-7b",
        "Average":46.37,
        "ARC":50.94,
        "HellaSwag":77.81,
        "MMLU":35.69,
        "TruthfulQA":34.33,
        "Winogrande":71.43,
        "GSM8K":8.04,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":253.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"google\/gemma-2b",
        "Average":46.37,
        "ARC":48.38,
        "HellaSwag":71.77,
        "MMLU":41.77,
        "TruthfulQA":33.08,
        "Winogrande":66.3,
        "GSM8K":16.91,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":615.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/OpenHermes-Gemma-2B",
        "Average":46.36,
        "ARC":49.32,
        "HellaSwag":72.26,
        "MMLU":37.67,
        "TruthfulQA":41.69,
        "Winogrande":65.11,
        "GSM8K":12.13,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.51,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"glenn2\/gemma-2b-lora16b2",
        "Average":46.35,
        "ARC":47.53,
        "HellaSwag":71.97,
        "MMLU":38.12,
        "TruthfulQA":36.45,
        "Winogrande":66.93,
        "GSM8K":17.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JiheonJeong\/v1",
        "Average":46.35,
        "ARC":48.29,
        "HellaSwag":71.74,
        "MMLU":41.78,
        "TruthfulQA":33.09,
        "Winogrande":66.22,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"JiheonJeong\/v1",
        "Average":46.35,
        "ARC":48.12,
        "HellaSwag":71.6,
        "MMLU":41.83,
        "TruthfulQA":33.04,
        "Winogrande":66.06,
        "GSM8K":17.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Menouar\/gemma-2b-chat-ultra",
        "Average":46.35,
        "ARC":48.29,
        "HellaSwag":70.18,
        "MMLU":39.19,
        "TruthfulQA":39.07,
        "Winogrande":65.35,
        "GSM8K":16.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jondurbin\/airoboros-7b-gpt4-1.4.1-qlora",
        "Average":46.34,
        "ARC":52.73,
        "HellaSwag":77.89,
        "MMLU":38.77,
        "TruthfulQA":36.07,
        "Winogrande":70.32,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wenge-research\/yayi-13b-llama2",
        "Average":46.32,
        "ARC":48.55,
        "HellaSwag":74.82,
        "MMLU":38.68,
        "TruthfulQA":42.19,
        "Winogrande":69.69,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-codellama-dolphin-orca-platypus-13b",
        "Average":46.32,
        "ARC":45.82,
        "HellaSwag":67.71,
        "MMLU":45.88,
        "TruthfulQA":44.67,
        "Winogrande":65.35,
        "GSM8K":8.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-orca-13b",
        "Average":46.28,
        "ARC":46.33,
        "HellaSwag":67.71,
        "MMLU":47.19,
        "TruthfulQA":46.66,
        "Winogrande":63.77,
        "GSM8K":5.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yhyhy3\/open_llama_7b_v2_med_instruct",
        "Average":46.24,
        "ARC":46.5,
        "HellaSwag":76.91,
        "MMLU":42.32,
        "TruthfulQA":40.33,
        "Winogrande":69.3,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Menouar\/gemma-2b-chat",
        "Average":46.2,
        "ARC":48.72,
        "HellaSwag":70.27,
        "MMLU":39.81,
        "TruthfulQA":38.79,
        "Winogrande":65.27,
        "GSM8K":14.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-llama2-7b-pretrain",
        "Average":46.18,
        "ARC":48.63,
        "HellaSwag":74.83,
        "MMLU":41.04,
        "TruthfulQA":39.08,
        "Winogrande":70.24,
        "GSM8K":3.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Average":46.18,
        "ARC":47.35,
        "HellaSwag":77.08,
        "MMLU":45.1,
        "TruthfulQA":36.46,
        "Winogrande":68.51,
        "GSM8K":2.58,
        "Type":"pretrained",
        "Architecture":"StableLMAlphaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":6.89,
        "Model Sha":47.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/carl-7b",
        "Average":46.16,
        "ARC":53.5,
        "HellaSwag":78.29,
        "MMLU":33.96,
        "TruthfulQA":40.29,
        "Winogrande":68.59,
        "GSM8K":2.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":7.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/vicuna-class-shishya-7b-ep3",
        "Average":46.14,
        "ARC":40.61,
        "HellaSwag":76.72,
        "MMLU":50.77,
        "TruthfulQA":36.87,
        "Winogrande":71.9,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vilm\/Quyen-Mini-v0.1",
        "Average":46.14,
        "ARC":39.33,
        "HellaSwag":60.57,
        "MMLU":43.93,
        "TruthfulQA":46.44,
        "Winogrande":59.12,
        "GSM8K":27.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/mistral-class-tutor-7b-ep3",
        "Average":46.09,
        "ARC":47.95,
        "HellaSwag":77.8,
        "MMLU":34.57,
        "TruthfulQA":44.69,
        "Winogrande":71.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom",
        "Average":46.07,
        "ARC":50.43,
        "HellaSwag":76.41,
        "MMLU":30.85,
        "TruthfulQA":39.76,
        "Winogrande":72.06,
        "GSM8K":6.9,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":176.25,
        "Model Sha":4506.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fireballoon\/baichuan-vicuna-chinese-7b",
        "Average":46.06,
        "ARC":43.52,
        "HellaSwag":71.12,
        "MMLU":46.87,
        "TruthfulQA":42.45,
        "Winogrande":66.85,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":62.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"NYTK\/PULI-LlumiX-32K",
        "Average":46.05,
        "ARC":48.63,
        "HellaSwag":75.0,
        "MMLU":41.65,
        "TruthfulQA":36.93,
        "Winogrande":68.03,
        "GSM8K":6.07,
        "Type":"continuously pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"illuin\/test-custom-llama",
        "Average":46.05,
        "ARC":52.3,
        "HellaSwag":77.49,
        "MMLU":36.61,
        "TruthfulQA":33.81,
        "Winogrande":72.06,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Neko-Institute-of-Science\/pygmalion-7b",
        "Average":46.04,
        "ARC":51.37,
        "HellaSwag":77.81,
        "MMLU":35.68,
        "TruthfulQA":34.54,
        "Winogrande":72.22,
        "GSM8K":4.62,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mctaco-modified2",
        "Average":46.03,
        "ARC":42.92,
        "HellaSwag":73.97,
        "MMLU":48.49,
        "TruthfulQA":40.43,
        "Winogrande":69.69,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/TheTop-5x7B-Instruct-P-v0.1",
        "Average":46.02,
        "ARC":38.57,
        "HellaSwag":51.54,
        "MMLU":63.36,
        "TruthfulQA":50.07,
        "Winogrande":72.61,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"shuvom\/yuj-v1",
        "Average":45.97,
        "ARC":45.65,
        "HellaSwag":70.1,
        "MMLU":43.78,
        "TruthfulQA":41.69,
        "Winogrande":69.85,
        "GSM8K":4.78,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.87,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/Reyna-Mini-1.8B-v0.2",
        "Average":45.94,
        "ARC":36.6,
        "HellaSwag":60.19,
        "MMLU":44.75,
        "TruthfulQA":41.24,
        "Winogrande":61.56,
        "GSM8K":31.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fierysurf\/Ambari-7B-base-v0.1-sharded",
        "Average":45.92,
        "ARC":47.95,
        "HellaSwag":74.62,
        "MMLU":40.39,
        "TruthfulQA":38.91,
        "Winogrande":72.06,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/ssh_1.8B",
        "Average":45.91,
        "ARC":39.08,
        "HellaSwag":62.37,
        "MMLU":44.09,
        "TruthfulQA":43.15,
        "Winogrande":59.27,
        "GSM8K":27.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"qnguyen3\/quan-1.8b-chat",
        "Average":45.91,
        "ARC":39.08,
        "HellaSwag":62.37,
        "MMLU":44.09,
        "TruthfulQA":43.15,
        "Winogrande":59.27,
        "GSM8K":27.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.8,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mihaiii\/Cluj-Napoca-0.2",
        "Average":45.91,
        "ARC":48.89,
        "HellaSwag":68.72,
        "MMLU":43.52,
        "TruthfulQA":44.77,
        "Winogrande":69.53,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":25.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/mistral_v1",
        "Average":45.85,
        "ARC":47.01,
        "HellaSwag":67.58,
        "MMLU":48.68,
        "TruthfulQA":37.53,
        "Winogrande":64.8,
        "GSM8K":9.48,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-13b-Instruct-hf",
        "Average":45.82,
        "ARC":44.54,
        "HellaSwag":64.93,
        "MMLU":38.89,
        "TruthfulQA":45.88,
        "Winogrande":68.03,
        "GSM8K":12.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":128.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nxn1231\/yi6",
        "Average":45.82,
        "ARC":47.78,
        "HellaSwag":68.25,
        "MMLU":54.05,
        "TruthfulQA":35.8,
        "Winogrande":64.64,
        "GSM8K":4.4,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheBloke\/CodeLlama-13B-Instruct-fp16",
        "Average":45.82,
        "ARC":44.62,
        "HellaSwag":64.94,
        "MMLU":38.77,
        "TruthfulQA":45.88,
        "Winogrande":68.03,
        "GSM8K":12.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sail\/Sailor-4B-Chat",
        "Average":45.8,
        "ARC":45.05,
        "HellaSwag":68.36,
        "MMLU":43.96,
        "TruthfulQA":42.09,
        "Winogrande":66.22,
        "GSM8K":9.1,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"universitytehran\/PersianMind-v1.0",
        "Average":45.78,
        "ARC":47.18,
        "HellaSwag":71.39,
        "MMLU":47.34,
        "TruthfulQA":41.37,
        "Winogrande":67.4,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":6.82,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fierysurf\/Kan-LLaMA-7B-SFT-v0.1-sharded",
        "Average":45.76,
        "ARC":45.9,
        "HellaSwag":71.43,
        "MMLU":40.86,
        "TruthfulQA":45.04,
        "Winogrande":68.82,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fierysurf\/Ambari-7B-Instruct-v0.1-sharded",
        "Average":45.74,
        "ARC":50.0,
        "HellaSwag":74.59,
        "MMLU":38.03,
        "TruthfulQA":40.39,
        "Winogrande":69.53,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"M4-ai\/tau-1.8B",
        "Average":45.73,
        "ARC":37.2,
        "HellaSwag":60.26,
        "MMLU":45.96,
        "TruthfulQA":39.72,
        "Winogrande":61.09,
        "GSM8K":30.17,
        "Type":"continuously pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lqtrung1998\/Codellama-7b-hf-ReFT-GSM8k",
        "Average":45.69,
        "ARC":43.52,
        "HellaSwag":64.53,
        "MMLU":40.86,
        "TruthfulQA":37.28,
        "Winogrande":64.25,
        "GSM8K":23.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Replete-AI\/Phi-Stoma",
        "Average":45.68,
        "ARC":48.46,
        "HellaSwag":60.29,
        "MMLU":51.53,
        "TruthfulQA":52.05,
        "Winogrande":61.72,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.82,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/llama2-7b-raw-sft",
        "Average":45.67,
        "ARC":47.44,
        "HellaSwag":75.25,
        "MMLU":33.86,
        "TruthfulQA":40.77,
        "Winogrande":73.01,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/mistral-7b-raw-sft",
        "Average":45.67,
        "ARC":47.44,
        "HellaSwag":75.25,
        "MMLU":33.86,
        "TruthfulQA":40.77,
        "Winogrande":73.01,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MAISAAI\/gemma-2b-coder",
        "Average":45.65,
        "ARC":48.98,
        "HellaSwag":71.43,
        "MMLU":37.02,
        "TruthfulQA":33.54,
        "Winogrande":66.85,
        "GSM8K":16.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":2.51,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mlabonne\/Gemmalpaca-2B",
        "Average":45.65,
        "ARC":48.72,
        "HellaSwag":71.36,
        "MMLU":36.3,
        "TruthfulQA":41.24,
        "Winogrande":65.59,
        "GSM8K":10.69,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggingface\/llama-7b",
        "Average":45.65,
        "ARC":51.02,
        "HellaSwag":77.82,
        "MMLU":35.71,
        "TruthfulQA":34.33,
        "Winogrande":71.43,
        "GSM8K":3.56,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Planner-7B-fp16",
        "Average":45.65,
        "ARC":51.02,
        "HellaSwag":77.82,
        "MMLU":35.71,
        "TruthfulQA":34.33,
        "Winogrande":71.43,
        "GSM8K":3.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"uukuguy\/speechless-codellama-platypus-13b",
        "Average":45.64,
        "ARC":45.31,
        "HellaSwag":68.63,
        "MMLU":42.82,
        "TruthfulQA":42.38,
        "Winogrande":65.59,
        "GSM8K":9.1,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"DevaMalla\/llama-base-7b",
        "Average":45.62,
        "ARC":50.94,
        "HellaSwag":77.8,
        "MMLU":35.67,
        "TruthfulQA":34.34,
        "Winogrande":71.43,
        "GSM8K":3.56,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WeOpenML\/PandaLM-Alpaca-7B-v1",
        "Average":45.59,
        "ARC":50.85,
        "HellaSwag":77.36,
        "MMLU":35.91,
        "TruthfulQA":36.63,
        "Winogrande":71.9,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/Hercules-Mini-1.8B",
        "Average":45.57,
        "ARC":37.03,
        "HellaSwag":59.53,
        "MMLU":44.77,
        "TruthfulQA":39.24,
        "Winogrande":62.27,
        "GSM8K":30.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-8",
        "Average":45.56,
        "ARC":49.49,
        "HellaSwag":78.55,
        "MMLU":30.3,
        "TruthfulQA":37.58,
        "Winogrande":70.48,
        "GSM8K":6.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"yeontaek\/WizardCoder-Python-13B-LoRa",
        "Average":45.56,
        "ARC":47.78,
        "HellaSwag":69.6,
        "MMLU":38.76,
        "TruthfulQA":43.97,
        "Winogrande":65.43,
        "GSM8K":7.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-4",
        "Average":45.54,
        "ARC":47.61,
        "HellaSwag":78.69,
        "MMLU":29.21,
        "TruthfulQA":37.79,
        "Winogrande":71.67,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-1",
        "Average":45.54,
        "ARC":47.61,
        "HellaSwag":78.69,
        "MMLU":29.21,
        "TruthfulQA":37.79,
        "Winogrande":71.67,
        "GSM8K":8.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/mistral-shishya-model-7b-ep3",
        "Average":45.53,
        "ARC":44.71,
        "HellaSwag":76.81,
        "MMLU":46.77,
        "TruthfulQA":33.87,
        "Winogrande":71.03,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ai4bharat\/Airavata",
        "Average":45.52,
        "ARC":46.5,
        "HellaSwag":69.26,
        "MMLU":43.9,
        "TruthfulQA":40.62,
        "Winogrande":68.82,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.87,
        "Model Sha":24.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/tamil-llama-7b-instruct-v0.1",
        "Average":45.52,
        "ARC":48.04,
        "HellaSwag":70.97,
        "MMLU":39.95,
        "TruthfulQA":41.7,
        "Winogrande":70.64,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-5",
        "Average":45.46,
        "ARC":48.38,
        "HellaSwag":78.51,
        "MMLU":29.52,
        "TruthfulQA":36.03,
        "Winogrande":71.82,
        "GSM8K":8.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Linly-AI\/Chinese-LLaMA-2-7B-hf",
        "Average":45.44,
        "ARC":48.04,
        "HellaSwag":73.25,
        "MMLU":35.04,
        "TruthfulQA":39.92,
        "Winogrande":70.17,
        "GSM8K":6.22,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shibing624\/chinese-llama-plus-13b-hf",
        "Average":45.39,
        "ARC":46.25,
        "HellaSwag":71.88,
        "MMLU":40.74,
        "TruthfulQA":39.89,
        "Winogrande":73.09,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-7b-chat",
        "Average":45.39,
        "ARC":46.5,
        "HellaSwag":75.51,
        "MMLU":37.62,
        "TruthfulQA":40.16,
        "Winogrande":68.43,
        "GSM8K":4.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":506.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mctaco-modified1",
        "Average":45.38,
        "ARC":40.87,
        "HellaSwag":73.4,
        "MMLU":47.42,
        "TruthfulQA":39.87,
        "Winogrande":69.46,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-0",
        "Average":45.38,
        "ARC":49.15,
        "HellaSwag":78.25,
        "MMLU":28.89,
        "TruthfulQA":36.18,
        "Winogrande":71.82,
        "GSM8K":7.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openthaigpt\/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf",
        "Average":45.35,
        "ARC":44.97,
        "HellaSwag":70.19,
        "MMLU":36.22,
        "TruthfulQA":49.99,
        "Winogrande":69.38,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"luqmanxyz\/FrankenVillain-7B-v1",
        "Average":45.34,
        "ARC":42.75,
        "HellaSwag":51.52,
        "MMLU":48.6,
        "TruthfulQA":56.19,
        "Winogrande":73.01,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beomi\/llama-2-ko-7b",
        "Average":45.32,
        "ARC":48.46,
        "HellaSwag":75.28,
        "MMLU":39.56,
        "TruthfulQA":34.49,
        "Winogrande":72.14,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.86,
        "Model Sha":156.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"haoranxu\/ALMA-7B",
        "Average":45.32,
        "ARC":50.34,
        "HellaSwag":75.5,
        "MMLU":38.04,
        "TruthfulQA":35.64,
        "Winogrande":72.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeneZC\/MiniChat-3B",
        "Average":45.31,
        "ARC":44.03,
        "HellaSwag":67.19,
        "MMLU":39.17,
        "TruthfulQA":45.67,
        "Winogrande":65.27,
        "GSM8K":10.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.02,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-c",
        "Average":45.29,
        "ARC":48.55,
        "HellaSwag":78.67,
        "MMLU":28.72,
        "TruthfulQA":38.26,
        "Winogrande":70.09,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ashercn97\/giraffe-7b",
        "Average":45.29,
        "ARC":47.18,
        "HellaSwag":75.53,
        "MMLU":38.89,
        "TruthfulQA":38.48,
        "Winogrande":68.98,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"facebook\/opt-iml-max-30b",
        "Average":45.28,
        "ARC":43.86,
        "HellaSwag":72.39,
        "MMLU":41.09,
        "TruthfulQA":38.16,
        "Winogrande":73.72,
        "GSM8K":2.5,
        "Type":"",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":36.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-openllama-7b-v12-bf16",
        "Average":45.28,
        "ARC":42.06,
        "HellaSwag":62.01,
        "MMLU":46.53,
        "TruthfulQA":45.18,
        "Winogrande":65.04,
        "GSM8K":10.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-3",
        "Average":45.27,
        "ARC":47.78,
        "HellaSwag":78.3,
        "MMLU":31.96,
        "TruthfulQA":36.43,
        "Winogrande":71.03,
        "GSM8K":6.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"StarFox7\/gemma-2b-dpo-v1",
        "Average":45.27,
        "ARC":51.88,
        "HellaSwag":70.87,
        "MMLU":37.7,
        "TruthfulQA":33.15,
        "Winogrande":67.25,
        "GSM8K":10.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-2-1_6b",
        "Average":45.25,
        "ARC":43.34,
        "HellaSwag":70.45,
        "MMLU":38.95,
        "TruthfulQA":36.78,
        "Winogrande":64.56,
        "GSM8K":17.44,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.64,
        "Model Sha":149.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/Orca-2-13B-16k",
        "Average":45.22,
        "ARC":53.67,
        "HellaSwag":69.48,
        "MMLU":41.02,
        "TruthfulQA":45.3,
        "Winogrande":60.06,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.02,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PotatoOff\/HamSter-0.1",
        "Average":45.19,
        "ARC":46.93,
        "HellaSwag":68.08,
        "MMLU":43.03,
        "TruthfulQA":51.24,
        "Winogrande":61.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kalisai\/Nusantara-4b-Indo-Chat",
        "Average":45.19,
        "ARC":45.39,
        "HellaSwag":70.16,
        "MMLU":38.39,
        "TruthfulQA":38.38,
        "Winogrande":67.25,
        "GSM8K":11.6,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/llama-shishya-7b-ep3-v1",
        "Average":45.19,
        "ARC":48.04,
        "HellaSwag":76.63,
        "MMLU":46.12,
        "TruthfulQA":30.9,
        "Winogrande":69.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Enno-Ai\/ennodata-7b",
        "Average":45.13,
        "ARC":51.02,
        "HellaSwag":77.62,
        "MMLU":33.95,
        "TruthfulQA":33.53,
        "Winogrande":70.96,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"abhinand\/gemma-2b-tamil",
        "Average":45.13,
        "ARC":47.44,
        "HellaSwag":71.3,
        "MMLU":38.21,
        "TruthfulQA":34.93,
        "Winogrande":65.98,
        "GSM8K":12.89,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jlevin\/guanaco-unchained-llama-2-7b",
        "Average":45.11,
        "ARC":47.35,
        "HellaSwag":72.16,
        "MMLU":41.76,
        "TruthfulQA":41.49,
        "Winogrande":64.48,
        "GSM8K":3.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-coding-7b-16k-tora",
        "Average":45.1,
        "ARC":41.21,
        "HellaSwag":64.45,
        "MMLU":39.14,
        "TruthfulQA":44.91,
        "Winogrande":63.61,
        "GSM8K":17.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/vicuna-7b-v1.5-lora-mctaco-modified4",
        "Average":45.1,
        "ARC":40.7,
        "HellaSwag":73.08,
        "MMLU":47.26,
        "TruthfulQA":41.59,
        "Winogrande":67.88,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Replete-AI\/Phi-Delthanar",
        "Average":45.07,
        "ARC":46.67,
        "HellaSwag":60.19,
        "MMLU":51.16,
        "TruthfulQA":50.92,
        "Winogrande":61.48,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.82,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Telugu-LLM-Labs\/Indic-gemma-2b-finetuned-sft-Navarasa-2.0",
        "Average":45.06,
        "ARC":44.71,
        "HellaSwag":68.4,
        "MMLU":38.21,
        "TruthfulQA":44.69,
        "Winogrande":65.11,
        "GSM8K":9.25,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-coding-7b-16k-tora",
        "Average":45.05,
        "ARC":41.13,
        "HellaSwag":64.48,
        "MMLU":38.86,
        "TruthfulQA":44.95,
        "Winogrande":63.85,
        "GSM8K":17.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/Qwen-VL-LLaMAfied-7B-Chat",
        "Average":45.0,
        "ARC":47.35,
        "HellaSwag":69.97,
        "MMLU":44.12,
        "TruthfulQA":42.87,
        "Winogrande":65.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":7.0,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-2",
        "Average":44.98,
        "ARC":47.18,
        "HellaSwag":78.47,
        "MMLU":28.83,
        "TruthfulQA":38.63,
        "Winogrande":70.4,
        "GSM8K":6.37,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kabster\/BioMistral-MedicalQA-FT",
        "Average":44.97,
        "ARC":40.02,
        "HellaSwag":67.26,
        "MMLU":23.12,
        "TruthfulQA":47.26,
        "Winogrande":61.56,
        "GSM8K":30.63,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"tyson0420\/stack_codellama-7b-inst",
        "Average":44.97,
        "ARC":43.52,
        "HellaSwag":66.17,
        "MMLU":39.59,
        "TruthfulQA":39.03,
        "Winogrande":65.67,
        "GSM8K":15.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/Qwenchana-4B-restart-OH",
        "Average":44.96,
        "ARC":45.31,
        "HellaSwag":70.42,
        "MMLU":37.93,
        "TruthfulQA":37.68,
        "Winogrande":66.85,
        "GSM8K":11.6,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.95,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/OpenHermes-Qwen1.5-1.8B",
        "Average":44.95,
        "ARC":37.8,
        "HellaSwag":59.73,
        "MMLU":45.8,
        "TruthfulQA":42.28,
        "Winogrande":60.22,
        "GSM8K":23.88,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"csitfun\/llama-7b-logicot",
        "Average":44.95,
        "ARC":47.01,
        "HellaSwag":72.56,
        "MMLU":38.93,
        "TruthfulQA":43.63,
        "Winogrande":67.56,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/WizardLM-7B-Uncensored",
        "Average":44.92,
        "ARC":47.87,
        "HellaSwag":73.08,
        "MMLU":35.42,
        "TruthfulQA":41.49,
        "Winogrande":68.43,
        "GSM8K":3.26,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenAssistant\/codellama-13b-oasst-sft-v10",
        "Average":44.85,
        "ARC":45.39,
        "HellaSwag":62.36,
        "MMLU":35.36,
        "TruthfulQA":45.02,
        "Winogrande":67.8,
        "GSM8K":13.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":64.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/NeuralReyna-Mini-1.8B-v0.2",
        "Average":44.85,
        "ARC":37.8,
        "HellaSwag":60.51,
        "MMLU":45.04,
        "TruthfulQA":37.75,
        "Winogrande":60.93,
        "GSM8K":27.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shareAI\/CodeLLaMA-chat-13b-Chinese",
        "Average":44.84,
        "ARC":43.26,
        "HellaSwag":63.87,
        "MMLU":34.29,
        "TruthfulQA":48.97,
        "Winogrande":67.88,
        "GSM8K":10.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":12.85,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Menouar\/saqr-7b-beta",
        "Average":44.84,
        "ARC":47.78,
        "HellaSwag":77.61,
        "MMLU":25.8,
        "TruthfulQA":39.38,
        "Winogrande":70.56,
        "GSM8K":7.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LLM360\/AmberChat",
        "Average":44.84,
        "ARC":42.92,
        "HellaSwag":74.01,
        "MMLU":38.75,
        "TruthfulQA":41.18,
        "Winogrande":66.61,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-7b-instruct",
        "Average":44.83,
        "ARC":50.34,
        "HellaSwag":77.91,
        "MMLU":32.35,
        "TruthfulQA":35.08,
        "Winogrande":70.48,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":457.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"uukuguy\/speechless-codellama-orca-13b",
        "Average":44.83,
        "ARC":44.37,
        "HellaSwag":65.2,
        "MMLU":43.46,
        "TruthfulQA":45.94,
        "Winogrande":64.01,
        "GSM8K":5.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vicgalle\/TruthfulQwen1.5-1.8B",
        "Average":44.81,
        "ARC":38.99,
        "HellaSwag":60.43,
        "MMLU":44.54,
        "TruthfulQA":50.86,
        "Winogrande":59.19,
        "GSM8K":14.86,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zorobin\/mistral-class-shishya-all-hal-7b-ep3",
        "Average":44.8,
        "ARC":46.59,
        "HellaSwag":78.87,
        "MMLU":34.45,
        "TruthfulQA":35.98,
        "Winogrande":72.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shibing624\/chinese-alpaca-plus-7b-hf",
        "Average":44.77,
        "ARC":49.23,
        "HellaSwag":70.48,
        "MMLU":38.39,
        "TruthfulQA":39.72,
        "Winogrande":70.09,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":50.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Menouar\/saqr-7b-merged",
        "Average":44.75,
        "ARC":47.7,
        "HellaSwag":77.51,
        "MMLU":25.78,
        "TruthfulQA":39.38,
        "Winogrande":70.56,
        "GSM8K":7.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeneZC\/MiniMA-2-3B",
        "Average":44.75,
        "ARC":44.71,
        "HellaSwag":69.33,
        "MMLU":41.22,
        "TruthfulQA":38.44,
        "Winogrande":66.69,
        "GSM8K":8.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Average":44.75,
        "ARC":37.71,
        "HellaSwag":58.87,
        "MMLU":46.37,
        "TruthfulQA":39.41,
        "Winogrande":61.72,
        "GSM8K":24.41,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":16.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Abhaykoul\/MediKAI",
        "Average":44.74,
        "ARC":46.5,
        "HellaSwag":60.56,
        "MMLU":49.3,
        "TruthfulQA":48.77,
        "Winogrande":61.72,
        "GSM8K":1.59,
        "Type":"base merges and moerges",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":14.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Writer\/palmyra-med-20b",
        "Average":44.71,
        "ARC":46.93,
        "HellaSwag":73.51,
        "MMLU":44.34,
        "TruthfulQA":35.47,
        "Winogrande":65.35,
        "GSM8K":2.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheBloke\/Poro-34B-GPTQ",
        "Average":44.67,
        "ARC":47.01,
        "HellaSwag":73.75,
        "MMLU":32.47,
        "TruthfulQA":38.37,
        "Winogrande":71.35,
        "GSM8K":5.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":48.06,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RESMPDEV\/Gemma-Wukong-2b",
        "Average":44.64,
        "ARC":45.9,
        "HellaSwag":66.83,
        "MMLU":38.01,
        "TruthfulQA":44.29,
        "Winogrande":62.98,
        "GSM8K":9.86,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RESMPDEV\/Gemma-Wukong-2b",
        "Average":44.55,
        "ARC":45.31,
        "HellaSwag":66.94,
        "MMLU":38.1,
        "TruthfulQA":44.29,
        "Winogrande":62.59,
        "GSM8K":10.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/ThetaWave-14B-v0.1",
        "Average":44.54,
        "ARC":42.83,
        "HellaSwag":47.09,
        "MMLU":61.45,
        "TruthfulQA":50.41,
        "Winogrande":65.43,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":14.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/tamil-llama-7b-base-v0.1",
        "Average":44.52,
        "ARC":46.67,
        "HellaSwag":72.85,
        "MMLU":40.95,
        "TruthfulQA":35.93,
        "Winogrande":70.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":9.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/Project-Baize-v2-7B-GPTQ",
        "Average":44.5,
        "ARC":45.99,
        "HellaSwag":73.44,
        "MMLU":35.46,
        "TruthfulQA":39.92,
        "Winogrande":69.69,
        "GSM8K":2.5,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":9.04,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"h2oai\/h2o-danube-1.8b-chat",
        "Average":44.49,
        "ARC":41.13,
        "HellaSwag":68.06,
        "MMLU":33.41,
        "TruthfulQA":41.64,
        "Winogrande":65.35,
        "GSM8K":17.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.83,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheDrummer\/Moistral-11B-v2",
        "Average":44.48,
        "ARC":45.14,
        "HellaSwag":71.9,
        "MMLU":39.01,
        "TruthfulQA":42.9,
        "Winogrande":67.96,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":11.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"qblocks\/falcon_7b_norobots",
        "Average":44.46,
        "ARC":47.87,
        "HellaSwag":77.92,
        "MMLU":27.94,
        "TruthfulQA":36.81,
        "Winogrande":71.74,
        "GSM8K":4.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jisukim8873\/falcon-7B-case-6",
        "Average":44.44,
        "ARC":46.5,
        "HellaSwag":78.49,
        "MMLU":28.97,
        "TruthfulQA":36.46,
        "Winogrande":70.09,
        "GSM8K":6.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WeOpenML\/Alpaca-7B-v1",
        "Average":44.41,
        "ARC":49.06,
        "HellaSwag":75.71,
        "MMLU":33.76,
        "TruthfulQA":36.28,
        "Winogrande":71.51,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/falcon_7b_norobots",
        "Average":44.4,
        "ARC":48.12,
        "HellaSwag":77.9,
        "MMLU":28.11,
        "TruthfulQA":36.76,
        "Winogrande":71.59,
        "GSM8K":3.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"csujeong\/Falcon-7B-Fintued-Finance-Stock-E",
        "Average":44.37,
        "ARC":50.09,
        "HellaSwag":78.26,
        "MMLU":27.36,
        "TruthfulQA":36.7,
        "Winogrande":70.72,
        "GSM8K":3.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"castorini\/rank_vicuna_7b_v1_fp16",
        "Average":44.36,
        "ARC":44.62,
        "HellaSwag":65.67,
        "MMLU":44.14,
        "TruthfulQA":45.13,
        "Winogrande":66.61,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/llama-shishya-7b-ep3-v2",
        "Average":44.33,
        "ARC":47.35,
        "HellaSwag":75.88,
        "MMLU":43.84,
        "TruthfulQA":30.16,
        "Winogrande":68.75,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-34b-Instruct-hf",
        "Average":44.33,
        "ARC":40.78,
        "HellaSwag":35.66,
        "MMLU":39.72,
        "TruthfulQA":44.29,
        "Winogrande":74.51,
        "GSM8K":31.01,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":262.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"liminerity\/ultra0",
        "Average":44.32,
        "ARC":41.47,
        "HellaSwag":68.02,
        "MMLU":33.37,
        "TruthfulQA":41.49,
        "Winogrande":65.51,
        "GSM8K":16.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/koala-7B-HF",
        "Average":44.29,
        "ARC":47.1,
        "HellaSwag":73.58,
        "MMLU":25.53,
        "TruthfulQA":45.96,
        "Winogrande":69.93,
        "GSM8K":3.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"anas-awadalla\/mpt-7b",
        "Average":44.28,
        "ARC":47.7,
        "HellaSwag":77.57,
        "MMLU":30.8,
        "TruthfulQA":33.44,
        "Winogrande":72.14,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mosaicml\/mpt-7b",
        "Average":44.28,
        "ARC":47.7,
        "HellaSwag":77.57,
        "MMLU":30.8,
        "TruthfulQA":33.44,
        "Winogrande":72.14,
        "GSM8K":4.02,
        "Type":"pretrained",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1139.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zorobin\/mistral-class-shishya-7b-ep3",
        "Average":44.28,
        "ARC":46.59,
        "HellaSwag":76.62,
        "MMLU":39.07,
        "TruthfulQA":33.54,
        "Winogrande":69.85,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_7b_v2",
        "Average":44.26,
        "ARC":43.69,
        "HellaSwag":72.2,
        "MMLU":41.29,
        "TruthfulQA":35.54,
        "Winogrande":69.38,
        "GSM8K":3.49,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Charlie911\/MultiLora-sharegpt",
        "Average":44.26,
        "ARC":45.65,
        "HellaSwag":65.54,
        "MMLU":37.95,
        "TruthfulQA":45.85,
        "Winogrande":66.61,
        "GSM8K":3.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sail\/Sailor-4B",
        "Average":44.19,
        "ARC":44.45,
        "HellaSwag":69.53,
        "MMLU":38.99,
        "TruthfulQA":37.02,
        "Winogrande":66.06,
        "GSM8K":9.1,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"llm-agents\/tora-code-13b-v1.0",
        "Average":44.19,
        "ARC":44.71,
        "HellaSwag":69.15,
        "MMLU":36.69,
        "TruthfulQA":34.98,
        "Winogrande":63.14,
        "GSM8K":16.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Writer\/palmyra-20b-chat",
        "Average":44.18,
        "ARC":43.52,
        "HellaSwag":72.83,
        "MMLU":35.18,
        "TruthfulQA":43.17,
        "Winogrande":66.46,
        "GSM8K":3.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":20.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-7b",
        "Average":44.17,
        "ARC":47.87,
        "HellaSwag":78.13,
        "MMLU":27.79,
        "TruthfulQA":34.26,
        "Winogrande":72.38,
        "GSM8K":4.62,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1019.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"speechlessai\/speechless-codellama-airoboros-orca-platypus-13b",
        "Average":44.1,
        "ARC":44.88,
        "HellaSwag":67.7,
        "MMLU":43.16,
        "TruthfulQA":40.88,
        "Winogrande":66.14,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"arshadshk\/Mistral-Hinglish-7B-Instruct-v0.2",
        "Average":44.09,
        "ARC":40.36,
        "HellaSwag":71.98,
        "MMLU":23.12,
        "TruthfulQA":49.96,
        "Winogrande":66.3,
        "GSM8K":12.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/falcon_7b_DolphinCoder",
        "Average":44.09,
        "ARC":48.72,
        "HellaSwag":78.03,
        "MMLU":27.08,
        "TruthfulQA":35.12,
        "Winogrande":70.48,
        "GSM8K":5.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/falcon_7b_DolphinCoder",
        "Average":44.09,
        "ARC":48.72,
        "HellaSwag":78.03,
        "MMLU":27.08,
        "TruthfulQA":35.12,
        "Winogrande":70.48,
        "GSM8K":5.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"bn999\/mistral-4.2B",
        "Average":44.06,
        "ARC":40.87,
        "HellaSwag":61.51,
        "MMLU":41.78,
        "TruthfulQA":44.82,
        "Winogrande":63.77,
        "GSM8K":11.6,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.42,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/GPT-JT-6B-v0",
        "Average":44.05,
        "ARC":42.06,
        "HellaSwag":67.96,
        "MMLU":49.34,
        "TruthfulQA":38.89,
        "Winogrande":64.8,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/gemoy-4b-instruct-scientific",
        "Average":44.04,
        "ARC":41.98,
        "HellaSwag":63.05,
        "MMLU":38.73,
        "TruthfulQA":41.96,
        "Winogrande":63.06,
        "GSM8K":15.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.57,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cyberagent\/calm2-7b-chat-dpo-experimental",
        "Average":44.03,
        "ARC":41.04,
        "HellaSwag":68.99,
        "MMLU":39.82,
        "TruthfulQA":43.13,
        "Winogrande":65.67,
        "GSM8K":5.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":7.01,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-1.8B-Chat",
        "Average":43.99,
        "ARC":38.74,
        "HellaSwag":60.02,
        "MMLU":45.87,
        "TruthfulQA":40.62,
        "Winogrande":59.67,
        "GSM8K":19.03,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"luffycodes\/llama-class-shishya-7b-ep3",
        "Average":43.88,
        "ARC":40.78,
        "HellaSwag":77.04,
        "MMLU":46.74,
        "TruthfulQA":27.94,
        "Winogrande":70.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/BigTranslate-13B-GPTQ",
        "Average":43.86,
        "ARC":45.31,
        "HellaSwag":75.1,
        "MMLU":31.18,
        "TruthfulQA":40.6,
        "Winogrande":70.96,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":17.99,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/Qwenchana-1.8B",
        "Average":43.83,
        "ARC":38.23,
        "HellaSwag":59.92,
        "MMLU":45.78,
        "TruthfulQA":39.58,
        "Winogrande":60.3,
        "GSM8K":19.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lvxy1117\/amber_fine_tune_sgall",
        "Average":43.77,
        "ARC":44.28,
        "HellaSwag":74.77,
        "MMLU":31.29,
        "TruthfulQA":40.48,
        "Winogrande":67.48,
        "GSM8K":4.32,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ise-uiuc\/Magicoder-S-CL-7B",
        "Average":43.73,
        "ARC":43.34,
        "HellaSwag":67.01,
        "MMLU":36.87,
        "TruthfulQA":38.67,
        "Winogrande":62.19,
        "GSM8K":14.33,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sail\/Sailor-4B",
        "Average":43.72,
        "ARC":43.86,
        "HellaSwag":69.51,
        "MMLU":37.45,
        "TruthfulQA":37.02,
        "Winogrande":65.67,
        "GSM8K":8.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.95,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AI-Sweden-Models\/gpt-sw3-20b-instruct",
        "Average":43.7,
        "ARC":43.17,
        "HellaSwag":71.09,
        "MMLU":31.32,
        "TruthfulQA":41.02,
        "Winogrande":66.77,
        "GSM8K":8.79,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.92,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2o-danube-1.8b-sft",
        "Average":43.68,
        "ARC":40.19,
        "HellaSwag":67.34,
        "MMLU":33.75,
        "TruthfulQA":40.29,
        "Winogrande":65.43,
        "GSM8K":15.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.83,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"synapsoft\/Llama-2-7b-hf-flan2022-1.2M",
        "Average":43.68,
        "ARC":23.29,
        "HellaSwag":78.46,
        "MMLU":42.33,
        "TruthfulQA":37.97,
        "Winogrande":75.53,
        "GSM8K":4.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"souvik0306\/falcon_7b_3epoch_norobots",
        "Average":43.65,
        "ARC":47.61,
        "HellaSwag":77.24,
        "MMLU":29.73,
        "TruthfulQA":36.27,
        "Winogrande":69.53,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hyunseoki\/ko-ref-llama2-13b",
        "Average":43.62,
        "ARC":48.38,
        "HellaSwag":73.56,
        "MMLU":34.83,
        "TruthfulQA":35.82,
        "Winogrande":69.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"deepseek-ai\/deepseek-coder-6.7b-instruct",
        "Average":43.57,
        "ARC":38.14,
        "HellaSwag":55.09,
        "MMLU":39.02,
        "TruthfulQA":45.56,
        "Winogrande":56.83,
        "GSM8K":26.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":258.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Fizzarolli\/sappha-2b-v3",
        "Average":43.53,
        "ARC":46.16,
        "HellaSwag":70.73,
        "MMLU":38.63,
        "TruthfulQA":39.94,
        "Winogrande":65.51,
        "GSM8K":0.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lvxy1117\/amber_fine_tune_sg_part1",
        "Average":43.5,
        "ARC":44.88,
        "HellaSwag":75.1,
        "MMLU":29.36,
        "TruthfulQA":40.85,
        "Winogrande":67.01,
        "GSM8K":3.79,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-40b",
        "Average":43.42,
        "ARC":43.0,
        "HellaSwag":72.37,
        "MMLU":34.97,
        "TruthfulQA":37.52,
        "Winogrande":67.96,
        "GSM8K":4.7,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":39.93,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/minima-3b-layla-v2",
        "Average":43.39,
        "ARC":44.2,
        "HellaSwag":69.93,
        "MMLU":28.53,
        "TruthfulQA":43.64,
        "Winogrande":65.43,
        "GSM8K":8.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":3.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-13b-hf",
        "Average":43.35,
        "ARC":40.87,
        "HellaSwag":63.35,
        "MMLU":32.81,
        "TruthfulQA":43.79,
        "Winogrande":67.17,
        "GSM8K":12.13,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":89.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/CodeLlama-13b-hf",
        "Average":43.35,
        "ARC":40.87,
        "HellaSwag":63.35,
        "MMLU":32.81,
        "TruthfulQA":43.79,
        "Winogrande":67.17,
        "GSM8K":12.13,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TigerResearch\/tigerbot-7b-sft",
        "Average":43.35,
        "ARC":41.64,
        "HellaSwag":60.56,
        "MMLU":29.89,
        "TruthfulQA":58.18,
        "Winogrande":63.54,
        "GSM8K":6.29,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"qnguyen3\/quan-1.8b-base",
        "Average":43.35,
        "ARC":36.95,
        "HellaSwag":58.46,
        "MMLU":45.44,
        "TruthfulQA":41.6,
        "Winogrande":57.93,
        "GSM8K":19.71,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.8,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/mistral-shishya-all-hal-7b-ep3-v2",
        "Average":43.31,
        "ARC":45.9,
        "HellaSwag":74.29,
        "MMLU":30.21,
        "TruthfulQA":39.71,
        "Winogrande":69.77,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fierysurf\/Kan-LLaMA-7B-base",
        "Average":43.31,
        "ARC":43.94,
        "HellaSwag":70.75,
        "MMLU":37.06,
        "TruthfulQA":39.57,
        "Winogrande":68.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lvxy1117\/amber_fine_tune_001",
        "Average":43.28,
        "ARC":44.8,
        "HellaSwag":73.78,
        "MMLU":30.41,
        "TruthfulQA":42.93,
        "Winogrande":64.09,
        "GSM8K":3.64,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cyberagent\/calm2-7b-chat",
        "Average":43.27,
        "ARC":40.27,
        "HellaSwag":68.12,
        "MMLU":39.39,
        "TruthfulQA":41.96,
        "Winogrande":64.96,
        "GSM8K":4.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/finetune_test_qwen15-1-8b-sft-lora",
        "Average":43.27,
        "ARC":36.18,
        "HellaSwag":57.77,
        "MMLU":44.96,
        "TruthfulQA":38.0,
        "Winogrande":61.17,
        "GSM8K":21.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"tiiuae\/falcon-7b-instruct",
        "Average":43.26,
        "ARC":46.16,
        "HellaSwag":70.85,
        "MMLU":25.84,
        "TruthfulQA":44.08,
        "Winogrande":67.96,
        "GSM8K":4.7,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":848.0
    },
    {
        "T":"?",
        "Model":"JosephusCheung\/Guanaco",
        "Average":43.25,
        "ARC":50.17,
        "HellaSwag":72.69,
        "MMLU":30.3,
        "TruthfulQA":37.64,
        "Winogrande":68.67,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":0.0,
        "Model Sha":229.0
    },
    {
        "T":"?",
        "Model":"l3utterfly\/minima-3b-layla-v1",
        "Average":43.21,
        "ARC":42.32,
        "HellaSwag":67.48,
        "MMLU":28.44,
        "TruthfulQA":46.46,
        "Winogrande":65.9,
        "GSM8K":8.64,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"tiiuae\/falcon-7b-instruct",
        "Average":43.16,
        "ARC":45.82,
        "HellaSwag":70.78,
        "MMLU":25.66,
        "TruthfulQA":44.07,
        "Winogrande":68.03,
        "GSM8K":4.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":848.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ziqingyang\/chinese-llama-2-7b",
        "Average":43.14,
        "ARC":44.45,
        "HellaSwag":69.5,
        "MMLU":37.47,
        "TruthfulQA":37.0,
        "Winogrande":68.98,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/GPT-JT-6B-v1",
        "Average":43.13,
        "ARC":40.87,
        "HellaSwag":67.15,
        "MMLU":47.19,
        "TruthfulQA":37.07,
        "Winogrande":65.27,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":301.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"u-chom\/ex-llm-e1",
        "Average":43.11,
        "ARC":39.93,
        "HellaSwag":68.11,
        "MMLU":39.44,
        "TruthfulQA":42.01,
        "Winogrande":64.88,
        "GSM8K":4.32,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"aloobun\/Cypher-Mini-1.8B",
        "Average":43.05,
        "ARC":39.59,
        "HellaSwag":67.45,
        "MMLU":31.14,
        "TruthfulQA":40.44,
        "Winogrande":65.19,
        "GSM8K":14.48,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.83,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"FreedomIntelligence\/phoenix-inst-chat-7b",
        "Average":43.03,
        "ARC":44.71,
        "HellaSwag":63.23,
        "MMLU":39.06,
        "TruthfulQA":47.08,
        "Winogrande":62.83,
        "GSM8K":1.29,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":43.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/GPT-NeoXT-Chat-Base-20B",
        "Average":43.02,
        "ARC":45.65,
        "HellaSwag":74.03,
        "MMLU":29.92,
        "TruthfulQA":34.51,
        "Winogrande":67.09,
        "GSM8K":6.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":695.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeorgiaTechResearchInstitute\/galpaca-30b",
        "Average":43.0,
        "ARC":49.57,
        "HellaSwag":58.2,
        "MMLU":43.78,
        "TruthfulQA":41.16,
        "Winogrande":62.51,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":30.0,
        "Model Sha":56.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheBloke\/CodeLlama-34B-Instruct-fp16",
        "Average":43.0,
        "ARC":40.78,
        "HellaSwag":35.66,
        "MMLU":39.72,
        "TruthfulQA":44.29,
        "Winogrande":74.51,
        "GSM8K":23.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lyogavin\/Anima-7B-100K",
        "Average":42.98,
        "ARC":46.59,
        "HellaSwag":72.28,
        "MMLU":33.4,
        "TruthfulQA":37.84,
        "Winogrande":67.09,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deita-1_8B",
        "Average":42.96,
        "ARC":36.52,
        "HellaSwag":60.63,
        "MMLU":45.62,
        "TruthfulQA":40.02,
        "Winogrande":59.35,
        "GSM8K":15.62,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":8.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoder2-7b",
        "Average":42.95,
        "ARC":38.31,
        "HellaSwag":51.91,
        "MMLU":41.21,
        "TruthfulQA":41.99,
        "Winogrande":59.19,
        "GSM8K":25.09,
        "Type":"pretrained",
        "Architecture":"Starcoder2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":7.17,
        "Model Sha":125.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Qwen-1_8B-Chat-llama",
        "Average":42.94,
        "ARC":36.95,
        "HellaSwag":54.34,
        "MMLU":44.55,
        "TruthfulQA":43.7,
        "Winogrande":58.88,
        "GSM8K":19.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Writer\/InstructPalmyra-20b",
        "Average":42.91,
        "ARC":47.1,
        "HellaSwag":73.0,
        "MMLU":28.26,
        "TruthfulQA":41.81,
        "Winogrande":64.72,
        "GSM8K":2.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":40.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vihangd\/dopeyshearedplats-2.7b-v1",
        "Average":42.9,
        "ARC":46.08,
        "HellaSwag":75.17,
        "MMLU":29.01,
        "TruthfulQA":44.12,
        "Winogrande":62.67,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":2.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/gpt-neox-20b-full-precision",
        "Average":42.87,
        "ARC":48.81,
        "HellaSwag":74.44,
        "MMLU":26.16,
        "TruthfulQA":36.89,
        "Winogrande":68.27,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Pierre-obi\/Mistral_solar-slerp",
        "Average":42.86,
        "ARC":43.0,
        "HellaSwag":57.93,
        "MMLU":40.48,
        "TruthfulQA":46.96,
        "Winogrande":68.19,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/landmark-attention-llama7b-fp16",
        "Average":42.84,
        "ARC":47.35,
        "HellaSwag":65.81,
        "MMLU":31.59,
        "TruthfulQA":42.63,
        "Winogrande":68.03,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/gemma-2b-it-sp-test1",
        "Average":42.79,
        "ARC":44.03,
        "HellaSwag":62.82,
        "MMLU":37.67,
        "TruthfulQA":45.77,
        "Winogrande":61.17,
        "GSM8K":5.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/gemma-2b-it-sp-test-openherms-step500",
        "Average":42.79,
        "ARC":44.03,
        "HellaSwag":62.82,
        "MMLU":37.67,
        "TruthfulQA":45.77,
        "Winogrande":61.17,
        "GSM8K":5.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/gemma-2b-it-sp-test",
        "Average":42.79,
        "ARC":44.03,
        "HellaSwag":62.82,
        "MMLU":37.67,
        "TruthfulQA":45.77,
        "Winogrande":61.17,
        "GSM8K":5.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-66b",
        "Average":42.78,
        "ARC":46.33,
        "HellaSwag":76.25,
        "MMLU":26.99,
        "TruthfulQA":35.43,
        "Winogrande":70.01,
        "GSM8K":1.67,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":66.0,
        "Model Sha":175.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abideen\/gemma-2b-openhermes",
        "Average":42.78,
        "ARC":43.94,
        "HellaSwag":62.74,
        "MMLU":37.62,
        "TruthfulQA":45.83,
        "Winogrande":60.93,
        "GSM8K":5.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":2.51,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Syed-Hasan-8503\/openhermes-gemma-2b-it",
        "Average":42.78,
        "ARC":43.94,
        "HellaSwag":62.74,
        "MMLU":37.62,
        "TruthfulQA":45.83,
        "Winogrande":60.93,
        "GSM8K":5.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":2.51,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Qwen-1_8b-EverythingLM",
        "Average":42.77,
        "ARC":38.65,
        "HellaSwag":62.66,
        "MMLU":44.94,
        "TruthfulQA":38.7,
        "Winogrande":58.96,
        "GSM8K":12.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"google\/gemma-2b-it",
        "Average":42.75,
        "ARC":43.94,
        "HellaSwag":62.7,
        "MMLU":37.65,
        "TruthfulQA":45.82,
        "Winogrande":60.93,
        "GSM8K":5.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":450.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-agents\/tora-code-13b-v1.0",
        "Average":42.7,
        "ARC":44.45,
        "HellaSwag":69.29,
        "MMLU":36.67,
        "TruthfulQA":34.98,
        "Winogrande":62.59,
        "GSM8K":8.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aloobun\/Cypher-Laser-Mixtral-2x1.8B-v0.1",
        "Average":42.65,
        "ARC":40.44,
        "HellaSwag":67.6,
        "MMLU":31.49,
        "TruthfulQA":40.62,
        "Winogrande":65.19,
        "GSM8K":10.54,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":3.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aloobun\/Cypher-Mixtral-2x1.8B-v0.1",
        "Average":42.62,
        "ARC":40.44,
        "HellaSwag":67.7,
        "MMLU":31.81,
        "TruthfulQA":39.94,
        "Winogrande":65.35,
        "GSM8K":10.46,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":3.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"axxd\/wizardllama-7b",
        "Average":42.61,
        "ARC":42.83,
        "HellaSwag":66.2,
        "MMLU":35.44,
        "TruthfulQA":35.71,
        "Winogrande":62.43,
        "GSM8K":13.04,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Chickaboo\/ChickaQ-V2-Large-Beta",
        "Average":42.61,
        "ARC":34.3,
        "HellaSwag":57.87,
        "MMLU":42.33,
        "TruthfulQA":43.85,
        "Winogrande":59.04,
        "GSM8K":18.27,
        "Type":"base merges and moerges",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":3.05,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"VMware\/open-llama-7b-open-instruct",
        "Average":42.59,
        "ARC":49.74,
        "HellaSwag":73.67,
        "MMLU":31.52,
        "TruthfulQA":34.65,
        "Winogrande":65.43,
        "GSM8K":0.53,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-3.0",
        "Available on the Hub":7.0,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Salesforce\/codegen-16B-nl",
        "Average":42.59,
        "ARC":46.76,
        "HellaSwag":71.87,
        "MMLU":32.35,
        "TruthfulQA":33.95,
        "Winogrande":67.96,
        "GSM8K":2.65,
        "Type":"pretrained",
        "Architecture":"CodeGenForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bsd-3-clause",
        "Available on the Hub":16.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-1024-20b",
        "Average":42.58,
        "ARC":48.04,
        "HellaSwag":72.76,
        "MMLU":25.96,
        "TruthfulQA":39.92,
        "Winogrande":66.3,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tensoic\/Gemma-2B-Samvaad",
        "Average":42.55,
        "ARC":46.59,
        "HellaSwag":68.17,
        "MMLU":33.09,
        "TruthfulQA":39.95,
        "Winogrande":61.64,
        "GSM8K":5.84,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-gpt-neox-20b-1000-steps",
        "Average":42.51,
        "ARC":48.55,
        "HellaSwag":74.61,
        "MMLU":26.39,
        "TruthfulQA":35.63,
        "Winogrande":66.77,
        "GSM8K":3.11,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vibhorag101\/llama-2-13b-chat-hf-phr_mental_therapy",
        "Average":42.5,
        "ARC":38.82,
        "HellaSwag":72.76,
        "MMLU":23.12,
        "TruthfulQA":46.92,
        "Winogrande":65.59,
        "GSM8K":7.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":13.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aevalone\/Test-7B-pthrough",
        "Average":42.47,
        "ARC":44.37,
        "HellaSwag":51.19,
        "MMLU":49.31,
        "TruthfulQA":48.57,
        "Winogrande":60.14,
        "GSM8K":1.21,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-oasst1-512-20b",
        "Average":42.44,
        "ARC":46.93,
        "HellaSwag":72.77,
        "MMLU":26.25,
        "TruthfulQA":37.5,
        "Winogrande":68.03,
        "GSM8K":3.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/tamil-llama-7b-instruct-v0.2",
        "Average":42.41,
        "ARC":40.19,
        "HellaSwag":68.83,
        "MMLU":23.12,
        "TruthfulQA":50.04,
        "Winogrande":66.77,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/codellama_7b_DolphinCoder",
        "Average":42.39,
        "ARC":41.98,
        "HellaSwag":65.5,
        "MMLU":38.11,
        "TruthfulQA":35.45,
        "Winogrande":63.61,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/codellama_7b_DolphinCoder",
        "Average":42.39,
        "ARC":41.98,
        "HellaSwag":65.5,
        "MMLU":38.11,
        "TruthfulQA":35.45,
        "Winogrande":63.61,
        "GSM8K":9.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ise-uiuc\/Magicoder-S-DS-6.7B",
        "Average":42.39,
        "ARC":38.31,
        "HellaSwag":54.48,
        "MMLU":38.71,
        "TruthfulQA":41.0,
        "Winogrande":58.41,
        "GSM8K":23.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":189.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhinand\/tamil-llama-7b-instruct-v0.2",
        "Average":42.39,
        "ARC":40.44,
        "HellaSwag":68.88,
        "MMLU":23.12,
        "TruthfulQA":50.11,
        "Winogrande":66.46,
        "GSM8K":5.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"JosephusCheung\/LL7M",
        "Average":42.38,
        "ARC":44.97,
        "HellaSwag":68.81,
        "MMLU":34.44,
        "TruthfulQA":41.39,
        "Winogrande":64.09,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":0.01,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-Instruct-7B-v0.1",
        "Average":42.38,
        "ARC":44.11,
        "HellaSwag":72.02,
        "MMLU":37.62,
        "TruthfulQA":33.96,
        "Winogrande":64.96,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Instruct",
        "Average":42.38,
        "ARC":44.11,
        "HellaSwag":72.02,
        "MMLU":37.62,
        "TruthfulQA":33.96,
        "Winogrande":64.96,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":104.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_7b",
        "Average":42.31,
        "ARC":47.01,
        "HellaSwag":71.98,
        "MMLU":30.49,
        "TruthfulQA":34.85,
        "Winogrande":67.96,
        "GSM8K":1.59,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":122.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"occultml\/Helios-10.7B-v2",
        "Average":42.25,
        "ARC":39.16,
        "HellaSwag":46.63,
        "MMLU":41.57,
        "TruthfulQA":55.51,
        "Winogrande":70.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cmarkea\/bloomz-7b1-mt-sft-chat",
        "Average":42.24,
        "ARC":44.03,
        "HellaSwag":62.6,
        "MMLU":38.64,
        "TruthfulQA":44.34,
        "Winogrande":63.3,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":7.07,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Galpaca-30b-MiniOrca",
        "Average":42.23,
        "ARC":48.89,
        "HellaSwag":57.8,
        "MMLU":43.72,
        "TruthfulQA":41.1,
        "Winogrande":60.06,
        "GSM8K":1.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":29.97,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"silvainrichou\/gemma-3b-002",
        "Average":42.22,
        "ARC":43.34,
        "HellaSwag":64.06,
        "MMLU":36.86,
        "TruthfulQA":42.68,
        "Winogrande":60.85,
        "GSM8K":5.53,
        "Type":"base merges and moerges",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.17,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/pythia-12b-sft-v8-7k-steps",
        "Average":42.21,
        "ARC":44.03,
        "HellaSwag":70.28,
        "MMLU":26.55,
        "TruthfulQA":36.53,
        "Winogrande":65.27,
        "GSM8K":10.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":21.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloomz-7b1",
        "Average":42.21,
        "ARC":42.49,
        "HellaSwag":63.01,
        "MMLU":37.85,
        "TruthfulQA":45.2,
        "Winogrande":64.64,
        "GSM8K":0.08,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":7.0,
        "Model Sha":127.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"klosax\/open_llama_13b_600bt_preview",
        "Average":42.21,
        "ARC":44.28,
        "HellaSwag":72.43,
        "MMLU":31.47,
        "TruthfulQA":34.66,
        "Winogrande":68.43,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namirocks\/mistral-shishya-all-hal-model-7b-ep3",
        "Average":42.19,
        "ARC":37.97,
        "HellaSwag":77.77,
        "MMLU":26.56,
        "TruthfulQA":36.43,
        "Winogrande":74.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"occultml\/Helios-10.7B",
        "Average":42.19,
        "ARC":38.91,
        "HellaSwag":46.6,
        "MMLU":41.4,
        "TruthfulQA":55.52,
        "Winogrande":70.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-SOLAR-11b-v2.0",
        "Average":42.19,
        "ARC":41.64,
        "HellaSwag":61.67,
        "MMLU":37.35,
        "TruthfulQA":47.72,
        "Winogrande":63.46,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.92,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TehVenom\/Moderator-Chan_GPT-JT-6b",
        "Average":42.17,
        "ARC":43.69,
        "HellaSwag":70.77,
        "MMLU":35.61,
        "TruthfulQA":36.05,
        "Winogrande":65.59,
        "GSM8K":1.29,
        "Type":"",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloomz-7b1-mt",
        "Average":42.14,
        "ARC":43.86,
        "HellaSwag":62.91,
        "MMLU":37.35,
        "TruthfulQA":45.65,
        "Winogrande":63.06,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":7.0,
        "Model Sha":130.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Heng666\/EastAsia-4x7B-Moe-experiment",
        "Average":42.12,
        "ARC":39.51,
        "HellaSwag":48.92,
        "MMLU":56.2,
        "TruthfulQA":49.83,
        "Winogrande":58.09,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":18.52,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"princeton-nlp\/Sheared-LLaMA-2.7B-ShareGPT",
        "Average":42.11,
        "ARC":41.04,
        "HellaSwag":71.26,
        "MMLU":28.5,
        "TruthfulQA":47.71,
        "Winogrande":64.17,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Writer\/palmyra-large",
        "Average":42.09,
        "ARC":44.97,
        "HellaSwag":71.85,
        "MMLU":28.54,
        "TruthfulQA":35.93,
        "Winogrande":67.88,
        "GSM8K":3.41,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-raven-14b",
        "Average":42.09,
        "ARC":44.62,
        "HellaSwag":71.25,
        "MMLU":25.92,
        "TruthfulQA":41.93,
        "Winogrande":66.69,
        "GSM8K":2.12,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":14.0,
        "Model Sha":55.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AlekseyKorshuk\/pygmalion-6b-vicuna-chatml",
        "Average":42.08,
        "ARC":40.61,
        "HellaSwag":67.73,
        "MMLU":33.92,
        "TruthfulQA":42.76,
        "Winogrande":63.06,
        "GSM8K":4.4,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":6.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/Marx-3B-V2",
        "Average":42.08,
        "ARC":44.03,
        "HellaSwag":72.92,
        "MMLU":27.84,
        "TruthfulQA":39.92,
        "Winogrande":66.54,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NurtureAI\/Orca-2-7B-16k",
        "Average":42.05,
        "ARC":50.6,
        "HellaSwag":63.89,
        "MMLU":36.68,
        "TruthfulQA":45.37,
        "Winogrande":54.22,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-tora-code-7b-v1.0",
        "Average":42.04,
        "ARC":42.66,
        "HellaSwag":65.16,
        "MMLU":38.56,
        "TruthfulQA":42.06,
        "Winogrande":62.9,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mediocredev\/open-llama-3b-v2-instruct",
        "Average":42.02,
        "ARC":38.48,
        "HellaSwag":70.24,
        "MMLU":39.69,
        "TruthfulQA":37.96,
        "Winogrande":65.75,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-30b",
        "Average":42.0,
        "ARC":43.26,
        "HellaSwag":74.07,
        "MMLU":26.66,
        "TruthfulQA":35.16,
        "Winogrande":70.64,
        "GSM8K":2.2,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":133.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ed001\/datascience-coder-6.7b",
        "Average":41.99,
        "ARC":34.64,
        "HellaSwag":53.83,
        "MMLU":37.96,
        "TruthfulQA":44.82,
        "Winogrande":55.72,
        "GSM8K":24.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":6.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-gpt-neox-20b-3000-steps",
        "Average":41.97,
        "ARC":46.42,
        "HellaSwag":72.08,
        "MMLU":26.16,
        "TruthfulQA":35.53,
        "Winogrande":68.75,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":20.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/pythia-12b-sft-v8-2.5k-steps",
        "Average":41.97,
        "ARC":42.32,
        "HellaSwag":70.15,
        "MMLU":27.36,
        "TruthfulQA":36.75,
        "Winogrande":65.67,
        "GSM8K":9.55,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-multilang-1024-20b",
        "Average":41.9,
        "ARC":47.44,
        "HellaSwag":72.58,
        "MMLU":26.37,
        "TruthfulQA":34.39,
        "Winogrande":68.43,
        "GSM8K":2.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wenge-research\/yayi-7b",
        "Average":41.88,
        "ARC":46.33,
        "HellaSwag":61.72,
        "MMLU":36.34,
        "TruthfulQA":43.7,
        "Winogrande":62.27,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vitruv\/vitruv_2",
        "Average":41.87,
        "ARC":43.34,
        "HellaSwag":68.02,
        "MMLU":32.98,
        "TruthfulQA":36.46,
        "Winogrande":66.46,
        "GSM8K":3.94,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":10.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/ereb-test",
        "Average":41.85,
        "ARC":40.7,
        "HellaSwag":71.04,
        "MMLU":28.06,
        "TruthfulQA":47.4,
        "Winogrande":63.93,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":2.7,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"togethercomputer\/GPT-JT-Moderation-6B",
        "Average":41.8,
        "ARC":40.53,
        "HellaSwag":67.66,
        "MMLU":41.63,
        "TruthfulQA":37.33,
        "Winogrande":62.67,
        "GSM8K":0.99,
        "Type":"",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":31.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/NeuralReyna-Mini-1.8B-v0.3",
        "Average":41.77,
        "ARC":35.58,
        "HellaSwag":61.13,
        "MMLU":44.22,
        "TruthfulQA":41.99,
        "Winogrande":60.93,
        "GSM8K":6.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/LongAlpaca-13B",
        "Average":41.74,
        "ARC":42.58,
        "HellaSwag":72.03,
        "MMLU":34.91,
        "TruthfulQA":36.85,
        "Winogrande":64.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-3b",
        "Average":41.74,
        "ARC":43.17,
        "HellaSwag":67.82,
        "MMLU":29.16,
        "TruthfulQA":41.56,
        "Winogrande":66.22,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":3.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2-instruct",
        "Average":41.72,
        "ARC":40.78,
        "HellaSwag":67.77,
        "MMLU":31.57,
        "TruthfulQA":40.32,
        "Winogrande":63.54,
        "GSM8K":6.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.11,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/Marx-3B",
        "Average":41.71,
        "ARC":43.17,
        "HellaSwag":72.68,
        "MMLU":28.46,
        "TruthfulQA":39.09,
        "Winogrande":65.59,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/gpt-neox-20b",
        "Average":41.69,
        "ARC":45.73,
        "HellaSwag":73.45,
        "MMLU":25.0,
        "TruthfulQA":31.61,
        "Winogrande":68.9,
        "GSM8K":5.46,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.74,
        "Model Sha":488.0
    },
    {
        "T":"?",
        "Model":"OpenAssistant\/pythia-12b-sft-v8-rlhf-2k-steps",
        "Average":41.65,
        "ARC":43.43,
        "HellaSwag":70.08,
        "MMLU":26.12,
        "TruthfulQA":36.06,
        "Winogrande":64.64,
        "GSM8K":9.55,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/shearedplats-2.7b-v2",
        "Average":41.61,
        "ARC":42.41,
        "HellaSwag":72.58,
        "MMLU":27.52,
        "TruthfulQA":39.76,
        "Winogrande":65.9,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":2.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teilomillet\/MiniMerlin-3b-v0.1",
        "Average":41.6,
        "ARC":40.7,
        "HellaSwag":54.06,
        "MMLU":43.32,
        "TruthfulQA":49.65,
        "Winogrande":60.54,
        "GSM8K":1.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"glaiveai\/glaive-coder-7b",
        "Average":41.56,
        "ARC":42.66,
        "HellaSwag":64.69,
        "MMLU":37.15,
        "TruthfulQA":39.88,
        "Winogrande":59.75,
        "GSM8K":5.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":52.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Average":41.49,
        "ARC":46.25,
        "HellaSwag":71.63,
        "MMLU":27.68,
        "TruthfulQA":33.03,
        "Winogrande":67.32,
        "GSM8K":3.03,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":93.0
    },
    {
        "T":"?",
        "Model":"nomic-ai\/gpt4all-j",
        "Average":41.49,
        "ARC":41.98,
        "HellaSwag":64.06,
        "MMLU":28.2,
        "TruthfulQA":42.78,
        "Winogrande":64.72,
        "GSM8K":7.2,
        "Type":"",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":288.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-pythia-12b-pretrained-sft",
        "Average":41.48,
        "ARC":45.31,
        "HellaSwag":67.67,
        "MMLU":27.81,
        "TruthfulQA":38.16,
        "Winogrande":65.9,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
        "Average":41.46,
        "ARC":41.81,
        "HellaSwag":73.01,
        "MMLU":26.36,
        "TruthfulQA":38.99,
        "Winogrande":66.69,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/Reyna-Mini-1.8B-v0.1",
        "Average":41.46,
        "ARC":35.24,
        "HellaSwag":60.42,
        "MMLU":45.37,
        "TruthfulQA":41.4,
        "Winogrande":60.85,
        "GSM8K":5.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"GeneZC\/MiniMA-3B",
        "Average":41.44,
        "ARC":43.43,
        "HellaSwag":68.06,
        "MMLU":28.69,
        "TruthfulQA":39.76,
        "Winogrande":65.98,
        "GSM8K":2.73,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.02,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/open-llama-3b-everything-v2",
        "Average":41.41,
        "ARC":42.83,
        "HellaSwag":73.28,
        "MMLU":26.87,
        "TruthfulQA":37.26,
        "Winogrande":66.61,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"Fredithefish\/ReasonixPajama-3B-HF",
        "Average":41.41,
        "ARC":39.25,
        "HellaSwag":63.47,
        "MMLU":26.09,
        "TruthfulQA":55.42,
        "Winogrande":63.69,
        "GSM8K":0.53,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.91,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"netcat420\/MFANN3b",
        "Average":41.4,
        "ARC":43.09,
        "HellaSwag":72.33,
        "MMLU":26.74,
        "TruthfulQA":40.22,
        "Winogrande":62.67,
        "GSM8K":3.34,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hakurei\/mommygpt-3B",
        "Average":41.36,
        "ARC":41.89,
        "HellaSwag":71.69,
        "MMLU":28.74,
        "TruthfulQA":37.9,
        "Winogrande":65.82,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":8.0
    },
    {
        "T":"?",
        "Model":"psmathur\/orca_mini_13b",
        "Average":41.36,
        "ARC":42.06,
        "HellaSwag":63.4,
        "MMLU":35.43,
        "TruthfulQA":43.1,
        "Winogrande":64.17,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Average":41.33,
        "ARC":40.7,
        "HellaSwag":69.39,
        "MMLU":30.11,
        "TruthfulQA":39.16,
        "Winogrande":67.64,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":21.83,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chargoddard\/llama-2-34b-uncode",
        "Average":41.33,
        "ARC":39.51,
        "HellaSwag":33.9,
        "MMLU":38.49,
        "TruthfulQA":40.94,
        "Winogrande":74.35,
        "GSM8K":20.77,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/oasst-sft-4-pythia-12b-epoch-3.5",
        "Average":41.31,
        "ARC":45.73,
        "HellaSwag":68.59,
        "MMLU":26.82,
        "TruthfulQA":37.81,
        "Winogrande":65.9,
        "GSM8K":3.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":354.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_7b",
        "Average":41.27,
        "ARC":43.94,
        "HellaSwag":65.22,
        "MMLU":29.97,
        "TruthfulQA":42.03,
        "Winogrande":66.06,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-NeoX-20B-Erebus",
        "Average":41.26,
        "ARC":45.48,
        "HellaSwag":72.79,
        "MMLU":26.77,
        "TruthfulQA":32.15,
        "Winogrande":68.11,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":79.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Average":41.25,
        "ARC":46.25,
        "HellaSwag":71.63,
        "MMLU":27.68,
        "TruthfulQA":33.03,
        "Winogrande":67.32,
        "GSM8K":1.59,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-3b-v4",
        "Average":41.24,
        "ARC":42.58,
        "HellaSwag":71.04,
        "MMLU":30.04,
        "TruthfulQA":37.26,
        "Winogrande":65.82,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":6.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/sheared-plus-westlake-normal",
        "Average":41.16,
        "ARC":39.76,
        "HellaSwag":70.33,
        "MMLU":26.81,
        "TruthfulQA":46.5,
        "Winogrande":63.54,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/open-llama-3b-v2-elmv3",
        "Average":41.14,
        "ARC":42.06,
        "HellaSwag":73.28,
        "MMLU":27.61,
        "TruthfulQA":35.54,
        "Winogrande":64.96,
        "GSM8K":3.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/Griffin-3B",
        "Average":41.13,
        "ARC":41.81,
        "HellaSwag":72.3,
        "MMLU":26.36,
        "TruthfulQA":38.33,
        "Winogrande":67.01,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mwitiderrick\/shearedplats-2.7b-v2-instruct-v0.1",
        "Average":41.13,
        "ARC":40.19,
        "HellaSwag":70.08,
        "MMLU":28.12,
        "TruthfulQA":41.23,
        "Winogrande":65.04,
        "GSM8K":2.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/open-llama-3b-v2-elmv3",
        "Average":41.13,
        "ARC":42.15,
        "HellaSwag":73.26,
        "MMLU":27.16,
        "TruthfulQA":35.51,
        "Winogrande":64.96,
        "GSM8K":3.71,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-coder-ds-6.7b",
        "Average":41.11,
        "ARC":36.86,
        "HellaSwag":52.46,
        "MMLU":38.08,
        "TruthfulQA":41.67,
        "Winogrande":58.88,
        "GSM8K":18.73,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.7,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VMware\/open-llama-0.7T-7B-open-instruct-v1.1",
        "Average":41.11,
        "ARC":46.67,
        "HellaSwag":67.67,
        "MMLU":28.55,
        "TruthfulQA":37.6,
        "Winogrande":65.43,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-3b-v3",
        "Average":41.11,
        "ARC":41.72,
        "HellaSwag":71.05,
        "MMLU":27.31,
        "TruthfulQA":37.86,
        "Winogrande":67.48,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/pythia-12b-pre-v8-12.5k-steps",
        "Average":41.1,
        "ARC":41.47,
        "HellaSwag":68.8,
        "MMLU":26.58,
        "TruthfulQA":36.82,
        "Winogrande":65.27,
        "GSM8K":7.66,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-NeoX-20B-Skein",
        "Average":41.1,
        "ARC":44.97,
        "HellaSwag":72.68,
        "MMLU":25.99,
        "TruthfulQA":31.64,
        "Winogrande":68.43,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":20.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
        "Average":41.09,
        "ARC":41.21,
        "HellaSwag":72.88,
        "MMLU":25.39,
        "TruthfulQA":38.87,
        "Winogrande":66.61,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xaviviro\/FLAMA-0.1-3B",
        "Average":41.07,
        "ARC":41.72,
        "HellaSwag":71.41,
        "MMLU":26.59,
        "TruthfulQA":37.19,
        "Winogrande":66.54,
        "GSM8K":2.96,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RobbeD\/OpenLlama-Platypus-3B",
        "Average":41.05,
        "ARC":41.21,
        "HellaSwag":71.67,
        "MMLU":29.86,
        "TruthfulQA":36.45,
        "Winogrande":65.98,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":3.43,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/Puma-3B",
        "Average":41.02,
        "ARC":41.3,
        "HellaSwag":71.85,
        "MMLU":27.51,
        "TruthfulQA":38.34,
        "Winogrande":66.38,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/wizard-orca-3b",
        "Average":41.0,
        "ARC":41.72,
        "HellaSwag":71.78,
        "MMLU":24.49,
        "TruthfulQA":40.04,
        "Winogrande":66.93,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"LLM360\/Amber",
        "Average":40.97,
        "ARC":40.96,
        "HellaSwag":73.79,
        "MMLU":26.84,
        "TruthfulQA":33.56,
        "Winogrande":67.88,
        "GSM8K":2.81,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":59.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"unit-mesh\/autodev-deepseek-6.7b-finetunes-poc",
        "Average":40.95,
        "ARC":35.41,
        "HellaSwag":52.41,
        "MMLU":37.56,
        "TruthfulQA":44.11,
        "Winogrande":56.67,
        "GSM8K":19.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/open-llama-3b-claude-30k",
        "Average":40.93,
        "ARC":41.72,
        "HellaSwag":72.64,
        "MMLU":24.03,
        "TruthfulQA":38.46,
        "Winogrande":66.54,
        "GSM8K":2.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mediocredev\/open-llama-3b-v2-chat",
        "Average":40.93,
        "ARC":40.61,
        "HellaSwag":70.3,
        "MMLU":28.73,
        "TruthfulQA":37.84,
        "Winogrande":65.51,
        "GSM8K":2.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-6.7b-chat-and-function-calling",
        "Average":40.91,
        "ARC":36.09,
        "HellaSwag":53.8,
        "MMLU":38.29,
        "TruthfulQA":42.83,
        "Winogrande":57.22,
        "GSM8K":17.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-6.7b-chat",
        "Average":40.9,
        "ARC":36.01,
        "HellaSwag":53.74,
        "MMLU":38.22,
        "TruthfulQA":42.94,
        "Winogrande":57.54,
        "GSM8K":16.98,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-6.7b-chat",
        "Average":40.9,
        "ARC":35.75,
        "HellaSwag":53.7,
        "MMLU":38.19,
        "TruthfulQA":42.94,
        "Winogrande":58.01,
        "GSM8K":16.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"deepseek-ai\/deepseek-coder-6.7b-base",
        "Average":40.87,
        "ARC":37.03,
        "HellaSwag":53.46,
        "MMLU":38.39,
        "TruthfulQA":40.28,
        "Winogrande":58.09,
        "GSM8K":17.97,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":63.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/MT7Bi-sft",
        "Average":40.85,
        "ARC":41.81,
        "HellaSwag":56.83,
        "MMLU":41.4,
        "TruthfulQA":44.61,
        "Winogrande":60.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"princeton-nlp\/Sheared-LLaMA-2.7B",
        "Average":40.84,
        "ARC":41.72,
        "HellaSwag":71.01,
        "MMLU":26.92,
        "TruthfulQA":37.32,
        "Winogrande":67.01,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":54.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lvxy1117\/amber_fine_tune_ori",
        "Average":40.83,
        "ARC":44.45,
        "HellaSwag":75.1,
        "MMLU":26.04,
        "TruthfulQA":34.94,
        "Winogrande":63.14,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/GPT-R",
        "Average":40.8,
        "ARC":41.21,
        "HellaSwag":66.89,
        "MMLU":36.5,
        "TruthfulQA":34.22,
        "Winogrande":64.4,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AtAndDev\/ShortKing-3b-v0.3",
        "Average":40.8,
        "ARC":40.96,
        "HellaSwag":70.72,
        "MMLU":26.21,
        "TruthfulQA":38.78,
        "Winogrande":66.93,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"dvruette\/oasst-pythia-12b-6000-steps",
        "Average":40.77,
        "ARC":45.39,
        "HellaSwag":69.68,
        "MMLU":25.97,
        "TruthfulQA":39.85,
        "Winogrande":63.22,
        "GSM8K":0.53,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/oasst-sft-1-pythia-12b",
        "Average":40.77,
        "ARC":46.42,
        "HellaSwag":70.0,
        "MMLU":26.19,
        "TruthfulQA":39.19,
        "Winogrande":62.19,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":280.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt-7b-bloom",
        "Average":40.75,
        "ARC":44.62,
        "HellaSwag":62.56,
        "MMLU":33.81,
        "TruthfulQA":40.61,
        "Winogrande":62.9,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hyunseoki\/ko-ref-llama2-7b",
        "Average":40.75,
        "ARC":42.66,
        "HellaSwag":66.58,
        "MMLU":30.41,
        "TruthfulQA":38.62,
        "Winogrande":66.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"dvruette\/oasst-pythia-12b-flash-attn-5000-steps",
        "Average":40.73,
        "ARC":44.97,
        "HellaSwag":69.75,
        "MMLU":26.64,
        "TruthfulQA":38.89,
        "Winogrande":63.14,
        "GSM8K":0.99,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"aevalone\/Pengland-Merge",
        "Average":40.72,
        "ARC":40.53,
        "HellaSwag":47.06,
        "MMLU":50.72,
        "TruthfulQA":47.03,
        "Winogrande":58.96,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.99,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Average":40.71,
        "ARC":41.81,
        "HellaSwag":68.75,
        "MMLU":28.47,
        "TruthfulQA":37.1,
        "Winogrande":67.17,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":20.92,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AlekseyKorshuk\/chatml-pyg-v1",
        "Average":40.7,
        "ARC":37.88,
        "HellaSwag":63.29,
        "MMLU":32.77,
        "TruthfulQA":42.61,
        "Winogrande":62.51,
        "GSM8K":5.16,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-1024-12b",
        "Average":40.65,
        "ARC":43.09,
        "HellaSwag":69.75,
        "MMLU":25.87,
        "TruthfulQA":38.0,
        "Winogrande":66.14,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-13B",
        "Average":40.62,
        "ARC":40.36,
        "HellaSwag":75.51,
        "MMLU":27.07,
        "TruthfulQA":32.83,
        "Winogrande":67.96,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Mihaiii\/dolphin-2.6-mistral-7b-dpo-5.93B",
        "Average":40.62,
        "ARC":38.99,
        "HellaSwag":61.01,
        "MMLU":27.32,
        "TruthfulQA":53.51,
        "Winogrande":62.67,
        "GSM8K":0.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":5.93,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"harborwater\/open-llama-3b-everythingLM-2048",
        "Average":40.62,
        "ARC":42.75,
        "HellaSwag":71.72,
        "MMLU":27.16,
        "TruthfulQA":34.26,
        "Winogrande":66.3,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Average":40.56,
        "ARC":42.58,
        "HellaSwag":69.91,
        "MMLU":26.53,
        "TruthfulQA":36.42,
        "Winogrande":67.17,
        "GSM8K":0.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Javalion-R",
        "Average":40.51,
        "ARC":41.72,
        "HellaSwag":68.02,
        "MMLU":30.81,
        "TruthfulQA":34.44,
        "Winogrande":65.43,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-oasst1-512-12b",
        "Average":40.48,
        "ARC":42.32,
        "HellaSwag":70.24,
        "MMLU":26.01,
        "TruthfulQA":36.41,
        "Winogrande":66.22,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":27.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/ThetaWave-28B-v0.1",
        "Average":40.4,
        "ARC":36.6,
        "HellaSwag":35.54,
        "MMLU":54.5,
        "TruthfulQA":49.86,
        "Winogrande":65.9,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":28.18,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Javelin-R",
        "Average":40.39,
        "ARC":41.64,
        "HellaSwag":69.01,
        "MMLU":30.7,
        "TruthfulQA":34.5,
        "Winogrande":64.8,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_opt13b_10e5",
        "Average":40.37,
        "ARC":42.49,
        "HellaSwag":70.31,
        "MMLU":25.45,
        "TruthfulQA":35.78,
        "Winogrande":66.85,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"dvruette\/oasst-pythia-12b-reference",
        "Average":40.33,
        "ARC":43.0,
        "HellaSwag":67.91,
        "MMLU":28.33,
        "TruthfulQA":36.57,
        "Winogrande":64.96,
        "GSM8K":1.21,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardCoder-Python-7B-V1.0",
        "Average":40.32,
        "ARC":41.81,
        "HellaSwag":65.06,
        "MMLU":32.29,
        "TruthfulQA":36.32,
        "Winogrande":61.72,
        "GSM8K":4.7,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":69.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Pirr\/pythia-13b-deduped-green_devil",
        "Average":40.31,
        "ARC":42.32,
        "HellaSwag":68.89,
        "MMLU":26.01,
        "TruthfulQA":35.56,
        "Winogrande":66.93,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/smartyplats-3b-v2",
        "Average":40.29,
        "ARC":41.04,
        "HellaSwag":71.19,
        "MMLU":24.32,
        "TruthfulQA":36.66,
        "Winogrande":66.93,
        "GSM8K":1.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/openllama_3b_EvolInstruct_lora_merged",
        "Average":40.28,
        "ARC":40.27,
        "HellaSwag":71.6,
        "MMLU":27.12,
        "TruthfulQA":34.78,
        "Winogrande":67.01,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_3b_v2",
        "Average":40.28,
        "ARC":40.27,
        "HellaSwag":71.6,
        "MMLU":27.12,
        "TruthfulQA":34.78,
        "Winogrande":67.01,
        "GSM8K":0.91,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":117.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kfkas\/Llama-2-ko-7b-Chat",
        "Average":40.27,
        "ARC":40.44,
        "HellaSwag":67.16,
        "MMLU":30.4,
        "TruthfulQA":35.48,
        "Winogrande":66.85,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheBloke\/CodeLlama-34B-Python-fp16",
        "Average":40.27,
        "ARC":38.14,
        "HellaSwag":34.8,
        "MMLU":32.95,
        "TruthfulQA":43.57,
        "Winogrande":72.14,
        "GSM8K":20.02,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-34b-Python-hf",
        "Average":40.27,
        "ARC":40.19,
        "HellaSwag":36.82,
        "MMLU":34.79,
        "TruthfulQA":44.28,
        "Winogrande":71.19,
        "GSM8K":14.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":33.74,
        "Model Sha":93.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/open-llama-3b-v2-layla",
        "Average":40.25,
        "ARC":38.23,
        "HellaSwag":66.43,
        "MMLU":28.56,
        "TruthfulQA":44.4,
        "Winogrande":62.83,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kfkas\/Llama-2-ko-7b-Chat",
        "Average":40.25,
        "ARC":40.44,
        "HellaSwag":67.12,
        "MMLU":30.19,
        "TruthfulQA":35.45,
        "Winogrande":66.61,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Javelin-GPTJ",
        "Average":40.23,
        "ARC":42.66,
        "HellaSwag":70.45,
        "MMLU":26.2,
        "TruthfulQA":36.08,
        "Winogrande":64.17,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sao10K\/Senko-11B-v1",
        "Average":40.21,
        "ARC":35.67,
        "HellaSwag":40.86,
        "MMLU":56.77,
        "TruthfulQA":54.78,
        "Winogrande":53.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-agents\/tora-code-7b-v1.0",
        "Average":40.21,
        "ARC":40.7,
        "HellaSwag":65.86,
        "MMLU":33.34,
        "TruthfulQA":34.84,
        "Winogrande":61.56,
        "GSM8K":4.93,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/gemoy-4b-instruct",
        "Average":40.2,
        "ARC":40.7,
        "HellaSwag":58.03,
        "MMLU":36.42,
        "TruthfulQA":46.64,
        "Winogrande":59.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.05,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Janin-R",
        "Average":40.19,
        "ARC":40.44,
        "HellaSwag":67.36,
        "MMLU":31.24,
        "TruthfulQA":34.49,
        "Winogrande":65.35,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/Bean-3B",
        "Average":40.18,
        "ARC":40.36,
        "HellaSwag":72.0,
        "MMLU":26.43,
        "TruthfulQA":36.11,
        "Winogrande":65.67,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TaylorAI\/Flash-Llama-3B",
        "Average":40.13,
        "ARC":40.1,
        "HellaSwag":71.56,
        "MMLU":26.88,
        "TruthfulQA":34.74,
        "Winogrande":66.61,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Dolly_Shygmalion-6b-Dev_V8P2",
        "Average":40.11,
        "ARC":41.38,
        "HellaSwag":67.67,
        "MMLU":28.48,
        "TruthfulQA":36.86,
        "Winogrande":64.33,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/gpt-j-6b",
        "Average":40.1,
        "ARC":41.38,
        "HellaSwag":67.54,
        "MMLU":26.78,
        "TruthfulQA":35.96,
        "Winogrande":65.98,
        "GSM8K":2.96,
        "Type":"pretrained",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":1364.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Xilabs\/calypso-3b-alpha-v2",
        "Average":40.09,
        "ARC":41.55,
        "HellaSwag":71.48,
        "MMLU":25.82,
        "TruthfulQA":35.73,
        "Winogrande":65.27,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":3.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/CodeBarcenas-7b",
        "Average":40.09,
        "ARC":42.32,
        "HellaSwag":63.43,
        "MMLU":33.39,
        "TruthfulQA":38.51,
        "Winogrande":60.38,
        "GSM8K":2.5,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/CodeLlama-34b-hf",
        "Average":40.08,
        "ARC":37.54,
        "HellaSwag":31.84,
        "MMLU":37.2,
        "TruthfulQA":38.89,
        "Winogrande":73.4,
        "GSM8K":21.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":34.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-13b",
        "Average":40.06,
        "ARC":39.93,
        "HellaSwag":71.2,
        "MMLU":24.9,
        "TruthfulQA":34.1,
        "Winogrande":68.51,
        "GSM8K":1.74,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":62.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-7b-Instruct-hf",
        "Average":40.05,
        "ARC":36.52,
        "HellaSwag":55.44,
        "MMLU":34.54,
        "TruthfulQA":41.25,
        "Winogrande":64.56,
        "GSM8K":7.96,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":172.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vihangd\/DopeyTinyLlama-1.1B-v1",
        "Average":40.04,
        "ARC":38.4,
        "HellaSwag":63.49,
        "MMLU":25.76,
        "TruthfulQA":37.36,
        "Winogrande":73.4,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-J-6B-Skein",
        "Average":40.02,
        "ARC":42.58,
        "HellaSwag":68.69,
        "MMLU":24.88,
        "TruthfulQA":38.7,
        "Winogrande":63.85,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.0,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/smartyplats-3b-v1",
        "Average":40.0,
        "ARC":40.53,
        "HellaSwag":70.85,
        "MMLU":25.31,
        "TruthfulQA":36.53,
        "Winogrande":65.75,
        "GSM8K":1.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-tools-7b",
        "Average":40.0,
        "ARC":38.91,
        "HellaSwag":57.69,
        "MMLU":33.24,
        "TruthfulQA":44.08,
        "Winogrande":58.56,
        "GSM8K":7.51,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Salesforce\/codegen-6B-nl",
        "Average":40.0,
        "ARC":42.32,
        "HellaSwag":68.59,
        "MMLU":25.93,
        "TruthfulQA":34.47,
        "Winogrande":66.46,
        "GSM8K":2.2,
        "Type":"pretrained",
        "Architecture":"CodeGenForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bsd-3-clause",
        "Available on the Hub":6.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"KnutJaegersberg\/Nanbeige-16B-Base-32K-llama",
        "Average":39.99,
        "ARC":47.61,
        "HellaSwag":73.08,
        "MMLU":45.26,
        "TruthfulQA":0.0,
        "Winogrande":72.93,
        "GSM8K":1.06,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":15.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Javalion-GPTJ",
        "Average":39.97,
        "ARC":41.89,
        "HellaSwag":68.69,
        "MMLU":26.85,
        "TruthfulQA":35.44,
        "Winogrande":65.27,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
        "Average":39.95,
        "ARC":41.98,
        "HellaSwag":66.82,
        "MMLU":25.69,
        "TruthfulQA":39.67,
        "Winogrande":64.88,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Kquant03\/Raiden-16x3.43B",
        "Average":39.93,
        "ARC":41.89,
        "HellaSwag":66.2,
        "MMLU":26.24,
        "TruthfulQA":39.18,
        "Winogrande":63.61,
        "GSM8K":2.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":35.78,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Average":39.92,
        "ARC":44.45,
        "HellaSwag":71.07,
        "MMLU":26.12,
        "TruthfulQA":32.04,
        "Winogrande":65.43,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":14.0,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/WizardLM-30B-GPTQ",
        "Average":39.9,
        "ARC":28.84,
        "HellaSwag":26.08,
        "MMLU":24.62,
        "TruthfulQA":49.14,
        "Winogrande":76.32,
        "GSM8K":34.42,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
        "Average":39.89,
        "ARC":41.3,
        "HellaSwag":62.44,
        "MMLU":27.55,
        "TruthfulQA":42.0,
        "Winogrande":64.56,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Dolly_Shygmalion-6b",
        "Average":39.89,
        "ARC":41.89,
        "HellaSwag":68.48,
        "MMLU":27.58,
        "TruthfulQA":33.91,
        "Winogrande":65.35,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Skegma-GPTJ",
        "Average":39.87,
        "ARC":43.77,
        "HellaSwag":69.22,
        "MMLU":25.37,
        "TruthfulQA":34.67,
        "Winogrande":64.64,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/PPO_Shygmalion-V8p4_Dev-6b",
        "Average":39.85,
        "ARC":40.7,
        "HellaSwag":67.04,
        "MMLU":29.31,
        "TruthfulQA":35.57,
        "Winogrande":63.93,
        "GSM8K":2.58,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/PPO_Pygway-V8p4_Dev-6b",
        "Average":39.85,
        "ARC":40.36,
        "HellaSwag":67.15,
        "MMLU":29.3,
        "TruthfulQA":35.26,
        "Winogrande":64.4,
        "GSM8K":2.65,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/Pythia-Chat-Base-7B",
        "Average":39.81,
        "ARC":40.02,
        "HellaSwag":68.67,
        "MMLU":27.44,
        "TruthfulQA":34.63,
        "Winogrande":64.01,
        "GSM8K":4.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/CodeLlama-7b-hf",
        "Average":39.81,
        "ARC":39.85,
        "HellaSwag":59.58,
        "MMLU":30.47,
        "TruthfulQA":38.62,
        "Winogrande":64.88,
        "GSM8K":5.46,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codellama\/CodeLlama-7b-hf",
        "Average":39.81,
        "ARC":39.93,
        "HellaSwag":60.8,
        "MMLU":31.12,
        "TruthfulQA":37.82,
        "Winogrande":64.01,
        "GSM8K":5.16,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":278.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/telugu-llama-7b-instruct-v0.1",
        "Average":39.77,
        "ARC":37.12,
        "HellaSwag":67.92,
        "MMLU":23.12,
        "TruthfulQA":49.05,
        "Winogrande":61.4,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/Dolly_Malion-6b",
        "Average":39.77,
        "ARC":42.83,
        "HellaSwag":68.43,
        "MMLU":27.13,
        "TruthfulQA":33.03,
        "Winogrande":65.43,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mwitiderrick\/open_llama_3b_glaive_assistant_v0.1",
        "Average":39.74,
        "ARC":40.7,
        "HellaSwag":67.45,
        "MMLU":27.74,
        "TruthfulQA":35.86,
        "Winogrande":64.72,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mwitiderrick\/open_llama_3b_glaive_code_v0.1",
        "Average":39.74,
        "ARC":40.7,
        "HellaSwag":67.45,
        "MMLU":27.74,
        "TruthfulQA":35.86,
        "Winogrande":64.72,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mwitiderrick\/open_llama_3b_glaive_v0.1",
        "Average":39.74,
        "ARC":40.7,
        "HellaSwag":67.45,
        "MMLU":27.74,
        "TruthfulQA":35.86,
        "Winogrande":64.72,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"heegyu\/WizardVicuna-Uncensored-3B-0719",
        "Average":39.73,
        "ARC":41.38,
        "HellaSwag":66.19,
        "MMLU":26.53,
        "TruthfulQA":39.35,
        "Winogrande":63.77,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/ChanMalion",
        "Average":39.73,
        "ARC":41.89,
        "HellaSwag":68.25,
        "MMLU":27.29,
        "TruthfulQA":33.89,
        "Winogrande":65.35,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mwitiderrick\/open_llama_3b_code_instruct_0.1",
        "Average":39.72,
        "ARC":41.21,
        "HellaSwag":66.96,
        "MMLU":27.82,
        "TruthfulQA":35.01,
        "Winogrande":65.43,
        "GSM8K":1.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhinand\/telugu-llama-7b-instruct-v0.1",
        "Average":39.71,
        "ARC":36.95,
        "HellaSwag":67.88,
        "MMLU":23.12,
        "TruthfulQA":48.97,
        "Winogrande":61.33,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Average":39.7,
        "ARC":41.38,
        "HellaSwag":70.26,
        "MMLU":25.63,
        "TruthfulQA":33.0,
        "Winogrande":66.46,
        "GSM8K":1.44,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":50.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/malayalam-llama-7b-instruct-v0.1",
        "Average":39.69,
        "ARC":37.2,
        "HellaSwag":67.81,
        "MMLU":23.12,
        "TruthfulQA":47.11,
        "Winogrande":62.9,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Janin-GPTJ",
        "Average":39.67,
        "ARC":40.87,
        "HellaSwag":67.29,
        "MMLU":27.4,
        "TruthfulQA":36.25,
        "Winogrande":64.25,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/GPT-J-Pyg_PPO-6B-Dev-V8p4",
        "Average":39.61,
        "ARC":40.19,
        "HellaSwag":66.43,
        "MMLU":30.39,
        "TruthfulQA":34.76,
        "Winogrande":64.01,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-13B-Erebus",
        "Average":39.61,
        "ARC":40.02,
        "HellaSwag":70.07,
        "MMLU":25.32,
        "TruthfulQA":34.93,
        "Winogrande":66.54,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":198.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-13B-Nerybus-Mix",
        "Average":39.61,
        "ARC":39.85,
        "HellaSwag":70.6,
        "MMLU":24.9,
        "TruthfulQA":34.02,
        "Winogrande":67.88,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":32.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-J-6B-Shinen",
        "Average":39.6,
        "ARC":39.85,
        "HellaSwag":67.06,
        "MMLU":27.72,
        "TruthfulQA":36.94,
        "Winogrande":64.09,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/gpt-j-6B-Dolly",
        "Average":39.6,
        "ARC":41.3,
        "HellaSwag":65.97,
        "MMLU":26.78,
        "TruthfulQA":37.91,
        "Winogrande":64.72,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-3.0",
        "Available on the Hub":6.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/GPT-J-Pyg_PPO-6B",
        "Average":39.6,
        "ARC":42.06,
        "HellaSwag":67.51,
        "MMLU":28.52,
        "TruthfulQA":31.95,
        "Winogrande":64.72,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":6.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-nl2sql-ds-6.7b",
        "Average":39.59,
        "ARC":36.35,
        "HellaSwag":52.83,
        "MMLU":36.8,
        "TruthfulQA":40.55,
        "Winogrande":55.96,
        "GSM8K":15.09,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-J-6B-Janeway",
        "Average":39.54,
        "ARC":40.87,
        "HellaSwag":67.11,
        "MMLU":27.45,
        "TruthfulQA":35.74,
        "Winogrande":64.72,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.0,
        "Model Sha":12.0
    },
    {
        "T":"?",
        "Model":"amazon\/LightGPT",
        "Average":39.54,
        "ARC":39.93,
        "HellaSwag":63.82,
        "MMLU":28.45,
        "TruthfulQA":36.69,
        "Winogrande":64.48,
        "GSM8K":3.87,
        "Type":"",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-13B-Nerys-v2",
        "Average":39.53,
        "ARC":39.68,
        "HellaSwag":70.53,
        "MMLU":25.36,
        "TruthfulQA":33.5,
        "Winogrande":67.88,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-Chat-3B-v1",
        "Average":39.53,
        "ARC":42.83,
        "HellaSwag":67.62,
        "MMLU":26.23,
        "TruthfulQA":34.44,
        "Winogrande":65.51,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":136.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"abhinand\/malayalam-llama-7b-instruct-v0.1",
        "Average":39.51,
        "ARC":37.03,
        "HellaSwag":67.75,
        "MMLU":23.12,
        "TruthfulQA":47.05,
        "Winogrande":62.12,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Average":39.49,
        "ARC":39.42,
        "HellaSwag":66.39,
        "MMLU":30.09,
        "TruthfulQA":35.6,
        "Winogrande":64.25,
        "GSM8K":1.21,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.11,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"heegyu\/WizardVicuna-3B-0719",
        "Average":39.48,
        "ARC":40.7,
        "HellaSwag":65.45,
        "MMLU":25.44,
        "TruthfulQA":40.71,
        "Winogrande":63.85,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"databricks\/dolly-v2-12b",
        "Average":39.46,
        "ARC":42.41,
        "HellaSwag":72.53,
        "MMLU":25.92,
        "TruthfulQA":33.83,
        "Winogrande":60.85,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.0,
        "Model Sha":1931.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/llama2-ppo",
        "Average":39.44,
        "ARC":41.64,
        "HellaSwag":49.46,
        "MMLU":35.36,
        "TruthfulQA":45.08,
        "Winogrande":64.96,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Evaloric\/Evaloric-1.1B-test",
        "Average":39.43,
        "ARC":36.6,
        "HellaSwag":60.97,
        "MMLU":26.12,
        "TruthfulQA":38.28,
        "Winogrande":69.61,
        "GSM8K":5.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/PPO_Pygway-6b-Mix",
        "Average":39.43,
        "ARC":41.81,
        "HellaSwag":67.77,
        "MMLU":28.42,
        "TruthfulQA":32.5,
        "Winogrande":64.4,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"harborwater\/dpo-test-hermes-open-llama-3b",
        "Average":39.42,
        "ARC":39.25,
        "HellaSwag":67.46,
        "MMLU":24.21,
        "TruthfulQA":39.81,
        "Winogrande":64.4,
        "GSM8K":1.36,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"julleong\/illuni-llama-2-ko-7b-test",
        "Average":39.41,
        "ARC":43.43,
        "HellaSwag":64.86,
        "MMLU":28.69,
        "TruthfulQA":33.3,
        "Winogrande":63.77,
        "GSM8K":2.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.86,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
        "Average":39.38,
        "ARC":41.64,
        "HellaSwag":66.23,
        "MMLU":27.26,
        "TruthfulQA":36.1,
        "Winogrande":64.4,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc",
        "Available on the Hub":2.91,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-Chat-7B-v0.1",
        "Average":39.37,
        "ARC":42.06,
        "HellaSwag":70.82,
        "MMLU":26.94,
        "TruthfulQA":36.09,
        "Winogrande":59.83,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Chat",
        "Average":39.37,
        "ARC":42.06,
        "HellaSwag":70.82,
        "MMLU":26.94,
        "TruthfulQA":36.09,
        "Winogrande":59.83,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":92.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/LongAlpaca-7B",
        "Average":39.36,
        "ARC":42.66,
        "HellaSwag":65.89,
        "MMLU":27.28,
        "TruthfulQA":40.16,
        "Winogrande":60.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.74,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/PPO_Shygmalion-6b",
        "Average":39.35,
        "ARC":40.27,
        "HellaSwag":66.88,
        "MMLU":27.53,
        "TruthfulQA":34.24,
        "Winogrande":65.35,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"digitous\/Adventien-GPTJ",
        "Average":39.31,
        "ARC":42.49,
        "HellaSwag":69.21,
        "MMLU":25.4,
        "TruthfulQA":36.95,
        "Winogrande":60.22,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mosaicml\/mpt-7b-storywriter",
        "Average":39.31,
        "ARC":45.65,
        "HellaSwag":74.14,
        "MMLU":28.8,
        "TruthfulQA":36.12,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":778.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Average":39.3,
        "ARC":41.3,
        "HellaSwag":67.05,
        "MMLU":26.48,
        "TruthfulQA":35.19,
        "Winogrande":64.09,
        "GSM8K":1.67,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.9,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-6.7B",
        "Average":39.26,
        "ARC":39.42,
        "HellaSwag":71.26,
        "MMLU":26.91,
        "TruthfulQA":32.73,
        "Winogrande":65.27,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":6.7,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoder2-3b",
        "Average":39.25,
        "ARC":34.56,
        "HellaSwag":47.62,
        "MMLU":38.65,
        "TruthfulQA":40.49,
        "Winogrande":54.54,
        "GSM8K":19.64,
        "Type":"pretrained",
        "Architecture":"Starcoder2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":3.03,
        "Model Sha":98.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"L-R\/LLmRA-3B-v0.1",
        "Average":39.25,
        "ARC":39.42,
        "HellaSwag":59.79,
        "MMLU":25.16,
        "TruthfulQA":50.62,
        "Winogrande":59.43,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"databricks\/dolly-v2-7b",
        "Average":39.24,
        "ARC":44.54,
        "HellaSwag":69.64,
        "MMLU":25.18,
        "TruthfulQA":34.88,
        "Winogrande":60.06,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":145.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xaviviro\/FLAMA-0.5-3B",
        "Average":39.23,
        "ARC":37.97,
        "HellaSwag":67.65,
        "MMLU":25.73,
        "TruthfulQA":41.11,
        "Winogrande":62.12,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/RedPajama-INCITE-Chat-Instruct-3B-V1",
        "Average":39.23,
        "ARC":42.58,
        "HellaSwag":67.48,
        "MMLU":25.99,
        "TruthfulQA":33.62,
        "Winogrande":64.8,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"heegyu\/RedTulu-Uncensored-3B-0719",
        "Average":39.19,
        "ARC":40.02,
        "HellaSwag":62.55,
        "MMLU":30.37,
        "TruthfulQA":37.59,
        "Winogrande":62.35,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-7b1",
        "Average":39.18,
        "ARC":41.13,
        "HellaSwag":62.0,
        "MMLU":26.25,
        "TruthfulQA":38.9,
        "Winogrande":65.43,
        "GSM8K":1.36,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":7.07,
        "Model Sha":177.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DanielSc4\/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
        "Average":39.16,
        "ARC":41.3,
        "HellaSwag":66.82,
        "MMLU":26.1,
        "TruthfulQA":35.04,
        "Winogrande":65.43,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dvruette\/oasst-pythia-6.9b-4000-steps",
        "Average":39.15,
        "ARC":41.64,
        "HellaSwag":64.24,
        "MMLU":26.26,
        "TruthfulQA":40.43,
        "Winogrande":61.8,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.9,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"matsuo-lab\/weblab-10b-instruction-sft",
        "Average":39.13,
        "ARC":40.1,
        "HellaSwag":65.3,
        "MMLU":26.66,
        "TruthfulQA":36.79,
        "Winogrande":64.09,
        "GSM8K":1.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.0,
        "Model Sha":71.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"h2oai\/h2o-danube-1.8b-base",
        "Average":39.12,
        "ARC":39.42,
        "HellaSwag":69.58,
        "MMLU":25.94,
        "TruthfulQA":33.86,
        "Winogrande":64.48,
        "GSM8K":1.44,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.83,
        "Model Sha":40.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/robin-33B-v2-GPTQ",
        "Average":39.1,
        "ARC":27.73,
        "HellaSwag":26.29,
        "MMLU":23.53,
        "TruthfulQA":49.54,
        "Winogrande":79.79,
        "GSM8K":27.75,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-6.7B-Erebus",
        "Average":39.09,
        "ARC":39.16,
        "HellaSwag":68.66,
        "MMLU":24.58,
        "TruthfulQA":35.12,
        "Winogrande":65.98,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.7,
        "Model Sha":88.0
    },
    {
        "T":"?",
        "Model":"YeungNLP\/firefly-bloom-7b1",
        "Average":39.09,
        "ARC":40.44,
        "HellaSwag":61.2,
        "MMLU":26.83,
        "TruthfulQA":40.83,
        "Winogrande":64.56,
        "GSM8K":0.68,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-6.7b",
        "Average":39.08,
        "ARC":39.16,
        "HellaSwag":68.66,
        "MMLU":24.57,
        "TruthfulQA":35.12,
        "Winogrande":65.98,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.7,
        "Model Sha":94.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"togethercomputer\/RedPajama-INCITE-Instruct-3B-v1",
        "Average":39.06,
        "ARC":41.55,
        "HellaSwag":65.48,
        "MMLU":25.03,
        "TruthfulQA":36.41,
        "Winogrande":64.48,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":90.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/deacon-3b",
        "Average":39.05,
        "ARC":39.68,
        "HellaSwag":66.42,
        "MMLU":27.13,
        "TruthfulQA":36.07,
        "Winogrande":64.64,
        "GSM8K":0.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":3.43,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/ScarletPajama-3B-HF",
        "Average":39.04,
        "ARC":39.76,
        "HellaSwag":64.89,
        "MMLU":27.28,
        "TruthfulQA":37.6,
        "Winogrande":64.48,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psmathur\/orca_mini_3b",
        "Average":39.03,
        "ARC":41.55,
        "HellaSwag":61.52,
        "MMLU":26.79,
        "TruthfulQA":42.42,
        "Winogrande":61.8,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/black_goo_recipe_c",
        "Average":39.01,
        "ARC":38.74,
        "HellaSwag":66.83,
        "MMLU":26.57,
        "TruthfulQA":36.54,
        "Winogrande":64.72,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/Guanaco-3B-Uncensored-v2",
        "Average":38.98,
        "ARC":42.15,
        "HellaSwag":66.72,
        "MMLU":26.18,
        "TruthfulQA":35.21,
        "Winogrande":63.3,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jb723\/cross_lingual_epoch2",
        "Average":38.97,
        "ARC":39.25,
        "HellaSwag":47.92,
        "MMLU":36.66,
        "TruthfulQA":47.9,
        "Winogrande":62.12,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mwitiderrick\/open_llama_3b_instruct_v_0.2",
        "Average":38.97,
        "ARC":38.48,
        "HellaSwag":66.77,
        "MMLU":25.34,
        "TruthfulQA":38.16,
        "Winogrande":63.46,
        "GSM8K":1.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Guanaco-3B-Uncensored-v2-GPTQ",
        "Average":38.95,
        "ARC":41.64,
        "HellaSwag":64.76,
        "MMLU":26.25,
        "TruthfulQA":36.58,
        "Winogrande":64.33,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"GPTQ",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.78,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/Guanaco-3B-Uncensored",
        "Average":38.94,
        "ARC":42.49,
        "HellaSwag":66.99,
        "MMLU":25.55,
        "TruthfulQA":34.71,
        "Winogrande":63.38,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"health360\/Healix-3B",
        "Average":38.93,
        "ARC":37.71,
        "HellaSwag":65.94,
        "MMLU":26.02,
        "TruthfulQA":37.4,
        "Winogrande":65.75,
        "GSM8K":0.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Technoculture\/MT7Bi-wizard-3-alpha-dpo",
        "Average":38.88,
        "ARC":41.21,
        "HellaSwag":59.34,
        "MMLU":27.31,
        "TruthfulQA":39.06,
        "Winogrande":65.35,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"CobraMamba\/mamba-gpt-3b",
        "Average":38.87,
        "ARC":40.53,
        "HellaSwag":64.94,
        "MMLU":25.35,
        "TruthfulQA":37.14,
        "Winogrande":65.04,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":4.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"appvoid\/palmer-002.5",
        "Average":38.86,
        "ARC":37.54,
        "HellaSwag":61.84,
        "MMLU":25.21,
        "TruthfulQA":40.22,
        "Winogrande":66.38,
        "GSM8K":1.97,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"OpenAssistant\/galactica-6.7b-finetuned",
        "Average":38.84,
        "ARC":41.55,
        "HellaSwag":51.01,
        "MMLU":38.03,
        "TruthfulQA":41.65,
        "Winogrande":57.7,
        "GSM8K":3.11,
        "Type":"",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.7,
        "Model Sha":34.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frank098\/orca_mini_3b_juniper",
        "Average":38.83,
        "ARC":40.87,
        "HellaSwag":61.73,
        "MMLU":26.37,
        "TruthfulQA":43.19,
        "Winogrande":60.3,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-6.7B-Nerybus-Mix",
        "Average":38.83,
        "ARC":39.16,
        "HellaSwag":68.63,
        "MMLU":24.47,
        "TruthfulQA":34.84,
        "Winogrande":65.11,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.7,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-12b",
        "Average":38.82,
        "ARC":39.59,
        "HellaSwag":68.82,
        "MMLU":26.76,
        "TruthfulQA":31.85,
        "Winogrande":64.17,
        "GSM8K":1.74,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":128.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"heegyu\/WizardVicuna-open-llama-3b-v2",
        "Average":38.77,
        "ARC":37.71,
        "HellaSwag":66.6,
        "MMLU":27.23,
        "TruthfulQA":36.8,
        "Winogrande":63.3,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sail\/Sailor-1.8B-Chat",
        "Average":38.76,
        "ARC":35.75,
        "HellaSwag":57.12,
        "MMLU":38.31,
        "TruthfulQA":38.71,
        "Winogrande":59.12,
        "GSM8K":3.56,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/black_goo_recipe_a",
        "Average":38.73,
        "ARC":38.14,
        "HellaSwag":66.56,
        "MMLU":25.75,
        "TruthfulQA":37.46,
        "Winogrande":63.93,
        "GSM8K":0.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-6B-nerys-v2",
        "Average":38.72,
        "ARC":38.4,
        "HellaSwag":68.57,
        "MMLU":24.34,
        "TruthfulQA":34.73,
        "Winogrande":65.59,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.0,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"andrijdavid\/tinyllama-dare",
        "Average":38.64,
        "ARC":37.29,
        "HellaSwag":62.78,
        "MMLU":25.2,
        "TruthfulQA":39.01,
        "Winogrande":65.9,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hakurei\/instruct-12b",
        "Average":38.63,
        "ARC":42.58,
        "HellaSwag":66.76,
        "MMLU":26.79,
        "TruthfulQA":31.96,
        "Winogrande":63.46,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-oig-oasst1-256-6_9b",
        "Average":38.62,
        "ARC":39.93,
        "HellaSwag":65.42,
        "MMLU":26.39,
        "TruthfulQA":35.0,
        "Winogrande":63.38,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":9.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-0.5B",
        "Average":38.62,
        "ARC":31.48,
        "HellaSwag":49.05,
        "MMLU":39.35,
        "TruthfulQA":38.3,
        "Winogrande":57.22,
        "GSM8K":16.3,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.62,
        "Model Sha":98.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Deathsquad10\/TakeTwo",
        "Average":38.6,
        "ARC":37.2,
        "HellaSwag":62.01,
        "MMLU":23.8,
        "TruthfulQA":36.02,
        "Winogrande":70.01,
        "GSM8K":2.58,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"matsuo-lab\/weblab-10b",
        "Average":38.59,
        "ARC":39.51,
        "HellaSwag":65.76,
        "MMLU":26.29,
        "TruthfulQA":36.02,
        "Winogrande":62.51,
        "GSM8K":1.44,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.0,
        "Model Sha":60.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/black_goo_recipe_d",
        "Average":38.57,
        "ARC":37.8,
        "HellaSwag":66.5,
        "MMLU":26.64,
        "TruthfulQA":36.46,
        "Winogrande":63.61,
        "GSM8K":0.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"InnerI\/I-Code-NousLlama7B-slerp",
        "Average":38.56,
        "ARC":40.36,
        "HellaSwag":61.05,
        "MMLU":28.37,
        "TruthfulQA":36.17,
        "Winogrande":64.64,
        "GSM8K":0.76,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RWKV\/rwkv-raven-7b",
        "Average":38.55,
        "ARC":39.42,
        "HellaSwag":66.48,
        "MMLU":23.64,
        "TruthfulQA":38.56,
        "Winogrande":62.9,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Average":38.54,
        "ARC":40.19,
        "HellaSwag":64.77,
        "MMLU":27.03,
        "TruthfulQA":33.23,
        "Winogrande":64.72,
        "GSM8K":1.29,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":88.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Lazycuber\/pyg-instruct-wizardlm",
        "Average":38.54,
        "ARC":40.96,
        "HellaSwag":66.71,
        "MMLU":26.33,
        "TruthfulQA":31.93,
        "Winogrande":63.69,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-30B-Erebus",
        "Average":38.53,
        "ARC":36.69,
        "HellaSwag":65.6,
        "MMLU":24.8,
        "TruthfulQA":38.76,
        "Winogrande":65.11,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.0,
        "Model Sha":56.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/CrimsonPajama",
        "Average":38.52,
        "ARC":40.19,
        "HellaSwag":65.47,
        "MMLU":25.95,
        "TruthfulQA":33.78,
        "Winogrande":65.19,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-oig-oasst1-512-6_9b",
        "Average":38.52,
        "ARC":40.44,
        "HellaSwag":65.58,
        "MMLU":24.9,
        "TruthfulQA":36.68,
        "Winogrande":62.51,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":9.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_opt6.7b_10e5",
        "Average":38.52,
        "ARC":37.03,
        "HellaSwag":65.65,
        "MMLU":25.0,
        "TruthfulQA":37.61,
        "Winogrande":65.43,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/guanaco-33B-GPTQ",
        "Average":38.51,
        "ARC":28.16,
        "HellaSwag":26.34,
        "MMLU":24.94,
        "TruthfulQA":48.98,
        "Winogrande":78.85,
        "GSM8K":23.81,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":74.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/LLongMA-3b-LIMA",
        "Average":38.51,
        "ARC":39.08,
        "HellaSwag":67.15,
        "MMLU":26.43,
        "TruthfulQA":34.71,
        "Winogrande":63.38,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":3.0,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"pszemraj\/pythia-6.9b-HC3",
        "Average":38.51,
        "ARC":36.52,
        "HellaSwag":61.76,
        "MMLU":26.94,
        "TruthfulQA":45.05,
        "Winogrande":60.77,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.9,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/black_goo_recipe_b",
        "Average":38.49,
        "ARC":37.63,
        "HellaSwag":66.72,
        "MMLU":25.68,
        "TruthfulQA":37.09,
        "Winogrande":63.77,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Fredithefish\/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
        "Average":38.47,
        "ARC":40.61,
        "HellaSwag":64.84,
        "MMLU":26.13,
        "TruthfulQA":35.41,
        "Winogrande":63.54,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-6b",
        "Average":38.47,
        "ARC":40.53,
        "HellaSwag":67.47,
        "MMLU":25.73,
        "TruthfulQA":32.53,
        "Winogrande":62.51,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":6.0,
        "Model Sha":716.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/WizardLM-33B-V1.0-Uncensored-GPTQ",
        "Average":38.43,
        "ARC":27.39,
        "HellaSwag":26.03,
        "MMLU":25.81,
        "TruthfulQA":48.9,
        "Winogrande":77.9,
        "GSM8K":24.56,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":44.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"anhnv125\/pygmalion-6b-roleplay",
        "Average":38.34,
        "ARC":40.53,
        "HellaSwag":67.47,
        "MMLU":25.73,
        "TruthfulQA":32.53,
        "Winogrande":62.67,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"TehVenom\/DiffMerge_Pygmalion_Main-onto-V8P4",
        "Average":38.31,
        "ARC":40.53,
        "HellaSwag":67.48,
        "MMLU":25.68,
        "TruthfulQA":32.55,
        "Winogrande":62.51,
        "GSM8K":1.14,
        "Type":"",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"acrastt\/OmegLLaMA-3B",
        "Average":38.28,
        "ARC":40.36,
        "HellaSwag":66.13,
        "MMLU":28.0,
        "TruthfulQA":33.31,
        "Winogrande":61.64,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_3b",
        "Average":38.26,
        "ARC":39.85,
        "HellaSwag":62.65,
        "MMLU":26.94,
        "TruthfulQA":34.97,
        "Winogrande":64.72,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":140.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"aihub-app\/zyte-1B",
        "Average":38.23,
        "ARC":37.88,
        "HellaSwag":61.37,
        "MMLU":24.61,
        "TruthfulQA":42.14,
        "Winogrande":61.96,
        "GSM8K":1.44,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xaviviro\/FLOR-6.3B-xat",
        "Average":38.23,
        "ARC":38.65,
        "HellaSwag":63.76,
        "MMLU":26.54,
        "TruthfulQA":37.96,
        "Winogrande":62.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aihub-app\/zyte-1.1B",
        "Average":38.22,
        "ARC":37.88,
        "HellaSwag":61.37,
        "MMLU":24.62,
        "TruthfulQA":42.15,
        "Winogrande":61.96,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"venkycs\/zyte-v1-1.1B",
        "Average":38.21,
        "ARC":37.29,
        "HellaSwag":61.41,
        "MMLU":24.6,
        "TruthfulQA":42.59,
        "Winogrande":62.04,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewof\/koishi-instruct-3b",
        "Average":38.16,
        "ARC":40.96,
        "HellaSwag":64.54,
        "MMLU":26.58,
        "TruthfulQA":31.65,
        "Winogrande":64.09,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":2.91,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abhaykoul\/qwen1.5-vortex",
        "Average":38.15,
        "ARC":31.74,
        "HellaSwag":47.78,
        "MMLU":38.44,
        "TruthfulQA":38.92,
        "Winogrande":56.51,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abhaykoul\/Qwen1.5-0.5B-vortex",
        "Average":38.15,
        "ARC":31.74,
        "HellaSwag":47.78,
        "MMLU":38.44,
        "TruthfulQA":38.92,
        "Winogrande":56.51,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RESMPDEV\/Qwen1.5-Wukong-0.5B",
        "Average":38.15,
        "ARC":31.74,
        "HellaSwag":47.78,
        "MMLU":38.44,
        "TruthfulQA":38.92,
        "Winogrande":56.51,
        "GSM8K":15.54,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lqtrung1998\/galactica-6.7b-ReFT-GSM8k",
        "Average":38.15,
        "ARC":40.7,
        "HellaSwag":50.34,
        "MMLU":37.62,
        "TruthfulQA":41.21,
        "Winogrande":58.33,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abhaykoul\/qwen1.5-vortex",
        "Average":38.13,
        "ARC":31.83,
        "HellaSwag":47.71,
        "MMLU":38.66,
        "TruthfulQA":38.98,
        "Winogrande":56.27,
        "GSM8K":15.31,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/d-Qwen1.5-0.5B",
        "Average":38.07,
        "ARC":30.29,
        "HellaSwag":47.75,
        "MMLU":38.21,
        "TruthfulQA":39.29,
        "Winogrande":55.8,
        "GSM8K":17.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-6.7b",
        "Average":38.06,
        "ARC":40.1,
        "HellaSwag":65.0,
        "MMLU":24.64,
        "TruthfulQA":32.85,
        "Winogrande":64.72,
        "GSM8K":1.06,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"saberai\/Zro1.5_3B",
        "Average":38.02,
        "ARC":35.92,
        "HellaSwag":61.11,
        "MMLU":25.55,
        "TruthfulQA":36.89,
        "Winogrande":58.72,
        "GSM8K":9.93,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Average":37.95,
        "ARC":39.68,
        "HellaSwag":66.31,
        "MMLU":24.96,
        "TruthfulQA":33.65,
        "Winogrande":62.35,
        "GSM8K":0.76,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"indischepartij\/TinyUltra-4x1.1B-Base-Alpha",
        "Average":37.94,
        "ARC":34.9,
        "HellaSwag":61.42,
        "MMLU":25.42,
        "TruthfulQA":37.59,
        "Winogrande":65.75,
        "GSM8K":2.58,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":3.38,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"gmonsoon\/TinyUltra-4x1.1B-Base-Alpha",
        "Average":37.94,
        "ARC":34.9,
        "HellaSwag":61.42,
        "MMLU":25.42,
        "TruthfulQA":37.59,
        "Winogrande":65.75,
        "GSM8K":2.58,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.38,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-Cinder-1.3B-Reason-Test",
        "Average":37.88,
        "ARC":34.56,
        "HellaSwag":58.24,
        "MMLU":25.79,
        "TruthfulQA":39.93,
        "Winogrande":63.93,
        "GSM8K":4.85,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/Galactica-6.7B-EssayWriter",
        "Average":37.75,
        "ARC":40.1,
        "HellaSwag":50.29,
        "MMLU":33.88,
        "TruthfulQA":40.27,
        "Winogrande":58.48,
        "GSM8K":3.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.66,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Devio\/test-22B",
        "Average":37.71,
        "ARC":39.42,
        "HellaSwag":64.51,
        "MMLU":27.13,
        "TruthfulQA":37.13,
        "Winogrande":57.7,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":21.83,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/TinyLlama-MoE-Chat",
        "Average":37.71,
        "ARC":34.73,
        "HellaSwag":59.29,
        "MMLU":29.71,
        "TruthfulQA":39.35,
        "Winogrande":62.19,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aihub-app\/zyte-1.1b",
        "Average":37.7,
        "ARC":37.54,
        "HellaSwag":60.82,
        "MMLU":24.57,
        "TruthfulQA":39.46,
        "Winogrande":62.04,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ericzzz\/falcon-rw-1b-instruct-openorca",
        "Average":37.63,
        "ARC":34.56,
        "HellaSwag":60.93,
        "MMLU":28.77,
        "TruthfulQA":37.42,
        "Winogrande":60.69,
        "GSM8K":3.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":10.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"RESMPDEV\/Gemma-Wukong1.1-2b",
        "Average":37.61,
        "ARC":33.45,
        "HellaSwag":42.39,
        "MMLU":42.52,
        "TruthfulQA":47.73,
        "Winogrande":59.59,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/falcon_1b_stage2",
        "Average":37.59,
        "ARC":35.49,
        "HellaSwag":65.56,
        "MMLU":23.83,
        "TruthfulQA":38.32,
        "Winogrande":62.35,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ikala\/bloom-zh-3b-chat",
        "Average":37.58,
        "ARC":38.82,
        "HellaSwag":54.71,
        "MMLU":31.62,
        "TruthfulQA":41.25,
        "Winogrande":58.64,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":3.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "Average":37.55,
        "ARC":36.43,
        "HellaSwag":61.41,
        "MMLU":25.01,
        "TruthfulQA":37.59,
        "Winogrande":64.64,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Evaloric\/Evaloric-1.1B",
        "Average":37.54,
        "ARC":35.07,
        "HellaSwag":60.93,
        "MMLU":25.36,
        "TruthfulQA":37.78,
        "Winogrande":64.96,
        "GSM8K":1.14,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/CodeLlama-13B-Python-fp16",
        "Average":37.52,
        "ARC":33.19,
        "HellaSwag":44.5,
        "MMLU":25.94,
        "TruthfulQA":43.99,
        "Winogrande":67.4,
        "GSM8K":10.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ddyuudd\/merge_dolly-v2-3b_dpo_test",
        "Average":37.49,
        "ARC":40.02,
        "HellaSwag":65.14,
        "MMLU":24.99,
        "TruthfulQA":33.3,
        "Winogrande":59.35,
        "GSM8K":2.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HiTZ\/GoLLIE-7B",
        "Average":37.48,
        "ARC":36.09,
        "HellaSwag":57.93,
        "MMLU":29.38,
        "TruthfulQA":39.27,
        "Winogrande":58.96,
        "GSM8K":3.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"gemmathon\/gemma-2b-ko-dev-pbmt192",
        "Average":37.47,
        "ARC":38.57,
        "HellaSwag":52.95,
        "MMLU":28.71,
        "TruthfulQA":42.54,
        "Winogrande":58.56,
        "GSM8K":3.49,
        "Type":"continuously pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"OEvortex\/vortex-3b-v2",
        "Average":37.46,
        "ARC":39.68,
        "HellaSwag":65.04,
        "MMLU":25.09,
        "TruthfulQA":33.8,
        "Winogrande":59.12,
        "GSM8K":2.05,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.78,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ddyuudd\/dolly-v2-3b",
        "Average":37.46,
        "ARC":39.68,
        "HellaSwag":65.04,
        "MMLU":25.09,
        "TruthfulQA":33.8,
        "Winogrande":59.12,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RESMPDEV\/Gemma-Wukong1.1-2b",
        "Average":37.46,
        "ARC":33.45,
        "HellaSwag":42.42,
        "MMLU":42.94,
        "TruthfulQA":47.7,
        "Winogrande":58.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-2.7B",
        "Average":37.41,
        "ARC":33.79,
        "HellaSwag":65.74,
        "MMLU":26.44,
        "TruthfulQA":34.57,
        "Winogrande":63.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":2.78,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Evaloric\/Evaloric-1.1B-V.0.1",
        "Average":37.41,
        "ARC":36.86,
        "HellaSwag":61.9,
        "MMLU":23.96,
        "TruthfulQA":35.4,
        "Winogrande":63.46,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Average":37.4,
        "ARC":38.14,
        "HellaSwag":60.01,
        "MMLU":25.92,
        "TruthfulQA":39.19,
        "Winogrande":59.83,
        "GSM8K":1.29,
        "Type":"pretrained",
        "Architecture":"GPT2Model",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":636.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ndavidson\/cisco-iNAM-1.1B",
        "Average":37.39,
        "ARC":36.01,
        "HellaSwag":60.74,
        "MMLU":26.39,
        "TruthfulQA":39.3,
        "Winogrande":60.46,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"gardner\/TinyLlama-1.1B-SlimOrca-Function-Calling-3T",
        "Average":37.38,
        "ARC":36.09,
        "HellaSwag":59.66,
        "MMLU":28.21,
        "TruthfulQA":36.74,
        "Winogrande":59.12,
        "GSM8K":4.47,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"l3utterfly\/tinyllama-1.1b-layla-v4",
        "Average":37.37,
        "ARC":34.81,
        "HellaSwag":61.25,
        "MMLU":25.53,
        "TruthfulQA":38.97,
        "Winogrande":61.48,
        "GSM8K":2.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"ericzzz\/falcon-rw-1b-chat",
        "Average":37.37,
        "ARC":35.58,
        "HellaSwag":61.12,
        "MMLU":24.51,
        "TruthfulQA":39.62,
        "Winogrande":61.72,
        "GSM8K":1.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"frankenmerger\/MiniLlama-1.8b-Chat-v0.1",
        "Average":37.37,
        "ARC":34.73,
        "HellaSwag":62.38,
        "MMLU":25.69,
        "TruthfulQA":38.97,
        "Winogrande":60.54,
        "GSM8K":1.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.89,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dball\/zephyr-tiny-dpo-qlora",
        "Average":37.35,
        "ARC":36.6,
        "HellaSwag":61.66,
        "MMLU":25.78,
        "TruthfulQA":36.4,
        "Winogrande":61.56,
        "GSM8K":2.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dampish\/StellarX-4B-V0",
        "Average":37.31,
        "ARC":36.95,
        "HellaSwag":61.9,
        "MMLU":26.85,
        "TruthfulQA":34.3,
        "Winogrande":63.85,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":4.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ShieldX\/manovyadh-1.1B-v1-chat",
        "Average":37.3,
        "ARC":35.92,
        "HellaSwag":60.03,
        "MMLU":25.82,
        "TruthfulQA":39.17,
        "Winogrande":61.09,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyLlama\/TinyLlama-1.1B-Chat-v1.0",
        "Average":37.28,
        "ARC":36.09,
        "HellaSwag":61.1,
        "MMLU":25.39,
        "TruthfulQA":37.48,
        "Winogrande":61.25,
        "GSM8K":2.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":880.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/WizardLM-30B-Uncensored-GPTQ",
        "Average":37.27,
        "ARC":29.44,
        "HellaSwag":26.47,
        "MMLU":24.35,
        "TruthfulQA":49.15,
        "Winogrande":73.16,
        "GSM8K":21.08,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":118.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DanielSc4\/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
        "Average":37.27,
        "ARC":38.65,
        "HellaSwag":63.53,
        "MMLU":25.16,
        "TruthfulQA":36.07,
        "Winogrande":60.14,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"GeorgiaTechResearchInstitute\/galactica-6.7b-evol-instruct-70k",
        "Average":37.27,
        "ARC":42.58,
        "HellaSwag":49.3,
        "MMLU":32.96,
        "TruthfulQA":42.1,
        "Winogrande":56.27,
        "GSM8K":0.38,
        "Type":"",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.7,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"venkycs\/ZySec-1B",
        "Average":37.26,
        "ARC":38.4,
        "HellaSwag":61.53,
        "MMLU":25.05,
        "TruthfulQA":35.66,
        "Winogrande":61.33,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/falcon_1b_stage1",
        "Average":37.25,
        "ARC":35.15,
        "HellaSwag":62.4,
        "MMLU":24.47,
        "TruthfulQA":40.0,
        "Winogrande":61.48,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-Cinder-1.3B-Reason-Test.2",
        "Average":37.25,
        "ARC":32.76,
        "HellaSwag":58.27,
        "MMLU":24.39,
        "TruthfulQA":39.0,
        "Winogrande":65.04,
        "GSM8K":4.02,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Nekochu\/Confluence-Renegade-7B",
        "Average":37.23,
        "ARC":31.91,
        "HellaSwag":45.38,
        "MMLU":31.48,
        "TruthfulQA":51.47,
        "Winogrande":63.14,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Average":37.23,
        "ARC":36.35,
        "HellaSwag":60.75,
        "MMLU":26.0,
        "TruthfulQA":39.04,
        "Winogrande":60.69,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Josephgflowers\/TinyLlama-3T-Cinder-v1.3",
        "Average":37.23,
        "ARC":33.96,
        "HellaSwag":58.14,
        "MMLU":25.41,
        "TruthfulQA":38.13,
        "Winogrande":63.93,
        "GSM8K":3.79,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Trelis\/TinyLlama-chat-SFT",
        "Average":37.21,
        "ARC":34.47,
        "HellaSwag":61.03,
        "MMLU":25.77,
        "TruthfulQA":39.29,
        "Winogrande":61.25,
        "GSM8K":1.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sreeramajay\/TinyLlama-1.1B-orca-v1.0",
        "Average":37.17,
        "ARC":36.35,
        "HellaSwag":61.23,
        "MMLU":25.18,
        "TruthfulQA":36.58,
        "Winogrande":61.4,
        "GSM8K":2.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TinyLlama\/TinyLlama-1.1B-Chat-v1.0",
        "Average":37.17,
        "ARC":35.92,
        "HellaSwag":61.11,
        "MMLU":25.0,
        "TruthfulQA":37.38,
        "Winogrande":61.17,
        "GSM8K":2.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":880.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"eren23\/DistiLabelOrca-TinyLLama-1.1B",
        "Average":37.17,
        "ARC":36.18,
        "HellaSwag":61.15,
        "MMLU":25.09,
        "TruthfulQA":38.05,
        "Winogrande":60.85,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/TinyLlama-1.1B-2.5T-chat-and-function-calling",
        "Average":37.16,
        "ARC":34.39,
        "HellaSwag":59.61,
        "MMLU":26.32,
        "TruthfulQA":38.92,
        "Winogrande":61.96,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kevin009\/lamatama",
        "Average":37.15,
        "ARC":36.35,
        "HellaSwag":61.12,
        "MMLU":24.72,
        "TruthfulQA":37.67,
        "Winogrande":60.77,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"OEvortex\/HelpingAI-Lite-2x1B",
        "Average":37.15,
        "ARC":36.09,
        "HellaSwag":61.11,
        "MMLU":25.1,
        "TruthfulQA":37.39,
        "Winogrande":60.85,
        "GSM8K":2.35,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.86,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"princeton-nlp\/Sheared-LLaMA-1.3B-ShareGPT",
        "Average":37.14,
        "ARC":33.96,
        "HellaSwag":62.55,
        "MMLU":26.42,
        "TruthfulQA":43.03,
        "Winogrande":56.83,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/d-Qwen1.5-1.8B",
        "Average":37.14,
        "ARC":30.89,
        "HellaSwag":49.73,
        "MMLU":37.92,
        "TruthfulQA":42.89,
        "Winogrande":59.19,
        "GSM8K":2.2,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Danielbrdz\/Barcenas-Tiny-1.1b-DPO",
        "Average":37.12,
        "ARC":36.26,
        "HellaSwag":61.2,
        "MMLU":24.83,
        "TruthfulQA":37.45,
        "Winogrande":60.93,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-2.7b",
        "Average":37.09,
        "ARC":37.37,
        "HellaSwag":60.74,
        "MMLU":25.86,
        "TruthfulQA":35.4,
        "Winogrande":62.12,
        "GSM8K":1.06,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":2.91,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Deathsquad10\/TinyLlama-repeat",
        "Average":37.09,
        "ARC":35.24,
        "HellaSwag":60.25,
        "MMLU":26.07,
        "TruthfulQA":38.78,
        "Winogrande":60.46,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"davanstrien\/TinyLlama-1.1B-Chat-v1.0-intel-dpo",
        "Average":37.09,
        "ARC":35.84,
        "HellaSwag":61.29,
        "MMLU":25.05,
        "TruthfulQA":37.38,
        "Winogrande":61.01,
        "GSM8K":1.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-rw-1b",
        "Average":37.07,
        "ARC":35.07,
        "HellaSwag":63.56,
        "MMLU":25.28,
        "TruthfulQA":35.96,
        "Winogrande":62.04,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":95.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Phind\/Phind-CodeLlama-34B-v1",
        "Average":37.06,
        "ARC":27.13,
        "HellaSwag":28.28,
        "MMLU":28.94,
        "TruthfulQA":44.94,
        "Winogrande":72.61,
        "GSM8K":20.47,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":321.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kalisai\/Nusantara-1.8b-Indo-Chat",
        "Average":37.06,
        "ARC":35.32,
        "HellaSwag":56.32,
        "MMLU":30.37,
        "TruthfulQA":37.27,
        "Winogrande":59.75,
        "GSM8K":3.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xaviviro\/OpenHermes-2.5-FLOR-6.3B",
        "Average":37.04,
        "ARC":33.45,
        "HellaSwag":54.53,
        "MMLU":25.18,
        "TruthfulQA":46.12,
        "Winogrande":62.98,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.3,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/TinyLlama-Cinder-1.3B-Test.2",
        "Average":37.04,
        "ARC":33.7,
        "HellaSwag":58.66,
        "MMLU":25.69,
        "TruthfulQA":37.98,
        "Winogrande":64.09,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloomz-3b",
        "Average":37.03,
        "ARC":36.86,
        "HellaSwag":54.95,
        "MMLU":32.91,
        "TruthfulQA":40.34,
        "Winogrande":57.14,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":3.0,
        "Model Sha":74.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kevin009\/TinyNaughtyLlama-v1.0",
        "Average":37.03,
        "ARC":35.92,
        "HellaSwag":61.04,
        "MMLU":25.82,
        "TruthfulQA":36.77,
        "Winogrande":60.22,
        "GSM8K":2.43,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alexredna\/TinyLlama-1.1B-Chat-v1.0-reasoning-v2-dpo",
        "Average":37.03,
        "ARC":34.39,
        "HellaSwag":61.87,
        "MMLU":26.34,
        "TruthfulQA":36.13,
        "Winogrande":63.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Abhaykoul\/HelpingAI-Lite-4x1b",
        "Average":37.02,
        "ARC":35.84,
        "HellaSwag":61.0,
        "MMLU":25.24,
        "TruthfulQA":37.39,
        "Winogrande":60.77,
        "GSM8K":1.9,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":3.38,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aabbhishekk\/TinyLlama-1.1B-miniguanaco",
        "Average":37.02,
        "ARC":35.15,
        "HellaSwag":60.26,
        "MMLU":26.26,
        "TruthfulQA":38.84,
        "Winogrande":60.14,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-13b-Python-hf",
        "Average":37.0,
        "ARC":32.59,
        "HellaSwag":43.94,
        "MMLU":27.23,
        "TruthfulQA":44.59,
        "Winogrande":65.04,
        "GSM8K":8.64,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sbawa\/elysa_model",
        "Average":37.0,
        "ARC":37.54,
        "HellaSwag":60.37,
        "MMLU":25.58,
        "TruthfulQA":37.37,
        "Winogrande":60.22,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIChenKai\/TinyLlama-1.1B-Chat-v1.0-x2-MoE",
        "Average":36.98,
        "ARC":36.01,
        "HellaSwag":61.04,
        "MMLU":24.81,
        "TruthfulQA":37.37,
        "Winogrande":60.38,
        "GSM8K":2.27,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.86,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-2.7B-Erebus",
        "Average":36.96,
        "ARC":34.39,
        "HellaSwag":60.91,
        "MMLU":26.7,
        "TruthfulQA":37.82,
        "Winogrande":61.64,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.7,
        "Model Sha":37.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jan-hq\/LlamaCorn-1.1B",
        "Average":36.94,
        "ARC":34.13,
        "HellaSwag":59.33,
        "MMLU":29.01,
        "TruthfulQA":36.78,
        "Winogrande":61.96,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cmarkea\/bloomz-3b-sft-chat",
        "Average":36.94,
        "ARC":36.86,
        "HellaSwag":54.34,
        "MMLU":31.49,
        "TruthfulQA":39.69,
        "Winogrande":58.88,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":3.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/TinyLlama-1.1B-2.5T-chat",
        "Average":36.93,
        "ARC":34.47,
        "HellaSwag":59.71,
        "MMLU":26.45,
        "TruthfulQA":38.8,
        "Winogrande":61.01,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kevin009\/babyllama-v0.6",
        "Average":36.92,
        "ARC":36.09,
        "HellaSwag":61.59,
        "MMLU":25.37,
        "TruthfulQA":35.84,
        "Winogrande":61.01,
        "GSM8K":1.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v1-3b",
        "Average":36.9,
        "ARC":36.86,
        "HellaSwag":55.1,
        "MMLU":26.7,
        "TruthfulQA":43.45,
        "Winogrande":58.88,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Phind\/Phind-CodeLlama-34B-v2",
        "Average":36.89,
        "ARC":24.57,
        "HellaSwag":27.6,
        "MMLU":25.76,
        "TruthfulQA":48.37,
        "Winogrande":71.82,
        "GSM8K":23.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":756.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-7b-Python-hf",
        "Average":36.89,
        "ARC":31.31,
        "HellaSwag":52.86,
        "MMLU":27.32,
        "TruthfulQA":42.21,
        "Winogrande":63.06,
        "GSM8K":4.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":120.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Average":36.88,
        "ARC":36.26,
        "HellaSwag":61.9,
        "MMLU":25.42,
        "TruthfulQA":36.31,
        "Winogrande":60.77,
        "GSM8K":0.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":3.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/falcon_1b_stage2",
        "Average":36.88,
        "ARC":33.11,
        "HellaSwag":63.19,
        "MMLU":24.22,
        "TruthfulQA":38.4,
        "Winogrande":62.35,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-2.7B-Nerybus-Mix",
        "Average":36.88,
        "ARC":33.7,
        "HellaSwag":61.21,
        "MMLU":26.6,
        "TruthfulQA":37.57,
        "Winogrande":62.04,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.7,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenBuddy\/openbuddy-openllama-3b-v10-bf16",
        "Average":36.87,
        "ARC":36.26,
        "HellaSwag":58.38,
        "MMLU":23.89,
        "TruthfulQA":42.04,
        "Winogrande":59.67,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lqtrung1998\/galactica-6.7b-ReFT-Rerank-GSM8k",
        "Average":36.86,
        "ARC":41.13,
        "HellaSwag":48.78,
        "MMLU":32.86,
        "TruthfulQA":41.2,
        "Winogrande":56.91,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForSequenceClassification",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":6.66,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-1.3B-Cinder-Reason-Test-2",
        "Average":36.83,
        "ARC":32.76,
        "HellaSwag":57.92,
        "MMLU":25.42,
        "TruthfulQA":37.26,
        "Winogrande":64.8,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"l3utterfly\/tinyllama-1.1b-layla-v1",
        "Average":36.82,
        "ARC":34.39,
        "HellaSwag":59.86,
        "MMLU":24.7,
        "TruthfulQA":41.03,
        "Winogrande":59.75,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Writer\/camel-5b-hf",
        "Average":36.81,
        "ARC":35.15,
        "HellaSwag":57.62,
        "MMLU":26.07,
        "TruthfulQA":40.65,
        "Winogrande":61.01,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":5.0,
        "Model Sha":110.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"appvoid\/palmer-002",
        "Average":36.79,
        "ARC":34.47,
        "HellaSwag":59.41,
        "MMLU":25.94,
        "TruthfulQA":37.06,
        "Winogrande":62.67,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TFLai\/pythia-2.8b-4bit-alpaca",
        "Average":36.77,
        "ARC":34.73,
        "HellaSwag":58.96,
        "MMLU":25.53,
        "TruthfulQA":39.14,
        "Winogrande":61.64,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":2.8,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-2.7B-Nerys-v2",
        "Average":36.75,
        "ARC":33.28,
        "HellaSwag":61.23,
        "MMLU":26.44,
        "TruthfulQA":37.23,
        "Winogrande":62.04,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.7,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/dopeyshearedplats-1.3b-v1",
        "Average":36.74,
        "ARC":34.39,
        "HellaSwag":64.31,
        "MMLU":25.4,
        "TruthfulQA":38.21,
        "Winogrande":57.38,
        "GSM8K":0.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-2.7b",
        "Average":36.74,
        "ARC":33.96,
        "HellaSwag":61.43,
        "MMLU":25.43,
        "TruthfulQA":37.43,
        "Winogrande":61.96,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.7,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jan-hq\/LlamaCorn-1.1B-Chat",
        "Average":36.73,
        "ARC":33.79,
        "HellaSwag":59.24,
        "MMLU":29.01,
        "TruthfulQA":36.86,
        "Winogrande":61.48,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"L-R\/LLmRa-2.7B",
        "Average":36.72,
        "ARC":37.03,
        "HellaSwag":60.65,
        "MMLU":25.58,
        "TruthfulQA":35.23,
        "Winogrande":61.56,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.7,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Average":36.72,
        "ARC":36.26,
        "HellaSwag":60.66,
        "MMLU":26.78,
        "TruthfulQA":35.56,
        "Winogrande":60.22,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.91,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/chopt-2_7b",
        "Average":36.72,
        "ARC":36.01,
        "HellaSwag":63.38,
        "MMLU":25.44,
        "TruthfulQA":37.71,
        "Winogrande":57.77,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/TinyLlama-MoE-Chat-0.1",
        "Average":36.7,
        "ARC":34.39,
        "HellaSwag":56.72,
        "MMLU":29.36,
        "TruthfulQA":37.82,
        "Winogrande":59.67,
        "GSM8K":2.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"M4-ai\/tau-0.5B",
        "Average":36.68,
        "ARC":29.27,
        "HellaSwag":47.43,
        "MMLU":37.53,
        "TruthfulQA":39.39,
        "Winogrande":56.83,
        "GSM8K":9.63,
        "Type":"continuously pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.5,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Changgil\/K2S3-SOLAR-11b-v1.0",
        "Average":36.67,
        "ARC":33.7,
        "HellaSwag":51.39,
        "MMLU":30.05,
        "TruthfulQA":45.99,
        "Winogrande":57.54,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alnrg2arg\/blockchainlabs_tinyllama_fusion_LHK_yunkong_v2",
        "Average":36.67,
        "ARC":34.9,
        "HellaSwag":63.11,
        "MMLU":26.75,
        "TruthfulQA":37.33,
        "Winogrande":57.14,
        "GSM8K":0.76,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"M4-ai\/tau-0.5B",
        "Average":36.65,
        "ARC":29.01,
        "HellaSwag":47.45,
        "MMLU":37.44,
        "TruthfulQA":39.39,
        "Winogrande":56.83,
        "GSM8K":9.78,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.5,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"danielhanchen\/open_llama_3b_600bt_preview",
        "Average":36.65,
        "ARC":36.86,
        "HellaSwag":59.96,
        "MMLU":25.97,
        "TruthfulQA":32.81,
        "Winogrande":63.69,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ajibawa-2023\/Code-290k-6.7B-Instruct",
        "Average":36.64,
        "ARC":34.9,
        "HellaSwag":51.99,
        "MMLU":34.89,
        "TruthfulQA":41.95,
        "Winogrande":52.64,
        "GSM8K":3.49,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":6.74,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"42dot\/42dot_LLM-SFT-1.3B",
        "Average":36.61,
        "ARC":36.09,
        "HellaSwag":58.96,
        "MMLU":25.51,
        "TruthfulQA":39.98,
        "Winogrande":58.41,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.44,
        "Model Sha":30.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Chickaboo\/ChickaQ",
        "Average":36.6,
        "ARC":29.44,
        "HellaSwag":49.15,
        "MMLU":37.05,
        "TruthfulQA":47.22,
        "Winogrande":56.12,
        "GSM8K":0.61,
        "Type":"base merges and moerges",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":0.62,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"alnrg2arg\/blockchainlabs_tinyllama_fusion_LHK_yunkong",
        "Average":36.6,
        "ARC":34.73,
        "HellaSwag":60.41,
        "MMLU":24.96,
        "TruthfulQA":37.45,
        "Winogrande":59.91,
        "GSM8K":2.12,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhinand\/TinyLlama-1.1B-OpenHermes-2.5-Chat-v0.1-sft",
        "Average":36.59,
        "ARC":33.79,
        "HellaSwag":58.72,
        "MMLU":24.52,
        "TruthfulQA":36.22,
        "Winogrande":60.93,
        "GSM8K":5.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HuggingFaceTB\/cosmo-1b",
        "Average":36.59,
        "ARC":38.57,
        "HellaSwag":55.13,
        "MMLU":26.69,
        "TruthfulQA":38.15,
        "Winogrande":55.49,
        "GSM8K":5.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.74,
        "Model Sha":104.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sail\/Sailor-1.8B",
        "Average":36.59,
        "ARC":33.11,
        "HellaSwag":57.06,
        "MMLU":30.44,
        "TruthfulQA":37.81,
        "Winogrande":58.41,
        "GSM8K":2.73,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.84,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"PSanni\/Deer-3b",
        "Average":36.55,
        "ARC":38.48,
        "HellaSwag":57.41,
        "MMLU":25.64,
        "TruthfulQA":39.98,
        "Winogrande":57.46,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/smolphin-test-bottomheavy",
        "Average":36.54,
        "ARC":32.68,
        "HellaSwag":59.17,
        "MMLU":25.84,
        "TruthfulQA":38.49,
        "Winogrande":61.8,
        "GSM8K":1.29,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alexredna\/Tukan-1.1B-Chat-reasoning-sft-COLA",
        "Average":36.53,
        "ARC":34.13,
        "HellaSwag":59.78,
        "MMLU":24.86,
        "TruthfulQA":38.25,
        "Winogrande":60.77,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HuggingFaceTB\/cosmo-1b",
        "Average":36.52,
        "ARC":38.57,
        "HellaSwag":55.08,
        "MMLU":26.5,
        "TruthfulQA":38.26,
        "Winogrande":55.33,
        "GSM8K":5.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.74,
        "Model Sha":104.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/TinyWombat-1.8b-Chat-v.1",
        "Average":36.48,
        "ARC":32.94,
        "HellaSwag":58.88,
        "MMLU":25.12,
        "TruthfulQA":39.74,
        "Winogrande":60.22,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.89,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"invalid-coder\/TinyLlama-1.1B-intermediate-step-1431k-3T-laser-dpo",
        "Average":36.46,
        "ARC":33.02,
        "HellaSwag":60.0,
        "MMLU":26.88,
        "TruthfulQA":38.08,
        "Winogrande":59.59,
        "GSM8K":1.21,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BEE-spoke-data\/TinyLlama-3T-1.1bee",
        "Average":36.46,
        "ARC":33.79,
        "HellaSwag":60.29,
        "MMLU":25.86,
        "TruthfulQA":38.13,
        "Winogrande":60.22,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abhaykoul\/Qwen1.5-0.5B-vortex-v2",
        "Average":36.45,
        "ARC":30.63,
        "HellaSwag":45.54,
        "MMLU":36.29,
        "TruthfulQA":44.29,
        "Winogrande":56.04,
        "GSM8K":5.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/smolphin-test-stack-sorted",
        "Average":36.42,
        "ARC":32.34,
        "HellaSwag":59.07,
        "MMLU":26.44,
        "TruthfulQA":37.48,
        "Winogrande":61.25,
        "GSM8K":1.97,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"codellama\/CodeLlama-7b-Python-hf",
        "Average":36.42,
        "ARC":29.27,
        "HellaSwag":50.12,
        "MMLU":28.37,
        "TruthfulQA":41.61,
        "Winogrande":64.01,
        "GSM8K":5.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.74,
        "Model Sha":120.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ozayezerceli\/TinyLlamax2-1.1b",
        "Average":36.42,
        "ARC":33.87,
        "HellaSwag":60.31,
        "MMLU":26.04,
        "TruthfulQA":37.32,
        "Winogrande":59.51,
        "GSM8K":1.44,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Average":36.42,
        "ARC":33.87,
        "HellaSwag":60.31,
        "MMLU":26.04,
        "TruthfulQA":37.32,
        "Winogrande":59.51,
        "GSM8K":1.44,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":127.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h4rz3rk4s3\/TinyNewsLlama-1.1B",
        "Average":36.41,
        "ARC":32.94,
        "HellaSwag":59.43,
        "MMLU":25.18,
        "TruthfulQA":40.95,
        "Winogrande":59.75,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/SmolPlatypus-1.5B-Sorted",
        "Average":36.4,
        "ARC":33.62,
        "HellaSwag":59.06,
        "MMLU":25.61,
        "TruthfulQA":37.88,
        "Winogrande":61.17,
        "GSM8K":1.06,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/xglm-7.5B",
        "Average":36.38,
        "ARC":34.13,
        "HellaSwag":60.77,
        "MMLU":27.79,
        "TruthfulQA":36.66,
        "Winogrande":58.72,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.5,
        "Model Sha":54.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SanjiWatsuki\/WoolyHermes-1.1B",
        "Average":36.37,
        "ARC":34.3,
        "HellaSwag":59.37,
        "MMLU":25.59,
        "TruthfulQA":37.58,
        "Winogrande":59.35,
        "GSM8K":2.05,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/TinyDolphin-2.8-1.1b",
        "Average":36.34,
        "ARC":34.3,
        "HellaSwag":59.44,
        "MMLU":25.59,
        "TruthfulQA":36.51,
        "Winogrande":60.69,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Phind\/Phind-CodeLlama-34B-Python-v1",
        "Average":36.33,
        "ARC":24.66,
        "HellaSwag":29.77,
        "MMLU":27.95,
        "TruthfulQA":45.27,
        "Winogrande":68.82,
        "GSM8K":21.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.0,
        "Model Sha":249.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/sheared-plus-westlake-50_75p",
        "Average":36.31,
        "ARC":34.04,
        "HellaSwag":58.05,
        "MMLU":26.24,
        "TruthfulQA":42.64,
        "Winogrande":56.91,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Average":36.27,
        "ARC":35.07,
        "HellaSwag":59.36,
        "MMLU":25.93,
        "TruthfulQA":38.02,
        "Winogrande":58.72,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.7,
        "Model Sha":65.0
    },
    {
        "T":"?",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
        "Average":36.26,
        "ARC":33.53,
        "HellaSwag":59.38,
        "MMLU":26.22,
        "TruthfulQA":36.79,
        "Winogrande":60.22,
        "GSM8K":1.44,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":44.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/SmolPlatypus-1.5B",
        "Average":36.23,
        "ARC":33.96,
        "HellaSwag":60.05,
        "MMLU":24.73,
        "TruthfulQA":36.82,
        "Winogrande":60.85,
        "GSM8K":0.99,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/TinyDolphin-2.8.1-1.1b",
        "Average":36.21,
        "ARC":34.98,
        "HellaSwag":60.11,
        "MMLU":25.31,
        "TruthfulQA":35.51,
        "Winogrande":60.69,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":9.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/smolphin-test-stack",
        "Average":36.2,
        "ARC":32.68,
        "HellaSwag":59.94,
        "MMLU":25.16,
        "TruthfulQA":36.64,
        "Winogrande":62.04,
        "GSM8K":0.76,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Average":36.2,
        "ARC":33.36,
        "HellaSwag":56.24,
        "MMLU":26.45,
        "TruthfulQA":39.78,
        "Winogrande":60.06,
        "GSM8K":1.29,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.72,
        "Model Sha":384.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bertin-project\/bertin-gpt-j-6B-alpaca",
        "Average":36.19,
        "ARC":36.01,
        "HellaSwag":54.3,
        "MMLU":27.66,
        "TruthfulQA":43.38,
        "Winogrande":55.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":6.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/falcon_1b_stage3_2",
        "Average":36.19,
        "ARC":34.56,
        "HellaSwag":58.37,
        "MMLU":23.87,
        "TruthfulQA":39.89,
        "Winogrande":60.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/sheared-plus-westlake-nearest-50_75p",
        "Average":36.18,
        "ARC":36.18,
        "HellaSwag":57.54,
        "MMLU":24.2,
        "TruthfulQA":42.39,
        "Winogrande":56.75,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Average":36.15,
        "ARC":34.64,
        "HellaSwag":56.74,
        "MMLU":25.55,
        "TruthfulQA":38.55,
        "Winogrande":61.4,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":4.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-3b",
        "Average":36.07,
        "ARC":35.75,
        "HellaSwag":54.37,
        "MMLU":26.59,
        "TruthfulQA":40.57,
        "Winogrande":57.62,
        "GSM8K":1.52,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":3.0,
        "Model Sha":83.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/Wizard-Vicuna-13B-Uncensored-GPTQ",
        "Average":36.06,
        "ARC":29.61,
        "HellaSwag":25.47,
        "MMLU":25.34,
        "TruthfulQA":50.25,
        "Winogrande":75.77,
        "GSM8K":9.93,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":289.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deacon-1_8b",
        "Average":36.03,
        "ARC":33.7,
        "HellaSwag":52.33,
        "MMLU":33.97,
        "TruthfulQA":39.05,
        "Winogrande":57.14,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Ba2han\/TinyOpenHermes-1.1B-4k",
        "Average":35.98,
        "ARC":33.62,
        "HellaSwag":58.53,
        "MMLU":26.45,
        "TruthfulQA":37.33,
        "Winogrande":59.91,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Azure99\/blossom-v2-3b",
        "Average":35.98,
        "ARC":35.32,
        "HellaSwag":54.1,
        "MMLU":23.99,
        "TruthfulQA":43.11,
        "Winogrande":58.8,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/shearedplats-1.3b-v1",
        "Average":35.97,
        "ARC":35.41,
        "HellaSwag":62.75,
        "MMLU":24.75,
        "TruthfulQA":33.93,
        "Winogrande":58.48,
        "GSM8K":0.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"remyxai\/localmentor_25K_3epochs_tinyllama",
        "Average":35.96,
        "ARC":34.22,
        "HellaSwag":59.01,
        "MMLU":24.93,
        "TruthfulQA":36.07,
        "Winogrande":60.46,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"princeton-nlp\/Sheared-LLaMA-1.3B",
        "Average":35.95,
        "ARC":32.85,
        "HellaSwag":60.91,
        "MMLU":25.71,
        "TruthfulQA":37.14,
        "Winogrande":58.64,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":81.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/GPT-J-6B-Adventure",
        "Average":35.95,
        "ARC":37.12,
        "HellaSwag":61.26,
        "MMLU":25.94,
        "TruthfulQA":34.56,
        "Winogrande":55.96,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":6.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"cognitivecomputations\/TinyDolphin-2.8.2-1.1b-laser",
        "Average":35.93,
        "ARC":33.36,
        "HellaSwag":58.53,
        "MMLU":25.93,
        "TruthfulQA":36.33,
        "Winogrande":60.14,
        "GSM8K":1.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ehartford\/CodeLlama-34b-Python-hf",
        "Average":35.92,
        "ARC":38.05,
        "HellaSwag":34.79,
        "MMLU":32.96,
        "TruthfulQA":43.57,
        "Winogrande":66.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":33.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Deathsquad10\/TinyMix",
        "Average":35.91,
        "ARC":32.0,
        "HellaSwag":53.69,
        "MMLU":24.27,
        "TruthfulQA":39.42,
        "Winogrande":64.09,
        "GSM8K":1.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/TinyLamma-SFT",
        "Average":35.88,
        "ARC":34.39,
        "HellaSwag":59.14,
        "MMLU":24.26,
        "TruthfulQA":37.2,
        "Winogrande":58.64,
        "GSM8K":1.67,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/smolphin-test1",
        "Average":35.85,
        "ARC":32.25,
        "HellaSwag":59.73,
        "MMLU":24.61,
        "TruthfulQA":35.81,
        "Winogrande":61.72,
        "GSM8K":0.99,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"MayaPH\/opt-flan-iml-6.7b",
        "Average":35.84,
        "ARC":30.12,
        "HellaSwag":58.82,
        "MMLU":25.12,
        "TruthfulQA":36.74,
        "Winogrande":64.25,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":6.66,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-1.3B-Cinder-Reason-Test",
        "Average":35.84,
        "ARC":32.51,
        "HellaSwag":55.85,
        "MMLU":26.61,
        "TruthfulQA":35.59,
        "Winogrande":62.12,
        "GSM8K":2.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/sheared-silicon10p",
        "Average":35.82,
        "ARC":36.18,
        "HellaSwag":51.12,
        "MMLU":25.56,
        "TruthfulQA":44.85,
        "Winogrande":57.22,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":2.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RWKV\/rwkv-raven-3b",
        "Average":35.81,
        "ARC":36.69,
        "HellaSwag":59.78,
        "MMLU":24.87,
        "TruthfulQA":35.6,
        "Winogrande":57.46,
        "GSM8K":0.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":3.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"VAIBHAV22334455\/JARVIS",
        "Average":35.78,
        "ARC":32.08,
        "HellaSwag":56.86,
        "MMLU":27.15,
        "TruthfulQA":37.33,
        "Winogrande":60.14,
        "GSM8K":1.14,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OEvortex\/vortex-3b",
        "Average":35.76,
        "ARC":31.91,
        "HellaSwag":56.89,
        "MMLU":27.32,
        "TruthfulQA":37.39,
        "Winogrande":60.14,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.78,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoder",
        "Average":35.73,
        "ARC":30.29,
        "HellaSwag":47.88,
        "MMLU":29.47,
        "TruthfulQA":41.3,
        "Winogrande":56.27,
        "GSM8K":9.17,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":2685.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Ba2han\/Tinypus-1.5B",
        "Average":35.73,
        "ARC":33.45,
        "HellaSwag":57.35,
        "MMLU":25.53,
        "TruthfulQA":39.35,
        "Winogrande":57.7,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.45,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Average":35.71,
        "ARC":32.68,
        "HellaSwag":59.99,
        "MMLU":25.69,
        "TruthfulQA":36.97,
        "Winogrande":58.72,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"42dot\/42dot_LLM-PLM-1.3B",
        "Average":35.7,
        "ARC":32.42,
        "HellaSwag":56.39,
        "MMLU":27.09,
        "TruthfulQA":38.68,
        "Winogrande":58.88,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.44,
        "Model Sha":21.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/SmolLlama-1.5B-Bottomheavy",
        "Average":35.68,
        "ARC":34.22,
        "HellaSwag":59.54,
        "MMLU":24.96,
        "TruthfulQA":35.0,
        "Winogrande":59.75,
        "GSM8K":0.61,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kalisai\/Nusantara-2.7b-Indo-Chat",
        "Average":35.68,
        "ARC":34.22,
        "HellaSwag":56.1,
        "MMLU":24.83,
        "TruthfulQA":37.41,
        "Winogrande":58.17,
        "GSM8K":3.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sartmis1\/starcoder-finetune-selfinstruct",
        "Average":35.65,
        "ARC":31.23,
        "HellaSwag":47.66,
        "MMLU":29.52,
        "TruthfulQA":41.63,
        "Winogrande":57.77,
        "GSM8K":6.07,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-0.5B-Chat",
        "Average":35.61,
        "ARC":30.55,
        "HellaSwag":44.07,
        "MMLU":33.82,
        "TruthfulQA":42.95,
        "Winogrande":54.62,
        "GSM8K":7.66,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.62,
        "Model Sha":39.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Minami-su\/Qwen1.5-0.5B-Chat_llamafy",
        "Average":35.61,
        "ARC":30.63,
        "HellaSwag":44.11,
        "MMLU":33.82,
        "TruthfulQA":42.97,
        "Winogrande":54.7,
        "GSM8K":7.43,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.5,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/Tiny-Llama-3-7b",
        "Average":35.6,
        "ARC":34.64,
        "HellaSwag":56.39,
        "MMLU":24.51,
        "TruthfulQA":38.03,
        "Winogrande":59.67,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.91,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"freecs\/Llama-3-7b",
        "Average":35.6,
        "ARC":34.64,
        "HellaSwag":56.39,
        "MMLU":24.51,
        "TruthfulQA":38.03,
        "Winogrande":59.67,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.91,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zyh3826\/20231206094523-pretrain-Llama-2-13b-hf-76000",
        "Average":35.58,
        "ARC":31.06,
        "HellaSwag":52.03,
        "MMLU":24.43,
        "TruthfulQA":44.71,
        "Winogrande":61.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"habanoz\/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
        "Average":35.58,
        "ARC":32.85,
        "HellaSwag":58.16,
        "MMLU":25.96,
        "TruthfulQA":38.35,
        "Winogrande":57.7,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Cinder-1.3B-Test",
        "Average":35.57,
        "ARC":33.19,
        "HellaSwag":55.48,
        "MMLU":26.37,
        "TruthfulQA":36.62,
        "Winogrande":58.96,
        "GSM8K":2.81,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.28,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/wizard-vicuna-13B-GPTQ",
        "Average":35.56,
        "ARC":28.67,
        "HellaSwag":25.94,
        "MMLU":25.84,
        "TruthfulQA":48.53,
        "Winogrande":74.74,
        "GSM8K":9.63,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":100.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PY007\/TinyLlama-1.1B-Chat-v0.3",
        "Average":35.56,
        "ARC":35.07,
        "HellaSwag":57.7,
        "MMLU":25.53,
        "TruthfulQA":36.67,
        "Winogrande":57.7,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoderbase",
        "Average":35.55,
        "ARC":30.29,
        "HellaSwag":47.21,
        "MMLU":32.12,
        "TruthfulQA":40.02,
        "Winogrande":55.8,
        "GSM8K":7.88,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":379.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pythainlp\/wangchanglm-7.5B-sft-en-sharded",
        "Average":35.55,
        "ARC":34.47,
        "HellaSwag":59.81,
        "MMLU":26.37,
        "TruthfulQA":34.15,
        "Winogrande":58.25,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.5,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/tau-0.5B-instruct-DPOP",
        "Average":35.54,
        "ARC":28.92,
        "HellaSwag":43.63,
        "MMLU":33.92,
        "TruthfulQA":42.73,
        "Winogrande":57.06,
        "GSM8K":6.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"22h\/open-cabrita3b",
        "Average":35.54,
        "ARC":33.79,
        "HellaSwag":55.35,
        "MMLU":25.16,
        "TruthfulQA":38.5,
        "Winogrande":59.43,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Dans-DiscountModels\/TinyLlama-1.1B-FFT-Test2",
        "Average":35.53,
        "ARC":34.22,
        "HellaSwag":57.96,
        "MMLU":25.54,
        "TruthfulQA":36.32,
        "Winogrande":58.8,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dball\/zephyr-tiny-sft-qlora-quantized-2",
        "Average":35.53,
        "ARC":33.19,
        "HellaSwag":58.58,
        "MMLU":25.21,
        "TruthfulQA":35.82,
        "Winogrande":58.8,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"HuggingFaceH4\/starchat-alpha",
        "Average":35.49,
        "ARC":31.57,
        "HellaSwag":49.43,
        "MMLU":30.76,
        "TruthfulQA":43.66,
        "Winogrande":55.09,
        "GSM8K":2.43,
        "Type":"",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":15.52,
        "Model Sha":228.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h4rz3rk4s3\/TinyPoliticaLlama-1.1B",
        "Average":35.47,
        "ARC":33.79,
        "HellaSwag":57.83,
        "MMLU":25.45,
        "TruthfulQA":38.06,
        "Winogrande":57.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bhenrym14\/airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
        "Average":35.46,
        "ARC":32.0,
        "HellaSwag":53.88,
        "MMLU":31.43,
        "TruthfulQA":38.59,
        "Winogrande":56.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":32.53,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AtAndDev\/ShortKingv0.1",
        "Average":35.45,
        "ARC":34.22,
        "HellaSwag":54.59,
        "MMLU":25.78,
        "TruthfulQA":41.64,
        "Winogrande":56.04,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"habanoz\/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
        "Average":35.45,
        "ARC":31.48,
        "HellaSwag":54.4,
        "MMLU":25.47,
        "TruthfulQA":42.34,
        "Winogrande":57.54,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nnpy\/Nape-0",
        "Average":35.43,
        "ARC":32.68,
        "HellaSwag":58.68,
        "MMLU":24.88,
        "TruthfulQA":38.99,
        "Winogrande":57.3,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lizhuang144\/starcoder_mirror",
        "Average":35.43,
        "ARC":31.31,
        "HellaSwag":45.82,
        "MMLU":29.29,
        "TruthfulQA":43.38,
        "Winogrande":57.22,
        "GSM8K":5.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"habanoz\/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
        "Average":35.42,
        "ARC":31.4,
        "HellaSwag":54.24,
        "MMLU":25.36,
        "TruthfulQA":42.47,
        "Winogrande":57.7,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/SmolLlama-1.5B",
        "Average":35.42,
        "ARC":32.76,
        "HellaSwag":56.74,
        "MMLU":24.53,
        "TruthfulQA":38.08,
        "Winogrande":59.27,
        "GSM8K":1.14,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeff31415\/TinyLlama-1.1B-1.5T-OpenOrca-Alpha",
        "Average":35.39,
        "ARC":32.76,
        "HellaSwag":53.77,
        "MMLU":25.73,
        "TruthfulQA":40.52,
        "Winogrande":58.96,
        "GSM8K":0.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/openchat_v2_openorca_preview-GPTQ",
        "Average":35.38,
        "ARC":27.99,
        "HellaSwag":26.06,
        "MMLU":24.24,
        "TruthfulQA":50.08,
        "Winogrande":70.64,
        "GSM8K":13.27,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/chopt-1_3b",
        "Average":35.32,
        "ARC":31.48,
        "HellaSwag":56.63,
        "MMLU":25.35,
        "TruthfulQA":40.19,
        "Winogrande":58.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-3-2",
        "Average":35.31,
        "ARC":33.28,
        "HellaSwag":49.24,
        "MMLU":27.86,
        "TruthfulQA":40.99,
        "Winogrande":60.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Walter-Llama-1B",
        "Average":35.29,
        "ARC":32.85,
        "HellaSwag":61.05,
        "MMLU":27.46,
        "TruthfulQA":33.93,
        "Winogrande":56.43,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vihangd\/dopeyplats-1.1b-2T-v1",
        "Average":35.28,
        "ARC":33.11,
        "HellaSwag":54.31,
        "MMLU":24.55,
        "TruthfulQA":39.26,
        "Winogrande":58.8,
        "GSM8K":1.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"habanoz\/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
        "Average":35.28,
        "ARC":31.14,
        "HellaSwag":54.31,
        "MMLU":25.42,
        "TruthfulQA":41.72,
        "Winogrande":57.77,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/TinyLlama-3T-Cinder-v1.2",
        "Average":35.26,
        "ARC":34.39,
        "HellaSwag":56.51,
        "MMLU":26.14,
        "TruthfulQA":36.78,
        "Winogrande":57.7,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Average":35.25,
        "ARC":36.01,
        "HellaSwag":59.66,
        "MMLU":24.67,
        "TruthfulQA":32.14,
        "Winogrande":58.33,
        "GSM8K":0.68,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":3.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/platypus-1_8b",
        "Average":35.24,
        "ARC":33.28,
        "HellaSwag":50.76,
        "MMLU":33.25,
        "TruthfulQA":40.73,
        "Winogrande":52.96,
        "GSM8K":0.45,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beberik\/TinyExperts-v0-4x1B",
        "Average":35.23,
        "ARC":31.4,
        "HellaSwag":52.29,
        "MMLU":25.87,
        "TruthfulQA":41.13,
        "Winogrande":60.14,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":2.62,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Deacon-1b",
        "Average":35.21,
        "ARC":32.42,
        "HellaSwag":58.62,
        "MMLU":24.89,
        "TruthfulQA":35.05,
        "Winogrande":59.59,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"facebook\/opt-iml-max-1.3b",
        "Average":35.21,
        "ARC":30.72,
        "HellaSwag":53.81,
        "MMLU":27.61,
        "TruthfulQA":38.34,
        "Winogrande":60.22,
        "GSM8K":0.53,
        "Type":"",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.3,
        "Model Sha":42.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Writer\/palmyra-base",
        "Average":35.18,
        "ARC":31.91,
        "HellaSwag":55.39,
        "MMLU":27.15,
        "TruthfulQA":37.57,
        "Winogrande":58.09,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":40.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/wizard-mega-13B-GPTQ",
        "Average":35.18,
        "ARC":27.73,
        "HellaSwag":26.01,
        "MMLU":24.97,
        "TruthfulQA":48.69,
        "Winogrande":74.74,
        "GSM8K":8.95,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":107.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-1.3B",
        "Average":35.16,
        "ARC":31.14,
        "HellaSwag":58.39,
        "MMLU":24.98,
        "TruthfulQA":37.43,
        "Winogrande":59.04,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":1.41,
        "Model Sha":6.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/chronos-wizardlm-uc-scot-st-13B-GPTQ",
        "Average":35.15,
        "ARC":27.99,
        "HellaSwag":26.1,
        "MMLU":25.72,
        "TruthfulQA":49.68,
        "Winogrande":74.51,
        "GSM8K":6.9,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":16.22,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Corianas\/DPO-miniguanaco-1.5T",
        "Average":35.13,
        "ARC":30.63,
        "HellaSwag":54.05,
        "MMLU":24.79,
        "TruthfulQA":42.69,
        "Winogrande":58.64,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/TinyWand-DPO",
        "Average":35.13,
        "ARC":31.66,
        "HellaSwag":50.42,
        "MMLU":26.22,
        "TruthfulQA":45.8,
        "Winogrande":54.78,
        "GSM8K":1.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.63,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beaugogh\/pythia-1.4b-deduped-sharegpt",
        "Average":35.11,
        "ARC":34.3,
        "HellaSwag":54.49,
        "MMLU":24.0,
        "TruthfulQA":41.81,
        "Winogrande":55.25,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HWERI\/pythia-1.4b-deduped-sharegpt",
        "Average":35.11,
        "ARC":34.3,
        "HellaSwag":54.49,
        "MMLU":24.0,
        "TruthfulQA":41.81,
        "Winogrande":55.25,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.42,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pythainlp\/wangchanglm-7.5B-sft-enth",
        "Average":35.11,
        "ARC":33.79,
        "HellaSwag":58.99,
        "MMLU":24.52,
        "TruthfulQA":34.9,
        "Winogrande":57.93,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.5,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/metharme-1.3b",
        "Average":35.04,
        "ARC":34.39,
        "HellaSwag":55.94,
        "MMLU":25.07,
        "TruthfulQA":37.68,
        "Winogrande":56.43,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.52,
        "Model Sha":21.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/falcon-1b-t-sft",
        "Average":35.02,
        "ARC":32.94,
        "HellaSwag":57.24,
        "MMLU":25.26,
        "TruthfulQA":38.49,
        "Winogrande":55.88,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"L-R\/LLmRa-1.3B",
        "Average":35.0,
        "ARC":32.68,
        "HellaSwag":58.77,
        "MMLU":23.23,
        "TruthfulQA":36.21,
        "Winogrande":59.04,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Average":35.0,
        "ARC":32.68,
        "HellaSwag":54.96,
        "MMLU":25.56,
        "TruthfulQA":38.66,
        "Winogrande":57.3,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.4,
        "Model Sha":19.0
    },
    {
        "T":"?",
        "Model":"habanoz\/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
        "Average":34.98,
        "ARC":30.72,
        "HellaSwag":54.32,
        "MMLU":24.78,
        "TruthfulQA":41.67,
        "Winogrande":57.62,
        "GSM8K":0.76,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h4rz3rk4s3\/TinyParlaMintLlama-1.1B",
        "Average":34.97,
        "ARC":31.66,
        "HellaSwag":55.87,
        "MMLU":24.84,
        "TruthfulQA":38.81,
        "Winogrande":58.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/falcon_1b_stage3",
        "Average":34.95,
        "ARC":33.11,
        "HellaSwag":54.08,
        "MMLU":25.11,
        "TruthfulQA":37.92,
        "Winogrande":59.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/cosmo-3b-test",
        "Average":34.94,
        "ARC":35.32,
        "HellaSwag":52.36,
        "MMLU":27.25,
        "TruthfulQA":39.02,
        "Winogrande":54.3,
        "GSM8K":1.36,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.95,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TinyLlama\/TinyLlama-1.1B-Chat-v0.6",
        "Average":34.94,
        "ARC":31.66,
        "HellaSwag":55.79,
        "MMLU":25.98,
        "TruthfulQA":34.72,
        "Winogrande":59.35,
        "GSM8K":2.12,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":67.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Deathsquad10\/TinyLlama-1.1B-Remix-V.2",
        "Average":34.91,
        "ARC":33.19,
        "HellaSwag":56.62,
        "MMLU":25.99,
        "TruthfulQA":34.64,
        "Winogrande":58.09,
        "GSM8K":0.91,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OpenAssistant\/stablelm-7b-sft-v7-epoch-3",
        "Average":34.85,
        "ARC":36.01,
        "HellaSwag":55.81,
        "MMLU":25.01,
        "TruthfulQA":37.02,
        "Winogrande":54.85,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":7.0,
        "Model Sha":66.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Jiayi-Pan\/Tiny-Vicuna-1B",
        "Average":34.76,
        "ARC":33.45,
        "HellaSwag":55.92,
        "MMLU":25.45,
        "TruthfulQA":33.82,
        "Winogrande":58.41,
        "GSM8K":1.52,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"w95\/megachat",
        "Average":34.75,
        "ARC":30.8,
        "HellaSwag":54.35,
        "MMLU":25.55,
        "TruthfulQA":39.85,
        "Winogrande":56.99,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"tyson0420\/mixtral_stack_llama",
        "Average":34.74,
        "ARC":34.56,
        "HellaSwag":50.24,
        "MMLU":27.97,
        "TruthfulQA":38.22,
        "Winogrande":57.3,
        "GSM8K":0.15,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/lamini-neo-1.3b",
        "Average":34.73,
        "ARC":32.76,
        "HellaSwag":49.13,
        "MMLU":28.79,
        "TruthfulQA":41.05,
        "Winogrande":56.51,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"frankenmerger\/cosmo-3b-test-v0.2",
        "Average":34.7,
        "ARC":35.32,
        "HellaSwag":51.7,
        "MMLU":27.33,
        "TruthfulQA":38.82,
        "Winogrande":53.51,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.95,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"OEvortex\/HelpingAI-Lite-1.5T",
        "Average":34.68,
        "ARC":31.23,
        "HellaSwag":52.39,
        "MMLU":25.93,
        "TruthfulQA":38.61,
        "Winogrande":58.33,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nnheui\/pythia-1.4b-sft-full",
        "Average":34.68,
        "ARC":32.68,
        "HellaSwag":52.08,
        "MMLU":25.44,
        "TruthfulQA":38.42,
        "Winogrande":57.46,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/LaMini-GPT-1.5B",
        "Average":34.67,
        "ARC":31.4,
        "HellaSwag":48.38,
        "MMLU":29.92,
        "TruthfulQA":42.47,
        "Winogrande":55.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.5,
        "Model Sha":35.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt1.3b_10e4",
        "Average":34.67,
        "ARC":30.55,
        "HellaSwag":53.52,
        "MMLU":26.89,
        "TruthfulQA":38.67,
        "Winogrande":58.41,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardCoder-15B-V1.0",
        "Average":34.64,
        "ARC":32.34,
        "HellaSwag":47.2,
        "MMLU":29.43,
        "TruthfulQA":41.56,
        "Winogrande":55.17,
        "GSM8K":2.12,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-openrail-m",
        "Available on the Hub":15.0,
        "Model Sha":726.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bn22\/tinyllama_frankenmerge",
        "Average":34.64,
        "ARC":30.2,
        "HellaSwag":51.01,
        "MMLU":26.11,
        "TruthfulQA":40.18,
        "Winogrande":58.72,
        "GSM8K":1.59,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"maywell\/TinyWand-SFT",
        "Average":34.61,
        "ARC":31.4,
        "HellaSwag":49.96,
        "MMLU":25.98,
        "TruthfulQA":43.08,
        "Winogrande":55.17,
        "GSM8K":2.05,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.63,
        "Model Sha":5.0
    },
    {
        "T":"?",
        "Model":"facebook\/opt-1.3b",
        "Average":34.6,
        "ARC":29.52,
        "HellaSwag":54.53,
        "MMLU":24.96,
        "TruthfulQA":38.71,
        "Winogrande":59.75,
        "GSM8K":0.15,
        "Type":"",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.3,
        "Model Sha":137.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0x7194633\/fialka-13B-v3",
        "Average":34.58,
        "ARC":30.97,
        "HellaSwag":48.83,
        "MMLU":26.36,
        "TruthfulQA":40.58,
        "Winogrande":59.43,
        "GSM8K":1.29,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"jeff31415\/TinyLlama-1.1B-1T-OpenOrca",
        "Average":34.58,
        "ARC":31.31,
        "HellaSwag":52.34,
        "MMLU":25.31,
        "TruthfulQA":38.58,
        "Winogrande":58.25,
        "GSM8K":1.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PY007\/TinyLlama-1.1B-Chat-v0.1",
        "Average":34.57,
        "ARC":32.0,
        "HellaSwag":54.21,
        "MMLU":26.71,
        "TruthfulQA":39.03,
        "Winogrande":54.93,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-955k-token-2T",
        "Average":34.56,
        "ARC":30.29,
        "HellaSwag":54.84,
        "MMLU":26.47,
        "TruthfulQA":36.07,
        "Winogrande":58.33,
        "GSM8K":1.36,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":28.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"jylee420\/gemma-2b-data-std",
        "Average":34.55,
        "ARC":37.54,
        "HellaSwag":32.49,
        "MMLU":35.82,
        "TruthfulQA":39.56,
        "Winogrande":61.72,
        "GSM8K":0.15,
        "Type":"continuously pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b-instruct",
        "Average":34.54,
        "ARC":30.97,
        "HellaSwag":51.42,
        "MMLU":26.17,
        "TruthfulQA":40.31,
        "Winogrande":56.75,
        "GSM8K":1.59,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.44,
        "Model Sha":3.0
    },
    {
        "T":"?",
        "Model":"habanoz\/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
        "Average":34.53,
        "ARC":31.06,
        "HellaSwag":55.02,
        "MMLU":26.41,
        "TruthfulQA":35.08,
        "Winogrande":58.01,
        "GSM8K":1.59,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bhenrym14\/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
        "Average":34.53,
        "ARC":25.34,
        "HellaSwag":26.66,
        "MMLU":23.36,
        "TruthfulQA":49.51,
        "Winogrande":73.72,
        "GSM8K":8.57,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":32.53,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/tinyllama-1.1b-chat-v0.3_platypus",
        "Average":34.5,
        "ARC":30.29,
        "HellaSwag":55.12,
        "MMLU":26.13,
        "TruthfulQA":39.15,
        "Winogrande":55.8,
        "GSM8K":0.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-1.3b",
        "Average":34.46,
        "ARC":31.14,
        "HellaSwag":51.43,
        "MMLU":26.55,
        "TruthfulQA":39.24,
        "Winogrande":57.38,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"NYTK\/PULI-GPTrio",
        "Average":34.42,
        "ARC":30.72,
        "HellaSwag":53.49,
        "MMLU":24.73,
        "TruthfulQA":39.03,
        "Winogrande":57.77,
        "GSM8K":0.76,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":10.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"ToastyPigeon\/SmolLlama-1.5B-Sorted",
        "Average":34.39,
        "ARC":31.91,
        "HellaSwag":56.39,
        "MMLU":24.48,
        "TruthfulQA":32.11,
        "Winogrande":60.85,
        "GSM8K":0.61,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gpt2-xl",
        "Average":34.38,
        "ARC":30.29,
        "HellaSwag":51.36,
        "MMLU":26.54,
        "TruthfulQA":38.54,
        "Winogrande":58.25,
        "GSM8K":1.29,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Average":34.37,
        "ARC":30.89,
        "HellaSwag":52.97,
        "MMLU":25.0,
        "TruthfulQA":39.55,
        "Winogrande":57.3,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/EverythingLM-13B-16K-GPTQ",
        "Average":34.37,
        "ARC":29.27,
        "HellaSwag":26.24,
        "MMLU":25.4,
        "TruthfulQA":48.58,
        "Winogrande":71.35,
        "GSM8K":5.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":16.23,
        "Model Sha":13.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Average":34.37,
        "ARC":32.0,
        "HellaSwag":51.78,
        "MMLU":26.21,
        "TruthfulQA":40.19,
        "Winogrande":55.41,
        "GSM8K":0.61,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":210.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"h2oai\/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
        "Average":34.32,
        "ARC":34.04,
        "HellaSwag":50.51,
        "MMLU":24.66,
        "TruthfulQA":41.8,
        "Winogrande":54.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/xglm-4.5B",
        "Average":34.31,
        "ARC":31.48,
        "HellaSwag":57.95,
        "MMLU":25.43,
        "TruthfulQA":35.84,
        "Winogrande":54.93,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":5.08,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Average":34.31,
        "ARC":30.38,
        "HellaSwag":50.4,
        "MMLU":26.14,
        "TruthfulQA":39.97,
        "Winogrande":58.88,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.44,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"winglian\/llama-2-4b",
        "Average":34.23,
        "ARC":31.23,
        "HellaSwag":53.29,
        "MMLU":24.22,
        "TruthfulQA":38.72,
        "Winogrande":57.46,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":4.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"L-R\/LLmRa-1.3B_V2",
        "Average":34.21,
        "ARC":30.46,
        "HellaSwag":53.03,
        "MMLU":26.06,
        "TruthfulQA":36.46,
        "Winogrande":59.27,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v2-1_5b",
        "Average":34.2,
        "ARC":32.59,
        "HellaSwag":53.98,
        "MMLU":24.93,
        "TruthfulQA":38.77,
        "Winogrande":54.7,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":5.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LoupGarou\/WizardCoder-Guanaco-15B-V1.1",
        "Average":34.19,
        "ARC":32.59,
        "HellaSwag":45.42,
        "MMLU":25.88,
        "TruthfulQA":42.33,
        "Winogrande":56.04,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "apache-2.0"
        ],
        "Available on the Hub":15.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/orpo-phi2",
        "Average":34.19,
        "ARC":31.23,
        "HellaSwag":41.52,
        "MMLU":28.9,
        "TruthfulQA":47.62,
        "Winogrande":55.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0x7194633\/fialka-13B-v4",
        "Average":34.18,
        "ARC":29.69,
        "HellaSwag":47.37,
        "MMLU":25.09,
        "TruthfulQA":43.65,
        "Winogrande":58.88,
        "GSM8K":0.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"GeorgiaTechResearchInstitute\/starcoder-gpteacher-code-instruct",
        "Average":34.15,
        "ARC":32.68,
        "HellaSwag":47.6,
        "MMLU":28.63,
        "TruthfulQA":40.41,
        "Winogrande":55.56,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":77.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2-xl_lima",
        "Average":34.12,
        "ARC":31.14,
        "HellaSwag":51.28,
        "MMLU":25.43,
        "TruthfulQA":38.74,
        "Winogrande":57.22,
        "GSM8K":0.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.56,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0x7194633\/fialka-13B-v3.1",
        "Average":34.11,
        "ARC":29.95,
        "HellaSwag":47.28,
        "MMLU":25.41,
        "TruthfulQA":43.03,
        "Winogrande":58.48,
        "GSM8K":0.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FINGU-AI\/FinguAI-Chat-v1",
        "Average":34.09,
        "ARC":29.18,
        "HellaSwag":44.08,
        "MMLU":30.39,
        "TruthfulQA":42.79,
        "Winogrande":56.59,
        "GSM8K":1.52,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.46,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/Walter-Falcon-1B",
        "Average":34.07,
        "ARC":31.06,
        "HellaSwag":54.92,
        "MMLU":24.58,
        "TruthfulQA":38.47,
        "Winogrande":55.41,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"habanoz\/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
        "Average":34.04,
        "ARC":30.55,
        "HellaSwag":53.7,
        "MMLU":26.07,
        "TruthfulQA":35.85,
        "Winogrande":58.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/stablelm-tuned-alpha-7b",
        "Average":34.04,
        "ARC":31.91,
        "HellaSwag":53.59,
        "MMLU":24.41,
        "TruthfulQA":40.37,
        "Winogrande":53.12,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":358.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/TinyLlama-3T-Cinder-v1.1",
        "Average":34.03,
        "ARC":34.04,
        "HellaSwag":50.4,
        "MMLU":25.75,
        "TruthfulQA":37.57,
        "Winogrande":56.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Deathsquad10\/TinyLlama-Remix",
        "Average":34.0,
        "ARC":31.14,
        "HellaSwag":49.5,
        "MMLU":27.34,
        "TruthfulQA":40.53,
        "Winogrande":55.41,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"croissantllm\/CroissantLLMBase",
        "Average":33.99,
        "ARC":30.63,
        "HellaSwag":54.18,
        "MMLU":25.72,
        "TruthfulQA":37.39,
        "Winogrande":55.41,
        "GSM8K":0.61,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"jzjiao\/opt-1.3b-rlhf",
        "Average":33.99,
        "ARC":28.92,
        "HellaSwag":52.77,
        "MMLU":25.39,
        "TruthfulQA":37.44,
        "Winogrande":58.96,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloom-1b7",
        "Average":33.98,
        "ARC":30.63,
        "HellaSwag":47.6,
        "MMLU":27.48,
        "TruthfulQA":41.31,
        "Winogrande":56.04,
        "GSM8K":0.83,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":1.72,
        "Model Sha":106.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-2.7b",
        "Average":33.98,
        "ARC":32.76,
        "HellaSwag":54.13,
        "MMLU":23.28,
        "TruthfulQA":37.17,
        "Winogrande":56.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"creativeml-openrail-m",
        "Available on the Hub":2.7,
        "Model Sha":52.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LoupGarou\/WizardCoder-Guanaco-15B-V1.0",
        "Average":33.96,
        "ARC":30.46,
        "HellaSwag":45.59,
        "MMLU":26.79,
        "TruthfulQA":46.39,
        "Winogrande":53.12,
        "GSM8K":1.44,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "apache-2.0"
        ],
        "Available on the Hub":15.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt-3b-bloom",
        "Average":33.96,
        "ARC":31.91,
        "HellaSwag":50.32,
        "MMLU":25.2,
        "TruthfulQA":41.79,
        "Winogrande":54.38,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.0,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt-2-xl_camel-ai-physics",
        "Average":33.96,
        "ARC":29.52,
        "HellaSwag":50.62,
        "MMLU":26.79,
        "TruthfulQA":39.12,
        "Winogrande":57.54,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.56,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt1.3b_10e5",
        "Average":33.8,
        "ARC":29.52,
        "HellaSwag":52.81,
        "MMLU":25.61,
        "TruthfulQA":38.18,
        "Winogrande":56.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
        "Average":33.78,
        "ARC":28.41,
        "HellaSwag":26.05,
        "MMLU":24.71,
        "TruthfulQA":49.54,
        "Winogrande":68.67,
        "GSM8K":5.31,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":35.58,
        "Model Sha":80.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoderbase-7b",
        "Average":33.75,
        "ARC":29.86,
        "HellaSwag":43.87,
        "MMLU":28.45,
        "TruthfulQA":40.46,
        "Winogrande":54.38,
        "GSM8K":5.46,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":7.0,
        "Model Sha":30.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Average":33.72,
        "ARC":29.27,
        "HellaSwag":49.71,
        "MMLU":26.26,
        "TruthfulQA":40.17,
        "Winogrande":56.59,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Average":33.58,
        "ARC":31.23,
        "HellaSwag":48.47,
        "MMLU":24.82,
        "TruthfulQA":39.63,
        "Winogrande":56.91,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.37,
        "Model Sha":231.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_opt1.3b_10e5",
        "Average":33.57,
        "ARC":29.44,
        "HellaSwag":51.7,
        "MMLU":25.38,
        "TruthfulQA":36.87,
        "Winogrande":58.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"RWKV\/rwkv-raven-1b5",
        "Average":33.56,
        "ARC":31.83,
        "HellaSwag":52.6,
        "MMLU":25.96,
        "TruthfulQA":37.09,
        "Winogrande":53.91,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":1.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lxe\/Cerebras-GPT-2.7B-Alpaca-SP",
        "Average":33.5,
        "ARC":30.8,
        "HellaSwag":48.88,
        "MMLU":25.12,
        "TruthfulQA":40.24,
        "Winogrande":55.41,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"postbot\/gpt-neo-1.3B-emailgen",
        "Average":33.47,
        "ARC":29.95,
        "HellaSwag":47.95,
        "MMLU":24.11,
        "TruthfulQA":42.55,
        "Winogrande":56.27,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/TinyLlama-3T-Cinder-v1",
        "Average":33.47,
        "ARC":33.53,
        "HellaSwag":46.36,
        "MMLU":26.03,
        "TruthfulQA":38.32,
        "Winogrande":56.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"sail\/Sailor-0.5B-Chat",
        "Average":33.47,
        "ARC":30.38,
        "HellaSwag":45.51,
        "MMLU":26.73,
        "TruthfulQA":39.85,
        "Winogrande":56.51,
        "GSM8K":1.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.62,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BEE-spoke-data\/TinyLlama-1.1bee",
        "Average":33.38,
        "ARC":30.55,
        "HellaSwag":51.8,
        "MMLU":24.25,
        "TruthfulQA":39.01,
        "Winogrande":54.46,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"l3utterfly\/llama2-3b-distilled-layla-v1",
        "Average":33.36,
        "ARC":30.46,
        "HellaSwag":46.05,
        "MMLU":23.91,
        "TruthfulQA":42.14,
        "Winogrande":57.38,
        "GSM8K":0.23,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":3.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v1-1_5b",
        "Average":33.35,
        "ARC":31.66,
        "HellaSwag":49.69,
        "MMLU":25.62,
        "TruthfulQA":37.08,
        "Winogrande":55.96,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":5.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Average":33.33,
        "ARC":27.05,
        "HellaSwag":51.68,
        "MMLU":26.64,
        "TruthfulQA":34.69,
        "Winogrande":59.75,
        "GSM8K":0.15,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.06,
        "Model Sha":77.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MrNJK\/gpt2-xl-sft",
        "Average":33.31,
        "ARC":30.03,
        "HellaSwag":49.17,
        "MMLU":25.56,
        "TruthfulQA":38.78,
        "Winogrande":55.56,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/Quokka_2.7b",
        "Average":33.26,
        "ARC":31.06,
        "HellaSwag":47.72,
        "MMLU":24.8,
        "TruthfulQA":40.14,
        "Winogrande":55.49,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.79,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Average":33.25,
        "ARC":29.1,
        "HellaSwag":49.29,
        "MMLU":25.17,
        "TruthfulQA":41.37,
        "Winogrande":54.14,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.7,
        "Model Sha":41.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Average":33.25,
        "ARC":31.83,
        "HellaSwag":52.25,
        "MMLU":25.77,
        "TruthfulQA":35.8,
        "Winogrande":53.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":1.0,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RaoFoundation\/774M-03_09_2024",
        "Average":33.22,
        "ARC":30.29,
        "HellaSwag":53.88,
        "MMLU":25.33,
        "TruthfulQA":34.44,
        "Winogrande":55.09,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shaohang\/Sparse0.5_OPT-1.3",
        "Average":33.19,
        "ARC":27.13,
        "HellaSwag":48.69,
        "MMLU":25.6,
        "TruthfulQA":39.11,
        "Winogrande":58.56,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"shaohang\/SparseOPT-1.3B",
        "Average":33.19,
        "ARC":27.13,
        "HellaSwag":48.69,
        "MMLU":25.6,
        "TruthfulQA":39.11,
        "Winogrande":58.56,
        "GSM8K":0.08,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/Qwenchana-0.5B-restart",
        "Average":33.15,
        "ARC":30.03,
        "HellaSwag":45.95,
        "MMLU":25.61,
        "TruthfulQA":40.48,
        "Winogrande":54.85,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.62,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"gmonsoon\/Qwenchana-0.5B-restart",
        "Average":33.1,
        "ARC":30.46,
        "HellaSwag":45.89,
        "MMLU":25.39,
        "TruthfulQA":40.48,
        "Winogrande":54.62,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.62,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"sail\/Sailor-0.5B",
        "Average":33.05,
        "ARC":29.69,
        "HellaSwag":45.82,
        "MMLU":25.62,
        "TruthfulQA":40.76,
        "Winogrande":55.33,
        "GSM8K":1.06,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.62,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"sail\/Sailor-0.5B",
        "Average":33.03,
        "ARC":29.69,
        "HellaSwag":45.82,
        "MMLU":25.13,
        "TruthfulQA":40.74,
        "Winogrande":55.56,
        "GSM8K":1.21,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.62,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"health360\/Healix-1.1B-V1-Chat-dDPO",
        "Average":33.0,
        "ARC":30.55,
        "HellaSwag":44.78,
        "MMLU":24.64,
        "TruthfulQA":41.55,
        "Winogrande":56.51,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aryanne\/TinyllamaMix-1.1B",
        "Average":32.99,
        "ARC":31.48,
        "HellaSwag":48.39,
        "MMLU":25.05,
        "TruthfulQA":33.45,
        "Winogrande":58.48,
        "GSM8K":1.06,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Average":32.95,
        "ARC":24.66,
        "HellaSwag":46.76,
        "MMLU":23.49,
        "TruthfulQA":44.47,
        "Winogrande":58.01,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"BloomModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kalisai\/Nusantara-0.8b-Indo-Chat",
        "Average":32.93,
        "ARC":30.38,
        "HellaSwag":44.61,
        "MMLU":26.89,
        "TruthfulQA":39.54,
        "Winogrande":54.7,
        "GSM8K":1.44,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.82,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v2-774m",
        "Average":32.86,
        "ARC":30.12,
        "HellaSwag":47.68,
        "MMLU":25.37,
        "TruthfulQA":40.0,
        "Winogrande":53.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DatPySci\/pythia-1b-spin-iter1",
        "Average":32.85,
        "ARC":30.55,
        "HellaSwag":49.26,
        "MMLU":24.46,
        "TruthfulQA":36.89,
        "Winogrande":53.59,
        "GSM8K":2.35,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DatPySci\/pythia-1b-sft-50k",
        "Average":32.85,
        "ARC":30.29,
        "HellaSwag":49.21,
        "MMLU":24.64,
        "TruthfulQA":37.07,
        "Winogrande":53.99,
        "GSM8K":1.9,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fhai50032\/Mistral-4B-FT-2",
        "Average":32.81,
        "ARC":25.94,
        "HellaSwag":39.63,
        "MMLU":25.46,
        "TruthfulQA":46.33,
        "Winogrande":56.59,
        "GSM8K":2.88,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.75,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Average":32.78,
        "ARC":29.1,
        "HellaSwag":49.65,
        "MMLU":24.27,
        "TruthfulQA":38.94,
        "Winogrande":53.59,
        "GSM8K":1.14,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.08,
        "Model Sha":15.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DatPySci\/pythia-1b-dpo",
        "Average":32.76,
        "ARC":30.12,
        "HellaSwag":49.24,
        "MMLU":24.24,
        "TruthfulQA":37.2,
        "Winogrande":54.06,
        "GSM8K":1.67,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"wandb\/pruned_mistral",
        "Average":32.74,
        "ARC":28.33,
        "HellaSwag":46.35,
        "MMLU":26.62,
        "TruthfulQA":41.09,
        "Winogrande":53.91,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.88,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
        "Average":32.68,
        "ARC":30.63,
        "HellaSwag":52.63,
        "MMLU":25.04,
        "TruthfulQA":34.96,
        "Winogrande":52.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.41,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DatPySci\/pythia-1b-sft-50k",
        "Average":32.66,
        "ARC":30.03,
        "HellaSwag":49.1,
        "MMLU":24.03,
        "TruthfulQA":37.01,
        "Winogrande":54.06,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"w601sxs\/b1ade-1b",
        "Average":32.59,
        "ARC":28.58,
        "HellaSwag":46.08,
        "MMLU":25.11,
        "TruthfulQA":41.34,
        "Winogrande":53.83,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TFLai\/gpt-neo-1.3B-4bit-alpaca",
        "Average":32.58,
        "ARC":28.24,
        "HellaSwag":46.35,
        "MMLU":25.19,
        "TruthfulQA":39.26,
        "Winogrande":56.2,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":1.3,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"DatPySci\/pythia-1b-dpo-full",
        "Average":32.55,
        "ARC":29.44,
        "HellaSwag":49.03,
        "MMLU":24.13,
        "TruthfulQA":37.27,
        "Winogrande":53.43,
        "GSM8K":1.97,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DatPySci\/pythia-1b-sft-full",
        "Average":32.52,
        "ARC":29.52,
        "HellaSwag":48.91,
        "MMLU":23.95,
        "TruthfulQA":37.08,
        "Winogrande":53.67,
        "GSM8K":1.97,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_spin_gpt2_e1_se0",
        "Average":32.5,
        "ARC":27.99,
        "HellaSwag":45.74,
        "MMLU":26.68,
        "TruthfulQA":39.06,
        "Winogrande":55.56,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DatPySci\/pythia-1b-self-kto-iter0",
        "Average":32.5,
        "ARC":30.2,
        "HellaSwag":49.06,
        "MMLU":24.11,
        "TruthfulQA":36.35,
        "Winogrande":53.43,
        "GSM8K":1.82,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloom-1b1",
        "Average":32.47,
        "ARC":28.33,
        "HellaSwag":42.78,
        "MMLU":26.7,
        "TruthfulQA":41.8,
        "Winogrande":55.01,
        "GSM8K":0.23,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":1.06,
        "Model Sha":53.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rinna\/bilingual-gpt-neox-4b-instruction-sft",
        "Average":32.46,
        "ARC":28.07,
        "HellaSwag":47.5,
        "MMLU":23.12,
        "TruthfulQA":43.76,
        "Winogrande":52.33,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.8,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_spin_tuned_gpt2_large",
        "Average":32.46,
        "ARC":27.9,
        "HellaSwag":45.12,
        "MMLU":27.08,
        "TruthfulQA":39.43,
        "Winogrande":54.62,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Average":32.44,
        "ARC":29.27,
        "HellaSwag":46.29,
        "MMLU":25.25,
        "TruthfulQA":40.49,
        "Winogrande":52.8,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"MBZUAI\/LaMini-GPT-774M",
        "Average":32.43,
        "ARC":27.65,
        "HellaSwag":43.81,
        "MMLU":26.3,
        "TruthfulQA":40.26,
        "Winogrande":56.59,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.77,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Salesforce\/codegen-6B-multi",
        "Average":32.43,
        "ARC":27.22,
        "HellaSwag":41.11,
        "MMLU":25.71,
        "TruthfulQA":45.65,
        "Winogrande":53.91,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"CodeGenForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bsd-3-clause",
        "Available on the Hub":6.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"DatPySci\/pythia-1b-kto-iter0",
        "Average":32.43,
        "ARC":30.12,
        "HellaSwag":48.95,
        "MMLU":24.39,
        "TruthfulQA":36.4,
        "Winogrande":53.12,
        "GSM8K":1.59,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.01,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"FabbriSimo01\/Bloom_1b_Quantized",
        "Average":32.41,
        "ARC":27.73,
        "HellaSwag":42.83,
        "MMLU":26.28,
        "TruthfulQA":41.82,
        "Winogrande":55.64,
        "GSM8K":0.15,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"deepseek-ai\/deepseek-coder-1.3b-instruct",
        "Average":32.4,
        "ARC":28.58,
        "HellaSwag":39.87,
        "MMLU":28.47,
        "TruthfulQA":44.02,
        "Winogrande":52.41,
        "GSM8K":1.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.3,
        "Model Sha":73.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_spin_gpt2_e0_se1",
        "Average":32.4,
        "ARC":27.99,
        "HellaSwag":45.84,
        "MMLU":26.44,
        "TruthfulQA":38.88,
        "Winogrande":55.17,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_refine_gpt2_e0_se1",
        "Average":32.39,
        "ARC":29.18,
        "HellaSwag":45.35,
        "MMLU":26.91,
        "TruthfulQA":37.89,
        "Winogrande":54.3,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/gpt2-large-conversational",
        "Average":32.33,
        "ARC":26.96,
        "HellaSwag":44.98,
        "MMLU":26.33,
        "TruthfulQA":39.6,
        "Winogrande":56.04,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":0.77,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"xaviviro\/FLOR-1.3B-xat",
        "Average":32.27,
        "ARC":26.79,
        "HellaSwag":41.63,
        "MMLU":26.65,
        "TruthfulQA":44.38,
        "Winogrande":53.43,
        "GSM8K":0.76,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Average":32.23,
        "ARC":28.58,
        "HellaSwag":43.94,
        "MMLU":25.38,
        "TruthfulQA":47.48,
        "Winogrande":47.99,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.95,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Rachneet\/gpt2-xl-alpaca",
        "Average":32.21,
        "ARC":26.79,
        "HellaSwag":43.85,
        "MMLU":26.31,
        "TruthfulQA":39.4,
        "Winogrande":56.91,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":1.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Devio\/test-3b",
        "Average":32.2,
        "ARC":27.65,
        "HellaSwag":44.79,
        "MMLU":23.53,
        "TruthfulQA":41.42,
        "Winogrande":55.49,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":3.5,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_refine_tuned_gpt2_large",
        "Average":32.19,
        "ARC":27.56,
        "HellaSwag":45.09,
        "MMLU":26.91,
        "TruthfulQA":37.91,
        "Winogrande":54.93,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"daekeun-ml\/phi-2-ko-v0.1",
        "Average":32.16,
        "ARC":30.72,
        "HellaSwag":37.26,
        "MMLU":27.34,
        "TruthfulQA":43.64,
        "Winogrande":52.72,
        "GSM8K":1.29,
        "Type":"continuously pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-3.0",
        "Available on the Hub":2.86,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Average":32.14,
        "ARC":29.18,
        "HellaSwag":43.73,
        "MMLU":23.1,
        "TruthfulQA":45.0,
        "Winogrande":51.85,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.95,
        "Model Sha":26.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"stabilityai\/stablelm-tuned-alpha-3b",
        "Average":32.14,
        "ARC":27.82,
        "HellaSwag":44.06,
        "MMLU":23.08,
        "TruthfulQA":42.33,
        "Winogrande":55.01,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "cc-by-nc-sa-4.0"
        ],
        "Available on the Hub":3.0,
        "Model Sha":112.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mohammed-Altaf\/Medical-ChatBot",
        "Average":32.13,
        "ARC":30.55,
        "HellaSwag":38.63,
        "MMLU":25.98,
        "TruthfulQA":41.25,
        "Winogrande":55.41,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openai-community\/gpt2-large",
        "Average":32.07,
        "ARC":25.77,
        "HellaSwag":45.62,
        "MMLU":26.07,
        "TruthfulQA":38.72,
        "Winogrande":55.41,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.81,
        "Model Sha":214.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca_refine_gpt2_e1_se0",
        "Average":32.06,
        "ARC":27.3,
        "HellaSwag":45.39,
        "MMLU":26.51,
        "TruthfulQA":37.28,
        "Winogrande":55.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/Alpaca-tuned-gpt2",
        "Average":32.02,
        "ARC":26.54,
        "HellaSwag":44.79,
        "MMLU":27.22,
        "TruthfulQA":37.65,
        "Winogrande":55.09,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mohammed-Altaf\/Medical-ChatBot",
        "Average":31.98,
        "ARC":30.46,
        "HellaSwag":38.6,
        "MMLU":25.96,
        "TruthfulQA":41.04,
        "Winogrande":54.85,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/SSH_355M",
        "Average":31.92,
        "ARC":26.96,
        "HellaSwag":38.98,
        "MMLU":27.59,
        "TruthfulQA":44.15,
        "Winogrande":53.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mohammed-Altaf\/Medical-ChatBot",
        "Average":31.87,
        "ARC":30.46,
        "HellaSwag":38.55,
        "MMLU":25.91,
        "TruthfulQA":41.02,
        "Winogrande":54.22,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hyunjae\/polyglot-ko-3.8b-total",
        "Average":31.87,
        "ARC":25.34,
        "HellaSwag":39.69,
        "MMLU":29.16,
        "TruthfulQA":43.67,
        "Winogrande":53.35,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Average":31.86,
        "ARC":25.85,
        "HellaSwag":44.1,
        "MMLU":26.78,
        "TruthfulQA":39.51,
        "Winogrande":54.38,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-1.3b-chat-and-function-calling",
        "Average":31.82,
        "ARC":26.28,
        "HellaSwag":39.27,
        "MMLU":26.92,
        "TruthfulQA":43.37,
        "Winogrande":51.7,
        "GSM8K":3.41,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikivis\/gpt2-large-lora-sft",
        "Average":31.82,
        "ARC":26.79,
        "HellaSwag":44.15,
        "MMLU":25.82,
        "TruthfulQA":39.06,
        "Winogrande":55.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.77,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"YeungNLP\/firefly-bloom-2b6-v2",
        "Average":31.82,
        "ARC":27.65,
        "HellaSwag":39.23,
        "MMLU":25.24,
        "TruthfulQA":42.27,
        "Winogrande":54.78,
        "GSM8K":1.74,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":2.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/Instruct_GPT_v1",
        "Average":31.77,
        "ARC":28.07,
        "HellaSwag":38.98,
        "MMLU":26.55,
        "TruthfulQA":42.22,
        "Winogrande":54.06,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-jp\/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
        "Average":31.77,
        "ARC":26.88,
        "HellaSwag":44.78,
        "MMLU":23.12,
        "TruthfulQA":45.19,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/SSH_300M",
        "Average":31.75,
        "ARC":28.24,
        "HellaSwag":38.74,
        "MMLU":27.03,
        "TruthfulQA":42.51,
        "Winogrande":53.67,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-1.3b-chat",
        "Average":31.74,
        "ARC":25.85,
        "HellaSwag":39.59,
        "MMLU":26.36,
        "TruthfulQA":43.92,
        "Winogrande":51.7,
        "GSM8K":3.03,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.35,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/orca_mini_13B-GPTQ",
        "Average":31.73,
        "ARC":27.3,
        "HellaSwag":25.85,
        "MMLU":25.31,
        "TruthfulQA":48.06,
        "Winogrande":63.77,
        "GSM8K":0.08,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":16.22,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/spin_gpt2_medium_alpaca_e2",
        "Average":31.71,
        "ARC":28.07,
        "HellaSwag":39.88,
        "MMLU":26.99,
        "TruthfulQA":41.52,
        "Winogrande":53.67,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt1.3b_10e6",
        "Average":31.7,
        "ARC":25.77,
        "HellaSwag":41.67,
        "MMLU":25.9,
        "TruthfulQA":42.72,
        "Winogrande":54.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"llm-jp\/llm-jp-13b-instruct-full-jaster-v1.0",
        "Average":31.63,
        "ARC":27.22,
        "HellaSwag":44.7,
        "MMLU":23.12,
        "TruthfulQA":44.69,
        "Winogrande":50.04,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BarraHome\/PequeLLaMa-1B-Instruct-v0.1-16bit",
        "Average":31.59,
        "ARC":27.99,
        "HellaSwag":43.03,
        "MMLU":24.73,
        "TruthfulQA":41.1,
        "Winogrande":52.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-355M",
        "Average":31.58,
        "ARC":25.43,
        "HellaSwag":46.67,
        "MMLU":25.3,
        "TruthfulQA":39.19,
        "Winogrande":52.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.4,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"AIGym\/deepseek-coder-1.3b-chat",
        "Average":31.57,
        "ARC":25.6,
        "HellaSwag":39.69,
        "MMLU":25.54,
        "TruthfulQA":43.94,
        "Winogrande":51.46,
        "GSM8K":3.18,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.35,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-410m",
        "Average":31.55,
        "ARC":26.19,
        "HellaSwag":40.85,
        "MMLU":27.25,
        "TruthfulQA":41.22,
        "Winogrande":53.12,
        "GSM8K":0.68,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.51,
        "Model Sha":16.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-13b-chat-longlora-32k-sft",
        "Average":31.54,
        "ARC":26.54,
        "HellaSwag":26.1,
        "MMLU":23.12,
        "TruthfulQA":49.16,
        "Winogrande":64.33,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/latent_gpt2_medium_alpaca_e3",
        "Average":31.53,
        "ARC":28.75,
        "HellaSwag":37.78,
        "MMLU":26.35,
        "TruthfulQA":44.74,
        "Winogrande":51.54,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v1-774m",
        "Average":31.51,
        "ARC":28.07,
        "HellaSwag":44.35,
        "MMLU":25.91,
        "TruthfulQA":36.11,
        "Winogrande":54.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikivis\/gpt2-large-lora-stf4",
        "Average":31.5,
        "ARC":26.88,
        "HellaSwag":42.17,
        "MMLU":25.53,
        "TruthfulQA":40.84,
        "Winogrande":53.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Average":31.5,
        "ARC":26.45,
        "HellaSwag":42.24,
        "MMLU":25.43,
        "TruthfulQA":40.5,
        "Winogrande":53.91,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":[
            "cc-by-sa-4.0"
        ],
        "Available on the Hub":3.0,
        "Model Sha":83.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/Instruct_GPT",
        "Average":31.46,
        "ARC":28.24,
        "HellaSwag":39.33,
        "MMLU":26.84,
        "TruthfulQA":39.72,
        "Winogrande":54.3,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-13b-chat-longlora-32k-sft",
        "Average":31.43,
        "ARC":26.11,
        "HellaSwag":26.17,
        "MMLU":23.12,
        "TruthfulQA":49.07,
        "Winogrande":64.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.02,
        "Model Sha":22.0
    },
    {
        "T":"?",
        "Model":"facebook\/xglm-1.7B",
        "Average":31.42,
        "ARC":25.85,
        "HellaSwag":45.68,
        "MMLU":25.1,
        "TruthfulQA":37.21,
        "Winogrande":53.91,
        "GSM8K":0.76,
        "Type":"",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.7,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-coder-ds-1.3b",
        "Average":31.4,
        "ARC":26.54,
        "HellaSwag":39.49,
        "MMLU":24.85,
        "TruthfulQA":42.12,
        "Winogrande":53.04,
        "GSM8K":2.35,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoderbase-3b",
        "Average":31.38,
        "ARC":25.85,
        "HellaSwag":39.11,
        "MMLU":27.35,
        "TruthfulQA":43.05,
        "Winogrande":51.14,
        "GSM8K":1.74,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":3.0,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/latent_gpt2_medium_alpaca_e2",
        "Average":31.37,
        "ARC":26.96,
        "HellaSwag":39.72,
        "MMLU":26.93,
        "TruthfulQA":41.01,
        "Winogrande":53.2,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikivis\/gpt2-large-lora-sft2",
        "Average":31.33,
        "ARC":26.62,
        "HellaSwag":42.68,
        "MMLU":24.72,
        "TruthfulQA":40.31,
        "Winogrande":53.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-774M",
        "Average":31.33,
        "ARC":28.75,
        "HellaSwag":40.8,
        "MMLU":25.1,
        "TruthfulQA":41.33,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.77,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/gpt-2-xl-EvolInstruct",
        "Average":31.32,
        "ARC":27.39,
        "HellaSwag":38.46,
        "MMLU":25.67,
        "TruthfulQA":42.76,
        "Winogrande":53.51,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.61,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"FabbriSimo01\/Cerebras_1.3b_Quantized",
        "Average":31.31,
        "ARC":25.94,
        "HellaSwag":38.56,
        "MMLU":26.79,
        "TruthfulQA":42.67,
        "Winogrande":53.51,
        "GSM8K":0.38,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Average":31.3,
        "ARC":26.28,
        "HellaSwag":38.54,
        "MMLU":26.59,
        "TruthfulQA":42.7,
        "Winogrande":53.43,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.3,
        "Model Sha":45.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Average":31.29,
        "ARC":24.83,
        "HellaSwag":41.29,
        "MMLU":25.99,
        "TruthfulQA":40.95,
        "Winogrande":54.38,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.51,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v2-355m",
        "Average":31.2,
        "ARC":28.33,
        "HellaSwag":40.54,
        "MMLU":26.77,
        "TruthfulQA":38.76,
        "Winogrande":52.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"winglian\/basilisk-4b",
        "Average":31.15,
        "ARC":25.85,
        "HellaSwag":39.6,
        "MMLU":24.61,
        "TruthfulQA":43.74,
        "Winogrande":53.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":4.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-1.3b",
        "Average":31.14,
        "ARC":28.07,
        "HellaSwag":46.96,
        "MMLU":24.12,
        "TruthfulQA":37.64,
        "Winogrande":50.04,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"agpl-3.0",
        "Available on the Hub":1.52,
        "Model Sha":61.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/spin_gpt2_medium_alpaca_e3",
        "Average":31.14,
        "ARC":27.82,
        "HellaSwag":38.82,
        "MMLU":26.92,
        "TruthfulQA":42.2,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nnheui\/pythia-410m-sft-full",
        "Average":31.12,
        "ARC":26.54,
        "HellaSwag":40.0,
        "MMLU":25.49,
        "TruthfulQA":40.21,
        "Winogrande":53.43,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.35,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nnheui\/pythia-410m-sft-full",
        "Average":31.06,
        "ARC":26.11,
        "HellaSwag":39.92,
        "MMLU":25.28,
        "TruthfulQA":40.11,
        "Winogrande":53.67,
        "GSM8K":1.29,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikivis\/gpt2-large-lora-sft1",
        "Average":31.01,
        "ARC":24.66,
        "HellaSwag":42.67,
        "MMLU":24.89,
        "TruthfulQA":39.37,
        "Winogrande":54.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.77,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-355M",
        "Average":31.0,
        "ARC":27.56,
        "HellaSwag":38.92,
        "MMLU":27.26,
        "TruthfulQA":38.53,
        "Winogrande":53.75,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":null,
        "Model":"baseline",
        "Average":31.0,
        "ARC":25.0,
        "HellaSwag":25.0,
        "MMLU":25.0,
        "TruthfulQA":25.0,
        "Winogrande":50.0,
        "GSM8K":0.21,
        "Type":"",
        "Architecture":null,
        "Precision":null,
        "Hub License":null,
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":null,
        "Model Sha":null
    },
    {
        "T":"\ud83d\udcac",
        "Model":"SummerSigh\/GPTNeo350M-Instruct-SFT",
        "Average":31.0,
        "ARC":25.94,
        "HellaSwag":38.55,
        "MMLU":25.76,
        "TruthfulQA":45.25,
        "Winogrande":50.2,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/bloom-1b1_10e6",
        "Average":30.98,
        "ARC":25.43,
        "HellaSwag":37.12,
        "MMLU":25.43,
        "TruthfulQA":44.4,
        "Winogrande":53.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/kaori-34b-v4",
        "Average":30.97,
        "ARC":23.89,
        "HellaSwag":28.97,
        "MMLU":25.59,
        "TruthfulQA":49.46,
        "Winogrande":57.22,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KaeriJenti\/Kaori-34b-v2",
        "Average":30.97,
        "ARC":23.89,
        "HellaSwag":28.97,
        "MMLU":25.59,
        "TruthfulQA":49.46,
        "Winogrande":57.22,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":34.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"postbot\/emailgen-pythia-410m-deduped",
        "Average":30.93,
        "ARC":27.9,
        "HellaSwag":40.04,
        "MMLU":27.35,
        "TruthfulQA":38.2,
        "Winogrande":52.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AI-Sweden-Models\/gpt-sw3-356m-instruct",
        "Average":30.93,
        "ARC":26.96,
        "HellaSwag":38.01,
        "MMLU":25.53,
        "TruthfulQA":40.74,
        "Winogrande":52.57,
        "GSM8K":1.74,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.47,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/GPT2-774M-CINDER-SHOW-MULTI-CHAT",
        "Average":30.87,
        "ARC":26.54,
        "HellaSwag":39.69,
        "MMLU":25.8,
        "TruthfulQA":37.15,
        "Winogrande":52.17,
        "GSM8K":3.87,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.77,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/Quokka_1.3b",
        "Average":30.86,
        "ARC":27.73,
        "HellaSwag":37.91,
        "MMLU":26.66,
        "TruthfulQA":40.14,
        "Winogrande":52.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.42,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Corianas\/1.3b",
        "Average":30.76,
        "ARC":27.3,
        "HellaSwag":38.3,
        "MMLU":26.77,
        "TruthfulQA":39.02,
        "Winogrande":53.04,
        "GSM8K":0.15,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":1.42,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Mediquad-4x7b",
        "Average":30.74,
        "ARC":27.47,
        "HellaSwag":28.21,
        "MMLU":28.66,
        "TruthfulQA":49.56,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":19.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-616M-Cinder",
        "Average":30.73,
        "ARC":26.45,
        "HellaSwag":36.4,
        "MMLU":24.86,
        "TruthfulQA":43.41,
        "Winogrande":53.28,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.62,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cmarkea\/bloomz-560m-sft-chat",
        "Average":30.72,
        "ARC":27.47,
        "HellaSwag":37.05,
        "MMLU":23.93,
        "TruthfulQA":42.35,
        "Winogrande":53.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":0.56,
        "Model Sha":10.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"player1537\/dolphinette",
        "Average":30.65,
        "ARC":24.91,
        "HellaSwag":37.33,
        "MMLU":25.37,
        "TruthfulQA":42.08,
        "Winogrande":54.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.56,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloomz-560m",
        "Average":30.63,
        "ARC":23.55,
        "HellaSwag":36.31,
        "MMLU":25.1,
        "TruthfulQA":45.69,
        "Winogrande":53.12,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":0.56,
        "Model Sha":93.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/medalpaca-13B-GPTQ-4bit",
        "Average":30.62,
        "ARC":29.35,
        "HellaSwag":26.32,
        "MMLU":25.44,
        "TruthfulQA":49.51,
        "Winogrande":53.12,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":16.22,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v1-355m",
        "Average":30.54,
        "ARC":27.13,
        "HellaSwag":39.07,
        "MMLU":27.12,
        "TruthfulQA":37.13,
        "Winogrande":52.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.36,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Minami-su\/Qwen1.5-7B-Chat_mistral",
        "Average":30.49,
        "ARC":24.49,
        "HellaSwag":26.69,
        "MMLU":25.78,
        "TruthfulQA":52.33,
        "Winogrande":53.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xhyi\/PT_GPTNEO350_ATG",
        "Average":30.46,
        "ARC":25.43,
        "HellaSwag":37.59,
        "MMLU":24.79,
        "TruthfulQA":43.05,
        "Winogrande":51.46,
        "GSM8K":0.45,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TehVenom\/DiffMerge-DollyGPT-Pygmalion",
        "Average":30.45,
        "ARC":23.63,
        "HellaSwag":34.38,
        "MMLU":24.41,
        "TruthfulQA":46.48,
        "Winogrande":53.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Average":30.45,
        "ARC":26.71,
        "HellaSwag":40.01,
        "MMLU":24.85,
        "TruthfulQA":39.58,
        "Winogrande":51.14,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.43,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"LordNoah\/latent_gpt2_medium_alpaca_e4",
        "Average":30.44,
        "ARC":29.1,
        "HellaSwag":39.8,
        "MMLU":25.52,
        "TruthfulQA":35.23,
        "Winogrande":52.41,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheTravellingEngineer\/bloom-560m-RLHF-v2",
        "Average":30.43,
        "ARC":26.45,
        "HellaSwag":37.67,
        "MMLU":23.95,
        "TruthfulQA":43.51,
        "Winogrande":50.91,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.56,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/mistral-inst-v02-dpo",
        "Average":30.43,
        "ARC":27.9,
        "HellaSwag":26.08,
        "MMLU":27.02,
        "TruthfulQA":50.8,
        "Winogrande":50.75,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Average":30.41,
        "ARC":23.63,
        "HellaSwag":37.05,
        "MMLU":25.93,
        "TruthfulQA":42.55,
        "Winogrande":53.04,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.47,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Average":30.4,
        "ARC":24.23,
        "HellaSwag":39.18,
        "MMLU":24.32,
        "TruthfulQA":41.51,
        "Winogrande":52.96,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.38,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"uukuguy\/speechless-codellama-orca-airoboros-13b-0.10e",
        "Average":30.36,
        "ARC":29.44,
        "HellaSwag":25.71,
        "MMLU":25.43,
        "TruthfulQA":49.64,
        "Winogrande":51.93,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"KnutJaegersberg\/megatron-gpt2-345m-evol_instruct_v2",
        "Average":30.31,
        "ARC":26.37,
        "HellaSwag":38.39,
        "MMLU":23.6,
        "TruthfulQA":41.19,
        "Winogrande":52.33,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.36,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Llama-160M-Chat-v1",
        "Average":30.28,
        "ARC":24.74,
        "HellaSwag":35.32,
        "MMLU":26.14,
        "TruthfulQA":44.16,
        "Winogrande":51.3,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.16,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vicgalle\/Miqu-6B-truthy",
        "Average":30.28,
        "ARC":27.65,
        "HellaSwag":26.71,
        "MMLU":27.04,
        "TruthfulQA":50.63,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-7b-v2-selfplay-v1",
        "Average":30.25,
        "ARC":31.91,
        "HellaSwag":30.89,
        "MMLU":53.02,
        "TruthfulQA":0.0,
        "Winogrande":65.67,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chlee10\/T3Q-MSlerp-7Bx2",
        "Average":30.24,
        "ARC":28.41,
        "HellaSwag":25.46,
        "MMLU":25.91,
        "TruthfulQA":47.28,
        "Winogrande":54.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AkiGogikar\/KnowledgeNinja-LiteLlama-460Mx6MoE-1T",
        "Average":30.23,
        "ARC":25.17,
        "HellaSwag":38.45,
        "MMLU":26.16,
        "TruthfulQA":41.57,
        "Winogrande":50.04,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":1.97,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"porkorbeef\/Llama-2-13b-sf",
        "Average":30.22,
        "ARC":29.52,
        "HellaSwag":26.49,
        "MMLU":25.98,
        "TruthfulQA":48.97,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-orca-airoboros-13b-0.10e",
        "Average":30.22,
        "ARC":29.27,
        "HellaSwag":25.74,
        "MMLU":25.69,
        "TruthfulQA":49.61,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yec019\/fbopt-350m-8bit",
        "Average":30.21,
        "ARC":23.55,
        "HellaSwag":36.6,
        "MMLU":26.22,
        "TruthfulQA":40.97,
        "Winogrande":52.64,
        "GSM8K":1.29,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":0.33,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kevin009\/flyingllama-v2",
        "Average":30.19,
        "ARC":24.74,
        "HellaSwag":38.44,
        "MMLU":26.37,
        "TruthfulQA":41.3,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.46,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"lqtrung1998\/Codellama-7b-hf-ReFT-Rerank-GSM8k",
        "Average":30.18,
        "ARC":29.27,
        "HellaSwag":26.13,
        "MMLU":24.64,
        "TruthfulQA":49.97,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForSequenceClassification",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":6.61,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
        "Average":30.18,
        "ARC":26.02,
        "HellaSwag":40.39,
        "MMLU":24.45,
        "TruthfulQA":37.57,
        "Winogrande":52.41,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.38,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Average":30.17,
        "ARC":24.91,
        "HellaSwag":38.47,
        "MMLU":26.17,
        "TruthfulQA":41.59,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.46,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ahxt\/LiteLlama-460M-1T",
        "Average":30.16,
        "ARC":24.83,
        "HellaSwag":38.39,
        "MMLU":25.96,
        "TruthfulQA":41.59,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.46,
        "Model Sha":152.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kevin009\/flyingllama",
        "Average":30.16,
        "ARC":24.74,
        "HellaSwag":38.35,
        "MMLU":26.14,
        "TruthfulQA":41.6,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.46,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Average":30.15,
        "ARC":29.61,
        "HellaSwag":25.62,
        "MMLU":26.7,
        "TruthfulQA":48.36,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-350M-Erebus",
        "Average":30.14,
        "ARC":23.81,
        "HellaSwag":34.35,
        "MMLU":26.23,
        "TruthfulQA":43.58,
        "Winogrande":52.57,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.33,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheTravellingEngineer\/bloom-1b1-RLHF",
        "Average":30.14,
        "ARC":27.99,
        "HellaSwag":26.19,
        "MMLU":26.86,
        "TruthfulQA":48.88,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.02,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"bigscience\/bloom-560m",
        "Average":30.13,
        "ARC":24.74,
        "HellaSwag":37.15,
        "MMLU":24.22,
        "TruthfulQA":42.44,
        "Winogrande":51.93,
        "GSM8K":0.3,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":0.56,
        "Model Sha":317.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yhyhy3\/med-orca-instruct-33b",
        "Average":30.12,
        "ARC":28.84,
        "HellaSwag":25.63,
        "MMLU":26.5,
        "TruthfulQA":49.26,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":33.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"porkorbeef\/Llama-2-13b",
        "Average":30.11,
        "ARC":29.35,
        "HellaSwag":26.35,
        "MMLU":24.94,
        "TruthfulQA":48.32,
        "Winogrande":51.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"health360\/Healix-410M",
        "Average":30.1,
        "ARC":25.09,
        "HellaSwag":32.02,
        "MMLU":24.94,
        "TruthfulQA":44.42,
        "Winogrande":54.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.41,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt350m_10e5",
        "Average":30.09,
        "ARC":24.15,
        "HellaSwag":36.53,
        "MMLU":26.0,
        "TruthfulQA":42.17,
        "Winogrande":51.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.33,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcchew\/Marcoroni-7B-LaMini-80K",
        "Average":30.09,
        "ARC":28.75,
        "HellaSwag":26.13,
        "MMLU":24.46,
        "TruthfulQA":49.71,
        "Winogrande":51.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"222gate\/TinyMistral-248Mx4-MOE",
        "Average":30.08,
        "ARC":29.52,
        "HellaSwag":25.71,
        "MMLU":24.82,
        "TruthfulQA":48.66,
        "Winogrande":51.78,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"doas\/test5",
        "Average":30.06,
        "ARC":28.41,
        "HellaSwag":26.63,
        "MMLU":25.36,
        "TruthfulQA":47.34,
        "Winogrande":52.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/starcoderbase-1b",
        "Average":30.06,
        "ARC":22.7,
        "HellaSwag":34.31,
        "MMLU":26.67,
        "TruthfulQA":45.79,
        "Winogrande":49.96,
        "GSM8K":0.91,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":1.14,
        "Model Sha":49.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/lamini-cerebras-1.3b",
        "Average":30.05,
        "ARC":26.88,
        "HellaSwag":37.96,
        "MMLU":28.43,
        "TruthfulQA":36.45,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/megatron-GPT-2-345m-EvolInstruct",
        "Average":30.01,
        "ARC":24.06,
        "HellaSwag":35.12,
        "MMLU":24.48,
        "TruthfulQA":41.25,
        "Winogrande":54.78,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.38,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-350m",
        "Average":30.01,
        "ARC":23.55,
        "HellaSwag":36.73,
        "MMLU":26.02,
        "TruthfulQA":40.83,
        "Winogrande":52.64,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.35,
        "Model Sha":108.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shitshow123\/mistral7b_sft_dpo",
        "Average":30.0,
        "ARC":27.56,
        "HellaSwag":25.53,
        "MMLU":24.05,
        "TruthfulQA":49.68,
        "Winogrande":53.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yeen214\/test_llama2_ko_7b",
        "Average":29.99,
        "ARC":29.95,
        "HellaSwag":26.94,
        "MMLU":25.62,
        "TruthfulQA":49.03,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikp\/phi2",
        "Average":29.98,
        "ARC":22.87,
        "HellaSwag":30.7,
        "MMLU":27.55,
        "TruthfulQA":46.1,
        "Winogrande":52.01,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-codellama-orca-platypus-13b-0.10e",
        "Average":29.96,
        "ARC":28.92,
        "HellaSwag":25.76,
        "MMLU":25.28,
        "TruthfulQA":49.22,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IDEA-CCNL\/Ziya-LLaMA-13B-Pretrain-v1",
        "Average":29.96,
        "ARC":27.99,
        "HellaSwag":26.0,
        "MMLU":27.04,
        "TruthfulQA":48.59,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":13.0,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"PygmalionAI\/pygmalion-350m",
        "Average":29.95,
        "ARC":25.0,
        "HellaSwag":37.8,
        "MMLU":25.68,
        "TruthfulQA":40.41,
        "Winogrande":50.28,
        "GSM8K":0.53,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.35,
        "Model Sha":53.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"senseable\/moe-x33",
        "Average":29.95,
        "ARC":26.19,
        "HellaSwag":26.44,
        "MMLU":24.93,
        "TruthfulQA":51.14,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":58.94,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hoskinson-center\/proofGPT-v0.1",
        "Average":29.94,
        "ARC":22.87,
        "HellaSwag":28.66,
        "MMLU":25.96,
        "TruthfulQA":51.64,
        "Winogrande":50.43,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shitshow123\/TinyLlama-1.1B-ChatStrong-DPO-PPO",
        "Average":29.93,
        "ARC":30.38,
        "HellaSwag":25.75,
        "MMLU":24.17,
        "TruthfulQA":48.87,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.03,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/mistral-environment-adapter",
        "Average":29.93,
        "ARC":29.18,
        "HellaSwag":25.81,
        "MMLU":25.38,
        "TruthfulQA":48.75,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcchew\/LaMini-40k-Platypus2-7B",
        "Average":29.91,
        "ARC":28.5,
        "HellaSwag":26.32,
        "MMLU":27.04,
        "TruthfulQA":47.39,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/OPT-350M-Nerys-v2",
        "Average":29.9,
        "ARC":23.63,
        "HellaSwag":35.49,
        "MMLU":25.91,
        "TruthfulQA":42.08,
        "Winogrande":51.62,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.35,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"postbot\/gpt2-medium-emailgen",
        "Average":29.87,
        "ARC":26.45,
        "HellaSwag":34.31,
        "MMLU":24.1,
        "TruthfulQA":43.96,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "apache-2.0"
        ],
        "Available on the Hub":0.38,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"rishiraj\/cutie",
        "Average":29.87,
        "ARC":26.96,
        "HellaSwag":27.02,
        "MMLU":24.17,
        "TruthfulQA":48.42,
        "Winogrande":52.64,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"doas\/test2",
        "Average":29.87,
        "ARC":29.61,
        "HellaSwag":26.65,
        "MMLU":24.34,
        "TruthfulQA":48.49,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheTravellingEngineer\/bloom-560m-RLHF",
        "Average":29.86,
        "ARC":24.4,
        "HellaSwag":36.96,
        "MMLU":23.63,
        "TruthfulQA":40.76,
        "Winogrande":53.12,
        "GSM8K":0.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.56,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"TheBloke\/WizardLM-7B-uncensored-GPTQ",
        "Average":29.86,
        "ARC":28.5,
        "HellaSwag":25.37,
        "MMLU":24.85,
        "TruthfulQA":50.86,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":9.04,
        "Model Sha":179.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/santa1.1b_10e6",
        "Average":29.84,
        "ARC":27.65,
        "HellaSwag":26.39,
        "MMLU":25.42,
        "TruthfulQA":49.4,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadCustomModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.23,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e6_run1",
        "Average":29.84,
        "ARC":23.98,
        "HellaSwag":29.79,
        "MMLU":24.49,
        "TruthfulQA":48.59,
        "Winogrande":52.17,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_30ep",
        "Average":29.84,
        "ARC":25.6,
        "HellaSwag":30.3,
        "MMLU":23.9,
        "TruthfulQA":47.22,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"uukuguy\/speechless-codellama-orca-platypus-13b-0.10e",
        "Average":29.83,
        "ARC":28.75,
        "HellaSwag":25.88,
        "MMLU":25.36,
        "TruthfulQA":49.27,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"IDEA-CCNL\/Ziya-LLaMA-13B-v1",
        "Average":29.82,
        "ARC":27.73,
        "HellaSwag":25.96,
        "MMLU":27.04,
        "TruthfulQA":48.65,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"gpl-3.0",
        "Available on the Hub":13.0,
        "Model Sha":267.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"monology\/mixtral-soup",
        "Average":29.82,
        "ARC":23.98,
        "HellaSwag":27.08,
        "MMLU":26.25,
        "TruthfulQA":49.94,
        "Winogrande":51.7,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Panchovix\/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
        "Average":29.81,
        "ARC":25.43,
        "HellaSwag":31.97,
        "MMLU":23.43,
        "TruthfulQA":47.0,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.0,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Minami-su\/roleplay_alpaca_llama_lora",
        "Average":29.8,
        "ARC":27.65,
        "HellaSwag":25.99,
        "MMLU":27.04,
        "TruthfulQA":48.63,
        "Winogrande":49.49,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vihangd\/neuralfalcon-1b-v1",
        "Average":29.8,
        "ARC":26.37,
        "HellaSwag":26.56,
        "MMLU":25.93,
        "TruthfulQA":49.03,
        "Winogrande":50.75,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcchew\/Marcoroni-7B-LaMini-40K",
        "Average":29.78,
        "ARC":27.65,
        "HellaSwag":26.23,
        "MMLU":26.92,
        "TruthfulQA":47.4,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MayaPH\/FinOPT-Franklin",
        "Average":29.78,
        "ARC":27.73,
        "HellaSwag":24.91,
        "MMLU":23.12,
        "TruthfulQA":52.4,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":1.32,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NEU-HAI\/mental-alpaca",
        "Average":29.77,
        "ARC":28.58,
        "HellaSwag":26.02,
        "MMLU":27.04,
        "TruthfulQA":48.61,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/PM_modelV2",
        "Average":29.77,
        "ARC":25.09,
        "HellaSwag":26.45,
        "MMLU":26.14,
        "TruthfulQA":51.36,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"NobodyExistsOnTheInternet\/clown-SUV-4x70b",
        "Average":29.76,
        "ARC":24.74,
        "HellaSwag":28.29,
        "MMLU":24.2,
        "TruthfulQA":48.81,
        "Winogrande":52.49,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":238.09,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_10ep",
        "Average":29.75,
        "ARC":23.98,
        "HellaSwag":31.24,
        "MMLU":24.79,
        "TruthfulQA":46.22,
        "Winogrande":52.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/TinyLlama-748M-Reason-With-Cinder-Test-2",
        "Average":29.73,
        "ARC":24.66,
        "HellaSwag":34.5,
        "MMLU":25.15,
        "TruthfulQA":42.76,
        "Winogrande":50.51,
        "GSM8K":0.83,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.75,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt350m_10e6",
        "Average":29.73,
        "ARC":23.98,
        "HellaSwag":32.36,
        "MMLU":24.96,
        "TruthfulQA":46.71,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.33,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"hoskinson-center\/proofGPT-v0.1-6.7B",
        "Average":29.72,
        "ARC":23.29,
        "HellaSwag":28.45,
        "MMLU":24.57,
        "TruthfulQA":50.87,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.7,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"0x7o\/BulgakovLM-3B",
        "Average":29.72,
        "ARC":28.33,
        "HellaSwag":26.57,
        "MMLU":24.99,
        "TruthfulQA":47.93,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.84,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Llama-68M-Chat-v1",
        "Average":29.72,
        "ARC":23.29,
        "HellaSwag":28.27,
        "MMLU":25.18,
        "TruthfulQA":47.27,
        "Winogrande":54.3,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.07,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vihangd\/neuralfalcon-1b-v1",
        "Average":29.72,
        "ARC":26.79,
        "HellaSwag":26.56,
        "MMLU":26.22,
        "TruthfulQA":48.93,
        "Winogrande":49.57,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"team-lucid\/mptk-1b",
        "Average":29.7,
        "ARC":24.06,
        "HellaSwag":35.61,
        "MMLU":26.95,
        "TruthfulQA":39.71,
        "Winogrande":51.07,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"MptForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/Tinyllama-320M-Cinder-v1",
        "Average":29.69,
        "ARC":27.73,
        "HellaSwag":29.68,
        "MMLU":24.52,
        "TruthfulQA":44.3,
        "Winogrande":51.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.34,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"danielpark\/gorani-100k-llama2-13b-instruct",
        "Average":29.69,
        "ARC":28.07,
        "HellaSwag":26.3,
        "MMLU":25.17,
        "TruthfulQA":48.96,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test2",
        "Average":29.69,
        "ARC":27.22,
        "HellaSwag":26.25,
        "MMLU":24.64,
        "TruthfulQA":50.14,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Delta",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TFLai\/gpt2-turkish-uncased",
        "Average":29.68,
        "ARC":24.49,
        "HellaSwag":25.08,
        "MMLU":26.59,
        "TruthfulQA":52.3,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"porkorbeef\/Llama-2-13b-12_153950",
        "Average":29.68,
        "ARC":28.58,
        "HellaSwag":26.58,
        "MMLU":20.79,
        "TruthfulQA":49.03,
        "Winogrande":53.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_40ep",
        "Average":29.66,
        "ARC":24.23,
        "HellaSwag":29.9,
        "MMLU":23.75,
        "TruthfulQA":49.02,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Technoculture\/mtor",
        "Average":29.65,
        "ARC":27.3,
        "HellaSwag":26.22,
        "MMLU":24.28,
        "TruthfulQA":49.68,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.6,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcchew\/Platypus-2-7B-LaMini-14K",
        "Average":29.64,
        "ARC":29.52,
        "HellaSwag":26.15,
        "MMLU":23.13,
        "TruthfulQA":48.29,
        "Winogrande":50.75,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"MatthieuJ\/ING_Triomphant_M2_SLERP",
        "Average":29.62,
        "ARC":27.22,
        "HellaSwag":26.45,
        "MMLU":24.21,
        "TruthfulQA":48.79,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5",
        "Average":29.62,
        "ARC":24.66,
        "HellaSwag":31.23,
        "MMLU":26.45,
        "TruthfulQA":43.92,
        "Winogrande":51.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vikash06\/doctorMistralLLM10k",
        "Average":29.61,
        "ARC":27.22,
        "HellaSwag":27.45,
        "MMLU":25.95,
        "TruthfulQA":48.28,
        "Winogrande":48.78,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"chihoonlee10\/T3Q-MSlerp-13B",
        "Average":29.61,
        "ARC":27.65,
        "HellaSwag":25.85,
        "MMLU":26.26,
        "TruthfulQA":48.01,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":12.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openbmb\/UltraRM-13b",
        "Average":29.58,
        "ARC":28.16,
        "HellaSwag":26.13,
        "MMLU":25.96,
        "TruthfulQA":47.91,
        "Winogrande":49.33,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":12.85,
        "Model Sha":46.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vicgalle\/alpaca-7b",
        "Average":29.57,
        "ARC":28.07,
        "HellaSwag":25.83,
        "MMLU":25.31,
        "TruthfulQA":48.49,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mavihsrr\/GetCode-slerp",
        "Average":29.57,
        "ARC":26.54,
        "HellaSwag":26.2,
        "MMLU":23.12,
        "TruthfulQA":49.78,
        "Winogrande":51.78,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SebastianSchramm\/Cerebras-GPT-111M-instruction",
        "Average":29.57,
        "ARC":24.4,
        "HellaSwag":26.05,
        "MMLU":25.87,
        "TruthfulQA":49.46,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.11,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"golaxy\/gogpt-560m",
        "Average":29.56,
        "ARC":26.37,
        "HellaSwag":31.86,
        "MMLU":25.29,
        "TruthfulQA":43.12,
        "Winogrande":50.75,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.56,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HWERI\/pythia-70m-deduped-cleansharegpt",
        "Average":29.56,
        "ARC":25.68,
        "HellaSwag":25.4,
        "MMLU":23.12,
        "TruthfulQA":51.15,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.07,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"G-reen\/EXPERIMENT-DPO-m7b2-3-merged",
        "Average":29.55,
        "ARC":29.52,
        "HellaSwag":25.9,
        "MMLU":23.12,
        "TruthfulQA":48.27,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.86,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"JackFram\/llama-160m",
        "Average":29.55,
        "ARC":24.83,
        "HellaSwag":35.23,
        "MMLU":24.26,
        "TruthfulQA":42.08,
        "Winogrande":50.83,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.16,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/xglm-564M",
        "Average":29.55,
        "ARC":24.57,
        "HellaSwag":34.64,
        "MMLU":25.18,
        "TruthfulQA":40.43,
        "Winogrande":52.25,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.56,
        "Model Sha":41.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/tinyllama-730M-test",
        "Average":29.55,
        "ARC":25.09,
        "HellaSwag":33.82,
        "MMLU":24.43,
        "TruthfulQA":42.9,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.75,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-2-3",
        "Average":29.55,
        "ARC":25.6,
        "HellaSwag":25.66,
        "MMLU":27.07,
        "TruthfulQA":47.99,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Abe13\/juniper-certificate-Llama-2-7b-chat-hf",
        "Average":29.55,
        "ARC":29.1,
        "HellaSwag":27.63,
        "MMLU":24.02,
        "TruthfulQA":48.23,
        "Winogrande":48.3,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"NobodyExistsOnTheInternet\/code-llama-70b-python-instruct",
        "Average":29.55,
        "ARC":29.61,
        "HellaSwag":25.66,
        "MMLU":23.5,
        "TruthfulQA":49.26,
        "Winogrande":49.25,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":68.98,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Medtulu-4x7B",
        "Average":29.54,
        "ARC":28.75,
        "HellaSwag":25.74,
        "MMLU":24.41,
        "TruthfulQA":47.91,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":19.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_20ep",
        "Average":29.54,
        "ARC":25.43,
        "HellaSwag":30.84,
        "MMLU":23.39,
        "TruthfulQA":46.49,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"winglian\/Llama-2-3b-hf",
        "Average":29.53,
        "ARC":26.96,
        "HellaSwag":26.52,
        "MMLU":23.33,
        "TruthfulQA":50.71,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":3.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ai-forever\/rugpt3large_based_on_gpt2",
        "Average":29.53,
        "ARC":22.61,
        "HellaSwag":32.84,
        "MMLU":24.9,
        "TruthfulQA":43.39,
        "Winogrande":53.12,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":65.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"bigcode\/santacoder",
        "Average":29.51,
        "ARC":26.28,
        "HellaSwag":25.6,
        "MMLU":25.89,
        "TruthfulQA":51.24,
        "Winogrande":48.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadCustomModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":0.0,
        "Model Sha":321.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Cartinoe5930\/iDUS",
        "Average":29.51,
        "ARC":27.73,
        "HellaSwag":26.65,
        "MMLU":24.91,
        "TruthfulQA":48.58,
        "Winogrande":49.17,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"WangZeJun\/bloom-820m-chat",
        "Average":29.5,
        "ARC":23.38,
        "HellaSwag":34.16,
        "MMLU":25.98,
        "TruthfulQA":40.32,
        "Winogrande":53.2,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":0.75,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"janhq\/supermario-v1",
        "Average":29.49,
        "ARC":27.73,
        "HellaSwag":25.83,
        "MMLU":27.04,
        "TruthfulQA":47.27,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"huggingtweets\/bladeecity-jerma985",
        "Average":29.49,
        "ARC":22.87,
        "HellaSwag":30.53,
        "MMLU":26.56,
        "TruthfulQA":44.99,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"abhinand\/mistral7b-test001",
        "Average":29.49,
        "ARC":24.66,
        "HellaSwag":26.78,
        "MMLU":23.12,
        "TruthfulQA":50.07,
        "Winogrande":52.33,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.58,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Panchovix\/airoboros-33b-gpt4-1.2-SuperHOT-8k",
        "Average":29.48,
        "ARC":24.66,
        "HellaSwag":31.23,
        "MMLU":23.13,
        "TruthfulQA":47.44,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":33.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"marcchew\/test1",
        "Average":29.48,
        "ARC":27.65,
        "HellaSwag":26.17,
        "MMLU":24.55,
        "TruthfulQA":48.33,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"codeparrot\/codeparrot",
        "Average":29.48,
        "ARC":21.67,
        "HellaSwag":28.34,
        "MMLU":25.55,
        "TruthfulQA":50.87,
        "Winogrande":50.2,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":96.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kz919\/mistral-7b-dpo-open-orca-flan-50k-synthetic-5-models",
        "Average":29.48,
        "ARC":25.51,
        "HellaSwag":25.52,
        "MMLU":26.82,
        "TruthfulQA":48.81,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/gpt-neo-125m",
        "Average":29.47,
        "ARC":22.95,
        "HellaSwag":30.26,
        "MMLU":25.97,
        "TruthfulQA":45.58,
        "Winogrande":51.78,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.15,
        "Model Sha":159.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"SilverCoder66\/Mistral-7B-Instruct-adapt-vbh",
        "Average":29.47,
        "ARC":27.56,
        "HellaSwag":25.73,
        "MMLU":25.38,
        "TruthfulQA":47.95,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"beomi\/KoAlpaca-Polyglot-5.8B",
        "Average":29.46,
        "ARC":27.65,
        "HellaSwag":35.58,
        "MMLU":24.72,
        "TruthfulQA":39.74,
        "Winogrande":49.01,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.0,
        "Model Sha":53.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/MusePy-1-2",
        "Average":29.46,
        "ARC":25.77,
        "HellaSwag":25.94,
        "MMLU":25.22,
        "TruthfulQA":49.33,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zelus82\/JuliusCesar-72B-BeyonderV.0",
        "Average":29.46,
        "ARC":26.02,
        "HellaSwag":26.24,
        "MMLU":23.12,
        "TruthfulQA":49.89,
        "Winogrande":51.46,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":37.39,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"porkorbeef\/Llama-2-13b-public",
        "Average":29.45,
        "ARC":29.95,
        "HellaSwag":26.65,
        "MMLU":22.74,
        "TruthfulQA":49.01,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"openbmb\/UltraLM-13b",
        "Average":29.45,
        "ARC":29.44,
        "HellaSwag":25.99,
        "MMLU":23.12,
        "TruthfulQA":48.61,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":13.0,
        "Model Sha":70.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/Mistral-v0.2-orpo",
        "Average":29.45,
        "ARC":27.99,
        "HellaSwag":26.41,
        "MMLU":23.12,
        "TruthfulQA":49.85,
        "Winogrande":49.33,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Average":29.44,
        "ARC":24.83,
        "HellaSwag":29.76,
        "MMLU":25.85,
        "TruthfulQA":44.55,
        "Winogrande":50.99,
        "GSM8K":0.68,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/lamini-neo-125m",
        "Average":29.44,
        "ARC":24.57,
        "HellaSwag":30.22,
        "MMLU":26.74,
        "TruthfulQA":42.85,
        "Winogrande":52.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"monology\/mixtral-ties",
        "Average":29.43,
        "ARC":26.45,
        "HellaSwag":26.19,
        "MMLU":24.05,
        "TruthfulQA":48.75,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KoboldAI\/fairseq-dense-125M",
        "Average":29.41,
        "ARC":24.06,
        "HellaSwag":34.14,
        "MMLU":23.98,
        "TruthfulQA":43.72,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"XGLMForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.16,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"princeton-nlp\/Sheared-Pythia-160m",
        "Average":29.41,
        "ARC":22.44,
        "HellaSwag":32.07,
        "MMLU":26.65,
        "TruthfulQA":43.22,
        "Winogrande":51.7,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.16,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/tiny_starcoder_py",
        "Average":29.41,
        "ARC":20.99,
        "HellaSwag":28.77,
        "MMLU":26.79,
        "TruthfulQA":47.68,
        "Winogrande":51.22,
        "GSM8K":0.99,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigcode-openrail-m",
        "Available on the Hub":0.16,
        "Model Sha":66.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Average":29.38,
        "ARC":22.01,
        "HellaSwag":28.99,
        "MMLU":26.83,
        "TruthfulQA":45.98,
        "Winogrande":52.49,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.26,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Average":29.38,
        "ARC":24.06,
        "HellaSwag":31.39,
        "MMLU":24.86,
        "TruthfulQA":44.34,
        "Winogrande":51.38,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.21,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"breadlicker45\/dough-base-001",
        "Average":29.37,
        "ARC":23.89,
        "HellaSwag":24.76,
        "MMLU":23.13,
        "TruthfulQA":53.4,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"breadlicker45\/dough-instruct-base-001",
        "Average":29.37,
        "ARC":23.89,
        "HellaSwag":24.76,
        "MMLU":23.13,
        "TruthfulQA":53.4,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"zelus82\/Asterix-B7",
        "Average":29.37,
        "ARC":28.16,
        "HellaSwag":25.65,
        "MMLU":24.59,
        "TruthfulQA":47.24,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Delta",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Deci\/DeciCoder-1b",
        "Average":29.37,
        "ARC":21.16,
        "HellaSwag":31.09,
        "MMLU":24.34,
        "TruthfulQA":47.05,
        "Winogrande":50.83,
        "GSM8K":1.74,
        "Type":"pretrained",
        "Architecture":"DeciCoderForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.11,
        "Model Sha":244.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"amazingvince\/zephyr-smol_llama-100m-dpo-full",
        "Average":29.37,
        "ARC":25.0,
        "HellaSwag":28.54,
        "MMLU":25.18,
        "TruthfulQA":45.75,
        "Winogrande":51.07,
        "GSM8K":0.68,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/lora_opt125m_10e5",
        "Average":29.37,
        "ARC":22.78,
        "HellaSwag":31.22,
        "MMLU":25.18,
        "TruthfulQA":45.26,
        "Winogrande":51.78,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_50ep",
        "Average":29.37,
        "ARC":23.89,
        "HellaSwag":28.98,
        "MMLU":23.74,
        "TruthfulQA":48.3,
        "Winogrande":51.3,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"yhyhy3\/med-orca-instruct-33b",
        "Average":29.36,
        "ARC":27.39,
        "HellaSwag":25.89,
        "MMLU":25.37,
        "TruthfulQA":49.6,
        "Winogrande":47.91,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":33.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Average":29.35,
        "ARC":23.98,
        "HellaSwag":28.43,
        "MMLU":25.07,
        "TruthfulQA":45.87,
        "Winogrande":52.25,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.4,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Technoculture\/PMCorca-2x13b",
        "Average":29.35,
        "ARC":27.22,
        "HellaSwag":25.94,
        "MMLU":23.12,
        "TruthfulQA":49.72,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":21.51,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e2",
        "Average":29.35,
        "ARC":23.21,
        "HellaSwag":31.41,
        "MMLU":26.55,
        "TruthfulQA":42.59,
        "Winogrande":52.17,
        "GSM8K":0.15,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Medorca-4x7b",
        "Average":29.35,
        "ARC":29.35,
        "HellaSwag":25.72,
        "MMLU":24.28,
        "TruthfulQA":48.42,
        "Winogrande":48.3,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":19.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Technoculture\/Mediquad-orca-20B",
        "Average":29.35,
        "ARC":29.35,
        "HellaSwag":25.72,
        "MMLU":24.28,
        "TruthfulQA":48.42,
        "Winogrande":48.3,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":19.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FINDA-FIT\/llama-r",
        "Average":29.34,
        "ARC":21.59,
        "HellaSwag":30.18,
        "MMLU":26.13,
        "TruthfulQA":45.38,
        "Winogrande":52.17,
        "GSM8K":0.61,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-0-3",
        "Average":29.34,
        "ARC":27.3,
        "HellaSwag":27.59,
        "MMLU":24.7,
        "TruthfulQA":43.73,
        "Winogrande":52.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BEE-spoke-data\/smol_llama-220M-openhermes",
        "Average":29.34,
        "ARC":25.17,
        "HellaSwag":28.98,
        "MMLU":26.17,
        "TruthfulQA":43.08,
        "Winogrande":52.01,
        "GSM8K":0.61,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BEE-spoke-data\/zephyr-220m-dpo-full",
        "Average":29.33,
        "ARC":25.43,
        "HellaSwag":29.15,
        "MMLU":26.43,
        "TruthfulQA":43.44,
        "Winogrande":50.99,
        "GSM8K":0.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shahzebnaveed\/codeparrot-ds",
        "Average":29.33,
        "ARC":25.26,
        "HellaSwag":25.75,
        "MMLU":23.11,
        "TruthfulQA":50.85,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BEE-spoke-data\/zephyr-220m-sft-full",
        "Average":29.33,
        "ARC":25.26,
        "HellaSwag":29.03,
        "MMLU":26.45,
        "TruthfulQA":43.23,
        "Winogrande":51.62,
        "GSM8K":0.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-1B1",
        "Average":29.32,
        "ARC":23.21,
        "HellaSwag":26.97,
        "MMLU":24.86,
        "TruthfulQA":50.63,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"yyjjtt\/test-model",
        "Average":29.31,
        "ARC":24.4,
        "HellaSwag":30.17,
        "MMLU":25.88,
        "TruthfulQA":44.59,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TaylorAI\/Flash-Llama-30M-20001",
        "Average":29.31,
        "ARC":23.89,
        "HellaSwag":25.76,
        "MMLU":24.09,
        "TruthfulQA":51.29,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-1-3",
        "Average":29.31,
        "ARC":25.0,
        "HellaSwag":27.42,
        "MMLU":24.03,
        "TruthfulQA":49.05,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Harshvir\/LaMini-Neo-1.3B-Mental-Health_lora",
        "Average":29.3,
        "ARC":25.77,
        "HellaSwag":25.67,
        "MMLU":27.0,
        "TruthfulQA":48.21,
        "Winogrande":49.17,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":1.3,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"klosax\/pythia-160m-deduped-step92k-193bt",
        "Average":29.3,
        "ARC":24.23,
        "HellaSwag":32.33,
        "MMLU":24.54,
        "TruthfulQA":43.49,
        "Winogrande":50.83,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.16,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bit-dny\/MindLLM",
        "Average":29.28,
        "ARC":22.44,
        "HellaSwag":34.11,
        "MMLU":25.5,
        "TruthfulQA":43.48,
        "Winogrande":49.33,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"bsp-albz\/llama2-13b-platypus-ckpt-1000",
        "Average":29.28,
        "ARC":28.16,
        "HellaSwag":26.55,
        "MMLU":23.17,
        "TruthfulQA":48.79,
        "Winogrande":49.01,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/DialoGPT-large",
        "Average":29.27,
        "ARC":23.38,
        "HellaSwag":25.77,
        "MMLU":23.81,
        "TruthfulQA":50.27,
        "Winogrande":52.41,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":250.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"voidful\/changpt-bart",
        "Average":29.27,
        "ARC":28.67,
        "HellaSwag":26.41,
        "MMLU":23.12,
        "TruthfulQA":47.94,
        "Winogrande":49.49,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.18,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MayaPH\/FinOPT-Lincoln",
        "Average":29.27,
        "ARC":26.71,
        "HellaSwag":25.6,
        "MMLU":23.0,
        "TruthfulQA":50.59,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.33,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"victor123\/WizardLM-13B-1.0",
        "Average":29.27,
        "ARC":28.5,
        "HellaSwag":25.97,
        "MMLU":23.12,
        "TruthfulQA":48.61,
        "Winogrande":49.41,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":12.85,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"max-2022\/test_mistral2",
        "Average":29.27,
        "ARC":27.9,
        "HellaSwag":25.32,
        "MMLU":24.74,
        "TruthfulQA":49.1,
        "Winogrande":48.54,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Isotonic\/smol_llama-4x220M-MoE",
        "Average":29.25,
        "ARC":25.09,
        "HellaSwag":29.24,
        "MMLU":25.88,
        "TruthfulQA":43.92,
        "Winogrande":51.22,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.6,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"playdev7\/theseed-v0.3",
        "Average":29.24,
        "ARC":25.94,
        "HellaSwag":26.05,
        "MMLU":24.55,
        "TruthfulQA":46.33,
        "Winogrande":52.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":24.37,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Average":29.23,
        "ARC":23.81,
        "HellaSwag":29.39,
        "MMLU":25.37,
        "TruthfulQA":44.77,
        "Winogrande":51.14,
        "GSM8K":0.91,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"FabbriSimo01\/GPT_Large_Quantized",
        "Average":29.21,
        "ARC":27.05,
        "HellaSwag":26.29,
        "MMLU":24.12,
        "TruthfulQA":48.46,
        "Winogrande":49.33,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2-dolly",
        "Average":29.21,
        "ARC":22.7,
        "HellaSwag":30.15,
        "MMLU":25.81,
        "TruthfulQA":44.97,
        "Winogrande":51.46,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"concedo\/Pythia-70M-ChatSalad",
        "Average":29.2,
        "ARC":20.99,
        "HellaSwag":27.28,
        "MMLU":24.78,
        "TruthfulQA":49.74,
        "Winogrande":52.41,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.1,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-7b-longlora-32k-ft",
        "Average":29.2,
        "ARC":27.9,
        "HellaSwag":25.61,
        "MMLU":23.08,
        "TruthfulQA":49.57,
        "Winogrande":49.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"crumb\/nano-mistral",
        "Average":29.2,
        "ARC":21.67,
        "HellaSwag":28.52,
        "MMLU":25.16,
        "TruthfulQA":47.42,
        "Winogrande":52.41,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.17,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"BEE-spoke-data\/smol_llama-220M-open_instruct",
        "Average":29.19,
        "ARC":25.0,
        "HellaSwag":29.71,
        "MMLU":26.11,
        "TruthfulQA":44.06,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.22,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/DialoGPT-small",
        "Average":29.19,
        "ARC":25.77,
        "HellaSwag":25.79,
        "MMLU":25.81,
        "TruthfulQA":47.49,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.18,
        "Model Sha":80.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Cartinoe5930\/DARE-Merging",
        "Average":29.19,
        "ARC":25.26,
        "HellaSwag":26.11,
        "MMLU":23.68,
        "TruthfulQA":48.31,
        "Winogrande":51.7,
        "GSM8K":0.08,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"fionazhang\/mistral-environment-all",
        "Average":29.18,
        "ARC":29.44,
        "HellaSwag":25.89,
        "MMLU":23.12,
        "TruthfulQA":47.92,
        "Winogrande":48.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"buildingthemoon\/testfinetunedmodel",
        "Average":29.18,
        "ARC":25.85,
        "HellaSwag":31.4,
        "MMLU":26.07,
        "TruthfulQA":40.75,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Facebook\/OPT-125M",
        "Average":29.17,
        "ARC":22.87,
        "HellaSwag":31.44,
        "MMLU":26.01,
        "TruthfulQA":42.87,
        "Winogrande":51.62,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-13b-longlora-16k-ft",
        "Average":29.17,
        "ARC":25.85,
        "HellaSwag":27.6,
        "MMLU":23.1,
        "TruthfulQA":48.89,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":13.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/CodeGPT-small-py",
        "Average":29.17,
        "ARC":22.7,
        "HellaSwag":27.26,
        "MMLU":25.05,
        "TruthfulQA":51.23,
        "Winogrande":48.78,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Hemanth-thunder\/Tamil-Mistral-7B-Instruct-v0.1",
        "Average":29.16,
        "ARC":27.13,
        "HellaSwag":27.09,
        "MMLU":24.5,
        "TruthfulQA":47.3,
        "Winogrande":48.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dans-DiscountModels\/TinyMistral-v2.5-MiniPile-Guidelines-E1",
        "Average":29.16,
        "ARC":26.54,
        "HellaSwag":25.65,
        "MMLU":23.44,
        "TruthfulQA":49.9,
        "Winogrande":49.41,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Hemanth-thunder\/Tamil-Mistral-7B-Instruct-v0.1",
        "Average":29.16,
        "ARC":27.39,
        "HellaSwag":27.16,
        "MMLU":24.42,
        "TruthfulQA":47.27,
        "Winogrande":48.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dans-DiscountModels\/TinyMistral-v2.5-MiniPile-Guidelines-E1",
        "Average":29.15,
        "ARC":26.45,
        "HellaSwag":25.68,
        "MMLU":23.53,
        "TruthfulQA":49.85,
        "Winogrande":49.41,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Average":29.15,
        "ARC":23.12,
        "HellaSwag":25.23,
        "MMLU":23.12,
        "TruthfulQA":51.67,
        "Winogrande":51.78,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MaziyarPanahi\/UNA-34Beagles-32K-bf16-v1-GPTQ",
        "Average":29.15,
        "ARC":26.11,
        "HellaSwag":26.29,
        "MMLU":24.43,
        "TruthfulQA":47.27,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":43.23,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-125m",
        "Average":29.15,
        "ARC":22.87,
        "HellaSwag":31.47,
        "MMLU":26.02,
        "TruthfulQA":42.87,
        "Winogrande":51.62,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.12,
        "Model Sha":109.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e3",
        "Average":29.15,
        "ARC":22.87,
        "HellaSwag":31.01,
        "MMLU":26.66,
        "TruthfulQA":42.52,
        "Winogrande":51.85,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ogimgio\/gpt-neo-125m-neurallinguisticpioneers",
        "Average":29.15,
        "ARC":22.44,
        "HellaSwag":30.36,
        "MMLU":25.14,
        "TruthfulQA":45.64,
        "Winogrande":51.22,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"kodonho\/Momo-70b-DPO-mixed",
        "Average":29.14,
        "ARC":26.28,
        "HellaSwag":24.98,
        "MMLU":23.06,
        "TruthfulQA":48.85,
        "Winogrande":51.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"cerebras\/Cerebras-GPT-590M",
        "Average":29.14,
        "ARC":23.72,
        "HellaSwag":32.4,
        "MMLU":25.97,
        "TruthfulQA":44.15,
        "Winogrande":48.15,
        "GSM8K":0.45,
        "Type":"",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.59,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"roneneldan\/TinyStories-1M",
        "Average":29.14,
        "ARC":23.46,
        "HellaSwag":25.23,
        "MMLU":24.57,
        "TruthfulQA":49.4,
        "Winogrande":52.17,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":29.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TheBloke\/Llama-2-7b-Chat-AWQ",
        "Average":29.14,
        "ARC":27.22,
        "HellaSwag":25.48,
        "MMLU":24.67,
        "TruthfulQA":49.95,
        "Winogrande":47.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":1.13,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"euclaise\/crow-1b",
        "Average":29.12,
        "ARC":25.51,
        "HellaSwag":25.87,
        "MMLU":24.8,
        "TruthfulQA":48.28,
        "Winogrande":49.41,
        "GSM8K":0.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yash21\/TinyYi-7b-Test",
        "Average":29.11,
        "ARC":26.88,
        "HellaSwag":26.14,
        "MMLU":24.41,
        "TruthfulQA":46.35,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yash21\/TinyYi-7B-Test",
        "Average":29.11,
        "ARC":26.88,
        "HellaSwag":26.14,
        "MMLU":24.41,
        "TruthfulQA":46.35,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":6.06,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Aspik101\/tulu-7b-instruct-pl-lora_unload",
        "Average":29.11,
        "ARC":28.67,
        "HellaSwag":26.05,
        "MMLU":23.12,
        "TruthfulQA":48.61,
        "Winogrande":48.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Average":29.11,
        "ARC":21.76,
        "HellaSwag":32.88,
        "MMLU":24.11,
        "TruthfulQA":44.35,
        "Winogrande":51.54,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"BloomModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"euclaise\/gpt-neox-122m-minipile-digits",
        "Average":29.1,
        "ARC":20.73,
        "HellaSwag":27.03,
        "MMLU":25.31,
        "TruthfulQA":49.19,
        "Winogrande":52.33,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc0-1.0",
        "Available on the Hub":0.17,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/160M-TinyLLama-Mini-Cinder",
        "Average":29.09,
        "ARC":24.66,
        "HellaSwag":28.16,
        "MMLU":25.09,
        "TruthfulQA":44.08,
        "Winogrande":52.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-7b-longlora-100k-ft",
        "Average":29.08,
        "ARC":28.16,
        "HellaSwag":25.43,
        "MMLU":23.48,
        "TruthfulQA":49.06,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":51.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"KnutJaegersberg\/internlm-20b-llamafied",
        "Average":29.08,
        "ARC":26.79,
        "HellaSwag":26.4,
        "MMLU":25.4,
        "TruthfulQA":48.06,
        "Winogrande":47.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":19.56,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe9",
        "Model":"Hemanth-thunder\/Tamil-Mistral-7B-v0.1",
        "Average":29.08,
        "ARC":28.75,
        "HellaSwag":26.52,
        "MMLU":24.28,
        "TruthfulQA":46.99,
        "Winogrande":47.91,
        "GSM8K":0.0,
        "Type":"continuously pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.39,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MysteriousAI\/Mia-001",
        "Average":29.05,
        "ARC":22.78,
        "HellaSwag":28.02,
        "MMLU":23.66,
        "TruthfulQA":48.25,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.11,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"OEvortex\/HelpingAI-110M",
        "Average":29.05,
        "ARC":22.78,
        "HellaSwag":28.02,
        "MMLU":23.66,
        "TruthfulQA":48.25,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.11,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e5_1ep",
        "Average":29.05,
        "ARC":23.46,
        "HellaSwag":30.9,
        "MMLU":26.73,
        "TruthfulQA":42.53,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"anas-awadalla\/mpt-1b-redpajama-200b",
        "Average":29.05,
        "ARC":25.77,
        "HellaSwag":26.08,
        "MMLU":24.5,
        "TruthfulQA":47.57,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MosaicGPT",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/gpt-YA-1-1_160M",
        "Average":29.03,
        "ARC":22.95,
        "HellaSwag":27.29,
        "MMLU":26.25,
        "TruthfulQA":47.02,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.16,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alibidaran\/medical_transcription_generator",
        "Average":29.03,
        "ARC":22.78,
        "HellaSwag":30.6,
        "MMLU":23.84,
        "TruthfulQA":46.5,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-160m",
        "Average":29.02,
        "ARC":22.78,
        "HellaSwag":30.34,
        "MMLU":24.95,
        "TruthfulQA":44.26,
        "Winogrande":51.54,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.21,
        "Model Sha":18.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/gpt2-conversational-or-qa",
        "Average":29.01,
        "ARC":21.42,
        "HellaSwag":27.61,
        "MMLU":26.51,
        "TruthfulQA":47.31,
        "Winogrande":51.14,
        "GSM8K":0.08,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":0.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/hepu-o4zf-ravz-7-0",
        "Average":29.01,
        "ARC":24.49,
        "HellaSwag":25.36,
        "MMLU":23.27,
        "TruthfulQA":51.67,
        "Winogrande":49.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"klosax\/pythia-70m-deduped-step44k-92bt",
        "Average":29.0,
        "ARC":22.1,
        "HellaSwag":28.21,
        "MMLU":26.03,
        "TruthfulQA":46.12,
        "Winogrande":51.54,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Average":28.98,
        "ARC":22.7,
        "HellaSwag":28.5,
        "MMLU":24.69,
        "TruthfulQA":46.09,
        "Winogrande":51.3,
        "GSM8K":0.61,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.4,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"crumb\/model-a-48.5m",
        "Average":28.98,
        "ARC":22.18,
        "HellaSwag":27.85,
        "MMLU":25.08,
        "TruthfulQA":46.75,
        "Winogrande":51.7,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.05,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Thytu\/phi-2-audio-super",
        "Average":28.97,
        "ARC":23.46,
        "HellaSwag":26.58,
        "MMLU":23.12,
        "TruthfulQA":49.53,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":2.78,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"huggingtweets\/jerma985",
        "Average":28.97,
        "ARC":21.67,
        "HellaSwag":30.91,
        "MMLU":26.57,
        "TruthfulQA":44.01,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mzio\/hedgehog-mistral_7b-alpaca_clean-smd_lora_1e_3",
        "Average":28.97,
        "ARC":23.29,
        "HellaSwag":25.47,
        "MMLU":23.5,
        "TruthfulQA":50.65,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Average":28.97,
        "ARC":23.55,
        "HellaSwag":28.77,
        "MMLU":24.24,
        "TruthfulQA":45.76,
        "Winogrande":50.67,
        "GSM8K":0.83,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Minueza-32M-UltraChat",
        "Average":28.97,
        "ARC":21.08,
        "HellaSwag":26.95,
        "MMLU":26.08,
        "TruthfulQA":47.7,
        "Winogrande":51.78,
        "GSM8K":0.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Average":28.96,
        "ARC":23.46,
        "HellaSwag":28.73,
        "MMLU":24.35,
        "TruthfulQA":45.8,
        "Winogrande":50.67,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":19.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"WizardLM\/WizardLM-30B-V1.0",
        "Average":28.96,
        "ARC":27.39,
        "HellaSwag":25.94,
        "MMLU":23.12,
        "TruthfulQA":48.61,
        "Winogrande":48.7,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":76.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"concedo\/OPT-19M-ChatSalad",
        "Average":28.96,
        "ARC":24.4,
        "HellaSwag":25.15,
        "MMLU":23.12,
        "TruthfulQA":51.36,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.02,
        "Model Sha":17.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TW3PartnersLLM\/TW3-v1-AlpacaSmaug-30B",
        "Average":28.95,
        "ARC":26.96,
        "HellaSwag":26.11,
        "MMLU":23.11,
        "TruthfulQA":48.45,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":30.41,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"WizardLM\/WizardLM-30B-V1.0",
        "Average":28.95,
        "ARC":27.39,
        "HellaSwag":25.94,
        "MMLU":23.12,
        "TruthfulQA":48.61,
        "Winogrande":48.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":30.0,
        "Model Sha":76.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/DiscordPy",
        "Average":28.94,
        "ARC":23.29,
        "HellaSwag":26.15,
        "MMLU":25.04,
        "TruthfulQA":48.16,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-70m",
        "Average":28.93,
        "ARC":21.59,
        "HellaSwag":27.29,
        "MMLU":25.9,
        "TruthfulQA":47.06,
        "Winogrande":51.46,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":38.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"xformAI\/opt-125m-gqa-ub-6-best-for-KV-cache",
        "Average":28.93,
        "ARC":24.23,
        "HellaSwag":25.0,
        "MMLU":23.12,
        "TruthfulQA":49.53,
        "Winogrande":51.7,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Felladrin\/Minueza-32M-Base",
        "Average":28.92,
        "ARC":21.33,
        "HellaSwag":26.39,
        "MMLU":24.8,
        "TruthfulQA":47.45,
        "Winogrande":53.2,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"vilm\/Mixsmol-4x400M-v0.1-epoch2",
        "Average":28.92,
        "ARC":23.55,
        "HellaSwag":32.6,
        "MMLU":25.26,
        "TruthfulQA":39.24,
        "Winogrande":52.64,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.77,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"anton-l\/gpt-j-tiny-random",
        "Average":28.92,
        "ARC":26.37,
        "HellaSwag":25.76,
        "MMLU":24.46,
        "TruthfulQA":47.44,
        "Winogrande":49.49,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTJForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"?",
        "Model":"Corianas\/590m",
        "Average":28.88,
        "ARC":24.15,
        "HellaSwag":31.91,
        "MMLU":26.61,
        "TruthfulQA":42.19,
        "Winogrande":48.38,
        "GSM8K":0.08,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/gpt-YA-1-1_70M",
        "Average":28.88,
        "ARC":22.53,
        "HellaSwag":27.37,
        "MMLU":25.38,
        "TruthfulQA":47.09,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cyberagent\/open-calm-large",
        "Average":28.88,
        "ARC":20.73,
        "HellaSwag":29.56,
        "MMLU":25.23,
        "TruthfulQA":46.52,
        "Winogrande":51.14,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qblocks\/gpt2_137m_DolphinCoder",
        "Average":28.87,
        "ARC":21.84,
        "HellaSwag":31.35,
        "MMLU":25.4,
        "TruthfulQA":41.58,
        "Winogrande":52.01,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Zangs3011\/gpt2_137m_DolphinCoder",
        "Average":28.87,
        "ARC":21.84,
        "HellaSwag":31.35,
        "MMLU":25.4,
        "TruthfulQA":41.58,
        "Winogrande":52.01,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"microsoft\/DialoGPT-medium",
        "Average":28.86,
        "ARC":24.49,
        "HellaSwag":26.21,
        "MMLU":25.84,
        "TruthfulQA":47.06,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":288.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Quake24\/easyTermsSummerizer",
        "Average":28.86,
        "ARC":25.77,
        "HellaSwag":25.81,
        "MMLU":23.12,
        "TruthfulQA":47.69,
        "Winogrande":50.75,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.41,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BFauber\/opt125m_10e4",
        "Average":28.85,
        "ARC":22.95,
        "HellaSwag":30.9,
        "MMLU":26.66,
        "TruthfulQA":42.88,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MayaPH\/FinOPT-Washington",
        "Average":28.85,
        "ARC":25.17,
        "HellaSwag":26.25,
        "MMLU":24.83,
        "TruthfulQA":45.8,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":0.12,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Average":28.85,
        "ARC":23.12,
        "HellaSwag":25.66,
        "MMLU":23.11,
        "TruthfulQA":51.32,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/StoryPy",
        "Average":28.85,
        "ARC":22.35,
        "HellaSwag":26.19,
        "MMLU":24.37,
        "TruthfulQA":49.1,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.1,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"postbot\/distilgpt2-emailgen",
        "Average":28.84,
        "ARC":21.76,
        "HellaSwag":27.52,
        "MMLU":25.97,
        "TruthfulQA":46.17,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.09,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"wtang06\/mpt-125m-c4",
        "Average":28.84,
        "ARC":22.18,
        "HellaSwag":26.41,
        "MMLU":24.68,
        "TruthfulQA":49.08,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"saarvajanik\/facebook-opt-6.7b-gqa-ub-16-best-for-KV-cache",
        "Average":28.84,
        "ARC":23.04,
        "HellaSwag":25.94,
        "MMLU":23.12,
        "TruthfulQA":48.99,
        "Winogrande":51.93,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ethzanalytics\/pythia-31m",
        "Average":28.81,
        "ARC":21.84,
        "HellaSwag":27.0,
        "MMLU":24.97,
        "TruthfulQA":49.1,
        "Winogrande":49.72,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yukang\/Llama-2-7b-longlora-16k-ft",
        "Average":28.81,
        "ARC":26.37,
        "HellaSwag":26.37,
        "MMLU":23.75,
        "TruthfulQA":47.76,
        "Winogrande":48.62,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Minueza-32M-Deita",
        "Average":28.8,
        "ARC":20.73,
        "HellaSwag":26.72,
        "MMLU":26.84,
        "TruthfulQA":47.75,
        "Winogrande":50.51,
        "GSM8K":0.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Minami-su\/Qwen1.5-0.5B-Chat_mistral",
        "Average":28.79,
        "ARC":25.51,
        "HellaSwag":26.41,
        "MMLU":23.08,
        "TruthfulQA":49.06,
        "Winogrande":48.7,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.5,
        "Model Sha":2.0
    },
    {
        "T":"?",
        "Model":"ByteWave\/Yi-8B-Llama",
        "Average":28.78,
        "ARC":25.68,
        "HellaSwag":26.79,
        "MMLU":24.14,
        "TruthfulQA":47.79,
        "Winogrande":48.3,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":8.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nthngdy\/pythia-owt2-70m-100k",
        "Average":28.78,
        "ARC":20.9,
        "HellaSwag":28.34,
        "MMLU":25.02,
        "TruthfulQA":45.12,
        "Winogrande":53.28,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/TinyMistral-248M-SFT-v3",
        "Average":28.78,
        "ARC":25.68,
        "HellaSwag":25.31,
        "MMLU":24.41,
        "TruthfulQA":48.87,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Average":28.78,
        "ARC":21.25,
        "HellaSwag":26.56,
        "MMLU":23.39,
        "TruthfulQA":49.6,
        "Winogrande":51.85,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":14.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tincando\/fiction_story_generator",
        "Average":28.77,
        "ARC":23.29,
        "HellaSwag":28.68,
        "MMLU":26.72,
        "TruthfulQA":43.79,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/256_5epoch",
        "Average":28.76,
        "ARC":22.27,
        "HellaSwag":28.99,
        "MMLU":26.62,
        "TruthfulQA":41.71,
        "Winogrande":52.72,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":0.32,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"binbi\/SF-72B-V1",
        "Average":28.75,
        "ARC":26.28,
        "HellaSwag":24.87,
        "MMLU":23.03,
        "TruthfulQA":48.78,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"binbi\/SF-72B-V1.8.6-V1.2",
        "Average":28.75,
        "ARC":26.28,
        "HellaSwag":24.87,
        "MMLU":23.03,
        "TruthfulQA":48.78,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Tensoic\/Qwixtral-4x1.8B-SFT",
        "Average":28.75,
        "ARC":21.42,
        "HellaSwag":24.96,
        "MMLU":23.42,
        "TruthfulQA":50.15,
        "Winogrande":52.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":1.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhiramtirumala\/DialoGPT-sarcastic-medium",
        "Average":28.73,
        "ARC":23.29,
        "HellaSwag":25.93,
        "MMLU":23.76,
        "TruthfulQA":46.04,
        "Winogrande":53.35,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"TW3PartnersLLM\/TW3-v2-AlpacaSmaug-72B",
        "Average":28.73,
        "ARC":25.77,
        "HellaSwag":25.23,
        "MMLU":23.0,
        "TruthfulQA":48.65,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Smol-Llama-101M-Chat-v1",
        "Average":28.73,
        "ARC":22.87,
        "HellaSwag":28.71,
        "MMLU":24.93,
        "TruthfulQA":45.76,
        "Winogrande":50.04,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":8.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"Aratako\/Qwen1.5-MoE-2x7B",
        "Average":28.73,
        "ARC":26.02,
        "HellaSwag":25.69,
        "MMLU":24.24,
        "TruthfulQA":48.5,
        "Winogrande":47.91,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"other",
        "Available on the Hub":12.05,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nthngdy\/pythia-owt2-70m-50k",
        "Average":28.71,
        "ARC":21.5,
        "HellaSwag":28.15,
        "MMLU":25.7,
        "TruthfulQA":44.5,
        "Winogrande":52.41,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.07,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"distilgpt2",
        "Average":28.71,
        "ARC":22.27,
        "HellaSwag":27.58,
        "MMLU":24.81,
        "TruthfulQA":44.49,
        "Winogrande":53.12,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.09,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HWERI\/pythia-70m-deduped-cleansharegpt-en",
        "Average":28.71,
        "ARC":21.16,
        "HellaSwag":27.16,
        "MMLU":25.24,
        "TruthfulQA":48.57,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.07,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Average":28.7,
        "ARC":22.7,
        "HellaSwag":27.6,
        "MMLU":25.28,
        "TruthfulQA":44.75,
        "Winogrande":51.54,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.06,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dfurman\/MoMoMerge-72B-v0.1",
        "Average":28.69,
        "ARC":26.28,
        "HellaSwag":25.27,
        "MMLU":23.08,
        "TruthfulQA":48.73,
        "Winogrande":48.78,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":72.29,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ibivibiv\/orthorus-125b-moe-v2",
        "Average":28.68,
        "ARC":26.28,
        "HellaSwag":25.17,
        "MMLU":22.79,
        "TruthfulQA":48.49,
        "Winogrande":49.33,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":120.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Yash21\/SuperChat-7B",
        "Average":28.67,
        "ARC":23.98,
        "HellaSwag":26.4,
        "MMLU":23.24,
        "TruthfulQA":47.21,
        "Winogrande":50.2,
        "GSM8K":0.99,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"xformAI\/facebook-opt-125m-qcqa-ub-6-best-for-KV-cache",
        "Average":28.66,
        "ARC":24.23,
        "HellaSwag":25.0,
        "MMLU":23.12,
        "TruthfulQA":48.41,
        "Winogrande":51.22,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"kenhktsui\/nano-phi-115M-v0.1",
        "Average":28.66,
        "ARC":21.93,
        "HellaSwag":27.86,
        "MMLU":25.34,
        "TruthfulQA":46.0,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Average":28.64,
        "ARC":23.63,
        "HellaSwag":31.74,
        "MMLU":23.18,
        "TruthfulQA":41.92,
        "Winogrande":50.91,
        "GSM8K":0.45,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.17,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"postbot\/distilgpt2-emailgen-V2",
        "Average":28.64,
        "ARC":20.99,
        "HellaSwag":26.78,
        "MMLU":25.53,
        "TruthfulQA":46.51,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.09,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TomGrc\/FN-OpenLLM_2x72B_MoE",
        "Average":28.62,
        "ARC":25.51,
        "HellaSwag":25.23,
        "MMLU":22.8,
        "TruthfulQA":48.47,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":120.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Average":28.61,
        "ARC":22.78,
        "HellaSwag":25.61,
        "MMLU":23.12,
        "TruthfulQA":49.65,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Average":28.6,
        "ARC":21.59,
        "HellaSwag":25.79,
        "MMLU":24.99,
        "TruthfulQA":50.62,
        "Winogrande":48.62,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Pythia-31M-Chat-v1",
        "Average":28.59,
        "ARC":21.84,
        "HellaSwag":26.81,
        "MMLU":24.55,
        "TruthfulQA":48.04,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"saarvajanik\/facebook-opt-6.7b-qcqa-ub-16-best-for-KV-cache",
        "Average":28.58,
        "ARC":23.81,
        "HellaSwag":27.05,
        "MMLU":23.12,
        "TruthfulQA":46.69,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2_open-platypus",
        "Average":28.58,
        "ARC":22.18,
        "HellaSwag":31.29,
        "MMLU":26.19,
        "TruthfulQA":40.35,
        "Winogrande":51.3,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"beomi\/KoAlpaca-KoRWKV-6B",
        "Average":28.57,
        "ARC":23.46,
        "HellaSwag":31.65,
        "MMLU":24.89,
        "TruthfulQA":39.83,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.53,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KnutJaegersberg\/RWKV-4-PilePlus-169M-20230520-done-ctx4096",
        "Average":28.57,
        "ARC":23.98,
        "HellaSwag":32.25,
        "MMLU":23.37,
        "TruthfulQA":42.29,
        "Winogrande":49.17,
        "GSM8K":0.38,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.13,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"yeen214\/llama2_7b_small_tuning_v1",
        "Average":28.56,
        "ARC":22.44,
        "HellaSwag":25.0,
        "MMLU":25.51,
        "TruthfulQA":48.7,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mzio\/hedgehog-alpaca_clean_mistral-mistral_7b_lk_esn_tqk_lora-lk_untied_head-lsc_1",
        "Average":28.56,
        "ARC":21.25,
        "HellaSwag":28.74,
        "MMLU":25.15,
        "TruthfulQA":46.66,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.28,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/chat_gpt2_dpo",
        "Average":28.56,
        "ARC":23.98,
        "HellaSwag":31.22,
        "MMLU":24.95,
        "TruthfulQA":41.26,
        "Winogrande":49.96,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aloobun\/falcon-1b-cot-t2",
        "Average":28.56,
        "ARC":24.74,
        "HellaSwag":24.75,
        "MMLU":23.12,
        "TruthfulQA":48.38,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"FalconForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"qiyinmiss\/My_GPT2",
        "Average":28.55,
        "ARC":21.93,
        "HellaSwag":31.59,
        "MMLU":25.84,
        "TruthfulQA":40.73,
        "Winogrande":50.51,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gpt2",
        "Average":28.53,
        "ARC":22.01,
        "HellaSwag":31.53,
        "MMLU":25.83,
        "TruthfulQA":40.69,
        "Winogrande":50.43,
        "GSM8K":0.68,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openai-community\/gpt2",
        "Average":28.53,
        "ARC":22.01,
        "HellaSwag":31.53,
        "MMLU":25.83,
        "TruthfulQA":40.69,
        "Winogrande":50.43,
        "GSM8K":0.68,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":1788.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/Quokka_590m",
        "Average":28.53,
        "ARC":24.4,
        "HellaSwag":31.61,
        "MMLU":25.36,
        "TruthfulQA":39.59,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.67,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2_guanaco-dolly-platypus",
        "Average":28.52,
        "ARC":23.55,
        "HellaSwag":31.03,
        "MMLU":26.4,
        "TruthfulQA":40.02,
        "Winogrande":50.12,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2_platypus-dolly-guanaco",
        "Average":28.51,
        "ARC":23.21,
        "HellaSwag":31.04,
        "MMLU":26.16,
        "TruthfulQA":40.31,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/math_gpt2",
        "Average":28.5,
        "ARC":24.23,
        "HellaSwag":30.88,
        "MMLU":25.38,
        "TruthfulQA":39.23,
        "Winogrande":51.07,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Josephgflowers\/distillgpt2Cinder",
        "Average":28.5,
        "ARC":24.49,
        "HellaSwag":27.24,
        "MMLU":24.97,
        "TruthfulQA":43.96,
        "Winogrande":50.12,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.08,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Average":28.49,
        "ARC":21.16,
        "HellaSwag":30.84,
        "MMLU":24.97,
        "TruthfulQA":45.64,
        "Winogrande":47.83,
        "GSM8K":0.53,
        "Type":"pretrained",
        "Architecture":"GPTBigCodeForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"openrail",
        "Available on the Hub":1.12,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/lamini-cerebras-256m",
        "Average":28.49,
        "ARC":21.76,
        "HellaSwag":28.7,
        "MMLU":26.66,
        "TruthfulQA":41.81,
        "Winogrande":52.01,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.26,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Minueza-32M-Chat",
        "Average":28.49,
        "ARC":20.39,
        "HellaSwag":26.54,
        "MMLU":25.75,
        "TruthfulQA":47.27,
        "Winogrande":50.99,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/code_gpt2_mini_model",
        "Average":28.49,
        "ARC":23.72,
        "HellaSwag":31.25,
        "MMLU":24.96,
        "TruthfulQA":39.86,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Average":28.49,
        "ARC":22.18,
        "HellaSwag":29.54,
        "MMLU":24.43,
        "TruthfulQA":44.03,
        "Winogrande":50.67,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.19,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"nisten\/smaugzilla-77b",
        "Average":28.49,
        "ARC":24.83,
        "HellaSwag":25.16,
        "MMLU":23.05,
        "TruthfulQA":48.22,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"mit",
        "Available on the Hub":76.65,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"0x7194633\/nanoFialka-v1",
        "Average":28.48,
        "ARC":22.01,
        "HellaSwag":28.12,
        "MMLU":25.03,
        "TruthfulQA":45.26,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"blueapple8259\/TinyStories-Alpaca",
        "Average":28.46,
        "ARC":23.98,
        "HellaSwag":24.92,
        "MMLU":23.35,
        "TruthfulQA":46.68,
        "Winogrande":51.85,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.07,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/gpt-Youtube",
        "Average":28.46,
        "ARC":23.29,
        "HellaSwag":26.34,
        "MMLU":23.54,
        "TruthfulQA":48.63,
        "Winogrande":48.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.21,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"daekeun-ml\/phi-2-upscaled-4B-instruct-v0.1",
        "Average":28.45,
        "ARC":22.95,
        "HellaSwag":28.68,
        "MMLU":26.8,
        "TruthfulQA":40.92,
        "Winogrande":50.59,
        "GSM8K":0.76,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":4.04,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"vilm\/Mixsmol-4x400M-v0.1-epoch1",
        "Average":28.45,
        "ARC":22.87,
        "HellaSwag":30.57,
        "MMLU":25.28,
        "TruthfulQA":39.03,
        "Winogrande":52.8,
        "GSM8K":0.15,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.77,
        "Model Sha":12.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Cheng98\/llama-39m",
        "Average":28.45,
        "ARC":24.06,
        "HellaSwag":25.57,
        "MMLU":24.31,
        "TruthfulQA":47.19,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":0.04,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Average":28.45,
        "ARC":20.22,
        "HellaSwag":27.78,
        "MMLU":26.1,
        "TruthfulQA":46.55,
        "Winogrande":49.96,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.01,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Average":28.45,
        "ARC":22.01,
        "HellaSwag":29.56,
        "MMLU":24.53,
        "TruthfulQA":44.07,
        "Winogrande":50.43,
        "GSM8K":0.08,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.19,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Sayan01\/Llama-Flan-XL2base",
        "Average":28.44,
        "ARC":20.65,
        "HellaSwag":25.33,
        "MMLU":23.19,
        "TruthfulQA":50.58,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"roneneldan\/TinyStories-28M",
        "Average":28.44,
        "ARC":22.78,
        "HellaSwag":25.83,
        "MMLU":23.53,
        "TruthfulQA":48.08,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.03,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Average":28.44,
        "ARC":21.08,
        "HellaSwag":27.17,
        "MMLU":25.26,
        "TruthfulQA":47.51,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.1,
        "Model Sha":22.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"budecosystem\/boomer-1b",
        "Average":28.44,
        "ARC":22.78,
        "HellaSwag":31.58,
        "MMLU":25.66,
        "TruthfulQA":39.17,
        "Winogrande":50.51,
        "GSM8K":0.91,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Dans-DiscountModels\/TinyMistral-v2-Test1",
        "Average":28.42,
        "ARC":21.5,
        "HellaSwag":26.79,
        "MMLU":23.36,
        "TruthfulQA":50.3,
        "Winogrande":48.54,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"roneneldan\/TinyStories-33M",
        "Average":28.41,
        "ARC":24.23,
        "HellaSwag":25.69,
        "MMLU":23.82,
        "TruthfulQA":47.64,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.03,
        "Model Sha":79.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2_camel_physics-platypus",
        "Average":28.41,
        "ARC":23.04,
        "HellaSwag":31.32,
        "MMLU":26.91,
        "TruthfulQA":39.56,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2_platypus-camel_physics",
        "Average":28.41,
        "ARC":23.04,
        "HellaSwag":31.32,
        "MMLU":26.91,
        "TruthfulQA":39.56,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dpv\/finetuned-gpt2-tiny",
        "Average":28.4,
        "ARC":21.84,
        "HellaSwag":31.6,
        "MMLU":25.86,
        "TruthfulQA":40.67,
        "Winogrande":50.12,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"SaylorTwift\/gpt2_test",
        "Average":28.4,
        "ARC":21.84,
        "HellaSwag":31.6,
        "MMLU":25.86,
        "TruthfulQA":40.67,
        "Winogrande":50.12,
        "GSM8K":0.3,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"behnamsh\/gpt2_platypus-camel_physics",
        "Average":28.4,
        "ARC":22.78,
        "HellaSwag":31.24,
        "MMLU":25.87,
        "TruthfulQA":38.95,
        "Winogrande":51.54,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"MBZUAI\/lamini-cerebras-590m",
        "Average":28.38,
        "ARC":24.32,
        "HellaSwag":31.58,
        "MMLU":25.57,
        "TruthfulQA":40.72,
        "Winogrande":47.91,
        "GSM8K":0.15,
        "Type":"",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.59,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cloudyu\/Qwen-72Bx2-MoE-120B",
        "Average":28.37,
        "ARC":25.94,
        "HellaSwag":24.91,
        "MMLU":23.27,
        "TruthfulQA":48.91,
        "Winogrande":47.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":120.61,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"xformAI\/facebook-opt-125m-qcqa-ub-6-best-for-q-loss",
        "Average":28.37,
        "ARC":23.29,
        "HellaSwag":25.57,
        "MMLU":23.15,
        "TruthfulQA":49.03,
        "Winogrande":49.17,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"mncai\/SGPT-1.3B-insurance-epoch10",
        "Average":28.37,
        "ARC":24.57,
        "HellaSwag":24.25,
        "MMLU":25.23,
        "TruthfulQA":45.24,
        "Winogrande":50.91,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vicgalle\/gpt2-alpaca-gpt4",
        "Average":28.34,
        "ARC":22.61,
        "HellaSwag":31.17,
        "MMLU":25.76,
        "TruthfulQA":38.04,
        "Winogrande":52.17,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":20.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/Quokka_256m",
        "Average":28.32,
        "ARC":22.87,
        "HellaSwag":28.84,
        "MMLU":26.48,
        "TruthfulQA":39.47,
        "Winogrande":52.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.32,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"roneneldan\/TinyStories-8M",
        "Average":28.31,
        "ARC":24.66,
        "HellaSwag":25.03,
        "MMLU":23.33,
        "TruthfulQA":46.54,
        "Winogrande":50.28,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.01,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/convo_bot_gpt_v1",
        "Average":28.3,
        "ARC":22.35,
        "HellaSwag":31.07,
        "MMLU":26.12,
        "TruthfulQA":38.71,
        "Winogrande":51.54,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"xzuyn\/GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
        "Average":28.3,
        "ARC":24.57,
        "HellaSwag":29.43,
        "MMLU":25.82,
        "TruthfulQA":38.84,
        "Winogrande":49.01,
        "GSM8K":2.12,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ethzanalytics\/pythia-31m",
        "Average":28.3,
        "ARC":19.97,
        "HellaSwag":26.34,
        "MMLU":24.27,
        "TruthfulQA":50.12,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v2-124m",
        "Average":28.3,
        "ARC":23.98,
        "HellaSwag":31.1,
        "MMLU":25.29,
        "TruthfulQA":38.98,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":5.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"instructkr\/ko-wand-136M",
        "Average":28.29,
        "ARC":21.33,
        "HellaSwag":25.0,
        "MMLU":23.58,
        "TruthfulQA":50.68,
        "Winogrande":49.17,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":[
            "apache-2.0"
        ],
        "Available on the Hub":0.14,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Locutusque\/TinyMistral-248M-v2.5",
        "Average":28.29,
        "ARC":24.57,
        "HellaSwag":27.49,
        "MMLU":23.15,
        "TruthfulQA":46.72,
        "Winogrande":47.83,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":23.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"huggingtweets\/gladosystem",
        "Average":28.29,
        "ARC":24.4,
        "HellaSwag":29.71,
        "MMLU":23.18,
        "TruthfulQA":41.78,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"namanpundir\/theus_concepttagger",
        "Average":28.29,
        "ARC":24.57,
        "HellaSwag":25.5,
        "MMLU":23.12,
        "TruthfulQA":48.25,
        "Winogrande":48.3,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"BartForConditionalGeneration",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/lamini-cerebras-111m",
        "Average":28.29,
        "ARC":22.1,
        "HellaSwag":27.12,
        "MMLU":25.51,
        "TruthfulQA":43.79,
        "Winogrande":51.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"gpt2",
        "Average":28.28,
        "ARC":21.59,
        "HellaSwag":31.58,
        "MMLU":25.4,
        "TruthfulQA":41.15,
        "Winogrande":49.57,
        "GSM8K":0.38,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Average":28.27,
        "ARC":22.18,
        "HellaSwag":25.55,
        "MMLU":23.12,
        "TruthfulQA":49.37,
        "Winogrande":49.41,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.03,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"saarvajanik\/facebook-opt-6.7b-qcqa-ub-16-best-for-q-loss",
        "Average":28.25,
        "ARC":21.67,
        "HellaSwag":26.65,
        "MMLU":23.15,
        "TruthfulQA":46.81,
        "Winogrande":51.22,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cyberagent\/open-calm-7b",
        "Average":28.21,
        "ARC":20.48,
        "HellaSwag":30.65,
        "MMLU":25.22,
        "TruthfulQA":44.15,
        "Winogrande":48.54,
        "GSM8K":0.23,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-sa-4.0",
        "Available on the Hub":7.0,
        "Model Sha":199.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"crumb\/gpt2023",
        "Average":28.2,
        "ARC":21.93,
        "HellaSwag":31.11,
        "MMLU":25.05,
        "TruthfulQA":40.71,
        "Winogrande":50.12,
        "GSM8K":0.3,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"AI-Sweden-Models\/gpt-sw3-126m-instruct",
        "Average":28.2,
        "ARC":23.38,
        "HellaSwag":29.88,
        "MMLU":23.78,
        "TruthfulQA":42.65,
        "Winogrande":48.54,
        "GSM8K":0.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.19,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/TinyMistral-248M-SFT-v4",
        "Average":28.2,
        "ARC":24.91,
        "HellaSwag":28.15,
        "MMLU":26.04,
        "TruthfulQA":39.56,
        "Winogrande":50.51,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"beomi\/KoRWKV-6B",
        "Average":28.19,
        "ARC":22.1,
        "HellaSwag":32.18,
        "MMLU":24.69,
        "TruthfulQA":39.05,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"RwkvForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":6.53,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"roneneldan\/TinyStories-3M",
        "Average":28.19,
        "ARC":22.01,
        "HellaSwag":25.58,
        "MMLU":24.99,
        "TruthfulQA":47.33,
        "Winogrande":49.25,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":0.0,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/code_gpt2",
        "Average":28.19,
        "ARC":23.29,
        "HellaSwag":30.99,
        "MMLU":25.03,
        "TruthfulQA":40.6,
        "Winogrande":49.25,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/TinyMistral-248M-Instruct",
        "Average":28.19,
        "ARC":24.32,
        "HellaSwag":27.52,
        "MMLU":25.18,
        "TruthfulQA":41.94,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"pszemraj\/distilgpt2-HC3",
        "Average":28.18,
        "ARC":24.66,
        "HellaSwag":27.99,
        "MMLU":23.95,
        "TruthfulQA":42.1,
        "Winogrande":50.36,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.09,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lgaalves\/gpt2-dolly",
        "Average":28.18,
        "ARC":21.76,
        "HellaSwag":30.77,
        "MMLU":24.66,
        "TruthfulQA":42.22,
        "Winogrande":49.57,
        "GSM8K":0.08,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.12,
        "Model Sha":3.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Average":28.17,
        "ARC":22.18,
        "HellaSwag":29.33,
        "MMLU":24.06,
        "TruthfulQA":43.97,
        "Winogrande":49.25,
        "GSM8K":0.23,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.08,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/Minueza-32Mx2-Chat",
        "Average":28.12,
        "ARC":20.14,
        "HellaSwag":26.36,
        "MMLU":26.07,
        "TruthfulQA":44.56,
        "Winogrande":51.62,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.04,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/math_gpt2_sft",
        "Average":28.03,
        "ARC":22.87,
        "HellaSwag":30.41,
        "MMLU":25.06,
        "TruthfulQA":37.62,
        "Winogrande":51.54,
        "GSM8K":0.68,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/Med_GPT2",
        "Average":28.02,
        "ARC":23.38,
        "HellaSwag":30.99,
        "MMLU":24.0,
        "TruthfulQA":38.95,
        "Winogrande":49.72,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"MBZUAI\/LaMini-GPT-124M",
        "Average":28.01,
        "ARC":24.32,
        "HellaSwag":30.82,
        "MMLU":24.99,
        "TruthfulQA":36.57,
        "Winogrande":51.38,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":0.12,
        "Model Sha":17.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Sharathhebbar24\/chat_gpt2",
        "Average":27.99,
        "ARC":23.04,
        "HellaSwag":30.76,
        "MMLU":24.39,
        "TruthfulQA":39.81,
        "Winogrande":49.96,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Locutusque\/LocutusqueXFelladrin-TinyMistral248M-Instruct",
        "Average":27.98,
        "ARC":24.74,
        "HellaSwag":27.79,
        "MMLU":26.12,
        "TruthfulQA":40.12,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":6.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shitshow123\/tinylamma-20000",
        "Average":27.95,
        "ARC":23.81,
        "HellaSwag":32.45,
        "MMLU":25.37,
        "TruthfulQA":34.87,
        "Winogrande":51.22,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.1,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Average":27.95,
        "ARC":20.48,
        "HellaSwag":28.09,
        "MMLU":24.47,
        "TruthfulQA":46.47,
        "Winogrande":48.22,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"BloomModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"M4-ai\/TinyMistral-6x248M-Instruct",
        "Average":27.89,
        "ARC":22.44,
        "HellaSwag":27.02,
        "MMLU":24.13,
        "TruthfulQA":43.16,
        "Winogrande":50.59,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.0,
        "Model Sha":8.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Mikivis\/xuanxuan",
        "Average":27.88,
        "ARC":23.46,
        "HellaSwag":31.12,
        "MMLU":26.27,
        "TruthfulQA":35.97,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"vicgalle\/gpt2-alpaca",
        "Average":27.86,
        "ARC":22.87,
        "HellaSwag":31.14,
        "MMLU":26.26,
        "TruthfulQA":36.22,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":0.14,
        "Model Sha":9.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aisquared\/dlite-v1-124m",
        "Average":27.86,
        "ARC":24.32,
        "HellaSwag":31.16,
        "MMLU":25.08,
        "TruthfulQA":36.38,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"psyche\/kogpt",
        "Average":27.83,
        "ARC":21.16,
        "HellaSwag":28.11,
        "MMLU":26.56,
        "TruthfulQA":42.06,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.39,
        "Model Sha":4.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Average":27.75,
        "ARC":20.22,
        "HellaSwag":26.73,
        "MMLU":25.51,
        "TruthfulQA":46.31,
        "Winogrande":47.75,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"?",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.11,
        "Model Sha":71.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Locutusque\/TinyMistral-248m",
        "Average":27.73,
        "ARC":22.87,
        "HellaSwag":28.02,
        "MMLU":23.15,
        "TruthfulQA":42.52,
        "Winogrande":49.8,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":0.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Locutusque\/TinyMistral-248M-v2.5-Instruct",
        "Average":27.7,
        "ARC":22.27,
        "HellaSwag":27.6,
        "MMLU":23.9,
        "TruthfulQA":44.21,
        "Winogrande":48.22,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"ai-forever\/mGPT",
        "Average":27.61,
        "ARC":23.81,
        "HellaSwag":26.37,
        "MMLU":25.17,
        "TruthfulQA":39.62,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":220.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Corianas\/111m",
        "Average":27.6,
        "ARC":19.71,
        "HellaSwag":26.68,
        "MMLU":25.28,
        "TruthfulQA":43.72,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":0.15,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"huashiyiqike\/testmodel",
        "Average":27.6,
        "ARC":19.71,
        "HellaSwag":26.68,
        "MMLU":25.28,
        "TruthfulQA":43.72,
        "Winogrande":50.2,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-sa-4.0",
        "Available on the Hub":0.15,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/TinyMistral-248M-Chat-v2",
        "Average":27.42,
        "ARC":23.29,
        "HellaSwag":27.39,
        "MMLU":23.52,
        "TruthfulQA":41.32,
        "Winogrande":49.01,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":25.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Felladrin\/TinyMistral-248M-Chat-v1",
        "Average":27.01,
        "ARC":21.59,
        "HellaSwag":27.45,
        "MMLU":23.08,
        "TruthfulQA":40.91,
        "Winogrande":49.01,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"khyat\/gujju-llama-instruct-v1.0",
        "Average":25.41,
        "ARC":24.49,
        "HellaSwag":51.24,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":53.59,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.88,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"OpenBuddy\/openbuddy-mixtral-7bx8-v17.2-32k",
        "Average":23.07,
        "ARC":33.53,
        "HellaSwag":31.36,
        "MMLU":17.8,
        "TruthfulQA":0.0,
        "Winogrande":55.72,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.74,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"databricks\/dolly-v2-3b",
        "Average":22.83,
        "ARC":25.26,
        "HellaSwag":26.55,
        "MMLU":24.7,
        "TruthfulQA":0.0,
        "Winogrande":59.43,
        "GSM8K":1.06,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":3.0,
        "Model Sha":276.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral-7b-v2-selfplay-v0",
        "Average":22.68,
        "ARC":29.44,
        "HellaSwag":26.17,
        "MMLU":25.38,
        "TruthfulQA":0.0,
        "Winogrande":55.09,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/Nexus-IKM-Hermes-2-Pro-Mistral-7B",
        "Average":22.65,
        "ARC":29.27,
        "HellaSwag":29.33,
        "MMLU":25.16,
        "TruthfulQA":0.0,
        "Winogrande":52.17,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.11,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/Nexus-IKM-Mistral-7B-v5-instruction",
        "Average":22.48,
        "ARC":27.73,
        "HellaSwag":28.93,
        "MMLU":24.69,
        "TruthfulQA":0.0,
        "Winogrande":53.51,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"v1olet\/v1olet_marcoroni-go-bruins-7B",
        "Average":22.43,
        "ARC":29.1,
        "HellaSwag":28.3,
        "MMLU":25.09,
        "TruthfulQA":0.0,
        "Winogrande":52.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Severian\/Mistral-v0.2-Nexus-Internal-Knowledge-Map-7B",
        "Average":22.29,
        "ARC":29.27,
        "HellaSwag":28.82,
        "MMLU":24.98,
        "TruthfulQA":0.0,
        "Winogrande":50.67,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"v1olet\/v1olet_mistral_7B",
        "Average":22.16,
        "ARC":29.18,
        "HellaSwag":28.13,
        "MMLU":26.24,
        "TruthfulQA":0.0,
        "Winogrande":49.41,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"FelixChao\/Magician-MoE-4x7B",
        "Average":22.14,
        "ARC":28.24,
        "HellaSwag":30.06,
        "MMLU":24.67,
        "TruthfulQA":0.0,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":19.73,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"azarafrooz\/mistral2-sp-lima-test",
        "Average":21.78,
        "ARC":29.44,
        "HellaSwag":26.16,
        "MMLU":25.38,
        "TruthfulQA":0.0,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"Adapter",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Average":21.78,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":59.67,
        "GSM8K":0.15,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"mit",
        "Available on the Hub":1.3,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"KevinNi\/mistral-class-bio-tutor",
        "Average":21.59,
        "ARC":28.07,
        "HellaSwag":28.02,
        "MMLU":23.79,
        "TruthfulQA":0.0,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.11,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"maximuslee07\/llama-2-13b-rockwellautomation",
        "Average":21.48,
        "ARC":28.16,
        "HellaSwag":25.77,
        "MMLU":25.14,
        "TruthfulQA":0.0,
        "Winogrande":49.8,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"jslin09\/bloom-560m-finetuned-fraud",
        "Average":21.37,
        "ARC":26.96,
        "HellaSwag":28.87,
        "MMLU":24.03,
        "TruthfulQA":0.0,
        "Winogrande":48.38,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"bigscience-bloom-rail-1.0",
        "Available on the Hub":0.56,
        "Model Sha":2.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ahnyeonchan\/OpenOrca-AYT-13B",
        "Average":21.35,
        "ARC":27.22,
        "HellaSwag":26.03,
        "MMLU":25.11,
        "TruthfulQA":0.0,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"llama2",
        "Available on the Hub":13.02,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/alignment-handbook-zephyr-7b_ppostep_100",
        "Average":21.3,
        "ARC":29.27,
        "HellaSwag":25.87,
        "MMLU":23.76,
        "TruthfulQA":0.0,
        "Winogrande":48.93,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Andron00e\/YetAnother_Open-Llama-3B-LoRA",
        "Average":21.29,
        "ARC":25.94,
        "HellaSwag":25.76,
        "MMLU":24.65,
        "TruthfulQA":0.0,
        "Winogrande":51.38,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"Andron00e\/YetAnother_Open-Llama-3B-LoRA-OpenOrca",
        "Average":21.2,
        "ARC":25.94,
        "HellaSwag":25.76,
        "MMLU":24.65,
        "TruthfulQA":0.0,
        "Winogrande":50.83,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":3.43,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Dampish\/Dante-2.8B",
        "Average":21.12,
        "ARC":25.09,
        "HellaSwag":26.05,
        "MMLU":24.51,
        "TruthfulQA":0.0,
        "Winogrande":51.07,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":2.8,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"juhwanlee\/gemma-7B-alpaca-case-3-3",
        "Average":21.06,
        "ARC":25.0,
        "HellaSwag":26.22,
        "MMLU":24.73,
        "TruthfulQA":0.0,
        "Winogrande":50.43,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GemmaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":8.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"BreadAi\/MuseCan",
        "Average":21.06,
        "ARC":28.07,
        "HellaSwag":25.0,
        "MMLU":24.19,
        "TruthfulQA":0.0,
        "Winogrande":49.09,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":null,
        "Available on the Hub":0.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"team-lucid\/mptk-1b",
        "Average":20.76,
        "ARC":22.7,
        "HellaSwag":25.11,
        "MMLU":27.02,
        "TruthfulQA":0.0,
        "Winogrande":49.72,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MptForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":1.31,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openbmb\/MiniCPM-2B-dpo-bf16-llama-format",
        "Average":20.67,
        "ARC":25.6,
        "HellaSwag":22.42,
        "MMLU":24.24,
        "TruthfulQA":0.0,
        "Winogrande":51.78,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":2.72,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mindy-labs\/mindy-7b",
        "Average":20.52,
        "ARC":23.63,
        "HellaSwag":25.82,
        "MMLU":24.15,
        "TruthfulQA":0.0,
        "Winogrande":49.49,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test",
        "Average":20.45,
        "ARC":23.04,
        "HellaSwag":25.23,
        "MMLU":23.28,
        "TruthfulQA":0.0,
        "Winogrande":51.14,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"amu\/zen",
        "Average":20.33,
        "ARC":23.98,
        "HellaSwag":25.08,
        "MMLU":23.26,
        "TruthfulQA":0.0,
        "Winogrande":49.64,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"alnrg2arg\/test_wanda_240109",
        "Average":20.24,
        "ARC":22.95,
        "HellaSwag":25.26,
        "MMLU":23.32,
        "TruthfulQA":0.0,
        "Winogrande":49.88,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"cc-by-nc-4.0",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"antiven0m\/brugle-rp",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"unknown",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"ewqr2130\/mistral-moe-scratch",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abhishek\/autotrain-c71ux-tngfu",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":7.24,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"abideen\/phi2-pro",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"PhiForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":2.78,
        "Model Sha":7.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TheTravellingEngineer\/bloom-1b1-RLHF-v2",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"",
        "Available on the Hub":1.0,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"aiplanet\/panda-coder-13B",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"4bit",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":13.0,
        "Model Sha":11.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shitshow123\/stablelm_sft_dpo",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.87,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"kyujinpy\/Sakura-SOLAR-Instruct-DPO-v1",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Unknown",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":10.73,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"uukuguy\/speechless-mistral-six-in-one-7b-orth-1.0",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"shitshow123\/moe_scratch",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":46.7,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"xdatasi\/antares-7b-slovenian",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":6.74,
        "Model Sha":2.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"RatanRohith\/NeuralPizza-7B-Merge-Slerp",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.92,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"MatthieuJ\/Forbin_13B_M1_SLERP",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"AbacusResearch\/jaLLAbi",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":14.36,
        "Model Sha":0.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"kihoonlee\/Merge-13B-v1-test",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":11.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"mathurinache\/Odysseas-11B",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"wtang06\/mpt-125m-c4",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"pretrained",
        "Architecture":"MPTForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.12,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"blueRab2it\/Godrick_7Bx2_MoE_13B-v0.1",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":11.54,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"RESMPDEV\/Mistral-7B-v0.2",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":7.24,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"RatanRohith\/NeuralPizza-Valor-7B-Merge-slerp",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.92,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mathurinache\/Odysseas-11B",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"apache-2.0",
        "Available on the Hub":0.48,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"dfurman\/llama-2-13b-dolphin-peft",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"Unknown",
        "Precision":"Adapter",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"?",
        "Available on the Hub":13.0,
        "Model Sha":0.0
    },
    {
        "T":"?",
        "Model":"Rardilit\/Panther_v1",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"",
        "Architecture":"LLaMAForCausalLM",
        "Precision":"Delta",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"other",
        "Available on the Hub":0.0,
        "Model Sha":1.0
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rizla\/rizla-11",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"base merges and moerges",
        "Architecture":"MixtralForCausalLM",
        "Precision":"Original",
        "Hub License":"bfloat16",
        "#Params (B)":true,
        "Hub":"cc-by-nc-2.0",
        "Available on the Hub":9.42,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"APMIC\/caigun-lora-model-33B",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"8bit",
        "#Params (B)":false,
        "Hub":"cc-by-nc-nd-4.0",
        "Available on the Hub":18.25,
        "Model Sha":0.0
    },
    {
        "T":"\ud83d\udd36",
        "Model":"clibrain\/Llama-2-ft-instruct-es",
        "Average":20.07,
        "ARC":22.7,
        "HellaSwag":25.04,
        "MMLU":23.12,
        "TruthfulQA":0.0,
        "Winogrande":49.57,
        "GSM8K":0.0,
        "Type":"fine-tuned on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"Original",
        "Hub License":"float16",
        "#Params (B)":false,
        "Hub":"apache-2.0",
        "Available on the Hub":0.0,
        "Model Sha":18.0
    }
]