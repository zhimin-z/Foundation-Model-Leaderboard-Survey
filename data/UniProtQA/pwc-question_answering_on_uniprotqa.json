[
    {
        "table_id":24909,
        "row_id":108175,
        "rank":1,
        "Model":"BioMedGPT-10B",
        "mlmodel":{

        },
        "method_short":"BioMedGPT-10B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "BLEU-2":"0.571",
            "BLEU-4":"0.535",
            "ROUGE-1":"0.743",
            "ROUGE-2":"0.759",
            "ROUGE-L":"0.622",
            "MEATOR":"0.754"
        },
        "raw_metrics":{
            "BLEU-2":0.571,
            "BLEU-4":0.535,
            "ROUGE-1":0.743,
            "ROUGE-2":0.759,
            "ROUGE-L":0.622,
            "MEATOR":0.754
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265550,
            "title":"BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine",
            "url":"\/paper\/biomedgpt-open-multimodal-generative-pre",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biomedgpt-open-multimodal-generative-pre\/review\/?hl=108175"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":24909,
        "row_id":108176,
        "rank":2,
        "Model":"Llama2-7B-chat",
        "mlmodel":{

        },
        "method_short":"Llama2-7B-chat",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-18",
        "metrics":{
            "BLEU-2":"0.019",
            "BLEU-4":"0.002",
            "ROUGE-1":"0.103",
            "ROUGE-2":"0.060",
            "ROUGE-L":"0.009",
            "MEATOR":"0.052"
        },
        "raw_metrics":{
            "BLEU-2":0.019,
            "BLEU-4":0.002,
            "ROUGE-1":0.103,
            "ROUGE-2":0.06,
            "ROUGE-L":0.009,
            "MEATOR":0.052
        },
        "uses_additional_data":false,
        "paper":{
            "id":1248363,
            "title":"Llama 2: Open Foundation and Fine-Tuned Chat Models",
            "url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat",
            "published":"2023-07-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat\/review\/?hl=108176"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    }
]