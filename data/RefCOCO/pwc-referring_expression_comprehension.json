[
    {
        "table_id":8606,
        "row_id":99111,
        "rank":1,
        "method":"UNINEXT-H",
        "mlmodel":{

        },
        "method_short":"UNINEXT-H",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-12",
        "metrics":{
            "Test A":"94.33",
            "Test B":"91.46",
            "Val":"92.64"
        },
        "raw_metrics":{
            "Test A":94.33,
            "Test B":91.46,
            "Val":92.64
        },
        "uses_additional_data":true,
        "paper":{
            "id":1172341,
            "title":"Universal Instance Perception as Object Discovery and Retrieval",
            "url":"\/paper\/universal-instance-perception-as-object",
            "published":"2023-03-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/universal-instance-perception-as-object\/review\/?hl=99111"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":103007,
        "rank":2,
        "method":"ONE-PEACE",
        "mlmodel":{

        },
        "method_short":"ONE-PEACE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-18",
        "metrics":{
            "Test A":"94.18",
            "Test B":"89.26",
            "Val":"92.58"
        },
        "raw_metrics":{
            "Test A":94.18,
            "Test B":89.26,
            "Val":92.58
        },
        "uses_additional_data":true,
        "paper":{
            "id":1211430,
            "title":"ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities",
            "url":"\/paper\/one-peace-exploring-one-general",
            "published":"2023-05-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/one-peace-exploring-one-general\/review\/?hl=103007"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":47711,
        "rank":3,
        "method":"OFA",
        "mlmodel":{

        },
        "method_short":"OFA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-07",
        "metrics":{
            "Test A":"94.03",
            "Test B":"88.44",
            "Val":"92.04"
        },
        "raw_metrics":{
            "Test A":94.03,
            "Test B":88.44,
            "Val":92.04
        },
        "uses_additional_data":true,
        "paper":{
            "id":956719,
            "title":"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework",
            "url":"\/paper\/unifying-architectures-tasks-and-modalities",
            "published":"2022-02-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unifying-architectures-tasks-and-modalities\/review\/?hl=47711"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":99412,
        "rank":4,
        "method":"PolyFormer-L",
        "mlmodel":{

        },
        "method_short":"PolyFormer-L",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-14",
        "metrics":{
            "Test A":"92.89",
            "Test B":"87.16",
            "Val":"90.38"
        },
        "raw_metrics":{
            "Test A":92.89,
            "Test B":87.16,
            "Val":90.38
        },
        "uses_additional_data":true,
        "paper":{
            "id":1158471,
            "title":"PolyFormer: Referring Image Segmentation as Sequential Polygon Generation",
            "url":"\/paper\/polyformer-referring-image-segmentation-as",
            "published":"2023-02-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/polyformer-referring-image-segmentation-as\/review\/?hl=99412"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":99413,
        "rank":5,
        "method":"PolyFormer-B",
        "mlmodel":{

        },
        "method_short":"PolyFormer-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-14",
        "metrics":{
            "Test A":"91.73",
            "Test B":"86.03",
            "Val":"89.73"
        },
        "raw_metrics":{
            "Test A":91.73,
            "Test B":86.03,
            "Val":89.73
        },
        "uses_additional_data":true,
        "paper":{
            "id":1158471,
            "title":"PolyFormer: Referring Image Segmentation as Sequential Polygon Generation",
            "url":"\/paper\/polyformer-referring-image-segmentation-as",
            "published":"2023-02-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/polyformer-referring-image-segmentation-as\/review\/?hl=99413"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":87283,
        "rank":6,
        "method":"DQ-DETR(R101)",
        "mlmodel":{

        },
        "method_short":"DQ-DETR",
        "method_details":"R101",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-28",
        "metrics":{
            "Test A":"91.04",
            "Test B":"83.51",
            "Val":"88.63"
        },
        "raw_metrics":{
            "Test A":91.04,
            "Test B":83.51,
            "Val":88.63
        },
        "uses_additional_data":false,
        "paper":{
            "id":1118747,
            "title":"DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding",
            "url":"\/paper\/dq-detr-dual-query-detection-transformer-for",
            "published":"2022-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/dq-detr-dual-query-detection-transformer-for\/review\/?hl=87283"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":30948,
        "rank":7,
        "method":"MDETR-ENB3",
        "mlmodel":{

        },
        "method_short":"MDETR-ENB3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-26",
        "metrics":{
            "Test A":"90.4",
            "Test B":"82.67",
            "Val":"87.51"
        },
        "raw_metrics":{
            "Test A":90.4,
            "Test B":82.67,
            "Val":87.51
        },
        "uses_additional_data":false,
        "paper":{
            "id":788341,
            "title":"MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding",
            "url":"\/paper\/mdetr-modulated-detection-for-end-to-end",
            "published":"2021-04-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mdetr-modulated-detection-for-end-to-end\/review\/?hl=30948"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":40726,
        "rank":8,
        "method":"Deformerable-MDETR",
        "mlmodel":{

        },
        "method_short":"Deformerable-MDETR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-26",
        "metrics":{
            "Test A":"89.16",
            "Test B":"83.00",
            "Val":"86.54"
        },
        "raw_metrics":{
            "Test A":89.16,
            "Test B":83.0,
            "Val":86.54
        },
        "uses_additional_data":false,
        "paper":{
            "id":788341,
            "title":"MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding",
            "url":"\/paper\/mdetr-modulated-detection-for-end-to-end",
            "published":"2021-04-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mdetr-modulated-detection-for-end-to-end\/review\/?hl=40726"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":14,
                "name":"DCN",
                "color":"#2771D3"
            },
            {
                "id":122,
                "name":"CycleMLP",
                "color":"#2771D3"
            },
            {
                "id":123,
                "name":"DeformableDetr",
                "color":"#27d371"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":73206,
        "rank":9,
        "method":"RefTR-PT",
        "mlmodel":{

        },
        "method_short":"RefTR-PT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-06",
        "metrics":{
            "Test A":"88.73",
            "Test B":"81.16",
            "Val":"85.65"
        },
        "raw_metrics":{
            "Test A":88.73,
            "Test B":81.16,
            "Val":85.65
        },
        "uses_additional_data":false,
        "paper":{
            "id":812506,
            "title":"Referring Transformer: A One-step Approach to Multi-task Visual Grounding",
            "url":"\/paper\/referring-transformer-a-one-step-approach-to",
            "published":"2021-06-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/referring-transformer-a-one-step-approach-to\/review\/?hl=73206"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":54,
                "name":"ResNet-101",
                "color":"#cc1e1e"
            },
            {
                "id":59,
                "name":"Multitask",
                "color":"#46b3d8"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":30950,
        "rank":10,
        "method":"VILLA-large",
        "mlmodel":{

        },
        "method_short":"VILLA-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-11",
        "metrics":{
            "Test A":"87.48",
            "Test B":"74.84",
            "Val":"82.39"
        },
        "raw_metrics":{
            "Test A":87.48,
            "Test B":74.84,
            "Val":82.39
        },
        "uses_additional_data":false,
        "paper":{
            "id":201836,
            "title":"Large-Scale Adversarial Training for Vision-and-Language Representation Learning",
            "url":"\/paper\/large-scale-adversarial-training-for-vision",
            "published":"2020-06-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-adversarial-training-for-vision\/review\/?hl=30950"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":40650,
        "rank":11,
        "method":"UNITER-L",
        "mlmodel":{

        },
        "method_short":"UNITER-L",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-25",
        "metrics":{
            "Test A":"87.04",
            "Test B":"74.17",
            "Val":"81.41"
        },
        "raw_metrics":{
            "Test A":87.04,
            "Test B":74.17,
            "Val":81.41
        },
        "uses_additional_data":false,
        "paper":{
            "id":156206,
            "title":"UNITER: UNiversal Image-TExt Representation Learning",
            "url":"\/paper\/uniter-learning-universal-image-text-1",
            "published":"2019-09-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uniter-learning-universal-image-text-1\/review\/?hl=40650"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":73207,
        "rank":12,
        "method":"RefTR",
        "mlmodel":{

        },
        "method_short":"RefTR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-06",
        "metrics":{
            "Test A":"85.59",
            "Test B":"76.57",
            "Val":"82.23"
        },
        "raw_metrics":{
            "Test A":85.59,
            "Test B":76.57,
            "Val":82.23
        },
        "uses_additional_data":false,
        "paper":{
            "id":812506,
            "title":"Referring Transformer: A One-step Approach to Multi-task Visual Grounding",
            "url":"\/paper\/referring-transformer-a-one-step-approach-to",
            "published":"2021-06-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/referring-transformer-a-one-step-approach-to\/review\/?hl=73207"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8606,
        "row_id":40649,
        "rank":13,
        "method":"TransVG",
        "mlmodel":{

        },
        "method_short":"TransVG",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-17",
        "metrics":{
            "Test A":"82.72",
            "Test B":"78.35",
            "Val":"81.02"
        },
        "raw_metrics":{
            "Test A":82.72,
            "Test B":78.35,
            "Val":81.02
        },
        "uses_additional_data":false,
        "paper":{
            "id":784424,
            "title":"TransVG: End-to-End Visual Grounding with Transformers",
            "url":"\/paper\/transvg-end-to-end-visual-grounding-with",
            "published":"2021-04-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/transvg-end-to-end-visual-grounding-with\/review\/?hl=40649"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":54,
                "name":"ResNet-101",
                "color":"#cc1e1e"
            },
            {
                "id":59,
                "name":"Multitask",
                "color":"#46b3d8"
            }
        ],
        "reports":[

        ]
    }
]