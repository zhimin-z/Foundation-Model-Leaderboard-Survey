[
    {
        "Model":"GPT-4 Turbo\u00a0\ud83d\udcc4",
        "Win Rate":"97.70%",
        "Length":2049
    },
    {
        "Model":"XwinLM 70b V0.1\u00a0\ud83d\udcc4",
        "Win Rate":"95.57%",
        "Length":1775
    },
    {
        "Model":"GPT-4\u00a0\ud83d\udcc4",
        "Win Rate":"95.28%",
        "Length":1365
    },
    {
        "Model":"LLaMA2 Chat 70B\u00a0\ud83d\udcc4",
        "Win Rate":"92.66%",
        "Length":1790
    },
    {
        "Model":"UltraLM 13B V2.0 (best-of-16)\u00a0\ud83d\udcc4",
        "Win Rate":"92.30%",
        "Length":1720
    },
    {
        "Model":"XwinLM 13b V0.1\u00a0\ud83d\udcc4",
        "Win Rate":"91.76%",
        "Length":1894
    },
    {
        "Model":"UltraLM 13B (best-of-16)\u00a0\ud83d\udcc4",
        "Win Rate":"91.54%",
        "Length":1980
    },
    {
        "Model":"Cohere Command\u00a0\ud83d\udcc4",
        "Win Rate":"91.49%",
        "Length":2012
    },
    {
        "Model":"Claude 2\u00a0\ud83d\udcc4",
        "Win Rate":"91.36%",
        "Length":1069
    },
    {
        "Model":"Zephyr 7B Beta\u00a0\ud83d\udcc4",
        "Win Rate":"90.60%",
        "Length":1444
    },
    {
        "Model":"OpenChat V3.1 13B\u00a0\ud83d\udcc4",
        "Win Rate":"89.49%",
        "Length":1484
    },
    {
        "Model":"ChatGPT\u00a0\ud83d\udcc4",
        "Win Rate":"89.37%",
        "Length":827
    },
    {
        "Model":"Evo v2 7B\u00a0\ud83d\udcc4",
        "Win Rate":"89.35%",
        "Length":1754
    },
    {
        "Model":"WizardLM 13B V1.2\u00a0\ud83d\udcc4",
        "Win Rate":"89.17%",
        "Length":1635
    },
    {
        "Model":"Vicuna 33B v1.3\u00a0\ud83d\udcc4",
        "Win Rate":"88.99%",
        "Length":1479
    },
    {
        "Model":"Claude\u00a0\ud83d\udcc4",
        "Win Rate":"88.39%",
        "Length":1082
    },
    {
        "Model":"CausalLM-14B\u00a0\ud83d\udcc4",
        "Win Rate":"88.26%",
        "Length":1391
    },
    {
        "Model":"Humpback LLaMa2 70B\u00a0\ud83d\udcc4",
        "Win Rate":"87.94%",
        "Length":1822
    },
    {
        "Model":"XwinLM 7b V0.1\u00a0\ud83d\udcc4",
        "Win Rate":"87.83%",
        "Length":1894
    },
    {
        "Model":"OpenBudddy-LLaMA2-70B-v10.1\u00a0\ud83d\udcc4",
        "Win Rate":"87.67%",
        "Length":1077
    },
    {
        "Model":"OpenChat V2-W 13B\u00a0\ud83d\udcc4",
        "Win Rate":"87.13%",
        "Length":1566
    },
    {
        "Model":"OpenBuddy-LLaMA-65B-v8\u00a0\ud83d\udcc4",
        "Win Rate":"86.53%",
        "Length":1162
    },
    {
        "Model":"WizardLM 13B V1.1\u00a0\ud83d\udcc4",
        "Win Rate":"86.32%",
        "Length":1525
    },
    {
        "Model":"Zephyr 7B Alpha\u00a0\ud83d\udcc4",
        "Win Rate":"85.76%",
        "Length":1302
    },
    {
        "Model":"OpenChat V2 13B\u00a0\ud83d\udcc4",
        "Win Rate":"84.97%",
        "Length":1564
    },
    {
        "Model":"Humpback LLaMa 65B\u00a0\ud83d\udcc4",
        "Win Rate":"83.71%",
        "Length":1269
    },
    {
        "Model":"UltraLM 13B V2.0",
        "Win Rate":"83.60%",
        "Length":1399
    },
    {
        "Model":"Recycled WizardLM 7B V2.0\u00a0\ud83d\udcc4",
        "Win Rate":"83.48%",
        "Length":1583
    },
    {
        "Model":"Vicuna 13B v1.3\u00a0\ud83d\udcc4",
        "Win Rate":"82.11%",
        "Length":1132
    },
    {
        "Model":"LLaMA2 Chat 7B Evol70k-NEFT\u00a0\ud83d\udcc4",
        "Win Rate":"82.09%",
        "Length":1612
    },
    {
        "Model":"PlatoLM 7B\u00a0\ud83d\udcc4",
        "Win Rate":"81.94%",
        "Length":1344
    },
    {
        "Model":"GPT-3.5\u00a0\ud83d\udcc4",
        "Win Rate":"81.71%",
        "Length":1018
    },
    {
        "Model":"OpenBuddy-LLaMA-30B-v7.1\u00a0\ud83d\udcc4",
        "Win Rate":"81.55%",
        "Length":968
    },
    {
        "Model":"LLaMA2 Chat 13B\u00a0\ud83d\udcc4",
        "Win Rate":"81.09%",
        "Length":1513
    },
    {
        "Model":"OpenChat-13B\u00a0\ud83d\udcc4",
        "Win Rate":"80.87%",
        "Length":1632
    },
    {
        "Model":"OpenBuddy-Falcon-40B-v9\u00a0\ud83d\udcc4",
        "Win Rate":"80.70%",
        "Length":1089
    },
    {
        "Model":"UltraLM 13B\u00a0\ud83d\udcc4",
        "Win Rate":"80.64%",
        "Length":1087
    },
    {
        "Model":"OpenChat8192-13B\u00a0\ud83d\udcc4",
        "Win Rate":"79.54%",
        "Length":1664
    },
    {
        "Model":"Evo 7B\u00a0\ud83d\udcc4",
        "Win Rate":"79.20%",
        "Length":1774
    },
    {
        "Model":"Claude2 Alpaca 13B\u00a0\ud83d\udcc4",
        "Win Rate":"78.93%",
        "Length":1127
    },
    {
        "Model":"Recycled WizardLM 7B V1.0\u00a0\ud83d\udcc4",
        "Win Rate":"78.88%",
        "Length":1494
    },
    {
        "Model":"OpenCoderPlus-15B\u00a0\ud83d\udcc4",
        "Win Rate":"78.70%",
        "Length":1628
    },
    {
        "Model":"OpenBudddy-LLaMA2-13B-v11.1\u00a0\ud83d\udcc4",
        "Win Rate":"77.49%",
        "Length":1057
    },
    {
        "Model":"Vicuna 7B v1.3\u00a0\ud83d\udcc4",
        "Win Rate":"76.84%",
        "Length":1110
    },
    {
        "Model":"WizardLM 13B\u00a0\ud83d\udcc4",
        "Win Rate":"75.31%",
        "Length":985
    },
    {
        "Model":"JinaChat\u00a0\ud83d\udcc4",
        "Win Rate":"74.13%",
        "Length":676
    },
    {
        "Model":"airoboros 65B\u00a0\ud83d\udcc4",
        "Win Rate":"73.91%",
        "Length":1512
    },
    {
        "Model":"airoboros 33B\u00a0\ud83d\udcc4",
        "Win Rate":"73.29%",
        "Length":1514
    },
    {
        "Model":"Guanaco 65B\u00a0\ud83d\udcc4",
        "Win Rate":"71.80%",
        "Length":1249
    },
    {
        "Model":"LLaMA2 Chat 7B\u00a0\ud83d\udcc4",
        "Win Rate":"71.37%",
        "Length":1479
    },
    {
        "Model":"Vicuna 13B\u00a0\ud83d\udcc4",
        "Win Rate":"70.43%",
        "Length":1037
    },
    {
        "Model":"OpenBuddy-Falcon-7b-v6\u00a0\ud83d\udcc4",
        "Win Rate":"70.36%",
        "Length":1152
    },
    {
        "Model":"Baize-v2 13B\u00a0\ud83d\udcc4",
        "Win Rate":"66.96%",
        "Length":930
    },
    {
        "Model":"LLaMA 33B OASST RLHF\u00a0\ud83d\udcc4",
        "Win Rate":"66.52%",
        "Length":1079
    },
    {
        "Model":"Minotaur 13B\u00a0\ud83d\udcc4",
        "Win Rate":"66.02%",
        "Length":881
    },
    {
        "Model":"Guanaco 33B\u00a0\ud83d\udcc4",
        "Win Rate":"65.96%",
        "Length":1311
    },
    {
        "Model":"Nous Hermes 13B\u00a0\ud83d\udcc4",
        "Win Rate":"65.47%",
        "Length":844
    },
    {
        "Model":"Vicuna 7B\u00a0\ud83d\udcc4",
        "Win Rate":"64.41%",
        "Length":1044
    },
    {
        "Model":"Baize-v2 7B\u00a0\ud83d\udcc4",
        "Win Rate":"63.85%",
        "Length":1127
    },
    {
        "Model":"Alpaca-7B-NEFT\u00a0\ud83d\udcc4",
        "Win Rate":"61.92%",
        "Length":1067
    },
    {
        "Model":"LLaMA 33B OASST SFT\u00a0\ud83d\udcc4",
        "Win Rate":"54.97%",
        "Length":748
    },
    {
        "Model":"Guanaco 13B\u00a0\ud83d\udcc4",
        "Win Rate":"52.61%",
        "Length":1774
    },
    {
        "Model":"Davinci003\u00a0\ud83d\udcc4",
        "Win Rate":"50.00%",
        "Length":307
    },
    {
        "Model":"ChatGLM2-6B\u00a0\ud83d\udcc4",
        "Win Rate":"47.13%",
        "Length":1027
    },
    {
        "Model":"Guanaco 7B\u00a0\ud83d\udcc4",
        "Win Rate":"46.58%",
        "Length":1364
    },
    {
        "Model":"Falcon 40B Instruct\u00a0\ud83d\udcc4",
        "Win Rate":"45.71%",
        "Length":662
    },
    {
        "Model":"Alpaca Farm PPO Sim (GPT-4) 7B\u00a0\ud83d\udcc4",
        "Win Rate":"44.10%",
        "Length":511
    },
    {
        "Model":"Pythia 12B SFT\u00a0\ud83d\udcc4",
        "Win Rate":"41.86%",
        "Length":913
    },
    {
        "Model":"Alpaca Farm PPO Human 7B\u00a0\ud83d\udcc4",
        "Win Rate":"41.24%",
        "Length":803
    },
    {
        "Model":"Alpaca 7B\u00a0\ud83d\udcc4",
        "Win Rate":"26.46%",
        "Length":396
    },
    {
        "Model":"Pythia 12B OASST SFT\u00a0\ud83d\udcc4",
        "Win Rate":"25.96%",
        "Length":726
    },
    {
        "Model":"Falcon 7B Instruct\u00a0\ud83d\udcc4",
        "Win Rate":"23.60%",
        "Length":478
    },
    {
        "Model":"Baichuan-13B-Chat\u00a0\ud83d\udcc4",
        "Win Rate":"21.80%",
        "Length":1727
    },
    {
        "Model":"Davinci001\u00a0\ud83d\udcc4",
        "Win Rate":"15.17%",
        "Length":296
    }
]