[
    {
        "table_id":12343,
        "row_id":107355,
        "rank":1,
        "Model":"ONE-PEACE (Audio-Visual)",
        "mlmodel":{

        },
        "method_short":"ONE-PEACE ",
        "method_details":"Audio-Visual",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-18",
        "metrics":{
            "Top 1 Accuracy":"68.2",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.2,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1211430,
            "title":"ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities",
            "url":"\/paper\/one-peace-exploring-one-general",
            "published":"2023-05-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/one-peace-exploring-one-general\/review\/?hl=107355"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":104149,
        "rank":2,
        "Model":"MAViL",
        "mlmodel":{

        },
        "method_short":"MAViL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Top 1 Accuracy":"67.1",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":67.1,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":103660,
        "rank":3,
        "Model":"MMT (Audio-Visual)",
        "mlmodel":{

        },
        "method_short":"MMT ",
        "method_details":"Audio-Visual",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-22",
        "metrics":{
            "Top 1 Accuracy":"66.2",
            "Top 5 Accuracy":"85.7",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":66.2,
            "Top 5 Accuracy":85.7,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178632,
            "title":"Multiscale Multimodal Transformer for Multimodal Action Recognition",
            "url":"\/paper\/multiscale-multimodal-transformer-for",
            "published":"2022-09-22T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":100187,
        "rank":4,
        "Model":"CAV-MAE (Audio-Visual)",
        "mlmodel":{

        },
        "method_short":"CAV-MAE ",
        "method_details":"Audio-Visual",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-02",
        "metrics":{
            "Top 1 Accuracy":"65.9",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.9,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1093718,
            "title":"Contrastive Audio-Visual Masked Autoencoder",
            "url":"\/paper\/contrastive-audio-visual-masked-autoencoder",
            "published":"2022-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-audio-visual-masked-autoencoder\/review\/?hl=100187"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":67,
                "name":"Self-Supervised Learning",
                "color":"#d72727"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            },
            {
                "id":88,
                "name":"Multi-modal",
                "color":"#2788d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":97116,
        "rank":5,
        "Model":"UAVM (Audio + Video)",
        "mlmodel":{

        },
        "method_short":"UAVM ",
        "method_details":"Audio + Video",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-29",
        "metrics":{
            "Top 1 Accuracy":"65.8",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.8,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1052495,
            "title":"UAVM: Towards Unifying Audio and Visual Models",
            "url":"\/paper\/uavm-a-unified-model-for-audio-visual",
            "published":"2022-07-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uavm-a-unified-model-for-audio-visual\/review\/?hl=97116"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":88,
                "name":"Multi-modal",
                "color":"#2788d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":106997,
        "rank":6,
        "Model":"Audiovisual Masked Autoencoder  (Audiovisual, Single)",
        "mlmodel":{

        },
        "method_short":"Audiovisual Masked Autoencoder  ",
        "method_details":"Audiovisual, Single",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-09",
        "metrics":{
            "Top 1 Accuracy":"65.0",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.0,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1126937,
            "title":"Audiovisual Masked Autoencoders",
            "url":"\/paper\/audiovisual-masked-autoencoders",
            "published":"2022-12-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/audiovisual-masked-autoencoders\/review\/?hl=106997"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":88,
                "name":"Multi-modal",
                "color":"#2788d3"
            },
            {
                "id":460,
                "name":"Self-supervised learning",
                "color":"#d32727"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":103663,
        "rank":7,
        "Model":"AVT (Audio-Visual)",
        "mlmodel":{

        },
        "method_short":"AVT ",
        "method_details":"Audio-Visual",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-22",
        "metrics":{
            "Top 1 Accuracy":"63.9",
            "Top 5 Accuracy":"85.0",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.9,
            "Top 5 Accuracy":85.0,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178631,
            "title":"AVT: Audio-Video Transformer for Multimodal Action Recognition",
            "url":"\/paper\/avt-audio-video-transformer-for-multimodal",
            "published":"2022-09-22T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":103009,
        "rank":8,
        "Model":"ONE-PEACE (Audio-Only)",
        "mlmodel":{

        },
        "method_short":"ONE-PEACE ",
        "method_details":"Audio-Only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-18",
        "metrics":{
            "Top 1 Accuracy":"59.6",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":59.6,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1211430,
            "title":"ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities",
            "url":"\/paper\/one-peace-exploring-one-general",
            "published":"2023-05-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/one-peace-exploring-one-general\/review\/?hl=103009"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":100188,
        "rank":9,
        "Model":"CAV-MAE (Audio-Only)",
        "mlmodel":{

        },
        "method_short":"CAV-MAE ",
        "method_details":"Audio-Only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-02",
        "metrics":{
            "Top 1 Accuracy":"59.5",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":59.5,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1093718,
            "title":"Contrastive Audio-Visual Masked Autoencoder",
            "url":"\/paper\/contrastive-audio-visual-masked-autoencoder",
            "published":"2022-10-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-audio-visual-masked-autoencoder\/review\/?hl=100188"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":106999,
        "rank":10,
        "Model":"Audiovisual Masked Autoencoder\n(Audio-only, Single)",
        "mlmodel":{

        },
        "method_short":"Audiovisual Masked Autoencoder\n",
        "method_details":"Audio-only, Single",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-09",
        "metrics":{
            "Top 1 Accuracy":"57.2",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":57.2,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1126937,
            "title":"Audiovisual Masked Autoencoders",
            "url":"\/paper\/audiovisual-masked-autoencoders",
            "published":"2022-12-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/audiovisual-masked-autoencoders\/review\/?hl=106999"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":460,
                "name":"Self-supervised learning",
                "color":"#d32727"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":99916,
        "rank":11,
        "Model":"MAST (Audio Only)",
        "mlmodel":{

        },
        "method_short":"MAST ",
        "method_details":"Audio Only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-19",
        "metrics":{
            "Top 1 Accuracy":"57.0",
            "Top 5 Accuracy":"81.3",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":57.0,
            "Top 5 Accuracy":81.3,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1176105,
            "title":"Multiscale Audio Spectrogram Transformer for Efficient Audio Classification",
            "url":"\/paper\/multiscale-audio-spectrogram-transformer-for",
            "published":"2023-03-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/multiscale-audio-spectrogram-transformer-for\/review\/?hl=99916"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":97114,
        "rank":12,
        "Model":"UAVM (Audio Only)",
        "mlmodel":{

        },
        "method_short":"UAVM ",
        "method_details":"Audio Only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-29",
        "metrics":{
            "Top 1 Accuracy":"56.5",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":56.5,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1052495,
            "title":"UAVM: Towards Unifying Audio and Visual Models",
            "url":"\/paper\/uavm-a-unified-model-for-audio-visual",
            "published":"2022-07-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uavm-a-unified-model-for-audio-visual\/review\/?hl=97114"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":103661,
        "rank":13,
        "Model":"MMT (Video)",
        "mlmodel":{

        },
        "method_short":"MMT ",
        "method_details":"Video",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-22",
        "metrics":{
            "Top 1 Accuracy":"56.1",
            "Top 5 Accuracy":"77.9",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":56.1,
            "Top 5 Accuracy":77.9,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178632,
            "title":"Multiscale Multimodal Transformer for Multimodal Action Recognition",
            "url":"\/paper\/multiscale-multimodal-transformer-for",
            "published":"2022-09-22T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":73326,
        "rank":14,
        "Model":"PlayItBackX3",
        "mlmodel":{

        },
        "method_short":"PlayItBackX3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Top 1 Accuracy":"53.7",
            "Top 5 Accuracy":"79.2",
            "Mean AP":"56.1",
            "AUC":"97.8",
            "d-prime":"2.846"
        },
        "raw_metrics":{
            "Top 1 Accuracy":53.7,
            "Top 5 Accuracy":79.2,
            "Mean AP":56.1,
            "AUC":97.8,
            "d-prime":2.846
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097080,
            "title":"Play It Back: Iterative Attention for Audio Recognition",
            "url":"\/paper\/play-it-back-iterative-attention-for-audio",
            "published":"2022-10-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/play-it-back-iterative-attention-for-audio\/review\/?hl=73326"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":103662,
        "rank":15,
        "Model":"AVT (V)",
        "mlmodel":{

        },
        "method_short":"AVT ",
        "method_details":"V",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-22",
        "metrics":{
            "Top 1 Accuracy":"53.2",
            "Top 5 Accuracy":"74.8",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":53.2,
            "Top 5 Accuracy":74.8,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178631,
            "title":"AVT: Audio-Video Transformer for Multimodal Action Recognition",
            "url":"\/paper\/avt-audio-video-transformer-for-multimodal",
            "published":"2022-09-22T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":39620,
        "rank":16,
        "Model":"MBT (A)",
        "mlmodel":{

        },
        "method_short":"MBT ",
        "method_details":"A",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-30",
        "metrics":{
            "Top 1 Accuracy":"52.3",
            "Top 5 Accuracy":"78.1",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":52.3,
            "Top 5 Accuracy":78.1,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":828708,
            "title":"Attention Bottlenecks for Multimodal Fusion",
            "url":"\/paper\/attention-bottlenecks-for-multimodal-fusion",
            "published":"2021-06-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/attention-bottlenecks-for-multimodal-fusion\/review\/?hl=39620"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":39621,
        "rank":17,
        "Model":"MBT (V)",
        "mlmodel":{

        },
        "method_short":"MBT ",
        "method_details":"V",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-30",
        "metrics":{
            "Top 1 Accuracy":"51.2",
            "Top 5 Accuracy":"72.6",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":51.2,
            "Top 5 Accuracy":72.6,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":828708,
            "title":"Attention Bottlenecks for Multimodal Fusion",
            "url":"\/paper\/attention-bottlenecks-for-multimodal-fusion",
            "published":"2021-06-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/attention-bottlenecks-for-multimodal-fusion\/review\/?hl=39621"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":97115,
        "rank":18,
        "Model":"UAVM (Video Only)",
        "mlmodel":{

        },
        "method_short":"UAVM ",
        "method_details":"Video Only",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-29",
        "metrics":{
            "Top 1 Accuracy":"49.9",
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":49.9,
            "Top 5 Accuracy":null,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1052495,
            "title":"UAVM: Towards Unifying Audio and Visual Models",
            "url":"\/paper\/uavm-a-unified-model-for-audio-visual",
            "published":"2022-07-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/uavm-a-unified-model-for-audio-visual\/review\/?hl=97115"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12343,
        "row_id":39622,
        "rank":19,
        "Model":"MBT (AV)",
        "mlmodel":{

        },
        "method_short":"MBT ",
        "method_details":"AV",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-30",
        "metrics":{
            "Top 1 Accuracy":null,
            "Top 5 Accuracy":"85.6",
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":null,
            "Top 5 Accuracy":85.6,
            "Mean AP":null,
            "AUC":null,
            "d-prime":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":828708,
            "title":"Attention Bottlenecks for Multimodal Fusion",
            "url":"\/paper\/attention-bottlenecks-for-multimodal-fusion",
            "published":"2021-06-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/attention-bottlenecks-for-multimodal-fusion\/review\/?hl=39622"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]