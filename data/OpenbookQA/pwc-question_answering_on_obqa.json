[
    {
        "table_id":12181,
        "row_id":118105,
        "rank":1,
        "Model":"FLAN 137B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"FLAN 137B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-03",
        "metrics":{
            "Accuracy":"78.4"
        },
        "raw_metrics":{
            "Accuracy":78.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":861409,
            "title":"Finetuned Language Models Are Zero-Shot Learners",
            "url":"\/paper\/finetuned-language-models-are-zero-shot",
            "published":"2021-09-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/finetuned-language-models-are-zero-shot\/review\/?hl=118105"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":118106,
        "rank":2,
        "Model":"FLAN 137B (few-shot, k=16)",
        "mlmodel":{

        },
        "method_short":"FLAN 137B ",
        "method_details":"few-shot, k=16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-03",
        "metrics":{
            "Accuracy":"78.2"
        },
        "raw_metrics":{
            "Accuracy":78.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":861409,
            "title":"Finetuned Language Models Are Zero-Shot Learners",
            "url":"\/paper\/finetuned-language-models-are-zero-shot",
            "published":"2021-09-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/finetuned-language-models-are-zero-shot\/review\/?hl=118106"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97639,
        "rank":3,
        "Model":"LLaMA 65B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 65B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"60.2"
        },
        "raw_metrics":{
            "Accuracy":60.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97639"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97638,
        "rank":4,
        "Model":"LLaMA 33B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 33B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"58.6"
        },
        "raw_metrics":{
            "Accuracy":58.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97638"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97633,
        "rank":5,
        "Model":"GPT-3 175B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"GPT-3 175B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-28",
        "metrics":{
            "Accuracy":"57.6"
        },
        "raw_metrics":{
            "Accuracy":57.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":198147,
            "title":"Language Models are Few-Shot Learners",
            "url":"\/paper\/language-models-are-few-shot-learners",
            "published":"2020-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/language-models-are-few-shot-learners\/review\/?hl=97633"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97636,
        "rank":6,
        "Model":"LLaMA 7B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 7B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"57.2"
        },
        "raw_metrics":{
            "Accuracy":57.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97636"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97637,
        "rank":7,
        "Model":"LLaMA 13B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"LLaMA 13B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"56.4"
        },
        "raw_metrics":{
            "Accuracy":56.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97637"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97635,
        "rank":8,
        "Model":"PaLM 540B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM 540B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-05",
        "metrics":{
            "Accuracy":"53.4"
        },
        "raw_metrics":{
            "Accuracy":53.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":989558,
            "title":"PaLM: Scaling Language Modeling with Pathways",
            "url":"\/paper\/palm-scaling-language-modeling-with-pathways-1",
            "published":"2022-04-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":12181,
        "row_id":97634,
        "rank":9,
        "Model":"PaLM 62B (zero-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM 62B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-05",
        "metrics":{
            "Accuracy":"50.4"
        },
        "raw_metrics":{
            "Accuracy":50.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":989558,
            "title":"PaLM: Scaling Language Modeling with Pathways",
            "url":"\/paper\/palm-scaling-language-modeling-with-pathways-1",
            "published":"2022-04-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]