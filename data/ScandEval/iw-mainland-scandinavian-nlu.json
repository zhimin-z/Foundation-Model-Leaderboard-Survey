[
    {
        "Model":"ltg\/norbert3-large",
        "num_model_parameters":"354.0",
        "vocabulary_size":50,
        "max_sequence_length":508,
        "speed":5048,
        "score":67.78,
        "da_score":60.51,
        "no_score":74.76,
        "sv_score":68.08,
        "dansk":73.62,
        "angry_tweets":48.29,
        "scala_da":71.55,
        "scandiqa_da":48.59,
        "norne_nb":93.12,
        "norne_nn":89.39,
        "norec":64.62,
        "scala_nb":77.97,
        "scala_nn":76.3,
        "norquad":66.03,
        "suc3":79.01,
        "swerec":75.32,
        "scala_sv":69.11,
        "scandiqa_sv":48.88
    },
    {
        "Model":"gpt-4-0613 (few-shot, val)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":8192,
        "speed":1244,
        "score":67.34,
        "da_score":61.57,
        "no_score":67.09,
        "sv_score":73.37,
        "dansk":64.94,
        "angry_tweets":59.97,
        "scala_da":71.56,
        "scandiqa_da":49.82,
        "norne_nb":81.16,
        "norne_nn":75.75,
        "norec":72.72,
        "scala_nb":77.3,
        "scala_nn":57.18,
        "norquad":49.93,
        "suc3":76.86,
        "swerec":79.19,
        "scala_sv":80.93,
        "scandiqa_sv":56.5
    },
    {
        "Model":"danish-foundation-models\/encoder-large-v1",
        "num_model_parameters":"355.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":6671,
        "score":64.31,
        "da_score":62.39,
        "no_score":65.49,
        "sv_score":65.05,
        "dansk":74.6,
        "angry_tweets":51.42,
        "scala_da":76.11,
        "scandiqa_da":47.42,
        "norne_nb":88.66,
        "norne_nn":84.59,
        "norec":55.59,
        "scala_nb":71.43,
        "scala_nn":53.3,
        "norquad":57.38,
        "suc3":74.18,
        "swerec":75.11,
        "scala_sv":64.11,
        "scandiqa_sv":46.79
    },
    {
        "Model":"KennethEnevoldsen\/dfm-sentence-encoder-large-1",
        "num_model_parameters":"355.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":6245,
        "score":64.24,
        "da_score":62.35,
        "no_score":66.32,
        "sv_score":64.05,
        "dansk":74.99,
        "angry_tweets":53.85,
        "scala_da":75.71,
        "scandiqa_da":44.85,
        "norne_nb":86.39,
        "norne_nn":83.22,
        "norec":59.61,
        "scala_nb":67.88,
        "scala_nn":62.44,
        "norquad":55.69,
        "suc3":71.65,
        "swerec":74.92,
        "scala_sv":63.43,
        "scandiqa_sv":46.2
    },
    {
        "Model":"KennethEnevoldsen\/dfm-sentence-encoder-large-2",
        "num_model_parameters":"355.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":6569,
        "score":64.24,
        "da_score":62.98,
        "no_score":66.24,
        "sv_score":63.52,
        "dansk":75.3,
        "angry_tweets":55.12,
        "scala_da":76.34,
        "scandiqa_da":45.15,
        "norne_nb":86.78,
        "norne_nn":83.28,
        "norec":58.73,
        "scala_nb":70.73,
        "scala_nn":59.58,
        "norquad":56.04,
        "suc3":71.86,
        "swerec":74.67,
        "scala_sv":62.77,
        "scandiqa_sv":44.77
    },
    {
        "Model":"google\/rembert",
        "num_model_parameters":"576.0",
        "vocabulary_size":250,
        "max_sequence_length":256,
        "speed":3355,
        "score":63.7,
        "da_score":57.49,
        "no_score":65.53,
        "sv_score":68.1,
        "dansk":70.19,
        "angry_tweets":50.19,
        "scala_da":69.72,
        "scandiqa_da":39.85,
        "norne_nb":88.7,
        "norne_nn":86.11,
        "norec":54.19,
        "scala_nb":69.83,
        "scala_nn":54.84,
        "norquad":58.18,
        "suc3":78.23,
        "swerec":75.99,
        "scala_sv":72.17,
        "scandiqa_sv":46.0
    },
    {
        "Model":"microsoft\/mdeberta-v3-base",
        "num_model_parameters":"279.0",
        "vocabulary_size":251,
        "max_sequence_length":512,
        "speed":9237,
        "score":62.86,
        "da_score":56.37,
        "no_score":64.44,
        "sv_score":67.78,
        "dansk":72.9,
        "angry_tweets":43.38,
        "scala_da":67.05,
        "scandiqa_da":42.15,
        "norne_nb":91.9,
        "norne_nn":86.81,
        "norec":53.69,
        "scala_nb":70.55,
        "scala_nn":61.21,
        "norquad":48.82,
        "suc3":78.84,
        "swerec":75.24,
        "scala_sv":72.3,
        "scandiqa_sv":44.74
    },
    {
        "Model":"NbAiLab\/nb-roberta-base-scandi",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15079,
        "score":62.7,
        "da_score":56.44,
        "no_score":66.16,
        "sv_score":65.49,
        "dansk":73.28,
        "angry_tweets":52.08,
        "scala_da":67.99,
        "scandiqa_da":32.39,
        "norne_nb":92.24,
        "norne_nn":87.58,
        "norec":59.98,
        "scala_nb":70.18,
        "scala_nn":70.81,
        "norquad":44.27,
        "suc3":80.02,
        "swerec":76.21,
        "scala_sv":71.92,
        "scandiqa_sv":33.8
    },
    {
        "Model":"intfloat\/multilingual-e5-large",
        "num_model_parameters":"560.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":6732,
        "score":62.44,
        "da_score":57.24,
        "no_score":62.56,
        "sv_score":67.54,
        "dansk":69.5,
        "angry_tweets":55.07,
        "scala_da":57.67,
        "scandiqa_da":46.71,
        "norne_nb":89.86,
        "norne_nn":84.32,
        "norec":61.52,
        "scala_nb":62.34,
        "scala_nn":34.88,
        "norquad":53.01,
        "suc3":80.36,
        "swerec":79.65,
        "scala_sv":63.15,
        "scandiqa_sv":46.99
    },
    {
        "Model":"NbAiLab\/nb-roberta-base-scandi-1e4",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15074,
        "score":61.93,
        "da_score":53.96,
        "no_score":66.29,
        "sv_score":65.53,
        "dansk":72.16,
        "angry_tweets":51.7,
        "scala_da":62.03,
        "scandiqa_da":29.95,
        "norne_nb":92.09,
        "norne_nn":86.85,
        "norec":59.84,
        "scala_nb":73.33,
        "scala_nn":71.06,
        "norquad":43.67,
        "suc3":79.9,
        "swerec":76.2,
        "scala_sv":73.62,
        "scandiqa_sv":32.38
    },
    {
        "Model":"ltg\/norbert3-base",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":508,
        "speed":11405,
        "score":61.4,
        "da_score":52.38,
        "no_score":69.86,
        "sv_score":61.95,
        "dansk":73.26,
        "angry_tweets":43.94,
        "scala_da":51.62,
        "scandiqa_da":40.7,
        "norne_nb":92.36,
        "norne_nn":88.49,
        "norec":59.73,
        "scala_nb":74.4,
        "scala_nn":68.85,
        "norquad":57.67,
        "suc3":78.21,
        "swerec":71.05,
        "scala_sv":56.02,
        "scandiqa_sv":42.52
    },
    {
        "Model":"KennethEnevoldsen\/dfm-sentence-encoder-medium-3",
        "num_model_parameters":"178.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":14050,
        "score":61.28,
        "da_score":56.45,
        "no_score":64.01,
        "sv_score":63.39,
        "dansk":71.21,
        "angry_tweets":47.55,
        "scala_da":68.72,
        "scandiqa_da":38.33,
        "norne_nb":91.17,
        "norne_nn":87.3,
        "norec":59.1,
        "scala_nb":74.32,
        "scala_nn":72.94,
        "norquad":34.06,
        "suc3":81.35,
        "swerec":71.16,
        "scala_sv":63.89,
        "scandiqa_sv":37.18
    },
    {
        "Model":"vesteinn\/ScandiBERT-no-faroese",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15436,
        "score":61.23,
        "da_score":54.43,
        "no_score":63.89,
        "sv_score":65.39,
        "dansk":69.79,
        "angry_tweets":47.73,
        "scala_da":68.28,
        "scandiqa_da":31.9,
        "norne_nb":91.09,
        "norne_nn":85.72,
        "norec":50.9,
        "scala_nb":69.34,
        "scala_nn":66.24,
        "norquad":48.45,
        "suc3":79.08,
        "swerec":72.53,
        "scala_sv":73.01,
        "scandiqa_sv":36.92
    },
    {
        "Model":"sentence-transformers\/use-cmlm-multilingual",
        "num_model_parameters":"471.0",
        "vocabulary_size":501,
        "max_sequence_length":512,
        "speed":13305,
        "score":60.83,
        "da_score":53.71,
        "no_score":63.11,
        "sv_score":65.66,
        "dansk":69.17,
        "angry_tweets":48.03,
        "scala_da":55.31,
        "scandiqa_da":42.34,
        "norne_nb":90.08,
        "norne_nn":86.04,
        "norec":56.35,
        "scala_nb":59.38,
        "scala_nn":46.54,
        "norquad":55.05,
        "suc3":80.05,
        "swerec":75.09,
        "scala_sv":61.83,
        "scandiqa_sv":45.69
    },
    {
        "Model":"NbAiLab\/nb-bert-base",
        "num_model_parameters":"178.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":14050,
        "score":60.67,
        "da_score":54.88,
        "no_score":64.39,
        "sv_score":62.74,
        "dansk":70.36,
        "angry_tweets":46.32,
        "scala_da":66.41,
        "scandiqa_da":36.42,
        "norne_nb":93.01,
        "norne_nn":88.43,
        "norec":60.84,
        "scala_nb":73.89,
        "scala_nn":72.1,
        "norquad":33.01,
        "suc3":80.38,
        "swerec":71.21,
        "scala_sv":64.03,
        "scandiqa_sv":35.33
    },
    {
        "Model":"vesteinn\/FoBERT",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15623,
        "score":60.15,
        "da_score":54.17,
        "no_score":62.6,
        "sv_score":63.69,
        "dansk":69.65,
        "angry_tweets":49.18,
        "scala_da":65.45,
        "scandiqa_da":32.4,
        "norne_nb":90.65,
        "norne_nn":84.88,
        "norec":52.44,
        "scala_nb":68.77,
        "scala_nn":65.4,
        "norquad":43.13,
        "suc3":78.58,
        "swerec":73.41,
        "scala_sv":71.14,
        "scandiqa_sv":31.62
    },
    {
        "Model":"xlm-roberta-large",
        "num_model_parameters":"560.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":6663,
        "score":60.14,
        "da_score":55.48,
        "no_score":61.61,
        "sv_score":63.33,
        "dansk":72.74,
        "angry_tweets":48.33,
        "scala_da":57.3,
        "scandiqa_da":43.57,
        "norne_nb":91.66,
        "norne_nn":86.19,
        "norec":50.25,
        "scala_nb":55.51,
        "scala_nn":43.89,
        "norquad":57.57,
        "suc3":80.33,
        "swerec":76.63,
        "scala_sv":49.72,
        "scandiqa_sv":46.64
    },
    {
        "Model":"pere\/roberta-debug-8",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15103,
        "score":59.95,
        "da_score":54.32,
        "no_score":63.08,
        "sv_score":62.45,
        "dansk":71.34,
        "angry_tweets":49.77,
        "scala_da":64.31,
        "scandiqa_da":31.86,
        "norne_nb":91.16,
        "norne_nn":84.75,
        "norec":55.25,
        "scala_nb":68.03,
        "scala_nn":66.9,
        "norquad":41.65,
        "suc3":74.48,
        "swerec":74.58,
        "scala_sv":69.07,
        "scandiqa_sv":31.66
    },
    {
        "Model":"setu4993\/LaBSE",
        "num_model_parameters":"471.0",
        "vocabulary_size":501,
        "max_sequence_length":512,
        "speed":13386,
        "score":58.93,
        "da_score":52.69,
        "no_score":60.74,
        "sv_score":63.36,
        "dansk":71.24,
        "angry_tweets":46.5,
        "scala_da":52.92,
        "scandiqa_da":40.08,
        "norne_nb":90.58,
        "norne_nn":85.21,
        "norec":54.26,
        "scala_nb":59.44,
        "scala_nn":49.3,
        "norquad":46.42,
        "suc3":77.78,
        "swerec":73.58,
        "scala_sv":60.36,
        "scandiqa_sv":41.71
    },
    {
        "Model":"gpt-3.5-turbo-0613 (few-shot, val)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":4095,
        "speed":1344,
        "score":58.75,
        "da_score":54.7,
        "no_score":56.17,
        "sv_score":65.37,
        "dansk":59.61,
        "angry_tweets":50.54,
        "scala_da":57.57,
        "scandiqa_da":51.09,
        "norne_nb":77.7,
        "norne_nn":73.92,
        "norec":58.88,
        "scala_nb":54.29,
        "scala_nn":32.82,
        "norquad":46.44,
        "suc3":73.04,
        "swerec":72.77,
        "scala_sv":58.06,
        "scandiqa_sv":57.59
    },
    {
        "Model":"pere\/roberta-base-exp-8",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15112,
        "score":58.74,
        "da_score":52.79,
        "no_score":63.83,
        "sv_score":59.59,
        "dansk":68.77,
        "angry_tweets":49.66,
        "scala_da":60.13,
        "scandiqa_da":32.6,
        "norne_nb":88.99,
        "norne_nn":82.99,
        "norec":57.37,
        "scala_nb":69.92,
        "scala_nn":70.05,
        "norquad":41.98,
        "suc3":73.44,
        "swerec":73.63,
        "scala_sv":58.91,
        "scandiqa_sv":32.39
    },
    {
        "Model":"pere\/roberta-debug-32",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":14958,
        "score":58.74,
        "da_score":53.4,
        "no_score":60.5,
        "sv_score":62.34,
        "dansk":68.46,
        "angry_tweets":50.48,
        "scala_da":64.34,
        "scandiqa_da":30.3,
        "norne_nb":89.07,
        "norne_nn":83.27,
        "norec":53.23,
        "scala_nb":70.06,
        "scala_nn":66.81,
        "norquad":34.17,
        "suc3":72.25,
        "swerec":75.04,
        "scala_sv":70.16,
        "scandiqa_sv":31.89
    },
    {
        "Model":"gpt-3.5-turbo-0613 (few-shot)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":4096,
        "speed":1344,
        "score":58.47,
        "da_score":55.49,
        "no_score":54.81,
        "sv_score":65.09,
        "dansk":59.4,
        "angry_tweets":51.8,
        "scala_da":54.22,
        "scandiqa_da":56.55,
        "norne_nb":74.92,
        "norne_nn":75.34,
        "norec":57.64,
        "scala_nb":49.93,
        "scala_nn":34.22,
        "norquad":44.39,
        "suc3":71.43,
        "swerec":77.5,
        "scala_sv":55.99,
        "scandiqa_sv":55.46
    },
    {
        "Model":"pere\/roberta-base-exp-32",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15081,
        "score":57.64,
        "da_score":50.05,
        "no_score":62.81,
        "sv_score":60.06,
        "dansk":71.9,
        "angry_tweets":51.33,
        "scala_da":44.45,
        "scandiqa_da":32.51,
        "norne_nb":91.66,
        "norne_nn":87.74,
        "norec":57.43,
        "scala_nb":63.31,
        "scala_nn":62.79,
        "norquad":41.05,
        "suc3":79.75,
        "swerec":74.73,
        "scala_sv":53.55,
        "scandiqa_sv":32.2
    },
    {
        "Model":"AI-Sweden-Models\/bert-large-nordic-pile-1M-steps",
        "num_model_parameters":"369.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":6571,
        "score":56.03,
        "da_score":46.96,
        "no_score":52.1,
        "sv_score":69.05,
        "dansk":67.4,
        "angry_tweets":41.53,
        "scala_da":41.62,
        "scandiqa_da":37.3,
        "norne_nb":87.5,
        "norne_nn":80.57,
        "norec":47.11,
        "scala_nb":52.62,
        "scala_nn":25.06,
        "norquad":38.4,
        "suc3":80.65,
        "swerec":77.43,
        "scala_sv":76.56,
        "scandiqa_sv":41.54
    },
    {
        "Model":"pere\/roberta-base-exp-32B",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15103,
        "score":55.06,
        "da_score":51.14,
        "no_score":56.67,
        "sv_score":57.38,
        "dansk":71.81,
        "angry_tweets":47.83,
        "scala_da":54.99,
        "scandiqa_da":29.92,
        "norne_nb":90.6,
        "norne_nn":86.76,
        "norec":52.19,
        "scala_nb":54.98,
        "scala_nn":58.33,
        "norquad":29.17,
        "suc3":77.97,
        "swerec":73.27,
        "scala_sv":47.19,
        "scandiqa_sv":31.07
    },
    {
        "Model":"vesteinn\/DanskBERT",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15749,
        "score":54.51,
        "da_score":59.57,
        "no_score":52.31,
        "sv_score":51.65,
        "dansk":72.55,
        "angry_tweets":52.86,
        "scala_da":75.2,
        "scandiqa_da":37.65,
        "norne_nb":86.82,
        "norne_nn":79.91,
        "norec":47.84,
        "scala_nb":51.99,
        "scala_nn":30.57,
        "norquad":36.75,
        "suc3":72.33,
        "swerec":67.77,
        "scala_sv":33.79,
        "scandiqa_sv":32.71
    },
    {
        "Model":"ltg\/norbert3-small",
        "num_model_parameters":"41.0",
        "vocabulary_size":50,
        "max_sequence_length":508,
        "speed":13515,
        "score":54.2,
        "da_score":48.24,
        "no_score":62.56,
        "sv_score":51.81,
        "dansk":67.89,
        "angry_tweets":39.34,
        "scala_da":50.9,
        "scandiqa_da":34.82,
        "norne_nb":90.02,
        "norne_nn":86.52,
        "norec":51.36,
        "scala_nb":67.29,
        "scala_nn":56.67,
        "norquad":48.63,
        "suc3":74.22,
        "swerec":63.8,
        "scala_sv":37.77,
        "scandiqa_sv":31.45
    },
    {
        "Model":"KBLab\/megatron-bert-large-swedish-cased-165k",
        "num_model_parameters":"370.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":7138,
        "score":52.91,
        "da_score":41.65,
        "no_score":46.69,
        "sv_score":70.39,
        "dansk":58.5,
        "angry_tweets":41.02,
        "scala_da":27.1,
        "scandiqa_da":39.99,
        "norne_nb":85.99,
        "norne_nn":79.47,
        "norec":39.53,
        "scala_nb":27.39,
        "scala_nn":23.56,
        "norquad":39.01,
        "suc3":81.05,
        "swerec":78.0,
        "scala_sv":76.79,
        "scandiqa_sv":45.71
    },
    {
        "Model":"AI-Nordics\/bert-large-swedish-cased",
        "num_model_parameters":"335.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":7199,
        "score":52.54,
        "da_score":42.27,
        "no_score":47.34,
        "sv_score":68.02,
        "dansk":60.66,
        "angry_tweets":38.46,
        "scala_da":32.29,
        "scandiqa_da":37.68,
        "norne_nb":83.32,
        "norne_nn":77.97,
        "norec":38.44,
        "scala_nb":37.54,
        "scala_nn":23.1,
        "norquad":39.97,
        "suc3":78.61,
        "swerec":77.47,
        "scala_sv":72.87,
        "scandiqa_sv":43.11
    },
    {
        "Model":"cardiffnlp\/twitter-xlm-roberta-base",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":14837,
        "score":52.05,
        "da_score":47.29,
        "no_score":50.94,
        "sv_score":57.92,
        "dansk":70.1,
        "angry_tweets":45.3,
        "scala_da":51.74,
        "scandiqa_da":22.01,
        "norne_nb":87.7,
        "norne_nn":81.41,
        "norec":48.34,
        "scala_nb":55.3,
        "scala_nn":37.46,
        "norquad":24.49,
        "suc3":72.49,
        "swerec":70.69,
        "scala_sv":56.6,
        "scandiqa_sv":31.89
    },
    {
        "Model":"KBLab\/megatron-bert-large-swedish-cased-110k",
        "num_model_parameters":"370.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":7075,
        "score":51.65,
        "da_score":41.35,
        "no_score":43.68,
        "sv_score":69.92,
        "dansk":60.18,
        "angry_tweets":39.2,
        "scala_da":26.68,
        "scandiqa_da":39.34,
        "norne_nb":84.03,
        "norne_nn":77.98,
        "norec":39.15,
        "scala_nb":21.39,
        "scala_nn":17.1,
        "norquad":35.32,
        "suc3":80.39,
        "swerec":78.45,
        "scala_sv":76.28,
        "scandiqa_sv":44.56
    },
    {
        "Model":"bert-base-multilingual-uncased",
        "num_model_parameters":"167.0",
        "vocabulary_size":106,
        "max_sequence_length":512,
        "speed":13993,
        "score":50.63,
        "da_score":45.57,
        "no_score":51.06,
        "sv_score":55.28,
        "dansk":64.92,
        "angry_tweets":33.5,
        "scala_da":46.75,
        "scandiqa_da":37.09,
        "norne_nb":82.9,
        "norne_nn":77.33,
        "norec":37.28,
        "scala_nb":49.41,
        "scala_nn":43.58,
        "norquad":40.35,
        "suc3":70.85,
        "swerec":63.3,
        "scala_sv":48.97,
        "scandiqa_sv":38.0
    },
    {
        "Model":"KB\/bert-base-swedish-cased",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":16181,
        "score":50.33,
        "da_score":39.21,
        "no_score":43.04,
        "sv_score":68.74,
        "dansk":61.74,
        "angry_tweets":33.28,
        "scala_da":33.15,
        "scandiqa_da":28.67,
        "norne_nb":85.91,
        "norne_nn":79.67,
        "norec":38.7,
        "scala_nb":39.13,
        "scala_nn":24.13,
        "norquad":19.04,
        "suc3":81.95,
        "swerec":75.58,
        "scala_sv":78.86,
        "scandiqa_sv":38.56
    },
    {
        "Model":"KBLab\/bert-base-swedish-cased",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":16164,
        "score":50.13,
        "da_score":39.27,
        "no_score":42.61,
        "sv_score":68.53,
        "dansk":61.74,
        "angry_tweets":33.31,
        "scala_da":33.35,
        "scandiqa_da":28.67,
        "norne_nb":85.33,
        "norne_nn":79.44,
        "norec":38.17,
        "scala_nb":39.49,
        "scala_nn":22.17,
        "norquad":19.04,
        "suc3":81.23,
        "swerec":75.73,
        "scala_sv":78.6,
        "scandiqa_sv":38.56
    },
    {
        "Model":"jonfd\/electra-small-nordic",
        "num_model_parameters":"22.0",
        "vocabulary_size":96,
        "max_sequence_length":128,
        "speed":5989,
        "score":49.76,
        "da_score":43.43,
        "no_score":51.22,
        "sv_score":54.63,
        "dansk":65.4,
        "angry_tweets":34.43,
        "scala_da":67.27,
        "scandiqa_da":6.6,
        "norne_nb":84.95,
        "norne_nn":79.57,
        "norec":40.15,
        "scala_nb":72.87,
        "scala_nn":63.77,
        "norquad":14.16,
        "suc3":71.07,
        "swerec":66.42,
        "scala_sv":69.19,
        "scandiqa_sv":11.85
    },
    {
        "Model":"bert-base-multilingual-cased",
        "num_model_parameters":"178.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":14083,
        "score":49.52,
        "da_score":40.76,
        "no_score":51.05,
        "sv_score":56.75,
        "dansk":63.17,
        "angry_tweets":32.38,
        "scala_da":27.93,
        "scandiqa_da":39.57,
        "norne_nb":88.72,
        "norne_nn":83.08,
        "norec":35.87,
        "scala_nb":44.22,
        "scala_nn":39.55,
        "norquad":40.55,
        "suc3":76.29,
        "swerec":61.78,
        "scala_sv":47.74,
        "scandiqa_sv":41.17
    },
    {
        "Model":"KBLab\/megatron-bert-base-swedish-cased-600k",
        "num_model_parameters":"135.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":15726,
        "score":49.26,
        "da_score":38.19,
        "no_score":43.03,
        "sv_score":66.55,
        "dansk":57.97,
        "angry_tweets":39.4,
        "scala_da":23.5,
        "scandiqa_da":31.87,
        "norne_nb":82.2,
        "norne_nn":76.64,
        "norec":40.2,
        "scala_nb":24.45,
        "scala_nn":19.18,
        "norquad":30.69,
        "suc3":78.91,
        "swerec":76.09,
        "scala_sv":70.08,
        "scandiqa_sv":41.14
    },
    {
        "Model":"Geotrend\/bert-base-en-fr-de-no-da-cased",
        "num_model_parameters":"118.0",
        "vocabulary_size":42,
        "max_sequence_length":512,
        "speed":13973,
        "score":49.23,
        "da_score":44.89,
        "no_score":49.07,
        "sv_score":53.73,
        "dansk":63.38,
        "angry_tweets":34.78,
        "scala_da":41.08,
        "scandiqa_da":40.32,
        "norne_nb":88.05,
        "norne_nn":83.08,
        "norec":35.34,
        "scala_nb":31.45,
        "scala_nn":36.12,
        "norquad":41.59,
        "suc3":76.55,
        "swerec":61.6,
        "scala_sv":37.44,
        "scandiqa_sv":39.32
    },
    {
        "Model":"Geotrend\/bert-base-en-no-cased",
        "num_model_parameters":"111.0",
        "vocabulary_size":33,
        "max_sequence_length":512,
        "speed":14081,
        "score":49.11,
        "da_score":44.37,
        "no_score":49.54,
        "sv_score":53.42,
        "dansk":62.66,
        "angry_tweets":33.91,
        "scala_da":40.96,
        "scandiqa_da":39.93,
        "norne_nb":89.07,
        "norne_nn":82.69,
        "norec":34.97,
        "scala_nb":39.58,
        "scala_nn":31.27,
        "norquad":41.89,
        "suc3":75.33,
        "swerec":61.8,
        "scala_sv":36.62,
        "scandiqa_sv":39.95
    },
    {
        "Model":"facebook\/xlm-v-base",
        "num_model_parameters":"778.0",
        "vocabulary_size":902,
        "max_sequence_length":512,
        "speed":13135,
        "score":49.09,
        "da_score":47.72,
        "no_score":43.3,
        "sv_score":56.24,
        "dansk":71.42,
        "angry_tweets":31.86,
        "scala_da":52.95,
        "scandiqa_da":34.66,
        "norne_nb":89.99,
        "norne_nn":78.6,
        "norec":17.93,
        "scala_nb":43.46,
        "scala_nn":10.97,
        "norquad":43.74,
        "suc3":68.39,
        "swerec":73.43,
        "scala_sv":45.09,
        "scandiqa_sv":38.04
    },
    {
        "Model":"Geotrend\/bert-base-25lang-cased",
        "num_model_parameters":"151.0",
        "vocabulary_size":85,
        "max_sequence_length":512,
        "speed":13908,
        "score":48.84,
        "da_score":40.98,
        "no_score":51.22,
        "sv_score":54.32,
        "dansk":62.53,
        "angry_tweets":32.88,
        "scala_da":29.01,
        "scandiqa_da":39.51,
        "norne_nb":87.99,
        "norne_nn":83.1,
        "norec":36.21,
        "scala_nb":46.43,
        "scala_nn":39.82,
        "norquad":40.01,
        "suc3":75.62,
        "swerec":62.5,
        "scala_sv":38.18,
        "scandiqa_sv":40.96
    },
    {
        "Model":"microsoft\/infoxlm-large",
        "num_model_parameters":"560.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":6696,
        "score":48.48,
        "da_score":42.97,
        "no_score":47.09,
        "sv_score":55.39,
        "dansk":74.42,
        "angry_tweets":37.94,
        "scala_da":15.26,
        "scandiqa_da":44.25,
        "norne_nb":91.9,
        "norne_nn":86.59,
        "norec":30.56,
        "scala_nb":9.79,
        "scala_nn":6.36,
        "norquad":60.47,
        "suc3":79.53,
        "swerec":75.42,
        "scala_sv":18.44,
        "scandiqa_sv":48.19
    },
    {
        "Model":"Geotrend\/bert-base-en-da-cased",
        "num_model_parameters":"111.0",
        "vocabulary_size":33,
        "max_sequence_length":512,
        "speed":14062,
        "score":48.38,
        "da_score":42.7,
        "no_score":48.2,
        "sv_score":54.23,
        "dansk":62.57,
        "angry_tweets":33.67,
        "scala_da":35.79,
        "scandiqa_da":38.77,
        "norne_nb":88.55,
        "norne_nn":83.09,
        "norec":35.16,
        "scala_nb":31.82,
        "scala_nn":32.94,
        "norquad":39.46,
        "suc3":74.88,
        "swerec":61.89,
        "scala_sv":40.22,
        "scandiqa_sv":39.95
    },
    {
        "Model":"Geotrend\/bert-base-da-cased",
        "num_model_parameters":"104.0",
        "vocabulary_size":23,
        "max_sequence_length":512,
        "speed":15432,
        "score":46.94,
        "da_score":40.89,
        "no_score":47.23,
        "sv_score":52.71,
        "dansk":62.76,
        "angry_tweets":32.06,
        "scala_da":30.95,
        "scandiqa_da":37.79,
        "norne_nb":87.52,
        "norne_nn":82.66,
        "norec":32.73,
        "scala_nb":36.41,
        "scala_nn":30.37,
        "norquad":37.71,
        "suc3":74.13,
        "swerec":62.18,
        "scala_sv":36.93,
        "scandiqa_sv":37.59
    },
    {
        "Model":"microsoft\/xlm-align-base",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":14744,
        "score":46.85,
        "da_score":39.98,
        "no_score":50.53,
        "sv_score":50.02,
        "dansk":70.36,
        "angry_tweets":47.83,
        "scala_da":11.87,
        "scandiqa_da":29.87,
        "norne_nb":90.07,
        "norne_nn":85.65,
        "norec":54.46,
        "scala_nb":12.16,
        "scala_nn":8.99,
        "norquad":49.24,
        "suc3":78.6,
        "swerec":73.67,
        "scala_sv":15.41,
        "scandiqa_sv":32.41
    },
    {
        "Model":"KBLab\/megatron-bert-base-swedish-cased-125k",
        "num_model_parameters":"135.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":15763,
        "score":46.4,
        "da_score":35.39,
        "no_score":38.03,
        "sv_score":65.78,
        "dansk":53.93,
        "angry_tweets":36.31,
        "scala_da":23.46,
        "scandiqa_da":27.85,
        "norne_nb":77.98,
        "norne_nn":75.0,
        "norec":33.88,
        "scala_nb":24.23,
        "scala_nn":18.18,
        "norquad":20.56,
        "suc3":79.29,
        "swerec":75.85,
        "scala_sv":70.43,
        "scandiqa_sv":37.56
    },
    {
        "Model":"RJuro\/munin-neuralbeagle-7b (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2499,
        "score":45.88,
        "da_score":44.21,
        "no_score":41.37,
        "sv_score":52.06,
        "dansk":49.85,
        "angry_tweets":50.81,
        "scala_da":24.76,
        "scandiqa_da":51.43,
        "norne_nb":61.9,
        "norne_nn":62.27,
        "norec":54.72,
        "scala_nb":18.9,
        "scala_nn":8.64,
        "norquad":34.91,
        "suc3":58.18,
        "swerec":79.42,
        "scala_sv":19.92,
        "scandiqa_sv":50.72
    },
    {
        "Model":"jhu-clsp\/bernice",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":5567,
        "score":45.09,
        "da_score":40.81,
        "no_score":41.42,
        "sv_score":53.05,
        "dansk":61.98,
        "angry_tweets":47.2,
        "scala_da":40.52,
        "scandiqa_da":13.53,
        "norne_nb":84.11,
        "norne_nn":77.82,
        "norec":39.63,
        "scala_nb":45.75,
        "scala_nn":33.74,
        "norquad":5.35,
        "suc3":71.34,
        "swerec":70.91,
        "scala_sv":53.52,
        "scandiqa_sv":16.41
    },
    {
        "Model":"flax-community\/nordic-roberta-wiki",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":16227,
        "score":44.99,
        "da_score":41.0,
        "no_score":39.45,
        "sv_score":54.52,
        "dansk":60.82,
        "angry_tweets":34.45,
        "scala_da":41.89,
        "scandiqa_da":26.83,
        "norne_nb":85.42,
        "norne_nn":78.92,
        "norec":36.27,
        "scala_nb":48.07,
        "scala_nn":29.81,
        "norquad":0.44,
        "suc3":72.9,
        "swerec":61.11,
        "scala_sv":55.05,
        "scandiqa_sv":29.04
    },
    {
        "Model":"microsoft\/infoxlm-base",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":14918,
        "score":44.7,
        "da_score":39.03,
        "no_score":47.1,
        "sv_score":47.97,
        "dansk":69.78,
        "angry_tweets":46.78,
        "scala_da":11.27,
        "scandiqa_da":28.28,
        "norne_nb":90.14,
        "norne_nn":84.12,
        "norec":44.42,
        "scala_nb":11.2,
        "scala_nn":7.12,
        "norquad":47.69,
        "suc3":79.43,
        "swerec":71.48,
        "scala_sv":7.26,
        "scandiqa_sv":33.72
    },
    {
        "Model":"KBLab\/bert-base-swedish-cased-new",
        "num_model_parameters":"135.0",
        "vocabulary_size":64,
        "max_sequence_length":512,
        "speed":15933,
        "score":44.21,
        "da_score":31.39,
        "no_score":36.21,
        "sv_score":65.04,
        "dansk":59.37,
        "angry_tweets":38.46,
        "scala_da":4.61,
        "scandiqa_da":23.13,
        "norne_nb":83.23,
        "norne_nn":79.16,
        "norec":33.94,
        "scala_nb":9.56,
        "scala_nn":4.16,
        "norquad":22.84,
        "suc3":79.99,
        "swerec":76.04,
        "scala_sv":73.52,
        "scandiqa_sv":30.6
    },
    {
        "Model":"mlabonne\/NeuralBeagle14-7B (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":3065,
        "score":44.19,
        "da_score":42.5,
        "no_score":39.66,
        "sv_score":50.41,
        "dansk":51.47,
        "angry_tweets":50.02,
        "scala_da":21.1,
        "scandiqa_da":47.41,
        "norne_nb":62.31,
        "norne_nn":62.81,
        "norec":53.12,
        "scala_nb":14.66,
        "scala_nn":10.88,
        "norquad":30.2,
        "suc3":58.85,
        "swerec":76.52,
        "scala_sv":18.63,
        "scandiqa_sv":47.63
    },
    {
        "Model":"clips\/mfaq",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":128,
        "speed":5591,
        "score":43.83,
        "da_score":39.17,
        "no_score":42.81,
        "sv_score":49.51,
        "dansk":68.49,
        "angry_tweets":45.6,
        "scala_da":28.26,
        "scandiqa_da":14.34,
        "norne_nb":89.46,
        "norne_nn":79.71,
        "norec":52.91,
        "scala_nb":27.55,
        "scala_nn":15.2,
        "norquad":12.36,
        "suc3":76.31,
        "swerec":73.32,
        "scala_sv":32.29,
        "scandiqa_sv":16.12
    },
    {
        "Model":"sentence-transformers\/paraphrase-xlm-r-multilingual-v1",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":14994,
        "score":43.76,
        "da_score":41.52,
        "no_score":39.83,
        "sv_score":49.95,
        "dansk":61.17,
        "angry_tweets":46.39,
        "scala_da":38.61,
        "scandiqa_da":19.9,
        "norne_nb":81.26,
        "norne_nn":74.05,
        "norec":49.93,
        "scala_nb":38.26,
        "scala_nn":25.17,
        "norquad":0.0,
        "suc3":70.22,
        "swerec":71.33,
        "scala_sv":39.6,
        "scandiqa_sv":18.65
    },
    {
        "Model":"flax-community\/swe-roberta-wiki-oscar",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15437,
        "score":43.53,
        "da_score":35.03,
        "no_score":33.88,
        "sv_score":61.67,
        "dansk":55.98,
        "angry_tweets":36.66,
        "scala_da":22.69,
        "scandiqa_da":24.81,
        "norne_nb":79.25,
        "norne_nn":75.39,
        "norec":36.56,
        "scala_nb":22.02,
        "scala_nn":19.72,
        "norquad":0.78,
        "suc3":75.4,
        "swerec":76.22,
        "scala_sv":65.73,
        "scandiqa_sv":29.34
    },
    {
        "Model":"distilbert-base-multilingual-cased",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26355,
        "score":43.08,
        "da_score":38.59,
        "no_score":41.92,
        "sv_score":48.73,
        "dansk":58.12,
        "angry_tweets":32.53,
        "scala_da":35.53,
        "scandiqa_da":28.19,
        "norne_nb":83.62,
        "norne_nn":80.69,
        "norec":33.16,
        "scala_nb":36.1,
        "scala_nn":30.1,
        "norquad":19.26,
        "suc3":70.08,
        "swerec":59.66,
        "scala_sv":33.71,
        "scandiqa_sv":31.48
    },
    {
        "Model":"sentence-transformers\/paraphrase-multilingual-mpnet-base-v2",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15100,
        "score":42.8,
        "da_score":39.99,
        "no_score":39.95,
        "sv_score":48.47,
        "dansk":61.18,
        "angry_tweets":49.13,
        "scala_da":29.66,
        "scandiqa_da":19.99,
        "norne_nb":81.94,
        "norne_nn":75.56,
        "norec":55.53,
        "scala_nb":36.01,
        "scala_nn":14.99,
        "norquad":0.0,
        "suc3":65.14,
        "swerec":73.47,
        "scala_sv":36.62,
        "scandiqa_sv":18.65
    },
    {
        "Model":"sentence-transformers\/stsb-xlm-r-multilingual",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15040,
        "score":42.66,
        "da_score":38.79,
        "no_score":38.69,
        "sv_score":50.5,
        "dansk":58.52,
        "angry_tweets":42.26,
        "scala_da":34.8,
        "scandiqa_da":19.6,
        "norne_nb":80.08,
        "norne_nn":74.59,
        "norec":52.16,
        "scala_nb":36.3,
        "scala_nn":14.21,
        "norquad":0.0,
        "suc3":68.94,
        "swerec":72.77,
        "scala_sv":40.21,
        "scandiqa_sv":20.09
    },
    {
        "Model":"timpal0l\/Mistral-7B-v0.1-flashback-v2 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2505,
        "score":42.66,
        "da_score":39.45,
        "no_score":35.76,
        "sv_score":52.77,
        "dansk":41.66,
        "angry_tweets":47.52,
        "scala_da":17.36,
        "scandiqa_da":51.28,
        "norne_nb":48.28,
        "norne_nn":50.51,
        "norec":49.76,
        "scala_nb":14.54,
        "scala_nn":9.16,
        "norquad":32.04,
        "suc3":44.16,
        "swerec":80.29,
        "scala_sv":34.8,
        "scandiqa_sv":51.82
    },
    {
        "Model":"DDSC\/roberta-base-scandinavian",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":14491,
        "score":42.6,
        "da_score":36.91,
        "no_score":41.07,
        "sv_score":49.83,
        "dansk":43.9,
        "angry_tweets":44.48,
        "scala_da":30.37,
        "scandiqa_da":28.89,
        "norne_nb":71.73,
        "norne_nn":79.8,
        "norec":46.74,
        "scala_nb":8.02,
        "scala_nn":17.04,
        "norquad":29.26,
        "suc3":58.84,
        "swerec":72.28,
        "scala_sv":37.61,
        "scandiqa_sv":30.59
    },
    {
        "Model":"Geotrend\/distilbert-base-25lang-cased",
        "num_model_parameters":"109.0",
        "vocabulary_size":85,
        "max_sequence_length":512,
        "speed":26099,
        "score":42.44,
        "da_score":37.99,
        "no_score":40.96,
        "sv_score":48.37,
        "dansk":58.44,
        "angry_tweets":31.81,
        "scala_da":34.13,
        "scandiqa_da":27.6,
        "norne_nb":83.59,
        "norne_nn":80.29,
        "norec":33.19,
        "scala_nb":32.6,
        "scala_nn":24.97,
        "norquad":19.93,
        "suc3":70.56,
        "swerec":60.69,
        "scala_sv":30.83,
        "scandiqa_sv":31.41
    },
    {
        "Model":"Geotrend\/distilbert-base-en-fr-de-no-da-cased",
        "num_model_parameters":"76.0",
        "vocabulary_size":42,
        "max_sequence_length":512,
        "speed":26081,
        "score":42.4,
        "da_score":38.22,
        "no_score":41.29,
        "sv_score":47.68,
        "dansk":58.78,
        "angry_tweets":31.3,
        "scala_da":34.92,
        "scandiqa_da":27.86,
        "norne_nb":83.49,
        "norne_nn":80.23,
        "norec":32.66,
        "scala_nb":33.65,
        "scala_nn":29.07,
        "norquad":19.29,
        "suc3":69.94,
        "swerec":59.83,
        "scala_sv":29.82,
        "scandiqa_sv":31.13
    },
    {
        "Model":"Geotrend\/distilbert-base-en-no-cased",
        "num_model_parameters":"69.0",
        "vocabulary_size":33,
        "max_sequence_length":512,
        "speed":26597,
        "score":42.23,
        "da_score":37.83,
        "no_score":41.71,
        "sv_score":47.15,
        "dansk":57.53,
        "angry_tweets":32.95,
        "scala_da":33.63,
        "scandiqa_da":27.21,
        "norne_nb":83.93,
        "norne_nn":79.39,
        "norec":32.32,
        "scala_nb":36.15,
        "scala_nn":30.17,
        "norquad":19.71,
        "suc3":69.28,
        "swerec":59.53,
        "scala_sv":29.36,
        "scandiqa_sv":30.42
    },
    {
        "Model":"Geotrend\/distilbert-base-en-da-cased",
        "num_model_parameters":"69.0",
        "vocabulary_size":33,
        "max_sequence_length":512,
        "speed":26196,
        "score":41.91,
        "da_score":38.95,
        "no_score":39.3,
        "sv_score":47.47,
        "dansk":59.5,
        "angry_tweets":31.89,
        "scala_da":36.0,
        "scandiqa_da":28.41,
        "norne_nb":83.27,
        "norne_nn":79.59,
        "norec":29.37,
        "scala_nb":31.5,
        "scala_nn":24.06,
        "norquad":18.62,
        "suc3":69.62,
        "swerec":59.42,
        "scala_sv":29.01,
        "scandiqa_sv":31.82
    },
    {
        "Model":"Geotrend\/distilbert-base-da-cased",
        "num_model_parameters":"61.0",
        "vocabulary_size":23,
        "max_sequence_length":512,
        "speed":28950,
        "score":41.63,
        "da_score":38.19,
        "no_score":39.67,
        "sv_score":47.03,
        "dansk":58.36,
        "angry_tweets":32.13,
        "scala_da":34.75,
        "scandiqa_da":27.5,
        "norne_nb":82.84,
        "norne_nn":78.83,
        "norec":30.7,
        "scala_nb":34.24,
        "scala_nn":27.2,
        "norquad":16.44,
        "suc3":69.25,
        "swerec":58.47,
        "scala_sv":29.8,
        "scandiqa_sv":30.61
    },
    {
        "Model":"sarnikowski\/convbert-medium-small-da-cased",
        "num_model_parameters":"24.0",
        "vocabulary_size":29,
        "max_sequence_length":512,
        "speed":13821,
        "score":40.91,
        "da_score":47.3,
        "no_score":36.92,
        "sv_score":38.5,
        "dansk":64.28,
        "angry_tweets":36.85,
        "scala_da":63.55,
        "scandiqa_da":24.52,
        "norne_nb":79.5,
        "norne_nn":73.03,
        "norec":32.4,
        "scala_nb":41.65,
        "scala_nn":25.53,
        "norquad":5.41,
        "suc3":58.01,
        "swerec":57.67,
        "scala_sv":13.4,
        "scandiqa_sv":24.92
    },
    {
        "Model":"Addedk\/kbbert-distilled-cased",
        "num_model_parameters":"82.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":29698,
        "score":40.23,
        "da_score":31.25,
        "no_score":31.65,
        "sv_score":57.79,
        "dansk":57.84,
        "angry_tweets":31.18,
        "scala_da":13.25,
        "scandiqa_da":22.73,
        "norne_nb":81.82,
        "norne_nn":75.89,
        "norec":33.42,
        "scala_nb":14.99,
        "scala_nn":13.63,
        "norquad":0.0,
        "suc3":80.12,
        "swerec":71.28,
        "scala_sv":51.58,
        "scandiqa_sv":28.16
    },
    {
        "Model":"Twitter\/twhin-bert-large",
        "num_model_parameters":"561.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":5299,
        "score":39.54,
        "da_score":36.67,
        "no_score":34.32,
        "sv_score":47.61,
        "dansk":66.39,
        "angry_tweets":39.36,
        "scala_da":7.06,
        "scandiqa_da":33.88,
        "norne_nb":86.26,
        "norne_nn":80.1,
        "norec":34.17,
        "scala_nb":12.11,
        "scala_nn":4.28,
        "norquad":11.74,
        "suc3":74.26,
        "swerec":63.35,
        "scala_sv":16.07,
        "scandiqa_sv":36.77
    },
    {
        "Model":"sentence-transformers\/paraphrase-multilingual-MiniLM-L12-v2",
        "num_model_parameters":"118.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":17428,
        "score":39.39,
        "da_score":36.46,
        "no_score":35.88,
        "sv_score":45.84,
        "dansk":56.75,
        "angry_tweets":44.48,
        "scala_da":26.74,
        "scandiqa_da":17.89,
        "norne_nb":78.31,
        "norne_nn":72.13,
        "norec":47.53,
        "scala_nb":26.92,
        "scala_nn":14.63,
        "norquad":0.0,
        "suc3":66.5,
        "swerec":72.19,
        "scala_sv":28.75,
        "scandiqa_sv":15.91
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2657,
        "score":39.19,
        "da_score":36.47,
        "no_score":34.5,
        "sv_score":46.6,
        "dansk":45.42,
        "angry_tweets":43.16,
        "scala_da":8.79,
        "scandiqa_da":48.51,
        "norne_nb":52.0,
        "norne_nn":55.12,
        "norec":47.25,
        "scala_nb":8.66,
        "scala_nn":6.8,
        "norquad":29.44,
        "suc3":53.34,
        "swerec":80.0,
        "scala_sv":4.61,
        "scandiqa_sv":48.43
    },
    {
        "Model":"danish-foundation-models\/encoder-medium-v1",
        "num_model_parameters":"111.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":16130,
        "score":38.23,
        "da_score":45.02,
        "no_score":35.66,
        "sv_score":34.0,
        "dansk":63.42,
        "angry_tweets":39.91,
        "scala_da":51.01,
        "scandiqa_da":25.76,
        "norne_nb":68.66,
        "norne_nn":61.77,
        "norec":36.56,
        "scala_nb":31.23,
        "scala_nn":5.4,
        "norquad":22.56,
        "suc3":49.62,
        "swerec":58.7,
        "scala_sv":2.23,
        "scandiqa_sv":25.45
    },
    {
        "Model":"Addedk\/mbert-swedish-distilled-cased",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26091,
        "score":38.07,
        "da_score":32.06,
        "no_score":35.05,
        "sv_score":47.12,
        "dansk":56.36,
        "angry_tweets":31.16,
        "scala_da":21.08,
        "scandiqa_da":19.63,
        "norne_nb":82.98,
        "norne_nn":76.65,
        "norec":30.38,
        "scala_nb":21.99,
        "scala_nn":19.06,
        "norquad":9.47,
        "suc3":73.41,
        "swerec":62.1,
        "scala_sv":34.86,
        "scandiqa_sv":18.1
    },
    {
        "Model":"jannikskytt\/MeDa-Bert",
        "num_model_parameters":"111.0",
        "vocabulary_size":32,
        "max_sequence_length":511,
        "speed":16114,
        "score":38.05,
        "da_score":44.97,
        "no_score":36.99,
        "sv_score":32.2,
        "dansk":64.64,
        "angry_tweets":44.62,
        "scala_da":47.47,
        "scandiqa_da":23.14,
        "norne_nb":71.69,
        "norne_nn":60.0,
        "norec":38.94,
        "scala_nb":30.32,
        "scala_nn":7.99,
        "norquad":24.02,
        "suc3":48.32,
        "swerec":53.98,
        "scala_sv":3.33,
        "scandiqa_sv":23.15
    },
    {
        "Model":"sarnikowski\/electra-small-discriminator-da-256-cased",
        "num_model_parameters":"13.0",
        "vocabulary_size":29,
        "max_sequence_length":512,
        "speed":20340,
        "score":37.93,
        "da_score":43.66,
        "no_score":33.65,
        "sv_score":36.49,
        "dansk":60.63,
        "angry_tweets":24.38,
        "scala_da":68.58,
        "scandiqa_da":21.03,
        "norne_nb":73.15,
        "norne_nn":66.34,
        "norec":29.97,
        "scala_nb":40.79,
        "scala_nn":25.08,
        "norquad":1.93,
        "suc3":52.79,
        "swerec":57.93,
        "scala_sv":14.72,
        "scandiqa_sv":20.54
    },
    {
        "Model":"birgermoell\/roberta-swedish-scandi",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15385,
        "score":37.74,
        "da_score":29.82,
        "no_score":28.56,
        "sv_score":54.84,
        "dansk":49.22,
        "angry_tweets":33.51,
        "scala_da":12.08,
        "scandiqa_da":24.49,
        "norne_nb":72.74,
        "norne_nn":69.74,
        "norec":29.68,
        "scala_nb":15.83,
        "scala_nn":8.7,
        "norquad":1.04,
        "suc3":68.55,
        "swerec":69.96,
        "scala_sv":52.88,
        "scandiqa_sv":27.99
    },
    {
        "Model":"Maltehb\/danish-bert-botxo",
        "num_model_parameters":"111.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":16091,
        "score":37.33,
        "da_score":45.69,
        "no_score":32.11,
        "sv_score":34.2,
        "dansk":66.71,
        "angry_tweets":43.79,
        "scala_da":45.96,
        "scandiqa_da":26.29,
        "norne_nb":72.62,
        "norne_nn":58.73,
        "norec":40.65,
        "scala_nb":29.47,
        "scala_nn":12.95,
        "norquad":0.91,
        "suc3":50.29,
        "swerec":57.42,
        "scala_sv":4.94,
        "scandiqa_sv":24.16
    },
    {
        "Model":"sarnikowski\/convbert-small-da-cased",
        "num_model_parameters":"13.0",
        "vocabulary_size":29,
        "max_sequence_length":512,
        "speed":14273,
        "score":37.26,
        "da_score":41.84,
        "no_score":34.03,
        "sv_score":35.92,
        "dansk":60.59,
        "angry_tweets":29.52,
        "scala_da":57.1,
        "scandiqa_da":20.16,
        "norne_nb":76.07,
        "norne_nn":70.94,
        "norec":32.49,
        "scala_nb":35.43,
        "scala_nn":21.11,
        "norquad":1.84,
        "suc3":55.06,
        "swerec":53.7,
        "scala_sv":12.38,
        "scandiqa_sv":22.53
    },
    {
        "Model":"ltg\/norbert3-xs",
        "num_model_parameters":"15.0",
        "vocabulary_size":50,
        "max_sequence_length":508,
        "speed":14208,
        "score":36.87,
        "da_score":31.49,
        "no_score":40.7,
        "sv_score":38.44,
        "dansk":59.94,
        "angry_tweets":39.16,
        "scala_da":2.16,
        "scandiqa_da":24.69,
        "norne_nb":87.63,
        "norne_nn":80.19,
        "norec":49.92,
        "scala_nb":7.93,
        "scala_nn":5.06,
        "norquad":22.46,
        "suc3":67.53,
        "swerec":59.27,
        "scala_sv":2.83,
        "scandiqa_sv":24.11
    },
    {
        "Model":"DDSC\/roberta-base-danish",
        "num_model_parameters":"125.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15004,
        "score":36.83,
        "da_score":37.96,
        "no_score":32.72,
        "sv_score":39.81,
        "dansk":63.84,
        "angry_tweets":43.9,
        "scala_da":17.16,
        "scandiqa_da":26.94,
        "norne_nb":76.14,
        "norne_nn":72.88,
        "norec":32.29,
        "scala_nb":0.45,
        "scala_nn":-0.08,
        "norquad":23.91,
        "suc3":65.95,
        "swerec":64.02,
        "scala_sv":0.8,
        "scandiqa_sv":28.46
    },
    {
        "Model":"Maltehb\/aelaectra-danish-electra-small-cased",
        "num_model_parameters":"14.0",
        "vocabulary_size":32,
        "max_sequence_length":128,
        "speed":6035,
        "score":35.23,
        "da_score":40.94,
        "no_score":31.55,
        "sv_score":33.19,
        "dansk":63.31,
        "angry_tweets":32.72,
        "scala_da":67.74,
        "scandiqa_da":0.0,
        "norne_nb":71.85,
        "norne_nn":67.14,
        "norec":29.0,
        "scala_nb":33.57,
        "scala_nn":21.79,
        "norquad":0.03,
        "suc3":57.82,
        "swerec":55.68,
        "scala_sv":19.26,
        "scandiqa_sv":0.0
    },
    {
        "Model":"danish-foundation-models\/munin-7b-alpha (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":3019,
        "score":34.76,
        "da_score":35.42,
        "no_score":25.42,
        "sv_score":43.43,
        "dansk":38.31,
        "angry_tweets":37.13,
        "scala_da":26.46,
        "scandiqa_da":39.77,
        "norne_nb":46.32,
        "norne_nn":48.2,
        "norec":20.46,
        "scala_nb":4.5,
        "scala_nn":1.1,
        "norquad":31.16,
        "suc3":39.55,
        "swerec":78.79,
        "scala_sv":15.77,
        "scandiqa_sv":39.62
    },
    {
        "Model":"dbmdz\/bert-base-historic-multilingual-cased",
        "num_model_parameters":"111.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":15165,
        "score":34.75,
        "da_score":26.28,
        "no_score":30.36,
        "sv_score":47.62,
        "dansk":47.61,
        "angry_tweets":24.17,
        "scala_da":8.14,
        "scandiqa_da":25.19,
        "norne_nb":68.63,
        "norne_nn":67.7,
        "norec":25.68,
        "scala_nb":6.73,
        "scala_nn":3.35,
        "norquad":22.57,
        "suc3":68.83,
        "swerec":64.25,
        "scala_sv":28.62,
        "scandiqa_sv":28.78
    },
    {
        "Model":"sentence-transformers\/distilbert-multilingual-nli-stsb-quora-ranking",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26151,
        "score":33.92,
        "da_score":28.84,
        "no_score":31.74,
        "sv_score":41.19,
        "dansk":54.48,
        "angry_tweets":36.6,
        "scala_da":8.84,
        "scandiqa_da":15.42,
        "norne_nb":77.81,
        "norne_nn":72.22,
        "norec":44.59,
        "scala_nb":8.98,
        "scala_nn":5.72,
        "norquad":0.0,
        "suc3":65.5,
        "swerec":68.33,
        "scala_sv":14.81,
        "scandiqa_sv":16.11
    },
    {
        "Model":"sentence-transformers\/quora-distilbert-multilingual",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26458,
        "score":33.8,
        "da_score":28.47,
        "no_score":31.74,
        "sv_score":41.2,
        "dansk":54.48,
        "angry_tweets":36.6,
        "scala_da":8.84,
        "scandiqa_da":13.97,
        "norne_nb":77.81,
        "norne_nn":72.22,
        "norec":44.59,
        "scala_nb":8.98,
        "scala_nn":5.72,
        "norquad":0.0,
        "suc3":65.5,
        "swerec":68.36,
        "scala_sv":14.81,
        "scandiqa_sv":16.11
    },
    {
        "Model":"dbmdz\/bert-medium-historic-multilingual-cased",
        "num_model_parameters":"42.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":24291,
        "score":33.23,
        "da_score":26.54,
        "no_score":29.05,
        "sv_score":44.1,
        "dansk":49.88,
        "angry_tweets":27.93,
        "scala_da":5.42,
        "scandiqa_da":22.93,
        "norne_nb":69.65,
        "norne_nn":66.78,
        "norec":26.33,
        "scala_nb":6.62,
        "scala_nn":5.16,
        "norquad":15.75,
        "suc3":66.11,
        "swerec":59.66,
        "scala_sv":26.28,
        "scandiqa_sv":24.36
    },
    {
        "Model":"Maltehb\/aelaectra-danish-electra-small-uncased",
        "num_model_parameters":"14.0",
        "vocabulary_size":32,
        "max_sequence_length":128,
        "speed":5995,
        "score":32.85,
        "da_score":41.16,
        "no_score":28.87,
        "sv_score":28.52,
        "dansk":62.52,
        "angry_tweets":34.45,
        "scala_da":65.15,
        "scandiqa_da":2.51,
        "norne_nb":59.76,
        "norne_nn":51.44,
        "norec":33.41,
        "scala_nb":32.87,
        "scala_nn":20.09,
        "norquad":0.0,
        "suc3":39.17,
        "swerec":57.71,
        "scala_sv":17.1,
        "scandiqa_sv":0.11
    },
    {
        "Model":"jjzha\/dajobbert-base-uncased",
        "num_model_parameters":"110.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":16243,
        "score":31.59,
        "da_score":38.38,
        "no_score":27.03,
        "sv_score":29.35,
        "dansk":60.78,
        "angry_tweets":39.65,
        "scala_da":37.67,
        "scandiqa_da":15.41,
        "norne_nb":65.95,
        "norne_nn":55.29,
        "norec":33.31,
        "scala_nb":20.34,
        "scala_nn":8.07,
        "norquad":0.0,
        "suc3":42.99,
        "swerec":55.49,
        "scala_sv":4.69,
        "scandiqa_sv":14.22
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2 (few-shot)",
        "num_model_parameters":"7111.0",
        "vocabulary_size":64,
        "max_sequence_length":2048,
        "speed":2351,
        "score":28.15,
        "da_score":22.16,
        "no_score":24.59,
        "sv_score":37.69,
        "dansk":20.84,
        "angry_tweets":18.07,
        "scala_da":10.54,
        "scandiqa_da":39.18,
        "norne_nb":29.62,
        "norne_nn":32.3,
        "norec":34.67,
        "scala_nb":8.37,
        "scala_nn":7.76,
        "norquad":24.67,
        "suc3":28.73,
        "swerec":77.47,
        "scala_sv":8.78,
        "scandiqa_sv":35.78
    },
    {
        "Model":"sentence-transformers\/distiluse-base-multilingual-cased-v1",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26344,
        "score":25.98,
        "da_score":23.28,
        "no_score":22.36,
        "sv_score":32.3,
        "dansk":46.78,
        "angry_tweets":27.78,
        "scala_da":3.04,
        "scandiqa_da":15.52,
        "norne_nb":60.76,
        "norne_nn":59.62,
        "norec":25.98,
        "scala_nb":2.65,
        "scala_nn":3.47,
        "norquad":0.2,
        "suc3":49.86,
        "swerec":60.06,
        "scala_sv":3.18,
        "scandiqa_sv":16.08
    },
    {
        "Model":"KBLab\/albert-base-swedish-cased-alpha",
        "num_model_parameters":"14.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15925,
        "score":25.8,
        "da_score":17.95,
        "no_score":22.3,
        "sv_score":37.13,
        "dansk":29.9,
        "angry_tweets":19.79,
        "scala_da":6.15,
        "scandiqa_da":15.96,
        "norne_nb":66.97,
        "norne_nn":63.9,
        "norec":18.85,
        "scala_nb":5.83,
        "scala_nn":4.02,
        "norquad":0.0,
        "suc3":47.19,
        "swerec":56.57,
        "scala_sv":20.92,
        "scandiqa_sv":23.86
    },
    {
        "Model":"dbmdz\/bert-mini-historic-multilingual-cased",
        "num_model_parameters":"12.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":47122,
        "score":25.15,
        "da_score":20.94,
        "no_score":23.1,
        "sv_score":31.43,
        "dansk":41.7,
        "angry_tweets":26.03,
        "scala_da":2.19,
        "scandiqa_da":13.82,
        "norne_nb":61.55,
        "norne_nn":59.9,
        "norec":24.59,
        "scala_nb":3.45,
        "scala_nn":2.72,
        "norquad":3.99,
        "suc3":50.07,
        "swerec":56.1,
        "scala_sv":5.05,
        "scandiqa_sv":14.49
    },
    {
        "Model":"jannesg\/bertsson",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":15314,
        "score":23.36,
        "da_score":18.76,
        "no_score":18.1,
        "sv_score":33.23,
        "dansk":32.63,
        "angry_tweets":24.11,
        "scala_da":2.91,
        "scandiqa_da":15.37,
        "norne_nb":49.3,
        "norne_nn":46.11,
        "norec":23.21,
        "scala_nb":2.26,
        "scala_nn":-0.66,
        "norquad":0.68,
        "suc3":51.13,
        "swerec":61.67,
        "scala_sv":2.87,
        "scandiqa_sv":17.24
    },
    {
        "Model":"3ebdola\/Dialectal-Arabic-XLM-R-Base",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":15177,
        "score":19.22,
        "da_score":15.82,
        "no_score":17.36,
        "sv_score":24.47,
        "dansk":36.51,
        "angry_tweets":22.07,
        "scala_da":1.63,
        "scandiqa_da":3.09,
        "norne_nb":55.55,
        "norne_nn":53.53,
        "norec":12.69,
        "scala_nb":2.79,
        "scala_nn":1.66,
        "norquad":0.0,
        "suc3":42.78,
        "swerec":44.95,
        "scala_sv":1.43,
        "scandiqa_sv":8.71
    },
    {
        "Model":"alexanderfalk\/danbert-small-cased",
        "num_model_parameters":"83.0",
        "vocabulary_size":52,
        "max_sequence_length":512,
        "speed":30013,
        "score":18.87,
        "da_score":19.57,
        "no_score":17.28,
        "sv_score":19.75,
        "dansk":33.05,
        "angry_tweets":30.67,
        "scala_da":13.01,
        "scandiqa_da":1.56,
        "norne_nb":42.18,
        "norne_nn":37.39,
        "norec":24.39,
        "scala_nb":7.29,
        "scala_nn":2.57,
        "norquad":0.0,
        "suc3":22.47,
        "swerec":53.88,
        "scala_sv":1.55,
        "scandiqa_sv":1.12
    },
    {
        "Model":"mhenrichsen\/danskgpt-tiny-chat (few-shot)",
        "num_model_parameters":"1100.0",
        "vocabulary_size":32,
        "max_sequence_length":2048,
        "speed":1745,
        "score":18.72,
        "da_score":18.96,
        "no_score":15.36,
        "sv_score":21.84,
        "dansk":22.31,
        "angry_tweets":34.05,
        "scala_da":0.7,
        "scandiqa_da":18.78,
        "norne_nb":28.74,
        "norne_nn":30.34,
        "norec":27.49,
        "scala_nb":-2.17,
        "scala_nn":0.26,
        "norquad":5.35,
        "suc3":27.31,
        "swerec":45.94,
        "scala_sv":-0.97,
        "scandiqa_sv":15.08
    },
    {
        "Model":"mhenrichsen\/danskgpt-tiny (few-shot)",
        "num_model_parameters":"1100.0",
        "vocabulary_size":32,
        "max_sequence_length":2048,
        "speed":8597,
        "score":14.93,
        "da_score":13.52,
        "no_score":11.81,
        "sv_score":19.47,
        "dansk":14.13,
        "angry_tweets":26.31,
        "scala_da":-0.54,
        "scandiqa_da":14.16,
        "norne_nb":27.37,
        "norne_nn":27.59,
        "norec":18.09,
        "scala_nb":-0.19,
        "scala_nn":-0.8,
        "norquad":2.15,
        "suc3":23.92,
        "swerec":31.93,
        "scala_sv":0.46,
        "scandiqa_sv":21.56
    },
    {
        "Model":"RabotaRu\/HRBert-mini",
        "num_model_parameters":"80.0",
        "vocabulary_size":200,
        "max_sequence_length":512,
        "speed":54951,
        "score":14.62,
        "da_score":11.54,
        "no_score":12.03,
        "sv_score":20.27,
        "dansk":22.21,
        "angry_tweets":20.33,
        "scala_da":0.9,
        "scandiqa_da":2.73,
        "norne_nb":31.87,
        "norne_nn":32.47,
        "norec":15.07,
        "scala_nb":1.26,
        "scala_nn":0.49,
        "norquad":0.0,
        "suc3":24.61,
        "swerec":52.31,
        "scala_sv":1.32,
        "scandiqa_sv":2.86
    },
    {
        "Model":"fresh-xlm-roberta-base",
        "num_model_parameters":"278.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":1319,
        "score":11.81,
        "da_score":9.08,
        "no_score":9.87,
        "sv_score":16.47,
        "dansk":16.04,
        "angry_tweets":17.37,
        "scala_da":1.34,
        "scandiqa_da":1.58,
        "norne_nb":25.49,
        "norne_nn":25.94,
        "norec":12.6,
        "scala_nb":0.5,
        "scala_nn":1.83,
        "norquad":0.0,
        "suc3":11.91,
        "swerec":51.11,
        "scala_sv":0.86,
        "scandiqa_sv":2.0
    },
    {
        "Model":"fresh-electra-small",
        "num_model_parameters":"14.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":7219,
        "score":10.74,
        "da_score":7.94,
        "no_score":7.78,
        "sv_score":16.49,
        "dansk":12.87,
        "angry_tweets":18.61,
        "scala_da":0.3,
        "scandiqa_da":0.0,
        "norne_nb":18.38,
        "norne_nn":12.76,
        "norec":15.29,
        "scala_nb":0.17,
        "scala_nn":0.37,
        "norquad":0.0,
        "suc3":10.54,
        "swerec":55.54,
        "scala_sv":-0.15,
        "scandiqa_sv":0.02
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m (few-shot)",
        "num_model_parameters":"186.0",
        "vocabulary_size":64,
        "max_sequence_length":2048,
        "speed":8958,
        "score":4.89,
        "da_score":5.02,
        "no_score":4.48,
        "sv_score":5.16,
        "dansk":3.43,
        "angry_tweets":9.18,
        "scala_da":-0.22,
        "scandiqa_da":7.7,
        "norne_nb":13.55,
        "norne_nn":9.38,
        "norec":7.78,
        "scala_nb":-1.46,
        "scala_nn":-2.97,
        "norquad":0.9,
        "suc3":5.66,
        "swerec":8.15,
        "scala_sv":-0.81,
        "scandiqa_sv":7.64
    }
]