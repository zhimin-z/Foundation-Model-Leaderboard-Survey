[
    {
        "rank":1,
        "model_id":"microsoft\/deberta-v3-large",
        "num_model_parameters":"434.0",
        "vocabulary_size":128,
        "max_sequence_length":512,
        "speed":2521,
        "score":76.37,
        "en_score":76.37,
        "conll_en":91.88,
        "sst5":64.04,
        "scala_en":75.1,
        "squad":74.47
    },
    {
        "rank":2,
        "model_id":"microsoft\/deberta-v3-base",
        "num_model_parameters":"184.0",
        "vocabulary_size":128,
        "max_sequence_length":512,
        "speed":5367,
        "score":72.66,
        "en_score":72.66,
        "conll_en":91.57,
        "sst5":61.66,
        "scala_en":68.74,
        "squad":68.69
    },
    {
        "rank":3,
        "model_id":"google\/electra-base-discriminator",
        "num_model_parameters":"109.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":9977,
        "score":69.88,
        "en_score":69.88,
        "conll_en":89.83,
        "sst5":63.55,
        "scala_en":67.87,
        "squad":58.27
    },
    {
        "rank":4,
        "model_id":"roberta-large",
        "num_model_parameters":"354.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":4542,
        "score":68.61,
        "en_score":68.61,
        "conll_en":91.53,
        "sst5":62.92,
        "scala_en":48.77,
        "squad":71.23
    },
    {
        "rank":5,
        "model_id":"roberta-base",
        "num_model_parameters":"124.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":13354,
        "score":67.64,
        "en_score":67.64,
        "conll_en":91.0,
        "sst5":59.54,
        "scala_en":57.29,
        "squad":62.75
    },
    {
        "rank":5,
        "model_id":"microsoft\/mdeberta-v3-base",
        "num_model_parameters":"278.0",
        "vocabulary_size":251,
        "max_sequence_length":512,
        "speed":9237,
        "score":67.45,
        "en_score":67.45,
        "conll_en":91.83,
        "sst5":53.75,
        "scala_en":62.11,
        "squad":62.1
    },
    {
        "rank":6,
        "model_id":"bert-large-cased",
        "num_model_parameters":"333.0",
        "vocabulary_size":29,
        "max_sequence_length":512,
        "speed":5051,
        "score":66.7,
        "en_score":66.7,
        "conll_en":89.84,
        "sst5":58.19,
        "scala_en":63.62,
        "squad":55.17
    },
    {
        "rank":7,
        "model_id":"bert-large-uncased",
        "num_model_parameters":"334.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":4711,
        "score":64.6,
        "en_score":64.6,
        "conll_en":88.8,
        "sst5":57.94,
        "scala_en":59.27,
        "squad":52.38
    },
    {
        "rank":7,
        "model_id":"distilroberta-base",
        "num_model_parameters":"82.0",
        "vocabulary_size":50,
        "max_sequence_length":512,
        "speed":17448,
        "score":62.59,
        "en_score":62.59,
        "conll_en":90.04,
        "sst5":56.08,
        "scala_en":54.9,
        "squad":49.36
    },
    {
        "rank":7,
        "model_id":"gpt-3.5-turbo-0613 (few-shot, val)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":4095,
        "speed":1344,
        "score":61.8,
        "en_score":61.8,
        "conll_en":71.48,
        "sst5":66.41,
        "scala_en":41.43,
        "squad":67.9
    },
    {
        "rank":8,
        "model_id":"google\/electra-large-discriminator",
        "num_model_parameters":"334.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":4700,
        "score":60.52,
        "en_score":60.52,
        "conll_en":67.87,
        "sst5":48.08,
        "scala_en":55.46,
        "squad":70.66
    },
    {
        "rank":9,
        "model_id":"bert-base-uncased",
        "num_model_parameters":"109.0",
        "vocabulary_size":31,
        "max_sequence_length":512,
        "speed":10296,
        "score":60.24,
        "en_score":60.24,
        "conll_en":87.62,
        "sst5":54.01,
        "scala_en":56.97,
        "squad":42.37
    },
    {
        "rank":10,
        "model_id":"xlm-roberta-large",
        "num_model_parameters":"559.0",
        "vocabulary_size":250,
        "max_sequence_length":512,
        "speed":6663,
        "score":59.05,
        "en_score":59.05,
        "conll_en":89.81,
        "sst5":41.97,
        "scala_en":35.55,
        "squad":68.88
    },
    {
        "rank":11,
        "model_id":"bert-base-multilingual-cased",
        "num_model_parameters":"177.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":14083,
        "score":56.18,
        "en_score":56.18,
        "conll_en":89.32,
        "sst5":41.89,
        "scala_en":38.34,
        "squad":55.19
    },
    {
        "rank":12,
        "model_id":"mistralai\/Mistral-7B-v0.1 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2657,
        "score":55.32,
        "en_score":55.32,
        "conll_en":63.4,
        "sst5":68.17,
        "scala_en":30.92,
        "squad":58.79
    },
    {
        "rank":13,
        "model_id":"distilbert-base-cased",
        "num_model_parameters":"65.0",
        "vocabulary_size":29,
        "max_sequence_length":512,
        "speed":19667,
        "score":53.52,
        "en_score":53.52,
        "conll_en":84.75,
        "sst5":50.94,
        "scala_en":53.47,
        "squad":24.93
    },
    {
        "rank":13,
        "model_id":"distilbert-base-multilingual-cased",
        "num_model_parameters":"135.0",
        "vocabulary_size":120,
        "max_sequence_length":512,
        "speed":26355,
        "score":48.49,
        "en_score":48.49,
        "conll_en":87.7,
        "sst5":36.48,
        "scala_en":40.79,
        "squad":29.0
    }
]