[
    {
        "rank":1,
        "model_id":"gpt-3.5-turbo-0613 (few-shot, val)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":4095,
        "speed":1344,
        "score":49.05,
        "de_score":49.05,
        "germeval":61.5,
        "sb10k":55.5,
        "scala_de":38.96,
        "germanquad":30.2,
        "mlsum":64.9,
        "mmlu_de":35.39,
        "hellaswag_de":56.88
    },
    {
        "rank":1,
        "model_id":"mlabonne\/NeuralBeagle14-7B (few-shot, val)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":8192,
        "speed":2549,
        "score":47.0,
        "de_score":47.0,
        "germeval":64.81,
        "sb10k":59.6,
        "scala_de":27.06,
        "germanquad":25.22,
        "mlsum":67.31,
        "mmlu_de":35.84,
        "hellaswag_de":49.13
    },
    {
        "rank":2,
        "model_id":"mistralai\/Mistral-7B-v0.1 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2657,
        "score":40.92,
        "de_score":40.92,
        "germeval":55.37,
        "sb10k":54.27,
        "scala_de":23.12,
        "germanquad":22.94,
        "mlsum":68.72,
        "mmlu_de":35.63,
        "hellaswag_de":26.4
    },
    {
        "rank":2,
        "model_id":"mistralai\/Mistral-7B-Instruct-v0.2 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":2538,
        "score":39.42,
        "de_score":39.42,
        "germeval":55.15,
        "sb10k":47.85,
        "scala_de":24.29,
        "germanquad":23.98,
        "mlsum":67.67,
        "mmlu_de":25.96,
        "hellaswag_de":31.06
    },
    {
        "rank":3,
        "model_id":"RuterNorway\/Llama-2-13b-chat-norwegian (few-shot)",
        "num_model_parameters":"unknown",
        "vocabulary_size":32,
        "max_sequence_length":4096,
        "speed":7778,
        "score":38.87,
        "de_score":38.87,
        "germeval":56.71,
        "sb10k":49.77,
        "scala_de":19.92,
        "germanquad":27.87,
        "mlsum":66.93,
        "mmlu_de":26.02,
        "hellaswag_de":24.88
    },
    {
        "rank":3,
        "model_id":"mistralai\/Mistral-7B-Instruct-v0.1 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":5443,
        "score":37.24,
        "de_score":37.24,
        "germeval":51.79,
        "sb10k":47.27,
        "scala_de":22.15,
        "germanquad":24.3,
        "mlsum":67.96,
        "mmlu_de":26.88,
        "hellaswag_de":20.34
    },
    {
        "rank":3,
        "model_id":"01-ai\/Yi-6B (few-shot)",
        "num_model_parameters":"6061.0",
        "vocabulary_size":64,
        "max_sequence_length":4096,
        "speed":2786,
        "score":36.47,
        "de_score":36.47,
        "germeval":44.97,
        "sb10k":53.14,
        "scala_de":7.64,
        "germanquad":30.12,
        "mlsum":66.73,
        "mmlu_de":29.8,
        "hellaswag_de":22.91
    },
    {
        "rank":4,
        "model_id":"meta-llama\/Llama-2-7b-chat-hf (few-shot)",
        "num_model_parameters":"6738.0",
        "vocabulary_size":32,
        "max_sequence_length":4096,
        "speed":2643,
        "score":34.16,
        "de_score":34.16,
        "germeval":50.0,
        "sb10k":46.54,
        "scala_de":15.3,
        "germanquad":25.57,
        "mlsum":67.66,
        "mmlu_de":20.13,
        "hellaswag_de":13.92
    },
    {
        "rank":5,
        "model_id":"meta-llama\/Llama-2-7b-hf (few-shot)",
        "num_model_parameters":"6738.0",
        "vocabulary_size":32,
        "max_sequence_length":4096,
        "speed":2648,
        "score":31.72,
        "de_score":31.72,
        "germeval":41.88,
        "sb10k":50.17,
        "scala_de":15.82,
        "germanquad":18.35,
        "mlsum":68.99,
        "mmlu_de":18.43,
        "hellaswag_de":8.37
    },
    {
        "rank":5,
        "model_id":"Rijgersberg\/GEITje-7B (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":32768,
        "speed":10401,
        "score":31.32,
        "de_score":31.32,
        "germeval":39.09,
        "sb10k":47.83,
        "scala_de":10.31,
        "germanquad":26.13,
        "mlsum":66.72,
        "mmlu_de":19.03,
        "hellaswag_de":10.1
    },
    {
        "rank":6,
        "model_id":"AI-Sweden-Models\/gpt-sw3-20b (few-shot)",
        "num_model_parameters":"20918.0",
        "vocabulary_size":64,
        "max_sequence_length":2048,
        "speed":4880,
        "score":22.35,
        "de_score":22.35,
        "germeval":35.78,
        "sb10k":34.13,
        "scala_de":2.18,
        "germanquad":17.99,
        "mlsum":62.21,
        "mmlu_de":3.58,
        "hellaswag_de":0.56
    },
    {
        "rank":7,
        "model_id":"RuterNorway\/Llama-2-7b-chat-norwegian (few-shot)",
        "num_model_parameters":"unknown",
        "vocabulary_size":32,
        "max_sequence_length":4096,
        "speed":10890,
        "score":20.38,
        "de_score":20.38,
        "germeval":27.22,
        "sb10k":33.54,
        "scala_de":0.45,
        "germanquad":20.4,
        "mlsum":62.18,
        "mmlu_de":-0.1,
        "hellaswag_de":-1.0
    },
    {
        "rank":8,
        "model_id":"RJuro\/kanelsnegl-v0.1 (few-shot)",
        "num_model_parameters":"7242.0",
        "vocabulary_size":32,
        "max_sequence_length":512,
        "speed":9757,
        "score":8.7,
        "de_score":8.7,
        "germeval":0.0,
        "sb10k":0.0,
        "scala_de":0.0,
        "germanquad":0.0,
        "mlsum":59.43,
        "mmlu_de":1.16,
        "hellaswag_de":0.31
    },
    {
        "rank":8,
        "model_id":"ai-forever\/mGPT (few-shot)",
        "num_model_parameters":"unknown",
        "vocabulary_size":100,
        "max_sequence_length":1024,
        "speed":13551,
        "score":4.49,
        "de_score":4.49,
        "germeval":0.3,
        "sb10k":0.29,
        "scala_de":-0.11,
        "germanquad":0.0,
        "mlsum":30.97,
        "mmlu_de":-0.6,
        "hellaswag_de":0.61
    }
]