[
    {
        "table_id":24589,
        "row_id":113007,
        "rank":1,
        "method":"LLaMA-VID-13B (2 Token)",
        "mlmodel":{

        },
        "method_short":"LLaMA-VID-13B ",
        "method_details":"2 Token",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "mean":"2.99",
            "Correctness of Information":"3.07",
            "Detail Orientation":"3.05",
            "Contextual Understanding":"3.60",
            "Temporal Understanding":"2.58",
            "Consistency":"2.63"
        },
        "raw_metrics":{
            "mean":2.99,
            "Correctness of Information":3.07,
            "Detail Orientation":3.05,
            "Contextual Understanding":3.6,
            "Temporal Understanding":2.58,
            "Consistency":2.63
        },
        "uses_additional_data":false,
        "paper":{
            "id":1329473,
            "title":"LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
            "url":"\/paper\/llama-vid-an-image-is-worth-2-tokens-in-large",
            "published":"2023-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-vid-an-image-is-worth-2-tokens-in-large\/review\/?hl=113007"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":112509,
        "rank":2,
        "method":"Chat-UniVi",
        "mlmodel":{

        },
        "method_short":"Chat-UniVi",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-14",
        "metrics":{
            "mean":"2.99",
            "Correctness of Information":"2.89",
            "Detail Orientation":"2.91",
            "Contextual Understanding":"3.46",
            "Temporal Understanding":"2.89",
            "Consistency":"2.81"
        },
        "raw_metrics":{
            "mean":2.99,
            "Correctness of Information":2.89,
            "Detail Orientation":2.91,
            "Contextual Understanding":3.46,
            "Temporal Understanding":2.89,
            "Consistency":2.81
        },
        "uses_additional_data":false,
        "paper":{
            "id":1320706,
            "title":"Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding",
            "url":"\/paper\/chat-univi-unified-visual-representation",
            "published":"2023-11-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/chat-univi-unified-visual-representation\/review\/?hl=112509"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":112846,
        "rank":3,
        "method":"VideoChat2",
        "mlmodel":{

        },
        "method_short":"VideoChat2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "mean":"2.98",
            "Correctness of Information":"3.02",
            "Detail Orientation":"2.88",
            "Contextual Understanding":"3.51",
            "Temporal Understanding":"2.66",
            "Consistency":"2.81"
        },
        "raw_metrics":{
            "mean":2.98,
            "Correctness of Information":3.02,
            "Detail Orientation":2.88,
            "Contextual Understanding":3.51,
            "Temporal Understanding":2.66,
            "Consistency":2.81
        },
        "uses_additional_data":false,
        "paper":{
            "id":1329478,
            "title":"MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
            "url":"\/paper\/mvbench-a-comprehensive-multi-modal-video",
            "published":"2023-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mvbench-a-comprehensive-multi-modal-video\/review\/?hl=112846"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":113008,
        "rank":4,
        "method":"LLaMA-VID-7B (2 Token)",
        "mlmodel":{

        },
        "method_short":"LLaMA-VID-7B ",
        "method_details":"2 Token",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "mean":"2.89",
            "Correctness of Information":"2.96",
            "Detail Orientation":"3.00",
            "Contextual Understanding":"3.53",
            "Temporal Understanding":"2.46",
            "Consistency":"2.51"
        },
        "raw_metrics":{
            "mean":2.89,
            "Correctness of Information":2.96,
            "Detail Orientation":3.0,
            "Contextual Understanding":3.53,
            "Temporal Understanding":2.46,
            "Consistency":2.51
        },
        "uses_additional_data":false,
        "paper":{
            "id":1329473,
            "title":"LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
            "url":"\/paper\/llama-vid-an-image-is-worth-2-tokens-in-large",
            "published":"2023-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-vid-an-image-is-worth-2-tokens-in-large\/review\/?hl=113008"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":112996,
        "rank":5,
        "method":"VTimeLLM",
        "mlmodel":{

        },
        "method_short":"VTimeLLM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-30",
        "metrics":{
            "mean":"2.85",
            "Correctness of Information":"2.78",
            "Detail Orientation":"3.10",
            "Contextual Understanding":"3.40",
            "Temporal Understanding":"2.49",
            "Consistency":"2.47"
        },
        "raw_metrics":{
            "mean":2.85,
            "Correctness of Information":2.78,
            "Detail Orientation":3.1,
            "Contextual Understanding":3.4,
            "Temporal Understanding":2.49,
            "Consistency":2.47
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333323,
            "title":"VTimeLLM: Empower LLM to Grasp Video Moments",
            "url":"\/paper\/vtimellm-empower-llm-to-grasp-video-moments",
            "published":"2023-11-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vtimellm-empower-llm-to-grasp-video-moments\/review\/?hl=112996"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":109664,
        "rank":6,
        "method":"BT-Adapter",
        "mlmodel":{

        },
        "method_short":"BT-Adapter",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-27",
        "metrics":{
            "mean":"2.69",
            "Correctness of Information":"2.68",
            "Detail Orientation":"2.69",
            "Contextual Understanding":"3.27",
            "Temporal Understanding":"2.34",
            "Consistency":"2.46"
        },
        "raw_metrics":{
            "mean":2.69,
            "Correctness of Information":2.68,
            "Detail Orientation":2.69,
            "Contextual Understanding":3.27,
            "Temporal Understanding":2.34,
            "Consistency":2.46
        },
        "uses_additional_data":false,
        "paper":{
            "id":1289477,
            "title":"One For All: Video Conversation is Feasible Without Video Instruction Tuning",
            "url":"\/paper\/one-for-all-video-conversation-is-feasible",
            "published":"2023-09-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/one-for-all-video-conversation-is-feasible\/review\/?hl=109664"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":109663,
        "rank":7,
        "method":"BT-Adapter (zero-shot)",
        "mlmodel":{

        },
        "method_short":"BT-Adapter ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-27",
        "metrics":{
            "mean":"2.46",
            "Correctness of Information":"2.16",
            "Detail Orientation":"2.46",
            "Contextual Understanding":"2.89",
            "Temporal Understanding":"2.13",
            "Consistency":"2.2"
        },
        "raw_metrics":{
            "mean":2.46,
            "Correctness of Information":2.16,
            "Detail Orientation":2.46,
            "Contextual Understanding":2.89,
            "Temporal Understanding":2.13,
            "Consistency":2.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1289477,
            "title":"One For All: Video Conversation is Feasible Without Video Instruction Tuning",
            "url":"\/paper\/one-for-all-video-conversation-is-feasible",
            "published":"2023-09-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/one-for-all-video-conversation-is-feasible\/review\/?hl=109663"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":106215,
        "rank":8,
        "method":"Video-ChatGPT",
        "mlmodel":{

        },
        "method_short":"Video-ChatGPT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-08",
        "metrics":{
            "mean":"2.38",
            "Correctness of Information":"2.4",
            "Detail Orientation":"2.52",
            "Contextual Understanding":"2.62",
            "Temporal Understanding":"1.98",
            "Consistency":"2.37"
        },
        "raw_metrics":{
            "mean":2.38,
            "Correctness of Information":2.4,
            "Detail Orientation":2.52,
            "Contextual Understanding":2.62,
            "Temporal Understanding":1.98,
            "Consistency":2.37
        },
        "uses_additional_data":false,
        "paper":{
            "id":1225920,
            "title":"Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models",
            "url":"\/paper\/video-chatgpt-towards-detailed-video",
            "published":"2023-06-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":106216,
        "rank":9,
        "method":"Video Chat",
        "mlmodel":{

        },
        "method_short":"Video Chat",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-10",
        "metrics":{
            "mean":"2.29",
            "Correctness of Information":"2.23",
            "Detail Orientation":"2.50",
            "Contextual Understanding":"2.53",
            "Temporal Understanding":"1.94",
            "Consistency":"2.24"
        },
        "raw_metrics":{
            "mean":2.29,
            "Correctness of Information":2.23,
            "Detail Orientation":2.5,
            "Contextual Understanding":2.53,
            "Temporal Understanding":1.94,
            "Consistency":2.24
        },
        "uses_additional_data":false,
        "paper":{
            "id":1205778,
            "title":"VideoChat: Chat-Centric Video Understanding",
            "url":"\/paper\/videochat-chat-centric-video-understanding",
            "published":"2023-05-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/videochat-chat-centric-video-understanding\/review\/?hl=106216"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":106217,
        "rank":10,
        "method":"LLaMA Adapter",
        "mlmodel":{

        },
        "method_short":"LLaMA Adapter",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-28",
        "metrics":{
            "mean":"2.16",
            "Correctness of Information":"2.03",
            "Detail Orientation":"2.32",
            "Contextual Understanding":"2.30",
            "Temporal Understanding":"1.98",
            "Consistency":"2.15"
        },
        "raw_metrics":{
            "mean":2.16,
            "Correctness of Information":2.03,
            "Detail Orientation":2.32,
            "Contextual Understanding":2.3,
            "Temporal Understanding":1.98,
            "Consistency":2.15
        },
        "uses_additional_data":false,
        "paper":{
            "id":1199360,
            "title":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model",
            "url":"\/paper\/llama-adapter-v2-parameter-efficient-visual",
            "published":"2023-04-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-adapter-v2-parameter-efficient-visual\/review\/?hl=106217"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":24589,
        "row_id":106218,
        "rank":11,
        "method":"Video LLaMA",
        "mlmodel":{

        },
        "method_short":"Video LLaMA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-05",
        "metrics":{
            "mean":"1.98",
            "Correctness of Information":"1.96",
            "Detail Orientation":"2.18",
            "Contextual Understanding":"2.16",
            "Temporal Understanding":"1.82",
            "Consistency":"1.79"
        },
        "raw_metrics":{
            "mean":1.98,
            "Correctness of Information":1.96,
            "Detail Orientation":2.18,
            "Contextual Understanding":2.16,
            "Temporal Understanding":1.82,
            "Consistency":1.79
        },
        "uses_additional_data":false,
        "paper":{
            "id":1223066,
            "title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
            "url":"\/paper\/video-llama-an-instruction-tuned-audio-visual",
            "published":"2023-06-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]