[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "F1":"0.174",
        "Denoised inference time (s)":"0.591",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"4.987",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "F1":"0.154",
        "Denoised inference time (s)":"0.424",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"5.528",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "F1":"0.154",
        "Denoised inference time (s)":"0.478",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"5.47",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "F1":"0.139",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"5.442",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "F1":"0.144",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"5.461",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "F1":"0.164",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"5.534",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "F1":"0.176",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"317.547",
        "# output tokens":"4.462",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"413.838",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"413.838",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"413.838",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "F1":"0.259",
        "Denoised inference time (s)":"0.82",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"4.989",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "F1":"0.197",
        "Denoised inference time (s)":"0.292",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"378.218",
        "# output tokens":"9.026",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "F1":"0.002",
        "Denoised inference time (s)":"0.269",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"402.929",
        "# output tokens":"20",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "F1":"0",
        "Denoised inference time (s)":"0.485",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "F1":"0",
        "Denoised inference time (s)":"0.301",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "F1":"0",
        "Denoised inference time (s)":"0.272",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "F1":"0",
        "Denoised inference time (s)":"0.27",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "F1":"0.254",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"5.094",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "F1":"0.245",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"407.57",
        "# output tokens":"5.08",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "F1":"0.199",
        "Denoised inference time (s)":"0.1",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"9.611",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "F1":"0.167",
        "Denoised inference time (s)":"0.104",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"403.046",
        "# output tokens":"9.2",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "F1":"0.101",
        "Denoised inference time (s)":"0.452",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"401.929",
        "# output tokens":"20",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "F1":"0.187",
        "Denoised inference time (s)":"0.341",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"405.929",
        "# output tokens":"20",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "F1":"0.248",
        "Denoised inference time (s)":"0.218",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"9.228",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "F1":"0.213",
        "Denoised inference time (s)":"0.067",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"9.026",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "F1":"0.432",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "F1":"0.26",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "F1":"0.271",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "F1":"0.472",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "F1":"0.215",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"11.872",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "F1":"0.236",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"19.977",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "F1":"0.296",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"410.282",
        "# output tokens":"19.662",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "F1":"0.392",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "F1":"0.243",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"4.536",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "F1":"0.247",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.046",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "F1":"0.165",
        "Denoised inference time (s)":"0.339",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.018",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "F1":"0.149",
        "Denoised inference time (s)":"0.118",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"4.839",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "F1":"0.12",
        "Denoised inference time (s)":"0.146",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.328",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "F1":"0.088",
        "Denoised inference time (s)":"0.169",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.725",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "F1":"0.734",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.01",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "F1":"0.623",
        "Denoised inference time (s)":"0.332",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.191",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "F1":"0.221",
        "Denoised inference time (s)":"0.159",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.115",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "F1":"0.212",
        "Denoised inference time (s)":"0.161",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.238",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "F1":"0.145",
        "Denoised inference time (s)":"0.116",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.771",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "F1":"0.684",
        "Denoised inference time (s)":"0.158",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "F1":"0.164",
        "Denoised inference time (s)":"0.099",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"0",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "F1":"0.631",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"343.552",
        "# output tokens":"5.691",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "F1":"0.586",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"343.552",
        "# output tokens":"5.056",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "F1":"0",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"20",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "F1":"0.228",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "F1":"0.33",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"388.046",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "F1":"0.144",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"385.96",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "F1":"0.1",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"385.96",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "F1":"0.139",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"385.96",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "F1":"0.183",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"385.96",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "F1":"0.254",
        "Denoised inference time (s)":"0.476",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"366.73",
        "# output tokens":"5.859",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "F1":"0.247",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.04",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "F1":"0.576",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"400.15",
        "# output tokens":"5.288",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "F1":"0.061",
        "Denoised inference time (s)":"0.207",
        "# eval":"515",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"402.441",
        "# output tokens":"15.611",
        "# trials":"3"
    }
]