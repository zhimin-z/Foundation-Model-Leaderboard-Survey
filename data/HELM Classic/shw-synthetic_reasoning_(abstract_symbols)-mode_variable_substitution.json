[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.303",
        "Denoised inference time (s)":"0.631",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.767",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.26",
        "Denoised inference time (s)":"0.401",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.892",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.315",
        "Denoised inference time (s)":"0.593",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.444",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.467",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.362",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.69",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.355",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.439",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.638",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.276",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"210.871",
        "# output tokens":"7.726",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.231",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"221.618",
        "# output tokens":"7.917",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.303",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"221.618",
        "# output tokens":"7.775",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.381",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"221.618",
        "# output tokens":"8.107",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.75",
        "Denoised inference time (s)":"1.019",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"8.387",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.426",
        "Denoised inference time (s)":"0.449",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"215.417",
        "# output tokens":"17.649",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.299",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"257.844",
        "# output tokens":"50",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.251",
        "Denoised inference time (s)":"0.773",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"9.477",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.151",
        "Denoised inference time (s)":"0.452",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"9.203",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.173",
        "Denoised inference time (s)":"0.322",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"8.518",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.131",
        "Denoised inference time (s)":"0.278",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"7.368",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.285",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"8.425",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.14",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"8.045",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.154",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"7.687",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.324",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"227.603",
        "# output tokens":"8.06",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.243",
        "Denoised inference time (s)":"0.169",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"25.959",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.29",
        "Denoised inference time (s)":"0.184",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"220.798",
        "# output tokens":"31.651",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.062",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.136",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.155",
        "Denoised inference time (s)":"0.572",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"257.844",
        "# output tokens":"50",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.137",
        "Denoised inference time (s)":"0.421",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"261.844",
        "# output tokens":"50",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.252",
        "Denoised inference time (s)":"0.341",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"19.621",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.184",
        "Denoised inference time (s)":"0.102",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"23.687",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.134",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.132",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.709",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.823",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.15",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.472",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.905",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.169",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"15.433",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.225",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"49.699",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.198",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"259.847",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.856",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.611",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.29",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.208",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"9.279",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.326",
        "Denoised inference time (s)":"0.401",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.409",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.212",
        "Denoised inference time (s)":"0.14",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.959",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.137",
        "Denoised inference time (s)":"0.172",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"10.147",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.126",
        "Denoised inference time (s)":"0.186",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"8.507",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.972",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.724",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.929",
        "Denoised inference time (s)":"0.384",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.637",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.195",
        "Denoised inference time (s)":"0.181",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.643",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.139",
        "Denoised inference time (s)":"0.172",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.1",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.069",
        "Denoised inference time (s)":"0.11",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"5.022",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "EM":"0.968",
        "Denoised inference time (s)":"0.379",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"8.724",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":"0.544",
        "Denoised inference time (s)":"0.161",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"8.74",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.944",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"204.513",
        "# output tokens":"7.85",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.936",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"204.513",
        "# output tokens":"7.86",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.101",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.093",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.039",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.142",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"50",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.466",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.577",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"226.798",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.134",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"276.398",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.043",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"276.398",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.262",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"276.398",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.167",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"276.398",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.332",
        "Denoised inference time (s)":"0.301",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"211.824",
        "# output tokens":"8.115",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.282",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.098",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.87",
        "Denoised inference time (s)":"-",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"218.315",
        "# output tokens":"7.724",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.078",
        "Denoised inference time (s)":"0.328",
        "# eval":"515",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"217.175",
        "# output tokens":"33.452",
        "# trials":"3"
    }
]