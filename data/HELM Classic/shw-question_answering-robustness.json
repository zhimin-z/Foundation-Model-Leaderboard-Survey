[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":0.464,
        "MMLU - EM (Robustness)":0.221,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.523",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.179,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.503",
        "QuAC - F1 (Robustness)":"0.222",
        "HellaSwag - EM (Robustness)":"0.726",
        "OpenbookQA - EM (Robustness)":"0.43",
        "TruthfulQA - EM (Robustness)":0.154
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":0.267,
        "MMLU - EM (Robustness)":0.2,
        "BoolQ - EM (Robustness)":0.567,
        "NarrativeQA - F1 (Robustness)":"0.4",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.098,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.41",
        "QuAC - F1 (Robustness)":"0.197",
        "HellaSwag - EM (Robustness)":"0.646",
        "OpenbookQA - EM (Robustness)":"0.412",
        "TruthfulQA - EM (Robustness)":0.155
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":0.401,
        "MMLU - EM (Robustness)":0.225,
        "BoolQ - EM (Robustness)":0.643,
        "NarrativeQA - F1 (Robustness)":"0.477",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.17,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.478",
        "QuAC - F1 (Robustness)":"0.219",
        "HellaSwag - EM (Robustness)":"0.695",
        "OpenbookQA - EM (Robustness)":"0.424",
        "TruthfulQA - EM (Robustness)":0.142
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":0.703,
        "MMLU - EM (Robustness)":0.392,
        "BoolQ - EM (Robustness)":0.692,
        "NarrativeQA - F1 (Robustness)":"0.565",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.235,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.56",
        "QuAC - F1 (Robustness)":"0.251",
        "HellaSwag - EM (Robustness)":"0.732",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.252
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":0.82,
        "MMLU - EM (Robustness)":0.417,
        "BoolQ - EM (Robustness)":0.729,
        "NarrativeQA - F1 (Robustness)":"0.66",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.315,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.599",
        "QuAC - F1 (Robustness)":"0.314",
        "HellaSwag - EM (Robustness)":"0.754",
        "OpenbookQA - EM (Robustness)":"0.47",
        "TruthfulQA - EM (Robustness)":0.39
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":0.778,
        "MMLU - EM (Robustness)":0.411,
        "BoolQ - EM (Robustness)":0.729,
        "NarrativeQA - F1 (Robustness)":"0.583",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.285,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.564",
        "QuAC - F1 (Robustness)":"0.276",
        "HellaSwag - EM (Robustness)":"0.755",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.293
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":0.473,
        "MMLU - EM (Robustness)":0.263,
        "BoolQ - EM (Robustness)":0.607,
        "NarrativeQA - F1 (Robustness)":"-",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.187,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.503",
        "QuAC - F1 (Robustness)":"-",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.21
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":0.322,
        "MMLU - EM (Robustness)":0.183,
        "BoolQ - EM (Robustness)":0.655,
        "NarrativeQA - F1 (Robustness)":"0.476",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.163,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.491",
        "QuAC - F1 (Robustness)":"0.185",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.112
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":0.453,
        "MMLU - EM (Robustness)":0.23,
        "BoolQ - EM (Robustness)":0.659,
        "NarrativeQA - F1 (Robustness)":"0.513",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.212,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.524",
        "QuAC - F1 (Robustness)":"0.193",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.151
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":0.558,
        "MMLU - EM (Robustness)":0.255,
        "BoolQ - EM (Robustness)":0.665,
        "NarrativeQA - F1 (Robustness)":"0.59",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.252,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.586",
        "QuAC - F1 (Robustness)":"0.233",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.106
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":0.832,
        "MMLU - EM (Robustness)":0.434,
        "BoolQ - EM (Robustness)":0.756,
        "NarrativeQA - F1 (Robustness)":"0.663",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.245,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.632",
        "QuAC - F1 (Robustness)":"0.313",
        "HellaSwag - EM (Robustness)":"0.766",
        "OpenbookQA - EM (Robustness)":"0.472",
        "TruthfulQA - EM (Robustness)":0.326
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":0.535,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.642,
        "NarrativeQA - F1 (Robustness)":"0.53",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.185,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.558",
        "QuAC - F1 (Robustness)":"0.234",
        "HellaSwag - EM (Robustness)":"0.699",
        "OpenbookQA - EM (Robustness)":"0.438",
        "TruthfulQA - EM (Robustness)":0.183
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":0.301,
        "MMLU - EM (Robustness)":0.378,
        "BoolQ - EM (Robustness)":0.0,
        "NarrativeQA - F1 (Robustness)":"0.099",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.031,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.122",
        "QuAC - F1 (Robustness)":"0.071",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.365
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":0.485,
        "MMLU - EM (Robustness)":0.29,
        "BoolQ - EM (Robustness)":0.614,
        "NarrativeQA - F1 (Robustness)":"0.383",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.238,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.471",
        "QuAC - F1 (Robustness)":"0.215",
        "HellaSwag - EM (Robustness)":"0.759",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.151
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":0.35,
        "MMLU - EM (Robustness)":0.253,
        "BoolQ - EM (Robustness)":0.545,
        "NarrativeQA - F1 (Robustness)":"0.357",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.172,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.347",
        "QuAC - F1 (Robustness)":"0.204",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.43",
        "TruthfulQA - EM (Robustness)":0.154
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":0.161,
        "MMLU - EM (Robustness)":0.184,
        "BoolQ - EM (Robustness)":0.562,
        "NarrativeQA - F1 (Robustness)":"0.3",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.102,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.266",
        "QuAC - F1 (Robustness)":"0.144",
        "HellaSwag - EM (Robustness)":"0.651",
        "OpenbookQA - EM (Robustness)":"0.382",
        "TruthfulQA - EM (Robustness)":0.149
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":0.13,
        "MMLU - EM (Robustness)":0.226,
        "BoolQ - EM (Robustness)":0.361,
        "NarrativeQA - F1 (Robustness)":"0.078",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.025,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.074",
        "QuAC - F1 (Robustness)":"0.098",
        "HellaSwag - EM (Robustness)":"0.405",
        "OpenbookQA - EM (Robustness)":"0.238",
        "TruthfulQA - EM (Robustness)":0.204
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":0.596,
        "MMLU - EM (Robustness)":0.299,
        "BoolQ - EM (Robustness)":0.718,
        "NarrativeQA - F1 (Robustness)":"0.39",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.283,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.533",
        "QuAC - F1 (Robustness)":"0.229",
        "HellaSwag - EM (Robustness)":"0.764",
        "OpenbookQA - EM (Robustness)":"0.482",
        "TruthfulQA - EM (Robustness)":0.116
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":0.222,
        "MMLU - EM (Robustness)":0.207,
        "BoolQ - EM (Robustness)":0.54,
        "NarrativeQA - F1 (Robustness)":"0.296",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.105,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.222",
        "QuAC - F1 (Robustness)":"0.152",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.414",
        "TruthfulQA - EM (Robustness)":0.17
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":0.542,
        "MMLU - EM (Robustness)":0.334,
        "BoolQ - EM (Robustness)":0.725,
        "NarrativeQA - F1 (Robustness)":"0.529",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.163,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.605",
        "QuAC - F1 (Robustness)":"0.17",
        "HellaSwag - EM (Robustness)":"0.696",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.171
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":0.826,
        "MMLU - EM (Robustness)":0.387,
        "BoolQ - EM (Robustness)":0.811,
        "NarrativeQA - F1 (Robustness)":"0.57",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.289,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.679",
        "QuAC - F1 (Robustness)":"0.238",
        "HellaSwag - EM (Robustness)":"0.774",
        "OpenbookQA - EM (Robustness)":"0.492",
        "TruthfulQA - EM (Robustness)":0.229
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":0.213,
        "MMLU - EM (Robustness)":0.217,
        "BoolQ - EM (Robustness)":0.621,
        "NarrativeQA - F1 (Robustness)":"0.135",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.099,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.228",
        "QuAC - F1 (Robustness)":"0.147",
        "HellaSwag - EM (Robustness)":"0.619",
        "OpenbookQA - EM (Robustness)":"0.398",
        "TruthfulQA - EM (Robustness)":0.181
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":0.31,
        "MMLU - EM (Robustness)":0.189,
        "BoolQ - EM (Robustness)":0.551,
        "NarrativeQA - F1 (Robustness)":"0.421",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.133,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.452",
        "QuAC - F1 (Robustness)":"0.191",
        "HellaSwag - EM (Robustness)":"0.661",
        "OpenbookQA - EM (Robustness)":"0.414",
        "TruthfulQA - EM (Robustness)":0.175
    },
    {
        "Model":"Pythia (6.9B)",
        "Mean win rate":0.171,
        "MMLU - EM (Robustness)":0.201,
        "BoolQ - EM (Robustness)":0.527,
        "NarrativeQA - F1 (Robustness)":"0.313",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.094,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.391",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.139
    },
    {
        "Model":"Pythia (12B)",
        "Mean win rate":0.245,
        "MMLU - EM (Robustness)":0.22,
        "BoolQ - EM (Robustness)":0.51,
        "NarrativeQA - F1 (Robustness)":"0.42",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.108,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.47",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.138
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":0.194,
        "MMLU - EM (Robustness)":0.258,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.045",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.153,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.071",
        "QuAC - F1 (Robustness)":"0.064",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.122
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":0.287,
        "MMLU - EM (Robustness)":0.272,
        "BoolQ - EM (Robustness)":0.646,
        "NarrativeQA - F1 (Robustness)":"0.059",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.141,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.291",
        "QuAC - F1 (Robustness)":"0.111",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.178
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":0.535,
        "MMLU - EM (Robustness)":0.27,
        "BoolQ - EM (Robustness)":0.623,
        "NarrativeQA - F1 (Robustness)":"0.409",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.208,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.408",
        "QuAC - F1 (Robustness)":"0.2",
        "HellaSwag - EM (Robustness)":"0.744",
        "OpenbookQA - EM (Robustness)":"0.488",
        "TruthfulQA - EM (Robustness)":0.205
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":0.461,
        "MMLU - EM (Robustness)":0.216,
        "BoolQ - EM (Robustness)":0.683,
        "NarrativeQA - F1 (Robustness)":"0.397",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.206,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.458",
        "QuAC - F1 (Robustness)":"0.199",
        "HellaSwag - EM (Robustness)":"0.699",
        "OpenbookQA - EM (Robustness)":"0.45",
        "TruthfulQA - EM (Robustness)":0.174
    },
    {
        "Model":"LLaMA (7B)",
        "Mean win rate":0.587,
        "MMLU - EM (Robustness)":0.268,
        "BoolQ - EM (Robustness)":0.688,
        "NarrativeQA - F1 (Robustness)":"0.485",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.222,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.519",
        "QuAC - F1 (Robustness)":"0.223",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.229
    },
    {
        "Model":"LLaMA (13B)",
        "Mean win rate":0.644,
        "MMLU - EM (Robustness)":0.37,
        "BoolQ - EM (Robustness)":0.67,
        "NarrativeQA - F1 (Robustness)":"0.544",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.272,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.556",
        "QuAC - F1 (Robustness)":"0.194",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.274
    },
    {
        "Model":"LLaMA (30B)",
        "Mean win rate":0.86,
        "MMLU - EM (Robustness)":0.461,
        "BoolQ - EM (Robustness)":0.791,
        "NarrativeQA - F1 (Robustness)":"0.611",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.36,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.612",
        "QuAC - F1 (Robustness)":"0.273",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.281
    },
    {
        "Model":"LLaMA (65B)",
        "Mean win rate":0.888,
        "MMLU - EM (Robustness)":0.504,
        "BoolQ - EM (Robustness)":0.84,
        "NarrativeQA - F1 (Robustness)":"0.567",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.388,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.624",
        "QuAC - F1 (Robustness)":"0.275",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.448
    },
    {
        "Model":"Llama 2 (7B)",
        "Mean win rate":0.675,
        "MMLU - EM (Robustness)":0.373,
        "BoolQ - EM (Robustness)":0.676,
        "NarrativeQA - F1 (Robustness)":"0.573",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.261,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.501",
        "QuAC - F1 (Robustness)":"0.271",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.234
    },
    {
        "Model":"Llama 2 (13B)",
        "Mean win rate":0.832,
        "MMLU - EM (Robustness)":0.444,
        "BoolQ - EM (Robustness)":0.753,
        "NarrativeQA - F1 (Robustness)":"0.682",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.324,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.563",
        "QuAC - F1 (Robustness)":"0.294",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.287
    },
    {
        "Model":"Llama 2 (70B)",
        "Mean win rate":0.972,
        "MMLU - EM (Robustness)":0.545,
        "BoolQ - EM (Robustness)":0.863,
        "NarrativeQA - F1 (Robustness)":"0.722",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.42,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.639",
        "QuAC - F1 (Robustness)":"0.362",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.468
    },
    {
        "Model":"Alpaca (7B)",
        "Mean win rate":0.41,
        "MMLU - EM (Robustness)":0.324,
        "BoolQ - EM (Robustness)":0.643,
        "NarrativeQA - F1 (Robustness)":"0.246",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.203,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.491",
        "QuAC - F1 (Robustness)":"0.16",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.199
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Mean win rate":0.648,
        "MMLU - EM (Robustness)":0.371,
        "BoolQ - EM (Robustness)":0.672,
        "NarrativeQA - F1 (Robustness)":"0.5",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.214,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.539",
        "QuAC - F1 (Robustness)":"0.25",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.258
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Mean win rate":0.786,
        "MMLU - EM (Robustness)":0.413,
        "BoolQ - EM (Robustness)":0.757,
        "NarrativeQA - F1 (Robustness)":"0.525",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.273,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.621",
        "QuAC - F1 (Robustness)":"0.247",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.341
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Mean win rate":0.897,
        "MMLU - EM (Robustness)":0.533,
        "BoolQ - EM (Robustness)":0.837,
        "NarrativeQA - F1 (Robustness)":"0.649",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.305,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.631",
        "QuAC - F1 (Robustness)":"0.31",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.339
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":0.654,
        "MMLU - EM (Robustness)":0.403,
        "BoolQ - EM (Robustness)":0.733,
        "NarrativeQA - F1 (Robustness)":"0.319",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.307,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.525",
        "QuAC - F1 (Robustness)":"0.194",
        "HellaSwag - EM (Robustness)":"0.757",
        "OpenbookQA - EM (Robustness)":"0.476",
        "TruthfulQA - EM (Robustness)":0.202
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":0.226,
        "MMLU - EM (Robustness)":0.169,
        "BoolQ - EM (Robustness)":0.638,
        "NarrativeQA - F1 (Robustness)":"0.352",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.149,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.299",
        "QuAC - F1 (Robustness)":"0.159",
        "HellaSwag - EM (Robustness)":"0.656",
        "OpenbookQA - EM (Robustness)":"0.408",
        "TruthfulQA - EM (Robustness)":0.136
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":0.547,
        "MMLU - EM (Robustness)":0.34,
        "BoolQ - EM (Robustness)":0.639,
        "NarrativeQA - F1 (Robustness)":"0.498",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.256,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.521",
        "QuAC - F1 (Robustness)":"0.208",
        "HellaSwag - EM (Robustness)":"0.738",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.145
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":0.247,
        "MMLU - EM (Robustness)":0.19,
        "BoolQ - EM (Robustness)":0.545,
        "NarrativeQA - F1 (Robustness)":"0.367",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.126,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.338",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"0.632",
        "OpenbookQA - EM (Robustness)":"0.396",
        "TruthfulQA - EM (Robustness)":0.186
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":0.117,
        "MMLU - EM (Robustness)":0.166,
        "BoolQ - EM (Robustness)":0.477,
        "NarrativeQA - F1 (Robustness)":"0.255",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.068,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.212",
        "QuAC - F1 (Robustness)":"0.149",
        "HellaSwag - EM (Robustness)":"0.489",
        "OpenbookQA - EM (Robustness)":"0.314",
        "TruthfulQA - EM (Robustness)":0.162
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":0.085,
        "MMLU - EM (Robustness)":0.204,
        "BoolQ - EM (Robustness)":0.461,
        "NarrativeQA - F1 (Robustness)":"0.104",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.031,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.043",
        "QuAC - F1 (Robustness)":"0.092",
        "HellaSwag - EM (Robustness)":"0.37",
        "OpenbookQA - EM (Robustness)":"0.27",
        "TruthfulQA - EM (Robustness)":0.167
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":0.978,
        "MMLU - EM (Robustness)":0.517,
        "BoolQ - EM (Robustness)":0.858,
        "NarrativeQA - F1 (Robustness)":"0.694",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.369,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.73",
        "QuAC - F1 (Robustness)":"0.42",
        "HellaSwag - EM (Robustness)":"0.798",
        "OpenbookQA - EM (Robustness)":"0.572",
        "TruthfulQA - EM (Robustness)":0.516
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":0.932,
        "MMLU - EM (Robustness)":0.525,
        "BoolQ - EM (Robustness)":0.841,
        "NarrativeQA - F1 (Robustness)":"0.638",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.299,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.665",
        "QuAC - F1 (Robustness)":"0.319",
        "HellaSwag - EM (Robustness)":"0.776",
        "OpenbookQA - EM (Robustness)":"0.52",
        "TruthfulQA - EM (Robustness)":0.547
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":0.309,
        "MMLU - EM (Robustness)":0.22,
        "BoolQ - EM (Robustness)":0.549,
        "NarrativeQA - F1 (Robustness)":"0.34",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.121,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.415",
        "QuAC - F1 (Robustness)":"0.169",
        "HellaSwag - EM (Robustness)":"0.625",
        "OpenbookQA - EM (Robustness)":"0.424",
        "TruthfulQA - EM (Robustness)":0.235
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":0.132,
        "MMLU - EM (Robustness)":0.186,
        "BoolQ - EM (Robustness)":0.384,
        "NarrativeQA - F1 (Robustness)":"0.126",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.04,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.151",
        "QuAC - F1 (Robustness)":"0.087",
        "HellaSwag - EM (Robustness)":"0.468",
        "OpenbookQA - EM (Robustness)":"0.39",
        "TruthfulQA - EM (Robustness)":0.195
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":0.052,
        "MMLU - EM (Robustness)":0.178,
        "BoolQ - EM (Robustness)":0.332,
        "NarrativeQA - F1 (Robustness)":"0.058",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.008,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.034",
        "QuAC - F1 (Robustness)":"0.067",
        "HellaSwag - EM (Robustness)":"0.32",
        "OpenbookQA - EM (Robustness)":"0.248",
        "TruthfulQA - EM (Robustness)":0.175
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Mean win rate":0.838,
        "MMLU - EM (Robustness)":0.525,
        "BoolQ - EM (Robustness)":0.66,
        "NarrativeQA - F1 (Robustness)":"0.602",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.327,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.556",
        "QuAC - F1 (Robustness)":"0.411",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.566
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Mean win rate":0.739,
        "MMLU - EM (Robustness)":0.262,
        "BoolQ - EM (Robustness)":0.845,
        "NarrativeQA - F1 (Robustness)":"0.566",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.284,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.606",
        "QuAC - F1 (Robustness)":"0.371",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.187
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Mean win rate":0.325,
        "MMLU - EM (Robustness)":0.217,
        "BoolQ - EM (Robustness)":0.585,
        "NarrativeQA - F1 (Robustness)":"0.346",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.134,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.396",
        "QuAC - F1 (Robustness)":"0.177",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.226
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Mean win rate":0.321,
        "MMLU - EM (Robustness)":0.218,
        "BoolQ - EM (Robustness)":0.629,
        "NarrativeQA - F1 (Robustness)":"0.403",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.132,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.536",
        "QuAC - F1 (Robustness)":"0.137",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.173
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Mean win rate":0.369,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.569,
        "NarrativeQA - F1 (Robustness)":"0.424",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.167,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.472",
        "QuAC - F1 (Robustness)":"0.186",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.173
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Mean win rate":0.437,
        "MMLU - EM (Robustness)":0.291,
        "BoolQ - EM (Robustness)":0.599,
        "NarrativeQA - F1 (Robustness)":"0.482",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.137,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.547",
        "QuAC - F1 (Robustness)":"0.164",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.197
    },
    {
        "Model":"MPT (30B)",
        "Mean win rate":0.671,
        "MMLU - EM (Robustness)":0.381,
        "BoolQ - EM (Robustness)":0.656,
        "NarrativeQA - F1 (Robustness)":"0.584",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.272,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.609",
        "QuAC - F1 (Robustness)":"0.231",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.177
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Mean win rate":0.676,
        "MMLU - EM (Robustness)":0.383,
        "BoolQ - EM (Robustness)":0.77,
        "NarrativeQA - F1 (Robustness)":"0.623",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.202,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.607",
        "QuAC - F1 (Robustness)":"0.204",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.177
    },
    {
        "Model":"Falcon (7B)",
        "Mean win rate":0.432,
        "MMLU - EM (Robustness)":0.236,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.436",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.185,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.489",
        "QuAC - F1 (Robustness)":"0.164",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.205
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Mean win rate":0.271,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.593,
        "NarrativeQA - F1 (Robustness)":"0.258",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.132,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.327",
        "QuAC - F1 (Robustness)":"0.179",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.17
    },
    {
        "Model":"Falcon (40B)",
        "Mean win rate":0.733,
        "MMLU - EM (Robustness)":0.457,
        "BoolQ - EM (Robustness)":0.763,
        "NarrativeQA - F1 (Robustness)":"0.557",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.329,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.593",
        "QuAC - F1 (Robustness)":"0.162",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.303
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Mean win rate":0.774,
        "MMLU - EM (Robustness)":0.446,
        "BoolQ - EM (Robustness)":0.781,
        "NarrativeQA - F1 (Robustness)":"0.508",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.335,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.591",
        "QuAC - F1 (Robustness)":"0.212",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.338
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":0.591,
        "MMLU - EM (Robustness)":0.32,
        "BoolQ - EM (Robustness)":0.728,
        "NarrativeQA - F1 (Robustness)":"0.629",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.117,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.6",
        "QuAC - F1 (Robustness)":"0.193",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.196
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":0.531,
        "MMLU - EM (Robustness)":0.348,
        "BoolQ - EM (Robustness)":0.656,
        "NarrativeQA - F1 (Robustness)":"0.317",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.267,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.567",
        "QuAC - F1 (Robustness)":"0.248",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.151
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":0.98,
        "MMLU - EM (Robustness)":0.566,
        "BoolQ - EM (Robustness)":0.878,
        "NarrativeQA - F1 (Robustness)":"0.672",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.363,
        "NaturalQuestions (open-book) - F1 (Robustness)":"-",
        "QuAC - F1 (Robustness)":"0.383",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.568
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":0.196,
        "MMLU - EM (Robustness)":0.243,
        "BoolQ - EM (Robustness)":0.566,
        "NarrativeQA - F1 (Robustness)":"0.088",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.047,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.125",
        "QuAC - F1 (Robustness)":"0.08",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.202
    }
]