[
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Jumbo v1 (178B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Large v1 (7.5B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v1 (17B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"J1-Grande v2 beta (17B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Grande (17B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Jurassic-2 Large (7.5B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.52",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"29.94",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"58.74",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"7.92",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"BLOOM (176B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T0pp (11B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.42",
        "Synthetic efficiency - # prompt tokens":"563.42",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere large v20220720 (13.1B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere small v20220720 (410M) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.86",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1.98",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"31.72",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"3.96",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"63.48",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (6.1B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"7.94",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"31.9",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"63.98",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"Cohere Command beta (52.4B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"7.96",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-J (6B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GPT-NeoX (20B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"T5 (11B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.52",
        "Synthetic efficiency - # prompt tokens":"357.62",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"UL2 (20B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.6",
        "Synthetic efficiency - # prompt tokens":"359.4",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (175B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"OPT (66B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"davinci (175B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"curie (6.7B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"ada (350M) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"30.8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"57.18",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-003 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"0.98",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.68",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1.96",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"31.08",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"3.92",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"61.8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-davinci-002 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"7.84",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.86",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"30.76",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"58.18",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-curie-001 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.66",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"30.26",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"57.58",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-babbage-001 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"15.98",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"31.34",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"59",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"text-ada-001 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-davinci-002 [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"62.74",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0",
        "Synthetic efficiency - # prompt tokens":"665.8",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"GLM (130B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"1",
        "Synthetic efficiency - # prompt tokens":"665.62",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 1]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"1",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 16]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"16",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 2]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"2",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 32]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"32",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 4]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"4",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 64]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"64",
        "Synthetic efficiency - # trials":"1"
    },
    {
        "Model":"YaLM (100B) [max_tokens: 8]",
        "Mean win rate":"-",
        "Synthetic efficiency - # eval":"10",
        "Synthetic efficiency - # train":"0",
        "Synthetic efficiency - truncated":"0.26",
        "Synthetic efficiency - # prompt tokens":"665.54",
        "Synthetic efficiency - # output tokens":"8",
        "Synthetic efficiency - # trials":"1"
    }
]