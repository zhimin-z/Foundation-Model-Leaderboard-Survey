[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.489",
        "Denoised inference time (s)":"0.997",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"18.016",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.39",
        "Denoised inference time (s)":"0.512",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"17.27",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.438",
        "Denoised inference time (s)":"0.674",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"17.47",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.473",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"17.541",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.535",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"17.095",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.504",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"16.74",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.402",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"59.535",
        "# output tokens":"15.873",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.41",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.501",
        "# output tokens":"12.38",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.472",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.501",
        "# output tokens":"12.716",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.47",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.501",
        "# output tokens":"12.731",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.492",
        "Denoised inference time (s)":"1.218",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"13.776",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.396",
        "Denoised inference time (s)":"0.888",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.746",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.008",
        "Denoised inference time (s)":"0.128",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.659",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.483",
        "Denoised inference time (s)":"0.886",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"14.469",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.466",
        "Denoised inference time (s)":"0.484",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"12.529",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.449",
        "Denoised inference time (s)":"0.358",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"14.225",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.254",
        "Denoised inference time (s)":"0.283",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"11.378",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.468",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"13.421",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.42",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"12.8",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.429",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"13.465",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.549",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.038",
        "# output tokens":"14.164",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.413",
        "Denoised inference time (s)":"0.094",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.422",
        "Denoised inference time (s)":"0.062",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.56",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.289",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"3.856",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.291",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"3.815",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.26",
        "Denoised inference time (s)":"0.245",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.659",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.386",
        "Denoised inference time (s)":"0.22",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.659",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.422",
        "Denoised inference time (s)":"0.596",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.405",
        "Denoised inference time (s)":"0.145",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.285",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.636",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.272",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.393",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.325",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.324",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.591",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.462",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.522",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.627",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.395",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.552",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.393",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.429",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.438",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.336",
        "# output tokens":"4.596",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.527",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.497",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.534",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.376",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.147",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.42",
        "Denoised inference time (s)":"0.602",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.702",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.387",
        "Denoised inference time (s)":"0.174",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"13.992",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.325",
        "Denoised inference time (s)":"0.196",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.804",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.233",
        "Denoised inference time (s)":"0.213",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"13.549",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.571",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"17.865",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.554",
        "Denoised inference time (s)":"0.57",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.86",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.404",
        "Denoised inference time (s)":"0.208",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"13.103",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.29",
        "Denoised inference time (s)":"0.213",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"13.713",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.188",
        "Denoised inference time (s)":"0.141",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"11.476",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.513",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"61.588",
        "# output tokens":"25.027",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.539",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"61.588",
        "# output tokens":"20.486",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.261",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"3.893",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.294",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"4.006",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.329",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"3.911",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.379",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"4.059",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.515",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.475",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.893",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.445",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.653",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.409",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.653",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.481",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.653",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.509",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.653",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.367",
        "Denoised inference time (s)":"0.507",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.453",
        "# output tokens":"19.833",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.331",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.013",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.553",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.333",
        "# output tokens":"14.742",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.033",
        "Denoised inference time (s)":"0.336",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"67.626",
        "# output tokens":"40",
        "# trials":"3"
    }
]