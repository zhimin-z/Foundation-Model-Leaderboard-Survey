[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.618,
        "Denoised inference time (s)":"1.126",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.679,
        "Denoised inference time (s)":"0.832",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.643,
        "Denoised inference time (s)":"0.966",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.628,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.537,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":5765.889,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.618,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.661,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2036.998,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)\u2620",
        "BPB":0.529,
        "Denoised inference time (s)":"2.381",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":7832.227,
        "# output tokens":0.011,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)\u2620",
        "BPB":0.577,
        "Denoised inference time (s)":"1.168",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.713,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)\u2620",
        "BPB":0.525,
        "Denoised inference time (s)":"0.456",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)\u2620",
        "BPB":0.503,
        "Denoised inference time (s)":"0.933",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2040.215,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)\u2620",
        "BPB":0.73,
        "Denoised inference time (s)":"0.881",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)\u2620",
        "BPB":0.756,
        "Denoised inference time (s)":"0.33",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)\u2620",
        "BPB":0.608,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2040.741,
        "# output tokens":0.004,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)\u2620",
        "BPB":0.701,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2040.741,
        "# output tokens":0.004,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":0.788,
        "Denoised inference time (s)":"0.239",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.865,
        "Denoised inference time (s)":"0.12",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":0.95,
        "Denoised inference time (s)":"0.134",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":1.055,
        "Denoised inference time (s)":"0.144",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.555,
        "Denoised inference time (s)":"-",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3965.679,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.563,
        "Denoised inference time (s)":"0.346",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3965.679,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":1.071,
        "Denoised inference time (s)":"0.156",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":1.229,
        "Denoised inference time (s)":"0.169",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":1.771,
        "Denoised inference time (s)":"0.12",
        "# eval":238,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2041.731,
        "# output tokens":0.0,
        "# trials":1
    }
]