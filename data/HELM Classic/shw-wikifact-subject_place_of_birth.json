[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.082",
        "Denoised inference time (s)":"0.907",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"16.059",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.053",
        "Denoised inference time (s)":"0.487",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"15.957",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.078",
        "Denoised inference time (s)":"0.614",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"15.375",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.088",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"15.605",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.118",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"11.381",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.1",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"11.632",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.063",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"40.488",
        "# output tokens":"13.22",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.087",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"57.58",
        "# output tokens":"8.588",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.102",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"57.58",
        "# output tokens":"8.511",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.111",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"57.58",
        "# output tokens":"8.406",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.117",
        "Denoised inference time (s)":"0.934",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"8.847",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.043",
        "Denoised inference time (s)":"0.792",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"55.324",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.121",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.497",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.114",
        "Denoised inference time (s)":"0.663",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"8.95",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.097",
        "Denoised inference time (s)":"0.401",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"8.989",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.084",
        "Denoised inference time (s)":"0.303",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"9.725",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.046",
        "Denoised inference time (s)":"0.282",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"11.284",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.121",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"8.834",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.093",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"10.068",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.101",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"8.686",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.132",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.727",
        "# output tokens":"8.649",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.025",
        "Denoised inference time (s)":"0.099",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.028",
        "Denoised inference time (s)":"0.063",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"63.855",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.014",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"5.089",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.016",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"4.314",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.013",
        "Denoised inference time (s)":"0.241",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.497",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.027",
        "Denoised inference time (s)":"0.266",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"66.497",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.033",
        "Denoised inference time (s)":"0.612",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"39.969",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.035",
        "Denoised inference time (s)":"0.145",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.055",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.312",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.068",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.422",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.106",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.258",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.206",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.14",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.152",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.229",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.06",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.451",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.073",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.094",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.08",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"64.34",
        "# output tokens":"3.32",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.135",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.106",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"12.606",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.057",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"12.61",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.092",
        "Denoised inference time (s)":"0.565",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"13.472",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.067",
        "Denoised inference time (s)":"0.172",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"13.776",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.049",
        "Denoised inference time (s)":"0.178",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"11.868",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.026",
        "Denoised inference time (s)":"0.211",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"13.173",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.164",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"13.901",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.146",
        "Denoised inference time (s)":"0.475",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"11.606",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.078",
        "Denoised inference time (s)":"0.203",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"12.333",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.058",
        "Denoised inference time (s)":"0.199",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"11.759",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.037",
        "Denoised inference time (s)":"0.137",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"10.702",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.152",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"55.616",
        "# output tokens":"15.895",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.126",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"55.616",
        "# output tokens":"16.795",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.026",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"3.96",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.024",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"3.879",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.047",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"3.646",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.042",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"3.474",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.114",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.107",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.855",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.113",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"60.595",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.088",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"60.595",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.134",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"60.595",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.133",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"60.595",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.05",
        "Denoised inference time (s)":"0.512",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"57.35",
        "# output tokens":"21.644",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.042",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"11.042",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.155",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.798",
        "# output tokens":"9.767",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.043",
        "Denoised inference time (s)":"0.333",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"60.311",
        "# output tokens":"38.752",
        "# trials":"3"
    }
]