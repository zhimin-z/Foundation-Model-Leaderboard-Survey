[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent (chain of thought)":0.026,
        "Denoised inference time (s)":"7.143",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":153.981,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"3.688",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":196.955,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"4.004",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":161.603,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent (chain of thought)":0.077,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":181.115,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent (chain of thought)":0.058,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":1981.487,
        "# output tokens":182.59,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":178.288,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.551,
        "truncated":0.0,
        "# prompt tokens":1050.064,
        "# output tokens":194.179,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.923,
        "truncated":0.0,
        "# prompt tokens":1467.327,
        "# output tokens":170.897,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.923,
        "truncated":0.0,
        "# prompt tokens":1467.327,
        "# output tokens":169.603,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.923,
        "truncated":0.0,
        "# prompt tokens":1467.327,
        "# output tokens":162.269,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent (chain of thought)":0.135,
        "Denoised inference time (s)":"5.91",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2000.609,
        "# output tokens":88.25,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent (chain of thought)":0.058,
        "Denoised inference time (s)":"19.535",
        "# eval":52,
        "# train":6.186,
        "truncated":0.0,
        "# prompt tokens":1408.955,
        "# output tokens":182.468,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"5.308",
        "# eval":52,
        "# train":2.545,
        "truncated":0.038,
        "# prompt tokens":548.583,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"7.073",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":158.558,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"4.977",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":193.244,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"3.083",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":221.487,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"1.79",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":220.404,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent (chain of thought)":0.045,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":162.096,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":5.071,
        "truncated":0.0,
        "# prompt tokens":1480.16,
        "# output tokens":161.686,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.878,
        "truncated":0.0,
        "# prompt tokens":1446.942,
        "# output tokens":197.699,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent (chain of thought)":0.051,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":4.878,
        "truncated":0.0,
        "# prompt tokens":1446.942,
        "# output tokens":147.276,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"4.702",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":167.032,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent (chain of thought)":0.058,
        "Denoised inference time (s)":"5.525",
        "# eval":52,
        "# train":5.295,
        "truncated":0.0,
        "# prompt tokens":1436.083,
        "# output tokens":126.929,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":144.25,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":131.519,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"8.446",
        "# eval":52,
        "# train":1.545,
        "truncated":0.038,
        "# prompt tokens":359.244,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.142",
        "# eval":52,
        "# train":1.519,
        "truncated":0.038,
        "# prompt tokens":356.686,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"14.981",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":219.955,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"6.099",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":186.859,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent (chain of thought)":0.077,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent (chain of thought)":0.077,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent (chain of thought)":0.038,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2490.962,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent (chain of thought)":0.077,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2490.962,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent (chain of thought)":0.231,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2490.962,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":28.635,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent (chain of thought)":0.038,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":378.923,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent (chain of thought)":0.058,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.962,
        "truncated":0.0,
        "# prompt tokens":1552.038,
        "# output tokens":324.346,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent (chain of thought)":0.212,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent (chain of thought)":0.096,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":5.154,
        "truncated":0.0,
        "# prompt tokens":1478.647,
        "# output tokens":153.923,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent (chain of thought)":0.026,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":5.154,
        "truncated":0.0,
        "# prompt tokens":1478.647,
        "# output tokens":199.256,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"6.817",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":220.788,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"1.884",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":254.635,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"1.65",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":254.705,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent (chain of thought)":0.006,
        "Denoised inference time (s)":"1.585",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":241.596,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent (chain of thought)":0.321,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2000.609,
        "# output tokens":104.397,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent (chain of thought)":0.256,
        "Denoised inference time (s)":"7.686",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2000.609,
        "# output tokens":257.327,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent (chain of thought)":0.013,
        "Denoised inference time (s)":"0.46",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":45.859,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent (chain of thought)":0.006,
        "Denoised inference time (s)":"0.684",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":76.513,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent (chain of thought)":0.006,
        "Denoised inference time (s)":"0.707",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":100.814,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent (chain of thought)":0.282,
        "Denoised inference time (s)":"3.613",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2000.609,
        "# output tokens":134.756,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent (chain of thought)":0.083,
        "Denoised inference time (s)":"1.288",
        "# eval":52,
        "# train":5.16,
        "truncated":0.0,
        "# prompt tokens":1479.782,
        "# output tokens":148.615,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent (chain of thought)":0.712,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2197.577,
        "# output tokens":102.212,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent (chain of thought)":0.615,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2197.577,
        "# output tokens":91.135,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":103.519,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":58.404,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":172.346,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":195.019,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent (chain of thought)":0.038,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent (chain of thought)":0.077,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":3.231,
        "truncated":0.0,
        "# prompt tokens":1519.442,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.385,
        "truncated":0.0,
        "# prompt tokens":965.096,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.385,
        "truncated":0.0,
        "# prompt tokens":965.096,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent (chain of thought)":0.019,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.385,
        "truncated":0.0,
        "# prompt tokens":965.096,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent (chain of thought)":0.038,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":2.385,
        "truncated":0.0,
        "# prompt tokens":965.096,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent (chain of thought)":0.045,
        "Denoised inference time (s)":"8.821",
        "# eval":52,
        "# train":5.423,
        "truncated":0.0,
        "# prompt tokens":1456.853,
        "# output tokens":147.212,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent (chain of thought)":0.026,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":5.154,
        "truncated":0.0,
        "# prompt tokens":1478.647,
        "# output tokens":114.897,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent (chain of thought)":0.256,
        "Denoised inference time (s)":"-",
        "# eval":52,
        "# train":8.0,
        "truncated":0.0,
        "# prompt tokens":2000.609,
        "# output tokens":94.654,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"5.451",
        "# eval":52,
        "# train":6.244,
        "truncated":0.0,
        "# prompt tokens":1423.205,
        "# output tokens":397.615,
        "# trials":3
    }
]