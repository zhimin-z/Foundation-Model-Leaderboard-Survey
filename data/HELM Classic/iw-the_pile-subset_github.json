[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.28,
        "Denoised inference time (s)":"0.816",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.358,
        "Denoised inference time (s)":"0.621",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.314,
        "Denoised inference time (s)":"0.728",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.333,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.241,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1867.809,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.322,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.343,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1298.67,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)\u2620",
        "BPB":0.336,
        "Denoised inference time (s)":"1.07",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2431.43,
        "# output tokens":0.307,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)\u2620",
        "BPB":0.269,
        "Denoised inference time (s)":"0.878",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1178.366,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)\u2620",
        "BPB":0.234,
        "Denoised inference time (s)":"0.455",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)\u2620",
        "BPB":0.212,
        "Denoised inference time (s)":"0.895",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1289.834,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)\u2620",
        "BPB":0.443,
        "Denoised inference time (s)":"0.806",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.808,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)\u2620",
        "BPB":0.468,
        "Denoised inference time (s)":"0.548",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.808,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)\u2620",
        "BPB":0.319,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.281,
        "# output tokens":0.008,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)\u2620",
        "BPB":0.418,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.281,
        "# output tokens":0.008,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":0.515,
        "Denoised inference time (s)":"0.226",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.587,
        "Denoised inference time (s)":"0.11",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":0.687,
        "Denoised inference time (s)":"0.128",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":0.823,
        "Denoised inference time (s)":"0.142",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.205,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2014.117,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.214,
        "Denoised inference time (s)":"0.257",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2014.117,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":0.677,
        "Denoised inference time (s)":"0.148",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":0.814,
        "Denoised inference time (s)":"0.155",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":1.156,
        "Denoised inference time (s)":"0.108",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1454.813,
        "# output tokens":0.0,
        "# trials":1
    }
]