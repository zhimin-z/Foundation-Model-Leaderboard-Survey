[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent":0.132,
        "Denoised inference time (s)":"0.556",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":3.903,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent":0.074,
        "Denoised inference time (s)":"0.425",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":5.109,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent":0.097,
        "Denoised inference time (s)":"0.47",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":4.733,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent":0.132,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":3.089,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent":0.186,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":2.868,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent":0.174,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":2.822,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent":0.097,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":341.349,
        "# output tokens":3.899,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent":0.109,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":400.558,
        "# output tokens":1.961,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent":0.105,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":400.558,
        "# output tokens":1.744,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent":0.147,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":400.558,
        "# output tokens":2.054,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent":0.19,
        "Denoised inference time (s)":"0.63",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":1.864,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent":0.062,
        "Denoised inference time (s)":"0.639",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":335.105,
        "# output tokens":3.946,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.27",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":399.907,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent":0.194,
        "Denoised inference time (s)":"0.565",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":3.275,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"0.373",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":4.326,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent":0.07,
        "Denoised inference time (s)":"0.31",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":4.554,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent":0.023,
        "Denoised inference time (s)":"0.299",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":6.213,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent":0.182,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":4.112,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent":0.047,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":4.717,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent":0.143,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":4.628,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":390.57,
        "# output tokens":3.915,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent":0.178,
        "Denoised inference time (s)":"0.226",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.225,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent":0.116,
        "Denoised inference time (s)":"0.376",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":3.008,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent":0.116,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":2.616,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent":0.151,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":2.07,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.44",
        "# eval":86,
        "# train":7.903,
        "truncated":0,
        "# prompt tokens":395.302,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.341",
        "# eval":86,
        "# train":7.895,
        "truncated":0,
        "# prompt tokens":398.857,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent":0.12,
        "Denoised inference time (s)":"0.632",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":1.81,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent":0.035,
        "Denoised inference time (s)":"3.354",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.105,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":2.651,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent":0.151,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":3.244,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent":0.174,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":3.593,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent":0.314,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent":0.337,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent":0.105,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":4.035,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent":0.058,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":3.628,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent":0.093,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":424.616,
        "# output tokens":3.686,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent":0.291,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent":0.178,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.395,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent":0.085,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.345,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent":0.101,
        "Denoised inference time (s)":"0.246",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.031,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent":0.058,
        "Denoised inference time (s)":"0.1",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.26,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent":0.078,
        "Denoised inference time (s)":"0.125",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.039,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent":0.039,
        "Denoised inference time (s)":"0.142",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":1.24,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent":0.547,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.74,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent":0.438,
        "Denoised inference time (s)":"0.243",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.31,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent":0.054,
        "Denoised inference time (s)":"0.138",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.213,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent":0.035,
        "Denoised inference time (s)":"0.137",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":1.837,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent":0.012,
        "Denoised inference time (s)":"0.089",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":1.411,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent":0.581,
        "Denoised inference time (s)":"0.22",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":3.519,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent":0.132,
        "Denoised inference time (s)":"0.12",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":3.864,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent":0.686,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":358.035,
        "# output tokens":2.593,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent":0.64,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":358.035,
        "# output tokens":2.849,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent":0.058,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":1.953,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":2.035,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":2.826,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":1.919,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent":0.151,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent":0.128,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":370.407,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent":0.116,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":410.558,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":410.558,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent":0.221,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":410.558,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent":0.186,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":410.558,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.363",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":389.291,
        "# output tokens":4.593,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent":0.101,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.027,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent":0.395,
        "Denoised inference time (s)":"-",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":385.523,
        "# output tokens":2.116,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.378",
        "# eval":86,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":344.605,
        "# output tokens":19.163,
        "# trials":3
    }
]