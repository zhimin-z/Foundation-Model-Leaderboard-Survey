[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":0.424,
        "CivilComments - EM (Fairness)":0.478
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":0.273,
        "CivilComments - EM (Fairness)":0.447
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":0.485,
        "CivilComments - EM (Fairness)":0.482
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":0.121,
        "CivilComments - EM (Fairness)":0.404
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":0.773,
        "CivilComments - EM (Fairness)":0.507
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":0.258,
        "CivilComments - EM (Fairness)":0.445
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":0.106,
        "CivilComments - EM (Fairness)":0.403
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":0.091,
        "CivilComments - EM (Fairness)":0.397
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":0.348,
        "CivilComments - EM (Fairness)":0.462
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":0.212,
        "CivilComments - EM (Fairness)":0.432
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":0.803,
        "CivilComments - EM (Fairness)":0.512
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":0.909,
        "CivilComments - EM (Fairness)":0.546
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":0.015,
        "CivilComments - EM (Fairness)":0.165
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":0.455,
        "CivilComments - EM (Fairness)":0.479
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":0.242,
        "CivilComments - EM (Fairness)":0.443
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":0.53,
        "CivilComments - EM (Fairness)":0.489
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":0.621,
        "CivilComments - EM (Fairness)":0.495
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":0.152,
        "CivilComments - EM (Fairness)":0.415
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":0.591,
        "CivilComments - EM (Fairness)":0.493
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":0.636,
        "CivilComments - EM (Fairness)":0.496
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":0.894,
        "CivilComments - EM (Fairness)":0.544
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":0.515,
        "CivilComments - EM (Fairness)":0.488
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":0.576,
        "CivilComments - EM (Fairness)":0.491
    },
    {
        "Model":"Pythia (6.9B)",
        "Mean win rate":0.061,
        "CivilComments - EM (Fairness)":0.333
    },
    {
        "Model":"Pythia (12B)",
        "Mean win rate":0.288,
        "CivilComments - EM (Fairness)":0.448
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":0.045,
        "CivilComments - EM (Fairness)":0.329
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":0.182,
        "CivilComments - EM (Fairness)":0.423
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":0.561,
        "CivilComments - EM (Fairness)":0.491
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":0.712,
        "CivilComments - EM (Fairness)":0.5
    },
    {
        "Model":"LLaMA (7B)",
        "Mean win rate":0.758,
        "CivilComments - EM (Fairness)":0.505
    },
    {
        "Model":"LLaMA (13B)",
        "Mean win rate":0.864,
        "CivilComments - EM (Fairness)":0.533
    },
    {
        "Model":"LLaMA (30B)",
        "Mean win rate":0.788,
        "CivilComments - EM (Fairness)":0.508
    },
    {
        "Model":"LLaMA (65B)",
        "Mean win rate":1.0,
        "CivilComments - EM (Fairness)":0.574
    },
    {
        "Model":"Llama 2 (7B)",
        "Mean win rate":0.742,
        "CivilComments - EM (Fairness)":0.503
    },
    {
        "Model":"Llama 2 (13B)",
        "Mean win rate":0.545,
        "CivilComments - EM (Fairness)":0.489
    },
    {
        "Model":"Llama 2 (70B)",
        "Mean win rate":0.924,
        "CivilComments - EM (Fairness)":0.551
    },
    {
        "Model":"Alpaca (7B)",
        "Mean win rate":0.5,
        "CivilComments - EM (Fairness)":0.483
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Mean win rate":0.97,
        "CivilComments - EM (Fairness)":0.564
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Mean win rate":0.985,
        "CivilComments - EM (Fairness)":0.569
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Mean win rate":0.818,
        "CivilComments - EM (Fairness)":0.52
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":0.47,
        "CivilComments - EM (Fairness)":0.48
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":0.394,
        "CivilComments - EM (Fairness)":0.473
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":0.439,
        "CivilComments - EM (Fairness)":0.478
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":0.136,
        "CivilComments - EM (Fairness)":0.412
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":0.409,
        "CivilComments - EM (Fairness)":0.474
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":0.227,
        "CivilComments - EM (Fairness)":0.436
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":0.955,
        "CivilComments - EM (Fairness)":0.559
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":0.364,
        "CivilComments - EM (Fairness)":0.463
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":0.379,
        "CivilComments - EM (Fairness)":0.471
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":0.667,
        "CivilComments - EM (Fairness)":0.499
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":0.652,
        "CivilComments - EM (Fairness)":0.497
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Mean win rate":0.167,
        "CivilComments - EM (Fairness)":0.422
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Mean win rate":0.833,
        "CivilComments - EM (Fairness)":0.525
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Mean win rate":0.076,
        "CivilComments - EM (Fairness)":0.393
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Mean win rate":0.682,
        "CivilComments - EM (Fairness)":0.499
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Mean win rate":0.197,
        "CivilComments - EM (Fairness)":0.431
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Mean win rate":0.879,
        "CivilComments - EM (Fairness)":0.54
    },
    {
        "Model":"MPT (30B)",
        "Mean win rate":0.939,
        "CivilComments - EM (Fairness)":0.553
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Mean win rate":0.848,
        "CivilComments - EM (Fairness)":0.527
    },
    {
        "Model":"Falcon (7B)",
        "Mean win rate":0.606,
        "CivilComments - EM (Fairness)":0.494
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Mean win rate":0.727,
        "CivilComments - EM (Fairness)":0.502
    },
    {
        "Model":"Falcon (40B)",
        "Mean win rate":0.03,
        "CivilComments - EM (Fairness)":0.292
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Mean win rate":0.333,
        "CivilComments - EM (Fairness)":0.462
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":0.697,
        "CivilComments - EM (Fairness)":0.5
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":0.303,
        "CivilComments - EM (Fairness)":0.449
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":0.0,
        "CivilComments - EM (Fairness)":0.006
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":0.318,
        "CivilComments - EM (Fairness)":0.456
    }
]