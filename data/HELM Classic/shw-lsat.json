[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.232",
        "Denoised inference time (s)":"0.665",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.196",
        "Denoised inference time (s)":"0.536",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.188",
        "Denoised inference time (s)":"0.587",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.191",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.219",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.22",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.217",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"905.539",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.235",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1180.557",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.188",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1180.557",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.212",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1180.557",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.213",
        "Denoised inference time (s)":"0.736",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.209",
        "Denoised inference time (s)":"0.418",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1156.451",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.186",
        "Denoised inference time (s)":"0.142",
        "# eval":"230",
        "# train":"3.609",
        "truncated":"0",
        "# prompt tokens":"926.957",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.2",
        "Denoised inference time (s)":"0.682",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.193",
        "Denoised inference time (s)":"0.487",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.212",
        "Denoised inference time (s)":"0.389",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.187",
        "Denoised inference time (s)":"0.423",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.204",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.206",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.178",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.229",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.878",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.175",
        "Denoised inference time (s)":"0.134",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.191",
        "Denoised inference time (s)":"0.27",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1202.164",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.196",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.183",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.159",
        "Denoised inference time (s)":"0.225",
        "# eval":"230",
        "# train":"0.938",
        "truncated":"0.064",
        "# prompt tokens":"417.646",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.207",
        "Denoised inference time (s)":"0.19",
        "# eval":"230",
        "# train":"0.93",
        "truncated":"0.07",
        "# prompt tokens":"420.317",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.22",
        "Denoised inference time (s)":"0.369",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.175",
        "Denoised inference time (s)":"0.116",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.209",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.187",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.148",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.235",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.235",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.222",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.183",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.209",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1261.191",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.228",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.19",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.191",
        "Denoised inference time (s)":"0.216",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.18",
        "Denoised inference time (s)":"0.103",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.261",
        "Denoised inference time (s)":"0.124",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.188",
        "Denoised inference time (s)":"0.141",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.233",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.229",
        "Denoised inference time (s)":"0.214",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.172",
        "Denoised inference time (s)":"0.141",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.19",
        "Denoised inference time (s)":"0.149",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.213",
        "Denoised inference time (s)":"0.102",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "EM":"0",
        "Denoised inference time (s)":"0.204",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":"0",
        "Denoised inference time (s)":"0.101",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.252",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1134.604",
        "# output tokens":"1.004",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.161",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1134.604",
        "# output tokens":"1.443",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.17",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.178",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.243",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.248",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1176.83",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.204",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1181.948",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.204",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1181.948",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1181.948",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.183",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1181.948",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.193",
        "Denoised inference time (s)":"0.576",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1156.543",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.187",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.225",
        "Denoised inference time (s)":"-",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1190.129",
        "# output tokens":"0.991",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.23",
        "Denoised inference time (s)":"0.251",
        "# eval":"230",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1186.445",
        "# output tokens":"1",
        "# trials":"3"
    }
]