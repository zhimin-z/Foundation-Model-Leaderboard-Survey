[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.054",
        "Denoised inference time (s)":"7.243",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"158.822",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.014",
        "Denoised inference time (s)":"3.907",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"214.018",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.054",
        "Denoised inference time (s)":"3.72",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"152.079",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.096",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"136.418",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.225",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"111.793",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.133",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"126.368",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.03",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"789.727",
        "# output tokens":"208.932",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.026",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"877.454",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.067",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"877.454",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.112",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"877.454",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.171",
        "Denoised inference time (s)":"6.171",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"98.636",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.095",
        "Denoised inference time (s)":"9.403",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"823.745",
        "# output tokens":"363.933",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"4.584",
        "# eval":"1000",
        "# train":"4.927",
        "truncated":"0",
        "# prompt tokens":"927.104",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.07",
        "Denoised inference time (s)":"6.722",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"154.41",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.018",
        "Denoised inference time (s)":"4.515",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"179.471",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.015",
        "Denoised inference time (s)":"2.315",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"164.999",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.004",
        "Denoised inference time (s)":"1.796",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"241.523",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.1",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"130.87",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.017",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"114.619",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.036",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"126.028",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.138",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"883.757",
        "# output tokens":"111.456",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.036",
        "Denoised inference time (s)":"3.353",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"367.283",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.053",
        "Denoised inference time (s)":"3.566",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"889.249",
        "# output tokens":"386.245",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.014",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.032",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.023",
        "Denoised inference time (s)":"8.635",
        "# eval":"1000",
        "# train":"1.905",
        "truncated":"0",
        "# prompt tokens":"460.351",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.024",
        "Denoised inference time (s)":"4.203",
        "# eval":"1000",
        "# train":"1.88",
        "truncated":"0",
        "# prompt tokens":"460.805",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.04",
        "Denoised inference time (s)":"7.663",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"391.689",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.018",
        "Denoised inference time (s)":"5.53",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"400",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.08",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.154",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.32",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.466",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.133",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.245",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.484",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.012",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"97.861",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.134",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"375.967",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.226",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1207.746",
        "# output tokens":"395.86",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.381",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.146",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"125.933",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.018",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"170.803",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.09",
        "Denoised inference time (s)":"4.044",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"128.738",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.016",
        "Denoised inference time (s)":"1.329",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"176.395",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.007",
        "Denoised inference time (s)":"1.626",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"251.824",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.006",
        "Denoised inference time (s)":"1.556",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"236.808",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.506",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"93.018",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.415",
        "Denoised inference time (s)":"2.641",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"85.812",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.006",
        "Denoised inference time (s)":"0.432",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"41.515",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0",
        "Denoised inference time (s)":"0.376",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"34.591",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.004",
        "Denoised inference time (s)":"0.435",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"57.682",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "EM":"0.568",
        "Denoised inference time (s)":"3.033",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"113.059",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":"0.049",
        "Denoised inference time (s)":"1.188",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"136.778",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.531",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"959.035",
        "# output tokens":"113.005",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.469",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"959.035",
        "# output tokens":"114.72",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.01",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.011",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.021",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.016",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"400",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.164",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.344",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"939.582",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.04",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1056.967",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.052",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1056.967",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.25",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1056.967",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.338",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1056.967",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.061",
        "Denoised inference time (s)":"6.761",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1066.292",
        "# output tokens":"151.917",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.063",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"76.416",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.633",
        "Denoised inference time (s)":"-",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"880.202",
        "# output tokens":"90.399",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0",
        "Denoised inference time (s)":"4.26",
        "# eval":"1000",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"829.652",
        "# output tokens":"400",
        "# trials":"3"
    }
]