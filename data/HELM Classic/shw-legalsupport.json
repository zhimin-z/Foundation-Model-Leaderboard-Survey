[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.484",
        "Denoised inference time (s)":"0.487",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.514",
        "Denoised inference time (s)":"0.395",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.504",
        "Denoised inference time (s)":"0.425",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.562",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.639",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.575",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.558",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"439.902",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.513",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.734",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.517",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.734",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.53",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.734",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.624",
        "Denoised inference time (s)":"0.555",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.543",
        "Denoised inference time (s)":"0.193",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"620.172",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.611",
        "Denoised inference time (s)":"0.146",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"689.176",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.558",
        "Denoised inference time (s)":"0.507",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.491",
        "Denoised inference time (s)":"0.349",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.507",
        "Denoised inference time (s)":"0.301",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.524",
        "Denoised inference time (s)":"0.313",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.526",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.489",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.566",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.606",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"629.922",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.479",
        "Denoised inference time (s)":"0.066",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.515",
        "Denoised inference time (s)":"0.245",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"610.996",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.521",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.491",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.558",
        "Denoised inference time (s)":"0.211",
        "# eval":"489",
        "# train":"1.323",
        "truncated":"0.002",
        "# prompt tokens":"395.955",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.506",
        "Denoised inference time (s)":"0.18",
        "# eval":"489",
        "# train":"1.286",
        "truncated":"0.002",
        "# prompt tokens":"392.164",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.532",
        "Denoised inference time (s)":"0.425",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.527",
        "Denoised inference time (s)":"0.118",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.485",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.587",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.638",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.591",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.532",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.591",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.585",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.483",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.605",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.589",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"707.947",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.585",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.58",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.504",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.496",
        "Denoised inference time (s)":"0.203",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.49",
        "Denoised inference time (s)":"0.094",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.492",
        "Denoised inference time (s)":"0.118",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.372",
        "Denoised inference time (s)":"0.14",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.622",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.615",
        "Denoised inference time (s)":"0.174",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.442",
        "Denoised inference time (s)":"0.139",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.517",
        "Denoised inference time (s)":"0.135",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.515",
        "Denoised inference time (s)":"0.089",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "EM":"0",
        "Denoised inference time (s)":"0.193",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":"0",
        "Denoised inference time (s)":"0.095",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.628",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"579.986",
        "# output tokens":"1.014",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.468",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"579.986",
        "# output tokens":"1.254",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.513",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.485",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.517",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.569",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.564",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.538",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"597.329",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.511",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"612.779",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.452",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"612.779",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.605",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"612.779",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.605",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"612.779",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.451",
        "Denoised inference time (s)":"0.229",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"609.591",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.492",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.623",
        "Denoised inference time (s)":"-",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"605.753",
        "# output tokens":"0.996",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.484",
        "Denoised inference time (s)":"0.105",
        "# eval":"489",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"604.56",
        "# output tokens":"1",
        "# trials":"3"
    }
]