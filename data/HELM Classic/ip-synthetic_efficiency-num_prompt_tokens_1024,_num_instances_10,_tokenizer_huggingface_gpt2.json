[
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"ada (350M) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":30.3,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":55.9,
        "# trials":1
    },
    {
        "Model":"text-davinci-003 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":15.9,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":30.3,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":59.1,
        "# trials":1
    },
    {
        "Model":"text-ada-001 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"code-davinci-002 [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 1]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 16]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":16.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 2]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 32]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":32.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 4]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":4.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 64]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":64.0,
        "# trials":1
    },
    {
        "Model":"code-cushman-001 (12B) [max_tokens: 8]",
        "# eval":10,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1024,
        "# output tokens":8.0,
        "# trials":1
    }
]