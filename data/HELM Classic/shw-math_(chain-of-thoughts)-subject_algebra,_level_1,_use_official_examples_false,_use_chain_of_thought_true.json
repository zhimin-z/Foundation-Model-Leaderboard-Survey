[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"7.445",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":163.086,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent (chain of thought)":0.012,
        "Denoised inference time (s)":"2.451",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":121.948,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent (chain of thought)":0.017,
        "Denoised inference time (s)":"3.478",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":139.691,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent (chain of thought)":0.074,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":112.141,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent (chain of thought)":0.079,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":121.037,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent (chain of thought)":0.035,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":132.709,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":840.541,
        "# output tokens":131.422,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":934.052,
        "# output tokens":142.723,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":934.052,
        "# output tokens":129.854,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent (chain of thought)":0.054,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":934.052,
        "# output tokens":111.973,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent (chain of thought)":0.128,
        "Denoised inference time (s)":"3.95",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":59.538,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent (chain of thought)":0.064,
        "Denoised inference time (s)":"15.377",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":762.489,
        "# output tokens":106.43,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.801",
        "# eval":135,
        "# train":7.662,
        "truncated":0,
        "# prompt tokens":945.667,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent (chain of thought)":0.04,
        "Denoised inference time (s)":"5.195",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":115.837,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent (chain of thought)":0.017,
        "Denoised inference time (s)":"3.243",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":123.654,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent (chain of thought)":0.017,
        "Denoised inference time (s)":"2.415",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":172.486,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"1.207",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":141.938,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent (chain of thought)":0.079,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":104.04,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent (chain of thought)":0.03,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":127.227,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent (chain of thought)":0.005,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":140.116,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent (chain of thought)":0.074,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":936.667,
        "# output tokens":114.731,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent (chain of thought)":0.032,
        "Denoised inference time (s)":"3.973",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":146.037,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent (chain of thought)":0.059,
        "Denoised inference time (s)":"3.874",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":863.896,
        "# output tokens":102.536,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":133.881,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent (chain of thought)":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":130.356,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"10.511",
        "# eval":135,
        "# train":3.946,
        "truncated":0,
        "# prompt tokens":471.148,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.23",
        "# eval":135,
        "# train":3.886,
        "truncated":0,
        "# prompt tokens":467.657,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent (chain of thought)":0.007,
        "Denoised inference time (s)":"13.848",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":142.533,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent (chain of thought)":0.01,
        "Denoised inference time (s)":"5.792",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":133.267,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent (chain of thought)":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent (chain of thought)":0.074,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent (chain of thought)":0.274,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent (chain of thought)":0.459,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent (chain of thought)":0.126,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent (chain of thought)":0.215,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent (chain of thought)":0.437,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":94.126,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent (chain of thought)":0.104,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":380.363,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent (chain of thought)":0.126,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":971.652,
        "# output tokens":368.837,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent (chain of thought)":0.422,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent (chain of thought)":0.136,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":97.553,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":131.889,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent (chain of thought)":0.049,
        "Denoised inference time (s)":"4.246",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":135.449,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"1.242",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":163.854,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent (chain of thought)":0.01,
        "Denoised inference time (s)":"1.327",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":201.842,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent (chain of thought)":0.01,
        "Denoised inference time (s)":"0.942",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":134.38,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent (chain of thought)":0.504,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":67.835,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent (chain of thought)":0.509,
        "Denoised inference time (s)":"2.825",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":92.099,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent (chain of thought)":0.005,
        "Denoised inference time (s)":"0.947",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":114.983,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"0.47",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":47.835,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"0.414",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":54.02,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent (chain of thought)":0.57,
        "Denoised inference time (s)":"2.048",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":73.43,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent (chain of thought)":0.037,
        "Denoised inference time (s)":"1.365",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":158.79,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent (chain of thought)":0.889,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":881.363,
        "# output tokens":71.496,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent (chain of thought)":0.881,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":881.363,
        "# output tokens":79.215,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":98.2,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent (chain of thought)":0.007,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":106.03,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":138.83,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent (chain of thought)":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":101.6,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent (chain of thought)":0.111,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent (chain of thought)":0.2,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":860.23,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent (chain of thought)":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1013.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent (chain of thought)":0.044,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1013.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent (chain of thought)":0.096,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1013.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent (chain of thought)":0.141,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1013.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent (chain of thought)":0.052,
        "Denoised inference time (s)":"6.172",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":934.607,
        "# output tokens":94.733,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":86.163,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent (chain of thought)":0.523,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":916.222,
        "# output tokens":65.326,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.433",
        "# eval":135,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":788.304,
        "# output tokens":396.385,
        "# trials":3
    }
]