[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.879",
        "Denoised inference time (s)":"0.669",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.855",
        "Denoised inference time (s)":"0.525",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.876",
        "Denoised inference time (s)":"0.579",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.872",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.819",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.876",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.869",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"818.943",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.629",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"840.166",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.663",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"840.166",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.566",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"840.166",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.573",
        "Denoised inference time (s)":"0.602",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.885",
        "Denoised inference time (s)":"0.416",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"792.165",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.166",
        "# eval":"493",
        "# train":"4.622",
        "truncated":"0",
        "# prompt tokens":"951.1",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.859",
        "Denoised inference time (s)":"0.571",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.71",
        "Denoised inference time (s)":"0.399",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.383",
        "Denoised inference time (s)":"0.339",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.126",
        "Denoised inference time (s)":"0.346",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.87",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.429",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.861",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.517",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"838.742",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.126",
        "Denoised inference time (s)":"0.213",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.874",
        "Denoised inference time (s)":"0.175",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"855.417",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.874",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.84",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.785",
        "Denoised inference time (s)":"0.234",
        "# eval":"493",
        "# train":"1.508",
        "truncated":"0.007",
        "# prompt tokens":"431.516",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.87",
        "Denoised inference time (s)":"0.22",
        "# eval":"493",
        "# train":"1.483",
        "truncated":"0.007",
        "# prompt tokens":"431.677",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.358",
        "Denoised inference time (s)":"0.693",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.32",
        "Denoised inference time (s)":"0.269",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.876",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.88",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.923",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.89",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.844",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.363",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.712",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.882",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"2.079",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.884",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.927",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1022.112",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.937",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1003.416",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.892",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.771",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.551",
        "Denoised inference time (s)":"0.211",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.34",
        "Denoised inference time (s)":"0.101",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.376",
        "Denoised inference time (s)":"0.121",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.383",
        "Denoised inference time (s)":"0.141",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.92",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.899",
        "Denoised inference time (s)":"0.181",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.877",
        "Denoised inference time (s)":"0.148",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.867",
        "Denoised inference time (s)":"0.14",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.827",
        "Denoised inference time (s)":"0.094",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.963",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"827.469",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.949",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"827.469",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.134",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.874",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.85",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.876",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.888",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.882",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"850.751",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.86",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"892.389",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.874",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"892.389",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.746",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"892.389",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.919",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"892.389",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.335",
        "Denoised inference time (s)":"0.632",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"988.455",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.815",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.964",
        "Denoised inference time (s)":"-",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"860.029",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.126",
        "Denoised inference time (s)":"0.502",
        "# eval":"493",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"795.001",
        "# output tokens":"5",
        "# trials":"3"
    }
]