[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"72.469",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"22.013",
        "XSUM - # trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"89.614",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"21.299",
        "XSUM - # trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"67.049",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"20.468",
        "XSUM - # trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"53.215",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"22.092",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"49.239",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"22.142",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"55.762",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"21.75",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1213.032",
        "CNN\/DailyMail - # output tokens":"58.246",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1133.388",
        "XSUM - # output tokens":"21.228",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1578.648",
        "CNN\/DailyMail - # output tokens":"80.866",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1532.912",
        "XSUM - # output tokens":"26.021",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1578.648",
        "CNN\/DailyMail - # output tokens":"83.112",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1532.912",
        "XSUM - # output tokens":"25.987",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1578.648",
        "CNN\/DailyMail - # output tokens":"75.51",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1532.912",
        "XSUM - # output tokens":"26.423",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"58.035",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.735",
        "XSUM - # output tokens":"28.94",
        "XSUM - # trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1541.33",
        "CNN\/DailyMail - # output tokens":"117.435",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1501.338",
        "XSUM - # output tokens":"54.066",
        "XSUM - # trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.335",
        "CNN\/DailyMail - truncated":"0.004",
        "CNN\/DailyMail - # prompt tokens":"886.838",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"2.068",
        "XSUM - truncated":"0.01",
        "XSUM - # prompt tokens":"907.769",
        "XSUM - # output tokens":"64",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"89.431",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"24.802",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"74.505",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"22.992",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"63.193",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"24.055",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"78.352",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"27.394",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"91.338",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"26.153",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"68.601",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.998",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.452",
        "XSUM - # output tokens":"23.626",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"73.723",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.997",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.293",
        "XSUM - # output tokens":"23.421",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1575.036",
        "CNN\/DailyMail - # output tokens":"74.406",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.997",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1537.293",
        "XSUM - # output tokens":"24.351",
        "XSUM - # trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"83.931",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"25.529",
        "XSUM - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1582.608",
        "CNN\/DailyMail - # output tokens":"80.409",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.997",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1545.148",
        "XSUM - # output tokens":"25.402",
        "XSUM - # trials":"3"
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.064",
        "CNN\/DailyMail - truncated":"0.932",
        "CNN\/DailyMail - # prompt tokens":"500.553",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"0.3",
        "XSUM - truncated":"0.671",
        "XSUM - # prompt tokens":"436.826",
        "XSUM - # output tokens":"64",
        "XSUM - # trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.061",
        "CNN\/DailyMail - truncated":"0.935",
        "CNN\/DailyMail - # prompt tokens":"500.829",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"0.293",
        "XSUM - truncated":"0.677",
        "XSUM - # prompt tokens":"437.97",
        "XSUM - # output tokens":"64",
        "XSUM - # trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"73.533",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"26.229",
        "XSUM - # trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"77.928",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"24.362",
        "XSUM - # trials":"3"
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"66.904",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"27.501",
        "XSUM - # trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"83.556",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"23.579",
        "XSUM - # trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"4.286",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1411.872",
        "CNN\/DailyMail - # output tokens":"68.76",
        "CNN\/DailyMail - # trials":"2.714",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.285",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1350.13",
        "XSUM - # output tokens":"31.877",
        "XSUM - # trials":"2.714"
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"4.286",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1411.872",
        "CNN\/DailyMail - # output tokens":"74.606",
        "CNN\/DailyMail - # trials":"2.714",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.285",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1350.13",
        "XSUM - # output tokens":"27.757",
        "XSUM - # trials":"2.714"
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"68.44",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"25.051",
        "XSUM - # trials":"3"
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"76.958",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"16.878",
        "XSUM - # trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"64.315",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.735",
        "XSUM - # output tokens":"35.293",
        "XSUM - # trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"4.286",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1411.872",
        "CNN\/DailyMail - # output tokens":"70.37",
        "CNN\/DailyMail - # trials":"2.714",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.286",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1350.402",
        "XSUM - # output tokens":"28.674",
        "XSUM - # trials":"2.714"
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"4.286",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1411.872",
        "CNN\/DailyMail - # output tokens":"94.314",
        "CNN\/DailyMail - # trials":"2.714",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.285",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1350.13",
        "XSUM - # output tokens":"32.345",
        "XSUM - # trials":"2.714"
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"116.858",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"40.165",
        "XSUM - # trials":"3"
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"114.938",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"34.806",
        "XSUM - # trials":"3"
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1657.124",
        "CNN\/DailyMail - # output tokens":"82.997",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.996",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1567.312",
        "XSUM - # output tokens":"25.737",
        "XSUM - # trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"83.965",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"4.999",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.418",
        "XSUM - # output tokens":"26.632",
        "XSUM - # trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"17.63",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1510.735",
        "XSUM - # output tokens":"25.248",
        "XSUM - # trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1544.765",
        "CNN\/DailyMail - # output tokens":"102.407",
        "CNN\/DailyMail - # trials":"3",
        "XSUM - # eval":"518",
        "XSUM - # train":"5",
        "XSUM - truncated":"0",
        "XSUM - # prompt tokens":"1507.497",
        "XSUM - # output tokens":"49.401",
        "XSUM - # trials":"3"
    }
]