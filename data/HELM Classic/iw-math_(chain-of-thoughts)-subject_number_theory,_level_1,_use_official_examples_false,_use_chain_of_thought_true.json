[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"8.661",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":190.7,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent (chain of thought)":0.044,
        "Denoised inference time (s)":"3.688",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":196.789,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"3.574",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":142.144,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":145.011,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent (chain of thought)":0.078,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":134.722,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent (chain of thought)":0.044,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":142.0,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":972.1,
        "# output tokens":164.678,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1132.167,
        "# output tokens":163.133,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1132.167,
        "# output tokens":136.156,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1132.167,
        "# output tokens":123.433,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent (chain of thought)":0.111,
        "Denoised inference time (s)":"3.576",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":51.467,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent (chain of thought)":0.011,
        "Denoised inference time (s)":"19.316",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":961.267,
        "# output tokens":154.389,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.43",
        "# eval":30,
        "# train":6.0,
        "truncated":0,
        "# prompt tokens":907.433,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"6.573",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":148.644,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"5.038",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":199.367,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent (chain of thought)":0.044,
        "Denoised inference time (s)":"2.752",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":198.344,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"1.234",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":138.111,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":111.322,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":161.289,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent (chain of thought)":0.078,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":151.767,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent (chain of thought)":0.078,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1147.867,
        "# output tokens":123.456,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"2.97",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":114.656,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent (chain of thought)":0.089,
        "Denoised inference time (s)":"5.521",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1050.033,
        "# output tokens":128.067,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":136.167,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":146.1,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"8.311",
        "# eval":30,
        "# train":2.822,
        "truncated":0,
        "# prompt tokens":382.856,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"4.748",
        "# eval":30,
        "# train":2.778,
        "truncated":0,
        "# prompt tokens":375.878,
        "# output tokens":400.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent (chain of thought)":0.089,
        "Denoised inference time (s)":"9.085",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":81.4,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent (chain of thought)":0.056,
        "Denoised inference time (s)":"5.637",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":132.533,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent (chain of thought)":0.233,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":400.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent (chain of thought)":0.333,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":97.9,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":384.4,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent (chain of thought)":0.167,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1121.633,
        "# output tokens":318.967,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent (chain of thought)":0.044,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":125.744,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent (chain of thought)":0.033,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":189.389,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent (chain of thought)":0.011,
        "Denoised inference time (s)":"5.034",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":161.644,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent (chain of thought)":0.056,
        "Denoised inference time (s)":"1.005",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":129.844,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent (chain of thought)":0.011,
        "Denoised inference time (s)":"1.138",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":170.011,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent (chain of thought)":0.011,
        "Denoised inference time (s)":"1.211",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":179.322,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent (chain of thought)":0.389,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":78.111,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent (chain of thought)":0.367,
        "Denoised inference time (s)":"2.923",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":94.756,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent (chain of thought)":0.056,
        "Denoised inference time (s)":"0.47",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":47.656,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent (chain of thought)":0.022,
        "Denoised inference time (s)":"0.375",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":33.611,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"0.529",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":72.456,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent (chain of thought)":0.367,
        "Denoised inference time (s)":"2.562",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":94.833,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent (chain of thought)":0.111,
        "Denoised inference time (s)":"0.817",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":90.356,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent (chain of thought)":0.733,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":983.233,
        "# output tokens":86.6,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent (chain of thought)":0.7,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":983.233,
        "# output tokens":88.4,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":115.567,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":76.9,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":183.6,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent (chain of thought)":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":78.333,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":943.033,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1101.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1101.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent (chain of thought)":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1101.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent (chain of thought)":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1101.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent (chain of thought)":0.078,
        "Denoised inference time (s)":"8.629",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1169.367,
        "# output tokens":157.156,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent (chain of thought)":0.089,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":86.689,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent (chain of thought)":0.244,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1115.067,
        "# output tokens":64.022,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent (chain of thought)":0.0,
        "Denoised inference time (s)":"5.56",
        "# eval":30,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":1005.767,
        "# output tokens":400.0,
        "# trials":3
    }
]