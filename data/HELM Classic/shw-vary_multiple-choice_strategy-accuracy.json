[
    {
        "Model":"Anthropic-LM v4-s3 (52B) [method: multiple_choice_joint]",
        "Mean win rate":"0.728",
        "HellaSwag - EM":"0.543",
        "OpenbookQA - EM":"0.684",
        "TruthfulQA - EM":"0.361",
        "MMLU - EM":"0.481",
        "BLiMP - EM":"0",
        "LegalSupport - EM":"0.624",
        "LSAT - EM":"0.213",
        "BBQ - EM":"0.551"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.603",
        "HellaSwag - EM":"0.593",
        "OpenbookQA - EM":"0.558",
        "TruthfulQA - EM":"0.332",
        "MMLU - EM":"0.408",
        "BLiMP - EM":"0.529",
        "LegalSupport - EM":"0.569",
        "LSAT - EM":"0.191",
        "BBQ - EM":"0.259"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.662",
        "HellaSwag - EM":"0.807",
        "OpenbookQA - EM":"0.446",
        "TruthfulQA - EM":"0.257",
        "MMLU - EM":"0.37",
        "BLiMP - EM":"0.829",
        "LegalSupport - EM":"0.544",
        "LSAT - EM":"0.222",
        "BBQ - EM":"0.279"
    },
    {
        "Model":"BLOOM (176B) [method: multiple_choice_joint]",
        "Mean win rate":"0.36",
        "HellaSwag - EM":"0.289",
        "OpenbookQA - EM":"0.351",
        "TruthfulQA - EM":"0.204",
        "MMLU - EM":"0.299",
        "BLiMP - EM":"0.249",
        "LegalSupport - EM":"0.543",
        "LSAT - EM":"0.209",
        "BBQ - EM":"0.375"
    },
    {
        "Model":"BLOOM (176B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.669",
        "HellaSwag - EM":"0.548",
        "OpenbookQA - EM":"0.534",
        "TruthfulQA - EM":"0.358",
        "MMLU - EM":"0.411",
        "BLiMP - EM":"0.527",
        "LegalSupport - EM":"0.566",
        "LSAT - EM":"0.243",
        "BBQ - EM":"0.263"
    },
    {
        "Model":"BLOOM (176B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.61",
        "HellaSwag - EM":"0.744",
        "OpenbookQA - EM":"0.448",
        "TruthfulQA - EM":"0.242",
        "MMLU - EM":"0.345",
        "BLiMP - EM":"0.819",
        "LegalSupport - EM":"0.579",
        "LSAT - EM":"0.243",
        "BBQ - EM":"0.259"
    },
    {
        "Model":"GPT-J (6B) [method: multiple_choice_joint]",
        "Mean win rate":"0.169",
        "HellaSwag - EM":"0.265",
        "OpenbookQA - EM":"0.282",
        "TruthfulQA - EM":"0.196",
        "MMLU - EM":"0.249",
        "BLiMP - EM":"0.242",
        "LegalSupport - EM":"0.479",
        "LSAT - EM":"0.175",
        "BBQ - EM":"0.307"
    },
    {
        "Model":"GPT-J (6B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.603",
        "HellaSwag - EM":"0.49",
        "OpenbookQA - EM":"0.514",
        "TruthfulQA - EM":"0.396",
        "MMLU - EM":"0.35",
        "BLiMP - EM":"0.495",
        "LegalSupport - EM":"0.558",
        "LSAT - EM":"0.239",
        "BBQ - EM":"0.27"
    },
    {
        "Model":"GPT-J (6B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.426",
        "HellaSwag - EM":"0.663",
        "OpenbookQA - EM":"0.42",
        "TruthfulQA - EM":"0.257",
        "MMLU - EM":"0.328",
        "BLiMP - EM":"0.834",
        "LegalSupport - EM":"0.509",
        "LSAT - EM":"0.204",
        "BBQ - EM":"0.259"
    },
    {
        "Model":"GPT-NeoX (20B) [method: multiple_choice_joint]",
        "Mean win rate":"0.243",
        "HellaSwag - EM":"0.271",
        "OpenbookQA - EM":"0.28",
        "TruthfulQA - EM":"0.213",
        "MMLU - EM":"0.276",
        "BLiMP - EM":"0.009",
        "LegalSupport - EM":"0.515",
        "LSAT - EM":"0.191",
        "BBQ - EM":"0.316"
    },
    {
        "Model":"GPT-NeoX (20B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.544",
        "HellaSwag - EM":"0.514",
        "OpenbookQA - EM":"0.524",
        "TruthfulQA - EM":"0.37",
        "MMLU - EM":"0.371",
        "BLiMP - EM":"0.542",
        "LegalSupport - EM":"0.526",
        "LSAT - EM":"0.226",
        "BBQ - EM":"0.253"
    },
    {
        "Model":"GPT-NeoX (20B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.544",
        "HellaSwag - EM":"0.718",
        "OpenbookQA - EM":"0.42",
        "TruthfulQA - EM":"0.24",
        "MMLU - EM":"0.361",
        "BLiMP - EM":"0.839",
        "LegalSupport - EM":"0.511",
        "LSAT - EM":"0.235",
        "BBQ - EM":"0.263"
    },
    {
        "Model":"OPT (175B) [method: multiple_choice_joint]",
        "Mean win rate":"0.36",
        "HellaSwag - EM":"0.305",
        "OpenbookQA - EM":"0.341",
        "TruthfulQA - EM":"0.251",
        "MMLU - EM":"0.318",
        "BLiMP - EM":"0",
        "LegalSupport - EM":"0.532",
        "LSAT - EM":"0.22",
        "BBQ - EM":"0.347"
    },
    {
        "Model":"OPT (175B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.618",
        "HellaSwag - EM":"0.548",
        "OpenbookQA - EM":"0.586",
        "TruthfulQA - EM":"0.405",
        "MMLU - EM":"0.35",
        "BLiMP - EM":"0.47",
        "LegalSupport - EM":"0.556",
        "LSAT - EM":"0.209",
        "BBQ - EM":"0.273"
    },
    {
        "Model":"OPT (175B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.596",
        "HellaSwag - EM":"0.791",
        "OpenbookQA - EM":"0.446",
        "TruthfulQA - EM":"0.292",
        "MMLU - EM":"0.353",
        "BLiMP - EM":"0.831",
        "LegalSupport - EM":"0.566",
        "LSAT - EM":"0.161",
        "BBQ - EM":"0.269"
    },
    {
        "Model":"OPT (66B) [method: multiple_choice_joint]",
        "Mean win rate":"0.199",
        "HellaSwag - EM":"0.253",
        "OpenbookQA - EM":"0.257",
        "TruthfulQA - EM":"0.199",
        "MMLU - EM":"0.276",
        "BLiMP - EM":"0.001",
        "LegalSupport - EM":"0.527",
        "LSAT - EM":"0.175",
        "BBQ - EM":"0.355"
    },
    {
        "Model":"OPT (66B) [method: multiple_choice_separate_calibrated]",
        "Mean win rate":"0.529",
        "HellaSwag - EM":"0.525",
        "OpenbookQA - EM":"0.534",
        "TruthfulQA - EM":"0.385",
        "MMLU - EM":"0.36",
        "BLiMP - EM":"0.459",
        "LegalSupport - EM":"0.558",
        "LSAT - EM":"0.17",
        "BBQ - EM":"0.265"
    },
    {
        "Model":"OPT (66B) [method: multiple_choice_separate_original]",
        "Mean win rate":"0.537",
        "HellaSwag - EM":"0.745",
        "OpenbookQA - EM":"0.41",
        "TruthfulQA - EM":"0.275",
        "MMLU - EM":"0.337",
        "BLiMP - EM":"0.827",
        "LegalSupport - EM":"0.573",
        "LSAT - EM":"0.157",
        "BBQ - EM":"0.274"
    }
]