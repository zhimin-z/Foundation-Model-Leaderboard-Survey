[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.528,
        "Denoised inference time (s)":"1.093",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.574,
        "Denoised inference time (s)":"0.81",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.548,
        "Denoised inference time (s)":"0.94",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.533,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.475,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":5018.687,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.527,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.558,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1958.024,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)\u2620",
        "BPB":0.532,
        "Denoised inference time (s)":"2.149",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6830.844,
        "# output tokens":0.309,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)\u2620",
        "BPB":0.47,
        "Denoised inference time (s)":"1.14",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1974.829,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)\u2620",
        "BPB":0.447,
        "Denoised inference time (s)":"0.453",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)\u2620",
        "BPB":0.452,
        "Denoised inference time (s)":"0.94",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1973.176,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)\u2620",
        "BPB":0.554,
        "Denoised inference time (s)":"0.863",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)\u2620",
        "BPB":0.573,
        "Denoised inference time (s)":"0.39",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)\u2620",
        "BPB":0.571,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1990.327,
        "# output tokens":0.011,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)\u2620",
        "BPB":0.646,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1990.327,
        "# output tokens":0.011,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":0.636,
        "Denoised inference time (s)":"0.238",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.695,
        "Denoised inference time (s)":"0.119",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":0.758,
        "Denoised inference time (s)":"0.133",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":0.839,
        "Denoised inference time (s)":"0.144",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.535,
        "Denoised inference time (s)":"-",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3737.732,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.54,
        "Denoised inference time (s)":"0.335",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3737.732,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":0.863,
        "Denoised inference time (s)":"0.155",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":0.974,
        "Denoised inference time (s)":"0.167",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":1.436,
        "Denoised inference time (s)":"0.119",
        "# eval":584,
        "# train":0,
        "truncated":0,
        "# prompt tokens":1991.284,
        "# output tokens":0.0,
        "# trials":1
    }
]