[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"0.475",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.156,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"0.377",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.433,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"0.428",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":3.0,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent":0.189,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.267,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent":0.222,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.467,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent":0.178,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.689,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":324.433,
        "# output tokens":2.267,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent":0.233,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":386.833,
        "# output tokens":1.333,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent":0.144,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":386.833,
        "# output tokens":1.167,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent":0.089,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":386.833,
        "# output tokens":1.267,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent":0.156,
        "Denoised inference time (s)":"0.635",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.911,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.616",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":322.6,
        "# output tokens":4.722,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.262",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":387.767,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent":0.111,
        "Denoised inference time (s)":"0.511",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":1.956,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent":0.122,
        "Denoised inference time (s)":"0.312",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":1.778,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent":0.156,
        "Denoised inference time (s)":"0.274",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":1.656,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent":0.056,
        "Denoised inference time (s)":"0.289",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":4.989,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent":0.244,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":2.1,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent":0.122,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":2.378,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent":0.189,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":1.444,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent":0.244,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":377.533,
        "# output tokens":1.889,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent":0.189,
        "Denoised inference time (s)":"0.239",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.167,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent":0.144,
        "Denoised inference time (s)":"0.3",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.356,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.767,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":2.2,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.449",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":387.767,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.341",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":391.767,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"0.76",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.189,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent":0.144,
        "Denoised inference time (s)":"4.429",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.6,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.967,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.933,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.4,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":2.3,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":2.1,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.633,
        "# output tokens":2.4,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.333,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent":0.156,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.489,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent":0.111,
        "Denoised inference time (s)":"0.253",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.256,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"0.102",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.6,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"0.12",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.233,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent":0.078,
        "Denoised inference time (s)":"0.141",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.044,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent":0.289,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.178,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent":0.244,
        "Denoised inference time (s)":"0.207",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.022,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent":0.078,
        "Denoised inference time (s)":"0.139",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.389,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent":0.011,
        "Denoised inference time (s)":"0.135",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.667,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent":0.1,
        "Denoised inference time (s)":"0.088",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.378,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent":0.267,
        "Denoised inference time (s)":"0.186",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.267,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"0.107",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":2.189,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent":0.533,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":349.233,
        "# output tokens":1.2,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent":0.5,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":349.233,
        "# output tokens":1.467,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.633,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent":0.1,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.133,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.2,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.133,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":359.033,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent":0.167,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":399.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":399.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":399.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":399.667,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.586",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":379.367,
        "# output tokens":3.433,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent":0.144,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.889,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent":0.211,
        "Denoised inference time (s)":"-",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":373.067,
        "# output tokens":1.067,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.353",
        "# eval":30,
        "# train":8,
        "truncated":0,
        "# prompt tokens":336.767,
        "# output tokens":19.211,
        "# trials":3
    }
]