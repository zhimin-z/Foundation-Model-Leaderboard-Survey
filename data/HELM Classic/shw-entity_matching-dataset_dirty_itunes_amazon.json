[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.755",
        "Denoised inference time (s)":"0.863",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.758",
        "Denoised inference time (s)":"0.639",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.752",
        "Denoised inference time (s)":"0.744",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.771",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.67",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.758",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.774",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1321.431",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.312",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1230.544",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.336",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1230.544",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.657",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1230.544",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.633",
        "Denoised inference time (s)":"0.747",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.81",
        "Denoised inference time (s)":"0.926",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1195.676",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.169",
        "# eval":"109",
        "# train":"2.792",
        "truncated":"0",
        "# prompt tokens":"909.596",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.752",
        "Denoised inference time (s)":"0.692",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.74",
        "Denoised inference time (s)":"0.495",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.468",
        "Denoised inference time (s)":"0.395",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.248",
        "Denoised inference time (s)":"0.429",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.679",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.746",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.502",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.333",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1228.223",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.287",
        "Denoised inference time (s)":"0.184",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.752",
        "Denoised inference time (s)":"0.302",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1274.144",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.339",
        "Denoised inference time (s)":"0.244",
        "# eval":"109",
        "# train":"0.48",
        "truncated":"0.388",
        "# prompt tokens":"365.89",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.297",
        "Denoised inference time (s)":"0.222",
        "# eval":"109",
        "# train":"0.434",
        "truncated":"0.422",
        "# prompt tokens":"358.095",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.422",
        "Denoised inference time (s)":"0.735",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.416",
        "Denoised inference time (s)":"1.33",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.835",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.725",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.385",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.56",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"2.165",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.771",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.798",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1628.165",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.899",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1598.312",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.835",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.538",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.44",
        "Denoised inference time (s)":"0.217",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.324",
        "Denoised inference time (s)":"0.104",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.673",
        "Denoised inference time (s)":"0.125",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.297",
        "Denoised inference time (s)":"0.141",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.966",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.948",
        "Denoised inference time (s)":"0.216",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.789",
        "Denoised inference time (s)":"0.142",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.755",
        "Denoised inference time (s)":"0.15",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.752",
        "Denoised inference time (s)":"0.103",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.963",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1347.092",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.881",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1347.092",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.45",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.826",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.826",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1388.477",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.771",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1560.486",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1560.486",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.872",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1560.486",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.752",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1560.486",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.346",
        "Denoised inference time (s)":"0.856",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1512.673",
        "# output tokens":"2",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.606",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.985",
        "Denoised inference time (s)":"-",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1234.728",
        "# output tokens":"1",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.248",
        "Denoised inference time (s)":"0.776",
        "# eval":"109",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"1183.098",
        "# output tokens":"5",
        "# trials":"3"
    }
]