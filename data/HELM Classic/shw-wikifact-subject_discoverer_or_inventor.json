[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.065",
        "Denoised inference time (s)":"1.289",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"24.829",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.072",
        "Denoised inference time (s)":"0.645",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"25.322",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.052",
        "Denoised inference time (s)":"0.834",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"24.555",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.068",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"26.624",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.1",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"20.997",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.084",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"22.074",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.045",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.472",
        "# output tokens":"22.968",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.08",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"81.656",
        "# output tokens":"25.22",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.113",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"81.656",
        "# output tokens":"20.309",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.083",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"81.656",
        "# output tokens":"17.401",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.119",
        "Denoised inference time (s)":"1.845",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.553",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.083",
        "Denoised inference time (s)":"0.868",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"75.079",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.124",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"93.587",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.103",
        "Denoised inference time (s)":"1.07",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"18.809",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.079",
        "Denoised inference time (s)":"0.662",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"20.021",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.075",
        "Denoised inference time (s)":"0.473",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"23.467",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.048",
        "Denoised inference time (s)":"0.36",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"23.844",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.146",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"25.754",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.064",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"21.305",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.074",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"17.49",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.138",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.553",
        "# output tokens":"20.351",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.043",
        "Denoised inference time (s)":"0.096",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.035",
        "Denoised inference time (s)":"0.055",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.161",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"6.513",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.015",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"6.279",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.022",
        "Denoised inference time (s)":"0.234",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"93.587",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.045",
        "Denoised inference time (s)":"0.222",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.587",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.063",
        "Denoised inference time (s)":"0.596",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.052",
        "Denoised inference time (s)":"0.145",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.081",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"5.302",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.089",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"5.708",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.098",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"5.518",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.213",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.114",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.166",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.261",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.066",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"6.124",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.067",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"6.009",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.091",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.362",
        "# output tokens":"5.762",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.142",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"0.999",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.113",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.131",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.065",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"25.512",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.095",
        "Denoised inference time (s)":"0.907",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.796",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.069",
        "Denoised inference time (s)":"0.256",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"25.663",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.035",
        "Denoised inference time (s)":"0.25",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"23.844",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.022",
        "Denoised inference time (s)":"0.276",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.044",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.179",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.797",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.176",
        "Denoised inference time (s)":"0.844",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.236",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.063",
        "Denoised inference time (s)":"0.286",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"24.049",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.011",
        "Denoised inference time (s)":"0.28",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"23.172",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.013",
        "Denoised inference time (s)":"0.206",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"22.157",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.112",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.364",
        "# output tokens":"33.587",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.121",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"86.364",
        "# output tokens":"30.266",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.007",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"6.534",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.005",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"7.156",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.029",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"6.048",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.031",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"5.689",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.165",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"0.999",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.104",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"87.161",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.084",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"89.245",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.066",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"89.245",
        "# output tokens":"0.995",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.142",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"89.245",
        "# output tokens":"0.999",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.138",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"89.245",
        "# output tokens":"0.993",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.078",
        "Denoised inference time (s)":"0.506",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"106.114",
        "# output tokens":"30.048",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.029",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"23.265",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.231",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.204",
        "# output tokens":"25.704",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.01",
        "Denoised inference time (s)":"0.338",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"81.31",
        "# output tokens":"40",
        "# trials":"3"
    }
]