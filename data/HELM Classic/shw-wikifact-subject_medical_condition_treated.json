[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":0.385,
        "Denoised inference time (s)":"0.994",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":17.904,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":0.307,
        "Denoised inference time (s)":"0.53",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":18.326,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":0.384,
        "Denoised inference time (s)":"0.704",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":18.767,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":0.423,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":19.415,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":0.435,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":14.682,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":0.46,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":13.359,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":0.296,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":63.123,
        "# output tokens":14.335,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":0.425,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.483,
        "# output tokens":11.552,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":0.453,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.483,
        "# output tokens":12.275,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":0.523,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.483,
        "# output tokens":12.209,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":0.481,
        "Denoised inference time (s)":"1.272",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":14.4,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "EM":0.342,
        "Denoised inference time (s)":"0.869",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":84.271,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "EM":0.031,
        "Denoised inference time (s)":"0.151",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":101.613,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":0.469,
        "Denoised inference time (s)":"0.948",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":15.669,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":0.39,
        "Denoised inference time (s)":"0.553",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":15.21,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":0.361,
        "Denoised inference time (s)":"0.366",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":14.474,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":0.117,
        "Denoised inference time (s)":"0.284",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":11.056,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":0.477,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":15.856,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":0.404,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":14.579,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":0.382,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":15.631,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":0.482,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.609,
        "# output tokens":15.509,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "EM":0.209,
        "Denoised inference time (s)":"0.088",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":0.32,
        "Denoised inference time (s)":"0.053",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":84.544,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":0.254,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.187,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "EM":0.241,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.242,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "EM":0.076,
        "Denoised inference time (s)":"0.237",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":101.613,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "EM":0.208,
        "Denoised inference time (s)":"0.224",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":105.613,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "EM":0.196,
        "Denoised inference time (s)":"0.595",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "EM":0.219,
        "Denoised inference time (s)":"0.143",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":40.0,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "EM":0.268,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":5.815,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "EM":0.265,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":6.074,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "EM":0.252,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":6.062,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "EM":0.484,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":0.441,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":0.472,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":0.521,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "EM":0.313,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":5.648,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":0.315,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":6.007,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":0.335,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":112.062,
        "# output tokens":6.008,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":0.471,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":0.431,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":20.664,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":0.339,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":19.656,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "EM":0.412,
        "Denoised inference time (s)":"0.774",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":20.353,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "EM":0.289,
        "Denoised inference time (s)":"0.202",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":17.829,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "EM":0.134,
        "Denoised inference time (s)":"0.216",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":18.158,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "EM":0.04,
        "Denoised inference time (s)":"0.25",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":19.718,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "EM":0.467,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":19.376,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "EM":0.478,
        "Denoised inference time (s)":"0.636",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":17.015,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "EM":0.269,
        "Denoised inference time (s)":"0.233",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":16.3,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "EM":0.132,
        "Denoised inference time (s)":"0.248",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":18.65,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "EM":0.044,
        "Denoised inference time (s)":"0.188",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":19.0,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":0.149,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":84.415,
        "# output tokens":34.315,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":0.227,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":84.415,
        "# output tokens":28.546,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":0.214,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.415,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":0.221,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.385,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":0.299,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.442,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":0.296,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":3.367,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "EM":0.489,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":0.431,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":85.211,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "EM":0.442,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":87.288,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":0.381,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":87.288,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "EM":0.52,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":87.288,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":0.494,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":87.288,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "EM":0.336,
        "Denoised inference time (s)":"0.508",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":83.371,
        "# output tokens":22.476,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":0.253,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":18.146,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":0.459,
        "Denoised inference time (s)":"-",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":92.644,
        "# output tokens":16.588,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "EM":0.133,
        "Denoised inference time (s)":"0.344",
        "# eval":850,
        "# train":5,
        "truncated":0,
        "# prompt tokens":83.011,
        "# output tokens":40.0,
        "# trials":3
    }
]