[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":0.452,
        "MMLU - EM (Robustness)":0.221,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.523",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.179,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.503",
        "QuAC - F1 (Robustness)":"0.222",
        "HellaSwag - EM (Robustness)":"0.726",
        "OpenbookQA - EM (Robustness)":"0.43",
        "TruthfulQA - EM (Robustness)":0.154,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.144",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.307",
        "IMDB - EM (Robustness)":0.923,
        "CivilComments - EM (Robustness)":0.271,
        "RAFT - EM (Robustness)":0.555
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":0.298,
        "MMLU - EM (Robustness)":0.2,
        "BoolQ - EM (Robustness)":0.567,
        "NarrativeQA - F1 (Robustness)":"0.4",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.098,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.41",
        "QuAC - F1 (Robustness)":"0.197",
        "HellaSwag - EM (Robustness)":"0.646",
        "OpenbookQA - EM (Robustness)":"0.412",
        "TruthfulQA - EM (Robustness)":0.155,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.105",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.248",
        "IMDB - EM (Robustness)":0.932,
        "CivilComments - EM (Robustness)":0.444,
        "RAFT - EM (Robustness)":0.443
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":0.423,
        "MMLU - EM (Robustness)":0.225,
        "BoolQ - EM (Robustness)":0.643,
        "NarrativeQA - F1 (Robustness)":"0.477",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.17,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.478",
        "QuAC - F1 (Robustness)":"0.219",
        "HellaSwag - EM (Robustness)":"0.695",
        "OpenbookQA - EM (Robustness)":"0.424",
        "TruthfulQA - EM (Robustness)":0.142,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.121",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.297",
        "IMDB - EM (Robustness)":0.941,
        "CivilComments - EM (Robustness)":0.417,
        "RAFT - EM (Robustness)":0.513
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":0.711,
        "MMLU - EM (Robustness)":0.392,
        "BoolQ - EM (Robustness)":0.692,
        "NarrativeQA - F1 (Robustness)":"0.565",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.235,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.56",
        "QuAC - F1 (Robustness)":"0.251",
        "HellaSwag - EM (Robustness)":"0.732",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.252,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.222",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.407",
        "IMDB - EM (Robustness)":0.947,
        "CivilComments - EM (Robustness)":0.495,
        "RAFT - EM (Robustness)":0.555
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":0.791,
        "MMLU - EM (Robustness)":0.417,
        "BoolQ - EM (Robustness)":0.729,
        "NarrativeQA - F1 (Robustness)":"0.66",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.315,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.599",
        "QuAC - F1 (Robustness)":"0.314",
        "HellaSwag - EM (Robustness)":"0.754",
        "OpenbookQA - EM (Robustness)":"0.47",
        "TruthfulQA - EM (Robustness)":0.39,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.337",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.607",
        "IMDB - EM (Robustness)":0.896,
        "CivilComments - EM (Robustness)":0.449,
        "RAFT - EM (Robustness)":0.69
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":0.764,
        "MMLU - EM (Robustness)":0.411,
        "BoolQ - EM (Robustness)":0.729,
        "NarrativeQA - F1 (Robustness)":"0.583",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.285,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.564",
        "QuAC - F1 (Robustness)":"0.276",
        "HellaSwag - EM (Robustness)":"0.755",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.293,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.227",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.423",
        "IMDB - EM (Robustness)":0.928,
        "CivilComments - EM (Robustness)":0.488,
        "RAFT - EM (Robustness)":0.618
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":0.527,
        "MMLU - EM (Robustness)":0.263,
        "BoolQ - EM (Robustness)":0.607,
        "NarrativeQA - F1 (Robustness)":"-",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.187,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.503",
        "QuAC - F1 (Robustness)":"-",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.21,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.177",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.397",
        "IMDB - EM (Robustness)":0.941,
        "CivilComments - EM (Robustness)":0.469,
        "RAFT - EM (Robustness)":0.498
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":0.319,
        "MMLU - EM (Robustness)":0.183,
        "BoolQ - EM (Robustness)":0.655,
        "NarrativeQA - F1 (Robustness)":"0.476",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.163,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.491",
        "QuAC - F1 (Robustness)":"0.185",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.112,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.887,
        "CivilComments - EM (Robustness)":0.416,
        "RAFT - EM (Robustness)":0.402
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":0.43,
        "MMLU - EM (Robustness)":0.23,
        "BoolQ - EM (Robustness)":0.659,
        "NarrativeQA - F1 (Robustness)":"0.513",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.212,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.524",
        "QuAC - F1 (Robustness)":"0.193",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.151,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.92,
        "CivilComments - EM (Robustness)":0.368,
        "RAFT - EM (Robustness)":0.436
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":0.546,
        "MMLU - EM (Robustness)":0.255,
        "BoolQ - EM (Robustness)":0.665,
        "NarrativeQA - F1 (Robustness)":"0.59",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.252,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.586",
        "QuAC - F1 (Robustness)":"0.233",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.106,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.932,
        "CivilComments - EM (Robustness)":0.263,
        "RAFT - EM (Robustness)":0.564
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":0.818,
        "MMLU - EM (Robustness)":0.434,
        "BoolQ - EM (Robustness)":0.756,
        "NarrativeQA - F1 (Robustness)":"0.663",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.245,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.632",
        "QuAC - F1 (Robustness)":"0.313",
        "HellaSwag - EM (Robustness)":"0.766",
        "OpenbookQA - EM (Robustness)":"0.472",
        "TruthfulQA - EM (Robustness)":0.326,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.928,
        "CivilComments - EM (Robustness)":0.514,
        "RAFT - EM (Robustness)":0.6
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":0.541,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.642,
        "NarrativeQA - F1 (Robustness)":"0.53",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.185,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.558",
        "QuAC - F1 (Robustness)":"0.234",
        "HellaSwag - EM (Robustness)":"0.699",
        "OpenbookQA - EM (Robustness)":"0.438",
        "TruthfulQA - EM (Robustness)":0.183,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.19",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.333",
        "IMDB - EM (Robustness)":0.92,
        "CivilComments - EM (Robustness)":0.467,
        "RAFT - EM (Robustness)":0.527
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":0.228,
        "MMLU - EM (Robustness)":0.378,
        "BoolQ - EM (Robustness)":0.0,
        "NarrativeQA - F1 (Robustness)":"0.099",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.031,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.122",
        "QuAC - F1 (Robustness)":"0.071",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.365,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.17,
        "CivilComments - EM (Robustness)":0.087,
        "RAFT - EM (Robustness)":0.085
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":0.506,
        "MMLU - EM (Robustness)":0.29,
        "BoolQ - EM (Robustness)":0.614,
        "NarrativeQA - F1 (Robustness)":"0.383",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.238,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.471",
        "QuAC - F1 (Robustness)":"0.215",
        "HellaSwag - EM (Robustness)":"0.759",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.151,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.207",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.397",
        "IMDB - EM (Robustness)":0.923,
        "CivilComments - EM (Robustness)":0.32,
        "RAFT - EM (Robustness)":0.563
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":0.345,
        "MMLU - EM (Robustness)":0.253,
        "BoolQ - EM (Robustness)":0.545,
        "NarrativeQA - F1 (Robustness)":"0.357",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.172,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.347",
        "QuAC - F1 (Robustness)":"0.204",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.43",
        "TruthfulQA - EM (Robustness)":0.154,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.13",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.257",
        "IMDB - EM (Robustness)":0.902,
        "CivilComments - EM (Robustness)":0.333,
        "RAFT - EM (Robustness)":0.49
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":0.188,
        "MMLU - EM (Robustness)":0.184,
        "BoolQ - EM (Robustness)":0.562,
        "NarrativeQA - F1 (Robustness)":"0.3",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.102,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.266",
        "QuAC - F1 (Robustness)":"0.144",
        "HellaSwag - EM (Robustness)":"0.651",
        "OpenbookQA - EM (Robustness)":"0.382",
        "TruthfulQA - EM (Robustness)":0.149,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.109",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.315",
        "IMDB - EM (Robustness)":0.889,
        "CivilComments - EM (Robustness)":0.136,
        "RAFT - EM (Robustness)":0.385
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":0.147,
        "MMLU - EM (Robustness)":0.226,
        "BoolQ - EM (Robustness)":0.361,
        "NarrativeQA - F1 (Robustness)":"0.078",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.025,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.074",
        "QuAC - F1 (Robustness)":"0.098",
        "HellaSwag - EM (Robustness)":"0.405",
        "OpenbookQA - EM (Robustness)":"0.238",
        "TruthfulQA - EM (Robustness)":0.204,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.252",
        "IMDB - EM (Robustness)":0.473,
        "CivilComments - EM (Robustness)":0.434,
        "RAFT - EM (Robustness)":0.403
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":0.596,
        "MMLU - EM (Robustness)":0.299,
        "BoolQ - EM (Robustness)":0.718,
        "NarrativeQA - F1 (Robustness)":"0.39",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.283,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.533",
        "QuAC - F1 (Robustness)":"0.229",
        "HellaSwag - EM (Robustness)":"0.764",
        "OpenbookQA - EM (Robustness)":"0.482",
        "TruthfulQA - EM (Robustness)":0.116,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.242",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.482",
        "IMDB - EM (Robustness)":0.923,
        "CivilComments - EM (Robustness)":0.408,
        "RAFT - EM (Robustness)":0.489
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":0.27,
        "MMLU - EM (Robustness)":0.207,
        "BoolQ - EM (Robustness)":0.54,
        "NarrativeQA - F1 (Robustness)":"0.296",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.105,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.222",
        "QuAC - F1 (Robustness)":"0.152",
        "HellaSwag - EM (Robustness)":"0.687",
        "OpenbookQA - EM (Robustness)":"0.414",
        "TruthfulQA - EM (Robustness)":0.17,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.13",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.314",
        "IMDB - EM (Robustness)":0.888,
        "CivilComments - EM (Robustness)":0.353,
        "RAFT - EM (Robustness)":0.502
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":0.616,
        "MMLU - EM (Robustness)":0.334,
        "BoolQ - EM (Robustness)":0.725,
        "NarrativeQA - F1 (Robustness)":"0.529",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.163,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.605",
        "QuAC - F1 (Robustness)":"0.17",
        "HellaSwag - EM (Robustness)":"0.696",
        "OpenbookQA - EM (Robustness)":"0.448",
        "TruthfulQA - EM (Robustness)":0.171,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.387",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.685",
        "IMDB - EM (Robustness)":0.921,
        "CivilComments - EM (Robustness)":0.468,
        "RAFT - EM (Robustness)":0.552
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":0.85,
        "MMLU - EM (Robustness)":0.387,
        "BoolQ - EM (Robustness)":0.811,
        "NarrativeQA - F1 (Robustness)":"0.57",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.289,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.679",
        "QuAC - F1 (Robustness)":"0.238",
        "HellaSwag - EM (Robustness)":"0.774",
        "OpenbookQA - EM (Robustness)":"0.492",
        "TruthfulQA - EM (Robustness)":0.229,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.434",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.734",
        "IMDB - EM (Robustness)":0.933,
        "CivilComments - EM (Robustness)":0.535,
        "RAFT - EM (Robustness)":0.599
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":0.291,
        "MMLU - EM (Robustness)":0.217,
        "BoolQ - EM (Robustness)":0.621,
        "NarrativeQA - F1 (Robustness)":"0.135",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.099,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.228",
        "QuAC - F1 (Robustness)":"0.147",
        "HellaSwag - EM (Robustness)":"0.619",
        "OpenbookQA - EM (Robustness)":"0.398",
        "TruthfulQA - EM (Robustness)":0.181,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.116",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.319",
        "IMDB - EM (Robustness)":0.903,
        "CivilComments - EM (Robustness)":0.418,
        "RAFT - EM (Robustness)":0.53
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":0.336,
        "MMLU - EM (Robustness)":0.189,
        "BoolQ - EM (Robustness)":0.551,
        "NarrativeQA - F1 (Robustness)":"0.421",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.133,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.452",
        "QuAC - F1 (Robustness)":"0.191",
        "HellaSwag - EM (Robustness)":"0.661",
        "OpenbookQA - EM (Robustness)":"0.414",
        "TruthfulQA - EM (Robustness)":0.175,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.096",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.351",
        "IMDB - EM (Robustness)":0.912,
        "CivilComments - EM (Robustness)":0.48,
        "RAFT - EM (Robustness)":0.399
    },
    {
        "Model":"Pythia (6.9B)",
        "Mean win rate":0.182,
        "MMLU - EM (Robustness)":0.201,
        "BoolQ - EM (Robustness)":0.527,
        "NarrativeQA - F1 (Robustness)":"0.313",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.094,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.391",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.139,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.871,
        "CivilComments - EM (Robustness)":0.363,
        "RAFT - EM (Robustness)":0.377
    },
    {
        "Model":"Pythia (12B)",
        "Mean win rate":0.272,
        "MMLU - EM (Robustness)":0.22,
        "BoolQ - EM (Robustness)":0.51,
        "NarrativeQA - F1 (Robustness)":"0.42",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.108,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.47",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.138,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.854,
        "CivilComments - EM (Robustness)":0.418,
        "RAFT - EM (Robustness)":0.45
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":0.164,
        "MMLU - EM (Robustness)":0.258,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.045",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.153,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.071",
        "QuAC - F1 (Robustness)":"0.064",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.122,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.304,
        "CivilComments - EM (Robustness)":0.392,
        "RAFT - EM (Robustness)":0.331
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":0.257,
        "MMLU - EM (Robustness)":0.272,
        "BoolQ - EM (Robustness)":0.646,
        "NarrativeQA - F1 (Robustness)":"0.059",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.141,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.291",
        "QuAC - F1 (Robustness)":"0.111",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.178,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.276,
        "CivilComments - EM (Robustness)":0.45,
        "RAFT - EM (Robustness)":0.349
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":0.519,
        "MMLU - EM (Robustness)":0.27,
        "BoolQ - EM (Robustness)":0.623,
        "NarrativeQA - F1 (Robustness)":"0.409",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.208,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.408",
        "QuAC - F1 (Robustness)":"0.2",
        "HellaSwag - EM (Robustness)":"0.744",
        "OpenbookQA - EM (Robustness)":"0.488",
        "TruthfulQA - EM (Robustness)":0.205,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.235",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.408",
        "IMDB - EM (Robustness)":0.919,
        "CivilComments - EM (Robustness)":0.184,
        "RAFT - EM (Robustness)":0.48
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":0.438,
        "MMLU - EM (Robustness)":0.216,
        "BoolQ - EM (Robustness)":0.683,
        "NarrativeQA - F1 (Robustness)":"0.397",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.206,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.458",
        "QuAC - F1 (Robustness)":"0.199",
        "HellaSwag - EM (Robustness)":"0.699",
        "OpenbookQA - EM (Robustness)":"0.45",
        "TruthfulQA - EM (Robustness)":0.174,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.179",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.437",
        "IMDB - EM (Robustness)":0.886,
        "CivilComments - EM (Robustness)":0.305,
        "RAFT - EM (Robustness)":0.405
    },
    {
        "Model":"LLaMA (7B)",
        "Mean win rate":0.568,
        "MMLU - EM (Robustness)":0.268,
        "BoolQ - EM (Robustness)":0.688,
        "NarrativeQA - F1 (Robustness)":"0.485",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.222,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.519",
        "QuAC - F1 (Robustness)":"0.223",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.229,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.897,
        "CivilComments - EM (Robustness)":0.492,
        "RAFT - EM (Robustness)":0.486
    },
    {
        "Model":"LLaMA (13B)",
        "Mean win rate":0.637,
        "MMLU - EM (Robustness)":0.37,
        "BoolQ - EM (Robustness)":0.67,
        "NarrativeQA - F1 (Robustness)":"0.544",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.272,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.556",
        "QuAC - F1 (Robustness)":"0.194",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.274,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.875,
        "CivilComments - EM (Robustness)":0.529,
        "RAFT - EM (Robustness)":0.559
    },
    {
        "Model":"LLaMA (30B)",
        "Mean win rate":0.815,
        "MMLU - EM (Robustness)":0.461,
        "BoolQ - EM (Robustness)":0.791,
        "NarrativeQA - F1 (Robustness)":"0.611",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.36,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.612",
        "QuAC - F1 (Robustness)":"0.273",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.281,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.893,
        "CivilComments - EM (Robustness)":0.503,
        "RAFT - EM (Robustness)":0.67
    },
    {
        "Model":"LLaMA (65B)",
        "Mean win rate":0.885,
        "MMLU - EM (Robustness)":0.504,
        "BoolQ - EM (Robustness)":0.84,
        "NarrativeQA - F1 (Robustness)":"0.567",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.388,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.624",
        "QuAC - F1 (Robustness)":"0.275",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.448,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.935,
        "CivilComments - EM (Robustness)":0.566,
        "RAFT - EM (Robustness)":0.655
    },
    {
        "Model":"Llama 2 (7B)",
        "Mean win rate":0.644,
        "MMLU - EM (Robustness)":0.373,
        "BoolQ - EM (Robustness)":0.676,
        "NarrativeQA - F1 (Robustness)":"0.573",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.261,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.501",
        "QuAC - F1 (Robustness)":"0.271",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.234,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.808,
        "CivilComments - EM (Robustness)":0.516,
        "RAFT - EM (Robustness)":0.573
    },
    {
        "Model":"Llama 2 (13B)",
        "Mean win rate":0.823,
        "MMLU - EM (Robustness)":0.444,
        "BoolQ - EM (Robustness)":0.753,
        "NarrativeQA - F1 (Robustness)":"0.682",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.324,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.563",
        "QuAC - F1 (Robustness)":"0.294",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.287,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.954,
        "CivilComments - EM (Robustness)":0.47,
        "RAFT - EM (Robustness)":0.652
    },
    {
        "Model":"Llama 2 (70B)",
        "Mean win rate":0.965,
        "MMLU - EM (Robustness)":0.545,
        "BoolQ - EM (Robustness)":0.863,
        "NarrativeQA - F1 (Robustness)":"0.722",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.42,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.639",
        "QuAC - F1 (Robustness)":"0.362",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.468,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.949,
        "CivilComments - EM (Robustness)":0.59,
        "RAFT - EM (Robustness)":0.673
    },
    {
        "Model":"Alpaca (7B)",
        "Mean win rate":0.379,
        "MMLU - EM (Robustness)":0.324,
        "BoolQ - EM (Robustness)":0.643,
        "NarrativeQA - F1 (Robustness)":"0.246",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.203,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.491",
        "QuAC - F1 (Robustness)":"0.16",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.199,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.561,
        "CivilComments - EM (Robustness)":0.482,
        "RAFT - EM (Robustness)":0.42
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Mean win rate":0.662,
        "MMLU - EM (Robustness)":0.371,
        "BoolQ - EM (Robustness)":0.672,
        "NarrativeQA - F1 (Robustness)":"0.5",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.214,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.539",
        "QuAC - F1 (Robustness)":"0.25",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.258,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.882,
        "CivilComments - EM (Robustness)":0.543,
        "RAFT - EM (Robustness)":0.6
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Mean win rate":0.732,
        "MMLU - EM (Robustness)":0.413,
        "BoolQ - EM (Robustness)":0.757,
        "NarrativeQA - F1 (Robustness)":"0.525",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.273,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.621",
        "QuAC - F1 (Robustness)":"0.247",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.341,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.674,
        "CivilComments - EM (Robustness)":0.593,
        "RAFT - EM (Robustness)":0.591
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Mean win rate":0.896,
        "MMLU - EM (Robustness)":0.533,
        "BoolQ - EM (Robustness)":0.837,
        "NarrativeQA - F1 (Robustness)":"0.649",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.305,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.631",
        "QuAC - F1 (Robustness)":"0.31",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.339,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.954,
        "CivilComments - EM (Robustness)":0.521,
        "RAFT - EM (Robustness)":0.652
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":0.65,
        "MMLU - EM (Robustness)":0.403,
        "BoolQ - EM (Robustness)":0.733,
        "NarrativeQA - F1 (Robustness)":"0.319",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.307,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.525",
        "QuAC - F1 (Robustness)":"0.194",
        "HellaSwag - EM (Robustness)":"0.757",
        "OpenbookQA - EM (Robustness)":"0.476",
        "TruthfulQA - EM (Robustness)":0.202,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.287",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.565",
        "IMDB - EM (Robustness)":0.921,
        "CivilComments - EM (Robustness)":0.409,
        "RAFT - EM (Robustness)":0.545
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":0.24,
        "MMLU - EM (Robustness)":0.169,
        "BoolQ - EM (Robustness)":0.638,
        "NarrativeQA - F1 (Robustness)":"0.352",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.149,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.299",
        "QuAC - F1 (Robustness)":"0.159",
        "HellaSwag - EM (Robustness)":"0.656",
        "OpenbookQA - EM (Robustness)":"0.408",
        "TruthfulQA - EM (Robustness)":0.136,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.105",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.278",
        "IMDB - EM (Robustness)":0.896,
        "CivilComments - EM (Robustness)":0.336,
        "RAFT - EM (Robustness)":0.445
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":0.509,
        "MMLU - EM (Robustness)":0.34,
        "BoolQ - EM (Robustness)":0.639,
        "NarrativeQA - F1 (Robustness)":"0.498",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.256,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.521",
        "QuAC - F1 (Robustness)":"0.208",
        "HellaSwag - EM (Robustness)":"0.738",
        "OpenbookQA - EM (Robustness)":"0.474",
        "TruthfulQA - EM (Robustness)":0.145,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.154",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.332",
        "IMDB - EM (Robustness)":0.873,
        "CivilComments - EM (Robustness)":0.461,
        "RAFT - EM (Robustness)":0.505
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":0.231,
        "MMLU - EM (Robustness)":0.19,
        "BoolQ - EM (Robustness)":0.545,
        "NarrativeQA - F1 (Robustness)":"0.367",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.126,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.338",
        "QuAC - F1 (Robustness)":"0.171",
        "HellaSwag - EM (Robustness)":"0.632",
        "OpenbookQA - EM (Robustness)":"0.396",
        "TruthfulQA - EM (Robustness)":0.186,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.11",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.253",
        "IMDB - EM (Robustness)":0.803,
        "CivilComments - EM (Robustness)":0.347,
        "RAFT - EM (Robustness)":0.413
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":0.117,
        "MMLU - EM (Robustness)":0.166,
        "BoolQ - EM (Robustness)":0.477,
        "NarrativeQA - F1 (Robustness)":"0.255",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.068,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.212",
        "QuAC - F1 (Robustness)":"0.149",
        "HellaSwag - EM (Robustness)":"0.489",
        "OpenbookQA - EM (Robustness)":"0.314",
        "TruthfulQA - EM (Robustness)":0.162,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.073",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.246",
        "IMDB - EM (Robustness)":0.5,
        "CivilComments - EM (Robustness)":0.4,
        "RAFT - EM (Robustness)":0.409
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":0.102,
        "MMLU - EM (Robustness)":0.204,
        "BoolQ - EM (Robustness)":0.461,
        "NarrativeQA - F1 (Robustness)":"0.104",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.031,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.043",
        "QuAC - F1 (Robustness)":"0.092",
        "HellaSwag - EM (Robustness)":"0.37",
        "OpenbookQA - EM (Robustness)":"0.27",
        "TruthfulQA - EM (Robustness)":0.167,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.072",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.247",
        "IMDB - EM (Robustness)":0.701,
        "CivilComments - EM (Robustness)":0.421,
        "RAFT - EM (Robustness)":0.345
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":0.91,
        "MMLU - EM (Robustness)":0.517,
        "BoolQ - EM (Robustness)":0.858,
        "NarrativeQA - F1 (Robustness)":"0.694",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.369,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.73",
        "QuAC - F1 (Robustness)":"0.42",
        "HellaSwag - EM (Robustness)":"0.798",
        "OpenbookQA - EM (Robustness)":"0.572",
        "TruthfulQA - EM (Robustness)":0.516,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.304",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.616",
        "IMDB - EM (Robustness)":0.779,
        "CivilComments - EM (Robustness)":0.594,
        "RAFT - EM (Robustness)":0.714
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":0.916,
        "MMLU - EM (Robustness)":0.525,
        "BoolQ - EM (Robustness)":0.841,
        "NarrativeQA - F1 (Robustness)":"0.638",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.299,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.665",
        "QuAC - F1 (Robustness)":"0.319",
        "HellaSwag - EM (Robustness)":"0.776",
        "OpenbookQA - EM (Robustness)":"0.52",
        "TruthfulQA - EM (Robustness)":0.547,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.344",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.628",
        "IMDB - EM (Robustness)":0.925,
        "CivilComments - EM (Robustness)":0.567,
        "RAFT - EM (Robustness)":0.666
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":0.337,
        "MMLU - EM (Robustness)":0.22,
        "BoolQ - EM (Robustness)":0.549,
        "NarrativeQA - F1 (Robustness)":"0.34",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.121,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.415",
        "QuAC - F1 (Robustness)":"0.169",
        "HellaSwag - EM (Robustness)":"0.625",
        "OpenbookQA - EM (Robustness)":"0.424",
        "TruthfulQA - EM (Robustness)":0.235,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.198",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.444",
        "IMDB - EM (Robustness)":0.881,
        "CivilComments - EM (Robustness)":0.129,
        "RAFT - EM (Robustness)":0.399
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":0.226,
        "MMLU - EM (Robustness)":0.186,
        "BoolQ - EM (Robustness)":0.384,
        "NarrativeQA - F1 (Robustness)":"0.126",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.04,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.151",
        "QuAC - F1 (Robustness)":"0.087",
        "HellaSwag - EM (Robustness)":"0.468",
        "OpenbookQA - EM (Robustness)":"0.39",
        "TruthfulQA - EM (Robustness)":0.195,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.122",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.356",
        "IMDB - EM (Robustness)":0.844,
        "CivilComments - EM (Robustness)":0.499,
        "RAFT - EM (Robustness)":0.383
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":0.105,
        "MMLU - EM (Robustness)":0.178,
        "BoolQ - EM (Robustness)":0.332,
        "NarrativeQA - F1 (Robustness)":"0.058",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.008,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.034",
        "QuAC - F1 (Robustness)":"0.067",
        "HellaSwag - EM (Robustness)":"0.32",
        "OpenbookQA - EM (Robustness)":"0.248",
        "TruthfulQA - EM (Robustness)":0.175,
        "MS MARCO (regular) - RR@10 (Robustness)":"0.069",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"0.252",
        "IMDB - EM (Robustness)":0.716,
        "CivilComments - EM (Robustness)":0.491,
        "RAFT - EM (Robustness)":0.335
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Mean win rate":0.816,
        "MMLU - EM (Robustness)":0.525,
        "BoolQ - EM (Robustness)":0.66,
        "NarrativeQA - F1 (Robustness)":"0.602",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.327,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.556",
        "QuAC - F1 (Robustness)":"0.411",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.566,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.857,
        "CivilComments - EM (Robustness)":0.605,
        "RAFT - EM (Robustness)":0.705
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Mean win rate":0.762,
        "MMLU - EM (Robustness)":0.262,
        "BoolQ - EM (Robustness)":0.845,
        "NarrativeQA - F1 (Robustness)":"0.566",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.284,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.606",
        "QuAC - F1 (Robustness)":"0.371",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.187,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.916,
        "CivilComments - EM (Robustness)":0.564,
        "RAFT - EM (Robustness)":0.677
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Mean win rate":0.293,
        "MMLU - EM (Robustness)":0.217,
        "BoolQ - EM (Robustness)":0.585,
        "NarrativeQA - F1 (Robustness)":"0.346",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.134,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.396",
        "QuAC - F1 (Robustness)":"0.177",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.226,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.843,
        "CivilComments - EM (Robustness)":0.336,
        "RAFT - EM (Robustness)":0.427
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Mean win rate":0.387,
        "MMLU - EM (Robustness)":0.218,
        "BoolQ - EM (Robustness)":0.629,
        "NarrativeQA - F1 (Robustness)":"0.403",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.132,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.536",
        "QuAC - F1 (Robustness)":"0.137",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.173,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.852,
        "CivilComments - EM (Robustness)":0.506,
        "RAFT - EM (Robustness)":0.548
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Mean win rate":0.331,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.569,
        "NarrativeQA - F1 (Robustness)":"0.424",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.167,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.472",
        "QuAC - F1 (Robustness)":"0.186",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.173,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.56,
        "CivilComments - EM (Robustness)":0.401,
        "RAFT - EM (Robustness)":0.489
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Mean win rate":0.495,
        "MMLU - EM (Robustness)":0.291,
        "BoolQ - EM (Robustness)":0.599,
        "NarrativeQA - F1 (Robustness)":"0.482",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.137,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.547",
        "QuAC - F1 (Robustness)":"0.164",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.197,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.82,
        "CivilComments - EM (Robustness)":0.527,
        "RAFT - EM (Robustness)":0.605
    },
    {
        "Model":"MPT (30B)",
        "Mean win rate":0.697,
        "MMLU - EM (Robustness)":0.381,
        "BoolQ - EM (Robustness)":0.656,
        "NarrativeQA - F1 (Robustness)":"0.584",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.272,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.609",
        "QuAC - F1 (Robustness)":"0.231",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.177,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.942,
        "CivilComments - EM (Robustness)":0.484,
        "RAFT - EM (Robustness)":0.58
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Mean win rate":0.656,
        "MMLU - EM (Robustness)":0.383,
        "BoolQ - EM (Robustness)":0.77,
        "NarrativeQA - F1 (Robustness)":"0.623",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.202,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.607",
        "QuAC - F1 (Robustness)":"0.204",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.177,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.942,
        "CivilComments - EM (Robustness)":0.408,
        "RAFT - EM (Robustness)":0.548
    },
    {
        "Model":"Falcon (7B)",
        "Mean win rate":0.425,
        "MMLU - EM (Robustness)":0.236,
        "BoolQ - EM (Robustness)":0.65,
        "NarrativeQA - F1 (Robustness)":"0.436",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.185,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.489",
        "QuAC - F1 (Robustness)":"0.164",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.205,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.692,
        "CivilComments - EM (Robustness)":0.485,
        "RAFT - EM (Robustness)":0.516
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Mean win rate":0.303,
        "MMLU - EM (Robustness)":0.25,
        "BoolQ - EM (Robustness)":0.593,
        "NarrativeQA - F1 (Robustness)":"0.258",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.132,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.327",
        "QuAC - F1 (Robustness)":"0.179",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.17,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.759,
        "CivilComments - EM (Robustness)":0.487,
        "RAFT - EM (Robustness)":0.445
    },
    {
        "Model":"Falcon (40B)",
        "Mean win rate":0.705,
        "MMLU - EM (Robustness)":0.457,
        "BoolQ - EM (Robustness)":0.763,
        "NarrativeQA - F1 (Robustness)":"0.557",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.329,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.593",
        "QuAC - F1 (Robustness)":"0.162",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.303,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.935,
        "CivilComments - EM (Robustness)":0.412,
        "RAFT - EM (Robustness)":0.586
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Mean win rate":0.763,
        "MMLU - EM (Robustness)":0.446,
        "BoolQ - EM (Robustness)":0.781,
        "NarrativeQA - F1 (Robustness)":"0.508",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.335,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.591",
        "QuAC - F1 (Robustness)":"0.212",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.338,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.938,
        "CivilComments - EM (Robustness)":0.523,
        "RAFT - EM (Robustness)":0.523
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":0.647,
        "MMLU - EM (Robustness)":0.32,
        "BoolQ - EM (Robustness)":0.728,
        "NarrativeQA - F1 (Robustness)":"0.629",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.117,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.6",
        "QuAC - F1 (Robustness)":"0.193",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.196,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.938,
        "CivilComments - EM (Robustness)":0.5,
        "RAFT - EM (Robustness)":0.577
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":0.522,
        "MMLU - EM (Robustness)":0.348,
        "BoolQ - EM (Robustness)":0.656,
        "NarrativeQA - F1 (Robustness)":"0.317",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.267,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.567",
        "QuAC - F1 (Robustness)":"0.248",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.151,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.906,
        "CivilComments - EM (Robustness)":0.443,
        "RAFT - EM (Robustness)":0.518
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":0.821,
        "MMLU - EM (Robustness)":0.566,
        "BoolQ - EM (Robustness)":0.878,
        "NarrativeQA - F1 (Robustness)":"0.672",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.363,
        "NaturalQuestions (open-book) - F1 (Robustness)":"-",
        "QuAC - F1 (Robustness)":"0.383",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.568,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.904,
        "CivilComments - EM (Robustness)":0.006,
        "RAFT - EM (Robustness)":0.677
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":0.205,
        "MMLU - EM (Robustness)":0.243,
        "BoolQ - EM (Robustness)":0.566,
        "NarrativeQA - F1 (Robustness)":"0.088",
        "NaturalQuestions (closed-book) - F1 (Robustness)":0.047,
        "NaturalQuestions (open-book) - F1 (Robustness)":"0.125",
        "QuAC - F1 (Robustness)":"0.08",
        "HellaSwag - EM (Robustness)":"-",
        "OpenbookQA - EM (Robustness)":"-",
        "TruthfulQA - EM (Robustness)":0.202,
        "MS MARCO (regular) - RR@10 (Robustness)":"-",
        "MS MARCO (TREC) - NDCG@10 (Robustness)":"-",
        "IMDB - EM (Robustness)":0.719,
        "CivilComments - EM (Robustness)":0.463,
        "RAFT - EM (Robustness)":0.211
    }
]