[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.745,
        "Denoised inference time (s)":"1.13",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.833,
        "Denoised inference time (s)":"0.835",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.792,
        "Denoised inference time (s)":"0.969",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.767,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.715,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":5999.966,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.762,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.803,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.982,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)\u2620",
        "BPB":0.709,
        "Denoised inference time (s)":"9.758",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8191.98,
        "# output tokens":128.85,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)\u2620",
        "BPB":0.691,
        "Denoised inference time (s)":"1.172",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.999,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "BPB":0.769,
        "Denoised inference time (s)":"0.944",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "BPB":0.807,
        "Denoised inference time (s)":"0.69",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "BPB":0.837,
        "Denoised inference time (s)":"0.533",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "BPB":0.967,
        "Denoised inference time (s)":"0.572",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "BPB":0.747,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "BPB":0.813,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.941,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "BPB":0.837,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2012.12,
        "# output tokens":0.998,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "BPB":0.772,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2012.12,
        "# output tokens":0.998,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)\u2620",
        "BPB":0.701,
        "Denoised inference time (s)":"0.458",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)\u2620",
        "BPB":0.677,
        "Denoised inference time (s)":"0.921",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.969,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)\u2620",
        "BPB":0.665,
        "Denoised inference time (s)":"0.884",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)\u2620",
        "BPB":0.684,
        "Denoised inference time (s)":"0.323",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)\u2620",
        "BPB":0.721,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.976,
        "# output tokens":0.02,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)\u2620",
        "BPB":0.818,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.976,
        "# output tokens":0.02,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":0.764,
        "Denoised inference time (s)":"0.239",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.828,
        "Denoised inference time (s)":"0.12",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":0.889,
        "Denoised inference time (s)":"0.134",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":0.958,
        "Denoised inference time (s)":"0.144",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.739,
        "Denoised inference time (s)":"-",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":4000.966,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.741,
        "Denoised inference time (s)":"0.347",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":4000.966,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":1.065,
        "Denoised inference time (s)":"0.156",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":1.168,
        "Denoised inference time (s)":"0.169",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":1.795,
        "Denoised inference time (s)":"0.12",
        "# eval":28,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.976,
        "# output tokens":0.0,
        "# trials":1
    }
]