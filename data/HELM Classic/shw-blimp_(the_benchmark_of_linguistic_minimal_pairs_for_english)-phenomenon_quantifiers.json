[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":0.738,
        "Denoised inference time (s)":"0.26",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":0.755,
        "Denoised inference time (s)":"0.239",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":0.727,
        "Denoised inference time (s)":"0.283",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":0.728,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":0.736,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":0.733,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":0.761,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":6.842,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":0.783,
        "Denoised inference time (s)":"0.452",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.389,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)",
        "EM":0.819,
        "Denoised inference time (s)":"1.093",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.396,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":0.808,
        "Denoised inference time (s)":"0.316",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":0.82,
        "Denoised inference time (s)":"0.203",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":0.82,
        "Denoised inference time (s)":"0.188",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":0.797,
        "Denoised inference time (s)":"0.214",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":0.799,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":0.834,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":0.739,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":0.773,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.222,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)",
        "EM":0.85,
        "Denoised inference time (s)":"0.554",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":0.859,
        "Denoised inference time (s)":"0.013",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":9.165,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)",
        "EM":0.892,
        "Denoised inference time (s)":"0.986",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)",
        "EM":0.882,
        "Denoised inference time (s)":"0.103",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":0.859,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":0.835,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "EM":0.845,
        "Denoised inference time (s)":"0.184",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "EM":0.848,
        "Denoised inference time (s)":"0.079",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "EM":0.873,
        "Denoised inference time (s)":"0.111",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "EM":0.841,
        "Denoised inference time (s)":"0.136",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "EM":0.76,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "EM":0.792,
        "Denoised inference time (s)":"0.158",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "EM":0.766,
        "Denoised inference time (s)":"0.12",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "EM":0.774,
        "Denoised inference time (s)":"0.122",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "EM":0.763,
        "Denoised inference time (s)":"0.076",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":8.931,
        "# output tokens":0.0,
        "# trials":1
    }
]