[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent":0.114,
        "Denoised inference time (s)":"0.586",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":3.649,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"0.434",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":3.702,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent":0.079,
        "Denoised inference time (s)":"0.508",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":4.877,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":3.044,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent":0.272,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":2.5,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":3.596,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent":0.009,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":440.421,
        "# output tokens":4.518,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent":0.088,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":485.316,
        "# output tokens":3.447,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent":0.123,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":485.316,
        "# output tokens":2.623,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent":0.219,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":485.316,
        "# output tokens":2.272,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent":0.272,
        "Denoised inference time (s)":"0.614",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.702,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent":0.079,
        "Denoised inference time (s)":"0.542",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":422.395,
        "# output tokens":2.254,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.276",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":487.5,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"0.659",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":5.351,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent":0.053,
        "Denoised inference time (s)":"0.421",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":5.596,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"0.323",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":4.64,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent":0.009,
        "Denoised inference time (s)":"0.317",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":6.561,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent":0.07,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":6.43,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":5.825,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":5.377,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent":0.114,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":476.342,
        "# output tokens":4.904,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent":0.088,
        "Denoised inference time (s)":"0.231",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":3.412,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"0.389",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":4.105,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent":0.053,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":6.079,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent":0.105,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":3.974,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.449",
        "# eval":38,
        "# train":7.07,
        "truncated":0,
        "# prompt tokens":442.956,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.341",
        "# eval":38,
        "# train":7.0,
        "truncated":0,
        "# prompt tokens":443.482,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent":0.105,
        "Denoised inference time (s)":"1.047",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.711,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"5.021",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":3.518,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":5.447,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":4.526,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent":0.237,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":3.079,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent":0.237,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent":0.237,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent":0.395,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":4.553,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent":0.079,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":3.474,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent":0.158,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":511.553,
        "# output tokens":3.184,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent":0.237,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent":0.193,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.886,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent":0.096,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":4.193,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent":0.123,
        "Denoised inference time (s)":"0.268",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.912,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"0.109",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":3.342,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent":0.053,
        "Denoised inference time (s)":"0.122",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.596,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent":0.061,
        "Denoised inference time (s)":"0.143",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.491,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent":0.561,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.605,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent":0.439,
        "Denoised inference time (s)":"0.223",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.982,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent":0.026,
        "Denoised inference time (s)":"0.144",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.588,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.139",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.974,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.093",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.009,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent":0.588,
        "Denoised inference time (s)":"0.218",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.895,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent":0.14,
        "Denoised inference time (s)":"0.124",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":4.404,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent":0.5,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":428.395,
        "# output tokens":2.0,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent":0.342,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":428.395,
        "# output tokens":2.842,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent":0.026,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":2.263,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent":0.053,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":3.395,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent":0.079,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":3.132,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent":0.053,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":4.974,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent":0.289,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent":0.237,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":453.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent":0.184,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":498.711,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent":0.079,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":498.711,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent":0.368,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":498.711,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent":0.289,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":498.711,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.807",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":472.0,
        "# output tokens":5.561,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent":0.105,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":2.93,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent":0.377,
        "Denoised inference time (s)":"-",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":469.105,
        "# output tokens":1.605,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.374",
        "# eval":38,
        "# train":8.0,
        "truncated":0,
        "# prompt tokens":416.763,
        "# output tokens":18.684,
        "# trials":3
    }
]