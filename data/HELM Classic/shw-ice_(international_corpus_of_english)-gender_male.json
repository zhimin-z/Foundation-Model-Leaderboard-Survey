[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.883,
        "Denoised inference time (s)":"1.128",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.931,
        "Denoised inference time (s)":"0.834",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.904,
        "Denoised inference time (s)":"0.967",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.871,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.833,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3000.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.863,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.901,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2042.905,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "BPB":0.849,
        "Denoised inference time (s)":"1.423",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3584.816,
        "# output tokens":1.75,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)",
        "BPB":0.738,
        "Denoised inference time (s)":"1.15",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.155,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "BPB":0.906,
        "Denoised inference time (s)":"0.947",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "BPB":0.946,
        "Denoised inference time (s)":"0.692",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "BPB":0.983,
        "Denoised inference time (s)":"0.534",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "BPB":1.15,
        "Denoised inference time (s)":"0.573",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "BPB":0.929,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "BPB":1.015,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.776,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "BPB":1.048,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2019.815,
        "# output tokens":0.976,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "BPB":0.962,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2019.815,
        "# output tokens":0.976,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)",
        "BPB":0.773,
        "Denoised inference time (s)":"0.516",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)",
        "BPB":0.765,
        "Denoised inference time (s)":"0.932",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.615,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)",
        "BPB":0.759,
        "Denoised inference time (s)":"1.007",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)",
        "BPB":0.782,
        "Denoised inference time (s)":"0.339",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "BPB":0.85,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.764,
        "# output tokens":0.013,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "BPB":0.93,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2047.764,
        "# output tokens":0.013,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":1.013,
        "Denoised inference time (s)":"0.239",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.969,
        "Denoised inference time (s)":"0.12",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":1.062,
        "Denoised inference time (s)":"0.134",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":1.148,
        "Denoised inference time (s)":"0.144",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.863,
        "Denoised inference time (s)":"-",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3513.665,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.85,
        "Denoised inference time (s)":"0.324",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3513.665,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":1.208,
        "Denoised inference time (s)":"0.156",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":1.341,
        "Denoised inference time (s)":"0.169",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":2.001,
        "Denoised inference time (s)":"0.12",
        "# eval":694,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2048.762,
        "# output tokens":0.0,
        "# trials":1
    }
]