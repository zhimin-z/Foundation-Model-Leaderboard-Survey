[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.445",
        "Denoised inference time (s)":"0.447",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"3.423",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.414",
        "Denoised inference time (s)":"0.347",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"4.572",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.696",
        "Denoised inference time (s)":"0.517",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"4.041",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.617",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"4.44",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.709",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"3.672",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.529",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"4.753",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.559",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"206.652",
        "# output tokens":"4.587",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.517",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"166.418",
        "# output tokens":"2.511",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.666",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"166.418",
        "# output tokens":"2.721",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.729",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"166.418",
        "# output tokens":"3.123",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.849",
        "Denoised inference time (s)":"0.644",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.479",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.545",
        "Denoised inference time (s)":"0.389",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"150.706",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.011",
        "Denoised inference time (s)":"0.166",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"265.076",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.594",
        "Denoised inference time (s)":"0.515",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"3.857",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.531",
        "Denoised inference time (s)":"0.281",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"2.462",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.511",
        "Denoised inference time (s)":"0.248",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"3.447",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.358",
        "Denoised inference time (s)":"0.246",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"3.203",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.587",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"3.887",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.411",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"1.959",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.372",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"1.901",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.421",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"165.418",
        "# output tokens":"1.591",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.337",
        "Denoised inference time (s)":"0.312",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.747",
        "Denoised inference time (s)":"0.325",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.652",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.798",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.347",
        "Denoised inference time (s)":"0.235",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"265.076",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.14",
        "Denoised inference time (s)":"0.216",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"269.076",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.494",
        "Denoised inference time (s)":"1.256",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.471",
        "Denoised inference time (s)":"0.054",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.56",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.686",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.706",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.65",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"0.91",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.658",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"0.994",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.624",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.742",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"0.964",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.524",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"3.34",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.622",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"4.194",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.686",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"4.998",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.696",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"166.418",
        "# output tokens":"0.964",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.753",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.252",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.554",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"3.352",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.668",
        "Denoised inference time (s)":"0.235",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.946",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.47",
        "Denoised inference time (s)":"0.094",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.479",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.473",
        "Denoised inference time (s)":"0.128",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.977",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.406",
        "Denoised inference time (s)":"0.149",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.335",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.751",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.297",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.603",
        "Denoised inference time (s)":"0.208",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.637",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.41",
        "Denoised inference time (s)":"0.136",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.436",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.231",
        "Denoised inference time (s)":"0.134",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.472",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.161",
        "Denoised inference time (s)":"0.09",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.761",
        "# trials":"3"
    },
    {
        "Model":"code-davinci-002",
        "EM":"0.805",
        "Denoised inference time (s)":"0.223",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"3.267",
        "# trials":"3"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":"0.451",
        "Denoised inference time (s)":"0.107",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.593",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.172",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"159.418",
        "# output tokens":"5.666",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.01",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"159.418",
        "# output tokens":"6",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.53",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.708",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.528",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.546",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.634",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"0.932",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.624",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.458",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"296.836",
        "# output tokens":"0.998",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.192",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"296.836",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.534",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"296.836",
        "# output tokens":"0.996",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.364",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"296.836",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.549",
        "Denoised inference time (s)":"1.216",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"203.784",
        "# output tokens":"4.583",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.447",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"1.045",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.579",
        "Denoised inference time (s)":"-",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"2.711",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.633",
        "Denoised inference time (s)":"0.273",
        "# eval":"500",
        "# train":"3",
        "truncated":"0",
        "# prompt tokens":"164.418",
        "# output tokens":"5",
        "# trials":"3"
    }
]