[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":0.263,
        "Denoised inference time (s)":"0.589",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.116,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":0.201,
        "Denoised inference time (s)":"0.399",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.371,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":0.247,
        "Denoised inference time (s)":"0.531",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.171,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":0.286,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.146,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":0.393,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.232,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":0.301,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":6.303,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":0.192,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":246.737,
        "# output tokens":5.819,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":0.209,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":294.059,
        "# output tokens":3.593,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":0.225,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":294.059,
        "# output tokens":3.645,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":0.312,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":294.059,
        "# output tokens":3.797,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":0.432,
        "Denoised inference time (s)":"0.868",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.829,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "EM":0.304,
        "Denoised inference time (s)":"0.34",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":274.195,
        "# output tokens":12.028,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "EM":0.0,
        "Denoised inference time (s)":"0.296",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":318.235,
        "# output tokens":38.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":0.194,
        "Denoised inference time (s)":"0.589",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":4.073,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":0.128,
        "Denoised inference time (s)":"0.353",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":3.927,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":0.129,
        "Denoised inference time (s)":"0.284",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":3.753,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":0.121,
        "Denoised inference time (s)":"0.269",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":3.558,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":0.229,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":3.876,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":0.096,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":3.716,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":0.123,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":5.674,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":0.243,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":292.607,
        "# output tokens":5.706,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "EM":0.174,
        "Denoised inference time (s)":"0.136",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":17.917,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":0.204,
        "Denoised inference time (s)":"0.14",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":287.815,
        "# output tokens":19.93,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":0.139,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "EM":0.176,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "EM":0.196,
        "Denoised inference time (s)":"0.531",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":317.835,
        "# output tokens":38.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "EM":0.205,
        "Denoised inference time (s)":"0.387",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":321.835,
        "# output tokens":38.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "EM":0.225,
        "Denoised inference time (s)":"0.257",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":13.045,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "EM":0.193,
        "Denoised inference time (s)":"0.075",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":13.868,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "EM":0.143,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "EM":0.214,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "EM":0.412,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "EM":0.438,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":0.222,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":0.324,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":0.489,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "EM":0.155,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":14.288,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":0.179,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":37.796,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":0.234,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":307.548,
        "# output tokens":37.843,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":0.451,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":0.362,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.457,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":0.232,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.977,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "EM":0.236,
        "Denoised inference time (s)":"0.348",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.535,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "EM":0.223,
        "Denoised inference time (s)":"0.124",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.709,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "EM":0.16,
        "Denoised inference time (s)":"0.152",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":6.671,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "EM":0.1,
        "Denoised inference time (s)":"0.173",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":6.435,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "EM":0.502,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.846,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "EM":0.488,
        "Denoised inference time (s)":"0.339",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.85,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "EM":0.19,
        "Denoised inference time (s)":"0.165",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.659,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "EM":0.123,
        "Denoised inference time (s)":"0.161",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.496,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "EM":0.063,
        "Denoised inference time (s)":"0.113",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.523,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "EM":0.54,
        "Denoised inference time (s)":"0.271",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":4.509,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "EM":0.341,
        "Denoised inference time (s)":"0.129",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":4.389,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":0.45,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":254.207,
        "# output tokens":6.412,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":0.509,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":254.207,
        "# output tokens":6.008,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":0.154,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":0.142,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":0.137,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":0.184,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":38.0,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "EM":0.335,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":0.35,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":281.682,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "EM":0.1,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":315.758,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":0.037,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":315.758,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "EM":0.238,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":315.758,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":0.216,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":315.758,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "EM":0.252,
        "Denoised inference time (s)":"0.347",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":268.083,
        "# output tokens":6.619,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":0.231,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.423,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":0.504,
        "Denoised inference time (s)":"-",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":286.053,
        "# output tokens":5.88,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "EM":0.056,
        "Denoised inference time (s)":"0.307",
        "# eval":515,
        "# train":4.2,
        "truncated":0,
        "# prompt tokens":285.977,
        "# output tokens":29.404,
        "# trials":3
    }
]