[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":0.9,
        "Denoised inference time (s)":"1.127",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":0.946,
        "Denoised inference time (s)":"0.833",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":0.922,
        "Denoised inference time (s)":"0.966",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":0.888,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":0.85,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3050.888,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":0.88,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":0.917,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2039.48,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "BPB":0.867,
        "Denoised inference time (s)":"1.431",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3580.979,
        "# output tokens":1.893,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)",
        "BPB":0.746,
        "Denoised inference time (s)":"1.144",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2044.125,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "BPB":0.922,
        "Denoised inference time (s)":"0.946",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "BPB":0.969,
        "Denoised inference time (s)":"0.691",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "BPB":1.008,
        "Denoised inference time (s)":"0.534",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "BPB":1.174,
        "Denoised inference time (s)":"0.573",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "BPB":0.952,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "BPB":1.041,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.509,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "BPB":1.067,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2017.721,
        "# output tokens":0.985,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "BPB":0.983,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2017.721,
        "# output tokens":0.985,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)",
        "BPB":0.78,
        "Denoised inference time (s)":"0.514",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)",
        "BPB":0.774,
        "Denoised inference time (s)":"0.924",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.722,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)",
        "BPB":0.763,
        "Denoised inference time (s)":"0.999",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)",
        "BPB":0.787,
        "Denoised inference time (s)":"0.326",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "BPB":0.865,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.321,
        "# output tokens":0.022,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "BPB":0.944,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2045.321,
        "# output tokens":0.022,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":1.018,
        "Denoised inference time (s)":"0.239",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":0.986,
        "Denoised inference time (s)":"0.12",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":1.084,
        "Denoised inference time (s)":"0.134",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":1.173,
        "Denoised inference time (s)":"0.144",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":0.895,
        "Denoised inference time (s)":"-",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3518.653,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":0.872,
        "Denoised inference time (s)":"0.324",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":3518.653,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":1.241,
        "Denoised inference time (s)":"0.156",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":1.376,
        "Denoised inference time (s)":"0.169",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":2.05,
        "Denoised inference time (s)":"0.12",
        "# eval":420,
        "# train":0,
        "truncated":0,
        "# prompt tokens":2046.318,
        "# output tokens":0.0,
        "# trials":1
    }
]