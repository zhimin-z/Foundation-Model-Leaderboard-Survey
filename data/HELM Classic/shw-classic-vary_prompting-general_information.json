[
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"456.485",
        "CivilComments - # output tokens":"1",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"474.485",
        "CivilComments - # output tokens":"1",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.964",
        "NaturalQuestions (open-book) - truncated":"0.007",
        "NaturalQuestions (open-book) - # prompt tokens":"1598.658",
        "NaturalQuestions (open-book) - # output tokens":"5.368",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"5",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1410.545",
        "IMDB - # output tokens":"1.003",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"1",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.964",
        "NaturalQuestions (open-book) - truncated":"0.007",
        "NaturalQuestions (open-book) - # prompt tokens":"1598.658",
        "NaturalQuestions (open-book) - # output tokens":"6.527",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"5",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1410.545",
        "IMDB - # output tokens":"1.005",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"1",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.964",
        "NaturalQuestions (open-book) - truncated":"0.007",
        "NaturalQuestions (open-book) - # prompt tokens":"1649.295",
        "NaturalQuestions (open-book) - # output tokens":"8.49",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1516.876",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"5",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1458.55",
        "IMDB - # output tokens":"4",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"495.502",
        "CivilComments - # output tokens":"4",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"5",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1422.545",
        "IMDB - # output tokens":"1.014",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"5",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1440.545",
        "IMDB - # output tokens":"1.01",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.964",
        "NaturalQuestions (open-book) - truncated":"0.007",
        "NaturalQuestions (open-book) - # prompt tokens":"1592.701",
        "NaturalQuestions (open-book) - # output tokens":"5.659",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.964",
        "NaturalQuestions (open-book) - truncated":"0.007",
        "NaturalQuestions (open-book) - # prompt tokens":"1610.575",
        "NaturalQuestions (open-book) - # output tokens":"5.601",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"58.035",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1567.919",
        "CNN\/DailyMail - # output tokens":"57.431",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"424.427",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"BLOOM (176B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"440.427",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.745",
        "NaturalQuestions (open-book) - truncated":"0.035",
        "NaturalQuestions (open-book) - # prompt tokens":"1308.07",
        "NaturalQuestions (open-book) - # output tokens":"32.451",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.948",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1353.765",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"406.427",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.743",
        "NaturalQuestions (open-book) - truncated":"0.035",
        "NaturalQuestions (open-book) - # prompt tokens":"1313.422",
        "NaturalQuestions (open-book) - # output tokens":"31.911",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.947",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1359.01",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"412.427",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.732",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1364.141",
        "NaturalQuestions (open-book) - # output tokens":"32.971",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1524.65",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1401.766",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"463.43",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.943",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1375.21",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.938",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1388.333",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.743",
        "NaturalQuestions (open-book) - truncated":"0.035",
        "NaturalQuestions (open-book) - # prompt tokens":"1313.422",
        "NaturalQuestions (open-book) - # output tokens":"38.803",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.738",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1327.346",
        "NaturalQuestions (open-book) - # output tokens":"28.376",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1541.33",
        "CNN\/DailyMail - # output tokens":"117.435",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1557.33",
        "CNN\/DailyMail - # output tokens":"116.814",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1468.664",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"BLOOM (176B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1474.664",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"506.075",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"488.075",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"3.348",
        "NaturalQuestions (open-book) - truncated":"0.057",
        "NaturalQuestions (open-book) - # prompt tokens":"903.653",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"2.497",
        "IMDB - truncated":"0.03",
        "IMDB - # prompt tokens":"912.895",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"482.075",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"3.305",
        "NaturalQuestions (open-book) - truncated":"0.057",
        "NaturalQuestions (open-book) - # prompt tokens":"903.262",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"2.463",
        "IMDB - truncated":"0.03",
        "IMDB - # prompt tokens":"911.919",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"494.075",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"3.033",
        "NaturalQuestions (open-book) - truncated":"0.057",
        "NaturalQuestions (open-book) - # prompt tokens":"902.918",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.297",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"887.541",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"2.165",
        "IMDB - truncated":"0.03",
        "IMDB - # prompt tokens":"886.888",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"576.179",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T0pp (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"2.35",
        "IMDB - truncated":"0.032",
        "IMDB - # prompt tokens":"906.606",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"2.44",
        "IMDB - truncated":"0.03",
        "IMDB - # prompt tokens":"910.174",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"3.31",
        "NaturalQuestions (open-book) - truncated":"0.058",
        "NaturalQuestions (open-book) - # prompt tokens":"904.233",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"3.396",
        "NaturalQuestions (open-book) - truncated":"0.057",
        "NaturalQuestions (open-book) - # prompt tokens":"903.877",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.288",
        "CNN\/DailyMail - truncated":"0.012",
        "CNN\/DailyMail - # prompt tokens":"894.042",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.335",
        "CNN\/DailyMail - truncated":"0.004",
        "CNN\/DailyMail - # prompt tokens":"886.838",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.419",
        "CNN\/DailyMail - truncated":"0.002",
        "CNN\/DailyMail - # prompt tokens":"882.39",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T0pp (11B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"1.398",
        "CNN\/DailyMail - truncated":"0.002",
        "CNN\/DailyMail - # prompt tokens":"882.262",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"456.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-J (6B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"474.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"51.47",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"38.562",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.671",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1466.931",
        "NaturalQuestions (open-book) - # output tokens":"47.893",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1516.876",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.923",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1419.668",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"495.502",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1389.454",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.928",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1405.601",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.691",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1419.574",
        "NaturalQuestions (open-book) - # output tokens":"247.23",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.683",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1434.337",
        "NaturalQuestions (open-book) - # output tokens":"53.823",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"83.931",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1567.919",
        "CNN\/DailyMail - # output tokens":"85.835",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-J (6B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"459.008",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"477.008",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.701",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1404.573",
        "NaturalQuestions (open-book) - # output tokens":"30.887",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.932",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1387.486",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"453.008",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.701",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1404.573",
        "NaturalQuestions (open-book) - # output tokens":"31.506",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.932",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1387.486",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"453.008",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.688",
        "NaturalQuestions (open-book) - truncated":"0.039",
        "NaturalQuestions (open-book) - # prompt tokens":"1442.965",
        "NaturalQuestions (open-book) - # output tokens":"39.902",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.23",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.919",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1422.48",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"498.002",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.93",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1398.09",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.922",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1412.398",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.704",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1394.229",
        "NaturalQuestions (open-book) - # output tokens":"87.693",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.699",
        "NaturalQuestions (open-book) - truncated":"0.039",
        "NaturalQuestions (open-book) - # prompt tokens":"1410.029",
        "NaturalQuestions (open-book) - # output tokens":"36.644",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1582.608",
        "CNN\/DailyMail - # output tokens":"80.409",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1600.608",
        "CNN\/DailyMail - # output tokens":"82.514",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1517.275",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GPT-NeoX (20B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1517.275",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.009",
        "CivilComments - truncated":"0.007",
        "CivilComments - # prompt tokens":"444.264",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.159",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"437.249",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.918",
        "NaturalQuestions (open-book) - truncated":"0.355",
        "NaturalQuestions (open-book) - # prompt tokens":"303.58",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.489",
        "IMDB - truncated":"0.172",
        "IMDB - # prompt tokens":"410.641",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.206",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"435.231",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.91",
        "NaturalQuestions (open-book) - truncated":"0.362",
        "NaturalQuestions (open-book) - # prompt tokens":"304.535",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.473",
        "IMDB - truncated":"0.173",
        "IMDB - # prompt tokens":"409.175",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.12",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"439.969",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.88",
        "NaturalQuestions (open-book) - truncated":"0.125",
        "NaturalQuestions (open-book) - # prompt tokens":"317.19",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.06",
        "CNN\/DailyMail - truncated":"0.828",
        "CNN\/DailyMail - # prompt tokens":"499.06",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.364",
        "IMDB - truncated":"0.174",
        "IMDB - # prompt tokens":"394.004",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"3.516",
        "CivilComments - truncated":"0.001",
        "CivilComments - # prompt tokens":"460.577",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"T5 (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.397",
        "IMDB - truncated":"0.338",
        "IMDB - # prompt tokens":"404.344",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.466",
        "IMDB - truncated":"0.173",
        "IMDB - # prompt tokens":"408.425",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.9",
        "NaturalQuestions (open-book) - truncated":"0.37",
        "NaturalQuestions (open-book) - # prompt tokens":"311.068",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.924",
        "NaturalQuestions (open-book) - truncated":"0.349",
        "NaturalQuestions (open-book) - # prompt tokens":"301.907",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.052",
        "CNN\/DailyMail - truncated":"0.944",
        "CNN\/DailyMail - # prompt tokens":"501.768",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.064",
        "CNN\/DailyMail - truncated":"0.932",
        "CNN\/DailyMail - # prompt tokens":"500.553",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.069",
        "CNN\/DailyMail - truncated":"0.926",
        "CNN\/DailyMail - # prompt tokens":"498.955",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"T5 (11B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.069",
        "CNN\/DailyMail - truncated":"0.927",
        "CNN\/DailyMail - # prompt tokens":"499.348",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"3.973",
        "CivilComments - truncated":"0.007",
        "CivilComments - # prompt tokens":"445.597",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.13",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"439.285",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.91",
        "NaturalQuestions (open-book) - truncated":"0.362",
        "NaturalQuestions (open-book) - # prompt tokens":"304.569",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.474",
        "IMDB - truncated":"0.174",
        "IMDB - # prompt tokens":"410.044",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.171",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"436.835",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.906",
        "NaturalQuestions (open-book) - truncated":"0.364",
        "NaturalQuestions (open-book) - # prompt tokens":"307.295",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.456",
        "IMDB - truncated":"0.174",
        "IMDB - # prompt tokens":"407.701",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"4.086",
        "CivilComments - truncated":"0.001",
        "CivilComments - # prompt tokens":"441.293",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.877",
        "NaturalQuestions (open-book) - truncated":"0.125",
        "NaturalQuestions (open-book) - # prompt tokens":"320.021",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.058",
        "CNN\/DailyMail - truncated":"0.83",
        "CNN\/DailyMail - # prompt tokens":"499.403",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.346",
        "IMDB - truncated":"0.177",
        "IMDB - # prompt tokens":"391.813",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"3.48",
        "CivilComments - truncated":"0.001",
        "CivilComments - # prompt tokens":"462.13",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"UL2 (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.379",
        "IMDB - truncated":"0.35",
        "IMDB - # prompt tokens":"402.945",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"0.449",
        "IMDB - truncated":"0.176",
        "IMDB - # prompt tokens":"407.098",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.895",
        "NaturalQuestions (open-book) - truncated":"0.375",
        "NaturalQuestions (open-book) - # prompt tokens":"313.159",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"0.918",
        "NaturalQuestions (open-book) - truncated":"0.355",
        "NaturalQuestions (open-book) - # prompt tokens":"303.619",
        "NaturalQuestions (open-book) - # output tokens":"300",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.048",
        "CNN\/DailyMail - truncated":"0.948",
        "CNN\/DailyMail - # prompt tokens":"501.855",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.061",
        "CNN\/DailyMail - truncated":"0.935",
        "CNN\/DailyMail - # prompt tokens":"500.829",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.069",
        "CNN\/DailyMail - truncated":"0.927",
        "CNN\/DailyMail - # prompt tokens":"499.564",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"UL2 (20B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"0.069",
        "CNN\/DailyMail - truncated":"0.927",
        "CNN\/DailyMail - # prompt tokens":"500.052",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"456.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (175B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"474.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"23.99",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"33.373",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.671",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1466.931",
        "NaturalQuestions (open-book) - # output tokens":"56.63",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1516.876",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.923",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1419.668",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"495.502",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1389.454",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.928",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1405.601",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.691",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1419.574",
        "NaturalQuestions (open-book) - # output tokens":"194.671",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.683",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1434.337",
        "NaturalQuestions (open-book) - # output tokens":"30.418",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"73.533",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1567.919",
        "CNN\/DailyMail - # output tokens":"76.392",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (175B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"456.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (66B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"474.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"51.029",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.689",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1424.771",
        "NaturalQuestions (open-book) - # output tokens":"77.831",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.935",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1378.788",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"450.485",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.671",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1466.931",
        "NaturalQuestions (open-book) - # output tokens":"84.159",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1516.876",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.923",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1419.668",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"495.502",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1389.454",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.928",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1405.601",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.691",
        "NaturalQuestions (open-book) - truncated":"0.036",
        "NaturalQuestions (open-book) - # prompt tokens":"1419.574",
        "NaturalQuestions (open-book) - # output tokens":"211.805",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.683",
        "NaturalQuestions (open-book) - truncated":"0.037",
        "NaturalQuestions (open-book) - # prompt tokens":"1434.337",
        "NaturalQuestions (open-book) - # output tokens":"76.684",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1549.919",
        "CNN\/DailyMail - # output tokens":"77.928",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1567.919",
        "CNN\/DailyMail - # output tokens":"76.078",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"OPT (66B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1484.253",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"459.077",
        "CivilComments - # output tokens":"2",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"441.077",
        "CivilComments - # output tokens":"2",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.619",
        "NaturalQuestions (open-book) - truncated":"0.047",
        "NaturalQuestions (open-book) - # prompt tokens":"1510.941",
        "NaturalQuestions (open-book) - # output tokens":"20.589",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.928",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1402.52",
        "IMDB - # output tokens":"2",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"441.077",
        "CivilComments - # output tokens":"2",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.619",
        "NaturalQuestions (open-book) - truncated":"0.047",
        "NaturalQuestions (open-book) - # prompt tokens":"1510.941",
        "NaturalQuestions (open-book) - # output tokens":"20.725",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.928",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1402.52",
        "IMDB - # output tokens":"2",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"441.077",
        "CivilComments - # output tokens":"2",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.568",
        "NaturalQuestions (open-book) - truncated":"0.047",
        "NaturalQuestions (open-book) - # prompt tokens":"1542.823",
        "NaturalQuestions (open-book) - # output tokens":"23.421",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1632.828",
        "CNN\/DailyMail - # output tokens":"77.928",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.913",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1438.092",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"485.717",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"GLM (130B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.917",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1427.179",
        "IMDB - # output tokens":"2",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.923",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1412.285",
        "IMDB - # output tokens":"2",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.613",
        "NaturalQuestions (open-book) - truncated":"0.047",
        "NaturalQuestions (open-book) - # prompt tokens":"1516.056",
        "NaturalQuestions (open-book) - # output tokens":"19.45",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.631",
        "NaturalQuestions (open-book) - truncated":"0.047",
        "NaturalQuestions (open-book) - # prompt tokens":"1502.677",
        "NaturalQuestions (open-book) - # output tokens":"21.064",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"4.999",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1674.94",
        "CNN\/DailyMail - # output tokens":"82.03",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1657.124",
        "CNN\/DailyMail - # output tokens":"82.997",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1591.124",
        "CNN\/DailyMail - # output tokens":"71.594",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"GLM (130B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1591.124",
        "CNN\/DailyMail - # output tokens":"86.123",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"458.019",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"YaLM (100B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Answer: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"476.019",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.699",
        "NaturalQuestions (open-book) - truncated":"0.038",
        "NaturalQuestions (open-book) - # prompt tokens":"1419.763",
        "NaturalQuestions (open-book) - # output tokens":"291.258",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1391.794",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"452.019",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.699",
        "NaturalQuestions (open-book) - truncated":"0.038",
        "NaturalQuestions (open-book) - # prompt tokens":"1419.763",
        "NaturalQuestions (open-book) - # output tokens":"293.843",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.933",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1391.794",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"452.019",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: <input>]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.685",
        "NaturalQuestions (open-book) - truncated":"0.038",
        "NaturalQuestions (open-book) - # prompt tokens":"1453.08",
        "NaturalQuestions (open-book) - # output tokens":"294.448",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1511.707",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.919",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1425.83",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"382.5",
        "CivilComments - # train":"5",
        "CivilComments - truncated":"0",
        "CivilComments - # prompt tokens":"491.004",
        "CivilComments - # output tokens":"5",
        "CivilComments - # trials":"3"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.929",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1402.276",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: Passage: , input_suffix: , output_prefix: Sentiment: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"1000",
        "IMDB - # train":"4.924",
        "IMDB - truncated":"0",
        "IMDB - # prompt tokens":"1417.566",
        "IMDB - # output tokens":"5",
        "IMDB - # trials":"3",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.702",
        "NaturalQuestions (open-book) - truncated":"0.038",
        "NaturalQuestions (open-book) - # prompt tokens":"1409.24",
        "NaturalQuestions (open-book) - # output tokens":"291.572",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"1000",
        "NaturalQuestions (open-book) - # train":"4.697",
        "NaturalQuestions (open-book) - truncated":"0.038",
        "NaturalQuestions (open-book) - # prompt tokens":"1425.403",
        "NaturalQuestions (open-book) - # output tokens":"292.879",
        "NaturalQuestions (open-book) - # trials":"3",
        "CNN\/DailyMail - # eval":"-",
        "CNN\/DailyMail - # train":"-",
        "CNN\/DailyMail - truncated":"-",
        "CNN\/DailyMail - # prompt tokens":"-",
        "CNN\/DailyMail - # output tokens":"-",
        "CNN\/DailyMail - # trials":"-",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1544.765",
        "CNN\/DailyMail - # output tokens":"102.407",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: I am an expert AI assistant who is here to help you with the following. , input_prefix: ### Article: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1562.765",
        "CNN\/DailyMail - # output tokens":"101.632",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: I: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1479.432",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    },
    {
        "Model":"YaLM (100B) [instructions: , input_prefix: Input: , input_suffix: ]",
        "Mean win rate":"-",
        "NaturalQuestions (open-book) - # eval":"-",
        "NaturalQuestions (open-book) - # train":"-",
        "NaturalQuestions (open-book) - truncated":"-",
        "NaturalQuestions (open-book) - # prompt tokens":"-",
        "NaturalQuestions (open-book) - # output tokens":"-",
        "NaturalQuestions (open-book) - # trials":"-",
        "CNN\/DailyMail - # eval":"466",
        "CNN\/DailyMail - # train":"5",
        "CNN\/DailyMail - truncated":"0",
        "CNN\/DailyMail - # prompt tokens":"1479.432",
        "CNN\/DailyMail - # output tokens":"128",
        "CNN\/DailyMail - # trials":"3",
        "IMDB - # eval":"-",
        "IMDB - # train":"-",
        "IMDB - truncated":"-",
        "IMDB - # prompt tokens":"-",
        "IMDB - # output tokens":"-",
        "IMDB - # trials":"-",
        "CivilComments - # eval":"-",
        "CivilComments - # train":"-",
        "CivilComments - truncated":"-",
        "CivilComments - # prompt tokens":"-",
        "CivilComments - # output tokens":"-",
        "CivilComments - # trials":"-"
    }
]