[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "BPB":2.18,
        "Denoised inference time (s)":"0.263",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "BPB":2.245,
        "Denoised inference time (s)":"0.24",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "BPB":2.205,
        "Denoised inference time (s)":"0.288",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "BPB":2.156,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "BPB":2.121,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "BPB":2.137,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "BPB":2.179,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":12.325,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "BPB":2.109,
        "Denoised inference time (s)":"0.736",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":5.959,
        "# trials":1
    },
    {
        "Model":"BLOOM (176B)",
        "BPB":1.986,
        "Denoised inference time (s)":"0.036",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":15.618,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "BPB":2.305,
        "Denoised inference time (s)":"0.32",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "BPB":2.324,
        "Denoised inference time (s)":"0.205",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "BPB":2.341,
        "Denoised inference time (s)":"0.189",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "BPB":2.525,
        "Denoised inference time (s)":"0.215",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "BPB":2.325,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "BPB":2.428,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "BPB":2.61,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":1.002,
        "# trials":1
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "BPB":2.73,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.471,
        "# output tokens":1.002,
        "# trials":1
    },
    {
        "Model":"GPT-J (6B)",
        "BPB":1.989,
        "Denoised inference time (s)":"0.438",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"GPT-NeoX (20B)",
        "BPB":1.943,
        "Denoised inference time (s)":"0.824",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.554,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (175B)",
        "BPB":1.81,
        "Denoised inference time (s)":"0.184",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"OPT (66B)",
        "BPB":1.85,
        "Denoised inference time (s)":"1.274",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "BPB":2.245,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "BPB":2.323,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"davinci (175B)",
        "BPB":2.141,
        "Denoised inference time (s)":"0.185",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"curie (6.7B)",
        "BPB":2.21,
        "Denoised inference time (s)":"0.08",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"babbage (1.3B)",
        "BPB":2.291,
        "Denoised inference time (s)":"0.111",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"ada (350M)",
        "BPB":2.395,
        "Denoised inference time (s)":"0.136",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-003",
        "BPB":2.192,
        "Denoised inference time (s)":"-",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-davinci-002",
        "BPB":2.147,
        "Denoised inference time (s)":"0.16",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-curie-001",
        "BPB":2.628,
        "Denoised inference time (s)":"0.12",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-babbage-001",
        "BPB":2.946,
        "Denoised inference time (s)":"0.123",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    },
    {
        "Model":"text-ada-001",
        "BPB":3.505,
        "Denoised inference time (s)":"0.077",
        "# eval":1000,
        "# train":0,
        "truncated":0,
        "# prompt tokens":16.422,
        "# output tokens":0.0,
        "# trials":1
    }
]