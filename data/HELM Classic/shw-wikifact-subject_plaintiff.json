[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.479",
        "Denoised inference time (s)":"1.079",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"19.698",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.451",
        "Denoised inference time (s)":"0.555",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"19.545",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.472",
        "Denoised inference time (s)":"0.758",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"20.413",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.556",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"20.313",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.66",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"18.122",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.597",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"17.719",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.497",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.542",
        "# output tokens":"18.233",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.51",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"118.135",
        "# output tokens":"16.937",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.514",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"118.135",
        "# output tokens":"16.656",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.608",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"118.135",
        "# output tokens":"17.431",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.594",
        "Denoised inference time (s)":"1.524",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"18.479",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.417",
        "Denoised inference time (s)":"0.801",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.094",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.045",
        "Denoised inference time (s)":"0.155",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"132.615",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.583",
        "Denoised inference time (s)":"1.094",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"18.955",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.531",
        "Denoised inference time (s)":"0.595",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"16.719",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.438",
        "Denoised inference time (s)":"0.412",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"17.844",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.413",
        "Denoised inference time (s)":"0.324",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"17.222",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.604",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"18.372",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.503",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"17.344",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.507",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"18.802",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.542",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"119.833",
        "# output tokens":"19.354",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.326",
        "Denoised inference time (s)":"0.099",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.403",
        "Denoised inference time (s)":"0.061",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"123.625",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.26",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.792",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.375",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.521",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.302",
        "Denoised inference time (s)":"0.288",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"132.615",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.403",
        "Denoised inference time (s)":"0.279",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"136.615",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.507",
        "Denoised inference time (s)":"0.612",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.392",
        "Denoised inference time (s)":"0.156",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.354",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"5.115",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.438",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"4.813",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.479",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"4.698",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.677",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.573",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.594",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.688",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.448",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"5.094",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.479",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"4.958",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.49",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"151.135",
        "# output tokens":"4.74",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.583",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.601",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"20.365",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.455",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"19.688",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.521",
        "Denoised inference time (s)":"0.78",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"20.42",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.406",
        "Denoised inference time (s)":"0.214",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"19.323",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.392",
        "Denoised inference time (s)":"0.226",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"19.681",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.295",
        "Denoised inference time (s)":"0.251",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"19.701",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.604",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"24.431",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.635",
        "Denoised inference time (s)":"0.667",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"17.917",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.483",
        "Denoised inference time (s)":"0.251",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"18.667",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.396",
        "Denoised inference time (s)":"0.251",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"18.833",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.26",
        "Denoised inference time (s)":"0.173",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"16.438",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.542",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"116.99",
        "# output tokens":"27.25",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.542",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"116.99",
        "# output tokens":"23.583",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.385",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.188",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.333",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.323",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.385",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.25",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.385",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"4.313",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.615",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.583",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"128.292",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.542",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"127.115",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.396",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"127.115",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.604",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"127.115",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.521",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"127.115",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.455",
        "Denoised inference time (s)":"0.521",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"124.854",
        "# output tokens":"25.243",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.441",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"17.531",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.594",
        "Denoised inference time (s)":"-",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"120.344",
        "# output tokens":"16.809",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.104",
        "Denoised inference time (s)":"0.343",
        "# eval":"96",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"115.698",
        "# output tokens":"40",
        "# trials":"3"
    }
]