[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.458",
        "Denoised inference time (s)":"0.734",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"11.814",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.33",
        "Denoised inference time (s)":"0.432",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"12.307",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.475",
        "Denoised inference time (s)":"0.547",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"11.684",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.522",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"11.951",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.48",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"10.682",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.484",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"10.679",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.292",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"53.642",
        "# output tokens":"11.389",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.477",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"71.989",
        "# output tokens":"5.767",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.493",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"71.989",
        "# output tokens":"5.859",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.495",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"71.989",
        "# output tokens":"5.889",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.429",
        "Denoised inference time (s)":"0.828",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"6.844",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.32",
        "Denoised inference time (s)":"0.792",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"68.036",
        "# output tokens":"39.172",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0",
        "Denoised inference time (s)":"0.122",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.213",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.582",
        "Denoised inference time (s)":"0.564",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.331",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.527",
        "Denoised inference time (s)":"0.335",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"5.976",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.475",
        "Denoised inference time (s)":"0.262",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.137",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.154",
        "Denoised inference time (s)":"0.26",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"7.397",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.504",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.229",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.387",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.981",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.573",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.269",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.544",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.643",
        "# output tokens":"6.091",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.196",
        "Denoised inference time (s)":"0.088",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.313",
        "Denoised inference time (s)":"0.055",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"74.061",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.407",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.336",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.433",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.201",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.288",
        "Denoised inference time (s)":"0.288",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.213",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.127",
        "Denoised inference time (s)":"0.239",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"80.213",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.342",
        "Denoised inference time (s)":"0.573",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"38.466",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.34",
        "Denoised inference time (s)":"0.137",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"38.376",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.191",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.714",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.494",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.689",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.568",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.682",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.611",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.578",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.574",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.605",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.302",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.605",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.239",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.789",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.502",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"76.776",
        "# output tokens":"2.622",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.559",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.515",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.354",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.427",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.369",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.528",
        "Denoised inference time (s)":"0.398",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.885",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.481",
        "Denoised inference time (s)":"0.134",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.28",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.407",
        "Denoised inference time (s)":"0.156",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.126",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.237",
        "Denoised inference time (s)":"0.196",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"10.637",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.457",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.609",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.554",
        "Denoised inference time (s)":"0.373",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.044",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.31",
        "Denoised inference time (s)":"0.169",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.424",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.262",
        "Denoised inference time (s)":"0.175",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.204",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.319",
        "Denoised inference time (s)":"0.125",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"8.713",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.434",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.931",
        "# output tokens":"10.486",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.419",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"65.931",
        "# output tokens":"10.182",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.442",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.229",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.42",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.231",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.479",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.346",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.479",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"2.251",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.625",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.604",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"72.061",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.545",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"70.904",
        "# output tokens":"0.999",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.469",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"70.904",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.631",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"70.904",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.568",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"70.904",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.578",
        "Denoised inference time (s)":"0.519",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"74.362",
        "# output tokens":"14.669",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.34",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.198",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.254",
        "Denoised inference time (s)":"-",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"73.674",
        "# output tokens":"7.427",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.045",
        "Denoised inference time (s)":"0.341",
        "# eval":"850",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"71.858",
        "# output tokens":"40",
        "# trials":"3"
    }
]