[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.634,
        "RAFT - # trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.499,
        "RAFT - # trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.59,
        "RAFT - # trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.574,
        "RAFT - # trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":5.0,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":944.157,
        "RAFT - # output tokens":3.597,
        "RAFT - # trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.644,
        "RAFT - # trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.658,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":712.248,
        "RAFT - # output tokens":3.562,
        "RAFT - # trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.56,
        "RAFT - truncated":0.002,
        "RAFT - # prompt tokens":810.769,
        "RAFT - # output tokens":2.916,
        "RAFT - # trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.56,
        "RAFT - truncated":0.002,
        "RAFT - # prompt tokens":810.769,
        "RAFT - # output tokens":2.796,
        "RAFT - # trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.56,
        "RAFT - truncated":0.002,
        "RAFT - # prompt tokens":810.769,
        "RAFT - # output tokens":3.097,
        "RAFT - # trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":5.0,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1279.572,
        "RAFT - # output tokens":2.986,
        "RAFT - # trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.567,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":779.203,
        "RAFT - # output tokens":7.127,
        "RAFT - # trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":3.913,
        "RAFT - truncated":0.09,
        "RAFT - # prompt tokens":650.012,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":3.051,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":3.02,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":2.965,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":3.239,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":2.99,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.557,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":814.446,
        "RAFT - # output tokens":3.038,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.554,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":813.265,
        "RAFT - # output tokens":3.148,
        "RAFT - # trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.554,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":813.265,
        "RAFT - # output tokens":3.15,
        "RAFT - # trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":14.276,
        "RAFT - # trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.56,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":807.97,
        "RAFT - # output tokens":13.945,
        "RAFT - # trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":2.433,
        "RAFT - truncated":0.394,
        "RAFT - # prompt tokens":420.742,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":2.433,
        "RAFT - truncated":0.394,
        "RAFT - # prompt tokens":423.537,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":3
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":9.057,
        "RAFT - # trials":3
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":18.712,
        "RAFT - # trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":29.961,
        "RAFT - # trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":29.361,
        "RAFT - # trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":0.982,
        "RAFT - # trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.78,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1153.852,
        "RAFT - # output tokens":1.0,
        "RAFT - # trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.78,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1153.852,
        "RAFT - # output tokens":1.0,
        "RAFT - # trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.78,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1153.852,
        "RAFT - # output tokens":1.0,
        "RAFT - # trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":19.468,
        "RAFT - # trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":24.4,
        "RAFT - # trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.552,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":954.111,
        "RAFT - # output tokens":15.4,
        "RAFT - # trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.789,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":328.595,
        "RAFT - # output tokens":1.0,
        "RAFT - # trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":3.023,
        "RAFT - # trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.76,
        "RAFT - # trials":3
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":3.056,
        "RAFT - # trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.867,
        "RAFT - # trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":3.511,
        "RAFT - # trials":3
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":3.125,
        "RAFT - # trials":3
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.752,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1033.465,
        "RAFT - # output tokens":3.137,
        "RAFT - # trials":3
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.752,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1033.465,
        "RAFT - # output tokens":3.057,
        "RAFT - # trials":3
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.751,
        "RAFT - # trials":3
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.774,
        "RAFT - # trials":3
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.997,
        "RAFT - # trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.818,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1002.239,
        "RAFT - # output tokens":2.982,
        "RAFT - # trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.818,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1002.239,
        "RAFT - # output tokens":2.955,
        "RAFT - # trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":30.0,
        "RAFT - # trials":1
    },
    {
        "Model":"MPT (30B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":0.975,
        "RAFT - # trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.605,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":869.691,
        "RAFT - # output tokens":1.0,
        "RAFT - # trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.6,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":877.464,
        "RAFT - # output tokens":0.975,
        "RAFT - # trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.6,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":877.464,
        "RAFT - # output tokens":0.995,
        "RAFT - # trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.6,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":877.464,
        "RAFT - # output tokens":0.973,
        "RAFT - # trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.6,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":877.464,
        "RAFT - # output tokens":0.984,
        "RAFT - # trials":1
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.563,
        "RAFT - truncated":0.07,
        "RAFT - # prompt tokens":803.318,
        "RAFT - # output tokens":4.886,
        "RAFT - # trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.556,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":812.938,
        "RAFT - # output tokens":2.967,
        "RAFT - # trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":5.0,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":1279.572,
        "RAFT - # output tokens":3.07,
        "RAFT - # trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":"-",
        "RAFT - # eval":40,
        "RAFT - # train":4.562,
        "RAFT - truncated":0.0,
        "RAFT - # prompt tokens":784.961,
        "RAFT - # output tokens":13.615,
        "RAFT - # trials":3
    }
]