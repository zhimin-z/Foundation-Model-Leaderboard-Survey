[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "EM":"0.28",
        "Denoised inference time (s)":"1.037",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"18.947",
        "# trials":"3"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "EM":"0.226",
        "Denoised inference time (s)":"0.54",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"18.943",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "EM":"0.269",
        "Denoised inference time (s)":"0.701",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"18.663",
        "# trials":"3"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "EM":"0.313",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"18.994",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "EM":"0.343",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"16.293",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "EM":"0.32",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"62.054",
        "# output tokens":"16.119",
        "# trials":"3"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "EM":"0.222",
        "Denoised inference time (s)":"-",
        "# eval":"734.667",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"61.068",
        "# output tokens":"16.577",
        "# trials":"3"
    },
    {
        "Model":"Luminous Base (13B)",
        "EM":"0.275",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"80.518",
        "# output tokens":"16.071",
        "# trials":"3"
    },
    {
        "Model":"Luminous Extended (30B)",
        "EM":"0.308",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"80.518",
        "# output tokens":"15.326",
        "# trials":"3"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "EM":"0.335",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"80.518",
        "# output tokens":"15.34",
        "# trials":"3"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "EM":"0.336",
        "Denoised inference time (s)":"1.394",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"16.654",
        "# trials":"3"
    },
    {
        "Model":"BLOOM (176B)",
        "EM":"0.221",
        "Denoised inference time (s)":"0.832",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"78.129",
        "# output tokens":"39.917",
        "# trials":"3"
    },
    {
        "Model":"T0pp (11B)",
        "EM":"0.013",
        "Denoised inference time (s)":"0.137",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"90.708",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "EM":"0.336",
        "Denoised inference time (s)":"0.979",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.567",
        "# trials":"3"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "EM":"0.286",
        "Denoised inference time (s)":"0.569",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.011",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "EM":"0.254",
        "Denoised inference time (s)":"0.394",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.923",
        "# trials":"3"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "EM":"0.141",
        "Denoised inference time (s)":"0.313",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.088",
        "# trials":"3"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "EM":"0.342",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"17.275",
        "# trials":"3"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "EM":"0.254",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.617",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "EM":"0.288",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"15.307",
        "# trials":"3"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "EM":"0.348",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"84.338",
        "# output tokens":"16.846",
        "# trials":"3"
    },
    {
        "Model":"GPT-J (6B)",
        "EM":"0.168",
        "Denoised inference time (s)":"0.094",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "EM":"0.207",
        "Denoised inference time (s)":"0.059",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"Pythia (6.9B)",
        "EM":"0.159",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.71",
        "# trials":"1"
    },
    {
        "Model":"Pythia (12B)",
        "EM":"0.175",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.212",
        "# trials":"1"
    },
    {
        "Model":"T5 (11B)",
        "EM":"0.118",
        "Denoised inference time (s)":"0.264",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"90.708",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"UL2 (20B)",
        "EM":"0.168",
        "Denoised inference time (s)":"0.238",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"94.708",
        "# output tokens":"40",
        "# trials":"3"
    },
    {
        "Model":"OPT (175B)",
        "EM":"0.22",
        "Denoised inference time (s)":"0.597",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"39.844",
        "# trials":"3"
    },
    {
        "Model":"OPT (66B)",
        "EM":"0.202",
        "Denoised inference time (s)":"0.145",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"39.838",
        "# trials":"3"
    },
    {
        "Model":"LLaMA (7B)",
        "EM":"0.184",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.806",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (13B)",
        "EM":"0.233",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.762",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (30B)",
        "EM":"0.275",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.721",
        "# trials":"1"
    },
    {
        "Model":"LLaMA (65B)",
        "EM":"0.421",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (7B)",
        "EM":"0.335",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (13B)",
        "EM":"0.365",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Llama 2 (70B)",
        "EM":"0.449",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Alpaca (7B)",
        "EM":"0.224",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.937",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "EM":"0.22",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.902",
        "# trials":"1"
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "EM":"0.268",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"97.741",
        "# output tokens":"4.765",
        "# trials":"1"
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "EM":"0.349",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"0",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"TNLG v2 (530B)",
        "EM":"0.337",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"17.836",
        "# trials":"3"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "EM":"0.236",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.298",
        "# trials":"3"
    },
    {
        "Model":"davinci (175B)",
        "EM":"0.306",
        "Denoised inference time (s)":"0.705",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.065",
        "# trials":"3"
    },
    {
        "Model":"curie (6.7B)",
        "EM":"0.236",
        "Denoised inference time (s)":"0.203",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.112",
        "# trials":"3"
    },
    {
        "Model":"babbage (1.3B)",
        "EM":"0.184",
        "Denoised inference time (s)":"0.217",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.315",
        "# trials":"3"
    },
    {
        "Model":"ada (350M)",
        "EM":"0.124",
        "Denoised inference time (s)":"0.242",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.3",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-003",
        "EM":"0.373",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"19.49",
        "# trials":"3"
    },
    {
        "Model":"text-davinci-002",
        "EM":"0.392",
        "Denoised inference time (s)":"0.615",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"16.338",
        "# trials":"3"
    },
    {
        "Model":"text-curie-001",
        "EM":"0.214",
        "Denoised inference time (s)":"0.246",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"18.325",
        "# trials":"3"
    },
    {
        "Model":"text-babbage-001",
        "EM":"0.15",
        "Denoised inference time (s)":"0.252",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"19.219",
        "# trials":"3"
    },
    {
        "Model":"text-ada-001",
        "EM":"0.119",
        "Denoised inference time (s)":"0.177",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"17.242",
        "# trials":"3"
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "EM":"0.279",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"79.057",
        "# output tokens":"27.193",
        "# trials":"1"
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "EM":"0.289",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"79.057",
        "# output tokens":"23.879",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "EM":"0.177",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.362",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "EM":"0.174",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.264",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "EM":"0.207",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.149",
        "# trials":"1"
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "EM":"0.211",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"4.018",
        "# trials":"1"
    },
    {
        "Model":"MPT (30B)",
        "EM":"0.369",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"MPT-Instruct (30B)",
        "EM":"0.328",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.942",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (7B)",
        "EM":"0.309",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "EM":"0.232",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon (40B)",
        "EM":"0.38",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.776",
        "# output tokens":"1",
        "# trials":"1"
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "EM":"0.359",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.776",
        "# output tokens":"0.999",
        "# trials":"1"
    },
    {
        "Model":"GLM (130B)",
        "EM":"0.237",
        "Denoised inference time (s)":"0.515",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"85.716",
        "# output tokens":"23.531",
        "# trials":"3"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "EM":"0.209",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"16.251",
        "# trials":"3"
    },
    {
        "Model":"Palmyra X (43B)",
        "EM":"0.338",
        "Denoised inference time (s)":"-",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"83.576",
        "# output tokens":"16.098",
        "# trials":"3"
    },
    {
        "Model":"YaLM (100B)",
        "EM":"0.049",
        "Denoised inference time (s)":"0.339",
        "# eval":"746.2",
        "# train":"5",
        "truncated":"0",
        "# prompt tokens":"80.918",
        "# output tokens":"39.875",
        "# trials":"3"
    }
]