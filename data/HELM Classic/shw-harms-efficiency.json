[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Mean win rate":"0.193",
        "Copyright (text) - Denoised inference time (s)":"43.165",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"2.786",
        "Disinformation (wedging) - Denoised inference time (s)":"6.57",
        "BBQ - Denoised inference time (s)":"0.421",
        "BOLD - Denoised inference time (s)":"1.059",
        "RealToxicityPrompts - Denoised inference time (s)":"4.399"
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Mean win rate":"0.453",
        "Copyright (text) - Denoised inference time (s)":"16.578",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"1.19",
        "Disinformation (wedging) - Denoised inference time (s)":"2.647",
        "BBQ - Denoised inference time (s)":"0.35",
        "BOLD - Denoised inference time (s)":"0.543",
        "RealToxicityPrompts - Denoised inference time (s)":"1.816"
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Mean win rate":"0.353",
        "Copyright (text) - Denoised inference time (s)":"21.785",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"1.671",
        "Disinformation (wedging) - Denoised inference time (s)":"3.388",
        "BBQ - Denoised inference time (s)":"0.383",
        "BOLD - Denoised inference time (s)":"0.684",
        "RealToxicityPrompts - Denoised inference time (s)":"2.351"
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Luminous Base (13B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Luminous Extended (30B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Mean win rate":"0.087",
        "Copyright (text) - Denoised inference time (s)":"57.497",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"3.761",
        "Disinformation (wedging) - Denoised inference time (s)":"26.043",
        "BBQ - Denoised inference time (s)":"0.601",
        "BOLD - Denoised inference time (s)":"1.525",
        "RealToxicityPrompts - Denoised inference time (s)":"6.086"
    },
    {
        "Model":"BLOOM (176B)",
        "Mean win rate":"0.427",
        "Copyright (text) - Denoised inference time (s)":"123.445",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"3.796",
        "Disinformation (wedging) - Denoised inference time (s)":"3.77",
        "BBQ - Denoised inference time (s)":"0.124",
        "BOLD - Denoised inference time (s)":"0.339",
        "RealToxicityPrompts - Denoised inference time (s)":"0.512"
    },
    {
        "Model":"T0pp (11B)",
        "Mean win rate":"0.587",
        "Copyright (text) - Denoised inference time (s)":"125.942",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"2.432",
        "Disinformation (wedging) - Denoised inference time (s)":"3.229",
        "BBQ - Denoised inference time (s)":"0.145",
        "BOLD - Denoised inference time (s)":"0.064",
        "RealToxicityPrompts - Denoised inference time (s)":"0.31"
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Mean win rate":"0.187",
        "Copyright (text) - Denoised inference time (s)":"41.309",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"2.767",
        "Disinformation (wedging) - Denoised inference time (s)":"7.736",
        "BBQ - Denoised inference time (s)":"0.494",
        "BOLD - Denoised inference time (s)":"1.077",
        "RealToxicityPrompts - Denoised inference time (s)":"4.279"
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Mean win rate":"0.36",
        "Copyright (text) - Denoised inference time (s)":"23.769",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"1.663",
        "Disinformation (wedging) - Denoised inference time (s)":"4.102",
        "BBQ - Denoised inference time (s)":"0.306",
        "BOLD - Denoised inference time (s)":"0.64",
        "RealToxicityPrompts - Denoised inference time (s)":"2.481"
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Mean win rate":"0.487",
        "Copyright (text) - Denoised inference time (s)":"12.491",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.897",
        "Disinformation (wedging) - Denoised inference time (s)":"3.038",
        "BBQ - Denoised inference time (s)":"0.276",
        "BOLD - Denoised inference time (s)":"0.416",
        "RealToxicityPrompts - Denoised inference time (s)":"1.377"
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Mean win rate":"0.627",
        "Copyright (text) - Denoised inference time (s)":"6.368",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.567",
        "Disinformation (wedging) - Denoised inference time (s)":"1.549",
        "BBQ - Denoised inference time (s)":"0.273",
        "BOLD - Denoised inference time (s)":"0.328",
        "RealToxicityPrompts - Denoised inference time (s)":"0.809"
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"GPT-J (6B)",
        "Mean win rate":"0.72",
        "Copyright (text) - Denoised inference time (s)":"56.007",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.8",
        "Disinformation (wedging) - Denoised inference time (s)":"3.164",
        "BBQ - Denoised inference time (s)":"0.069",
        "BOLD - Denoised inference time (s)":"0.119",
        "RealToxicityPrompts - Denoised inference time (s)":"0.318"
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Mean win rate":"0.627",
        "Copyright (text) - Denoised inference time (s)":"85.841",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.618",
        "Disinformation (wedging) - Denoised inference time (s)":"3.574",
        "BBQ - Denoised inference time (s)":"0.226",
        "BOLD - Denoised inference time (s)":"0.067",
        "RealToxicityPrompts - Denoised inference time (s)":"0.116"
    },
    {
        "Model":"T5 (11B)",
        "Mean win rate":"0.42",
        "Copyright (text) - Denoised inference time (s)":"169.803",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"5.378",
        "Disinformation (wedging) - Denoised inference time (s)":"14.682",
        "BBQ - Denoised inference time (s)":"0.191",
        "BOLD - Denoised inference time (s)":"0.079",
        "RealToxicityPrompts - Denoised inference time (s)":"0.201"
    },
    {
        "Model":"UL2 (20B)",
        "Mean win rate":"0.573",
        "Copyright (text) - Denoised inference time (s)":"58.835",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"3.399",
        "Disinformation (wedging) - Denoised inference time (s)":"2.869",
        "BBQ - Denoised inference time (s)":"0.179",
        "BOLD - Denoised inference time (s)":"0.092",
        "RealToxicityPrompts - Denoised inference time (s)":"0.429"
    },
    {
        "Model":"OPT (175B)",
        "Mean win rate":"0.367",
        "Copyright (text) - Denoised inference time (s)":"147.973",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"3.4",
        "Disinformation (wedging) - Denoised inference time (s)":"3.357",
        "BBQ - Denoised inference time (s)":"0.285",
        "BOLD - Denoised inference time (s)":"0.339",
        "RealToxicityPrompts - Denoised inference time (s)":"0.493"
    },
    {
        "Model":"OPT (66B)",
        "Mean win rate":"0.607",
        "Copyright (text) - Denoised inference time (s)":"103.365",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.805",
        "Disinformation (wedging) - Denoised inference time (s)":"11.231",
        "BBQ - Denoised inference time (s)":"0.043",
        "BOLD - Denoised inference time (s)":"0.163",
        "RealToxicityPrompts - Denoised inference time (s)":"0.319"
    },
    {
        "Model":"TNLG v2 (530B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"davinci (175B)",
        "Mean win rate":"0.313",
        "Copyright (text) - Denoised inference time (s)":"30.57",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"2.279",
        "Disinformation (wedging) - Denoised inference time (s)":"6.191",
        "BBQ - Denoised inference time (s)":"0.22",
        "BOLD - Denoised inference time (s)":"0.723",
        "RealToxicityPrompts - Denoised inference time (s)":"3.131"
    },
    {
        "Model":"curie (6.7B)",
        "Mean win rate":"0.747",
        "Copyright (text) - Denoised inference time (s)":"7.238",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.572",
        "Disinformation (wedging) - Denoised inference time (s)":"1.677",
        "BBQ - Denoised inference time (s)":"0.092",
        "BOLD - Denoised inference time (s)":"0.199",
        "RealToxicityPrompts - Denoised inference time (s)":"0.768"
    },
    {
        "Model":"babbage (1.3B)",
        "Mean win rate":"0.8",
        "Copyright (text) - Denoised inference time (s)":"6.241",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.536",
        "Disinformation (wedging) - Denoised inference time (s)":"1.408",
        "BBQ - Denoised inference time (s)":"0.12",
        "BOLD - Denoised inference time (s)":"0.216",
        "RealToxicityPrompts - Denoised inference time (s)":"0.702"
    },
    {
        "Model":"ada (350M)",
        "Mean win rate":"0.68",
        "Copyright (text) - Denoised inference time (s)":"6.274",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.6",
        "Disinformation (wedging) - Denoised inference time (s)":"2.27",
        "BBQ - Denoised inference time (s)":"0.141",
        "BOLD - Denoised inference time (s)":"0.245",
        "RealToxicityPrompts - Denoised inference time (s)":"0.727"
    },
    {
        "Model":"text-davinci-003",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"text-davinci-002",
        "Mean win rate":"0.353",
        "Copyright (text) - Denoised inference time (s)":"24.315",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"2.097",
        "Disinformation (wedging) - Denoised inference time (s)":"6.253",
        "BBQ - Denoised inference time (s)":"0.213",
        "BOLD - Denoised inference time (s)":"0.674",
        "RealToxicityPrompts - Denoised inference time (s)":"2.995"
    },
    {
        "Model":"text-curie-001",
        "Mean win rate":"0.733",
        "Copyright (text) - Denoised inference time (s)":"2.391",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.559",
        "Disinformation (wedging) - Denoised inference time (s)":"1.558",
        "BBQ - Denoised inference time (s)":"0.131",
        "BOLD - Denoised inference time (s)":"0.248",
        "RealToxicityPrompts - Denoised inference time (s)":"0.791"
    },
    {
        "Model":"text-babbage-001",
        "Mean win rate":"0.727",
        "Copyright (text) - Denoised inference time (s)":"2.356",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.575",
        "Disinformation (wedging) - Denoised inference time (s)":"1.389",
        "BBQ - Denoised inference time (s)":"0.132",
        "BOLD - Denoised inference time (s)":"0.248",
        "RealToxicityPrompts - Denoised inference time (s)":"0.797"
    },
    {
        "Model":"text-ada-001",
        "Mean win rate":"0.88",
        "Copyright (text) - Denoised inference time (s)":"1.414",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"0.494",
        "Disinformation (wedging) - Denoised inference time (s)":"1.394",
        "BBQ - Denoised inference time (s)":"0.088",
        "BOLD - Denoised inference time (s)":"0.187",
        "RealToxicityPrompts - Denoised inference time (s)":"0.658"
    },
    {
        "Model":"code-davinci-002",
        "Mean win rate":"0",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"25.355",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Mean win rate":"1",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"8.198",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"GLM (130B)",
        "Mean win rate":"0.16",
        "Copyright (text) - Denoised inference time (s)":"239.957",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"7.321",
        "Disinformation (wedging) - Denoised inference time (s)":"12.018",
        "BBQ - Denoised inference time (s)":"0.482",
        "BOLD - Denoised inference time (s)":"0.677",
        "RealToxicityPrompts - Denoised inference time (s)":"0.668"
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"Palmyra X (43B)",
        "Mean win rate":"-",
        "Copyright (text) - Denoised inference time (s)":"-",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"-",
        "Disinformation (wedging) - Denoised inference time (s)":"-",
        "BBQ - Denoised inference time (s)":"-",
        "BOLD - Denoised inference time (s)":"-",
        "RealToxicityPrompts - Denoised inference time (s)":"-"
    },
    {
        "Model":"YaLM (100B)",
        "Mean win rate":"0.533",
        "Copyright (text) - Denoised inference time (s)":"103.907",
        "Copyright (code) - Denoised inference time (s)":"-",
        "Disinformation (reiteration) - Denoised inference time (s)":"4.501",
        "Disinformation (wedging) - Denoised inference time (s)":"2.182",
        "BBQ - Denoised inference time (s)":"0.093",
        "BOLD - Denoised inference time (s)":"0.24",
        "RealToxicityPrompts - Denoised inference time (s)":"0.553"
    }
]