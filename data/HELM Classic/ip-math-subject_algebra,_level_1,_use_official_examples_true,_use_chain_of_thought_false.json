[
    {
        "Model":"J1-Jumbo v1 (178B)",
        "Equivalent":0.062,
        "Denoised inference time (s)":"0.537",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":3.59,
        "# trials":3
    },
    {
        "Model":"J1-Large v1 (7.5B)",
        "Equivalent":0.02,
        "Denoised inference time (s)":"0.405",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":4.146,
        "# trials":3
    },
    {
        "Model":"J1-Grande v1 (17B)",
        "Equivalent":0.054,
        "Denoised inference time (s)":"0.463",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":4.607,
        "# trials":3
    },
    {
        "Model":"J1-Grande v2 beta (17B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":3.19,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Jumbo (178B)",
        "Equivalent":0.136,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":2.879,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Grande (17B)",
        "Equivalent":0.091,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":3.081,
        "# trials":3
    },
    {
        "Model":"Jurassic-2 Large (7.5B)",
        "Equivalent":0.059,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":327.207,
        "# output tokens":4.072,
        "# trials":3
    },
    {
        "Model":"Luminous Base (13B)",
        "Equivalent":0.057,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":389.719,
        "# output tokens":2.904,
        "# trials":3
    },
    {
        "Model":"Luminous Extended (30B)",
        "Equivalent":0.062,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":389.719,
        "# output tokens":2.412,
        "# trials":3
    },
    {
        "Model":"Luminous Supreme (70B)",
        "Equivalent":0.128,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":389.719,
        "# output tokens":2.323,
        "# trials":3
    },
    {
        "Model":"Anthropic-LM v4-s3 (52B)",
        "Equivalent":0.099,
        "Denoised inference time (s)":"0.624",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.716,
        "# trials":3
    },
    {
        "Model":"BLOOM (176B)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"0.534",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":323.822,
        "# output tokens":2.427,
        "# trials":3
    },
    {
        "Model":"T0pp (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.276",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":390.052,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20220609 (52.4B)",
        "Equivalent":0.099,
        "Denoised inference time (s)":"0.542",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":2.706,
        "# trials":3
    },
    {
        "Model":"Cohere large v20220720 (13.1B)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"0.352",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":3.499,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20220720 (6.1B)",
        "Equivalent":0.017,
        "Denoised inference time (s)":"0.309",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":4.533,
        "# trials":3
    },
    {
        "Model":"Cohere small v20220720 (410M)",
        "Equivalent":0.007,
        "Denoised inference time (s)":"0.296",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":6.059,
        "# trials":3
    },
    {
        "Model":"Cohere xlarge v20221108 (52.4B)",
        "Equivalent":0.069,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":4.299,
        "# trials":3
    },
    {
        "Model":"Cohere medium v20221108 (6.1B)",
        "Equivalent":0.017,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":4.662,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (6.1B)",
        "Equivalent":0.022,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":3.657,
        "# trials":3
    },
    {
        "Model":"Cohere Command beta (52.4B)",
        "Equivalent":0.077,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":380.333,
        "# output tokens":3.4,
        "# trials":3
    },
    {
        "Model":"GPT-J (6B)",
        "Equivalent":0.072,
        "Denoised inference time (s)":"0.218",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.23,
        "# trials":3
    },
    {
        "Model":"GPT-NeoX (20B)",
        "Equivalent":0.084,
        "Denoised inference time (s)":"0.351",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":2.449,
        "# trials":3
    },
    {
        "Model":"Pythia (6.9B)",
        "Equivalent":0.052,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":2.489,
        "# trials":1
    },
    {
        "Model":"Pythia (12B)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":1.956,
        "# trials":1
    },
    {
        "Model":"T5 (11B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.439",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":390.052,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"UL2 (20B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.341",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":394.052,
        "# output tokens":20.0,
        "# trials":3
    },
    {
        "Model":"OPT (175B)",
        "Equivalent":0.04,
        "Denoised inference time (s)":"0.783",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.212,
        "# trials":3
    },
    {
        "Model":"OPT (66B)",
        "Equivalent":0.03,
        "Denoised inference time (s)":"4.113",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.237,
        "# trials":3
    },
    {
        "Model":"LLaMA (7B)",
        "Equivalent":0.096,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":3.17,
        "# trials":1
    },
    {
        "Model":"LLaMA (13B)",
        "Equivalent":0.133,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":3.074,
        "# trials":1
    },
    {
        "Model":"LLaMA (30B)",
        "Equivalent":0.2,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":2.711,
        "# trials":1
    },
    {
        "Model":"LLaMA (65B)",
        "Equivalent":0.267,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (7B)",
        "Equivalent":0.089,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (13B)",
        "Equivalent":0.141,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Llama 2 (70B)",
        "Equivalent":0.289,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Alpaca (7B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":3.104,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (7B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":3.8,
        "# trials":1
    },
    {
        "Model":"Vicuna v1.3 (13B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":414.652,
        "# output tokens":4.215,
        "# trials":1
    },
    {
        "Model":"Mistral v0.1 (7B)",
        "Equivalent":0.17,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":0.0,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"TNLG v2 (530B)",
        "Equivalent":0.111,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.985,
        "# trials":3
    },
    {
        "Model":"TNLG v2 (6.7B)",
        "Equivalent":0.025,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.551,
        "# trials":3
    },
    {
        "Model":"davinci (175B)",
        "Equivalent":0.067,
        "Denoised inference time (s)":"0.25",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.141,
        "# trials":3
    },
    {
        "Model":"curie (6.7B)",
        "Equivalent":0.022,
        "Denoised inference time (s)":"0.102",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.563,
        "# trials":3
    },
    {
        "Model":"babbage (1.3B)",
        "Equivalent":0.015,
        "Denoised inference time (s)":"0.124",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.847,
        "# trials":3
    },
    {
        "Model":"ada (350M)",
        "Equivalent":0.044,
        "Denoised inference time (s)":"0.142",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.289,
        "# trials":3
    },
    {
        "Model":"text-davinci-003",
        "Equivalent":0.281,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.669,
        "# trials":3
    },
    {
        "Model":"text-davinci-002",
        "Equivalent":0.264,
        "Denoised inference time (s)":"0.234",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.948,
        "# trials":3
    },
    {
        "Model":"text-curie-001",
        "Equivalent":0.047,
        "Denoised inference time (s)":"0.137",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.131,
        "# trials":3
    },
    {
        "Model":"text-babbage-001",
        "Equivalent":0.03,
        "Denoised inference time (s)":"0.137",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.869,
        "# trials":3
    },
    {
        "Model":"text-ada-001",
        "Equivalent":0.02,
        "Denoised inference time (s)":"0.09",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.598,
        "# trials":3
    },
    {
        "Model":"code-davinci-002",
        "Equivalent":0.331,
        "Denoised inference time (s)":"0.198",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.733,
        "# trials":3
    },
    {
        "Model":"code-cushman-001 (12B)",
        "Equivalent":0.037,
        "Denoised inference time (s)":"0.117",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":3.477,
        "# trials":3
    },
    {
        "Model":"gpt-3.5-turbo-0301",
        "Equivalent":0.4,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":350.363,
        "# output tokens":2.148,
        "# trials":1
    },
    {
        "Model":"gpt-3.5-turbo-0613",
        "Equivalent":0.378,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":350.363,
        "# output tokens":2.193,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base-v1 (3B)",
        "Equivalent":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":1.8,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct-v1 (3B)",
        "Equivalent":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":2.237,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Base (7B)",
        "Equivalent":0.074,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":2.43,
        "# trials":1
    },
    {
        "Model":"RedPajama-INCITE-Instruct (7B)",
        "Equivalent":0.015,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":2.111,
        "# trials":1
    },
    {
        "Model":"MPT (30B)",
        "Equivalent":0.089,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"MPT-Instruct (30B)",
        "Equivalent":0.081,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":361.23,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (7B)",
        "Equivalent":0.037,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":401.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (7B)",
        "Equivalent":0.059,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":401.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon (40B)",
        "Equivalent":0.17,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":401.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"Falcon-Instruct (40B)",
        "Equivalent":0.126,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":401.163,
        "# output tokens":1.0,
        "# trials":1
    },
    {
        "Model":"GLM (130B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.666",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":379.607,
        "# output tokens":4.77,
        "# trials":3
    },
    {
        "Model":"InstructPalmyra (30B)",
        "Equivalent":0.054,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":2.457,
        "# trials":3
    },
    {
        "Model":"Palmyra X (43B)",
        "Equivalent":0.284,
        "Denoised inference time (s)":"-",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":375.556,
        "# output tokens":1.617,
        "# trials":3
    },
    {
        "Model":"YaLM (100B)",
        "Equivalent":0.0,
        "Denoised inference time (s)":"0.347",
        "# eval":135,
        "# train":8,
        "truncated":0,
        "# prompt tokens":338.304,
        "# output tokens":18.941,
        "# trials":3
    }
]