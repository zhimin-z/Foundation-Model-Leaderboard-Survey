[
    {
        "Model":"mlabonne\/NeuralBeagle14-7B",
        "Average":60.25,
        "AGIEval":46.06,
        "GPT4All":76.77,
        "TruthfulQA":70.32,
        "Bigbench":47.86,
        "Likes":99,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralBeagle14-7B"
    },
    {
        "Model":"mlabonne\/FrakenBeagle14-11B",
        "Average":60.17,
        "AGIEval":45.08,
        "GPT4All":76.08,
        "TruthfulQA":70.93,
        "Bigbench":48.58,
        "Likes":2,
        "URL":"https:\/\/huggingface.co\/mlabonne\/FrakenBeagle14-11B"
    },
    {
        "Model":"mlabonne\/DareBeagle-7B-v2",
        "Average":59.93,
        "AGIEval":45.6,
        "GPT4All":76.58,
        "TruthfulQA":69.48,
        "Bigbench":48.07,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/mlabonne\/DareBeagle-7B-v2"
    },
    {
        "Model":"shadowml\/DareBeagle-7B",
        "Average":59.91,
        "AGIEval":45.47,
        "GPT4All":76.63,
        "TruthfulQA":69.48,
        "Bigbench":48.05,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/shadowml\/DareBeagle-7B"
    },
    {
        "Model":"shadowml\/DareBeagel-2x7B",
        "Average":59.83,
        "AGIEval":45.51,
        "GPT4All":76.56,
        "TruthfulQA":69.45,
        "Bigbench":47.82,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/shadowml\/DareBeagel-2x7B"
    },
    {
        "Model":"mlabonne\/Beagle14-7B",
        "Average":59.4,
        "AGIEval":44.38,
        "GPT4All":76.53,
        "TruthfulQA":69.44,
        "Bigbench":47.25,
        "Likes":10,
        "URL":"https:\/\/huggingface.co\/mlabonne\/Beagle14-7B"
    },
    {
        "Model":"mlabonne\/NeuralDaredevil-7B",
        "Average":59.39,
        "AGIEval":45.23,
        "GPT4All":76.2,
        "TruthfulQA":67.61,
        "Bigbench":48.52,
        "Likes":18,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralDaredevil-7B"
    },
    {
        "Model":"argilla\/distilabeled-Marcoro14-7B-slerp",
        "Average":58.93,
        "AGIEval":45.38,
        "GPT4All":76.48,
        "TruthfulQA":65.68,
        "Bigbench":48.18,
        "Likes":6,
        "URL":"https:\/\/huggingface.co\/argilla\/distilabeled-Marcoro14-7B-slerp"
    },
    {
        "Model":"mlabonne\/NeuralMarcoro14-7B",
        "Average":58.4,
        "AGIEval":44.59,
        "GPT4All":76.17,
        "TruthfulQA":65.94,
        "Bigbench":46.9,
        "Likes":33,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralMarcoro14-7B"
    },
    {
        "Model":"shadowml\/Daredevil-7B",
        "Average":58.22,
        "AGIEval":44.85,
        "GPT4All":76.07,
        "TruthfulQA":64.89,
        "Bigbench":47.07,
        "Likes":1,
        "URL":"https:\/\/huggingface.co\/shadowml\/Daredevil-7B"
    },
    {
        "Model":"occultml\/CatMarcoro14-7B-slerp",
        "Average":58.06,
        "AGIEval":45.21,
        "GPT4All":75.91,
        "TruthfulQA":63.81,
        "Bigbench":47.31,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/occultml\/CatMarcoro14-7B-slerp"
    },
    {
        "Model":"mlabonne\/NeuralDarewin-7B",
        "Average":57.85,
        "AGIEval":45.6,
        "GPT4All":74.29,
        "TruthfulQA":63.15,
        "Bigbench":48.35,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralDarewin-7B"
    },
    {
        "Model":"fblgit\/una-cybertron-7b-v2-bf16",
        "Average":57.76,
        "AGIEval":43.29,
        "GPT4All":74.98,
        "TruthfulQA":65.32,
        "Bigbench":47.45,
        "Likes":113,
        "URL":"https:\/\/huggingface.co\/fblgit\/una-cybertron-7b-v2-bf16"
    },
    {
        "Model":"mlabonne\/Marcoro14-7B-slerp",
        "Average":57.67,
        "AGIEval":44.66,
        "GPT4All":76.24,
        "TruthfulQA":64.15,
        "Bigbench":45.64,
        "Likes":20,
        "URL":"https:\/\/huggingface.co\/mlabonne\/Marcoro14-7B-slerp"
    },
    {
        "Model":"Weyaxi\/OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "Average":57.27,
        "AGIEval":43.5,
        "GPT4All":74.88,
        "TruthfulQA":63.22,
        "Bigbench":47.5,
        "Likes":37,
        "URL":"https:\/\/huggingface.co\/Weyaxi\/OpenHermes-2.5-neural-chat-v3-3-Slerp"
    },
    {
        "Model":"mlabonne\/Darewin-7B",
        "Average":57.2,
        "AGIEval":45.08,
        "GPT4All":75.36,
        "TruthfulQA":60.94,
        "Bigbench":47.44,
        "Likes":1,
        "URL":"https:\/\/huggingface.co\/mlabonne\/Darewin-7B"
    },
    {
        "Model":"mlabonne\/Beyonder-4x7B-v2",
        "Average":57.13,
        "AGIEval":45.29,
        "GPT4All":75.95,
        "TruthfulQA":60.86,
        "Bigbench":46.4,
        "Likes":99,
        "URL":"https:\/\/huggingface.co\/mlabonne\/Beyonder-4x7B-v2"
    },
    {
        "Model":"OpenPipe\/mistral-ft-optimized-1218",
        "Average":56.85,
        "AGIEval":44.74,
        "GPT4All":75.6,
        "TruthfulQA":59.89,
        "Bigbench":47.17,
        "Likes":146,
        "URL":"https:\/\/huggingface.co\/OpenPipe\/mistral-ft-optimized-1218"
    },
    {
        "Model":"mistralai\/Mistral-7B-Instruct-v0.2",
        "Average":54.81,
        "AGIEval":38.5,
        "GPT4All":71.64,
        "TruthfulQA":66.82,
        "Bigbench":42.29,
        "Likes":715,
        "URL":"https:\/\/huggingface.co\/mistralai\/Mistral-7B-Instruct-v0.2"
    },
    {
        "Model":"cognitivecomputations\/dolphin-2.6-mistral-7b-dpo-laser",
        "Average":53.92,
        "AGIEval":38.32,
        "GPT4All":73.77,
        "TruthfulQA":61.03,
        "Bigbench":42.58,
        "Likes":62,
        "URL":"https:\/\/huggingface.co\/cognitivecomputations\/dolphin-2.6-mistral-7b-dpo-laser"
    },
    {
        "Model":"openchat\/openchat-3.5-0106",
        "Average":53.71,
        "AGIEval":44.17,
        "GPT4All":73.72,
        "TruthfulQA":52.53,
        "Bigbench":44.4,
        "Likes":140,
        "URL":"https:\/\/huggingface.co\/openchat\/openchat-3.5-0106"
    },
    {
        "Model":"mlabonne\/NeuralHermes-2.5-Mistral-7B-laser",
        "Average":53.62,
        "AGIEval":43.54,
        "GPT4All":73.44,
        "TruthfulQA":55.26,
        "Bigbench":42.24,
        "Likes":8,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralHermes-2.5-Mistral-7B-laser"
    },
    {
        "Model":"mlabonne\/NeuralHermes-2.5-Mistral-7B",
        "Average":53.51,
        "AGIEval":43.67,
        "GPT4All":73.24,
        "TruthfulQA":55.37,
        "Bigbench":41.76,
        "Likes":128,
        "URL":"https:\/\/huggingface.co\/mlabonne\/NeuralHermes-2.5-Mistral-7B"
    },
    {
        "Model":"openchat\/openchat-3.5-1210",
        "Average":53.14,
        "AGIEval":42.62,
        "GPT4All":72.84,
        "TruthfulQA":53.21,
        "Bigbench":43.88,
        "Likes":257,
        "URL":"https:\/\/huggingface.co\/openchat\/openchat-3.5-1210"
    },
    {
        "Model":"teknium\/OpenHermes-2.5-Mistral-7B",
        "Average":52.42,
        "AGIEval":42.75,
        "GPT4All":72.99,
        "TruthfulQA":52.99,
        "Bigbench":40.94,
        "Likes":563,
        "URL":"https:\/\/huggingface.co\/teknium\/OpenHermes-2.5-Mistral-7B"
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-alpha",
        "Average":51.72,
        "AGIEval":38.0,
        "GPT4All":72.24,
        "TruthfulQA":56.06,
        "Bigbench":40.57,
        "Likes":1027,
        "URL":"https:\/\/huggingface.co\/HuggingFaceH4\/zephyr-7b-alpha"
    },
    {
        "Model":"mlabonne\/zephusion-2x7b",
        "Average":51.66,
        "AGIEval":37.82,
        "GPT4All":72.14,
        "TruthfulQA":55.96,
        "Bigbench":40.71,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/mlabonne\/zephusion-2x7b"
    },
    {
        "Model":"Open-Orca\/Mistral-7B-OpenOrca",
        "Average":51.39,
        "AGIEval":39.24,
        "GPT4All":72.39,
        "TruthfulQA":52.27,
        "Bigbench":41.65,
        "Likes":574,
        "URL":"https:\/\/huggingface.co\/Open-Orca\/Mistral-7B-OpenOrca"
    },
    {
        "Model":"openchat\/openchat_3.5",
        "Average":51.34,
        "AGIEval":42.67,
        "GPT4All":72.92,
        "TruthfulQA":47.27,
        "Bigbench":42.51,
        "Likes":1022,
        "URL":"https:\/\/huggingface.co\/openchat\/openchat_3.5"
    },
    {
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":51.16,
        "AGIEval":42.06,
        "GPT4All":72.72,
        "TruthfulQA":47.33,
        "Bigbench":42.53,
        "Likes":433,
        "URL":"https:\/\/huggingface.co\/berkeley-nest\/Starling-LM-7B-alpha"
    },
    {
        "Model":"cognitivecomputations\/dolphin-2.2.1-mistral-7b",
        "Average":51.05,
        "AGIEval":38.64,
        "GPT4All":72.24,
        "TruthfulQA":54.09,
        "Bigbench":39.22,
        "Likes":156,
        "URL":"https:\/\/huggingface.co\/cognitivecomputations\/dolphin-2.2.1-mistral-7b"
    },
    {
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":50.99,
        "AGIEval":37.33,
        "GPT4All":71.83,
        "TruthfulQA":55.1,
        "Bigbench":39.7,
        "Likes":1212,
        "URL":"https:\/\/huggingface.co\/HuggingFaceH4\/zephyr-7b-beta"
    },
    {
        "Model":"mistralai\/Mistral-7B-Instruct-v0.1",
        "Average":49.15,
        "AGIEval":33.36,
        "GPT4All":67.87,
        "TruthfulQA":55.89,
        "Bigbench":39.48,
        "Likes":1280,
        "URL":"https:\/\/huggingface.co\/mistralai\/Mistral-7B-Instruct-v0.1"
    },
    {
        "Model":"shadowml\/phixtral-4x2_8odd",
        "Average":48.42,
        "AGIEval":34.46,
        "GPT4All":72.34,
        "TruthfulQA":49.56,
        "Bigbench":37.3,
        "Likes":1,
        "URL":"https:\/\/huggingface.co\/shadowml\/phixtral-4x2_8odd"
    },
    {
        "Model":"mlabonne\/phixtral-3x2_8",
        "Average":48.23,
        "AGIEval":33.58,
        "GPT4All":72.1,
        "TruthfulQA":49.59,
        "Bigbench":37.67,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/mlabonne\/phixtral-3x2_8"
    },
    {
        "Model":"shadowml\/phixtral-4x2_8odo",
        "Average":48.08,
        "AGIEval":33.74,
        "GPT4All":71.93,
        "TruthfulQA":48.68,
        "Bigbench":37.95,
        "Likes":0,
        "URL":"https:\/\/huggingface.co\/shadowml\/phixtral-4x2_8odo"
    },
    {
        "Model":"meetkai\/functionary-small-v2.2",
        "Average":47.99,
        "AGIEval":33.15,
        "GPT4All":70.35,
        "TruthfulQA":51.5,
        "Bigbench":36.97,
        "Likes":3,
        "URL":"https:\/\/huggingface.co\/meetkai\/functionary-small-v2.2"
    },
    {
        "Model":"rhysjones\/phi-2-orange",
        "Average":47.97,
        "AGIEval":33.37,
        "GPT4All":71.33,
        "TruthfulQA":49.87,
        "Bigbench":37.3,
        "Likes":17,
        "URL":"https:\/\/huggingface.co\/rhysjones\/phi-2-orange"
    },
    {
        "Model":"mlabonne\/phixtral-2x2_8",
        "Average":47.78,
        "AGIEval":34.1,
        "GPT4All":70.44,
        "TruthfulQA":48.78,
        "Bigbench":37.82,
        "Likes":112,
        "URL":"https:\/\/huggingface.co\/mlabonne\/phixtral-2x2_8"
    },
    {
        "Model":"mlabonne\/phixtral-4x2_8",
        "Average":47.7,
        "AGIEval":33.91,
        "GPT4All":70.44,
        "TruthfulQA":48.78,
        "Bigbench":37.68,
        "Likes":168,
        "URL":"https:\/\/huggingface.co\/mlabonne\/phixtral-4x2_8"
    },
    {
        "Model":"lxuechen\/phi-2-dpo",
        "Average":46.93,
        "AGIEval":30.39,
        "GPT4All":71.68,
        "TruthfulQA":50.75,
        "Bigbench":34.9,
        "Likes":11,
        "URL":"https:\/\/huggingface.co\/lxuechen\/phi-2-dpo"
    },
    {
        "Model":"cognitivecomputations\/dolphin-2_6-phi-2",
        "Average":46.89,
        "AGIEval":33.12,
        "GPT4All":69.85,
        "TruthfulQA":47.39,
        "Bigbench":37.2,
        "Likes":154,
        "URL":"https:\/\/huggingface.co\/cognitivecomputations\/dolphin-2_6-phi-2"
    },
    {
        "Model":"meta-math\/MetaMath-Mistral-7B",
        "Average":46.64,
        "AGIEval":33.91,
        "GPT4All":70.12,
        "TruthfulQA":44.83,
        "Bigbench":37.71,
        "Likes":56,
        "URL":"https:\/\/huggingface.co\/meta-math\/MetaMath-Mistral-7B"
    },
    {
        "Model":"marcel\/phixtral-4x2_8-gates-poc",
        "Average":46.51,
        "AGIEval":31.78,
        "GPT4All":70.22,
        "TruthfulQA":47.01,
        "Bigbench":37.02,
        "Likes":4,
        "URL":"https:\/\/huggingface.co\/marcel\/phixtral-4x2_8-gates-poc"
    },
    {
        "Model":"Yhyu13\/phi-2-sft-dpo-gpt4_en-ep1",
        "Average":46.43,
        "AGIEval":30.61,
        "GPT4All":71.13,
        "TruthfulQA":48.74,
        "Bigbench":35.23,
        "Likes":7,
        "URL":"https:\/\/huggingface.co\/Yhyu13\/phi-2-sft-dpo-gpt4_en-ep1"
    },
    {
        "Model":"deepseek-ai\/deepseek-moe-16b-chat",
        "Average":45.72,
        "AGIEval":30.42,
        "GPT4All":68.72,
        "TruthfulQA":48.73,
        "Bigbench":35.02,
        "Likes":77,
        "URL":"https:\/\/huggingface.co\/deepseek-ai\/deepseek-moe-16b-chat"
    },
    {
        "Model":"microsoft\/phi-2",
        "Average":44.61,
        "AGIEval":27.98,
        "GPT4All":70.8,
        "TruthfulQA":44.43,
        "Bigbench":35.21,
        "Likes":2500,
        "URL":"https:\/\/huggingface.co\/microsoft\/phi-2"
    },
    {
        "Model":"stabilityai\/stablelm-zephyr-3b",
        "Average":44.42,
        "AGIEval":34.04,
        "GPT4All":62.07,
        "TruthfulQA":46.46,
        "Bigbench":35.11,
        "Likes":185,
        "URL":"https:\/\/huggingface.co\/stabilityai\/stablelm-zephyr-3b"
    },
    {
        "Model":"venkycs\/phi-2-instruct",
        "Average":43.86,
        "AGIEval":25.8,
        "GPT4All":67.93,
        "TruthfulQA":44.82,
        "Bigbench":36.88,
        "Likes":28,
        "URL":"https:\/\/huggingface.co\/venkycs\/phi-2-instruct"
    }
]