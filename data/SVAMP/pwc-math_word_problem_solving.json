[
    {
        "table_id":8169,
        "row_id":105235,
        "rank":1,
        "method":"Model Selection (GPT-4)",
        "mlmodel":{

        },
        "method_short":"Model Selection ",
        "method_details":"GPT-4",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "Execution Accuracy":"93.7",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":93.7,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1214247,
            "title":"Automatic Model Selection with Large Language Models for Reasoning",
            "url":"\/paper\/automatic-model-selection-with-large-language",
            "published":"2023-05-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automatic-model-selection-with-large-language\/review\/?hl=105235"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":101536,
        "rank":2,
        "method":"PHP (GPT-4)",
        "mlmodel":{

        },
        "method_short":"PHP ",
        "method_details":"GPT-4",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-19",
        "metrics":{
            "Execution Accuracy":"91.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":91.9,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1193695,
            "title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models",
            "url":"\/paper\/progressive-hint-prompting-improves-reasoning",
            "published":"2023-04-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/progressive-hint-prompting-improves-reasoning\/review\/?hl=101536"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":104140,
        "rank":3,
        "method":"Self-Evaluation Guided Decoding (Codex, PAL, multiple reasoning chains, 7-shot gen, 5-shot eval)",
        "mlmodel":{

        },
        "method_short":"Self-Evaluation Guided Decoding ",
        "method_details":"Codex, PAL, multiple reasoning chains, 7-shot gen, 5-shot eval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"90.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":90.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":106293,
        "rank":4,
        "method":"LLaMA 2-Chat",
        "mlmodel":{

        },
        "method_short":"LLaMA 2-Chat",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-18",
        "metrics":{
            "Execution Accuracy":"69.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":69.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1248363,
            "title":"Llama 2: Open Foundation and Fine-Tuned Chat Models",
            "url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat",
            "published":"2023-07-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat\/review\/?hl=106293"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":99655,
        "rank":5,
        "method":"PaLM (zero-shot, CoT)",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"zero-shot, CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Execution Accuracy":"62.1",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":62.1,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=99655"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":99654,
        "rank":6,
        "method":"PaLM (zero-shot)",
        "mlmodel":{

        },
        "method_short":"PaLM ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Execution Accuracy":"58.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":58.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=99654"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":111643,
        "rank":7,
        "method":"ATHENA (roberta-large)",
        "mlmodel":{

        },
        "method_short":"ATHENA ",
        "method_details":"roberta-large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-02",
        "metrics":{
            "Execution Accuracy":"54.8",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":54.8,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1313161,
            "title":"ATHENA: Mathematical Reasoning with Thought Expansion",
            "url":"\/paper\/athena-mathematical-reasoning-with-thought",
            "published":"2023-11-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/athena-mathematical-reasoning-with-thought\/review\/?hl=111643"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":104315,
        "rank":8,
        "method":"MsAT-DeductReasoner",
        "mlmodel":{

        },
        "method_short":"MsAT-DeductReasoner",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-02",
        "metrics":{
            "Execution Accuracy":"48.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":48.9,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1222351,
            "title":"Learning Multi-Step Reasoning by Solving Arithmetic Tasks",
            "url":"\/paper\/learning-multi-step-reasoning-from-arithmetic",
            "published":"2023-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-multi-step-reasoning-from-arithmetic\/review\/?hl=104315"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":66174,
        "rank":9,
        "method":"Roberta-DeductReasoner",
        "mlmodel":{

        },
        "method_short":"Roberta-DeductReasoner",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-19",
        "metrics":{
            "Execution Accuracy":"47.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":47.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":980172,
            "title":"Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction",
            "url":"\/paper\/learning-to-reason-deductively-math-word",
            "published":"2022-03-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-to-reason-deductively-math-word\/review\/?hl=66174"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":111639,
        "rank":10,
        "method":"ATHENA (roberta-base)",
        "mlmodel":{

        },
        "method_short":"ATHENA ",
        "method_details":"roberta-base",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-02",
        "metrics":{
            "Execution Accuracy":"45.6",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":45.6,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1313161,
            "title":"ATHENA: Mathematical Reasoning with Thought Expansion",
            "url":"\/paper\/athena-mathematical-reasoning-with-thought",
            "published":"2023-11-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/athena-mathematical-reasoning-with-thought\/review\/?hl=111639"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":29858,
        "rank":11,
        "method":"Graph2Tree with RoBERTa",
        "mlmodel":{

        },
        "method_short":"Graph2Tree with RoBERTa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-12",
        "metrics":{
            "Execution Accuracy":"43.8",
            "Accuracy":"43.8"
        },
        "raw_metrics":{
            "Execution Accuracy":43.8,
            "Accuracy":43.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":753666,
            "title":"Are NLP Models really able to Solve Simple Math Word Problems?",
            "url":"\/paper\/are-nlp-models-really-able-to-solve-simple",
            "published":"2021-03-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/are-nlp-models-really-able-to-solve-simple\/review\/?hl=29858"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":29859,
        "rank":12,
        "method":"GTS with RoBERTa",
        "mlmodel":{

        },
        "method_short":"GTS with RoBERTa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-12",
        "metrics":{
            "Execution Accuracy":"41.0",
            "Accuracy":"41.0"
        },
        "raw_metrics":{
            "Execution Accuracy":41.0,
            "Accuracy":41.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":753666,
            "title":"Are NLP Models really able to Solve Simple Math Word Problems?",
            "url":"\/paper\/are-nlp-models-really-able-to-solve-simple",
            "published":"2021-03-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/are-nlp-models-really-able-to-solve-simple\/review\/?hl=29859"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":29860,
        "rank":13,
        "method":"LSTM Seq2Seq with RoBERTa",
        "mlmodel":{

        },
        "method_short":"LSTM Seq2Seq with RoBERTa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-12",
        "metrics":{
            "Execution Accuracy":"40.3",
            "Accuracy":"40.3"
        },
        "raw_metrics":{
            "Execution Accuracy":40.3,
            "Accuracy":40.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":753666,
            "title":"Are NLP Models really able to Solve Simple Math Word Problems?",
            "url":"\/paper\/are-nlp-models-really-able-to-solve-simple",
            "published":"2021-03-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/are-nlp-models-really-able-to-solve-simple\/review\/?hl=29860"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":29861,
        "rank":14,
        "method":"Transformer with RoBERTa",
        "mlmodel":{

        },
        "method_short":"Transformer with RoBERTa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-12",
        "metrics":{
            "Execution Accuracy":"38.9",
            "Accuracy":"38.9"
        },
        "raw_metrics":{
            "Execution Accuracy":38.9,
            "Accuracy":38.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":753666,
            "title":"Are NLP Models really able to Solve Simple Math Word Problems?",
            "url":"\/paper\/are-nlp-models-really-able-to-solve-simple",
            "published":"2021-03-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/are-nlp-models-really-able-to-solve-simple\/review\/?hl=29861"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97005,
        "rank":15,
        "method":"Toolformer",
        "mlmodel":{

        },
        "method_short":"Toolformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"29.4",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":29.4,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97007,
        "rank":16,
        "method":"GPT-3 (175B)",
        "mlmodel":{

        },
        "method_short":"GPT-3 ",
        "method_details":"175B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"10.0",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":10.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97004,
        "rank":17,
        "method":"Toolformer (disabled)",
        "mlmodel":{

        },
        "method_short":"Toolformer ",
        "method_details":"disabled",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"6.3",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":6.3,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97002,
        "rank":18,
        "method":"GPT-J",
        "mlmodel":{

        },
        "method_short":"GPT-J",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"5.2",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":5.2,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97003,
        "rank":19,
        "method":"GPT-J + CC",
        "mlmodel":{

        },
        "method_short":"GPT-J + CC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"5.0",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":5.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":8169,
        "row_id":97006,
        "rank":20,
        "method":"OPT (66B)",
        "mlmodel":{

        },
        "method_short":"OPT ",
        "method_details":"66B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Execution Accuracy":"4.9",
            "Accuracy":null
        },
        "raw_metrics":{
            "Execution Accuracy":4.9,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]