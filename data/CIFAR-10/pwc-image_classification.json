[
    {
        "table_id":120,
        "row_id":20351,
        "rank":1,
        "Model":"ViT-H\/14",
        "mlmodel":{

        },
        "method_short":"ViT-H\/14",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Percentage correct":"99.9",
            "PARAMS":"632M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.9,
            "PARAMS":632000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":229828,
            "title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
            "url":"\/paper\/an-image-is-worth-16x16-words-transformers-1",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-image-is-worth-16x16-words-transformers-1\/review\/?hl=20351"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":101349,
        "rank":2,
        "Model":"DINOv2 (ViT-g\/14, frozen model, linear eval)",
        "mlmodel":{

        },
        "method_short":"DINOv2 ",
        "method_details":"ViT-g\/14, frozen model, linear eval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-14",
        "metrics":{
            "Percentage correct":"99.5",
            "PARAMS":"1100M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.5,
            "PARAMS":1100000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191620,
            "title":"DINOv2: Learning Robust Visual Features without Supervision",
            "url":"\/paper\/dinov2-learning-robust-visual-features",
            "published":"2023-04-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":70809,
        "rank":3,
        "Model":"\u00b52Net (ViT-L\/16)",
        "mlmodel":{

        },
        "method_short":"\u00b52Net ",
        "method_details":"ViT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-25",
        "metrics":{
            "Percentage correct":"99.49",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.49,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015923,
            "title":"An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems",
            "url":"\/paper\/an-evolutionary-approach-to-dynamic",
            "published":"2022-05-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-evolutionary-approach-to-dynamic\/review\/?hl=70809"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":20352,
        "rank":4,
        "Model":"ViT-L\/16",
        "mlmodel":{

        },
        "method_short":"ViT-L\/16",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Percentage correct":"99.42",
            "PARAMS":"307M",
            "Top-1 Accuracy":"99.5",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.42,
            "PARAMS":307000000.0,
            "Top-1 Accuracy":99.5,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":229828,
            "title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
            "url":"\/paper\/an-image-is-worth-16x16-words-transformers-1",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-image-is-worth-16x16-words-transformers-1\/review\/?hl=20352"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29443,
        "rank":5,
        "Model":"CaiT-M-36 U 224",
        "mlmodel":{

        },
        "method_short":"CaiT-M-36 U 224",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-31",
        "metrics":{
            "Percentage correct":"99.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":772635,
            "title":"Going deeper with Image Transformers",
            "url":"\/paper\/going-deeper-with-image-transformers",
            "published":"2021-03-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/going-deeper-with-image-transformers\/review\/?hl=29443"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29255,
        "rank":6,
        "Model":"CvT-W24",
        "mlmodel":{

        },
        "method_short":"CvT-W24",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-29",
        "metrics":{
            "Percentage correct":"99.39",
            "PARAMS":null,
            "Top-1 Accuracy":"99.39",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.39,
            "PARAMS":null,
            "Top-1 Accuracy":99.39,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":758429,
            "title":"CvT: Introducing Convolutions to Vision Transformers",
            "url":"\/paper\/cvt-introducing-convolutions-to-vision",
            "published":"2021-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cvt-introducing-convolutions-to-vision\/review\/?hl=29255"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9479,
        "rank":7,
        "Model":"BiT-L (ResNet)",
        "mlmodel":{

        },
        "method_short":"BiT-L ",
        "method_details":"ResNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-24",
        "metrics":{
            "Percentage correct":"99.37",
            "PARAMS":null,
            "Top-1 Accuracy":"99.37",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.37,
            "PARAMS":null,
            "Top-1 Accuracy":99.37,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":178162,
            "title":"Big Transfer (BiT): General Visual Representation Learning",
            "url":"\/paper\/large-scale-learning-of-general-visual",
            "published":"2019-12-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-learning-of-general-visual\/review\/?hl=9479"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":49542,
        "rank":8,
        "Model":"ViT-B (attn fine-tune)",
        "mlmodel":{

        },
        "method_short":"ViT-B ",
        "method_details":"attn fine-tune",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-18",
        "metrics":{
            "Percentage correct":"99.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":979672,
            "title":"Three things everyone should know about Vision Transformers",
            "url":"\/paper\/three-things-everyone-should-know-about",
            "published":"2022-03-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/three-things-everyone-should-know-about\/review\/?hl=49542"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":81780,
        "rank":9,
        "Model":"Heinsen Routing + BEiT-large 16 224",
        "mlmodel":{

        },
        "method_short":"Heinsen Routing + BEiT-large 16 224",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-20",
        "metrics":{
            "Percentage correct":"99.2",
            "PARAMS":"309.5M",
            "Top-1 Accuracy":"99.2",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.2,
            "PARAMS":309500000.0,
            "Top-1 Accuracy":99.2,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1116016,
            "title":"An Algorithm for Routing Vectors in Sequences",
            "url":"\/paper\/an-algorithm-for-routing-vectors-in-sequences",
            "published":"2022-11-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-algorithm-for-routing-vectors-in-sequences\/review\/?hl=81780"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":46662,
        "rank":10,
        "Model":"ViT-B\/16 (PUGD)",
        "mlmodel":{

        },
        "method_short":"ViT-B\/16 ",
        "method_details":"PUGD",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-29",
        "metrics":{
            "Percentage correct":"99.13%",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.13,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":877399,
            "title":"Perturbated Gradients Updating within Unit Space for Deep Learning",
            "url":"\/paper\/update-in-unit-gradient",
            "published":"2021-10-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":101141,
        "rank":11,
        "Model":"Astroformer",
        "mlmodel":{

        },
        "method_short":"Astroformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-03",
        "metrics":{
            "Percentage correct":"99.12",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.12,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1189544,
            "title":"Astroformer: More Data Might not be all you need for Classification",
            "url":"\/paper\/astroformer-more-data-might-not-be-all-you",
            "published":"2023-04-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/astroformer-more-data-might-not-be-all-you\/review\/?hl=101141"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":28519,
        "rank":12,
        "Model":"CeiT-S (384 finetune resolution)",
        "mlmodel":{

        },
        "method_short":"CeiT-S ",
        "method_details":"384 finetune resolution",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-22",
        "metrics":{
            "Percentage correct":"99.1",
            "PARAMS":null,
            "Top-1 Accuracy":"99.1",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.1,
            "PARAMS":null,
            "Top-1 Accuracy":99.1,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":755729,
            "title":"Incorporating Convolution Designs into Visual Transformers",
            "url":"\/paper\/incorporating-convolution-designs-into-visual",
            "published":"2021-03-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/incorporating-convolution-designs-into-visual\/review\/?hl=28519"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37557,
        "rank":13,
        "Model":"AutoFormer-S | 384",
        "mlmodel":{

        },
        "method_short":"AutoFormer-S | 384",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-01",
        "metrics":{
            "Percentage correct":"99.1",
            "PARAMS":"23M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.1,
            "PARAMS":23000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":828740,
            "title":"AutoFormer: Searching Transformers for Visual Recognition",
            "url":"\/paper\/autoformer-searching-transformers-for-visual",
            "published":"2021-07-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/autoformer-searching-transformers-for-visual\/review\/?hl=37557"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":27421,
        "rank":14,
        "Model":"TNT-B",
        "mlmodel":{

        },
        "method_short":"TNT-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-27",
        "metrics":{
            "Percentage correct":"99.1",
            "PARAMS":"65.6M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.1,
            "PARAMS":65600000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":749686,
            "title":"Transformer in Transformer",
            "url":"\/paper\/transformer-in-transformer",
            "published":"2021-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/transformer-in-transformer\/review\/?hl=27421"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":23830,
        "rank":15,
        "Model":"DeiT-B",
        "mlmodel":{

        },
        "method_short":"DeiT-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-23",
        "metrics":{
            "Percentage correct":"99.1",
            "PARAMS":"86M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.1,
            "PARAMS":86000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":731001,
            "title":"Training data-efficient image transformers & distillation through attention",
            "url":"\/paper\/training-data-efficient-image-transformers",
            "published":"2020-12-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/training-data-efficient-image-transformers\/review\/?hl=23830"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29457,
        "rank":16,
        "Model":"EfficientNetV2-L",
        "mlmodel":{

        },
        "method_short":"EfficientNetV2-L",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-01",
        "metrics":{
            "Percentage correct":"99.1",
            "PARAMS":"121M",
            "Top-1 Accuracy":"99.1",
            "Parameters":"121M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.1,
            "PARAMS":121000000.0,
            "Top-1 Accuracy":99.1,
            "Parameters":121000000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":773495,
            "title":"EfficientNetV2: Smaller Models and Faster Training",
            "url":"\/paper\/efficientnetv2-smaller-models-and-faster",
            "published":"2021-04-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficientnetv2-smaller-models-and-faster\/review\/?hl=29457"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":5,
                "name":"EfficientNet",
                "color":"#05A300"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":21018,
        "rank":17,
        "Model":"LaNet",
        "mlmodel":{

        },
        "method_short":"LaNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-01",
        "metrics":{
            "Percentage correct":"99.03",
            "PARAMS":"44.1M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.03,
            "PARAMS":44100000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":228602,
            "title":"Sample-Efficient Neural Architecture Search by Learning Action Space for Monte Carlo Tree Search",
            "url":"\/paper\/sample-efficient-neural-architecture-search-1",
            "published":"2019-01-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":28512,
        "rank":18,
        "Model":"CeiT-S",
        "mlmodel":{

        },
        "method_short":"CeiT-S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-22",
        "metrics":{
            "Percentage correct":"99",
            "PARAMS":null,
            "Top-1 Accuracy":"99",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.0,
            "PARAMS":null,
            "Top-1 Accuracy":99.0,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":755729,
            "title":"Incorporating Convolution Designs into Visual Transformers",
            "url":"\/paper\/incorporating-convolution-designs-into-visual",
            "published":"2021-03-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/incorporating-convolution-designs-into-visual\/review\/?hl=28512"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":3082,
        "rank":19,
        "Model":"GPIPE + transfer learning",
        "mlmodel":{

        },
        "method_short":"GPIPE + transfer learning",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-11-16",
        "metrics":{
            "Percentage correct":"99",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":62516,
            "title":"GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism",
            "url":"\/paper\/gpipe-efficient-training-of-giant-neural",
            "published":"2018-11-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpipe-efficient-training-of-giant-neural\/review\/?hl=3082"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":10492,
        "rank":20,
        "Model":"TResNet-XL",
        "mlmodel":{

        },
        "method_short":"TResNet-XL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-03-30",
        "metrics":{
            "Percentage correct":"99",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":188636,
            "title":"TResNet: High Performance GPU-Dedicated Architecture",
            "url":"\/paper\/tresnet-high-performance-gpu-dedicated",
            "published":"2020-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tresnet-high-performance-gpu-dedicated\/review\/?hl=10492"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":36275,
        "rank":21,
        "Model":"GFNet-H-B",
        "mlmodel":{

        },
        "method_short":"GFNet-H-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-01",
        "metrics":{
            "Percentage correct":"99.0",
            "PARAMS":"54M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.0,
            "PARAMS":54000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":828703,
            "title":"Global Filter Networks for Image Classification",
            "url":"\/paper\/global-filter-networks-for-image",
            "published":"2021-07-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29453,
        "rank":22,
        "Model":"EfficientNetV2-M",
        "mlmodel":{

        },
        "method_short":"EfficientNetV2-M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-01",
        "metrics":{
            "Percentage correct":"99.0",
            "PARAMS":"55M",
            "Top-1 Accuracy":"99.0",
            "Parameters":"55M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":99.0,
            "PARAMS":55000000.0,
            "Top-1 Accuracy":99.0,
            "Parameters":55000000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":773495,
            "title":"EfficientNetV2: Smaller Models and Faster Training",
            "url":"\/paper\/efficientnetv2-smaller-models-and-faster",
            "published":"2021-04-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficientnetv2-smaller-models-and-faster\/review\/?hl=29453"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":5,
                "name":"EfficientNet",
                "color":"#05A300"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9483,
        "rank":23,
        "Model":"BiT-M (ResNet)",
        "mlmodel":{

        },
        "method_short":"BiT-M ",
        "method_details":"ResNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-24",
        "metrics":{
            "Percentage correct":"98.91",
            "PARAMS":null,
            "Top-1 Accuracy":"98.91",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.91,
            "PARAMS":null,
            "Top-1 Accuracy":98.91,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":178162,
            "title":"Big Transfer (BiT): General Visual Representation Learning",
            "url":"\/paper\/large-scale-learning-of-general-visual",
            "published":"2019-12-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-learning-of-general-visual\/review\/?hl=9483"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11231,
        "rank":24,
        "Model":"EfficientNet-B7",
        "mlmodel":{

        },
        "method_short":"EfficientNet-B7",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-28",
        "metrics":{
            "Percentage correct":"98.9",
            "PARAMS":"64M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.9,
            "PARAMS":64000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":117456,
            "title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
            "url":"\/paper\/efficientnet-rethinking-model-scaling-for",
            "published":"2019-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficientnet-rethinking-model-scaling-for\/review\/?hl=11231"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":5,
                "name":"EfficientNet",
                "color":"#05A300"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":22065,
        "rank":25,
        "Model":"PyramidNet-272, S=4",
        "mlmodel":{

        },
        "method_short":"PyramidNet-272, S=4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-30",
        "metrics":{
            "Percentage correct":"98.71",
            "PARAMS":"32.6M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.71,
            "PARAMS":32600000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":237979,
            "title":"Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training",
            "url":"\/paper\/splitnet-divide-and-co-training",
            "published":"2020-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34938,
        "rank":26,
        "Model":"ResMLP-24",
        "mlmodel":{

        },
        "method_short":"ResMLP-24",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-07",
        "metrics":{
            "Percentage correct":"98.7",
            "PARAMS":null,
            "Top-1 Accuracy":"98.7",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.7,
            "PARAMS":null,
            "Top-1 Accuracy":98.7,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":795412,
            "title":"ResMLP: Feedforward networks for image classification with data-efficient training",
            "url":"\/paper\/resmlp-feedforward-networks-for-image",
            "published":"2021-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/resmlp-feedforward-networks-for-image\/review\/?hl=34938"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29449,
        "rank":27,
        "Model":"EfficientNetV2-S",
        "mlmodel":{

        },
        "method_short":"EfficientNetV2-S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-01",
        "metrics":{
            "Percentage correct":"98.7",
            "PARAMS":"24M",
            "Top-1 Accuracy":"98.7",
            "Parameters":"24M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.7,
            "PARAMS":24000000.0,
            "Top-1 Accuracy":98.7,
            "Parameters":24000000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":773495,
            "title":"EfficientNetV2: Smaller Models and Faster Training",
            "url":"\/paper\/efficientnetv2-smaller-models-and-faster",
            "published":"2021-04-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficientnetv2-smaller-models-and-faster\/review\/?hl=29449"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":5,
                "name":"EfficientNet",
                "color":"#05A300"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":32002,
        "rank":28,
        "Model":"PyramidNet-272 (ASAM)",
        "mlmodel":{

        },
        "method_short":"PyramidNet-272 ",
        "method_details":"ASAM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-23",
        "metrics":{
            "Percentage correct":"98.68",
            "PARAMS":"26M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.68,
            "PARAMS":26000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":747890,
            "title":"ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks",
            "url":"\/paper\/asam-adaptive-sharpness-aware-minimization",
            "published":"2021-02-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/asam-adaptive-sharpness-aware-minimization\/review\/?hl=32002"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":10148,
        "rank":29,
        "Model":"PyramidNet + ShakeDrop + Fast AA + FMix",
        "mlmodel":{

        },
        "method_short":"PyramidNet + ShakeDrop + Fast AA + FMix",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-27",
        "metrics":{
            "Percentage correct":"98.64",
            "PARAMS":"26.21M",
            "Top-1 Accuracy":"98.64",
            "Parameters":"26.21M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.64,
            "PARAMS":26210000.0,
            "Top-1 Accuracy":98.64,
            "Parameters":26210000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":185056,
            "title":"FMix: Enhancing Mixed Sample Data Augmentation",
            "url":"\/paper\/understanding-and-enhancing-mixed-sample-data",
            "published":"2020-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/understanding-and-enhancing-mixed-sample-data\/review\/?hl=10148"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":21310,
        "rank":30,
        "Model":"PyramidNet (SAM)",
        "mlmodel":{

        },
        "method_short":"PyramidNet ",
        "method_details":"SAM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-03",
        "metrics":{
            "Percentage correct":"98.6",
            "PARAMS":null,
            "Top-1 Accuracy":"98.6",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.6,
            "PARAMS":null,
            "Top-1 Accuracy":98.6,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":225198,
            "title":"Sharpness-Aware Minimization for Efficiently Improving Generalization",
            "url":"\/paper\/sharpness-aware-minimization-for-efficiently-1",
            "published":"2020-10-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sharpness-aware-minimization-for-efficiently-1\/review\/?hl=21310"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39259,
        "rank":31,
        "Model":"ConvMLP-M",
        "mlmodel":{

        },
        "method_short":"ConvMLP-M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-09",
        "metrics":{
            "Percentage correct":"98.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":864188,
            "title":"ConvMLP: Hierarchical Convolutional MLPs for Vision",
            "url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for",
            "published":"2021-09-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for\/review\/?hl=39259"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39262,
        "rank":32,
        "Model":"ConvMLP-L",
        "mlmodel":{

        },
        "method_short":"ConvMLP-L",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-09",
        "metrics":{
            "Percentage correct":"98.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":864188,
            "title":"ConvMLP: Hierarchical Convolutional MLPs for Vision",
            "url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for",
            "published":"2021-09-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for\/review\/?hl=39262"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34323,
        "rank":33,
        "Model":"ViT-B\/16- SAM",
        "mlmodel":{

        },
        "method_short":"ViT-B\/16- SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"98.6",
            "PARAMS":"87M",
            "Top-1 Accuracy":null,
            "Parameters":"87M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.6,
            "PARAMS":87000000.0,
            "Top-1 Accuracy":null,
            "Parameters":87000000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34323"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34136,
        "rank":34,
        "Model":"DVT (T2T-ViT-24)",
        "mlmodel":{

        },
        "method_short":"DVT ",
        "method_details":"T2T-ViT-24",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-31",
        "metrics":{
            "Percentage correct":"98.53",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.53,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":808027,
            "title":"Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition",
            "url":"\/paper\/not-all-images-are-worth-16x16-words-dynamic",
            "published":"2021-05-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/not-all-images-are-worth-16x16-words-dynamic\/review\/?hl=34136"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":18984,
        "rank":35,
        "Model":"E2E-3M",
        "mlmodel":{

        },
        "method_short":"E2E-3M",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-30",
        "metrics":{
            "Percentage correct":"98.52",
            "PARAMS":"20M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.52,
            "PARAMS":20000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":211171,
            "title":"Rethinking Recurrent Neural Networks and Other Improvements for Image Classification",
            "url":"\/paper\/rethinking-recurrent-neural-networks-and",
            "published":"2020-07-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/rethinking-recurrent-neural-networks-and\/review\/?hl=18984"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":28498,
        "rank":36,
        "Model":"CeiT-T",
        "mlmodel":{

        },
        "method_short":"CeiT-T",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-22",
        "metrics":{
            "Percentage correct":"98.5",
            "PARAMS":null,
            "Top-1 Accuracy":"98.5",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.5,
            "PARAMS":null,
            "Top-1 Accuracy":98.5,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":755729,
            "title":"Incorporating Convolution Designs into Visual Transformers",
            "url":"\/paper\/incorporating-convolution-designs-into-visual",
            "published":"2021-03-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/incorporating-convolution-designs-into-visual\/review\/?hl=28498"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16571,
        "rank":37,
        "Model":"NAT-M4",
        "mlmodel":{

        },
        "method_short":"NAT-M4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-12",
        "metrics":{
            "Percentage correct":"98.4",
            "PARAMS":"6.9M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.4,
            "PARAMS":6900000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":194717,
            "title":"Neural Architecture Transfer",
            "url":"\/paper\/neural-architecture-transfer",
            "published":"2020-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-architecture-transfer\/review\/?hl=16571"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":22067,
        "rank":38,
        "Model":"WRN-40-10, S=4",
        "mlmodel":{

        },
        "method_short":"WRN-40-10, S=4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-30",
        "metrics":{
            "Percentage correct":"98.38",
            "PARAMS":"55.9M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.38,
            "PARAMS":55900000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":237979,
            "title":"Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training",
            "url":"\/paper\/splitnet-divide-and-co-training",
            "published":"2020-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":22068,
        "rank":39,
        "Model":"WRN-28-10, S=4",
        "mlmodel":{

        },
        "method_short":"WRN-28-10, S=4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-30",
        "metrics":{
            "Percentage correct":"98.32",
            "PARAMS":"36.7M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.32,
            "PARAMS":36700000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":237979,
            "title":"Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training",
            "url":"\/paper\/splitnet-divide-and-co-training",
            "published":"2020-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":55420,
        "rank":40,
        "Model":"Dynamics 2",
        "mlmodel":{

        },
        "method_short":"Dynamics 2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-20",
        "metrics":{
            "Percentage correct":"98.31",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.31,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1014194,
            "title":"PSO-Convolutional Neural Networks with Heterogeneous Learning Rate",
            "url":"\/paper\/pso-convolutional-neural-networks-with",
            "published":"2022-05-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pso-convolutional-neural-networks-with\/review\/?hl=55420"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":22066,
        "rank":41,
        "Model":"Shake-Shake 26 2x96d, S=4",
        "mlmodel":{

        },
        "method_short":"Shake-Shake 26 2x96d, S=4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-30",
        "metrics":{
            "Percentage correct":"98.31",
            "PARAMS":"26.3M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.31,
            "PARAMS":26300000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":237979,
            "title":"Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training",
            "url":"\/paper\/splitnet-divide-and-co-training",
            "published":"2020-11-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":40191,
        "rank":42,
        "Model":"ResNet50 (A1)",
        "mlmodel":{

        },
        "method_short":"ResNet50 ",
        "method_details":"A1",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-10-01",
        "metrics":{
            "Percentage correct":"98.3",
            "PARAMS":"25M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.3,
            "PARAMS":25000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":877343,
            "title":"ResNet strikes back: An improved training procedure in timm",
            "url":"\/paper\/resnet-strikes-back-an-improved-training",
            "published":"2021-10-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9314,
        "rank":43,
        "Model":"PyramidNet+ShakeDrop (Fast AA)",
        "mlmodel":{

        },
        "method_short":"PyramidNet+ShakeDrop ",
        "method_details":"Fast AA",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-01",
        "metrics":{
            "Percentage correct":"98.3",
            "PARAMS":"26.21M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.3,
            "PARAMS":26210000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":113336,
            "title":"Fast AutoAugment",
            "url":"\/paper\/fast-autoaugment",
            "published":"2019-05-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fast-autoaugment\/review\/?hl=9314"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16508,
        "rank":44,
        "Model":"NoisyDARTS-A-t",
        "mlmodel":{

        },
        "method_short":"NoisyDARTS-A-t",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Percentage correct":"98.28",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.28,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":194030,
            "title":"Noisy Differentiable Architecture Search",
            "url":"\/paper\/noisy-differentiable-architecture-search",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/noisy-differentiable-architecture-search\/review\/?hl=16508"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29482,
        "rank":45,
        "Model":"LeViT-192",
        "mlmodel":{

        },
        "method_short":"LeViT-192",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-02",
        "metrics":{
            "Percentage correct":"98.2",
            "PARAMS":null,
            "Top-1 Accuracy":"98.2",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.2,
            "PARAMS":null,
            "Top-1 Accuracy":98.2,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":774248,
            "title":"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference",
            "url":"\/paper\/levit-a-vision-transformer-in-convnet-s",
            "published":"2021-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/levit-a-vision-transformer-in-convnet-s\/review\/?hl=29482"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34321,
        "rank":46,
        "Model":"ResNet-152-SAM",
        "mlmodel":{

        },
        "method_short":"ResNet-152-SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"98.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34321"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34322,
        "rank":47,
        "Model":"ViT-S\/16- SAM",
        "mlmodel":{

        },
        "method_short":"ViT-S\/16- SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"98.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34322"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":56716,
        "rank":48,
        "Model":"Bamboo (ViT-B\/16)",
        "mlmodel":{

        },
        "method_short":"Bamboo ",
        "method_details":"ViT-B\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-15",
        "metrics":{
            "Percentage correct":"98.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":977452,
            "title":"Bamboo: Building Mega-Scale Vision Dataset Continually with Human-Machine Synergy",
            "url":"\/paper\/bamboo-building-mega-scale-vision-dataset",
            "published":"2022-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bamboo-building-mega-scale-vision-dataset\/review\/?hl=56716"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16572,
        "rank":49,
        "Model":"NAT-M3",
        "mlmodel":{

        },
        "method_short":"NAT-M3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-12",
        "metrics":{
            "Percentage correct":"98.2",
            "PARAMS":"6.2M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.2,
            "PARAMS":6200000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":194717,
            "title":"Neural Architecture Transfer",
            "url":"\/paper\/neural-architecture-transfer",
            "published":"2020-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-architecture-transfer\/review\/?hl=16572"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29473,
        "rank":50,
        "Model":"LeViT-256",
        "mlmodel":{

        },
        "method_short":"LeViT-256",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-02",
        "metrics":{
            "Percentage correct":"98.1",
            "PARAMS":null,
            "Top-1 Accuracy":"98.1",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.1,
            "PARAMS":null,
            "Top-1 Accuracy":98.1,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":774248,
            "title":"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference",
            "url":"\/paper\/levit-a-vision-transformer-in-convnet-s",
            "published":"2021-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/levit-a-vision-transformer-in-convnet-s\/review\/?hl=29473"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34937,
        "rank":51,
        "Model":"ResMLP-12",
        "mlmodel":{

        },
        "method_short":"ResMLP-12",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-07",
        "metrics":{
            "Percentage correct":"98.1",
            "PARAMS":null,
            "Top-1 Accuracy":"98.1",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.1,
            "PARAMS":null,
            "Top-1 Accuracy":98.1,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":795412,
            "title":"ResMLP: Feedforward networks for image classification with data-efficient training",
            "url":"\/paper\/resmlp-feedforward-networks-for-image",
            "published":"2021-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/resmlp-feedforward-networks-for-image\/review\/?hl=34937"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":30491,
        "rank":52,
        "Model":"PyramidNet + AA (AMP)",
        "mlmodel":{

        },
        "method_short":"PyramidNet + AA ",
        "method_details":"AMP",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-10",
        "metrics":{
            "Percentage correct":"98.02",
            "PARAMS":"27.22M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.02,
            "PARAMS":27220000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":226773,
            "title":"Regularizing Neural Networks via Adversarial Model Perturbation",
            "url":"\/paper\/regularizing-neural-networks-via-adversarial",
            "published":"2020-10-10T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":8859,
        "rank":53,
        "Model":"EnAET",
        "mlmodel":{

        },
        "method_short":"EnAET",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-21",
        "metrics":{
            "Percentage correct":"98.01",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":"98.01",
            "Parameters":"36.5M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.01,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":98.01,
            "Parameters":36500000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":173827,
            "title":"EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations",
            "url":"\/paper\/enaet-self-trained-ensemble-autoencoding",
            "published":"2019-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/enaet-self-trained-ensemble-autoencoding\/review\/?hl=8859"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29464,
        "rank":54,
        "Model":"LeViT-384",
        "mlmodel":{

        },
        "method_short":"LeViT-384",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-02",
        "metrics":{
            "Percentage correct":"98",
            "PARAMS":null,
            "Top-1 Accuracy":"98",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.0,
            "PARAMS":null,
            "Top-1 Accuracy":98.0,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":774248,
            "title":"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference",
            "url":"\/paper\/levit-a-vision-transformer-in-convnet-s",
            "published":"2021-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/levit-a-vision-transformer-in-convnet-s\/review\/?hl=29464"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39256,
        "rank":55,
        "Model":"ConvMLP-S",
        "mlmodel":{

        },
        "method_short":"ConvMLP-S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-09",
        "metrics":{
            "Percentage correct":"98",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":864188,
            "title":"ConvMLP: Hierarchical Convolutional MLPs for Vision",
            "url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for",
            "published":"2021-09-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/convmlp-hierarchical-convolutional-mlps-for\/review\/?hl=39256"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16111,
        "rank":56,
        "Model":"MUXNet-m",
        "mlmodel":{

        },
        "method_short":"MUXNet-m",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-03-31",
        "metrics":{
            "Percentage correct":"98.0",
            "PARAMS":"2.1M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.0,
            "PARAMS":2100000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":188988,
            "title":"MUXConv: Information Multiplexing in Convolutional Neural Networks",
            "url":"\/paper\/muxconv-information-multiplexing-in",
            "published":"2020-03-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/muxconv-information-multiplexing-in\/review\/?hl=16111"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":38235,
        "rank":57,
        "Model":"CCT-7\/3x1",
        "mlmodel":{

        },
        "method_short":"CCT-7\/3x1*",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-12",
        "metrics":{
            "Percentage correct":"98",
            "PARAMS":"3.76M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":98.0,
            "PARAMS":3760000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":778781,
            "title":"Escaping the Big Data Paradigm with Compact Transformers",
            "url":"\/paper\/escaping-the-big-data-paradigm-with-compact",
            "published":"2021-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/escaping-the-big-data-paradigm-with-compact\/review\/?hl=38235"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":4485,
        "rank":58,
        "Model":"Proxyless-G + c\/o",
        "mlmodel":{

        },
        "method_short":"Proxyless-G + c\/o",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-02",
        "metrics":{
            "Percentage correct":"97.92",
            "PARAMS":"5.7M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.92,
            "PARAMS":5700000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":64252,
            "title":"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware",
            "url":"\/paper\/proxylessnas-direct-neural-architecture",
            "published":"2018-12-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/proxylessnas-direct-neural-architecture\/review\/?hl=4485"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16573,
        "rank":59,
        "Model":"NAT-M2",
        "mlmodel":{

        },
        "method_short":"NAT-M2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-12",
        "metrics":{
            "Percentage correct":"97.9",
            "PARAMS":"4.6M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.9,
            "PARAMS":4600000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":194717,
            "title":"Neural Architecture Transfer",
            "url":"\/paper\/neural-architecture-transfer",
            "published":"2020-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-architecture-transfer\/review\/?hl=16573"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24595,
        "rank":60,
        "Model":"WRN-28-10+AutoDropout+RandAugment",
        "mlmodel":{

        },
        "method_short":"WRN-28-10+AutoDropout+RandAugment",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-01-05",
        "metrics":{
            "Percentage correct":"97.9",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.9,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":734166,
            "title":"AutoDropout: Learning Dropout Patterns to Regularize Deep Networks",
            "url":"\/paper\/autodropout-learning-dropout-patterns-to",
            "published":"2021-01-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/autodropout-learning-dropout-patterns-to\/review\/?hl=24595"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2733,
        "rank":61,
        "Model":"SENet + ShakeShake + Cutout",
        "mlmodel":{

        },
        "method_short":"SENet + ShakeShake + Cutout",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-09-05",
        "metrics":{
            "Percentage correct":"97.88",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.88,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":6645,
            "title":"Squeeze-and-Excitation Networks",
            "url":"\/paper\/squeeze-and-excitation-networks",
            "published":"2017-09-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/squeeze-and-excitation-networks\/review\/?hl=2733"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39443,
        "rank":62,
        "Model":"HCGNet-A3",
        "mlmodel":{

        },
        "method_short":"HCGNet-A3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-26",
        "metrics":{
            "Percentage correct":"97.86",
            "PARAMS":"11.4M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.86,
            "PARAMS":11400000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151373,
            "title":"Gated Convolutional Networks with Hybrid Connectivity for Image Classification",
            "url":"\/paper\/gated-convolutional-networks-with-hybrid",
            "published":"2019-08-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gated-convolutional-networks-with-hybrid\/review\/?hl=39443"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":70705,
        "rank":63,
        "Model":"Wide-ResNet-28-10",
        "mlmodel":{

        },
        "method_short":"Wide-ResNet-28-10",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-29",
        "metrics":{
            "Percentage correct":"97.85",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.85,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1084638,
            "title":"Automatic Data Augmentation via Invariance-Constrained Learning",
            "url":"\/paper\/automatic-data-augmentation-via-invariance",
            "published":"2022-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automatic-data-augmentation-via-invariance\/review\/?hl=70705"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":79163,
        "rank":64,
        "Model":"ResNeXt-50 (AutoMix)",
        "mlmodel":{

        },
        "method_short":"ResNeXt-50 ",
        "method_details":"AutoMix",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-24",
        "metrics":{
            "Percentage correct":"97.84",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.84,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":756879,
            "title":"AutoMix: Unveiling the Power of Mixup for Stronger Classifiers",
            "url":"\/paper\/automix-unveiling-the-power-of-mixup",
            "published":"2021-03-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automix-unveiling-the-power-of-mixup\/review\/?hl=79163"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34674,
        "rank":65,
        "Model":"ResNet-152x4-AGC (ImageNet-21K)",
        "mlmodel":{

        },
        "method_short":"ResNet-152x4-AGC ",
        "method_details":"ImageNet-21K",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-31",
        "metrics":{
            "Percentage correct":"97.82",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.82,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":809405,
            "title":"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images",
            "url":"\/paper\/effect-of-large-scale-pre-training-on-full",
            "published":"2021-05-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/effect-of-large-scale-pre-training-on-full\/review\/?hl=34674"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34325,
        "rank":66,
        "Model":"Mixer-B\/16- SAM",
        "mlmodel":{

        },
        "method_short":"Mixer-B\/16- SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"97.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34325"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":97469,
        "rank":67,
        "Model":"CCT-7\/3x1+VTM",
        "mlmodel":{

        },
        "method_short":"CCT-7\/3x1+VTM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-14",
        "metrics":{
            "Percentage correct":"97.78",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.78,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1093473,
            "title":"TokenMixup: Efficient Attention-guided Token-level Data Augmentation for Transformers",
            "url":"\/paper\/tokenmixup-efficient-attention-guided-token",
            "published":"2022-10-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tokenmixup-efficient-attention-guided-token\/review\/?hl=97469"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":28410,
        "rank":68,
        "Model":"WRN-28-10",
        "mlmodel":{

        },
        "method_short":"WRN-28-10",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-10",
        "metrics":{
            "Percentage correct":"97.73",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.73,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":752790,
            "title":"MixMo: Mixing Multiple Inputs for Multiple Outputs via Deep Subnetworks",
            "url":"\/paper\/mixmo-mixing-multiple-inputs-for-multiple",
            "published":"2021-03-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mixmo-mixing-multiple-inputs-for-multiple\/review\/?hl=28410"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39445,
        "rank":69,
        "Model":"HCGNet-A2",
        "mlmodel":{

        },
        "method_short":"HCGNet-A2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-26",
        "metrics":{
            "Percentage correct":"97.71",
            "PARAMS":"3.1M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.71,
            "PARAMS":3100000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151373,
            "title":"Gated Convolutional Networks with Hybrid Connectivity for Image Classification",
            "url":"\/paper\/gated-convolutional-networks-with-hybrid",
            "published":"2019-08-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gated-convolutional-networks-with-hybrid\/review\/?hl=39445"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":3946,
        "rank":70,
        "Model":"WRN + fixup init + mixup + cutout",
        "mlmodel":{

        },
        "method_short":"WRN + fixup init + mixup + cutout",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-27",
        "metrics":{
            "Percentage correct":"97.7",
            "PARAMS":"18M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.7,
            "PARAMS":18000000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88304,
            "title":"Fixup Initialization: Residual Learning Without Normalization",
            "url":"\/paper\/fixup-initialization-residual-learning",
            "published":"2019-01-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fixup-initialization-residual-learning\/review\/?hl=3946"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":71932,
        "rank":71,
        "Model":"TransBoost-ResNet50",
        "mlmodel":{

        },
        "method_short":"TransBoost-ResNet50",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-26",
        "metrics":{
            "Percentage correct":"97.61",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.61,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1016638,
            "title":"TransBoost: Improving the Best ImageNet Performance using Deep Transduction",
            "url":"\/paper\/transboost-improving-the-best-imagenet",
            "published":"2022-05-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/transboost-improving-the-best-imagenet\/review\/?hl=71932"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16509,
        "rank":72,
        "Model":"NoisyDARTS-a",
        "mlmodel":{

        },
        "method_short":"NoisyDARTS-a",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Percentage correct":"97.61",
            "PARAMS":"5.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.61,
            "PARAMS":5500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":194030,
            "title":"Noisy Differentiable Architecture Search",
            "url":"\/paper\/noisy-differentiable-architecture-search",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/noisy-differentiable-architecture-search\/review\/?hl=16509"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29491,
        "rank":73,
        "Model":"LeViT-128",
        "mlmodel":{

        },
        "method_short":"LeViT-128",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-02",
        "metrics":{
            "Percentage correct":"97.6",
            "PARAMS":null,
            "Top-1 Accuracy":"97.6",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.6,
            "PARAMS":null,
            "Top-1 Accuracy":97.6,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":774248,
            "title":"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference",
            "url":"\/paper\/levit-a-vision-transformer-in-convnet-s",
            "published":"2021-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/levit-a-vision-transformer-in-convnet-s\/review\/?hl=29491"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9743,
        "rank":74,
        "Model":"DenseNet-BC-190 + batchboost",
        "mlmodel":{

        },
        "method_short":"DenseNet-BC-190 + batchboost",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-01-21",
        "metrics":{
            "Percentage correct":"97.54",
            "PARAMS":"25.6M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.54,
            "PARAMS":25600000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":180227,
            "title":"batchboost: regularization for stabilizing training with resistance to underfitting & overfitting",
            "url":"\/paper\/batchboost-regularization-for-stabilizing",
            "published":"2020-01-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":29500,
        "rank":75,
        "Model":"LeViT-128S",
        "mlmodel":{

        },
        "method_short":"LeViT-128S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-02",
        "metrics":{
            "Percentage correct":"97.5",
            "PARAMS":null,
            "Top-1 Accuracy":"97.5",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.5,
            "PARAMS":null,
            "Top-1 Accuracy":97.5,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":774248,
            "title":"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference",
            "url":"\/paper\/levit-a-vision-transformer-in-convnet-s",
            "published":"2021-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/levit-a-vision-transformer-in-convnet-s\/review\/?hl=29500"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":8226,
        "rank":76,
        "Model":"Shared WRN",
        "mlmodel":{

        },
        "method_short":"Shared WRN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-02-26",
        "metrics":{
            "Percentage correct":"97.47",
            "PARAMS":"33.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.47,
            "PARAMS":33500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":106973,
            "title":"Learning Implicitly Recurrent CNNs Through Parameter Sharing",
            "url":"\/paper\/learning-implicitly-recurrent-cnns-through",
            "published":"2019-02-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-implicitly-recurrent-cnns-through\/review\/?hl=8226"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":7835,
        "rank":77,
        "Model":"Manifold Mixup WRN 28-10",
        "mlmodel":{

        },
        "method_short":"Manifold Mixup WRN 28-10",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-06-13",
        "metrics":{
            "Percentage correct":"97.45",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.45,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":456,
            "title":"Manifold Mixup: Better Representations by Interpolating Hidden States",
            "url":"\/paper\/manifold-mixup-better-representations-by",
            "published":"2018-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/manifold-mixup-better-representations-by\/review\/?hl=7835"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":30224,
        "rank":78,
        "Model":"WRN 28-14",
        "mlmodel":{

        },
        "method_short":"WRN 28-14",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-25",
        "metrics":{
            "Percentage correct":"97.45",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.45,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":210517,
            "title":"Neural networks with late-phase weights",
            "url":"\/paper\/economical-ensembles-with-hypernetworks",
            "published":"2020-07-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/economical-ensembles-with-hypernetworks\/review\/?hl=30224"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":108614,
        "rank":79,
        "Model":"SparseSwin",
        "mlmodel":{

        },
        "method_short":"SparseSwin",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-11",
        "metrics":{
            "Percentage correct":"97.43",
            "PARAMS":"17.58M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.43,
            "PARAMS":17580000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1275397,
            "title":"SparseSwin: Swin Transformer with Sparse Transformer Block",
            "url":"\/paper\/sparseswin-swin-transformer-with-sparse",
            "published":"2023-09-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sparseswin-swin-transformer-with-sparse\/review\/?hl=108614"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24912,
        "rank":80,
        "Model":"WRN-28-10 with reSGHMC",
        "mlmodel":{

        },
        "method_short":"WRN-28-10 with reSGHMC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-08-12",
        "metrics":{
            "Percentage correct":"97.42",
            "PARAMS":"36.5M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.42,
            "PARAMS":36500000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":212799,
            "title":"Non-convex Learning via Replica Exchange Stochastic Gradient MCMC",
            "url":"\/paper\/non-convex-learning-via-replica-exchange",
            "published":"2020-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/non-convex-learning-via-replica-exchange\/review\/?hl=24912"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":16574,
        "rank":81,
        "Model":"NAT-M1",
        "mlmodel":{

        },
        "method_short":"NAT-M1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-12",
        "metrics":{
            "Percentage correct":"97.4",
            "PARAMS":"4.3M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.4,
            "PARAMS":4300000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":194717,
            "title":"Neural Architecture Transfer",
            "url":"\/paper\/neural-architecture-transfer",
            "published":"2020-05-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-architecture-transfer\/review\/?hl=16574"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34320,
        "rank":82,
        "Model":"ResNet-50-SAM",
        "mlmodel":{

        },
        "method_short":"ResNet-50-SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"97.4",
            "PARAMS":"25M",
            "Top-1 Accuracy":null,
            "Parameters":"25M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.4,
            "PARAMS":25000000.0,
            "Top-1 Accuracy":null,
            "Parameters":25000000.0,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34320"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":99303,
        "rank":83,
        "Model":"kNN-CLIP",
        "mlmodel":{

        },
        "method_short":"kNN-CLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-03",
        "metrics":{
            "Percentage correct":"97.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":988322,
            "title":"Revisiting a kNN-based Image Classification System with High-capacity Storage",
            "url":"\/paper\/revisiting-a-knn-based-image-classification",
            "published":"2022-04-03T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/revisiting-a-knn-based-image-classification\/review\/?hl=99303"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":397,
                "name":"Memory-Centric",
                "color":"#2771D3"
            },
            {
                "id":231,
                "name":"CLIP Pre-trained",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":5057,
        "rank":84,
        "Model":"DenseNet-BC-190 + Mixup",
        "mlmodel":{

        },
        "method_short":"DenseNet-BC-190 + Mixup",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-10-25",
        "metrics":{
            "Percentage correct":"97.3",
            "PARAMS":"25.6M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.3,
            "PARAMS":25600000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":4927,
            "title":"mixup: Beyond Empirical Risk Minimization",
            "url":"\/paper\/mixup-beyond-empirical-risk-minimization",
            "published":"2017-10-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mixup-beyond-empirical-risk-minimization\/review\/?hl=5057"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":55719,
        "rank":85,
        "Model":"WaveMixLite-144\/7",
        "mlmodel":{

        },
        "method_short":"WaveMixLite-144\/7",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-28",
        "metrics":{
            "Percentage correct":"97.29",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.29,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1017845,
            "title":"WaveMix: A Resource-efficient Neural Network for Image Analysis",
            "url":"\/paper\/wavemix-lite-a-resource-efficient-neural",
            "published":"2022-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/wavemix-lite-a-resource-efficient-neural\/review\/?hl=55719"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":33771,
        "rank":86,
        "Model":"Transformer local-attention (NesT-B)",
        "mlmodel":{

        },
        "method_short":"Transformer local-attention ",
        "method_details":"NesT-B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-26",
        "metrics":{
            "Percentage correct":"97.2",
            "PARAMS":"90.1M",
            "Top-1 Accuracy":"97.2",
            "Parameters":"90.1M",
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.2,
            "PARAMS":90100000.0,
            "Top-1 Accuracy":97.2,
            "Parameters":90100000.0,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":805906,
            "title":"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding",
            "url":"\/paper\/aggregating-nested-transformers",
            "published":"2021-05-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/aggregating-nested-transformers\/review\/?hl=33771"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":56799,
        "rank":87,
        "Model":"PyramidNet",
        "mlmodel":{

        },
        "method_short":"PyramidNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-19",
        "metrics":{
            "Percentage correct":"97.14",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.14,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1012738,
            "title":"EXACT: How to Train Your Accuracy",
            "url":"\/paper\/exact-how-to-train-your-accuracy",
            "published":"2022-05-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exact-how-to-train-your-accuracy\/review\/?hl=56799"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":4163,
        "rank":88,
        "Model":"ShakeShake-2x64d + SWA",
        "mlmodel":{

        },
        "method_short":"ShakeShake-2x64d + SWA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-03-14",
        "metrics":{
            "Percentage correct":"97.12",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.12,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":8278,
            "title":"Averaging Weights Leads to Wider Optima and Better Generalization",
            "url":"\/paper\/averaging-weights-leads-to-wider-optima-and",
            "published":"2018-03-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/averaging-weights-leads-to-wider-optima-and\/review\/?hl=4163"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11232,
        "rank":89,
        "Model":"PyramidNet-200 + CutMix",
        "mlmodel":{

        },
        "method_short":"PyramidNet-200 + CutMix",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-13",
        "metrics":{
            "Percentage correct":"97.12",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.12,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":114316,
            "title":"CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features",
            "url":"\/paper\/cutmix-regularization-strategy-to-train",
            "published":"2019-05-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cutmix-regularization-strategy-to-train\/review\/?hl=11232"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":70704,
        "rank":90,
        "Model":"Wide-ResNet-40-2",
        "mlmodel":{

        },
        "method_short":"Wide-ResNet-40-2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-29",
        "metrics":{
            "Percentage correct":"97.05",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.05,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1084638,
            "title":"Automatic Data Augmentation via Invariance-Constrained Learning",
            "url":"\/paper\/automatic-data-augmentation-via-invariance",
            "published":"2022-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automatic-data-augmentation-via-invariance\/review\/?hl=70704"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":59664,
        "rank":91,
        "Model":"ORN",
        "mlmodel":{

        },
        "method_short":"ORN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-01-07",
        "metrics":{
            "Percentage correct":"97.02",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":97.02,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":20459,
            "title":"Oriented Response Networks",
            "url":"\/paper\/oriented-response-networks",
            "published":"2017-01-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/oriented-response-networks\/review\/?hl=59664"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24910,
        "rank":92,
        "Model":"WRN-16-8 with reSGHMC",
        "mlmodel":{

        },
        "method_short":"WRN-16-8 with reSGHMC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-08-12",
        "metrics":{
            "Percentage correct":"96.87",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.87,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":212799,
            "title":"Non-convex Learning via Replica Exchange Stochastic Gradient MCMC",
            "url":"\/paper\/non-convex-learning-via-replica-exchange",
            "published":"2020-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/non-convex-learning-via-replica-exchange\/review\/?hl=24910"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":43587,
        "rank":93,
        "Model":"ResNet_XnIDR",
        "mlmodel":{

        },
        "method_short":"ResNet_XnIDR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-21",
        "metrics":{
            "Percentage correct":"96.87",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.87,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":914375,
            "title":"XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For Convolutional Neural Networks",
            "url":"\/paper\/xnodr-and-xnidr-two-accurate-and-fast-fully",
            "published":"2021-11-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/xnodr-and-xnidr-two-accurate-and-fast-fully\/review\/?hl=43587"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":39444,
        "rank":94,
        "Model":"HCGNet-A1",
        "mlmodel":{

        },
        "method_short":"HCGNet-A1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-26",
        "metrics":{
            "Percentage correct":"96.85",
            "PARAMS":"1.1M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.85,
            "PARAMS":1100000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151373,
            "title":"Gated Convolutional Networks with Hybrid Connectivity for Image Classification",
            "url":"\/paper\/gated-convolutional-networks-with-hybrid",
            "published":"2019-08-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gated-convolutional-networks-with-hybrid\/review\/?hl=39444"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":30223,
        "rank":95,
        "Model":"WRN 28-10",
        "mlmodel":{

        },
        "method_short":"WRN 28-10",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-25",
        "metrics":{
            "Percentage correct":"96.81",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.81,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":210517,
            "title":"Neural networks with late-phase weights",
            "url":"\/paper\/economical-ensembles-with-hypernetworks",
            "published":"2020-07-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/economical-ensembles-with-hypernetworks\/review\/?hl=30223"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24592,
        "rank":96,
        "Model":"AutoDropout",
        "mlmodel":{

        },
        "method_short":"AutoDropout",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-01-05",
        "metrics":{
            "Percentage correct":"96.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":734166,
            "title":"AutoDropout: Learning Dropout Patterns to Regularize Deep Networks",
            "url":"\/paper\/autodropout-learning-dropout-patterns-to",
            "published":"2021-01-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/autodropout-learning-dropout-patterns-to\/review\/?hl=24592"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":4162,
        "rank":97,
        "Model":"WRN-28-10 + SWA",
        "mlmodel":{

        },
        "method_short":"WRN-28-10 + SWA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-03-14",
        "metrics":{
            "Percentage correct":"96.79",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.79,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":8278,
            "title":"Averaging Weights Leads to Wider Optima and Better Generalization",
            "url":"\/paper\/averaging-weights-leads-to-wider-optima-and",
            "published":"2018-03-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/averaging-weights-leads-to-wider-optima-and\/review\/?hl=4162"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":45116,
        "rank":98,
        "Model":"ConvMixer-256\/16",
        "mlmodel":{

        },
        "method_short":"ConvMixer-256\/16",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-24",
        "metrics":{
            "Percentage correct":"96.74",
            "PARAMS":"1.34M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.74,
            "PARAMS":1340000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":949389,
            "title":"Patches Are All You Need?",
            "url":"\/paper\/patches-are-all-you-need-1",
            "published":"2022-01-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/patches-are-all-you-need-1\/review\/?hl=45116"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":6200,
        "rank":99,
        "Model":"Wide ResNet+cutout",
        "mlmodel":{

        },
        "method_short":"Wide ResNet+cutout",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-16",
        "metrics":{
            "Percentage correct":"96.71",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.71,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":145964,
            "title":"Single-bit-per-weight deep convolutional neural networks without batch-normalization layers for embedded systems",
            "url":"\/paper\/single-bit-per-weight-deep-convolutional",
            "published":"2019-07-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/single-bit-per-weight-deep-convolutional\/review\/?hl=6200"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":4492,
        "rank":100,
        "Model":"Deep pyramidal residual network",
        "mlmodel":{

        },
        "method_short":"Deep pyramidal residual network",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-10-10",
        "metrics":{
            "Percentage correct":"96.69",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.69,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":17912,
            "title":"Deep Pyramidal Residual Networks",
            "url":"\/paper\/deep-pyramidal-residual-networks",
            "published":"2016-10-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-pyramidal-residual-networks\/review\/?hl=4492"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2489,
        "rank":101,
        "Model":"CoPaNet-R-164",
        "mlmodel":{

        },
        "method_short":"CoPaNet-R-164",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-09-29",
        "metrics":{
            "Percentage correct":"96.62",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.62,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":16830,
            "title":"Deep Competitive Pathway Networks",
            "url":"\/paper\/deep-competitive-pathway-networks",
            "published":"2017-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-competitive-pathway-networks\/review\/?hl=2489"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2487,
        "rank":102,
        "Model":"DenseNet (DenseNet-BC-190)",
        "mlmodel":{

        },
        "method_short":"DenseNet ",
        "method_details":"DenseNet-BC-190",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-08-25",
        "metrics":{
            "Percentage correct":"96.54",
            "PARAMS":null,
            "Top-1 Accuracy":"96.54",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.54,
            "PARAMS":null,
            "Top-1 Accuracy":96.54,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":11275,
            "title":"Densely Connected Convolutional Networks",
            "url":"\/paper\/densely-connected-convolutional-networks",
            "published":"2016-08-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/densely-connected-convolutional-networks\/review\/?hl=2487"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11233,
        "rank":103,
        "Model":"SKNet-29 (ResNeXt-29, 16\u00d732d)",
        "mlmodel":{

        },
        "method_short":"SKNet-29 ",
        "method_details":"ResNeXt-29, 16\u00d732d",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-03-15",
        "metrics":{
            "Percentage correct":"96.53",
            "PARAMS":null,
            "Top-1 Accuracy":"96.53",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.53,
            "PARAMS":null,
            "Top-1 Accuracy":96.53,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":108643,
            "title":"Selective Kernel Networks",
            "url":"\/paper\/selective-kernel-networks",
            "published":"2019-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/selective-kernel-networks\/review\/?hl=11233"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":6,
                "name":"ResNeXt",
                "color":"#86960b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":561,
        "rank":104,
        "Model":"Fractional MP",
        "mlmodel":{

        },
        "method_short":"Fractional MP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-18",
        "metrics":{
            "Percentage correct":"96.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":40756,
            "title":"Fractional Max-Pooling",
            "url":"\/paper\/fractional-max-pooling",
            "published":"2014-12-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fractional-max-pooling\/review\/?hl=561"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":33602,
        "rank":105,
        "Model":"PDO-eConv (p8, 4.6M)",
        "mlmodel":{

        },
        "method_short":"PDO-eConv ",
        "method_details":"p8, 4.6M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-20",
        "metrics":{
            "Percentage correct":"96.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":209855,
            "title":"PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions",
            "url":"\/paper\/pdo-econvs-partial-differential-operator",
            "published":"2020-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pdo-econvs-partial-differential-operator\/review\/?hl=33602"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":28154,
        "rank":106,
        "Model":"UPANets",
        "mlmodel":{

        },
        "method_short":"UPANets",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-15",
        "metrics":{
            "Percentage correct":"96.47",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.47,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":754475,
            "title":"UPANets: Learning from the Universal Pixel Attention Networks",
            "url":"\/paper\/upanets-learning-from-the-universal-pixel",
            "published":"2021-03-15T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":586,
        "rank":107,
        "Model":"NAS-RL",
        "mlmodel":{

        },
        "method_short":"NAS-RL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-11-05",
        "metrics":{
            "Percentage correct":"96.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":26264,
            "title":"Neural Architecture Search with Reinforcement Learning",
            "url":"\/paper\/neural-architecture-search-with-reinforcement",
            "published":"2016-11-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-architecture-search-with-reinforcement\/review\/?hl=586"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11234,
        "rank":108,
        "Model":"VGG11B(2x) + LocalLearning + CO",
        "mlmodel":{

        },
        "method_short":"VGG11B",
        "method_details":"2x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-20",
        "metrics":{
            "Percentage correct":"96.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":87899,
            "title":"Training Neural Networks with Local Error Signals",
            "url":"\/paper\/training-neural-networks-with-local-error",
            "published":"2019-01-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/training-neural-networks-with-local-error\/review\/?hl=11234"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":8227,
        "rank":109,
        "Model":"Residual Gates + WRN",
        "mlmodel":{

        },
        "method_short":"Residual Gates + WRN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-11-04",
        "metrics":{
            "Percentage correct":"96.35",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.35,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":27401,
            "title":"Learning Identity Mappings with Residual Gates",
            "url":"\/paper\/learning-identity-mappings-with-residual",
            "published":"2016-11-04T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/learning-identity-mappings-with-residual\/review\/?hl=8227"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":33600,
        "rank":110,
        "Model":"PDO-eConv (p8, 2.62M)",
        "mlmodel":{

        },
        "method_short":"PDO-eConv ",
        "method_details":"p8, 2.62M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-20",
        "metrics":{
            "Percentage correct":"96.32",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.32,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":209855,
            "title":"PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions",
            "url":"\/paper\/pdo-econvs-partial-differential-operator",
            "published":"2020-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pdo-econvs-partial-differential-operator\/review\/?hl=33600"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":3856,
        "rank":111,
        "Model":"SimpleNetv2",
        "mlmodel":{

        },
        "method_short":"SimpleNetv2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-02-17",
        "metrics":{
            "Percentage correct":"96.29",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.29,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10054,
            "title":"Towards Principled Design of Deep Convolutional Networks: Introducing SimpNet",
            "url":"\/paper\/towards-principled-design-of-deep",
            "published":"2018-02-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/towards-principled-design-of-deep\/review\/?hl=3856"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24908,
        "rank":112,
        "Model":"ResNet56 with reSGHMC",
        "mlmodel":{

        },
        "method_short":"ResNet56 with reSGHMC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-08-12",
        "metrics":{
            "Percentage correct":"96.12",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.12,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":212799,
            "title":"Non-convex Learning via Replica Exchange Stochastic Gradient MCMC",
            "url":"\/paper\/non-convex-learning-via-replica-exchange",
            "published":"2020-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/non-convex-learning-via-replica-exchange\/review\/?hl=24908"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34324,
        "rank":113,
        "Model":"Mixer-S\/16- SAM",
        "mlmodel":{

        },
        "method_short":"Mixer-S\/16- SAM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-03",
        "metrics":{
            "Percentage correct":"96.1",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.1,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":810994,
            "title":"When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
            "url":"\/paper\/when-vision-transformers-outperform-resnets",
            "published":"2021-06-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/when-vision-transformers-outperform-resnets\/review\/?hl=34324"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":30488,
        "rank":114,
        "Model":"PreActResNet18 (AMP)",
        "mlmodel":{

        },
        "method_short":"PreActResNet18 ",
        "method_details":"AMP",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-10",
        "metrics":{
            "Percentage correct":"96.03",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.03,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":226773,
            "title":"Regularizing Neural Networks via Adversarial Model Perturbation",
            "url":"\/paper\/regularizing-neural-networks-via-adversarial",
            "published":"2020-10-10T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":46195,
        "rank":115,
        "Model":"ConvMixer-256\/8",
        "mlmodel":{

        },
        "method_short":"ConvMixer-256\/8",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-24",
        "metrics":{
            "Percentage correct":"96.03",
            "PARAMS":"0.71M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":96.03,
            "PARAMS":710000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":949389,
            "title":"Patches Are All You Need?",
            "url":"\/paper\/patches-are-all-you-need-1",
            "published":"2022-01-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/patches-are-all-you-need-1\/review\/?hl=46195"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":60838,
        "rank":116,
        "Model":"Local Mixup Resnet18",
        "mlmodel":{

        },
        "method_short":"Local Mixup Resnet18",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-12",
        "metrics":{
            "Percentage correct":"95.97",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.97,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944473,
            "title":"Preventing Manifold Intrusion with Locality: Local Mixup",
            "url":"\/paper\/preventing-manifold-intrusion-with-locality",
            "published":"2022-01-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/preventing-manifold-intrusion-with-locality\/review\/?hl=60838"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":34673,
        "rank":117,
        "Model":"ResNet-50x1-ACG (ImageNet-21K)",
        "mlmodel":{

        },
        "method_short":"ResNet-50x1-ACG ",
        "method_details":"ImageNet-21K",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-31",
        "metrics":{
            "Percentage correct":"95.78",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.78,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":809405,
            "title":"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images",
            "url":"\/paper\/effect-of-large-scale-pre-training-on-full",
            "published":"2021-05-31T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/effect-of-large-scale-pre-training-on-full\/review\/?hl=34673"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":559,
        "rank":118,
        "Model":"ACN",
        "mlmodel":{

        },
        "method_short":"ACN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-21",
        "metrics":{
            "Percentage correct":"95.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":41269,
            "title":"Striving for Simplicity: The All Convolutional Net",
            "url":"\/paper\/striving-for-simplicity-the-all-convolutional",
            "published":"2014-12-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/striving-for-simplicity-the-all-convolutional\/review\/?hl=559"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":587,
        "rank":119,
        "Model":"Evolution ensemble",
        "mlmodel":{

        },
        "method_short":"Evolution ensemble",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-03-03",
        "metrics":{
            "Percentage correct":"95.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":21751,
            "title":"Large-Scale Evolution of Image Classifiers",
            "url":"\/paper\/large-scale-evolution-of-image-classifiers",
            "published":"2017-03-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-evolution-of-image-classifiers\/review\/?hl=587"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":58167,
        "rank":120,
        "Model":"ResNet-18",
        "mlmodel":{

        },
        "method_short":"ResNet-18",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-19",
        "metrics":{
            "Percentage correct":"95.55",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.55,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1033419,
            "title":"Benchopt: Reproducible, efficient and collaborative optimization benchmarks",
            "url":"\/paper\/benchopt-reproducible-efficient-and",
            "published":"2022-06-27T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":93,
                "name":"ResNet-18",
                "color":"#2771D3"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":3855,
        "rank":121,
        "Model":"SimpleNetv1",
        "mlmodel":{

        },
        "method_short":"SimpleNetv1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-08-22",
        "metrics":{
            "Percentage correct":"95.51",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.51,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":10271,
            "title":"Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures",
            "url":"\/paper\/lets-keep-it-simple-using-simple",
            "published":"2016-08-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/lets-keep-it-simple-using-simple\/review\/?hl=3855"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":103898,
        "rank":122,
        "Model":"IM-Loss (ResNet-19)",
        "mlmodel":{

        },
        "method_short":"IM-Loss ",
        "method_details":"ResNet-19",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-31",
        "metrics":{
            "Percentage correct":"95.49",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"95.49"
        },
        "raw_metrics":{
            "Percentage correct":95.49,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":95.49
        },
        "uses_additional_data":false,
        "paper":{
            "id":1219293,
            "title":"IM-Loss: Information Maximization Loss for Spiking Neural Networks",
            "url":"\/paper\/im-loss-information-maximization-loss-for",
            "published":"2022-10-31T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":446,
                "name":"SNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":584,
        "rank":123,
        "Model":"ResNet-1001",
        "mlmodel":{

        },
        "method_short":"ResNet-1001",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-03-16",
        "metrics":{
            "Percentage correct":"95.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":31943,
            "title":"Identity Mappings in Deep Residual Networks",
            "url":"\/paper\/identity-mappings-in-deep-residual-networks",
            "published":"2016-03-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/identity-mappings-in-deep-residual-networks\/review\/?hl=584"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24906,
        "rank":124,
        "Model":"ResNet32 with reSGHMC",
        "mlmodel":{

        },
        "method_short":"ResNet32 with reSGHMC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-08-12",
        "metrics":{
            "Percentage correct":"95.35",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.35,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":212799,
            "title":"Non-convex Learning via Replica Exchange Stochastic Gradient MCMC",
            "url":"\/paper\/non-convex-learning-via-replica-exchange",
            "published":"2020-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/non-convex-learning-via-replica-exchange\/review\/?hl=24906"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37892,
        "rank":125,
        "Model":"ResNet-18+MM+FRL",
        "mlmodel":{

        },
        "method_short":"ResNet-18+MM+FRL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-22",
        "metrics":{
            "Percentage correct":"95.33",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.33,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":236892,
            "title":"Learning Class Unique Features in Fine-Grained Visual Classification",
            "url":"\/paper\/towards-class-specific-unit",
            "published":"2020-11-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/towards-class-specific-unit\/review\/?hl=37892"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":103877,
        "rank":126,
        "Model":"PSN (Modified PLIF Net)",
        "mlmodel":{

        },
        "method_short":"PSN ",
        "method_details":"Modified PLIF Net",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Percentage correct":"95.32",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.32,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":446,
                "name":"SNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":35882,
        "rank":127,
        "Model":"CCT-6\/3x1",
        "mlmodel":{

        },
        "method_short":"CCT-6\/3x1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-12",
        "metrics":{
            "Percentage correct":"95.29",
            "PARAMS":"3.17M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.29,
            "PARAMS":3170000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":778781,
            "title":"Escaping the Big Data Paradigm with Compact Transformers",
            "url":"\/paper\/escaping-the-big-data-paradigm-with-compact",
            "published":"2021-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/escaping-the-big-data-paradigm-with-compact\/review\/?hl=35882"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":31936,
        "rank":128,
        "Model":"MomentumNet",
        "mlmodel":{

        },
        "method_short":"MomentumNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-15",
        "metrics":{
            "Percentage correct":"95.18 \u00b1 0.06",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.18,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":745817,
            "title":"Momentum Residual Neural Networks",
            "url":"\/paper\/momentum-residual-neural-networks",
            "published":"2021-02-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/momentum-residual-neural-networks\/review\/?hl=31936"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":70844,
        "rank":129,
        "Model":"Context-Aware Pipeline",
        "mlmodel":{

        },
        "method_short":"Context-Aware Pipeline",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-30",
        "metrics":{
            "Percentage correct":"95.16",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.16,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1086201,
            "title":"Context-Aware Compilation of DNN Training Pipelines across Edge and Cloud",
            "url":"\/paper\/context-aware-compilation-of-dnn-training",
            "published":"2021-12-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":5104,
        "rank":130,
        "Model":"SRM-ResNet-56",
        "mlmodel":{

        },
        "method_short":"SRM-ResNet-56",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-03-26",
        "metrics":{
            "Percentage correct":"95.05",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.05,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":109531,
            "title":"SRM : A Style-based Recalibration Module for Convolutional Neural Networks",
            "url":"\/paper\/srm-a-style-based-recalibration-module-for",
            "published":"2019-03-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/srm-a-style-based-recalibration-module-for\/review\/?hl=5104"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11235,
        "rank":131,
        "Model":"MixMatch",
        "mlmodel":{

        },
        "method_short":"MixMatch",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-06",
        "metrics":{
            "Percentage correct":"95.05",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.05,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":113866,
            "title":"MixMatch: A Holistic Approach to Semi-Supervised Learning",
            "url":"\/paper\/mixmatch-a-holistic-approach-to-semi",
            "published":"2019-05-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mixmatch-a-holistic-approach-to-semi\/review\/?hl=11235"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11236,
        "rank":132,
        "Model":"WRN-22-8 (Sparse Momentum)",
        "mlmodel":{

        },
        "method_short":"WRN-22-8 ",
        "method_details":"Sparse Momentum",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-10",
        "metrics":{
            "Percentage correct":"95.04",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.04,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":145337,
            "title":"Sparse Networks from Scratch: Faster Training without Losing Performance",
            "url":"\/paper\/sparse-networks-from-scratch-faster-training",
            "published":"2019-07-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sparse-networks-from-scratch-faster-training\/review\/?hl=11236"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":22373,
        "rank":133,
        "Model":"LP-BNN (ours) + cutout",
        "mlmodel":{

        },
        "method_short":"LP-BNN ",
        "method_details":"ours",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-04",
        "metrics":{
            "Percentage correct":"95.02",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":95.02,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":725368,
            "title":"Encoding the latent posterior of Bayesian Neural Networks for uncertainty quantification",
            "url":"\/paper\/encoding-the-latent-posterior-of-bayesian",
            "published":"2020-12-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/encoding-the-latent-posterior-of-bayesian\/review\/?hl=22373"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":65929,
        "rank":134,
        "Model":"kEffNet-B0 V2 32ch + H Flip",
        "mlmodel":{

        },
        "method_short":"kEffNet-B0 V2 32ch + H Flip",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-01",
        "metrics":{
            "Percentage correct":"94.95",
            "PARAMS":"0.95M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.95,
            "PARAMS":950000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1071979,
            "title":"An Enhanced Scheme for Reducing the Complexity of Pointwise Convolutions in CNNs for Image Classification Based on Interleaved Grouped Filters without Divisibility Constraints",
            "url":"\/paper\/an-enhanced-scheme-for-reducing-the",
            "published":"2022-09-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":27347,
        "rank":135,
        "Model":"Prodpoly",
        "mlmodel":{

        },
        "method_short":"Prodpoly",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-20",
        "metrics":{
            "Percentage correct":"94.9",
            "PARAMS":null,
            "Top-1 Accuracy":"94.9",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.9,
            "PARAMS":null,
            "Top-1 Accuracy":94.9,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":205264,
            "title":"Deep Polynomial Neural Networks",
            "url":"\/paper\/deep-polynomial-neural-networks",
            "published":"2020-06-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-polynomial-neural-networks\/review\/?hl=27347"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":50762,
        "rank":136,
        "Model":"ResNet-9",
        "mlmodel":{

        },
        "method_short":"ResNet-9",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-10-16",
        "metrics":{
            "Percentage correct":"94.79",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.79,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":985382,
            "title":"CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters",
            "url":"\/paper\/cnn-filter-db-an-empirical-investigation-of",
            "published":"2022-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/cnn-filter-db-an-empirical-investigation-of\/review\/?hl=50762"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2482,
        "rank":137,
        "Model":"Stochastic Depth",
        "mlmodel":{

        },
        "method_short":"Stochastic Depth",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-03-30",
        "metrics":{
            "Percentage correct":"94.77",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.77,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":31816,
            "title":"Deep Networks with Stochastic Depth",
            "url":"\/paper\/deep-networks-with-stochastic-depth",
            "published":"2016-03-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-networks-with-stochastic-depth\/review\/?hl=2482"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":26708,
        "rank":138,
        "Model":"VGG-19 with GradInit",
        "mlmodel":{

        },
        "method_short":"VGG-19 with GradInit",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-16",
        "metrics":{
            "Percentage correct":"94.71",
            "PARAMS":"20.03M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.71,
            "PARAMS":20030000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":745741,
            "title":"GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training",
            "url":"\/paper\/gradinit-learning-to-initialize-neural",
            "published":"2021-02-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":24904,
        "rank":139,
        "Model":"ResNet20 with reSGHMC",
        "mlmodel":{

        },
        "method_short":"ResNet20 with reSGHMC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-08-12",
        "metrics":{
            "Percentage correct":"94.62",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.62,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":212799,
            "title":"Non-convex Learning via Replica Exchange Stochastic Gradient MCMC",
            "url":"\/paper\/non-convex-learning-via-replica-exchange",
            "published":"2020-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/non-convex-learning-via-replica-exchange\/review\/?hl=24904"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":33598,
        "rank":140,
        "Model":"PDO-eConv (p6m,0.37M)",
        "mlmodel":{

        },
        "method_short":"PDO-eConv ",
        "method_details":"p6m,0.37M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-20",
        "metrics":{
            "Percentage correct":"94.62",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.62,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":209855,
            "title":"PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions",
            "url":"\/paper\/pdo-econvs-partial-differential-operator",
            "published":"2020-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pdo-econvs-partial-differential-operator\/review\/?hl=33598"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":588,
        "rank":141,
        "Model":"Evolution",
        "mlmodel":{

        },
        "method_short":"Evolution",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-03-03",
        "metrics":{
            "Percentage correct":"94.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":21751,
            "title":"Large-Scale Evolution of Image Classifiers",
            "url":"\/paper\/large-scale-evolution-of-image-classifiers",
            "published":"2017-03-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-evolution-of-image-classifiers\/review\/?hl=588"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":590,
        "rank":142,
        "Model":"RL+NT",
        "mlmodel":{

        },
        "method_short":"RL+NT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-07-16",
        "metrics":{
            "Percentage correct":"94.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":14376,
            "title":"Efficient Architecture Search by Network Transformation",
            "url":"\/paper\/efficient-architecture-search-by-network",
            "published":"2017-07-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficient-architecture-search-by-network\/review\/?hl=590"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":45898,
        "rank":143,
        "Model":"Convolutional Performer for Vision (CPV)",
        "mlmodel":{

        },
        "method_short":"Convolutional Performer for Vision ",
        "method_details":"CPV",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-25",
        "metrics":{
            "Percentage correct":"94.46",
            "PARAMS":"1.3M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.46,
            "PARAMS":1300000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":950540,
            "title":"Convolutional Xformers for Vision",
            "url":"\/paper\/convolutional-xformers-for-vision",
            "published":"2022-01-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/convolutional-xformers-for-vision\/review\/?hl=45898"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":177,
                "name":"Xformer",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":585,
        "rank":144,
        "Model":"ResNet+ELU",
        "mlmodel":{

        },
        "method_short":"ResNet+ELU",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-04-14",
        "metrics":{
            "Percentage correct":"94.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":29973,
            "title":"Deep Residual Networks with Exponential Linear Unit",
            "url":"\/paper\/deep-residual-networks-with-exponential",
            "published":"2016-04-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-residual-networks-with-exponential\/review\/?hl=585"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":589,
        "rank":145,
        "Model":"Deep Complex",
        "mlmodel":{

        },
        "method_short":"Deep Complex",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-05-27",
        "metrics":{
            "Percentage correct":"94.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":9457,
            "title":"Deep Complex Networks",
            "url":"\/paper\/deep-complex-networks",
            "published":"2017-05-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-complex-networks\/review\/?hl=589"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":33596,
        "rank":146,
        "Model":"PDO-eConv (p6,0.36M)",
        "mlmodel":{

        },
        "method_short":"PDO-eConv ",
        "method_details":"p6,0.36M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-20",
        "metrics":{
            "Percentage correct":"94.35",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.35,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":209855,
            "title":"PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions",
            "url":"\/paper\/pdo-econvs-partial-differential-operator",
            "published":"2020-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pdo-econvs-partial-differential-operator\/review\/?hl=33596"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9357,
        "rank":147,
        "Model":"Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods",
        "mlmodel":{

        },
        "method_short":"Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-01-24",
        "metrics":{
            "Percentage correct":"94.29",
            "PARAMS":"4.3M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.29,
            "PARAMS":4300000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":180974,
            "title":"Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods",
            "url":"\/paper\/stochastic-optimization-of-plain",
            "published":"2020-01-24T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":581,
        "rank":148,
        "Model":"Fitnet4-LSUV",
        "mlmodel":{

        },
        "method_short":"Fitnet4-LSUV",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-19",
        "metrics":{
            "Percentage correct":"94.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":35905,
            "title":"All you need is a good init",
            "url":"\/paper\/all-you-need-is-a-good-init",
            "published":"2015-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/all-you-need-is-a-good-init\/review\/?hl=581"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9595,
        "rank":149,
        "Model":"ResNet 9 + Mish",
        "mlmodel":{

        },
        "method_short":"ResNet 9 + Mish",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-23",
        "metrics":{
            "Percentage correct":"94.05",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.05,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151086,
            "title":"Mish: A Self Regularized Non-Monotonic Activation Function",
            "url":"\/paper\/mish-a-self-regularized-non-monotonic-neural",
            "published":"2019-08-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":573,
        "rank":150,
        "Model":"Tree+Max-Avg pooling",
        "mlmodel":{

        },
        "method_short":"Tree+Max-Avg pooling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-09-30",
        "metrics":{
            "Percentage correct":"94.0",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":38290,
            "title":"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",
            "url":"\/paper\/generalizing-pooling-functions-in",
            "published":"2015-09-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/generalizing-pooling-functions-in\/review\/?hl=573"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11237,
        "rank":151,
        "Model":"Standard ACNet",
        "mlmodel":{

        },
        "method_short":"Standard ACNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-07",
        "metrics":{
            "Percentage correct":"94",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":94.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":110903,
            "title":"Adaptively Connected Neural Networks",
            "url":"\/paper\/adaptively-connected-neural-networks",
            "published":"2019-04-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/adaptively-connected-neural-networks\/review\/?hl=11237"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11238,
        "rank":152,
        "Model":"SA quadratic embedding",
        "mlmodel":{

        },
        "method_short":"SA quadratic embedding",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-08",
        "metrics":{
            "Percentage correct":"93.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":170294,
            "title":"On the Relationship between Self-Attention and Convolutional Layers",
            "url":"\/paper\/on-the-relationship-between-self-attention-1",
            "published":"2019-11-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/on-the-relationship-between-self-attention-1\/review\/?hl=11238"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":53410,
        "rank":153,
        "Model":"kEffNet-B0 32ch",
        "mlmodel":{

        },
        "method_short":"kEffNet-B0 32ch",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-01",
        "metrics":{
            "Percentage correct":"93.75",
            "PARAMS":"1.06M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.75,
            "PARAMS":1060000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1000583,
            "title":"Grouped Pointwise Convolutions Reduce Parameters in Convolutional Neural Networks",
            "url":"\/paper\/grouped-pointwise-convolutions-reduce",
            "published":"2022-06-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":105306,
        "rank":154,
        "Model":"OTTT",
        "mlmodel":{

        },
        "method_short":"OTTT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-09",
        "metrics":{
            "Percentage correct":"93.73",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.73,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1089055,
            "title":"Online Training Through Time for Spiking Neural Networks",
            "url":"\/paper\/online-training-through-time-for-spiking",
            "published":"2022-10-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/online-training-through-time-for-spiking\/review\/?hl=105306"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":446,
                "name":"SNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":555,
        "rank":155,
        "Model":"SSCNN",
        "mlmodel":{

        },
        "method_short":"SSCNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-09-22",
        "metrics":{
            "Percentage correct":"93.7",
            "PARAMS":null,
            "Top-1 Accuracy":"93.7",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.7,
            "PARAMS":null,
            "Top-1 Accuracy":93.7,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":43969,
            "title":"Spatially-sparse convolutional neural networks",
            "url":"\/paper\/spatially-sparse-convolutional-neural",
            "published":"2014-09-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/spatially-sparse-convolutional-neural\/review\/?hl=555"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":31444,
        "rank":156,
        "Model":"NNCLR",
        "mlmodel":{

        },
        "method_short":"NNCLR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Percentage correct":"93.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":788988,
            "title":"With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations",
            "url":"\/paper\/with-a-little-help-from-my-friends-nearest",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/with-a-little-help-from-my-friends-nearest\/review\/?hl=31444"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":562,
        "rank":157,
        "Model":"Tuned CNN",
        "mlmodel":{

        },
        "method_short":"Tuned CNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-02-19",
        "metrics":{
            "Percentage correct":"93.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":39656,
            "title":"Scalable Bayesian Optimization Using Deep Neural Networks",
            "url":"\/paper\/scalable-bayesian-optimization-using-deep",
            "published":"2015-02-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scalable-bayesian-optimization-using-deep\/review\/?hl=562"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":582,
        "rank":158,
        "Model":"Exponential Linear Units",
        "mlmodel":{

        },
        "method_short":"Exponential Linear Units",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-23",
        "metrics":{
            "Percentage correct":"93.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":35865,
            "title":"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)",
            "url":"\/paper\/fast-and-accurate-deep-network-learning-by",
            "published":"2015-11-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/fast-and-accurate-deep-network-learning-by\/review\/?hl=582"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":575,
        "rank":159,
        "Model":"BNM NiN",
        "mlmodel":{

        },
        "method_short":"BNM NiN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-09",
        "metrics":{
            "Percentage correct":"93.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":37821,
            "title":"Batch-normalized Maxout Network in Network",
            "url":"\/paper\/batch-normalized-maxout-network-in-network",
            "published":"2015-11-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/batch-normalized-maxout-network-in-network\/review\/?hl=575"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":583,
        "rank":160,
        "Model":"Universum Prescription",
        "mlmodel":{

        },
        "method_short":"Universum Prescription",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-11",
        "metrics":{
            "Percentage correct":"93.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":28630,
            "title":"Universum Prescription: Regularization using Unlabeled Data",
            "url":"\/paper\/universum-prescription-regularization-using",
            "published":"2015-11-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/universum-prescription-regularization-using\/review\/?hl=583"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":576,
        "rank":161,
        "Model":"CMsC",
        "mlmodel":{

        },
        "method_short":"CMsC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-18",
        "metrics":{
            "Percentage correct":"93.1",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":93.1,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":37651,
            "title":"Competitive Multi-scale Convolution",
            "url":"\/paper\/competitive-multi-scale-convolution",
            "published":"2015-11-18T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/competitive-multi-scale-convolution\/review\/?hl=576"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":53394,
        "rank":162,
        "Model":"kMobileNet V3 Large 16ch",
        "mlmodel":{

        },
        "method_short":"kMobileNet V3 Large 16ch",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-01",
        "metrics":{
            "Percentage correct":"92.74",
            "PARAMS":"0.40M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.74,
            "PARAMS":400000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1000583,
            "title":"Grouped Pointwise Convolutions Reduce Parameters in Convolutional Neural Networks",
            "url":"\/paper\/grouped-pointwise-convolutions-reduce",
            "published":"2022-06-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":560,
        "rank":163,
        "Model":"NiN+APL",
        "mlmodel":{

        },
        "method_short":"NiN+APL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-21",
        "metrics":{
            "Percentage correct":"92.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":41121,
            "title":"Learning Activation Functions to Improve Deep Neural Networks",
            "url":"\/paper\/learning-activation-functions-to-improve-deep",
            "published":"2014-12-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-activation-functions-to-improve-deep\/review\/?hl=560"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":577,
        "rank":164,
        "Model":"VDN",
        "mlmodel":{

        },
        "method_short":"VDN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-07-22",
        "metrics":{
            "Percentage correct":"92.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":37493,
            "title":"Training Very Deep Networks",
            "url":"\/paper\/training-very-deep-networks",
            "published":"2015-07-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/training-very-deep-networks\/review\/?hl=577"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":38278,
        "rank":165,
        "Model":"ResNet",
        "mlmodel":{

        },
        "method_short":"ResNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-10",
        "metrics":{
            "Percentage correct":"92.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":796189,
            "title":"A Bregman Learning Framework for Sparse Neural Networks",
            "url":"\/paper\/a-bregman-learning-framework-for-sparse",
            "published":"2021-05-10T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":574,
        "rank":166,
        "Model":"SWWAE",
        "mlmodel":{

        },
        "method_short":"SWWAE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-06-08",
        "metrics":{
            "Percentage correct":"92.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":36021,
            "title":"Stacked What-Where Auto-encoders",
            "url":"\/paper\/stacked-what-where-auto-encoders",
            "published":"2015-06-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/stacked-what-where-auto-encoders\/review\/?hl=574"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":40955,
        "rank":167,
        "Model":"FlexTCN-7",
        "mlmodel":{

        },
        "method_short":"FlexTCN-7",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-10-15",
        "metrics":{
            "Percentage correct":"92.2\u00b10.1",
            "PARAMS":"0.67M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.2,
            "PARAMS":670000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":889320,
            "title":"FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes",
            "url":"\/paper\/flexconv-continuous-kernel-convolutions-with-1",
            "published":"2021-10-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/flexconv-continuous-kernel-convolutions-with-1\/review\/?hl=40955"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":30308,
        "rank":168,
        "Model":"ReActNet-18",
        "mlmodel":{

        },
        "method_short":"ReActNet-18",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-16",
        "metrics":{
            "Percentage correct":"92.08",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.08,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":783568,
            "title":"\"BNN - BN = ?\": Training Binary Neural Networks without Batch Normalization",
            "url":"\/paper\/bnn-bn-training-binary-neural-networks",
            "published":"2021-04-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bnn-bn-training-binary-neural-networks\/review\/?hl=30308"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":8259,
        "rank":169,
        "Model":"ResNet v2-20 (Mish activation)",
        "mlmodel":{

        },
        "method_short":"ResNet v2-20 ",
        "method_details":"Mish activation",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-08-23",
        "metrics":{
            "Percentage correct":"92.02",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.02,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":151086,
            "title":"Mish: A Self Regularized Non-Monotonic Activation Function",
            "url":"\/paper\/mish-a-self-regularized-non-monotonic-neural",
            "published":"2019-08-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":70840,
        "rank":170,
        "Model":"Context-Aware DNN tree",
        "mlmodel":{

        },
        "method_short":"Context-Aware DNN tree",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-29",
        "metrics":{
            "Percentage correct":"92.01",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":92.01,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1085783,
            "title":"Context-aware deep model compression for edge cloud computing",
            "url":"\/paper\/context-aware-deep-model-compression-for-edge",
            "published":"2020-11-29T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":553,
        "rank":171,
        "Model":"DSN",
        "mlmodel":{

        },
        "method_short":"DSN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-09-18",
        "metrics":{
            "Percentage correct":"91.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":43944,
            "title":"Deeply-Supervised Nets",
            "url":"\/paper\/deeply-supervised-nets",
            "published":"2014-09-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deeply-supervised-nets\/review\/?hl=553"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":578,
        "rank":172,
        "Model":"BinaryConnect",
        "mlmodel":{

        },
        "method_short":"BinaryConnect",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-02",
        "metrics":{
            "Percentage correct":"91.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":34579,
            "title":"BinaryConnect: Training Deep Neural Networks with binary weights during propagations",
            "url":"\/paper\/binaryconnect-training-deep-neural-networks",
            "published":"2015-11-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/binaryconnect-training-deep-neural-networks\/review\/?hl=578"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2075,
        "rank":173,
        "Model":"CLS-GAN",
        "mlmodel":{

        },
        "method_short":"CLS-GAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-01-23",
        "metrics":{
            "Percentage correct":"91.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":8018,
            "title":"Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities",
            "url":"\/paper\/loss-sensitive-generative-adversarial",
            "published":"2017-01-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/loss-sensitive-generative-adversarial\/review\/?hl=2075"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":572,
        "rank":174,
        "Model":"MIM",
        "mlmodel":{

        },
        "method_short":"MIM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-08-03",
        "metrics":{
            "Percentage correct":"91.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":37965,
            "title":"On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units",
            "url":"\/paper\/on-the-importance-of-normalisation-layers-in",
            "published":"2015-08-03T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/on-the-importance-of-normalisation-layers-in\/review\/?hl=572"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":579,
        "rank":175,
        "Model":"Spectral Representations for Convolutional Neural Networks",
        "mlmodel":{

        },
        "method_short":"Spectral Representations for Convolutional Neural Networks",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-06-11",
        "metrics":{
            "Percentage correct":"91.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":40186,
            "title":"Spectral Representations for Convolutional Neural Networks",
            "url":"\/paper\/spectral-representations-for-convolutional",
            "published":"2015-06-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/spectral-representations-for-convolutional\/review\/?hl=579"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":79132,
        "rank":176,
        "Model":"DLME (ResNet-18, linear)",
        "mlmodel":{

        },
        "method_short":"DLME ",
        "method_details":"ResNet-18, linear",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-07",
        "metrics":{
            "Percentage correct":"91.3",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.3,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1039508,
            "title":"DLME: Deep Local-flatness Manifold Embedding",
            "url":"\/paper\/dlme-deep-local-flatness-manifold-embedding",
            "published":"2022-07-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/dlme-deep-local-flatness-manifold-embedding\/review\/?hl=79132"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11239,
        "rank":177,
        "Model":"RMDL (30 RDLs)",
        "mlmodel":{

        },
        "method_short":"RMDL ",
        "method_details":"30 RDLs",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-05-03",
        "metrics":{
            "Percentage correct":"91.21",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.21,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1893,
            "title":"RMDL: Random Multimodel Deep Learning for Classification",
            "url":"\/paper\/rmdl-random-multimodel-deep-learning-for",
            "published":"2018-05-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/rmdl-random-multimodel-deep-learning-for\/review\/?hl=11239"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":549,
        "rank":178,
        "Model":"Network in Network",
        "mlmodel":{

        },
        "method_short":"Network in Network",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2013-12-16",
        "metrics":{
            "Percentage correct":"91.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":46271,
            "title":"Network In Network",
            "url":"\/paper\/network-in-network",
            "published":"2013-12-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/network-in-network\/review\/?hl=549"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96976,
        "rank":179,
        "Model":"ResNet-26 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-26 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"91.1",
            "PARAMS":"0.366M",
            "Top-1 Accuracy":"91.1",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":91.1,
            "PARAMS":366000.0,
            "Top-1 Accuracy":91.1,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96977,
        "rank":180,
        "Model":"ResNet-32 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-32 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"90.9",
            "PARAMS":"0.464M",
            "Top-1 Accuracy":"90.9",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.9,
            "PARAMS":464000.0,
            "Top-1 Accuracy":90.9,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":53409,
        "rank":181,
        "Model":"kDenseNet-BC L100 12ch",
        "mlmodel":{

        },
        "method_short":"kDenseNet-BC L100 12ch",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-01",
        "metrics":{
            "Percentage correct":"90.83",
            "PARAMS":"0.35M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.83,
            "PARAMS":350000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1000583,
            "title":"Grouped Pointwise Convolutions Reduce Parameters in Convolutional Neural Networks",
            "url":"\/paper\/grouped-pointwise-convolutions-reduce",
            "published":"2022-06-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":556,
        "rank":182,
        "Model":"Deep Networks with Internal Selective Attention through Feedback Connections",
        "mlmodel":{

        },
        "method_short":"Deep Networks with Internal Selective Attention through Feedback Connections",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-07-11",
        "metrics":{
            "Percentage correct":"90.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":44555,
            "title":"Deep Networks with Internal Selective Attention through Feedback Connections",
            "url":"\/paper\/deep-networks-with-internal-selective",
            "published":"2014-07-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/deep-networks-with-internal-selective\/review\/?hl=556"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":2479,
        "rank":183,
        "Model":"Maxout Network (k=2)",
        "mlmodel":{

        },
        "method_short":"Maxout Network ",
        "method_details":"k=2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2013-02-18",
        "metrics":{
            "Percentage correct":"90.65",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.65,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":48160,
            "title":"Maxout Networks",
            "url":"\/paper\/maxout-networks",
            "published":"2013-02-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/maxout-networks\/review\/?hl=2479"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":64275,
        "rank":184,
        "Model":"ResNet-18",
        "mlmodel":{

        },
        "method_short":"ResNet-18",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Percentage correct":"90.65",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.65,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":172198,
            "title":"Knowledge Representing: Efficient, Sparse Representation of Prior Knowledge for Knowledge Distillation",
            "url":"\/paper\/knowledge-representing-efficient-sparse",
            "published":"2019-11-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/knowledge-representing-efficient-sparse\/review\/?hl=64275"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":550,
        "rank":185,
        "Model":"DNN+Probabilistic Maxout",
        "mlmodel":{

        },
        "method_short":"DNN+Probabilistic Maxout",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2013-12-20",
        "metrics":{
            "Percentage correct":"90.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":46420,
            "title":"Improving Deep Neural Networks with Probabilistic Maxout Units",
            "url":"\/paper\/improving-deep-neural-networks-with",
            "published":"2013-12-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/improving-deep-neural-networks-with\/review\/?hl=550"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":541,
        "rank":186,
        "Model":"GP EI",
        "mlmodel":{

        },
        "method_short":"GP EI",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2012-06-13",
        "metrics":{
            "Percentage correct":"90.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":50282,
            "title":"Practical Bayesian Optimization of Machine Learning Algorithms",
            "url":"\/paper\/practical-bayesian-optimization-of-machine",
            "published":"2012-06-13T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96978,
        "rank":187,
        "Model":"ResNet-44 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-44 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"90.5",
            "PARAMS":"0.658M",
            "Top-1 Accuracy":"90.5",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.5,
            "PARAMS":658000.0,
            "Top-1 Accuracy":90.5,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96975,
        "rank":188,
        "Model":"ResNet-20 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-20 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"90.4",
            "PARAMS":"0.269M",
            "Top-1 Accuracy":"90.4",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.4,
            "PARAMS":269000.0,
            "Top-1 Accuracy":90.4,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":47988,
        "rank":189,
        "Model":"SEER (RegNet10B)",
        "mlmodel":{

        },
        "method_short":"SEER ",
        "method_details":"RegNet10B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-16",
        "metrics":{
            "Percentage correct":"90",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":90.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":963673,
            "title":"Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision",
            "url":"\/paper\/vision-models-are-more-robust-and-fair-when",
            "published":"2022-02-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vision-models-are-more-robust-and-fair-when\/review\/?hl=47988"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":53393,
        "rank":190,
        "Model":"kMobileNet 16ch",
        "mlmodel":{

        },
        "method_short":"kMobileNet 16ch",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-01",
        "metrics":{
            "Percentage correct":"89.81",
            "PARAMS":"0.24M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.81,
            "PARAMS":240000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1000583,
            "title":"Grouped Pointwise Convolutions Reduce Parameters in Convolutional Neural Networks",
            "url":"\/paper\/grouped-pointwise-convolutions-reduce",
            "published":"2022-06-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":563,
        "rank":191,
        "Model":"APAC",
        "mlmodel":{

        },
        "method_short":"APAC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-05-13",
        "metrics":{
            "Percentage correct":"89.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":40737,
            "title":"APAC: Augmented PAttern Classification with Neural Networks",
            "url":"\/paper\/apac-augmented-pattern-classification-with",
            "published":"2015-05-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/apac-augmented-pattern-classification-with\/review\/?hl=563"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":10426,
        "rank":192,
        "Model":"ensemble of 7 models",
        "mlmodel":{

        },
        "method_short":"ensemble of 7 models",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-10-26",
        "metrics":{
            "Percentage correct":"89.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":15158,
            "title":"Dynamic Routing Between Capsules",
            "url":"\/paper\/dynamic-routing-between-capsules",
            "published":"2017-10-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/dynamic-routing-between-capsules\/review\/?hl=10426"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":570,
        "rank":193,
        "Model":"DCNN+GFE",
        "mlmodel":{

        },
        "method_short":"DCNN+GFE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-10-06",
        "metrics":{
            "Percentage correct":"89.1",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.1,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":16559,
            "title":"Deep Convolutional Neural Networks as Generic Feature Extractors",
            "url":"\/paper\/deep-convolutional-neural-networks-as-generic",
            "published":"2017-10-06T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":14,
                "name":"DCN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":542,
        "rank":194,
        "Model":"DCNN",
        "mlmodel":{

        },
        "method_short":"DCNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2012-12-01",
        "metrics":{
            "Percentage correct":"89",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":79567,
            "title":"ImageNet Classification with Deep Convolutional Neural Networks",
            "url":"\/paper\/imagenet-classification-with-deep",
            "published":"2012-12-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":14,
                "name":"DCN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96974,
        "rank":195,
        "Model":"ResNet-14 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-14 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"89.0",
            "PARAMS":"0.172M",
            "Top-1 Accuracy":"89.0",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":89.0,
            "PARAMS":172000.0,
            "Top-1 Accuracy":89.0,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":538,
        "rank":196,
        "Model":"MCDNN",
        "mlmodel":{

        },
        "method_short":"MCDNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2012-02-13",
        "metrics":{
            "Percentage correct":"88.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":88.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":50125,
            "title":"Multi-column Deep Neural Networks for Image Classification",
            "url":"\/paper\/multi-column-deep-neural-networks-for-image",
            "published":"2012-02-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/multi-column-deep-neural-networks-for-image\/review\/?hl=538"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":571,
        "rank":197,
        "Model":"RReLU",
        "mlmodel":{

        },
        "method_short":"RReLU",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-05-05",
        "metrics":{
            "Percentage correct":"88.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":88.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":37395,
            "title":"Empirical Evaluation of Rectified Activations in Convolutional Network",
            "url":"\/paper\/empirical-evaluation-of-rectified-activations",
            "published":"2015-05-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/empirical-evaluation-of-rectified-activations\/review\/?hl=571"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96979,
        "rank":198,
        "Model":"ResNet-56 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-56 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"88.8",
            "PARAMS":"0.853M",
            "Top-1 Accuracy":"88.8",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":88.8,
            "PARAMS":853000.0,
            "Top-1 Accuracy":88.8,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":109081,
        "rank":199,
        "Model":"Diffusion Classifier (zero-shot)",
        "mlmodel":{

        },
        "method_short":"Diffusion Classifier ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-28",
        "metrics":{
            "Percentage correct":"88.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":88.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1181860,
            "title":"Your Diffusion Model is Secretly a Zero-Shot Classifier",
            "url":"\/paper\/your-diffusion-model-is-secretly-a-zero-shot",
            "published":"2023-03-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/your-diffusion-model-is-secretly-a-zero-shot\/review\/?hl=109081"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":566,
        "rank":200,
        "Model":"ReNet",
        "mlmodel":{

        },
        "method_short":"ReNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-05-03",
        "metrics":{
            "Percentage correct":"87.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":87.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":39499,
            "title":"ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks",
            "url":"\/paper\/renet-a-recurrent-neural-network-based",
            "published":"2015-05-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/renet-a-recurrent-neural-network-based\/review\/?hl=566"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":558,
        "rank":201,
        "Model":"An Analysis of Unsupervised Pre-training in Light of Recent Advances",
        "mlmodel":{

        },
        "method_short":"An Analysis of Unsupervised Pre-training in Light of Recent Advances",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-20",
        "metrics":{
            "Percentage correct":"86.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":86.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":41299,
            "title":"An Analysis of Unsupervised Pre-training in Light of Recent Advances",
            "url":"\/paper\/an-analysis-of-unsupervised-pre-training-in",
            "published":"2014-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-analysis-of-unsupervised-pre-training-in\/review\/?hl=558"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":45761,
        "rank":202,
        "Model":"cvpr_class",
        "mlmodel":{

        },
        "method_short":"cvpr_class",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-12-10",
        "metrics":{
            "Percentage correct":"86.65",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":86.65,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":37118,
            "title":"Deep Residual Learning for Image Recognition",
            "url":"\/paper\/deep-residual-learning-for-image-recognition",
            "published":"2015-12-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-residual-learning-for-image-recognition\/review\/?hl=45761"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":96973,
        "rank":203,
        "Model":"ResNet-8 (Trainable Activations)",
        "mlmodel":{

        },
        "method_short":"ResNet-8 ",
        "method_details":"Trainable Activations",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-01-26",
        "metrics":{
            "Percentage correct":"86.5",
            "PARAMS":"0.075M",
            "Top-1 Accuracy":"86.5",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":86.5,
            "PARAMS":75000.0,
            "Top-1 Accuracy":86.5,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156497,
            "title":"Trainable Activations for Image Classification",
            "url":"\/paper\/trainable-activations-for-image",
            "published":"2023-01-26T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":45746,
        "rank":204,
        "Model":"cvpr_class",
        "mlmodel":{

        },
        "method_short":"cvpr_class",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-25",
        "metrics":{
            "Percentage correct":"85.28",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":85.28,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":877343,
            "title":"ResNet strikes back: An improved training procedure in timm",
            "url":"\/paper\/resnet-strikes-back-an-improved-training",
            "published":"2021-10-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":43211,
        "rank":205,
        "Model":"WaveMix",
        "mlmodel":{

        },
        "method_short":"WaveMix",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-29",
        "metrics":{
            "Percentage correct":"85.21",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":85.21,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":883640,
            "title":"WaveMix: Multi-Resolution Token Mixing for Images",
            "url":"\/paper\/wavemix-multi-resolution-token-mixing-for",
            "published":"2021-09-29T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":545,
        "rank":206,
        "Model":"Stochastic Pooling",
        "mlmodel":{

        },
        "method_short":"Stochastic Pooling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2013-01-16",
        "metrics":{
            "Percentage correct":"84.9",
            "PARAMS":null,
            "Top-1 Accuracy":"84.9",
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":84.9,
            "PARAMS":null,
            "Top-1 Accuracy":84.9,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":50080,
            "title":"Stochastic Pooling for Regularization of Deep Convolutional Neural Networks",
            "url":"\/paper\/stochastic-pooling-for-regularization-of-deep",
            "published":"2013-01-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/stochastic-pooling-for-regularization-of-deep\/review\/?hl=545"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":540,
        "rank":207,
        "Model":"Improving neural networks by preventing co-adaptation of feature detectors",
        "mlmodel":{

        },
        "method_short":"Improving neural networks by preventing co-adaptation of feature detectors",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2012-07-03",
        "metrics":{
            "Percentage correct":"84.4",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":84.4,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":50040,
            "title":"Improving neural networks by preventing co-adaptation of feature detectors",
            "url":"\/paper\/improving-neural-networks-by-preventing-co",
            "published":"2012-07-03T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":36566,
        "rank":208,
        "Model":"CCN",
        "mlmodel":{

        },
        "method_short":"CCN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"83.36",
            "PARAMS":"0.906075M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":83.36,
            "PARAMS":906075.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":177,
                "name":"Xformer",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37868,
        "rank":209,
        "Model":"CvN",
        "mlmodel":{

        },
        "method_short":"CvN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"83.26",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":83.26,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37867,
        "rank":210,
        "Model":"CvP",
        "mlmodel":{

        },
        "method_short":"CvP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"83.19",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":83.19,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":21865,
        "rank":211,
        "Model":"UL-Hopfield (ULH)",
        "mlmodel":{

        },
        "method_short":"UL-Hopfield ",
        "method_details":"ULH",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-05-02",
        "metrics":{
            "Percentage correct":"83.1",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":83.1,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":4623,
            "title":"Unsupervised Learning using Pretrained CNN and Associative Memory Bank",
            "url":"\/paper\/unsupervised-learning-using-pretrained-cnn",
            "published":"2018-05-02T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/unsupervised-learning-using-pretrained-cnn\/review\/?hl=21865"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11240,
        "rank":212,
        "Model":"DCGAN",
        "mlmodel":{

        },
        "method_short":"DCGAN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-19",
        "metrics":{
            "Percentage correct":"82.8",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":82.8,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":36691,
            "title":"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
            "url":"\/paper\/unsupervised-representation-learning-with-1",
            "published":"2015-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-representation-learning-with-1\/review\/?hl=11240"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":554,
        "rank":213,
        "Model":"CKN",
        "mlmodel":{

        },
        "method_short":"CKN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-06-12",
        "metrics":{
            "Percentage correct":"82.2",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":82.2,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":43322,
            "title":"Convolutional Kernel Networks",
            "url":"\/paper\/convolutional-kernel-networks",
            "published":"2014-06-12T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/convolutional-kernel-networks\/review\/?hl=554"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":557,
        "rank":214,
        "Model":"Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
        "mlmodel":{

        },
        "method_short":"Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-12-01",
        "metrics":{
            "Percentage correct":"82",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":82.0,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":78774,
            "title":"Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
            "url":"\/paper\/discriminative-unsupervised-feature-learning-1",
            "published":"2014-12-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":20689,
        "rank":215,
        "Model":"Sign-symmetry",
        "mlmodel":{

        },
        "method_short":"Sign-symmetry",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-10-17",
        "metrics":{
            "Percentage correct":"80.98",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":80.98,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":36241,
            "title":"How Important is Weight Symmetry in Backpropagation?",
            "url":"\/paper\/how-important-is-weight-symmetry-in",
            "published":"2015-10-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/how-important-is-weight-symmetry-in\/review\/?hl=20689"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":80742,
        "rank":216,
        "Model":"pFedBreD_ns_mg",
        "mlmodel":{

        },
        "method_short":"pFedBreD_ns_mg",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-19",
        "metrics":{
            "Percentage correct":"80.63",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":80.63,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1114807,
            "title":"Personalized Federated Learning with Hidden Information on Personalized Prior",
            "url":"\/paper\/personalized-federated-learning-with-hidden",
            "published":"2022-11-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/personalized-federated-learning-with-hidden\/review\/?hl=80742"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":11241,
        "rank":217,
        "Model":"1 Layer K-means",
        "mlmodel":{

        },
        "method_short":"1 Layer K-means",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-11-19",
        "metrics":{
            "Percentage correct":"80.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":80.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":36691,
            "title":"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
            "url":"\/paper\/unsupervised-representation-learning-with-1",
            "published":"2015-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-representation-learning-with-1\/review\/?hl=11241"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":544,
        "rank":218,
        "Model":"Learning with Recursive Perceptual Representations",
        "mlmodel":{

        },
        "method_short":"Learning with Recursive Perceptual Representations",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2012-12-01",
        "metrics":{
            "Percentage correct":"79.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":79.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":79755,
            "title":"Learning with Recursive Perceptual Representations",
            "url":"\/paper\/learning-with-recursive-perceptual",
            "published":"2012-12-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37866,
        "rank":219,
        "Model":"LeViP",
        "mlmodel":{

        },
        "method_short":"LeViP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"79.50",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":79.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":552,
        "rank":220,
        "Model":"PCANet",
        "mlmodel":{

        },
        "method_short":"PCANet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2014-04-14",
        "metrics":{
            "Percentage correct":"78.7",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":78.7,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":44217,
            "title":"PCANet: A Simple Deep Learning Baseline for Image Classification?",
            "url":"\/paper\/pcanet-a-simple-deep-learning-baseline-for",
            "published":"2014-04-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pcanet-a-simple-deep-learning-baseline-for\/review\/?hl=552"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37871,
        "rank":221,
        "Model":"Hybrid ViT+RoPE",
        "mlmodel":{

        },
        "method_short":"Hybrid ViT+RoPE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"76.9",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":76.9,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":564,
        "rank":222,
        "Model":"FLSCNN",
        "mlmodel":{

        },
        "method_short":"FLSCNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-03-16",
        "metrics":{
            "Percentage correct":"75.9",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":75.9,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":39192,
            "title":"Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network",
            "url":"\/paper\/enhanced-image-classification-with-a-fast",
            "published":"2015-03-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/enhanced-image-classification-with-a-fast\/review\/?hl=564"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":36568,
        "rank":223,
        "Model":"Hybrid Vision Nystromformer (ViN)",
        "mlmodel":{

        },
        "method_short":"Hybrid Vision Nystromformer ",
        "method_details":"ViN",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"75.26",
            "PARAMS":"0.623706M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":75.26,
            "PARAMS":623706.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":177,
                "name":"Xformer",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":37870,
        "rank":224,
        "Model":"Hybrid PiN",
        "mlmodel":{

        },
        "method_short":"Hybrid PiN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"74",
            "PARAMS":"0.990298M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":74.0,
            "PARAMS":990298.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":177,
                "name":"Xformer",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":55123,
        "rank":225,
        "Model":"SmoothNetV1",
        "mlmodel":{

        },
        "method_short":"SmoothNetV1",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-09",
        "metrics":{
            "Percentage correct":"73.5",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":73.5,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1006049,
            "title":"SmoothNets: Optimizing CNN architecture design for differentially private deep learning",
            "url":"\/paper\/smoothnets-optimizing-cnn-architecture-design",
            "published":"2022-05-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/smoothnets-optimizing-cnn-architecture-design\/review\/?hl=55123"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":36562,
        "rank":226,
        "Model":"Vision Nystromformer (ViN)",
        "mlmodel":{

        },
        "method_short":"Vision Nystromformer ",
        "method_details":"ViN",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-05",
        "metrics":{
            "Percentage correct":"65.06",
            "PARAMS":"0.530970M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":65.06,
            "PARAMS":530970.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":831110,
            "title":"Vision Xformers: Efficient Attention for Image Classification",
            "url":"\/paper\/vision-xformers-efficient-attention-for-image",
            "published":"2021-07-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":177,
                "name":"Xformer",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":9321,
        "rank":227,
        "Model":"ANODE",
        "mlmodel":{

        },
        "method_short":"ANODE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-02",
        "metrics":{
            "Percentage correct":"60.6",
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":60.6,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":110432,
            "title":"Augmented Neural ODEs",
            "url":"\/paper\/augmented-neural-odes",
            "published":"2019-04-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/augmented-neural-odes\/review\/?hl=9321"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":109769,
        "rank":228,
        "Model":"TripleNet-B",
        "mlmodel":{

        },
        "method_short":"TripleNet-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-02",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":"12.63M",
            "Accuracy":"87.03"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":12630000.0,
            "Accuracy":87.03
        },
        "uses_additional_data":false,
        "paper":{
            "id":988298,
            "title":"Efficient Convolutional Neural Networks on Raspberry Pi for Image Classification",
            "url":"\/paper\/triplenet-a-low-computing-power-platform-of",
            "published":"2022-04-02T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":72498,
        "rank":229,
        "Model":"efficient adaptive ensembling",
        "mlmodel":{

        },
        "method_short":"efficient adaptive ensembling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-15",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"99.612"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":99.612
        },
        "uses_additional_data":true,
        "paper":{
            "id":1027725,
            "title":"Efficient Adaptive Ensembling for Image Classification",
            "url":"\/paper\/efficient-adaptive-ensembling-for-image",
            "published":"2022-06-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/efficient-adaptive-ensembling-for-image\/review\/?hl=72498"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":102757,
        "rank":230,
        "Model":"ASF-former-B",
        "mlmodel":{

        },
        "method_short":"ASF-former-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-26",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"98.8%"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":98.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":999999,
            "title":"Adaptive Split-Fusion Transformer",
            "url":"\/paper\/adaptive-split-fusion-transformer",
            "published":"2022-04-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/adaptive-split-fusion-transformer\/review\/?hl=102757"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":102754,
        "rank":231,
        "Model":"ASF-former-S",
        "mlmodel":{

        },
        "method_short":"ASF-former-S",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-26",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"98.7%"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":98.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":999999,
            "title":"Adaptive Split-Fusion Transformer",
            "url":"\/paper\/adaptive-split-fusion-transformer",
            "published":"2022-04-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/adaptive-split-fusion-transformer\/review\/?hl=102754"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":113826,
        "rank":232,
        "Model":"GAC-SNN",
        "mlmodel":{

        },
        "method_short":"GAC-SNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-12",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"96.46"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":96.46
        },
        "uses_additional_data":false,
        "paper":{
            "id":1263133,
            "title":"Gated Attention Coding for Training High-performance and Efficient Spiking Neural Networks",
            "url":"\/paper\/gated-attention-coding-for-training-high",
            "published":"2023-08-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gated-attention-coding-for-training-high\/review\/?hl=113826"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":98861,
        "rank":233,
        "Model":"SNN",
        "mlmodel":{

        },
        "method_short":"SNN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-13",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":"68.3"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":null,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":68.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1156633,
            "title":"Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data",
            "url":"\/paper\/sneaky-spikes-uncovering-stealthy-backdoor",
            "published":"2023-02-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sneaky-spikes-uncovering-stealthy-backdoor\/review\/?hl=98861"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":50598,
        "rank":234,
        "Model":"ExquisiteNetV2",
        "mlmodel":{

        },
        "method_short":"ExquisiteNetV2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-19",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"0.518230M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":518230.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":802068,
            "title":"A Novel lightweight Convolutional Neural Network, ExquisiteNetV2",
            "url":"\/paper\/a-novel-lightweight-convolutional-neural",
            "published":"2021-05-19T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":43455,
        "rank":235,
        "Model":"kEffNet-B0",
        "mlmodel":{

        },
        "method_short":"kEffNet-B0",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-14",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"0.64M",
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":640000.0,
            "Top-1 Accuracy":null,
            "Parameters":null,
            "Accuracy":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":896400,
            "title":"Grouped Pointwise Convolutions Significantly Reduces Parameters in EfficientNet",
            "url":"\/paper\/grouped-pointwise-convolutions-significantly",
            "published":"2021-10-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":5,
                "name":"EfficientNet",
                "color":"#05A300"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":110070,
        "rank":236,
        "Model":"ShortNet1-53",
        "mlmodel":{

        },
        "method_short":"ShortNet1-53",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-08-02",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"2.16M",
            "Top-1 Accuracy":"86.64",
            "Parameters":"2.16M",
            "Accuracy":"86.64"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":2160000.0,
            "Top-1 Accuracy":86.64,
            "Parameters":2160000.0,
            "Accuracy":86.64
        },
        "uses_additional_data":false,
        "paper":{
            "id":1053465,
            "title":"Connection Reduction of DenseNet for Image Recognition",
            "url":"\/paper\/connection-reduction-is-all-you-need",
            "published":"2022-08-02T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":110079,
        "rank":237,
        "Model":"ThresholdNet",
        "mlmodel":{

        },
        "method_short":"ThresholdNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-08-28",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"15.32M",
            "Top-1 Accuracy":"86.34",
            "Parameters":"15.32M",
            "Accuracy":"86.34"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":15320000.0,
            "Top-1 Accuracy":86.34,
            "Parameters":15320000.0,
            "Accuracy":86.34
        },
        "uses_additional_data":false,
        "paper":{
            "id":858407,
            "title":"New Pruning Method Based on DenseNet Network for Image Classification",
            "url":"\/paper\/threshold-pruning-tool-for-densely-connected",
            "published":"2021-08-28T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":109768,
        "rank":238,
        "Model":"ThreshNet95",
        "mlmodel":{

        },
        "method_short":"ThreshNet95",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-09",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"16.19M",
            "Top-1 Accuracy":"86.69",
            "Parameters":"16.19M",
            "Accuracy":"86.69"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":16190000.0,
            "Top-1 Accuracy":86.69,
            "Parameters":16190000.0,
            "Accuracy":86.69
        },
        "uses_additional_data":false,
        "paper":{
            "id":942696,
            "title":"ThreshNet: An Efficient DenseNet Using Threshold Mechanism to Reduce Connections",
            "url":"\/paper\/threshnet-an-efficient-densenet-using",
            "published":"2022-01-09T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":120,
        "row_id":110078,
        "rank":239,
        "Model":"APVT",
        "mlmodel":{

        },
        "method_short":"APVT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-02",
        "metrics":{
            "Percentage correct":null,
            "PARAMS":"22.88M",
            "Top-1 Accuracy":"80.45",
            "Parameters":"22.88M",
            "Accuracy":"80.45"
        },
        "raw_metrics":{
            "Percentage correct":null,
            "PARAMS":22880000.0,
            "Top-1 Accuracy":80.45,
            "Parameters":22880000.0,
            "Accuracy":80.45
        },
        "uses_additional_data":false,
        "paper":{
            "id":970441,
            "title":"Aggregated Pyramid Vision Transformer: Split-transform-merge Strategy for Image Recognition without Convolutions",
            "url":"\/paper\/aggregated-pyramid-vision-transformer-split",
            "published":"2022-03-02T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]