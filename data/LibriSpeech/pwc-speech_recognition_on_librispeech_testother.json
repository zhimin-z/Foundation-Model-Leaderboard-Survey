[
    {
        "table_id":108,
        "row_id":42323,
        "rank":1,
        "Model":"w2v-BERT XXL",
        "mlmodel":{

        },
        "method_short":"w2v-BERT XXL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-08-07",
        "metrics":{
            "Word Error Rate (WER)":"2.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.5
        },
        "uses_additional_data":true,
        "paper":{
            "id":851392,
            "title":"W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training",
            "url":"\/paper\/w2v-bert-combining-contrastive-learning-and",
            "published":"2021-08-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/w2v-bert-combining-contrastive-learning-and\/review\/?hl=42323"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21210,
        "rank":2,
        "Model":"Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light",
        "mlmodel":{

        },
        "method_short":"Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-20",
        "metrics":{
            "Word Error Rate (WER)":"2.6"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":229254,
            "title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition",
            "url":"\/paper\/pushing-the-limits-of-semi-supervised",
            "published":"2020-10-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pushing-the-limits-of-semi-supervised\/review\/?hl=21210"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":51677,
        "rank":3,
        "Model":"HuBERT with Libri-Light",
        "mlmodel":{

        },
        "method_short":"HuBERT with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-14",
        "metrics":{
            "Word Error Rate (WER)":"2.9"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":816688,
            "title":"HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
            "url":"\/paper\/hubert-self-supervised-speech-representation",
            "published":"2021-06-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":26288,
        "rank":4,
        "Model":"Conv + Transformer + wav2vec2.0 + pseudo labeling",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer + wav2vec2.0 + pseudo labeling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Word Error Rate (WER)":"3.1"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":229991,
            "title":"Self-training and Pre-training are Complementary for Speech Recognition",
            "url":"\/paper\/self-training-and-pre-training-are",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-training-and-pre-training-are\/review\/?hl=26288"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":20257,
        "rank":5,
        "Model":"wav2vec 2.0 with Libri-Light",
        "mlmodel":{

        },
        "method_short":"wav2vec 2.0 with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-20",
        "metrics":{
            "Word Error Rate (WER)":"3.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":205125,
            "title":"wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
            "url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised",
            "published":"2020-06-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised\/review\/?hl=20257"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":30059,
        "rank":6,
        "Model":"SpeechStew (1B)",
        "mlmodel":{

        },
        "method_short":"SpeechStew ",
        "method_details":"1B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Word Error Rate (WER)":"3.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":775979,
            "title":"SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network",
            "url":"\/paper\/speechstew-simply-mix-all-available-speech",
            "published":"2021-04-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/speechstew-simply-mix-all-available-speech\/review\/?hl=30059"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":16618,
        "rank":7,
        "Model":"ContextNet + SpecAugment-based Noisy Student Training with Libri-Light",
        "mlmodel":{

        },
        "method_short":"ContextNet + SpecAugment-based Noisy Student Training with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"3.4"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":195697,
            "title":"Improved Noisy Student Training for Automatic Speech Recognition",
            "url":"\/paper\/improved-noisy-student-training-for-automatic",
            "published":"2020-05-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-noisy-student-training-for-automatic\/review\/?hl=16618"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            },
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":101115,
        "rank":8,
        "Model":"E-Branchformer (L) + Internal Language Model Estimation",
        "mlmodel":{

        },
        "method_short":"E-Branchformer ",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-30",
        "metrics":{
            "Word Error Rate (WER)":"3.65"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.65
        },
        "uses_additional_data":false,
        "paper":{
            "id":1085392,
            "title":"E-Branchformer: Branchformer with Enhanced merging for speech recognition",
            "url":"\/paper\/e-branchformer-branchformer-with-enhanced",
            "published":"2022-09-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/e-branchformer-branchformer-with-enhanced\/review\/?hl=101115"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":52586,
        "rank":9,
        "Model":"data2vec",
        "mlmodel":{

        },
        "method_short":"data2vec",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-02-07",
        "metrics":{
            "Word Error Rate (WER)":"3.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":957898,
            "title":"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language",
            "url":"\/paper\/data2vec-a-general-framework-for-self-1",
            "published":"2022-02-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/data2vec-a-general-framework-for-self-1\/review\/?hl=52586"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":17284,
        "rank":10,
        "Model":"Conv + Transformer AM + Iterative Pseudo-Labeling (n-gram LM + Transformer Rescoring)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM + Iterative Pseudo-Labeling ",
        "method_details":"n-gram LM + Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"3.83"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.83
        },
        "uses_additional_data":true,
        "paper":{
            "id":195598,
            "title":"Iterative Pseudo-Labeling for Speech Recognition",
            "url":"\/paper\/iterative-pseudo-labeling-for-speech",
            "published":"2020-05-19T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21213,
        "rank":11,
        "Model":"Conformer(L)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"3.9"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=21213"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":30061,
        "rank":12,
        "Model":"SpeechStew (100M)",
        "mlmodel":{

        },
        "method_short":"SpeechStew ",
        "method_details":"100M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Word Error Rate (WER)":"4.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":775979,
            "title":"SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network",
            "url":"\/paper\/speechstew-simply-mix-all-available-speech",
            "published":"2021-04-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/speechstew-simply-mix-all-available-speech\/review\/?hl=30061"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":20258,
        "rank":13,
        "Model":"wav2vec 2.0",
        "mlmodel":{

        },
        "method_short":"wav2vec 2.0",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-20",
        "metrics":{
            "Word Error Rate (WER)":"4.1"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":205125,
            "title":"wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
            "url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised",
            "published":"2020-06-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised\/review\/?hl=20258"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":20537,
        "rank":14,
        "Model":"ContextNet(L)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"4.1"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20537"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21236,
        "rank":15,
        "Model":"Conv + Transformer AM (ConvLM with Transformer Rescoring)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM ",
        "method_details":"ConvLM with Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-19",
        "metrics":{
            "Word Error Rate (WER)":"4.11"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.11
        },
        "uses_additional_data":true,
        "paper":{
            "id":173487,
            "title":"End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures",
            "url":"\/paper\/end-to-end-asr-from-supervised-to-semi",
            "published":"2019-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/end-to-end-asr-from-supervised-to-semi\/review\/?hl=21236"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21237,
        "rank":16,
        "Model":"CTC + Transformer LM rescoring",
        "mlmodel":{

        },
        "method_short":"CTC + Transformer LM rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"4.20"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":195612,
            "title":"Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces",
            "url":"\/paper\/fast-simpler-and-more-accurate-hybrid-asr",
            "published":"2020-05-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/fast-simpler-and-more-accurate-hybrid-asr\/review\/?hl=21237"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":22214,
        "rank":17,
        "Model":"Transformer Transducer",
        "mlmodel":{

        },
        "method_short":"Transformer Transducer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-05",
        "metrics":{
            "Word Error Rate (WER)":"4.20"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":233304,
            "title":"Improving RNN Transducer Based ASR with Auxiliary Tasks",
            "url":"\/paper\/improving-rnn-transducer-based-asr-with",
            "published":"2020-11-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-rnn-transducer-based-asr-with\/review\/?hl=22214"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":114118,
        "rank":18,
        "Model":"Qwen-Audio",
        "mlmodel":{

        },
        "method_short":"Qwen-Audio",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-15",
        "metrics":{
            "Word Error Rate (WER)":"4.2"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":1320758,
            "title":"Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models",
            "url":"\/paper\/qwen-audio-advancing-universal-audio",
            "published":"2023-11-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21211,
        "rank":19,
        "Model":"Conformer(M)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"4.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=21211"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":16832,
        "rank":20,
        "Model":"Multistream CNN with Self-Attentive SRU",
        "mlmodel":{

        },
        "method_short":"Multistream CNN with Self-Attentive SRU",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-21",
        "metrics":{
            "Word Error Rate (WER)":"4.46"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.46
        },
        "uses_additional_data":false,
        "paper":{
            "id":195984,
            "title":"ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition",
            "url":"\/paper\/asapp-asr-multistream-cnn-and-self-attentive",
            "published":"2020-05-21T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/asapp-asr-multistream-cnn-and-self-attentive\/review\/?hl=16832"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":20535,
        "rank":21,
        "Model":"ContextNet(M)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"4.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20535"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            },
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21232,
        "rank":22,
        "Model":"hybrid + Transformer LM rescoring",
        "mlmodel":{

        },
        "method_short":"hybrid + Transformer LM rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-22",
        "metrics":{
            "Word Error Rate (WER)":"4.85"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.85
        },
        "uses_additional_data":false,
        "paper":{
            "id":165161,
            "title":"Transformer-based Acoustic Modeling for Hybrid Speech Recognition",
            "url":"\/paper\/transformer-based-acoustic-modeling-for",
            "published":"2019-10-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/transformer-based-acoustic-modeling-for\/review\/?hl=21232"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11186,
        "rank":23,
        "Model":"Hybrid model with Transformer rescoring",
        "mlmodel":{

        },
        "method_short":"Hybrid model with Transformer rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-08",
        "metrics":{
            "Word Error Rate (WER)":"5.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":113941,
            "title":"RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w\/o Data Augmentation",
            "url":"\/paper\/rwth-asr-systems-for-librispeech-hybrid-vs",
            "published":"2019-05-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/rwth-asr-systems-for-librispeech-hybrid-vs\/review\/?hl=11186"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":21212,
        "rank":24,
        "Model":"Conformer(S)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"5.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=21212"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":17281,
        "rank":25,
        "Model":"Conv + Transformer AM (ConvLM  with Transformer Rescoring) (LS only)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM ",
        "method_details":"ConvLM  with Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-19",
        "metrics":{
            "Word Error Rate (WER)":"5.18"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.18
        },
        "uses_additional_data":false,
        "paper":{
            "id":173487,
            "title":"End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures",
            "url":"\/paper\/end-to-end-asr-from-supervised-to-semi",
            "published":"2019-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/end-to-end-asr-from-supervised-to-semi\/review\/?hl=17281"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":20533,
        "rank":26,
        "Model":"ContextNet(S)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"5.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20533"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            },
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":29784,
        "rank":27,
        "Model":"LSTM Transducer",
        "mlmodel":{

        },
        "method_short":"LSTM Transducer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-07",
        "metrics":{
            "Word Error Rate (WER)":"5.6"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":776586,
            "title":"Librispeech Transducer Model with Internal Language Model Prior Correction",
            "url":"\/paper\/librispeech-transducer-model-with-internal",
            "published":"2021-04-07T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11187,
        "rank":28,
        "Model":"Transformer",
        "mlmodel":{

        },
        "method_short":"Transformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-13",
        "metrics":{
            "Word Error Rate (WER)":"5.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":153553,
            "title":"A Comparative Study on Transformer vs RNN in Speech Applications",
            "url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in",
            "published":"2019-09-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in\/review\/?hl=11187"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11188,
        "rank":29,
        "Model":"LAS + SpecAugment",
        "mlmodel":{

        },
        "method_short":"LAS + SpecAugment",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-18",
        "metrics":{
            "Word Error Rate (WER)":"5.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":112034,
            "title":"SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
            "url":"\/paper\/specaugment-a-simple-data-augmentation-method",
            "published":"2019-04-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/specaugment-a-simple-data-augmentation-method\/review\/?hl=11188"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11189,
        "rank":30,
        "Model":"Multi-Stream Self-Attention With Dilated 1D Convolutions",
        "mlmodel":{

        },
        "method_short":"Multi-Stream Self-Attention With Dilated 1D Convolutions",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-01",
        "metrics":{
            "Word Error Rate (WER)":"5.80"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":156882,
            "title":"State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions",
            "url":"\/paper\/state-of-the-art-speech-recognition-using",
            "published":"2019-10-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/state-of-the-art-speech-recognition-using\/review\/?hl=11189"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":56340,
        "rank":31,
        "Model":"Squeezeformer (L)",
        "mlmodel":{

        },
        "method_short":"Squeezeformer ",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-02",
        "metrics":{
            "Word Error Rate (WER)":"5.97"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.97
        },
        "uses_additional_data":false,
        "paper":{
            "id":1020654,
            "title":"Squeezeformer: An Efficient Transformer for Automatic Speech Recognition",
            "url":"\/paper\/squeezeformer-an-efficient-transformer-for",
            "published":"2022-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/squeezeformer-an-efficient-transformer-for\/review\/?hl=56340"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11190,
        "rank":32,
        "Model":"LAS (no LM)",
        "mlmodel":{

        },
        "method_short":"LAS ",
        "method_details":"no LM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-18",
        "metrics":{
            "Word Error Rate (WER)":"6.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":112034,
            "title":"SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
            "url":"\/paper\/specaugment-a-simple-data-augmentation-method",
            "published":"2019-04-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/specaugment-a-simple-data-augmentation-method\/review\/?hl=11190"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":45283,
        "rank":33,
        "Model":"Conformer with Relaxed Attention",
        "mlmodel":{

        },
        "method_short":"Conformer with Relaxed Attention",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-02",
        "metrics":{
            "Word Error Rate (WER)":"6.85"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.85
        },
        "uses_additional_data":false,
        "paper":{
            "id":830212,
            "title":"Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition",
            "url":"\/paper\/relaxed-attention-a-simple-method-to-boost",
            "published":"2021-07-02T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":41296,
        "rank":34,
        "Model":"QuartzNet15x5",
        "mlmodel":{

        },
        "method_short":"QuartzNet15x5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-22",
        "metrics":{
            "Word Error Rate (WER)":"7.25"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":7.25
        },
        "uses_additional_data":false,
        "paper":{
            "id":195229,
            "title":"QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions",
            "url":"\/paper\/quartznet-deep-automatic-speech-recognition",
            "published":"2019-10-22T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":4193,
        "rank":35,
        "Model":"tdnn + chain + rnnlm rescoring",
        "mlmodel":{

        },
        "method_short":"tdnn + chain + rnnlm rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-04-15",
        "metrics":{
            "Word Error Rate (WER)":"7.63"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":7.63
        },
        "uses_additional_data":false,
        "paper":{
            "id":106607,
            "title":"Neural Network Language Modeling with Letter-based Features and Importance Sampling",
            "url":"\/paper\/neural-network-language-modeling-with-letter",
            "published":"2018-04-15T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11191,
        "rank":36,
        "Model":"Jasper DR 10x5 (+ Time\/Freq Masks)",
        "mlmodel":{

        },
        "method_short":"Jasper DR 10x5 ",
        "method_details":"+ Time\/Freq Masks",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-05",
        "metrics":{
            "Word Error Rate (WER)":"7.84"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":7.84
        },
        "uses_additional_data":false,
        "paper":{
            "id":110989,
            "title":"Jasper: An End-to-End Convolutional Neural Acoustic Model",
            "url":"\/paper\/jasper-an-end-to-end-convolutional-neural",
            "published":"2019-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/jasper-an-end-to-end-convolutional-neural\/review\/?hl=11191"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11192,
        "rank":37,
        "Model":"Espresso",
        "mlmodel":{

        },
        "method_short":"Espresso",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-18",
        "metrics":{
            "Word Error Rate (WER)":"8.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":8.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":154341,
            "title":"Espresso: A Fast End-to-end Neural Speech Recognition Toolkit",
            "url":"\/paper\/espresso-a-fast-end-to-end-neural-speech",
            "published":"2019-09-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/espresso-a-fast-end-to-end-neural-speech\/review\/?hl=11192"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":11193,
        "rank":38,
        "Model":"Jasper DR 10x5",
        "mlmodel":{

        },
        "method_short":"Jasper DR 10x5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-05",
        "metrics":{
            "Word Error Rate (WER)":"8.79"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":8.79
        },
        "uses_additional_data":true,
        "paper":{
            "id":110989,
            "title":"Jasper: An End-to-End Convolutional Neural Acoustic Model",
            "url":"\/paper\/jasper-an-end-to-end-convolutional-neural",
            "published":"2019-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/jasper-an-end-to-end-convolutional-neural\/review\/?hl=11193"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":114768,
        "rank":39,
        "Model":"MT4SSL",
        "mlmodel":{

        },
        "method_short":"MT4SSL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-14",
        "metrics":{
            "Word Error Rate (WER)":"9.6"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":9.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1110528,
            "title":"MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets",
            "url":"\/paper\/mt4ssl-boosting-self-supervised-speech",
            "published":"2022-11-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mt4ssl-boosting-self-supervised-speech\/review\/?hl=114768"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":5635,
        "rank":40,
        "Model":"Convolutional Speech Recognition",
        "mlmodel":{

        },
        "method_short":"Convolutional Speech Recognition",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-17",
        "metrics":{
            "Word Error Rate (WER)":"10.47"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":10.47
        },
        "uses_additional_data":false,
        "paper":{
            "id":65363,
            "title":"Fully Convolutional Speech Recognition",
            "url":"\/paper\/fully-convolutional-speech-recognition",
            "published":"2018-12-17T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/fully-convolutional-speech-recognition\/review\/?hl=5635"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":25150,
        "rank":41,
        "Model":"CTC-CRF 4gram-LM",
        "mlmodel":{

        },
        "method_short":"CTC-CRF 4gram-LM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-16",
        "metrics":{
            "Word Error Rate (WER)":"10.65"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":10.65
        },
        "uses_additional_data":false,
        "paper":{
            "id":742207,
            "title":"CRF-based Single-stage Acoustic Modeling with CTC Topology",
            "url":"\/paper\/crf-based-single-stage-acoustic-modeling-with",
            "published":"2019-04-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":437,
        "rank":42,
        "Model":"TDNN + pNorm + speed up\/down speech",
        "mlmodel":{

        },
        "method_short":"TDNN + pNorm + speed up\/down speech",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-07-09",
        "metrics":{
            "Word Error Rate (WER)":"12.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":12.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":3377,
        "rank":43,
        "Model":"Deep Speech 2",
        "mlmodel":{

        },
        "method_short":"Deep Speech 2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-12-08",
        "metrics":{
            "Word Error Rate (WER)":"13.25"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":13.25
        },
        "uses_additional_data":true,
        "paper":{
            "id":37158,
            "title":"Deep Speech 2: End-to-End Speech Recognition in English and Mandarin",
            "url":"\/paper\/deep-speech-2-end-to-end-speech-recognition",
            "published":"2015-12-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-speech-2-end-to-end-speech-recognition\/review\/?hl=3377"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":10128,
        "rank":44,
        "Model":"Local Prior Matching (Large Model, ConvLM LM)",
        "mlmodel":{

        },
        "method_short":"Local Prior Matching ",
        "method_details":"Large Model, ConvLM LM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-24",
        "metrics":{
            "Word Error Rate (WER)":"15.28"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":15.28
        },
        "uses_additional_data":false,
        "paper":{
            "id":184373,
            "title":"Semi-Supervised Speech Recognition via Local Prior Matching",
            "url":"\/paper\/semi-supervised-speech-recognition-via-local",
            "published":"2020-02-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":3390,
        "rank":45,
        "Model":"Snips",
        "mlmodel":{

        },
        "method_short":"Snips",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-05-25",
        "metrics":{
            "Word Error Rate (WER)":"16.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":16.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":2556,
            "title":"Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces",
            "url":"\/paper\/snips-voice-platform-an-embedded-spoken",
            "published":"2018-05-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/snips-voice-platform-an-embedded-spoken\/review\/?hl=3390"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":108,
        "row_id":10127,
        "rank":46,
        "Model":"Local Prior Matching (Large Model)",
        "mlmodel":{

        },
        "method_short":"Local Prior Matching ",
        "method_details":"Large Model",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-24",
        "metrics":{
            "Word Error Rate (WER)":"20.84"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":20.84
        },
        "uses_additional_data":false,
        "paper":{
            "id":184373,
            "title":"Semi-Supervised Speech Recognition via Local Prior Matching",
            "url":"\/paper\/semi-supervised-speech-recognition-via-local",
            "published":"2020-02-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]