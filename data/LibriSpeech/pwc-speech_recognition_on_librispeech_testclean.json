[
    {
        "table_id":107,
        "row_id":21209,
        "rank":1,
        "Model":"Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light",
        "mlmodel":{

        },
        "method_short":"Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-20",
        "metrics":{
            "Word Error Rate (WER)":"1.4"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":229254,
            "title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition",
            "url":"\/paper\/pushing-the-limits-of-semi-supervised",
            "published":"2020-10-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pushing-the-limits-of-semi-supervised\/review\/?hl=21209"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":42322,
        "rank":2,
        "Model":"w2v-BERT XXL",
        "mlmodel":{

        },
        "method_short":"w2v-BERT XXL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-08-07",
        "metrics":{
            "Word Error Rate (WER)":"1.4"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":851392,
            "title":"W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training",
            "url":"\/paper\/w2v-bert-combining-contrastive-learning-and",
            "published":"2021-08-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/w2v-bert-combining-contrastive-learning-and\/review\/?hl=42322"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":26287,
        "rank":3,
        "Model":"Conv + Transformer + wav2vec2.0 + pseudo labeling",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer + wav2vec2.0 + pseudo labeling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Word Error Rate (WER)":"1.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.5
        },
        "uses_additional_data":true,
        "paper":{
            "id":229991,
            "title":"Self-training and Pre-training are Complementary for Speech Recognition",
            "url":"\/paper\/self-training-and-pre-training-are",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-training-and-pre-training-are\/review\/?hl=26287"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":16617,
        "rank":4,
        "Model":"ContextNet + SpecAugment-based Noisy Student Training with Libri-Light",
        "mlmodel":{

        },
        "method_short":"ContextNet + SpecAugment-based Noisy Student Training with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"1.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":195697,
            "title":"Improved Noisy Student Training for Automatic Speech Recognition",
            "url":"\/paper\/improved-noisy-student-training-for-automatic",
            "published":"2020-05-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-noisy-student-training-for-automatic\/review\/?hl=16617"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":30057,
        "rank":5,
        "Model":"SpeechStew (1B)",
        "mlmodel":{

        },
        "method_short":"SpeechStew ",
        "method_details":"1B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Word Error Rate (WER)":"1.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":775979,
            "title":"SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network",
            "url":"\/paper\/speechstew-simply-mix-all-available-speech",
            "published":"2021-04-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/speechstew-simply-mix-all-available-speech\/review\/?hl=30057"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":16831,
        "rank":6,
        "Model":"Multistream CNN with Self-Attentive SRU (WER includes text normalization)",
        "mlmodel":{

        },
        "method_short":"Multistream CNN with Self-Attentive SRU ",
        "method_details":"WER includes text normalization",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-21",
        "metrics":{
            "Word Error Rate (WER)":"1.75"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.75
        },
        "uses_additional_data":false,
        "paper":{
            "id":195984,
            "title":"ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition",
            "url":"\/paper\/asapp-asr-multistream-cnn-and-self-attentive",
            "published":"2020-05-21T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/asapp-asr-multistream-cnn-and-self-attentive\/review\/?hl=16831"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":17,
                "name":"CNN",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":114272,
        "rank":7,
        "Model":"Stateformer",
        "mlmodel":{

        },
        "method_short":"Stateformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-21",
        "metrics":{
            "Word Error Rate (WER)":"1.76"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.76
        },
        "uses_additional_data":false,
        "paper":{
            "id":1212901,
            "title":"Multi-Head State Space Model for Speech Recognition",
            "url":"\/paper\/multi-head-state-space-model-for-speech",
            "published":"2023-05-21T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/multi-head-state-space-model-for-speech\/review\/?hl=114272"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":20259,
        "rank":8,
        "Model":"wav2vec 2.0 with Libri-Light",
        "mlmodel":{

        },
        "method_short":"wav2vec 2.0 with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-20",
        "metrics":{
            "Word Error Rate (WER)":"1.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":205125,
            "title":"wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
            "url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised",
            "published":"2020-06-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/wav2vec-2-0-a-framework-for-self-supervised\/review\/?hl=20259"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":51676,
        "rank":9,
        "Model":"HuBERT with Libri-Light",
        "mlmodel":{

        },
        "method_short":"HuBERT with Libri-Light",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-14",
        "metrics":{
            "Word Error Rate (WER)":"1.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":816688,
            "title":"HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
            "url":"\/paper\/hubert-self-supervised-speech-representation",
            "published":"2021-06-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":101114,
        "rank":10,
        "Model":"E-Branchformer (L) + Internal Language Model Estimation",
        "mlmodel":{

        },
        "method_short":"E-Branchformer ",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-30",
        "metrics":{
            "Word Error Rate (WER)":"1.81"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.81
        },
        "uses_additional_data":false,
        "paper":{
            "id":1085392,
            "title":"E-Branchformer: Branchformer with Enhanced merging for speech recognition",
            "url":"\/paper\/e-branchformer-branchformer-with-enhanced",
            "published":"2022-09-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/e-branchformer-branchformer-with-enhanced\/review\/?hl=101114"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":416,
                "name":"E-Branchformer",
                "color":"#1da6c9"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":20536,
        "rank":11,
        "Model":"ContextNet(L)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"1.9"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20536"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":26188,
        "rank":12,
        "Model":"Conformer(L)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"1.9"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=26188"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":35041,
        "rank":13,
        "Model":"Transformer+Time reduction+Self Knowledge distillation",
        "mlmodel":{

        },
        "method_short":"Transformer+Time reduction+Self Knowledge distillation",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-17",
        "metrics":{
            "Word Error Rate (WER)":"1.9"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":1.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":755041,
            "title":"Transformer-based ASR Incorporating Time-reduction Layer and Fine-tuning with Self-Knowledge Distillation",
            "url":"\/paper\/transformer-based-asr-incorporating-time",
            "published":"2021-03-17T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/transformer-based-asr-incorporating-time\/review\/?hl=35041"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":20534,
        "rank":14,
        "Model":"ContextNet(M)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"2"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20534"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":22215,
        "rank":15,
        "Model":"Transformer Transducer",
        "mlmodel":{

        },
        "method_short":"Transformer Transducer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-05",
        "metrics":{
            "Word Error Rate (WER)":"2.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":233304,
            "title":"Improving RNN Transducer Based ASR with Auxiliary Tasks",
            "url":"\/paper\/improving-rnn-transducer-based-asr-with",
            "published":"2020-11-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-rnn-transducer-based-asr-with\/review\/?hl=22215"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":26187,
        "rank":16,
        "Model":"Conformer(M)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"2"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=26187"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":30058,
        "rank":17,
        "Model":"SpeechStew (100M)",
        "mlmodel":{

        },
        "method_short":"SpeechStew ",
        "method_details":"100M",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Word Error Rate (WER)":"2.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":775979,
            "title":"SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network",
            "url":"\/paper\/speechstew-simply-mix-all-available-speech",
            "published":"2021-04-05T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/speechstew-simply-mix-all-available-speech\/review\/?hl=30058"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":114117,
        "rank":18,
        "Model":"Qwen-Audio",
        "mlmodel":{

        },
        "method_short":"Qwen-Audio",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-15",
        "metrics":{
            "Word Error Rate (WER)":"2.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1320758,
            "title":"Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models",
            "url":"\/paper\/qwen-audio-advancing-universal-audio",
            "published":"2023-11-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":21235,
        "rank":19,
        "Model":"Conv + Transformer AM + Pseudo-Labeling (ConvLM with Transformer Rescoring)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM + Pseudo-Labeling ",
        "method_details":"ConvLM with Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-19",
        "metrics":{
            "Word Error Rate (WER)":"2.03"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.03
        },
        "uses_additional_data":true,
        "paper":{
            "id":173487,
            "title":"End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures",
            "url":"\/paper\/end-to-end-asr-from-supervised-to-semi",
            "published":"2019-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/end-to-end-asr-from-supervised-to-semi\/review\/?hl=21235"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":17512,
        "rank":20,
        "Model":"Conv + Transformer AM + Iterative Pseudo-Labeling (n-gram LM + Transformer Rescoring)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM + Iterative Pseudo-Labeling ",
        "method_details":"n-gram LM + Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"2.10"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":195598,
            "title":"Iterative Pseudo-Labeling for Speech Recognition",
            "url":"\/paper\/iterative-pseudo-labeling-for-speech",
            "published":"2020-05-19T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":21244,
        "rank":21,
        "Model":"CTC + Transformer LM rescoring",
        "mlmodel":{

        },
        "method_short":"CTC + Transformer LM rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-19",
        "metrics":{
            "Word Error Rate (WER)":"2.10"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":195612,
            "title":"Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces",
            "url":"\/paper\/fast-simpler-and-more-accurate-hybrid-asr",
            "published":"2020-05-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/fast-simpler-and-more-accurate-hybrid-asr\/review\/?hl=21244"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":26186,
        "rank":22,
        "Model":"Conformer(S)",
        "mlmodel":{

        },
        "method_short":"Conformer",
        "method_details":"S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-16",
        "metrics":{
            "Word Error Rate (WER)":"2.1"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":195428,
            "title":"Conformer: Convolution-augmented Transformer for Speech Recognition",
            "url":"\/paper\/conformer-convolution-augmented-transformer",
            "published":"2020-05-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/conformer-convolution-augmented-transformer\/review\/?hl=26186"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11178,
        "rank":23,
        "Model":"Multi-Stream Self-Attention With Dilated 1D Convolutions",
        "mlmodel":{

        },
        "method_short":"Multi-Stream Self-Attention With Dilated 1D Convolutions",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-01",
        "metrics":{
            "Word Error Rate (WER)":"2.20"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":156882,
            "title":"State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions",
            "url":"\/paper\/state-of-the-art-speech-recognition-using",
            "published":"2019-10-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/state-of-the-art-speech-recognition-using\/review\/?hl=11178"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":29785,
        "rank":24,
        "Model":"LSTM Transducer",
        "mlmodel":{

        },
        "method_short":"LSTM Transducer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-07",
        "metrics":{
            "Word Error Rate (WER)":"2.23"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.23
        },
        "uses_additional_data":false,
        "paper":{
            "id":776586,
            "title":"Librispeech Transducer Model with Internal Language Model Prior Correction",
            "url":"\/paper\/librispeech-transducer-model-with-internal",
            "published":"2021-04-07T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":21238,
        "rank":25,
        "Model":"Hybrid + Transformer LM rescoring",
        "mlmodel":{

        },
        "method_short":"Hybrid + Transformer LM rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-22",
        "metrics":{
            "Word Error Rate (WER)":"2.26"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.26
        },
        "uses_additional_data":false,
        "paper":{
            "id":165161,
            "title":"Transformer-based Acoustic Modeling for Hybrid Speech Recognition",
            "url":"\/paper\/transformer-based-acoustic-modeling-for",
            "published":"2019-10-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/transformer-based-acoustic-modeling-for\/review\/?hl=21238"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11179,
        "rank":26,
        "Model":"Hybrid model with Transformer rescoring",
        "mlmodel":{

        },
        "method_short":"Hybrid model with Transformer rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-08",
        "metrics":{
            "Word Error Rate (WER)":"2.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":113941,
            "title":"RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w\/o Data Augmentation",
            "url":"\/paper\/rwth-asr-systems-for-librispeech-hybrid-vs",
            "published":"2019-05-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/rwth-asr-systems-for-librispeech-hybrid-vs\/review\/?hl=11179"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":20532,
        "rank":27,
        "Model":"ContextNet(S)",
        "mlmodel":{

        },
        "method_short":"ContextNet",
        "method_details":"S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-07",
        "metrics":{
            "Word Error Rate (WER)":"2.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":194104,
            "title":"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
            "url":"\/paper\/contextnet-improving-convolutional-neural",
            "published":"2020-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contextnet-improving-convolutional-neural\/review\/?hl=20532"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":17280,
        "rank":28,
        "Model":"Conv + Transformer AM (ConvLM  with Transformer Rescoring) (LS only)",
        "mlmodel":{

        },
        "method_short":"Conv + Transformer AM ",
        "method_details":"ConvLM  with Transformer Rescoring",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-19",
        "metrics":{
            "Word Error Rate (WER)":"2.31"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.31
        },
        "uses_additional_data":false,
        "paper":{
            "id":173487,
            "title":"End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures",
            "url":"\/paper\/end-to-end-asr-from-supervised-to-semi",
            "published":"2019-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/end-to-end-asr-from-supervised-to-semi\/review\/?hl=17280"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":56339,
        "rank":29,
        "Model":"Squeezeformer (L)",
        "mlmodel":{

        },
        "method_short":"Squeezeformer ",
        "method_details":"L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-02",
        "metrics":{
            "Word Error Rate (WER)":"2.47"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.47
        },
        "uses_additional_data":false,
        "paper":{
            "id":1020654,
            "title":"Squeezeformer: An Efficient Transformer for Automatic Speech Recognition",
            "url":"\/paper\/squeezeformer-an-efficient-transformer-for",
            "published":"2022-06-02T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/squeezeformer-an-efficient-transformer-for\/review\/?hl=56339"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":9,
                "name":"Conformer",
                "color":"#74d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":111568,
        "rank":30,
        "Model":"LAS + SpecAugment",
        "mlmodel":{

        },
        "method_short":"LAS + SpecAugment",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-18",
        "metrics":{
            "Word Error Rate (WER)":"2.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":112034,
            "title":"SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
            "url":"\/paper\/specaugment-a-simple-data-augmentation-method",
            "published":"2019-04-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/specaugment-a-simple-data-augmentation-method\/review\/?hl=111568"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11181,
        "rank":31,
        "Model":"Transformer",
        "mlmodel":{

        },
        "method_short":"Transformer",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-13",
        "metrics":{
            "Word Error Rate (WER)":"2.6"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":153553,
            "title":"A Comparative Study on Transformer vs RNN in Speech Applications",
            "url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in",
            "published":"2019-09-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-comparative-study-on-transformer-vs-rnn-in\/review\/?hl=11181"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":41295,
        "rank":32,
        "Model":"QuartzNet15x5",
        "mlmodel":{

        },
        "method_short":"QuartzNet15x5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-10-22",
        "metrics":{
            "Word Error Rate (WER)":"2.69"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.69
        },
        "uses_additional_data":false,
        "paper":{
            "id":195229,
            "title":"QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions",
            "url":"\/paper\/quartznet-deep-automatic-speech-recognition",
            "published":"2019-10-22T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11182,
        "rank":33,
        "Model":"LAS (no LM)",
        "mlmodel":{

        },
        "method_short":"LAS ",
        "method_details":"no LM",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-18",
        "metrics":{
            "Word Error Rate (WER)":"2.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":112034,
            "title":"SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
            "url":"\/paper\/specaugment-a-simple-data-augmentation-method",
            "published":"2019-04-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/specaugment-a-simple-data-augmentation-method\/review\/?hl=11182"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":26313,
        "rank":34,
        "Model":"wav2vec_wav2letter",
        "mlmodel":{

        },
        "method_short":"wav2vec_wav2letter",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-22",
        "metrics":{
            "Word Error Rate (WER)":"2.7"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":229991,
            "title":"Self-training and Pre-training are Complementary for Speech Recognition",
            "url":"\/paper\/self-training-and-pre-training-are",
            "published":"2020-10-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-training-and-pre-training-are\/review\/?hl=26313"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11183,
        "rank":35,
        "Model":"Espresso",
        "mlmodel":{

        },
        "method_short":"Espresso",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-18",
        "metrics":{
            "Word Error Rate (WER)":"2.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":154341,
            "title":"Espresso: A Fast End-to-end Neural Speech Recognition Toolkit",
            "url":"\/paper\/espresso-a-fast-end-to-end-neural-speech",
            "published":"2019-09-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/espresso-a-fast-end-to-end-neural-speech\/review\/?hl=11183"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11184,
        "rank":36,
        "Model":"Jasper DR 10x5 (+ Time\/Freq Masks)",
        "mlmodel":{

        },
        "method_short":"Jasper DR 10x5 ",
        "method_details":"+ Time\/Freq Masks",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-05",
        "metrics":{
            "Word Error Rate (WER)":"2.84"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.84
        },
        "uses_additional_data":false,
        "paper":{
            "id":110989,
            "title":"Jasper: An End-to-End Convolutional Neural Acoustic Model",
            "url":"\/paper\/jasper-an-end-to-end-convolutional-neural",
            "published":"2019-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/jasper-an-end-to-end-convolutional-neural\/review\/?hl=11184"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":11185,
        "rank":37,
        "Model":"Jasper DR 10x5",
        "mlmodel":{

        },
        "method_short":"Jasper DR 10x5",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-05",
        "metrics":{
            "Word Error Rate (WER)":"2.95"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":2.95
        },
        "uses_additional_data":false,
        "paper":{
            "id":110989,
            "title":"Jasper: An End-to-End Convolutional Neural Acoustic Model",
            "url":"\/paper\/jasper-an-end-to-end-convolutional-neural",
            "published":"2019-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/jasper-an-end-to-end-convolutional-neural\/review\/?hl=11185"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":4191,
        "rank":38,
        "Model":"tdnn + chain + rnnlm rescoring",
        "mlmodel":{

        },
        "method_short":"tdnn + chain + rnnlm rescoring",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-04-15",
        "metrics":{
            "Word Error Rate (WER)":"3.06"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.06
        },
        "uses_additional_data":false,
        "paper":{
            "id":106607,
            "title":"Neural Network Language Modeling with Letter-based Features and Importance Sampling",
            "url":"\/paper\/neural-network-language-modeling-with-letter",
            "published":"2018-04-15T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":4803,
        "rank":39,
        "Model":"Convolutional Speech Recognition",
        "mlmodel":{

        },
        "method_short":"Convolutional Speech Recognition",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-12-17",
        "metrics":{
            "Word Error Rate (WER)":"3.26"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.26
        },
        "uses_additional_data":false,
        "paper":{
            "id":65363,
            "title":"Fully Convolutional Speech Recognition",
            "url":"\/paper\/fully-convolutional-speech-recognition",
            "published":"2018-12-17T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/fully-convolutional-speech-recognition\/review\/?hl=4803"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":114767,
        "rank":40,
        "Model":"MT4SSL",
        "mlmodel":{

        },
        "method_short":"MT4SSL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-14",
        "metrics":{
            "Word Error Rate (WER)":"3.4"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1110528,
            "title":"MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets",
            "url":"\/paper\/mt4ssl-boosting-self-supervised-speech",
            "published":"2022-11-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mt4ssl-boosting-self-supervised-speech\/review\/?hl=114767"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":4804,
        "rank":41,
        "Model":"Model Unit Exploration",
        "mlmodel":{

        },
        "method_short":"Model Unit Exploration",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-02-05",
        "metrics":{
            "Word Error Rate (WER)":"3.60"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":105242,
            "title":"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition",
            "url":"\/paper\/model-unit-exploration-for-sequence-to",
            "published":"2019-02-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/model-unit-exploration-for-sequence-to\/review\/?hl=4804"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3401,
        "rank":42,
        "Model":"Seq-to-seq attention",
        "mlmodel":{

        },
        "method_short":"Seq-to-seq attention",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-05-08",
        "metrics":{
            "Word Error Rate (WER)":"3.82"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":3.82
        },
        "uses_additional_data":false,
        "paper":{
            "id":4233,
            "title":"Improved training of end-to-end attention models for speech recognition",
            "url":"\/paper\/improved-training-of-end-to-end-attention",
            "published":"2018-05-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-training-of-end-to-end-attention\/review\/?hl=3401"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":8,
                "name":"LSTM",
                "color":"#e60000"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":25149,
        "rank":43,
        "Model":"CTC-CRF 4gram-LM",
        "mlmodel":{

        },
        "method_short":"CTC-CRF 4gram-LM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-04-16",
        "metrics":{
            "Word Error Rate (WER)":"4.09"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.09
        },
        "uses_additional_data":false,
        "paper":{
            "id":742207,
            "title":"CRF-based Single-stage Acoustic Modeling with CTC Topology",
            "url":"\/paper\/crf-based-single-stage-acoustic-modeling-with",
            "published":"2019-04-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":434,
        "rank":44,
        "Model":"HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations",
        "mlmodel":{

        },
        "method_short":"HMM-TDNN trained with MMI + data augmentation ",
        "method_details":"speed",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Word Error Rate (WER)":"4.3"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":71,
                "name":"HMM",
                "color":"#e28e18"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":432,
        "rank":45,
        "Model":"HMM-TDNN + iVectors",
        "mlmodel":{

        },
        "method_short":"HMM-TDNN + iVectors",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Word Error Rate (WER)":"4.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":71,
                "name":"HMM",
                "color":"#e28e18"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3403,
        "rank":46,
        "Model":"Gated ConvNets",
        "mlmodel":{

        },
        "method_short":"Gated ConvNets",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-12-22",
        "metrics":{
            "Word Error Rate (WER)":"4.8"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":4.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":12618,
            "title":"Letter-Based Speech Recognition with Gated ConvNets",
            "url":"\/paper\/letter-based-speech-recognition-with-gated",
            "published":"2017-12-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/letter-based-speech-recognition-with-gated\/review\/?hl=3403"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3376,
        "rank":47,
        "Model":"Deep Speech 2",
        "mlmodel":{

        },
        "method_short":"Deep Speech 2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2015-12-08",
        "metrics":{
            "Word Error Rate (WER)":"5.33"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.33
        },
        "uses_additional_data":false,
        "paper":{
            "id":37158,
            "title":"Deep Speech 2: End-to-End Speech Recognition in English and Mandarin",
            "url":"\/paper\/deep-speech-2-end-to-end-speech-recognition",
            "published":"2015-12-08T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deep-speech-2-end-to-end-speech-recognition\/review\/?hl=3376"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3402,
        "rank":48,
        "Model":"CTC + policy learning",
        "mlmodel":{

        },
        "method_short":"CTC + policy learning",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-12-19",
        "metrics":{
            "Word Error Rate (WER)":"5.42"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.42
        },
        "uses_additional_data":false,
        "paper":{
            "id":12784,
            "title":"Improving End-to-End Speech Recognition with Policy Learning",
            "url":"\/paper\/improving-end-to-end-speech-recognition-with-1",
            "published":"2017-12-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/improving-end-to-end-speech-recognition-with-1\/review\/?hl=3402"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":431,
        "rank":49,
        "Model":"HMM-DNN + pNorm*",
        "mlmodel":{

        },
        "method_short":"HMM-DNN + pNorm*",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Word Error Rate (WER)":"5.5"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":5.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":71,
                "name":"HMM",
                "color":"#e28e18"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3399,
        "rank":50,
        "Model":"Li-GRU",
        "mlmodel":{

        },
        "method_short":"Li-GRU",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-11-19",
        "metrics":{
            "Word Error Rate (WER)":"6.2"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":62694,
            "title":"The PyTorch-Kaldi Speech Recognition Toolkit",
            "url":"\/paper\/the-pytorch-kaldi-speech-recognition-toolkit",
            "published":"2018-11-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/the-pytorch-kaldi-speech-recognition-toolkit\/review\/?hl=3399"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":3389,
        "rank":51,
        "Model":"Snips",
        "mlmodel":{

        },
        "method_short":"Snips",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-05-25",
        "metrics":{
            "Word Error Rate (WER)":"6.4"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":6.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":2556,
            "title":"Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces",
            "url":"\/paper\/snips-voice-platform-an-embedded-spoken",
            "published":"2018-05-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/snips-voice-platform-an-embedded-spoken\/review\/?hl=3389"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":10126,
        "rank":52,
        "Model":"Local Prior Matching (Large Model)",
        "mlmodel":{

        },
        "method_short":"Local Prior Matching ",
        "method_details":"Large Model",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-24",
        "metrics":{
            "Word Error Rate (WER)":"7.19"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":7.19
        },
        "uses_additional_data":false,
        "paper":{
            "id":184373,
            "title":"Semi-Supervised Speech Recognition via Local Prior Matching",
            "url":"\/paper\/semi-supervised-speech-recognition-via-local",
            "published":"2020-02-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":430,
        "rank":53,
        "Model":"HMM-(SAT)GMM",
        "mlmodel":{

        },
        "method_short":"HMM-",
        "method_details":"SAT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Word Error Rate (WER)":"8.0"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":8.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":71,
                "name":"HMM",
                "color":"#e28e18"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":107,
        "row_id":56336,
        "rank":54,
        "Model":"AmNet",
        "mlmodel":{

        },
        "method_short":"AmNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-08-03",
        "metrics":{
            "Word Error Rate (WER)":"8.6"
        },
        "raw_metrics":{
            "Word Error Rate (WER)":8.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":846182,
            "title":"Amortized Neural Networks for Low-Latency Speech Recognition",
            "url":"\/paper\/amortized-neural-networks-for-low-latency",
            "published":"2021-08-03T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/amortized-neural-networks-for-low-latency\/review\/?hl=56336"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]