[
    {
        "table_id":25753,
        "row_id":113743,
        "rank":1,
        "method":"ProViQ",
        "mlmodel":{

        },
        "Model":"ProViQ",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "Accuracy":"64.6"
        },
        "raw_metrics":{
            "Accuracy":64.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1335834,
            "title":"Zero-Shot Video Question Answering with Procedural Programs",
            "url":"\/paper\/zero-shot-video-question-answering-with",
            "published":"2023-12-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/zero-shot-video-question-answering-with\/review\/?hl=113743"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25753,
        "row_id":113100,
        "rank":2,
        "method":"Sevila",
        "mlmodel":{

        },
        "Model":"Sevila",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "Accuracy":"63.6"
        },
        "raw_metrics":{
            "Accuracy":63.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333248,
            "title":"Self-Chained Image-Language Model for Video Localization and Question Answering",
            "url":"\/paper\/self-chained-image-language-model-for-video-1",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25753,
        "row_id":112857,
        "rank":3,
        "method":"VideoChat2",
        "mlmodel":{

        },
        "Model":"VideoChat2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-28",
        "metrics":{
            "Accuracy":"61.7"
        },
        "raw_metrics":{
            "Accuracy":61.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1329478,
            "title":"MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
            "url":"\/paper\/mvbench-a-comprehensive-multi-modal-video",
            "published":"2023-11-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mvbench-a-comprehensive-multi-modal-video\/review\/?hl=112857"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25753,
        "row_id":113379,
        "rank":4,
        "method":"ViperGPT",
        "mlmodel":{

        },
        "Model":"ViperGPT",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-24",
        "metrics":{
            "Accuracy":"60.0"
        },
        "raw_metrics":{
            "Accuracy":60.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1163517,
            "title":"VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation",
            "url":"\/paper\/provably-efficient-neural-offline",
            "published":"2023-02-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/provably-efficient-neural-offline\/review\/?hl=113379"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25753,
        "row_id":112856,
        "rank":5,
        "method":"InternVideo",
        "mlmodel":{

        },
        "Model":"InternVideo",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-06",
        "metrics":{
            "Accuracy":"49.1"
        },
        "raw_metrics":{
            "Accuracy":49.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1124231,
            "title":"InternVideo: General Video Foundation Models via Generative and Discriminative Learning",
            "url":"\/paper\/internvideo-general-video-foundation-models",
            "published":"2022-12-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/internvideo-general-video-foundation-models\/review\/?hl=112856"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]