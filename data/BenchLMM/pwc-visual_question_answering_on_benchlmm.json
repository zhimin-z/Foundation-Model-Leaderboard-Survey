[
    {
        "table_id":25851,
        "row_id":113615,
        "rank":1,
        "Model":"GPT-4V",
        "mlmodel":{

        },
        "method_short":"GPT-4V",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "GPT-3.5 score":"58.37"
        },
        "raw_metrics":{
            "GPT-3.5 score":58.37
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=113615"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":114647,
        "rank":2,
        "Model":"Sphinx-V2-1K",
        "mlmodel":{

        },
        "method_short":"Sphinx-V2-1K",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-13",
        "metrics":{
            "GPT-3.5 score":"57.43"
        },
        "raw_metrics":{
            "GPT-3.5 score":57.43
        },
        "uses_additional_data":false,
        "paper":{
            "id":1319249,
            "title":"SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models",
            "url":"\/paper\/sphinx-the-joint-mixing-of-weights-tasks-and",
            "published":"2023-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/sphinx-the-joint-mixing-of-weights-tasks-and\/review\/?hl=114647"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113618,
        "rank":3,
        "Model":"LLaVA-1.5-13B",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-05",
        "metrics":{
            "GPT-3.5 score":"55.53"
        },
        "raw_metrics":{
            "GPT-3.5 score":55.53
        },
        "uses_additional_data":false,
        "paper":{
            "id":1293065,
            "title":"Improved Baselines with Visual Instruction Tuning",
            "url":"\/paper\/improved-baselines-with-visual-instruction",
            "published":"2023-10-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-visual-instruction\/review\/?hl=113618"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113622,
        "rank":4,
        "Model":"LLaVA-1.5-7B",
        "mlmodel":{

        },
        "method_short":"LLaVA-1.5-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-17",
        "metrics":{
            "GPT-3.5 score":"46.83"
        },
        "raw_metrics":{
            "GPT-3.5 score":46.83
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333505,
            "title":"Visual Instruction Tuning",
            "url":"\/paper\/visual-instruction-tuning-1",
            "published":"2023-04-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113619,
        "rank":5,
        "Model":"InstructBLIP-13B",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "GPT-3.5 score":"45.03"
        },
        "raw_metrics":{
            "GPT-3.5 score":45.03
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333348,
            "title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
            "url":"\/paper\/instructblip-towards-general-purpose-vision",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113623,
        "rank":6,
        "Model":"InstructBLIP-7B",
        "mlmodel":{

        },
        "method_short":"InstructBLIP-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-11",
        "metrics":{
            "GPT-3.5 score":"44.63"
        },
        "raw_metrics":{
            "GPT-3.5 score":44.63
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333348,
            "title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
            "url":"\/paper\/instructblip-towards-general-purpose-vision",
            "published":"2023-05-11T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113620,
        "rank":7,
        "Model":"LLaVA-1-13B",
        "mlmodel":{

        },
        "method_short":"LLaVA-1-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-17",
        "metrics":{
            "GPT-3.5 score":"43.50"
        },
        "raw_metrics":{
            "GPT-3.5 score":43.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333505,
            "title":"Visual Instruction Tuning",
            "url":"\/paper\/visual-instruction-tuning-1",
            "published":"2023-04-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113625,
        "rank":8,
        "Model":"Otter-7B",
        "mlmodel":{

        },
        "method_short":"Otter-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-05",
        "metrics":{
            "GPT-3.5 score":"39.13"
        },
        "raw_metrics":{
            "GPT-3.5 score":39.13
        },
        "uses_additional_data":false,
        "paper":{
            "id":1203116,
            "title":"Otter: A Multi-Modal Model with In-Context Instruction Tuning",
            "url":"\/paper\/otter-a-multi-modal-model-with-in-context",
            "published":"2023-05-05T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113621,
        "rank":9,
        "Model":"MiniGPT4-13B",
        "mlmodel":{

        },
        "method_short":"MiniGPT4-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-20",
        "metrics":{
            "GPT-3.5 score":"34.93"
        },
        "raw_metrics":{
            "GPT-3.5 score":34.93
        },
        "uses_additional_data":false,
        "paper":{
            "id":1195560,
            "title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
            "url":"\/paper\/minigpt-4-enhancing-vision-language",
            "published":"2023-04-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/minigpt-4-enhancing-vision-language\/review\/?hl=113621"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":25851,
        "row_id":113624,
        "rank":10,
        "Model":"MiniGPTv2-7B",
        "mlmodel":{

        },
        "method_short":"MiniGPTv2-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-14",
        "metrics":{
            "GPT-3.5 score":"30.1"
        },
        "raw_metrics":{
            "GPT-3.5 score":30.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1300879,
            "title":"MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning",
            "url":"\/paper\/minigpt-v2-large-language-model-as-a-unified",
            "published":"2023-10-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/minigpt-v2-large-language-model-as-a-unified\/review\/?hl=113624"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]