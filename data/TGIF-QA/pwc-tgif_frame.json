[
    {
        "table_id":16819,
        "row_id":103552,
        "rank":1,
        "method":"VLAB",
        "mlmodel":{

        },
        "Model":"VLAB",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-22",
        "metrics":{
            "Accuracy":"79.0"
        },
        "raw_metrics":{
            "Accuracy":79.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1212983,
            "title":"VLAB: Enhancing Video Language Pre-training by Feature Adapting and Blending",
            "url":"\/paper\/vlab-enhancing-video-language-pre-training-by",
            "published":"2023-05-22T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/vlab-enhancing-video-language-pre-training-by\/review\/?hl=103552"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":101418,
        "rank":2,
        "method":"VALOR",
        "mlmodel":{

        },
        "Model":"VALOR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-17",
        "metrics":{
            "Accuracy":"78.7"
        },
        "raw_metrics":{
            "Accuracy":78.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191887,
            "title":"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset",
            "url":"\/paper\/valor-vision-audio-language-omni-perception",
            "published":"2023-04-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/valor-vision-audio-language-omni-perception\/review\/?hl=101418"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":99058,
        "rank":3,
        "method":"MuLTI",
        "mlmodel":{

        },
        "Model":"MuLTI",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-10",
        "metrics":{
            "Accuracy":"75.6"
        },
        "raw_metrics":{
            "Accuracy":75.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1171789,
            "title":"MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler and Multiple Choice Modeling",
            "url":"\/paper\/multi-efficient-video-and-language",
            "published":"2023-03-10T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/multi-efficient-video-and-language\/review\/?hl=99058"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":96430,
        "rank":4,
        "method":"mPLUG-2",
        "mlmodel":{

        },
        "Model":"mPLUG-2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-01",
        "metrics":{
            "Accuracy":"75.4"
        },
        "raw_metrics":{
            "Accuracy":75.4
        },
        "uses_additional_data":true,
        "paper":{
            "id":1151002,
            "title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video",
            "url":"\/paper\/mplug-2-a-modularized-multi-modal-foundation",
            "published":"2023-02-01T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mplug-2-a-modularized-multi-modal-foundation\/review\/?hl=96430"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":88493,
        "rank":5,
        "method":"HiTeA",
        "mlmodel":{

        },
        "Model":"HiTeA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-30",
        "metrics":{
            "Accuracy":"73.2"
        },
        "raw_metrics":{
            "Accuracy":73.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":1136078,
            "title":"HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training",
            "url":"\/paper\/hitea-hierarchical-temporal-aware-video",
            "published":"2022-12-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/hitea-hierarchical-temporal-aware-video\/review\/?hl=88493"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":96088,
        "rank":6,
        "method":"VIOLETv2",
        "mlmodel":{

        },
        "Model":"VIOLETv2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-04",
        "metrics":{
            "Accuracy":"72.8"
        },
        "raw_metrics":{
            "Accuracy":72.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":1069338,
            "title":"An Empirical Study of End-to-End Video-Language Transformers with Masked Visual Modeling",
            "url":"\/paper\/an-empirical-study-of-end-to-end-video",
            "published":"2022-09-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-end-to-end-video\/review\/?hl=96088"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":88020,
        "rank":7,
        "method":"Clover",
        "mlmodel":{

        },
        "Model":"Clover",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-16",
        "metrics":{
            "Accuracy":"71.6"
        },
        "raw_metrics":{
            "Accuracy":71.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1045027,
            "title":"Clover: Towards A Unified Video-Language Alignment and Fusion Model",
            "url":"\/paper\/clover-towards-a-unified-video-language",
            "published":"2022-07-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/clover-towards-a-unified-video-language\/review\/?hl=88020"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":108841,
        "rank":8,
        "method":"FrozenBiLM+",
        "mlmodel":{

        },
        "Model":"FrozenBiLM+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"69.0"
        },
        "raw_metrics":{
            "Accuracy":69.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265311,
            "title":"Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models",
            "url":"\/paper\/open-vocabulary-video-question-answering-a",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/open-vocabulary-video-question-answering-a\/review\/?hl=108841"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":106341,
        "rank":9,
        "method":"LRCE",
        "mlmodel":{

        },
        "Model":"LRCE",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-06-30",
        "metrics":{
            "Accuracy":"68.8"
        },
        "raw_metrics":{
            "Accuracy":68.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1250520,
            "title":"Lightweight Recurrent Cross-modal Encoder for Video Question Answering",
            "url":"\/paper\/lightweight-recurrent-cross-modal-encoder-for",
            "published":"2023-06-30T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":70084,
        "rank":10,
        "method":"FrozenBiLM",
        "mlmodel":{

        },
        "Model":"FrozenBiLM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-16",
        "metrics":{
            "Accuracy":"68.6"
        },
        "raw_metrics":{
            "Accuracy":68.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1028387,
            "title":"Zero-Shot Video Question Answering via Frozen Bidirectional Language Models",
            "url":"\/paper\/zero-shot-video-question-answering-via-frozen",
            "published":"2022-06-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/zero-shot-video-question-answering-via-frozen\/review\/?hl=70084"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":108838,
        "rank":11,
        "method":"All-in-one+",
        "mlmodel":{

        },
        "Model":"All-in-one+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"66.0"
        },
        "raw_metrics":{
            "Accuracy":66.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265311,
            "title":"Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models",
            "url":"\/paper\/open-vocabulary-video-question-answering-a",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/open-vocabulary-video-question-answering-a\/review\/?hl=108838"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":108840,
        "rank":12,
        "method":"VIOLET+",
        "mlmodel":{

        },
        "Model":"VIOLET+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"65.3"
        },
        "raw_metrics":{
            "Accuracy":65.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265311,
            "title":"Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models",
            "url":"\/paper\/open-vocabulary-video-question-answering-a",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/open-vocabulary-video-question-answering-a\/review\/?hl=108840"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":52527,
        "rank":13,
        "method":"All-in-one-B",
        "mlmodel":{

        },
        "Model":"All-in-one-B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-14",
        "metrics":{
            "Accuracy":"64.2"
        },
        "raw_metrics":{
            "Accuracy":64.2
        },
        "uses_additional_data":true,
        "paper":{
            "id":976242,
            "title":"All in One: Exploring Unified Video-Language Pre-training",
            "url":"\/paper\/all-in-one-exploring-unified-video-language",
            "published":"2022-03-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/all-in-one-exploring-unified-video-language\/review\/?hl=52527"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":100001,
        "rank":14,
        "method":"VIOLET + MELTR",
        "mlmodel":{

        },
        "Model":"VIOLET + MELTR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-23",
        "metrics":{
            "Accuracy":"63.4"
        },
        "raw_metrics":{
            "Accuracy":63.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1179150,
            "title":"MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models",
            "url":"\/paper\/meltr-meta-loss-transformer-for-learning-to",
            "published":"2023-03-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/meltr-meta-loss-transformer-for-learning-to\/review\/?hl=100001"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":16819,
        "row_id":108839,
        "rank":15,
        "method":"JustAsk+",
        "mlmodel":{

        },
        "Model":"JustAsk+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "Accuracy":"57.4"
        },
        "raw_metrics":{
            "Accuracy":57.4
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265311,
            "title":"Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models",
            "url":"\/paper\/open-vocabulary-video-question-answering-a",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/open-vocabulary-video-question-answering-a\/review\/?hl=108839"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]