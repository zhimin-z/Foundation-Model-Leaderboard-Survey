[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.981081081081081",
        "Coherence":"3",
        "Factuality":"2.9756756756756757",
        "Comprehensiveness":"2.997297297297297",
        "Overall":"4.962162162162162"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.9945945945945946",
        "Coherence":"3",
        "Factuality":"2.997297297297297",
        "Comprehensiveness":"3",
        "Overall":"4.991891891891892"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.5594594594594593",
        "Coherence":"2.9324324324324325",
        "Factuality":"2.8135135135135134",
        "Comprehensiveness":"2.3324324324324324",
        "Overall":"3.845945945945946"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.8189189189189188",
        "Coherence":"2.9891891891891893",
        "Factuality":"2.937837837837838",
        "Comprehensiveness":"2.537837837837838",
        "Overall":"4.3432432432432435"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8945945945945946",
        "Coherence":"3",
        "Factuality":"2.9675675675675675",
        "Comprehensiveness":"2.627027027027027",
        "Overall":"4.5162162162162165"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.381081081081081",
        "Coherence":"2.7432432432432434",
        "Factuality":"2.6864864864864866",
        "Comprehensiveness":"2.016216216216216",
        "Overall":"3.4486486486486485"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.4675675675675675",
        "Coherence":"2.962162162162162",
        "Factuality":"2.8513513513513513",
        "Comprehensiveness":"2.0837837837837836",
        "Overall":"3.572972972972973"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.427027027027027",
        "Coherence":"2.9297297297297296",
        "Factuality":"2.7054054054054055",
        "Comprehensiveness":"2.1324324324324326",
        "Overall":"3.5432432432432432"
    }
]