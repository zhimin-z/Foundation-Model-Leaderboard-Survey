[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9810810811,
        "Coherence":3.0,
        "Factuality":2.9756756757,
        "Comprehensiveness":2.9972972973,
        "Overall":4.9621621622
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9945945946,
        "Coherence":3.0,
        "Factuality":2.9972972973,
        "Comprehensiveness":3.0,
        "Overall":4.9918918919
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5594594595,
        "Coherence":2.9324324324,
        "Factuality":2.8135135135,
        "Comprehensiveness":2.3324324324,
        "Overall":3.8459459459
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8189189189,
        "Coherence":2.9891891892,
        "Factuality":2.9378378378,
        "Comprehensiveness":2.5378378378,
        "Overall":4.3432432432
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8945945946,
        "Coherence":3.0,
        "Factuality":2.9675675676,
        "Comprehensiveness":2.627027027,
        "Overall":4.5162162162
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3810810811,
        "Coherence":2.7432432432,
        "Factuality":2.6864864865,
        "Comprehensiveness":2.0162162162,
        "Overall":3.4486486486
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4675675676,
        "Coherence":2.9621621622,
        "Factuality":2.8513513514,
        "Comprehensiveness":2.0837837838,
        "Overall":3.572972973
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.427027027,
        "Coherence":2.9297297297,
        "Factuality":2.7054054054,
        "Comprehensiveness":2.1324324324,
        "Overall":3.5432432432
    }
]