[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9805825243,
        "Coherence":3.0,
        "Factuality":2.9805825243,
        "Comprehensiveness":2.9961165049,
        "Overall":4.9660194175
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9990291262,
        "Coherence":3.0,
        "Factuality":2.9961165049,
        "Comprehensiveness":3.0,
        "Overall":4.9941747573
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.6019417476,
        "Coherence":2.9097087379,
        "Factuality":2.8165048544,
        "Comprehensiveness":2.2922330097,
        "Overall":3.8834951456
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8485436893,
        "Coherence":2.9902912621,
        "Factuality":2.9339805825,
        "Comprehensiveness":2.5339805825,
        "Overall":4.3708737864
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.913592233,
        "Coherence":2.9961165049,
        "Factuality":2.9708737864,
        "Comprehensiveness":2.613592233,
        "Overall":4.5223300971
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.4330097087,
        "Coherence":2.7747572816,
        "Factuality":2.7504854369,
        "Comprehensiveness":2.0553398058,
        "Overall":3.5330097087
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4961165049,
        "Coherence":2.9601941748,
        "Factuality":2.8922330097,
        "Comprehensiveness":2.0621359223,
        "Overall":3.6155339806
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4990291262,
        "Coherence":2.9233009709,
        "Factuality":2.8174757282,
        "Comprehensiveness":2.1155339806,
        "Overall":3.6359223301
    }
]