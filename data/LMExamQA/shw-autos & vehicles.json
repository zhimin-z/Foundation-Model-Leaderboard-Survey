[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9714285714285715",
        "Coherence":"3",
        "Factuality":"2.966666666666667",
        "Comprehensiveness":"2.9952380952380953",
        "Overall":"4.942857142857143"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.9904761904761905",
        "Coherence":"3",
        "Factuality":"2.992857142857143",
        "Comprehensiveness":"3",
        "Overall":"4.985714285714286"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.480952380952381",
        "Coherence":"2.933333333333333",
        "Factuality":"2.6476190476190475",
        "Comprehensiveness":"2.3285714285714287",
        "Overall":"3.761904761904762"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.776190476190476",
        "Coherence":"2.9857142857142858",
        "Factuality":"2.895238095238095",
        "Comprehensiveness":"2.526190476190476",
        "Overall":"4.295238095238095"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.888095238095238",
        "Coherence":"2.9952380952380953",
        "Factuality":"2.9404761904761907",
        "Comprehensiveness":"2.619047619047619",
        "Overall":"4.5"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.335714285714286",
        "Coherence":"2.783333333333333",
        "Factuality":"2.6809523809523808",
        "Comprehensiveness":"2.0404761904761903",
        "Overall":"3.4095238095238094"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.466666666666667",
        "Coherence":"2.9404761904761907",
        "Factuality":"2.788095238095238",
        "Comprehensiveness":"2.1476190476190475",
        "Overall":"3.6666666666666665"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.4452380952380954",
        "Coherence":"2.926190476190476",
        "Factuality":"2.7023809523809526",
        "Comprehensiveness":"2.1904761904761907",
        "Overall":"3.6357142857142857"
    }
]