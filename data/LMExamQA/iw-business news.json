[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9583333333,
        "Coherence":3.0,
        "Factuality":2.9583333333,
        "Comprehensiveness":2.9666666667,
        "Overall":4.925
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":4.9916666667
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5666666667,
        "Coherence":2.95,
        "Factuality":2.7583333333,
        "Comprehensiveness":2.3416666667,
        "Overall":3.875
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8166666667,
        "Coherence":3.0,
        "Factuality":2.8916666667,
        "Comprehensiveness":2.525,
        "Overall":4.2916666667
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8833333333,
        "Coherence":3.0,
        "Factuality":2.9416666667,
        "Comprehensiveness":2.5416666667,
        "Overall":4.4083333333
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3583333333,
        "Coherence":2.75,
        "Factuality":2.6666666667,
        "Comprehensiveness":2.0166666667,
        "Overall":3.4416666667
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.35,
        "Coherence":2.9333333333,
        "Factuality":2.7833333333,
        "Comprehensiveness":2.0833333333,
        "Overall":3.4416666667
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4833333333,
        "Coherence":2.9083333333,
        "Factuality":2.7166666667,
        "Comprehensiveness":2.1166666667,
        "Overall":3.5833333333
    }
]