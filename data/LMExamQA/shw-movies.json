[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9307692307692306",
        "Coherence":"3",
        "Factuality":"2.9384615384615387",
        "Comprehensiveness":"3",
        "Overall":"4.9"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.9923076923076923",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"4.992307692307692"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.353846153846154",
        "Coherence":"2.876923076923077",
        "Factuality":"2.6",
        "Comprehensiveness":"2.246153846153846",
        "Overall":"3.5153846153846153"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.753846153846154",
        "Coherence":"2.9846153846153847",
        "Factuality":"2.9076923076923076",
        "Comprehensiveness":"2.5",
        "Overall":"4.230769230769231"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8692307692307693",
        "Coherence":"3",
        "Factuality":"2.9615384615384617",
        "Comprehensiveness":"2.6076923076923078",
        "Overall":"4.461538461538462"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.269230769230769",
        "Coherence":"2.6846153846153844",
        "Factuality":"2.6384615384615384",
        "Comprehensiveness":"2.0615384615384613",
        "Overall":"3.3076923076923075"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.4",
        "Coherence":"2.9692307692307693",
        "Factuality":"2.7153846153846155",
        "Comprehensiveness":"2.076923076923077",
        "Overall":"3.423076923076923"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.2384615384615385",
        "Coherence":"2.9076923076923076",
        "Factuality":"2.5615384615384613",
        "Comprehensiveness":"2.046153846153846",
        "Overall":"3.207692307692308"
    }
]