[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.914285714285714",
        "Coherence":"3",
        "Factuality":"2.9",
        "Comprehensiveness":"2.9857142857142858",
        "Overall":"4.8428571428571425"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.9571428571428573",
        "Coherence":"3",
        "Factuality":"2.9571428571428573",
        "Comprehensiveness":"3",
        "Overall":"4.928571428571429"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.4285714285714284",
        "Coherence":"2.9571428571428573",
        "Factuality":"2.5142857142857142",
        "Comprehensiveness":"2.3142857142857145",
        "Overall":"3.7"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.6285714285714286",
        "Coherence":"2.9714285714285715",
        "Factuality":"2.7857142857142856",
        "Comprehensiveness":"2.4714285714285715",
        "Overall":"4.057142857142857"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8285714285714287",
        "Coherence":"3",
        "Factuality":"2.8857142857142857",
        "Comprehensiveness":"2.585714285714286",
        "Overall":"4.414285714285715"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.142857142857143",
        "Coherence":"2.6857142857142855",
        "Factuality":"2.5285714285714285",
        "Comprehensiveness":"1.8",
        "Overall":"3.0428571428571427"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.3857142857142857",
        "Coherence":"2.9285714285714284",
        "Factuality":"2.742857142857143",
        "Comprehensiveness":"2.1857142857142855",
        "Overall":"3.585714285714286"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.157142857142857",
        "Coherence":"2.9714285714285715",
        "Factuality":"2.5285714285714285",
        "Comprehensiveness":"1.9428571428571428",
        "Overall":"3.1714285714285713"
    }
]