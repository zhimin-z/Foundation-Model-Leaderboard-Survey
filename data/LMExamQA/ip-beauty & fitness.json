[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9913043478,
        "Coherence":3.0,
        "Factuality":2.9913043478,
        "Comprehensiveness":3.0,
        "Overall":4.9826086957
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5260869565,
        "Coherence":2.9434782609,
        "Factuality":2.747826087,
        "Comprehensiveness":2.2869565217,
        "Overall":3.7913043478
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.852173913,
        "Coherence":2.9956521739,
        "Factuality":2.9173913043,
        "Comprehensiveness":2.5695652174,
        "Overall":4.4173913043
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8826086957,
        "Coherence":3.0,
        "Factuality":2.9391304348,
        "Comprehensiveness":2.652173913,
        "Overall":4.5260869565
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.4347826087,
        "Coherence":2.752173913,
        "Factuality":2.7608695652,
        "Comprehensiveness":2.0913043478,
        "Overall":3.5608695652
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5260869565,
        "Coherence":2.9347826087,
        "Factuality":2.8565217391,
        "Comprehensiveness":2.1043478261,
        "Overall":3.7086956522
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5652173913,
        "Coherence":2.9391304348,
        "Factuality":2.8173913043,
        "Comprehensiveness":2.2043478261,
        "Overall":3.7652173913
    }
]