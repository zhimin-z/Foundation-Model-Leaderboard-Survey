[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9639534884,
        "Coherence":2.9988372093,
        "Factuality":2.9593023256,
        "Comprehensiveness":2.9953488372,
        "Overall":4.9290697674
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9941860465,
        "Coherence":3.0,
        "Factuality":2.9930232558,
        "Comprehensiveness":3.0,
        "Overall":4.9872093023
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.488372093,
        "Coherence":2.9093023256,
        "Factuality":2.7255813953,
        "Comprehensiveness":2.273255814,
        "Overall":3.7197674419
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.788372093,
        "Coherence":2.9930232558,
        "Factuality":2.9093023256,
        "Comprehensiveness":2.4813953488,
        "Overall":4.2523255814
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.873255814,
        "Coherence":2.9976744186,
        "Factuality":2.9476744186,
        "Comprehensiveness":2.5906976744,
        "Overall":4.4511627907
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3244186047,
        "Coherence":2.7569767442,
        "Factuality":2.6837209302,
        "Comprehensiveness":2.0279069767,
        "Overall":3.3546511628
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4476744186,
        "Coherence":2.9418604651,
        "Factuality":2.8244186047,
        "Comprehensiveness":2.0848837209,
        "Overall":3.5441860465
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4151162791,
        "Coherence":2.9279069767,
        "Factuality":2.7290697674,
        "Comprehensiveness":2.1174418605,
        "Overall":3.523255814
    }
]