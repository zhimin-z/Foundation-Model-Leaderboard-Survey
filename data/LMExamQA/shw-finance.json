[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9909090909090907",
        "Coherence":"3",
        "Factuality":"2.9909090909090907",
        "Comprehensiveness":"3",
        "Overall":"4.986363636363636"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"5"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.518181818181818",
        "Coherence":"2.868181818181818",
        "Factuality":"2.7045454545454546",
        "Comprehensiveness":"2.2818181818181817",
        "Overall":"3.768181818181818"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.840909090909091",
        "Coherence":"2.9909090909090907",
        "Factuality":"2.9318181818181817",
        "Comprehensiveness":"2.6636363636363636",
        "Overall":"4.495454545454545"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.909090909090909",
        "Coherence":"2.9909090909090907",
        "Factuality":"2.9727272727272727",
        "Comprehensiveness":"2.7409090909090907",
        "Overall":"4.6454545454545455"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.4681818181818183",
        "Coherence":"2.8954545454545455",
        "Factuality":"2.8363636363636364",
        "Comprehensiveness":"2.1227272727272726",
        "Overall":"3.659090909090909"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.4727272727272727",
        "Coherence":"2.9727272727272727",
        "Factuality":"2.8863636363636362",
        "Comprehensiveness":"2.1136363636363638",
        "Overall":"3.6772727272727272"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.4863636363636363",
        "Coherence":"2.9045454545454548",
        "Factuality":"2.790909090909091",
        "Comprehensiveness":"2.1454545454545455",
        "Overall":"3.6818181818181817"
    }
]