[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.8933333333333335",
        "Coherence":"3",
        "Factuality":"2.8766666666666665",
        "Comprehensiveness":"2.9766666666666666",
        "Overall":"4.793333333333333"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.986666666666667",
        "Coherence":"3",
        "Factuality":"2.986666666666667",
        "Comprehensiveness":"3",
        "Overall":"4.976666666666667"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.4266666666666667",
        "Coherence":"2.9133333333333336",
        "Factuality":"2.64",
        "Comprehensiveness":"2.25",
        "Overall":"3.6333333333333333"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.6966666666666668",
        "Coherence":"2.97",
        "Factuality":"2.83",
        "Comprehensiveness":"2.47",
        "Overall":"4.133333333333334"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8333333333333335",
        "Coherence":"2.986666666666667",
        "Factuality":"2.9366666666666665",
        "Comprehensiveness":"2.566666666666667",
        "Overall":"4.386666666666667"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.1766666666666667",
        "Coherence":"2.7066666666666666",
        "Factuality":"2.526666666666667",
        "Comprehensiveness":"1.94",
        "Overall":"3.15"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.3866666666666667",
        "Coherence":"2.9766666666666666",
        "Factuality":"2.776666666666667",
        "Comprehensiveness":"2.1",
        "Overall":"3.47"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.3466666666666667",
        "Coherence":"2.933333333333333",
        "Factuality":"2.6866666666666665",
        "Comprehensiveness":"2.09",
        "Overall":"3.4133333333333336"
    }
]