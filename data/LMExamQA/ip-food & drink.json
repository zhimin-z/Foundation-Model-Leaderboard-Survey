[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9727272727,
        "Coherence":3.0,
        "Factuality":2.9681818182,
        "Comprehensiveness":2.9909090909,
        "Overall":4.9409090909
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9954545455,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":2.9954545455,
        "Overall":4.9909090909
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5,
        "Coherence":2.9090909091,
        "Factuality":2.6727272727,
        "Comprehensiveness":2.3181818182,
        "Overall":3.8045454545
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8136363636,
        "Coherence":2.9909090909,
        "Factuality":2.8909090909,
        "Comprehensiveness":2.5363636364,
        "Overall":4.3409090909
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8545454545,
        "Coherence":3.0,
        "Factuality":2.9363636364,
        "Comprehensiveness":2.6136363636,
        "Overall":4.4681818182
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3545454545,
        "Coherence":2.7363636364,
        "Factuality":2.6363636364,
        "Comprehensiveness":2.0318181818,
        "Overall":3.4363636364
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4818181818,
        "Coherence":2.95,
        "Factuality":2.7863636364,
        "Comprehensiveness":2.1772727273,
        "Overall":3.7181818182
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4454545455,
        "Coherence":2.9318181818,
        "Factuality":2.7,
        "Comprehensiveness":2.2090909091,
        "Overall":3.65
    }
]