[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9678571429,
        "Coherence":3.0,
        "Factuality":2.9607142857,
        "Comprehensiveness":3.0,
        "Overall":4.9321428571
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9928571429,
        "Coherence":3.0,
        "Factuality":2.9928571429,
        "Comprehensiveness":3.0,
        "Overall":4.9857142857
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.4857142857,
        "Coherence":2.9107142857,
        "Factuality":2.7142857143,
        "Comprehensiveness":2.3357142857,
        "Overall":3.7678571429
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.825,
        "Coherence":2.9928571429,
        "Factuality":2.9178571429,
        "Comprehensiveness":2.5928571429,
        "Overall":4.3964285714
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8892857143,
        "Coherence":3.0,
        "Factuality":2.9428571429,
        "Comprehensiveness":2.6892857143,
        "Overall":4.55
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.45,
        "Coherence":2.7821428571,
        "Factuality":2.75,
        "Comprehensiveness":2.1071428571,
        "Overall":3.5892857143
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5071428571,
        "Coherence":2.9821428571,
        "Factuality":2.8892857143,
        "Comprehensiveness":2.1214285714,
        "Overall":3.6535714286
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4678571429,
        "Coherence":2.9214285714,
        "Factuality":2.7535714286,
        "Comprehensiveness":2.1821428571,
        "Overall":3.6178571429
    }
]