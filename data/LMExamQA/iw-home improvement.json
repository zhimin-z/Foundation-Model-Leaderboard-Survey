[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9857142857,
        "Coherence":3.0,
        "Factuality":2.9857142857,
        "Comprehensiveness":3.0,
        "Overall":4.9714285714
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5571428571,
        "Coherence":2.8857142857,
        "Factuality":2.7142857143,
        "Comprehensiveness":2.4,
        "Overall":3.9142857143
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.7428571429,
        "Coherence":2.9571428571,
        "Factuality":2.8571428571,
        "Comprehensiveness":2.4857142857,
        "Overall":4.2142857143
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8428571429,
        "Coherence":2.9714285714,
        "Factuality":2.9714285714,
        "Comprehensiveness":2.5285714286,
        "Overall":4.3857142857
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3142857143,
        "Coherence":2.6285714286,
        "Factuality":2.6714285714,
        "Comprehensiveness":2.0142857143,
        "Overall":3.3571428571
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5,
        "Coherence":2.9428571429,
        "Factuality":2.8857142857,
        "Comprehensiveness":2.1714285714,
        "Overall":3.7571428571
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4857142857,
        "Coherence":2.9142857143,
        "Factuality":2.8142857143,
        "Comprehensiveness":2.2285714286,
        "Overall":3.7
    }
]