[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9666666667,
        "Coherence":3.0,
        "Factuality":2.9619047619,
        "Comprehensiveness":2.9904761905,
        "Overall":4.9380952381
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":2.9952380952,
        "Overall":4.9952380952
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5952380952,
        "Coherence":2.9,
        "Factuality":2.8285714286,
        "Comprehensiveness":2.3380952381,
        "Overall":3.8857142857
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8857142857,
        "Coherence":2.9904761905,
        "Factuality":2.9619047619,
        "Comprehensiveness":2.6095238095,
        "Overall":4.4904761905
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9476190476,
        "Coherence":3.0,
        "Factuality":2.9952380952,
        "Comprehensiveness":2.6714285714,
        "Overall":4.6142857143
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.5142857143,
        "Coherence":2.8333333333,
        "Factuality":2.8238095238,
        "Comprehensiveness":2.1238095238,
        "Overall":3.6714285714
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5285714286,
        "Coherence":2.980952381,
        "Factuality":2.9285714286,
        "Comprehensiveness":2.1047619048,
        "Overall":3.6952380952
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5761904762,
        "Coherence":2.9428571429,
        "Factuality":2.8476190476,
        "Comprehensiveness":2.219047619,
        "Overall":3.8142857143
    }
]