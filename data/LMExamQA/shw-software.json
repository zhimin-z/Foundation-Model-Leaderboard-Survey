[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9916666666666667",
        "Coherence":"3",
        "Factuality":"2.9833333333333334",
        "Comprehensiveness":"2.9916666666666667",
        "Overall":"4.975"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"2.9916666666666667",
        "Comprehensiveness":"3",
        "Overall":"4.991666666666666"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.5833333333333335",
        "Coherence":"2.8833333333333333",
        "Factuality":"2.808333333333333",
        "Comprehensiveness":"2.325",
        "Overall":"3.85"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.85",
        "Coherence":"2.9916666666666667",
        "Factuality":"2.933333333333333",
        "Comprehensiveness":"2.5833333333333335",
        "Overall":"4.425"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.9",
        "Coherence":"3",
        "Factuality":"2.95",
        "Comprehensiveness":"2.566666666666667",
        "Overall":"4.466666666666667"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.341666666666667",
        "Coherence":"2.691666666666667",
        "Factuality":"2.6416666666666666",
        "Comprehensiveness":"1.9916666666666667",
        "Overall":"3.4"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.4833333333333334",
        "Coherence":"2.9583333333333335",
        "Factuality":"2.8333333333333335",
        "Comprehensiveness":"2.1",
        "Overall":"3.6083333333333334"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.5416666666666665",
        "Coherence":"2.9166666666666665",
        "Factuality":"2.8333333333333335",
        "Comprehensiveness":"2.158333333333333",
        "Overall":"3.691666666666667"
    }
]