[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9666666667,
        "Coherence":3.0,
        "Factuality":2.98,
        "Comprehensiveness":2.99,
        "Overall":4.94
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5666666667,
        "Coherence":2.92,
        "Factuality":2.7733333333,
        "Comprehensiveness":2.3433333333,
        "Overall":3.88
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.86,
        "Coherence":2.9866666667,
        "Factuality":2.94,
        "Comprehensiveness":2.5766666667,
        "Overall":4.4233333333
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9233333333,
        "Coherence":3.0,
        "Factuality":2.9633333333,
        "Comprehensiveness":2.6733333333,
        "Overall":4.5733333333
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.4066666667,
        "Coherence":2.8066666667,
        "Factuality":2.7333333333,
        "Comprehensiveness":2.0166666667,
        "Overall":3.4866666667
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.54,
        "Coherence":2.9766666667,
        "Factuality":2.88,
        "Comprehensiveness":2.0966666667,
        "Overall":3.6933333333
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.52,
        "Coherence":2.95,
        "Factuality":2.7766666667,
        "Comprehensiveness":2.22,
        "Overall":3.7266666667
    }
]