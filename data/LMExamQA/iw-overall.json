[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9696665471,
        "Coherence":2.9996414485,
        "Factuality":2.9670491215,
        "Comprehensiveness":2.993832915,
        "Overall":4.9404446038
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9951237003,
        "Coherence":3.0,
        "Factuality":2.9941914665,
        "Comprehensiveness":2.9990319111,
        "Overall":4.9892434564
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5214413768,
        "Coherence":2.9125493008,
        "Factuality":2.7319110792,
        "Comprehensiveness":2.2930082467,
        "Overall":3.7864109
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8057726784,
        "Coherence":2.9892793116,
        "Factuality":2.9060236644,
        "Comprehensiveness":2.5439225529,
        "Overall":4.3334887056
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8828612406,
        "Coherence":2.9960917892,
        "Factuality":2.9487629975,
        "Comprehensiveness":2.6321262101,
        "Overall":4.5035138042
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.349874507,
        "Coherence":2.7381857297,
        "Factuality":2.6803155253,
        "Comprehensiveness":2.0269630692,
        "Overall":3.4155969882
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.465937612,
        "Coherence":2.9601290785,
        "Factuality":2.8423449265,
        "Comprehensiveness":2.0860882037,
        "Overall":3.596055934
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4579060595,
        "Coherence":2.9254930082,
        "Factuality":2.7500896379,
        "Comprehensiveness":2.1526353532,
        "Overall":3.6118321979
    }
]