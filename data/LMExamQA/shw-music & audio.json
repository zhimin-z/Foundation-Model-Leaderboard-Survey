[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.95,
        "Coherence":3.0,
        "Factuality":2.9333333333,
        "Comprehensiveness":2.9916666667,
        "Overall":4.8833333333
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9916666667,
        "Coherence":3.0,
        "Factuality":2.9916666667,
        "Comprehensiveness":3.0,
        "Overall":4.9833333333
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.45,
        "Coherence":2.9083333333,
        "Factuality":2.625,
        "Comprehensiveness":2.25,
        "Overall":3.5916666667
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.7083333333,
        "Coherence":3.0,
        "Factuality":2.825,
        "Comprehensiveness":2.4083333333,
        "Overall":4.0833333333
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8416666667,
        "Coherence":2.9916666667,
        "Factuality":2.925,
        "Comprehensiveness":2.525,
        "Overall":4.3583333333
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3083333333,
        "Coherence":2.775,
        "Factuality":2.6833333333,
        "Comprehensiveness":1.9583333333,
        "Overall":3.275
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.3666666667,
        "Coherence":2.9166666667,
        "Factuality":2.7833333333,
        "Comprehensiveness":2.0166666667,
        "Overall":3.3583333333
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.325,
        "Coherence":2.9083333333,
        "Factuality":2.6416666667,
        "Comprehensiveness":2.0166666667,
        "Overall":3.3333333333
    }
]