[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.95",
        "Coherence":"3",
        "Factuality":"2.933333333333333",
        "Comprehensiveness":"2.9916666666666667",
        "Overall":"4.883333333333334"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.9916666666666667",
        "Coherence":"3",
        "Factuality":"2.9916666666666667",
        "Comprehensiveness":"3",
        "Overall":"4.983333333333333"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.45",
        "Coherence":"2.908333333333333",
        "Factuality":"2.625",
        "Comprehensiveness":"2.25",
        "Overall":"3.591666666666667"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.7083333333333335",
        "Coherence":"3",
        "Factuality":"2.825",
        "Comprehensiveness":"2.408333333333333",
        "Overall":"4.083333333333333"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.841666666666667",
        "Coherence":"2.9916666666666667",
        "Factuality":"2.925",
        "Comprehensiveness":"2.525",
        "Overall":"4.358333333333333"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.308333333333333",
        "Coherence":"2.775",
        "Factuality":"2.683333333333333",
        "Comprehensiveness":"1.9583333333333333",
        "Overall":"3.275"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.3666666666666667",
        "Coherence":"2.9166666666666665",
        "Factuality":"2.783333333333333",
        "Comprehensiveness":"2.0166666666666666",
        "Overall":"3.3583333333333334"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.325",
        "Coherence":"2.908333333333333",
        "Factuality":"2.6416666666666666",
        "Comprehensiveness":"2.0166666666666666",
        "Overall":"3.3333333333333335"
    }
]