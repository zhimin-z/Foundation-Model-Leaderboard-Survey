[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9777777778,
        "Coherence":3.0,
        "Factuality":2.9777777778,
        "Comprehensiveness":2.9888888889,
        "Overall":4.9666666667
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5111111111,
        "Coherence":2.8888888889,
        "Factuality":2.8222222222,
        "Comprehensiveness":2.3222222222,
        "Overall":3.7888888889
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8444444444,
        "Coherence":3.0,
        "Factuality":2.9666666667,
        "Comprehensiveness":2.6222222222,
        "Overall":4.4777777778
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8888888889,
        "Coherence":3.0,
        "Factuality":2.9555555556,
        "Comprehensiveness":2.6444444444,
        "Overall":4.5222222222
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3777777778,
        "Coherence":2.7333333333,
        "Factuality":2.7,
        "Comprehensiveness":2.0222222222,
        "Overall":3.4444444444
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4888888889,
        "Coherence":2.9666666667,
        "Factuality":2.8444444444,
        "Comprehensiveness":2.1444444444,
        "Overall":3.6222222222
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5,
        "Coherence":2.9444444444,
        "Factuality":2.7888888889,
        "Comprehensiveness":2.2333333333,
        "Overall":3.7444444444
    }
]