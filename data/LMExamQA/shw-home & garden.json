[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.983783783783784",
        "Coherence":"3",
        "Factuality":"2.9756756756756757",
        "Comprehensiveness":"3",
        "Overall":"4.962162162162162"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.997297297297297",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"4.9972972972972975"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.5054054054054054",
        "Coherence":"2.8945945945945946",
        "Factuality":"2.7054054054054055",
        "Comprehensiveness":"2.3162162162162163",
        "Overall":"3.7756756756756755"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.810810810810811",
        "Coherence":"2.9891891891891893",
        "Factuality":"2.9054054054054053",
        "Comprehensiveness":"2.6",
        "Overall":"4.383783783783784"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8864864864864863",
        "Coherence":"2.9945945945945946",
        "Factuality":"2.9513513513513514",
        "Comprehensiveness":"2.6243243243243244",
        "Overall":"4.5"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.327027027027027",
        "Coherence":"2.645945945945946",
        "Factuality":"2.6972972972972973",
        "Comprehensiveness":"2.0108108108108107",
        "Overall":"3.354054054054054"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.5675675675675675",
        "Coherence":"2.964864864864865",
        "Factuality":"2.8972972972972975",
        "Comprehensiveness":"2.1837837837837837",
        "Overall":"3.7864864864864867"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.581081081081081",
        "Coherence":"2.927027027027027",
        "Factuality":"2.843243243243243",
        "Comprehensiveness":"2.245945945945946",
        "Overall":"3.8054054054054056"
    }
]