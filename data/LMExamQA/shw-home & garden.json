[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9837837838,
        "Coherence":3.0,
        "Factuality":2.9756756757,
        "Comprehensiveness":3.0,
        "Overall":4.9621621622
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9972972973,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":4.9972972973
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5054054054,
        "Coherence":2.8945945946,
        "Factuality":2.7054054054,
        "Comprehensiveness":2.3162162162,
        "Overall":3.7756756757
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8108108108,
        "Coherence":2.9891891892,
        "Factuality":2.9054054054,
        "Comprehensiveness":2.6,
        "Overall":4.3837837838
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8864864865,
        "Coherence":2.9945945946,
        "Factuality":2.9513513514,
        "Comprehensiveness":2.6243243243,
        "Overall":4.5
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.327027027,
        "Coherence":2.6459459459,
        "Factuality":2.6972972973,
        "Comprehensiveness":2.0108108108,
        "Overall":3.3540540541
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5675675676,
        "Coherence":2.9648648649,
        "Factuality":2.8972972973,
        "Comprehensiveness":2.1837837838,
        "Overall":3.7864864865
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5810810811,
        "Coherence":2.927027027,
        "Factuality":2.8432432432,
        "Comprehensiveness":2.2459459459,
        "Overall":3.8054054054
    }
]