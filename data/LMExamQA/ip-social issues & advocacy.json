[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9833333333,
        "Coherence":3.0,
        "Factuality":2.9916666667,
        "Comprehensiveness":3.0,
        "Overall":4.975
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9916666667,
        "Coherence":3.0,
        "Factuality":2.9916666667,
        "Comprehensiveness":3.0,
        "Overall":4.9833333333
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.6583333333,
        "Coherence":2.9666666667,
        "Factuality":2.9,
        "Comprehensiveness":2.375,
        "Overall":4.025
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.875,
        "Coherence":3.0,
        "Factuality":2.975,
        "Comprehensiveness":2.575,
        "Overall":4.4333333333
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9083333333,
        "Coherence":3.0,
        "Factuality":2.9583333333,
        "Comprehensiveness":2.7,
        "Overall":4.6
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3666666667,
        "Coherence":2.6833333333,
        "Factuality":2.6583333333,
        "Comprehensiveness":2.025,
        "Overall":3.425
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.425,
        "Coherence":2.9916666667,
        "Factuality":2.8416666667,
        "Comprehensiveness":2.0083333333,
        "Overall":3.4833333333
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5416666667,
        "Coherence":2.9833333333,
        "Factuality":2.8416666667,
        "Comprehensiveness":2.1833333333,
        "Overall":3.7083333333
    }
]