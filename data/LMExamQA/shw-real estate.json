[
    {
        "Model":"Vicuna-13B",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.6,
        "Coherence":2.8555555556,
        "Factuality":2.8333333333,
        "Comprehensiveness":2.3222222222,
        "Overall":3.8888888889
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.9111111111,
        "Coherence":2.9888888889,
        "Factuality":2.9888888889,
        "Comprehensiveness":2.5888888889,
        "Overall":4.5
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9444444444,
        "Coherence":3.0,
        "Factuality":2.9888888889,
        "Comprehensiveness":2.7333333333,
        "Overall":4.6777777778
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3666666667,
        "Coherence":2.7222222222,
        "Factuality":2.6777777778,
        "Comprehensiveness":2.0,
        "Overall":3.4222222222
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5111111111,
        "Coherence":2.9777777778,
        "Factuality":2.9333333333,
        "Comprehensiveness":2.0888888889,
        "Overall":3.6555555556
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5888888889,
        "Coherence":2.9111111111,
        "Factuality":2.8777777778,
        "Comprehensiveness":2.2,
        "Overall":3.8333333333
    }
]