[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"5"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"5"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.6",
        "Coherence":"2.8555555555555556",
        "Factuality":"2.8333333333333335",
        "Comprehensiveness":"2.3222222222222224",
        "Overall":"3.888888888888889"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.911111111111111",
        "Coherence":"2.988888888888889",
        "Factuality":"2.988888888888889",
        "Comprehensiveness":"2.588888888888889",
        "Overall":"4.5"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.9444444444444446",
        "Coherence":"3",
        "Factuality":"2.988888888888889",
        "Comprehensiveness":"2.7333333333333334",
        "Overall":"4.677777777777778"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.3666666666666667",
        "Coherence":"2.7222222222222223",
        "Factuality":"2.6777777777777776",
        "Comprehensiveness":"2",
        "Overall":"3.422222222222222"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.511111111111111",
        "Coherence":"2.977777777777778",
        "Factuality":"2.933333333333333",
        "Comprehensiveness":"2.088888888888889",
        "Overall":"3.6555555555555554"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.588888888888889",
        "Coherence":"2.911111111111111",
        "Factuality":"2.8777777777777778",
        "Comprehensiveness":"2.2",
        "Overall":"3.8333333333333335"
    }
]