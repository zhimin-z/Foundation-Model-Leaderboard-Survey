[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.7333333333333334",
        "Coherence":"3",
        "Factuality":"2.7",
        "Comprehensiveness":"2.966666666666667",
        "Overall":"4.566666666666666"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.966666666666667",
        "Coherence":"3",
        "Factuality":"2.966666666666667",
        "Comprehensiveness":"3",
        "Overall":"4.933333333333334"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.2",
        "Coherence":"2.966666666666667",
        "Factuality":"2.3666666666666667",
        "Comprehensiveness":"2.2",
        "Overall":"3.3333333333333335"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.433333333333333",
        "Coherence":"3",
        "Factuality":"2.6",
        "Comprehensiveness":"2.4",
        "Overall":"3.7"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.6333333333333333",
        "Coherence":"2.9",
        "Factuality":"2.7333333333333334",
        "Comprehensiveness":"2.3666666666666667",
        "Overall":"3.933333333333333"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"1.9",
        "Coherence":"2.466666666666667",
        "Factuality":"2.2666666666666666",
        "Comprehensiveness":"1.8",
        "Overall":"2.7333333333333334"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.033333333333333",
        "Coherence":"2.966666666666667",
        "Factuality":"2.5",
        "Comprehensiveness":"1.9666666666666666",
        "Overall":"2.966666666666667"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"1.9666666666666666",
        "Coherence":"2.933333333333333",
        "Factuality":"2.3333333333333335",
        "Comprehensiveness":"1.8333333333333333",
        "Overall":"2.8333333333333335"
    }
]