[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9785714285714286",
        "Coherence":"3",
        "Factuality":"2.9785714285714286",
        "Comprehensiveness":"2.992857142857143",
        "Overall":"4.957142857142857"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"2.992857142857143",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"3",
        "Overall":"4.992857142857143"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.5357142857142856",
        "Coherence":"2.9714285714285715",
        "Factuality":"2.807142857142857",
        "Comprehensiveness":"2.2357142857142858",
        "Overall":"3.7857142857142856"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.7928571428571427",
        "Coherence":"2.992857142857143",
        "Factuality":"2.95",
        "Comprehensiveness":"2.4857142857142858",
        "Overall":"4.264285714285714"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.8857142857142857",
        "Coherence":"3",
        "Factuality":"2.9642857142857144",
        "Comprehensiveness":"2.65",
        "Overall":"4.5285714285714285"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.3214285714285716",
        "Coherence":"2.75",
        "Factuality":"2.664285714285714",
        "Comprehensiveness":"1.9428571428571428",
        "Overall":"3.3142857142857145"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.407142857142857",
        "Coherence":"2.9785714285714286",
        "Factuality":"2.842857142857143",
        "Comprehensiveness":"1.95",
        "Overall":"3.3785714285714286"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.3",
        "Coherence":"2.9214285714285713",
        "Factuality":"2.6785714285714284",
        "Comprehensiveness":"1.9928571428571429",
        "Overall":"3.3285714285714287"
    }
]