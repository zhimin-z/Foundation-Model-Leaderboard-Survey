[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9892307692,
        "Coherence":2.9984615385,
        "Factuality":2.9892307692,
        "Comprehensiveness":2.9969230769,
        "Overall":4.9784615385
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9953846154,
        "Coherence":3.0,
        "Factuality":2.9953846154,
        "Comprehensiveness":2.9984615385,
        "Overall":4.9923076923
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.6784615385,
        "Coherence":2.96,
        "Factuality":2.8015384615,
        "Comprehensiveness":2.3953846154,
        "Overall":4.0646153846
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8646153846,
        "Coherence":2.9923076923,
        "Factuality":2.9323076923,
        "Comprehensiveness":2.6569230769,
        "Overall":4.5153846154
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9261538462,
        "Coherence":2.9938461538,
        "Factuality":2.9661538462,
        "Comprehensiveness":2.7153846154,
        "Overall":4.6353846154
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.4846153846,
        "Coherence":2.7861538462,
        "Factuality":2.7523076923,
        "Comprehensiveness":2.1046153846,
        "Overall":3.6307692308
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5584615385,
        "Coherence":2.9615384615,
        "Factuality":2.8846153846,
        "Comprehensiveness":2.1046153846,
        "Overall":3.74
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5338461538,
        "Coherence":2.9292307692,
        "Factuality":2.7584615385,
        "Comprehensiveness":2.2092307692,
        "Overall":3.7430769231
    }
]