[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9833333333333334",
        "Coherence":"3",
        "Factuality":"2.9833333333333334",
        "Comprehensiveness":"3",
        "Overall":"4.966666666666667"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"2.9833333333333334",
        "Comprehensiveness":"3",
        "Overall":"4.983333333333333"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.45",
        "Coherence":"2.933333333333333",
        "Factuality":"2.6166666666666667",
        "Comprehensiveness":"2.2",
        "Overall":"3.6666666666666665"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.783333333333333",
        "Coherence":"3",
        "Factuality":"2.9166666666666665",
        "Comprehensiveness":"2.4166666666666665",
        "Overall":"4.216666666666667"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.933333333333333",
        "Coherence":"3",
        "Factuality":"2.966666666666667",
        "Comprehensiveness":"2.65",
        "Overall":"4.583333333333333"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.25",
        "Coherence":"2.8",
        "Factuality":"2.683333333333333",
        "Comprehensiveness":"1.9666666666666666",
        "Overall":"3.3"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.4833333333333334",
        "Coherence":"2.9833333333333334",
        "Factuality":"2.8",
        "Comprehensiveness":"2.1166666666666667",
        "Overall":"3.6"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.4",
        "Coherence":"2.966666666666667",
        "Factuality":"2.5833333333333335",
        "Comprehensiveness":"2.1166666666666667",
        "Overall":"3.533333333333333"
    }
]