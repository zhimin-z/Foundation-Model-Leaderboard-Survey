[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9923076923,
        "Coherence":3.0,
        "Factuality":2.9923076923,
        "Comprehensiveness":3.0,
        "Overall":4.9846153846
    },
    {
        "Model":"ChatGPT",
        "Accuracy":3.0,
        "Coherence":3.0,
        "Factuality":3.0,
        "Comprehensiveness":3.0,
        "Overall":5.0
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5846153846,
        "Coherence":2.8769230769,
        "Factuality":2.7769230769,
        "Comprehensiveness":2.3461538462,
        "Overall":3.9307692308
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8,
        "Coherence":2.9846153846,
        "Factuality":2.9461538462,
        "Comprehensiveness":2.5615384615,
        "Overall":4.3461538462
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.9,
        "Coherence":3.0,
        "Factuality":2.9615384615,
        "Comprehensiveness":2.6923076923,
        "Overall":4.5846153846
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.1923076923,
        "Coherence":2.6076923077,
        "Factuality":2.6769230769,
        "Comprehensiveness":1.8923076923,
        "Overall":3.2153846154
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.5307692308,
        "Coherence":2.9769230769,
        "Factuality":2.8307692308,
        "Comprehensiveness":2.1769230769,
        "Overall":3.7538461538
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.5846153846,
        "Coherence":2.9615384615,
        "Factuality":2.8538461538,
        "Comprehensiveness":2.2461538462,
        "Overall":3.8846153846
    }
]