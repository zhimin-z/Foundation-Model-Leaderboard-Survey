[
    {
        "Model":"Vicuna-13B",
        "Accuracy":"2.9703703703703703",
        "Coherence":"3",
        "Factuality":"2.9703703703703703",
        "Comprehensiveness":"2.9925925925925925",
        "Overall":"4.948148148148148"
    },
    {
        "Model":"ChatGPT",
        "Accuracy":"3",
        "Coherence":"3",
        "Factuality":"3",
        "Comprehensiveness":"2.9962962962962965",
        "Overall":"4.996296296296296"
    },
    {
        "Model":"GLM-130B",
        "Accuracy":"2.574074074074074",
        "Coherence":"2.903703703703704",
        "Factuality":"2.837037037037037",
        "Comprehensiveness":"2.3074074074074074",
        "Overall":"3.848148148148148"
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":"2.8777777777777778",
        "Coherence":"2.988888888888889",
        "Factuality":"2.966666666666667",
        "Comprehensiveness":"2.6",
        "Overall":"4.477777777777778"
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":"2.9518518518518517",
        "Coherence":"3",
        "Factuality":"2.9962962962962965",
        "Comprehensiveness":"2.6703703703703705",
        "Overall":"4.618518518518519"
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":"2.477777777777778",
        "Coherence":"2.8185185185185184",
        "Factuality":"2.8444444444444446",
        "Comprehensiveness":"2.085185185185185",
        "Overall":"3.611111111111111"
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":"2.5481481481481483",
        "Coherence":"2.9814814814814814",
        "Factuality":"2.9444444444444446",
        "Comprehensiveness":"2.1148148148148147",
        "Overall":"3.7185185185185183"
    },
    {
        "Model":"Flan-T5",
        "Accuracy":"2.574074074074074",
        "Coherence":"2.925925925925926",
        "Factuality":"2.8666666666666667",
        "Comprehensiveness":"2.2111111111111112",
        "Overall":"3.803703703703704"
    }
]