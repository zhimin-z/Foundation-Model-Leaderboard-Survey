[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9816326531,
        "Coherence":3.0,
        "Factuality":2.9897959184,
        "Comprehensiveness":2.987755102,
        "Overall":4.9653061224
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9959183673,
        "Coherence":3.0,
        "Factuality":2.9959183673,
        "Comprehensiveness":2.9959183673,
        "Overall":4.9918367347
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.5326530612,
        "Coherence":2.8959183673,
        "Factuality":2.7326530612,
        "Comprehensiveness":2.2979591837,
        "Overall":3.8285714286
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.8204081633,
        "Coherence":2.9857142857,
        "Factuality":2.9040816327,
        "Comprehensiveness":2.5734693878,
        "Overall":4.3897959184
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8836734694,
        "Coherence":2.9959183673,
        "Factuality":2.9551020408,
        "Comprehensiveness":2.6673469388,
        "Overall":4.5469387755
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.3897959184,
        "Coherence":2.7551020408,
        "Factuality":2.6897959184,
        "Comprehensiveness":2.0897959184,
        "Overall":3.512244898
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.4571428571,
        "Coherence":2.9632653061,
        "Factuality":2.8632653061,
        "Comprehensiveness":2.0530612245,
        "Overall":3.5857142857
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.4448979592,
        "Coherence":2.9387755102,
        "Factuality":2.7367346939,
        "Comprehensiveness":2.1530612245,
        "Overall":3.6346938776
    }
]