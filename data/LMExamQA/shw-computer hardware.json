[
    {
        "Model":"Vicuna-13B",
        "Accuracy":2.9307692308,
        "Coherence":3.0,
        "Factuality":2.9307692308,
        "Comprehensiveness":2.9923076923,
        "Overall":4.8692307692
    },
    {
        "Model":"ChatGPT",
        "Accuracy":2.9923076923,
        "Coherence":3.0,
        "Factuality":2.9846153846,
        "Comprehensiveness":3.0,
        "Overall":4.9769230769
    },
    {
        "Model":"GLM-130B",
        "Accuracy":2.4230769231,
        "Coherence":2.8846153846,
        "Factuality":2.6153846154,
        "Comprehensiveness":2.2769230769,
        "Overall":3.6307692308
    },
    {
        "Model":"LLaMA-13B",
        "Accuracy":2.7230769231,
        "Coherence":2.9846153846,
        "Factuality":2.8153846154,
        "Comprehensiveness":2.5384615385,
        "Overall":4.2
    },
    {
        "Model":"LLaMA-65B",
        "Accuracy":2.8461538462,
        "Coherence":3.0,
        "Factuality":2.9,
        "Comprehensiveness":2.6615384615,
        "Overall":4.4307692308
    },
    {
        "Model":"BLOOMZ",
        "Accuracy":2.2076923077,
        "Coherence":2.6615384615,
        "Factuality":2.5692307692,
        "Comprehensiveness":1.9230769231,
        "Overall":3.2076923077
    },
    {
        "Model":"Flan-UL2",
        "Accuracy":2.3769230769,
        "Coherence":2.9692307692,
        "Factuality":2.7307692308,
        "Comprehensiveness":2.0,
        "Overall":3.3692307692
    },
    {
        "Model":"Flan-T5",
        "Accuracy":2.3615384615,
        "Coherence":2.9153846154,
        "Factuality":2.6153846154,
        "Comprehensiveness":2.1769230769,
        "Overall":3.4923076923
    }
]