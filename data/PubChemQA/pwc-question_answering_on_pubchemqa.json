[
    {
        "table_id":24910,
        "row_id":108177,
        "rank":1,
        "Model":"BioMedGPT-10B",
        "mlmodel":{

        },
        "method_short":"BioMedGPT-10B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-18",
        "metrics":{
            "BLEU-2":"0.234",
            "BLEU-4":"0.141",
            "ROUGE-1":"0.386",
            "ROUGE-2":"0.206",
            "ROUGE-L":"0.332",
            "MEATOR":"0.308"
        },
        "raw_metrics":{
            "BLEU-2":0.234,
            "BLEU-4":0.141,
            "ROUGE-1":0.386,
            "ROUGE-2":0.206,
            "ROUGE-L":0.332,
            "MEATOR":0.308
        },
        "uses_additional_data":false,
        "paper":{
            "id":1265550,
            "title":"BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine",
            "url":"\/paper\/biomedgpt-open-multimodal-generative-pre",
            "published":"2023-08-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/biomedgpt-open-multimodal-generative-pre\/review\/?hl=108177"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":24910,
        "row_id":108178,
        "rank":2,
        "Model":"Llama2-7B-chat",
        "mlmodel":{

        },
        "method_short":"Llama2-7B-chat",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-18",
        "metrics":{
            "BLEU-2":"0.075",
            "BLEU-4":"0.009",
            "ROUGE-1":"0.184",
            "ROUGE-2":"0.043",
            "ROUGE-L":"0.142",
            "MEATOR":"0.149"
        },
        "raw_metrics":{
            "BLEU-2":0.075,
            "BLEU-4":0.009,
            "ROUGE-1":0.184,
            "ROUGE-2":0.043,
            "ROUGE-L":0.142,
            "MEATOR":0.149
        },
        "uses_additional_data":false,
        "paper":{
            "id":1248363,
            "title":"Llama 2: Open Foundation and Fine-Tuned Chat Models",
            "url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat",
            "published":"2023-07-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat\/review\/?hl=108178"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":467,
                "name":"commercially available",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    }
]