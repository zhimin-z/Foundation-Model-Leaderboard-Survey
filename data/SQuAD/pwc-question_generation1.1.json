[
    {
        "table_id":1253,
        "row_id":17153,
        "rank":1,
        "method":"ERNIE-GENLARGE (beam size=5)",
        "mlmodel":{

        },
        "method_short":"ERNIE-GENLARGE ",
        "method_details":"beam size=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-01-26",
        "metrics":{
            "BLEU-4":"25.41",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":25.41,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":181520,
            "title":"ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation",
            "url":"\/paper\/ernie-gen-an-enhanced-multi-flow-pre-training",
            "published":"2020-01-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ernie-gen-an-enhanced-multi-flow-pre-training\/review\/?hl=17153"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":88416,
        "rank":2,
        "method":"BART (TextBox 2.0)",
        "mlmodel":{

        },
        "method_short":"BART ",
        "method_details":"TextBox 2.0",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-26",
        "metrics":{
            "BLEU-4":"25.08",
            "METEOR":"26.73",
            "ROUGE-L":"52.55"
        },
        "raw_metrics":{
            "BLEU-4":25.08,
            "METEOR":26.73,
            "ROUGE-L":52.55
        },
        "uses_additional_data":false,
        "paper":{
            "id":1134528,
            "title":"TextBox 2.0: A Text Generation Library with Pre-trained Language Models",
            "url":"\/paper\/textbox-2-0-a-text-generation-library-with",
            "published":"2022-12-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/textbox-2-0-a-text-generation-library-with\/review\/?hl=88416"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":39101,
        "rank":3,
        "method":"ProphetNet + ASGen",
        "mlmodel":{

        },
        "method_short":"ProphetNet + ASGen",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-01",
        "metrics":{
            "BLEU-4":"24.44",
            "METEOR":"26.73",
            "ROUGE-L":"52.8"
        },
        "raw_metrics":{
            "BLEU-4":24.44,
            "METEOR":26.73,
            "ROUGE-L":52.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":224429,
            "title":"Learning to Generate Questions by Recovering Answer-containing Sentences",
            "url":"\/paper\/learning-to-generate-questions-by-recovering",
            "published":"2021-01-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":16986,
        "rank":4,
        "method":"UniLMv2",
        "mlmodel":{

        },
        "method_short":"UniLMv2",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-28",
        "metrics":{
            "BLEU-4":"24.43",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":24.43,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":185201,
            "title":"UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training",
            "url":"\/paper\/unilmv2-pseudo-masked-language-models-for",
            "published":"2020-02-28T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":97320,
        "rank":5,
        "method":"ProphetNet + syn. mask + localness",
        "mlmodel":{

        },
        "method_short":"ProphetNet + syn. mask + localness",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-09",
        "metrics":{
            "BLEU-4":"24.37",
            "METEOR":"26.26",
            "ROUGE-L":"52.77"
        },
        "raw_metrics":{
            "BLEU-4":24.37,
            "METEOR":26.26,
            "ROUGE-L":52.77
        },
        "uses_additional_data":false,
        "paper":{
            "id":1072000,
            "title":"Enhancing Pre-trained Models with Text Structure Knowledge for Question Generation",
            "url":"\/paper\/enhancing-pre-trained-models-with-text",
            "published":"2022-09-09T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/enhancing-pre-trained-models-with-text\/review\/?hl=97320"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":10350,
        "rank":6,
        "method":"ProphetNet",
        "mlmodel":{

        },
        "method_short":"ProphetNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-01-13",
        "metrics":{
            "BLEU-4":"23.91",
            "METEOR":"26.6",
            "ROUGE-L":"52.3"
        },
        "raw_metrics":{
            "BLEU-4":23.91,
            "METEOR":26.6,
            "ROUGE-L":52.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":179556,
            "title":"ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training",
            "url":"\/paper\/prophetnet-predicting-future-n-gram-for",
            "published":"2020-01-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/prophetnet-predicting-future-n-gram-for\/review\/?hl=10350"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":96580,
        "rank":7,
        "method":"UniLM + ASGen",
        "mlmodel":{

        },
        "method_short":"UniLM + ASGen",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-01-01",
        "metrics":{
            "BLEU-4":"23.7",
            "METEOR":"25.9",
            "ROUGE-L":"52.3"
        },
        "raw_metrics":{
            "BLEU-4":23.7,
            "METEOR":25.9,
            "ROUGE-L":52.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":224429,
            "title":"Learning to Generate Questions by Recovering Answer-containing Sentences",
            "url":"\/paper\/learning-to-generate-questions-by-recovering",
            "published":"2021-01-01T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":8025,
        "rank":8,
        "method":"UniLM",
        "mlmodel":{

        },
        "method_short":"UniLM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-08",
        "metrics":{
            "BLEU-4":"22.78",
            "METEOR":"25.1",
            "ROUGE-L":"51.1"
        },
        "raw_metrics":{
            "BLEU-4":22.78,
            "METEOR":25.1,
            "ROUGE-L":51.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":113932,
            "title":"Unified Language Model Pre-training for Natural Language Understanding and Generation",
            "url":"\/paper\/unified-language-model-pre-training-for",
            "published":"2019-05-08T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":77303,
        "rank":9,
        "method":"BERTSQG",
        "mlmodel":{

        },
        "method_short":"BERTSQG",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-01",
        "metrics":{
            "BLEU-4":"22.17",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":22.17,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":167783,
            "title":"A Recurrent BERT-based Model for Question Generation",
            "url":"\/paper\/a-recurrent-bert-based-model-for-question",
            "published":"2019-11-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":6703,
        "rank":10,
        "method":"Selector & NQG++",
        "mlmodel":{

        },
        "method_short":"Selector & NQG++",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-09-03",
        "metrics":{
            "BLEU-4":"15.874",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":15.874,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":152245,
            "title":"Mixture Content Selection for Diverse Sequence Generation",
            "url":"\/paper\/mixture-content-selection-for-diverse",
            "published":"2019-09-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mixture-content-selection-for-diverse\/review\/?hl=6703"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":10985,
        "rank":11,
        "method":"MPQG",
        "mlmodel":{

        },
        "method_short":"MPQG",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-06-01",
        "metrics":{
            "BLEU-4":"13.91",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":13.91,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":68497,
            "title":"Leveraging Context Information for Natural Question Generation",
            "url":"\/paper\/leveraging-context-information-for-natural",
            "published":"2018-06-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":9454,
        "rank":12,
        "method":"RNN +attn +copy",
        "mlmodel":{

        },
        "method_short":"RNN +attn +copy",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-01",
        "metrics":{
            "BLEU-4":"13.5",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":13.5,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":107212,
            "title":"Evaluating Rewards for Question Generation Models",
            "url":"\/paper\/evaluating-rewards-for-question-generation",
            "published":"2019-02-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/evaluating-rewards-for-question-generation\/review\/?hl=9454"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1253,
        "row_id":6704,
        "rank":13,
        "method":"NQG++",
        "mlmodel":{

        },
        "method_short":"NQG++",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2017-04-06",
        "metrics":{
            "BLEU-4":"13.27",
            "METEOR":null,
            "ROUGE-L":null
        },
        "raw_metrics":{
            "BLEU-4":13.27,
            "METEOR":null,
            "ROUGE-L":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":23960,
            "title":"Neural Question Generation from Text: A Preliminary Study",
            "url":"\/paper\/neural-question-generation-from-text-a",
            "published":"2017-04-06T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/neural-question-generation-from-text-a\/review\/?hl=6704"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]