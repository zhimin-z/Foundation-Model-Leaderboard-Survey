[
    {
        "T":"\ud83d\udcac",
        "Model":"abacusai\/Smaug-72B-v0.1",
        "Average":75.6,
        "ENEM":77.82,
        "BLUEX":68.29,
        "OAB Exams":58.77,
        "ASSIN2 RTE":92.96,
        "ASSIN2 STS":81.79,
        "FAQUAD NLI":77.47,
        "HateBR":85.65,
        "PT Hate Speech":65.31,
        "tweetSentBR":72.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":72.29,
        "Hub":410,
        "Model sha":"a1d657156f82c24b670158406378648233487011",
        "Evaluation Time (s)":63777.96,
        "Leaderboard Average":80.48,
        "NPM (Average)":62.92
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-72B-Chat",
        "Average":74.32,
        "ENEM":77.05,
        "BLUEX":67.59,
        "OAB Exams":55.31,
        "ASSIN2 RTE":92.8,
        "ASSIN2 STS":78.2,
        "FAQUAD NLI":79.48,
        "HateBR":86.84,
        "PT Hate Speech":62.59,
        "tweetSentBR":68.98,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":72.0,
        "Hub":150,
        "Model sha":"96a2df029f0045547ee55cfc8b925b2cac4353e5",
        "Evaluation Time (s)":17508.24,
        "Leaderboard Average":65.98,
        "NPM (Average)":61.3
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-72B",
        "Average":74.24,
        "ENEM":78.24,
        "BLUEX":68.43,
        "OAB Exams":60.32,
        "ASSIN2 RTE":92.88,
        "ASSIN2 STS":80.03,
        "FAQUAD NLI":78.4,
        "HateBR":87.64,
        "PT Hate Speech":51.7,
        "tweetSentBR":70.53,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":72.29,
        "Hub":312,
        "Model sha":"6dae9c86d4f42c3be60ffb525f784ee1991605cb",
        "Evaluation Time (s)":16495.36,
        "Leaderboard Average":73.6,
        "NPM (Average)":60.44
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-14B-Chat",
        "Average":72.59,
        "ENEM":69.84,
        "BLUEX":60.78,
        "OAB Exams":48.43,
        "ASSIN2 RTE":93.22,
        "ASSIN2 STS":78.09,
        "FAQUAD NLI":78.86,
        "HateBR":83.29,
        "PT Hate Speech":71.29,
        "tweetSentBR":69.5,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":14.17,
        "Hub":0,
        "Model sha":"519cfcc93dc11a4f470138d800b4987484e70677",
        "Evaluation Time (s)":4551.3,
        "Leaderboard Average":null,
        "NPM (Average)":59.41
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Yi-34B",
        "Average":72.42,
        "ENEM":73.13,
        "BLUEX":65.79,
        "OAB Exams":55.99,
        "ASSIN2 RTE":92.15,
        "ASSIN2 STS":79.85,
        "FAQUAD NLI":76.05,
        "HateBR":77.04,
        "PT Hate Speech":66.08,
        "tweetSentBR":65.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":34.39,
        "Hub":194,
        "Model sha":"fcb0a8847e76aea14aba9aa44009d4418ad7c18f",
        "Evaluation Time (s)":53412.74,
        "Leaderboard Average":73.74,
        "NPM (Average)":57.96
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-SOLAR-10.7B",
        "Average":71.63,
        "ENEM":70.75,
        "BLUEX":56.05,
        "OAB Exams":47.7,
        "ASSIN2 RTE":91.78,
        "ASSIN2 STS":79.7,
        "FAQUAD NLI":80.09,
        "HateBR":85.07,
        "PT Hate Speech":67.23,
        "tweetSentBR":66.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":10.73,
        "Hub":0,
        "Model sha":"14c1fbe2f71acdcd58247b30d5439bd572d52386",
        "Evaluation Time (s)":38715.39,
        "Leaderboard Average":null,
        "NPM (Average)":57.87
    },
    {
        "T":"\ud83d\udcac",
        "Model":"01-ai\/Yi-34B-Chat",
        "Average":70.76,
        "ENEM":71.24,
        "BLUEX":63.28,
        "OAB Exams":52.03,
        "ASSIN2 RTE":92.4,
        "ASSIN2 STS":74.19,
        "FAQUAD NLI":71.57,
        "HateBR":71.98,
        "PT Hate Speech":71.35,
        "tweetSentBR":68.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":34.39,
        "Hub":290,
        "Model sha":"099f03d1482e74cd1acb40d6c91c98824a594e12",
        "Evaluation Time (s)":22785.73,
        "Leaderboard Average":65.32,
        "NPM (Average)":55.78
    },
    {
        "T":"\ud83d\udcac",
        "Model":"internlm\/internlm2-chat-7b",
        "Average":69.81,
        "ENEM":61.79,
        "BLUEX":51.18,
        "OAB Exams":42.46,
        "ASSIN2 RTE":91.01,
        "ASSIN2 STS":82.55,
        "FAQUAD NLI":78.26,
        "HateBR":88.12,
        "PT Hate Speech":71.42,
        "tweetSentBR":61.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.0,
        "Hub":0,
        "Model sha":"f7dc28191037a297c086b5b70c6a226e2134e46d",
        "Evaluation Time (s)":16125.16,
        "Leaderboard Average":null,
        "NPM (Average)":55.7
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mistralai\/Mixtral-8x7B-Instruct-v0.1",
        "Average":69.71,
        "ENEM":71.31,
        "BLUEX":59.81,
        "OAB Exams":49.57,
        "ASSIN2 RTE":61.76,
        "ASSIN2 STS":82.74,
        "FAQUAD NLI":80.09,
        "HateBR":78.49,
        "PT Hate Speech":73.13,
        "tweetSentBR":70.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":46.7,
        "Hub":3320,
        "Model sha":"125c431e2ff41a156b9f9076f744d2f35dd6e67a",
        "Evaluation Time (s)":16579.94,
        "Leaderboard Average":72.62,
        "NPM (Average)":52.91
    },
    {
        "T":"\ud83d\udcac",
        "Model":"upstage\/SOLAR-10.7B-Instruct-v1.0",
        "Average":69.47,
        "ENEM":68.23,
        "BLUEX":58.28,
        "OAB Exams":46.06,
        "ASSIN2 RTE":92.77,
        "ASSIN2 STS":81.67,
        "FAQUAD NLI":75.43,
        "HateBR":80.39,
        "PT Hate Speech":69.13,
        "tweetSentBR":53.23,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"cc-by-nc-4.0",
        "#Params (B)":10.73,
        "Hub":538,
        "Model sha":"cd8ae35fb366b089e13377a1cc03d656cc775314",
        "Evaluation Time (s)":22998.28,
        "Leaderboard Average":74.2,
        "NPM (Average)":54.28
    },
    {
        "T":"\ud83d\udd36",
        "Model":"internlm\/internlm2-20b",
        "Average":69.42,
        "ENEM":68.23,
        "BLUEX":57.72,
        "OAB Exams":47.02,
        "ASSIN2 RTE":90.15,
        "ASSIN2 STS":82.56,
        "FAQUAD NLI":64.54,
        "HateBR":75.94,
        "PT Hate Speech":70.14,
        "tweetSentBR":68.48,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":20.0,
        "Hub":31,
        "Model sha":"e907218c93c47558942c969478319e908947e97b",
        "Evaluation Time (s)":9542.84,
        "Leaderboard Average":69.75,
        "NPM (Average)":53.38
    },
    {
        "T":"\ud83d\udcac",
        "Model":"FuseAI\/OpenChat-3.5-7B-Solar",
        "Average":69.04,
        "ENEM":64.52,
        "BLUEX":54.66,
        "OAB Exams":42.19,
        "ASSIN2 RTE":92.77,
        "ASSIN2 STS":78.23,
        "FAQUAD NLI":77.78,
        "HateBR":82.23,
        "PT Hate Speech":70.22,
        "tweetSentBR":58.78,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":7,
        "Model sha":"fb752742c8079d96925008a5f1371c08a1128f4f",
        "Evaluation Time (s)":7438.89,
        "Leaderboard Average":66.46,
        "NPM (Average)":54.33
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Average":68.87,
        "ENEM":69.49,
        "BLUEX":58.97,
        "OAB Exams":48.66,
        "ASSIN2 RTE":91.85,
        "ASSIN2 STS":78.27,
        "FAQUAD NLI":65.18,
        "HateBR":89.29,
        "PT Hate Speech":54.99,
        "tweetSentBR":63.13,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":10.73,
        "Hub":204,
        "Model sha":"399afd2ff676489c2712feb0f92286a77b8d0cd5",
        "Evaluation Time (s)":5202.34,
        "Leaderboard Average":66.04,
        "NPM (Average)":52.86
    },
    {
        "T":"\ud83d\udcac",
        "Model":"openchat\/openchat-3.5-0106",
        "Average":68.69,
        "ENEM":64.38,
        "BLUEX":52.71,
        "OAB Exams":44.87,
        "ASSIN2 RTE":92.73,
        "ASSIN2 STS":83.17,
        "FAQUAD NLI":79.21,
        "HateBR":79.31,
        "PT Hate Speech":71.88,
        "tweetSentBR":50.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":241,
        "Model sha":"9619fb7d2a8e25fa6b0633c0f57f7f4aa79b45c4",
        "Evaluation Time (s)":4417.12,
        "Leaderboard Average":69.3,
        "NPM (Average)":53.51
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-14B",
        "Average":68.22,
        "ENEM":58.71,
        "BLUEX":45.62,
        "OAB Exams":44.92,
        "ASSIN2 RTE":90.75,
        "ASSIN2 STS":75.19,
        "FAQUAD NLI":74.76,
        "HateBR":87.47,
        "PT Hate Speech":69.55,
        "tweetSentBR":67.04,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":14.17,
        "Hub":0,
        "Model sha":"39b74a78357df4d2296e838d87565967d663a67a",
        "Evaluation Time (s)":18905.09,
        "Leaderboard Average":null,
        "NPM (Average)":53.62
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rishiraj\/CatPPT",
        "Average":68.06,
        "ENEM":65.43,
        "BLUEX":56.33,
        "OAB Exams":42.82,
        "ASSIN2 RTE":92.48,
        "ASSIN2 STS":78.01,
        "FAQUAD NLI":77.01,
        "HateBR":85.53,
        "PT Hate Speech":67.92,
        "tweetSentBR":46.99,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":true,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":15,
        "Model sha":"7cb7df3f5ba954a917e19aa2c78dde45b68610f2",
        "Evaluation Time (s)":3620.52,
        "Leaderboard Average":72.32,
        "NPM (Average)":52.83
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm-20b",
        "Average":67.97,
        "ENEM":60.18,
        "BLUEX":52.57,
        "OAB Exams":44.05,
        "ASSIN2 RTE":89.19,
        "ASSIN2 STS":81.47,
        "FAQUAD NLI":77.46,
        "HateBR":80.09,
        "PT Hate Speech":73.24,
        "tweetSentBR":53.48,
        "Type":"pretrained",
        "Architecture":"InternLMForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":20.0,
        "Hub":72,
        "Model sha":"80729bcf52fbc4553d965926b27304ac5e156d98",
        "Evaluation Time (s)":10187.42,
        "Leaderboard Average":59.55,
        "NPM (Average)":52.49
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"rishiraj\/CatPPT-base",
        "Average":67.92,
        "ENEM":65.36,
        "BLUEX":55.91,
        "OAB Exams":42.96,
        "ASSIN2 RTE":92.36,
        "ASSIN2 STS":77.84,
        "FAQUAD NLI":76.94,
        "HateBR":85.84,
        "PT Hate Speech":67.26,
        "tweetSentBR":46.78,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":true,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":39,
        "Model sha":"2f73ffc6b55b7bc3e0a1cc6fa613ee948c9484c4",
        "Evaluation Time (s)":3664.26,
        "Leaderboard Average":72.25,
        "NPM (Average)":52.62
    },
    {
        "T":"\ud83d\udcac",
        "Model":"berkeley-nest\/Starling-LM-7B-alpha",
        "Average":67.9,
        "ENEM":64.03,
        "BLUEX":55.63,
        "OAB Exams":42.19,
        "ASSIN2 RTE":92.73,
        "ASSIN2 STS":80.14,
        "FAQUAD NLI":78.42,
        "HateBR":82.22,
        "PT Hate Speech":70.04,
        "tweetSentBR":45.69,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-nc-4.0",
        "#Params (B)":7.24,
        "Hub":490,
        "Model sha":"9dc75f55e3b3aed4275ae0dfd71bbbf2c1292ffa",
        "Evaluation Time (s)":9761.69,
        "Leaderboard Average":67.05,
        "NPM (Average)":52.53
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Average":67.87,
        "ENEM":72.57,
        "BLUEX":64.26,
        "OAB Exams":54.9,
        "ASSIN2 RTE":91.03,
        "ASSIN2 STS":78.71,
        "FAQUAD NLI":48.3,
        "HateBR":69.3,
        "PT Hate Speech":59.95,
        "tweetSentBR":71.83,
        "Type":"pretrained",
        "Architecture":"MixtralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":46.7,
        "Hub":1409,
        "Model sha":"985aa055896a8f943d4a9f2572e6ea1341823841",
        "Evaluation Time (s)":9062.56,
        "Leaderboard Average":68.42,
        "NPM (Average)":49.44
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-14B",
        "Average":67.86,
        "ENEM":69.35,
        "BLUEX":55.49,
        "OAB Exams":50.02,
        "ASSIN2 RTE":90.61,
        "ASSIN2 STS":76.97,
        "FAQUAD NLI":52.05,
        "HateBR":80.79,
        "PT Hate Speech":67.26,
        "tweetSentBR":68.23,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":14.17,
        "Hub":194,
        "Model sha":"c4051215126d906ac22bb67fe5edb39a921cd831",
        "Evaluation Time (s)":10457.03,
        "Leaderboard Average":65.86,
        "NPM (Average)":51.01
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Average":67.73,
        "ENEM":71.59,
        "BLUEX":61.34,
        "OAB Exams":53.62,
        "ASSIN2 RTE":88.65,
        "ASSIN2 STS":79.14,
        "FAQUAD NLI":45.39,
        "HateBR":82.81,
        "PT Hate Speech":58.12,
        "tweetSentBR":68.89,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":68.98,
        "Hub":774,
        "Model sha":"90052941a64de02075ca800b09fcea1bdaacb939",
        "Evaluation Time (s)":16005.52,
        "Leaderboard Average":null,
        "NPM (Average)":49.75
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-7B-Chat",
        "Average":67.72,
        "ENEM":61.58,
        "BLUEX":52.29,
        "OAB Exams":44.05,
        "ASSIN2 RTE":89.25,
        "ASSIN2 STS":70.12,
        "FAQUAD NLI":72.46,
        "HateBR":78.1,
        "PT Hate Speech":73.24,
        "tweetSentBR":68.41,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.72,
        "Hub":0,
        "Model sha":"03df580367e73ba602b3b678fbdf650fa3593e89",
        "Evaluation Time (s)":3062.62,
        "Leaderboard Average":null,
        "NPM (Average)":52.41
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/notux-8x7b-v1",
        "Average":67.69,
        "ENEM":70.96,
        "BLUEX":60.22,
        "OAB Exams":49.52,
        "ASSIN2 RTE":61.77,
        "ASSIN2 STS":82.4,
        "FAQUAD NLI":79.85,
        "HateBR":77.91,
        "PT Hate Speech":73.3,
        "tweetSentBR":53.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":46.7,
        "Hub":160,
        "Model sha":"0b29f9afcbae2ab4c5085638d8f5a7f6d44c6b17",
        "Evaluation Time (s)":14894.21,
        "Leaderboard Average":72.97,
        "NPM (Average)":49.9
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"paulml\/OGNO-7B",
        "Average":67.63,
        "ENEM":63.54,
        "BLUEX":54.38,
        "OAB Exams":41.78,
        "ASSIN2 RTE":91.95,
        "ASSIN2 STS":77.73,
        "FAQUAD NLI":78.53,
        "HateBR":81.47,
        "PT Hate Speech":70.09,
        "tweetSentBR":49.22,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-nc-4.0",
        "#Params (B)":7.24,
        "Hub":16,
        "Model sha":"a5d97f2e6962dc2c539a5bbca6a1160f87ccce84",
        "Evaluation Time (s)":3642.9,
        "Leaderboard Average":76.34,
        "NPM (Average)":52.23
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"bardsai\/jaskier-7b-dpo-v5.6",
        "Average":67.58,
        "ENEM":63.4,
        "BLUEX":54.24,
        "OAB Exams":41.59,
        "ASSIN2 RTE":92.28,
        "ASSIN2 STS":77.71,
        "FAQUAD NLI":78.31,
        "HateBR":80.99,
        "PT Hate Speech":70.19,
        "tweetSentBR":49.47,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-4.0",
        "#Params (B)":7.24,
        "Hub":24,
        "Model sha":"479916ec1f7c46bbc61d1b8d48efde894a34aba1",
        "Evaluation Time (s)":3646.53,
        "Leaderboard Average":76.41,
        "NPM (Average)":52.14
    },
    {
        "T":"\ud83d\udcac",
        "Model":"FuseAI\/FuseChat-7B-VaRM",
        "Average":67.49,
        "ENEM":64.8,
        "BLUEX":54.94,
        "OAB Exams":41.82,
        "ASSIN2 RTE":92.73,
        "ASSIN2 STS":78.37,
        "FAQUAD NLI":78.73,
        "HateBR":82.23,
        "PT Hate Speech":69.73,
        "tweetSentBR":44.07,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":45,
        "Model sha":"cda1eebe5ba3912c900045ed7847600e29b22c64",
        "Evaluation Time (s)":7729.94,
        "Leaderboard Average":66.52,
        "NPM (Average)":52.02
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-72B",
        "Average":67.42,
        "ENEM":33.03,
        "BLUEX":52.99,
        "OAB Exams":48.66,
        "ASSIN2 RTE":91.88,
        "ASSIN2 STS":71.68,
        "FAQUAD NLI":75.94,
        "HateBR":87.61,
        "PT Hate Speech":74.15,
        "tweetSentBR":70.8,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":72.29,
        "Hub":0,
        "Model sha":"cc2f19f5bc9ad693d4447e42e9844d9931ab8e81",
        "Evaluation Time (s)":67103.05,
        "Leaderboard Average":null,
        "NPM (Average)":53.39
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Intel\/neural-chat-7b-v3-1",
        "Average":67.27,
        "ENEM":62.63,
        "BLUEX":47.98,
        "OAB Exams":39.73,
        "ASSIN2 RTE":92.69,
        "ASSIN2 STS":76.58,
        "FAQUAD NLI":78.4,
        "HateBR":89.06,
        "PT Hate Speech":66.86,
        "tweetSentBR":51.46,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":525,
        "Model sha":"e852bc2e78a3fe509ec28c6d76512df3012acba7",
        "Evaluation Time (s)":5475.06,
        "Leaderboard Average":61.59,
        "NPM (Average)":52.26
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Average":67.22,
        "ENEM":66.41,
        "BLUEX":55.35,
        "OAB Exams":47.29,
        "ASSIN2 RTE":90.24,
        "ASSIN2 STS":73.49,
        "FAQUAD NLI":74.98,
        "HateBR":76.66,
        "PT Hate Speech":58.61,
        "tweetSentBR":61.91,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MixtralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":46.7,
        "Hub":291,
        "Model sha":"29972fcc16f3492f5adeec6ddcb99ebb46f8ac2d",
        "Evaluation Time (s)":11726.71,
        "Leaderboard Average":73.12,
        "NPM (Average)":50.59
    },
    {
        "T":"\ud83d\udd36",
        "Model":"NousResearch\/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Average":67.17,
        "ENEM":65.57,
        "BLUEX":55.35,
        "OAB Exams":47.11,
        "ASSIN2 RTE":90.11,
        "ASSIN2 STS":73.47,
        "FAQUAD NLI":76.26,
        "HateBR":76.41,
        "PT Hate Speech":58.11,
        "tweetSentBR":62.17,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"MixtralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":46.7,
        "Hub":291,
        "Model sha":"29972fcc16f3492f5adeec6ddcb99ebb46f8ac2d",
        "Evaluation Time (s)":11464.24,
        "Leaderboard Average":73.35,
        "NPM (Average)":50.56
    },
    {
        "T":"\ud83e\udd1d",
        "Model":"mlabonne\/Monarch-7B",
        "Average":67.01,
        "ENEM":62.28,
        "BLUEX":52.57,
        "OAB Exams":42.0,
        "ASSIN2 RTE":92.4,
        "ASSIN2 STS":76.98,
        "FAQUAD NLI":76.57,
        "HateBR":83.76,
        "PT Hate Speech":68.09,
        "tweetSentBR":48.4,
        "Type":"base merges and moerges",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-nc-4.0",
        "#Params (B)":7.24,
        "Hub":7,
        "Model sha":"c7f7fb0a6a12f2abc4568bd9d48c320622a56e39",
        "Evaluation Time (s)":3680.23,
        "Leaderboard Average":76.25,
        "NPM (Average)":51.39
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HuggingFaceH4\/zephyr-7b-gemma-v0.1",
        "Average":65.91,
        "ENEM":58.5,
        "BLUEX":48.54,
        "OAB Exams":41.28,
        "ASSIN2 RTE":85.98,
        "ASSIN2 STS":72.44,
        "FAQUAD NLI":75.08,
        "HateBR":87.4,
        "PT Hate Speech":62.47,
        "tweetSentBR":61.53,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":8.54,
        "Hub":98,
        "Model sha":"03b3427d0ed07d2e0f86c0a7e53d82d4beef9540",
        "Evaluation Time (s)":49966.15,
        "Leaderboard Average":61.48,
        "NPM (Average)":49.73
    },
    {
        "T":"\ud83d\udcac",
        "Model":"allenai\/tulu-2-dpo-13b",
        "Average":65.78,
        "ENEM":58.43,
        "BLUEX":48.12,
        "OAB Exams":41.09,
        "ASSIN2 RTE":89.89,
        "ASSIN2 STS":75.7,
        "FAQUAD NLI":72.65,
        "HateBR":74.41,
        "PT Hate Speech":69.86,
        "tweetSentBR":61.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":13.0,
        "Hub":16,
        "Model sha":"aa3e5cfac970cbfb2604773fb1807ebb98f056cc",
        "Evaluation Time (s)":20551.31,
        "Leaderboard Average":null,
        "NPM (Average)":49.1
    },
    {
        "T":"\ud83d\udcac",
        "Model":"meta-llama\/Llama-2-70b-chat-hf",
        "Average":65.69,
        "ENEM":62.56,
        "BLUEX":47.57,
        "OAB Exams":37.68,
        "ASSIN2 RTE":85.14,
        "ASSIN2 STS":71.81,
        "FAQUAD NLI":78.44,
        "HateBR":86.92,
        "PT Hate Speech":67.14,
        "tweetSentBR":53.94,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":68.98,
        "Hub":2022,
        "Model sha":"e4b287212771ce25f782ed8636cbea2d7c5ac7e2",
        "Evaluation Time (s)":41479.03,
        "Leaderboard Average":null,
        "NPM (Average)":49.68
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Intel\/neural-chat-7b-v3-3",
        "Average":65.34,
        "ENEM":62.63,
        "BLUEX":50.35,
        "OAB Exams":39.64,
        "ASSIN2 RTE":91.41,
        "ASSIN2 STS":75.88,
        "FAQUAD NLI":71.47,
        "HateBR":86.54,
        "PT Hate Speech":63.22,
        "tweetSentBR":46.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.0,
        "Hub":53,
        "Model sha":"cdce282d00962dcc4dc317fc5786b332d370a6d4",
        "Evaluation Time (s)":3746.44,
        "Leaderboard Average":69.83,
        "NPM (Average)":48.72
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/CapybaraHermes-2.5-Mistral-7B",
        "Average":65.08,
        "ENEM":62.42,
        "BLUEX":52.43,
        "OAB Exams":44.33,
        "ASSIN2 RTE":90.1,
        "ASSIN2 STS":70.18,
        "FAQUAD NLI":74.9,
        "HateBR":79.59,
        "PT Hate Speech":68.97,
        "tweetSentBR":42.83,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":0,
        "Model sha":"d06c86726aadd8dadb92c5b9b9e3ce8ef246c471",
        "Evaluation Time (s)":8192.04,
        "Leaderboard Average":null,
        "NPM (Average)":48.47
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/OpenHermes-2.5-Mistral-7B",
        "Average":64.84,
        "ENEM":63.89,
        "BLUEX":52.85,
        "OAB Exams":43.64,
        "ASSIN2 RTE":90.1,
        "ASSIN2 STS":68.87,
        "FAQUAD NLI":71.2,
        "HateBR":80.18,
        "PT Hate Speech":69.02,
        "tweetSentBR":43.84,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":703,
        "Model sha":"24c0bea14d53e6f67f1fbe2eca5bfe7cae389b33",
        "Evaluation Time (s)":3482.83,
        "Leaderboard Average":61.52,
        "NPM (Average)":48.04
    },
    {
        "T":"\ud83d\udcac",
        "Model":"argilla\/notus-7b-v1",
        "Average":64.82,
        "ENEM":61.3,
        "BLUEX":50.49,
        "OAB Exams":41.32,
        "ASSIN2 RTE":88.31,
        "ASSIN2 STS":72.01,
        "FAQUAD NLI":68.69,
        "HateBR":74.13,
        "PT Hate Speech":69.16,
        "tweetSentBR":57.95,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.0,
        "Hub":108,
        "Model sha":"30172203a2d41cb487bf7e2b92a821080783b2c9",
        "Evaluation Time (s)":15178.87,
        "Leaderboard Average":60.22,
        "NPM (Average)":47.45
    },
    {
        "T":"\ud83d\udcac",
        "Model":"mistralai\/Mistral-7B-Instruct-v0.2",
        "Average":64.81,
        "ENEM":58.92,
        "BLUEX":52.16,
        "OAB Exams":39.23,
        "ASSIN2 RTE":90.52,
        "ASSIN2 STS":74.32,
        "FAQUAD NLI":66.1,
        "HateBR":81.21,
        "PT Hate Speech":70.26,
        "tweetSentBR":50.57,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":1155,
        "Model sha":"b70aa86578567ba3301b21c8a27bea4e8f6d6d61",
        "Evaluation Time (s)":8523.04,
        "Leaderboard Average":65.71,
        "NPM (Average)":47.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm2-base-20b",
        "Average":64.71,
        "ENEM":60.53,
        "BLUEX":54.8,
        "OAB Exams":44.78,
        "ASSIN2 RTE":80.27,
        "ASSIN2 STS":78.3,
        "FAQUAD NLI":67.54,
        "HateBR":69.54,
        "PT Hate Speech":66.84,
        "tweetSentBR":59.76,
        "Type":"pretrained",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":20.0,
        "Hub":6,
        "Model sha":"1857a15e05788043d65645da2ce47781b4ae1777",
        "Evaluation Time (s)":17142.67,
        "Leaderboard Average":null,
        "NPM (Average)":45.94
    },
    {
        "T":"\ud83d\udd36",
        "Model":"cnmoro\/Mistral-7B-Portuguese",
        "Average":64.7,
        "ENEM":58.08,
        "BLUEX":48.68,
        "OAB Exams":37.08,
        "ASSIN2 RTE":90.31,
        "ASSIN2 STS":76.55,
        "FAQUAD NLI":58.84,
        "HateBR":79.21,
        "PT Hate Speech":68.87,
        "tweetSentBR":64.71,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":7.24,
        "Hub":2,
        "Model sha":"54078abd0ad81e60533aa0af17889b9255265d27",
        "Evaluation Time (s)":3820.84,
        "Leaderboard Average":null,
        "NPM (Average)":47.24
    },
    {
        "T":"\ud83d\udcac",
        "Model":"internlm\/internlm2-chat-20b",
        "Average":64.59,
        "ENEM":64.8,
        "BLUEX":56.47,
        "OAB Exams":43.69,
        "ASSIN2 RTE":89.38,
        "ASSIN2 STS":80.06,
        "FAQUAD NLI":53.89,
        "HateBR":68.08,
        "PT Hate Speech":69.18,
        "tweetSentBR":55.73,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":20.0,
        "Hub":0,
        "Model sha":"3f710f76f56f8c40dc5dd800dbe66f3341cb2c87",
        "Evaluation Time (s)":26950.72,
        "Leaderboard Average":null,
        "NPM (Average)":45.55
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"JJhooww\/Mistral_Relora_Step2k",
        "Average":64.42,
        "ENEM":61.58,
        "BLUEX":52.57,
        "OAB Exams":39.82,
        "ASSIN2 RTE":91.13,
        "ASSIN2 STS":70.75,
        "FAQUAD NLI":65.27,
        "HateBR":81.34,
        "PT Hate Speech":65.36,
        "tweetSentBR":51.94,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":7.24,
        "Hub":1,
        "Model sha":"3bd728425d680d1f0472b1cdc553f036bfc90c48",
        "Evaluation Time (s)":10134.08,
        "Leaderboard Average":null,
        "NPM (Average)":47.15
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"JJhooww\/MistralReloadBR_v2_ptbr",
        "Average":63.98,
        "ENEM":60.81,
        "BLUEX":47.98,
        "OAB Exams":40.73,
        "ASSIN2 RTE":91.01,
        "ASSIN2 STS":74.56,
        "FAQUAD NLI":47.6,
        "HateBR":79.83,
        "PT Hate Speech":66.32,
        "tweetSentBR":67.0,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":1,
        "Model sha":"c8af942dac6f459dfe2baa4fd25a597baa1d86fe",
        "Evaluation Time (s)":16404.02,
        "Leaderboard Average":null,
        "NPM (Average)":45.67
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"google\/gemma-7b",
        "Average":63.88,
        "ENEM":66.76,
        "BLUEX":56.47,
        "OAB Exams":42.28,
        "ASSIN2 RTE":81.37,
        "ASSIN2 STS":63.83,
        "FAQUAD NLI":68.54,
        "HateBR":83.96,
        "PT Hate Speech":44.92,
        "tweetSentBR":66.77,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":8.54,
        "Hub":0,
        "Model sha":"227defe192b6aaa8256a288fd7ee32553cc7c8ff",
        "Evaluation Time (s)":3144.5,
        "Leaderboard Average":null,
        "NPM (Average)":45.2
    },
    {
        "T":"\ud83d\udcac",
        "Model":"teknium\/OpenHermes-2-Mistral-7B",
        "Average":63.76,
        "ENEM":62.7,
        "BLUEX":54.24,
        "OAB Exams":42.6,
        "ASSIN2 RTE":89.87,
        "ASSIN2 STS":68.91,
        "FAQUAD NLI":66.18,
        "HateBR":73.94,
        "PT Hate Speech":68.15,
        "tweetSentBR":47.26,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.0,
        "Hub":250,
        "Model sha":"4c6e34123b140ce773a8433cae5410949289102c",
        "Evaluation Time (s)":3534.73,
        "Leaderboard Average":null,
        "NPM (Average)":45.84
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lmsys\/vicuna-13b-v1.5",
        "Average":63.67,
        "ENEM":55.77,
        "BLUEX":44.23,
        "OAB Exams":39.95,
        "ASSIN2 RTE":87.05,
        "ASSIN2 STS":73.73,
        "FAQUAD NLI":70.42,
        "HateBR":76.02,
        "PT Hate Speech":68.06,
        "tweetSentBR":57.82,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":13.0,
        "Hub":164,
        "Model sha":"3deb0106f72a3a433f0c6ea0cb978bdf14bcd3a6",
        "Evaluation Time (s)":15572.88,
        "Leaderboard Average":55.41,
        "NPM (Average)":46.02
    },
    {
        "T":"\ud83d\udd36",
        "Model":"internlm\/internlm2-7b",
        "Average":63.44,
        "ENEM":62.84,
        "BLUEX":51.32,
        "OAB Exams":40.18,
        "ASSIN2 RTE":87.58,
        "ASSIN2 STS":79.13,
        "FAQUAD NLI":46.18,
        "HateBR":68.86,
        "PT Hate Speech":68.47,
        "tweetSentBR":66.36,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":7.0,
        "Hub":24,
        "Model sha":"392eed693a16636da26a6c73aa06ac1e70b5146f",
        "Evaluation Time (s)":5274.42,
        "Leaderboard Average":66.68,
        "NPM (Average)":43.72
    },
    {
        "T":"\ud83d\udcac",
        "Model":"HuggingFaceH4\/zephyr-7b-beta",
        "Average":62.77,
        "ENEM":57.87,
        "BLUEX":47.98,
        "OAB Exams":39.32,
        "ASSIN2 RTE":88.36,
        "ASSIN2 STS":66.78,
        "FAQUAD NLI":70.18,
        "HateBR":81.77,
        "PT Hate Speech":66.59,
        "tweetSentBR":46.06,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.24,
        "Hub":1364,
        "Model sha":"dc24cabd13eacd3ae3a5fe574bd645483a335a4a",
        "Evaluation Time (s)":4042.03,
        "Leaderboard Average":61.95,
        "NPM (Average)":45.24
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-65b",
        "Average":62.24,
        "ENEM":66.83,
        "BLUEX":55.35,
        "OAB Exams":46.38,
        "ASSIN2 RTE":77.08,
        "ASSIN2 STS":68.75,
        "FAQUAD NLI":43.97,
        "HateBR":67.74,
        "PT Hate Speech":66.74,
        "tweetSentBR":67.3,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":65.29,
        "Hub":69,
        "Model sha":"49707c5313d34d1c5a846e29cf2a2a650c22c8ee",
        "Evaluation Time (s)":15716.49,
        "Leaderboard Average":62.79,
        "NPM (Average)":41.37
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-2-Mistral-7B-DPO",
        "Average":61.73,
        "ENEM":63.26,
        "BLUEX":54.1,
        "OAB Exams":43.74,
        "ASSIN2 RTE":60.15,
        "ASSIN2 STS":69.16,
        "FAQUAD NLI":71.38,
        "HateBR":77.68,
        "PT Hate Speech":70.91,
        "tweetSentBR":45.22,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":124,
        "Model sha":"b66d6a6b24c9d59639b12b5df43020059f662aaf",
        "Evaluation Time (s)":3520.25,
        "Leaderboard Average":68.1,
        "NPM (Average)":41.63
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-4B-Chat",
        "Average":61.34,
        "ENEM":50.52,
        "BLUEX":46.59,
        "OAB Exams":37.45,
        "ASSIN2 RTE":84.11,
        "ASSIN2 STS":72.32,
        "FAQUAD NLI":57.06,
        "HateBR":81.93,
        "PT Hate Speech":58.86,
        "tweetSentBR":63.19,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":3.95,
        "Hub":0,
        "Model sha":"f055cb5b26eaba7e123bd76b86ce391153fbe897",
        "Evaluation Time (s)":2603.44,
        "Leaderboard Average":null,
        "NPM (Average)":41.95
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Average":61.13,
        "ENEM":63.89,
        "BLUEX":50.21,
        "OAB Exams":43.92,
        "ASSIN2 RTE":88.92,
        "ASSIN2 STS":62.0,
        "FAQUAD NLI":48.0,
        "HateBR":76.73,
        "PT Hate Speech":59.64,
        "tweetSentBR":56.84,
        "Type":"pretrained",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.24,
        "Hub":2950,
        "Model sha":"26bca36bde8333b5d7f72e9ed20ccda6a618af24",
        "Evaluation Time (s)":4133.22,
        "Leaderboard Average":60.97,
        "NPM (Average)":41.32
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-7B",
        "Average":61.11,
        "ENEM":60.67,
        "BLUEX":37.55,
        "OAB Exams":43.23,
        "ASSIN2 RTE":89.44,
        "ASSIN2 STS":68.71,
        "FAQUAD NLI":48.99,
        "HateBR":81.51,
        "PT Hate Speech":66.65,
        "tweetSentBR":53.22,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.72,
        "Hub":0,
        "Model sha":"e52fa2ef47411cc8bc9f752d1d8d9072b37742e7",
        "Evaluation Time (s)":14604.5,
        "Leaderboard Average":null,
        "NPM (Average)":41.98
    },
    {
        "T":"\ud83d\udd36",
        "Model":"TencentARC\/Mistral_Pro_8B_v0.1",
        "Average":60.72,
        "ENEM":61.37,
        "BLUEX":48.82,
        "OAB Exams":40.77,
        "ASSIN2 RTE":85.74,
        "ASSIN2 STS":68.5,
        "FAQUAD NLI":43.97,
        "HateBR":68.86,
        "PT Hate Speech":61.95,
        "tweetSentBR":66.46,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":8.99,
        "Hub":60,
        "Model sha":"acae0ffeb040f1ee654068403a0305263e932ee0",
        "Evaluation Time (s)":4369.78,
        "Leaderboard Average":61.06,
        "NPM (Average)":39.83
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-40b",
        "Average":60.27,
        "ENEM":55.28,
        "BLUEX":49.65,
        "OAB Exams":44.37,
        "ASSIN2 RTE":81.38,
        "ASSIN2 STS":56.32,
        "FAQUAD NLI":43.97,
        "HateBR":76.01,
        "PT Hate Speech":65.54,
        "tweetSentBR":69.89,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":40.0,
        "Hub":2384,
        "Model sha":"4a70170c215b36a3cce4b4253f6d0612bb7d4146",
        "Evaluation Time (s)":14009.15,
        "Leaderboard Average":58.07,
        "NPM (Average)":40.23
    },
    {
        "T":"\ud83d\udcac",
        "Model":"01-ai\/Yi-6B-Chat",
        "Average":60.05,
        "ENEM":55.7,
        "BLUEX":50.07,
        "OAB Exams":41.18,
        "ASSIN2 RTE":79.48,
        "ASSIN2 STS":56.84,
        "FAQUAD NLI":63.8,
        "HateBR":77.57,
        "PT Hate Speech":57.12,
        "tweetSentBR":58.65,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":6.06,
        "Hub":46,
        "Model sha":"f14752bd87e64d8d614d4f5bec6660b3e95ae528",
        "Evaluation Time (s)":6620.04,
        "Leaderboard Average":null,
        "NPM (Average)":40.26
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen-7B-Chat",
        "Average":59.87,
        "ENEM":52.06,
        "BLUEX":46.04,
        "OAB Exams":37.72,
        "ASSIN2 RTE":85.5,
        "ASSIN2 STS":69.08,
        "FAQUAD NLI":48.45,
        "HateBR":71.35,
        "PT Hate Speech":65.67,
        "tweetSentBR":62.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.72,
        "Hub":0,
        "Model sha":"8d24619bab456ea5abe2823c1d05fc5edec19174",
        "Evaluation Time (s)":4289.59,
        "Leaderboard Average":null,
        "NPM (Average)":39.39
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-30b",
        "Average":59.68,
        "ENEM":61.3,
        "BLUEX":51.88,
        "OAB Exams":41.91,
        "ASSIN2 RTE":72.94,
        "ASSIN2 STS":60.49,
        "FAQUAD NLI":51.95,
        "HateBR":68.23,
        "PT Hate Speech":68.29,
        "tweetSentBR":60.09,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":32.53,
        "Hub":42,
        "Model sha":"2b1edcdb3c7ced7bce6c1aa75c94545777c3118b",
        "Evaluation Time (s)":8772.91,
        "Leaderboard Average":56.96,
        "NPM (Average)":38.48
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"01-ai\/Yi-6B",
        "Average":59.48,
        "ENEM":56.89,
        "BLUEX":51.32,
        "OAB Exams":44.6,
        "ASSIN2 RTE":79.04,
        "ASSIN2 STS":56.67,
        "FAQUAD NLI":59.85,
        "HateBR":74.26,
        "PT Hate Speech":61.84,
        "tweetSentBR":50.81,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":6.06,
        "Hub":353,
        "Model sha":"59c6151fb7880f89c01a95a76634e17cd09a2e94",
        "Evaluation Time (s)":3469.26,
        "Leaderboard Average":54.02,
        "NPM (Average)":39.16
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-7B",
        "Average":58.14,
        "ENEM":55.14,
        "BLUEX":48.68,
        "OAB Exams":38.72,
        "ASSIN2 RTE":84.73,
        "ASSIN2 STS":68.58,
        "FAQUAD NLI":44.71,
        "HateBR":58.94,
        "PT Hate Speech":58.55,
        "tweetSentBR":65.17,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":7.72,
        "Hub":335,
        "Model sha":"ef3c5c9c57b252f3149c1408daf4d649ec8b6c85",
        "Evaluation Time (s)":2582.2,
        "Leaderboard Average":59.19,
        "NPM (Average)":35.43
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Average":57.49,
        "ENEM":53.74,
        "BLUEX":44.51,
        "OAB Exams":39.95,
        "ASSIN2 RTE":86.32,
        "ASSIN2 STS":58.74,
        "FAQUAD NLI":43.97,
        "HateBR":81.08,
        "PT Hate Speech":53.1,
        "tweetSentBR":56.03,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":13.02,
        "Hub":517,
        "Model sha":"dc1d3b3bfdb69df26f8fc966c16353274b138c55",
        "Evaluation Time (s)":4584.65,
        "Leaderboard Average":55.69,
        "NPM (Average)":36.18
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lmsys\/vicuna-7b-v1.5",
        "Average":57.03,
        "ENEM":50.59,
        "BLUEX":41.31,
        "OAB Exams":36.08,
        "ASSIN2 RTE":79.57,
        "ASSIN2 STS":50.76,
        "FAQUAD NLI":59.38,
        "HateBR":69.81,
        "PT Hate Speech":65.87,
        "tweetSentBR":59.89,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":7.0,
        "Hub":189,
        "Model sha":"de56c35b1763eaae20f4d60efd64af0a9091ebe5",
        "Evaluation Time (s)":7615.68,
        "Leaderboard Average":52.06,
        "NPM (Average)":36.33
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicolasdec\/cabra13b",
        "Average":56.5,
        "ENEM":48.85,
        "BLUEX":40.89,
        "OAB Exams":35.31,
        "ASSIN2 RTE":85.55,
        "ASSIN2 STS":57.19,
        "FAQUAD NLI":45.45,
        "HateBR":77.78,
        "PT Hate Speech":64.13,
        "tweetSentBR":53.37,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":13.0,
        "Hub":4,
        "Model sha":"c14738689a4be398433675f34197f40b60b2f920",
        "Evaluation Time (s)":5241.05,
        "Leaderboard Average":null,
        "NPM (Average)":35.43
    },
    {
        "T":"\ud83d\udcac",
        "Model":"stabilityai\/stablelm-2-zephyr-1_6b",
        "Average":55.81,
        "ENEM":40.52,
        "BLUEX":32.41,
        "OAB Exams":33.39,
        "ASSIN2 RTE":86.51,
        "ASSIN2 STS":64.18,
        "FAQUAD NLI":50.99,
        "HateBR":70.66,
        "PT Hate Speech":63.78,
        "tweetSentBR":59.9,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.64,
        "Hub":0,
        "Model sha":"c89d7d19e9781974793a7e9b0fe55bcabcf8abc5",
        "Evaluation Time (s)":4324.24,
        "Leaderboard Average":null,
        "NPM (Average)":34.32
    },
    {
        "T":"\ud83d\udcac",
        "Model":"NousResearch\/Nous-Hermes-13b",
        "Average":55.7,
        "ENEM":46.19,
        "BLUEX":36.3,
        "OAB Exams":34.35,
        "ASSIN2 RTE":66.3,
        "ASSIN2 STS":51.66,
        "FAQUAD NLI":62.45,
        "HateBR":74.49,
        "PT Hate Speech":70.41,
        "tweetSentBR":59.17,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"gpl",
        "#Params (B)":13.0,
        "Hub":421,
        "Model sha":"24e8c03148ffd1f3e469744dfc24ad2ad82848f8",
        "Evaluation Time (s)":9906.37,
        "Leaderboard Average":54.04,
        "NPM (Average)":34.41
    },
    {
        "T":"\ud83d\udcac",
        "Model":"CohereForAI\/aya-101",
        "Average":55.56,
        "ENEM":57.03,
        "BLUEX":47.84,
        "OAB Exams":38.95,
        "ASSIN2 RTE":84.59,
        "ASSIN2 STS":18.93,
        "FAQUAD NLI":35.37,
        "HateBR":85.78,
        "PT Hate Speech":58.59,
        "tweetSentBR":72.92,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"T5ForConditionalGeneration",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":12.92,
        "Hub":0,
        "Model sha":"bb36885b37c25bb1a5f621d324dc861ab92e8ae5",
        "Evaluation Time (s)":5207.61,
        "Leaderboard Average":null,
        "NPM (Average)":35.41
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm2-base-7b",
        "Average":55.31,
        "ENEM":48.08,
        "BLUEX":47.29,
        "OAB Exams":37.54,
        "ASSIN2 RTE":72.72,
        "ASSIN2 STS":68.16,
        "FAQUAD NLI":43.97,
        "HateBR":51.98,
        "PT Hate Speech":67.97,
        "tweetSentBR":60.08,
        "Type":"pretrained",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":7.0,
        "Hub":7,
        "Model sha":"62f4666967b577a7c7af08cf6ed73ea121c9f514",
        "Evaluation Time (s)":8686.57,
        "Leaderboard Average":null,
        "NPM (Average)":30.83
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eduagarcia\/gemma-7b-it_no_chat_template",
        "Average":55.17,
        "ENEM":47.03,
        "BLUEX":36.02,
        "OAB Exams":35.17,
        "ASSIN2 RTE":84.71,
        "ASSIN2 STS":68.25,
        "FAQUAD NLI":38.09,
        "HateBR":82.72,
        "PT Hate Speech":44.32,
        "tweetSentBR":60.2,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":8.54,
        "Hub":0,
        "Model sha":"c118185bcd59d54c263108c24ddeadd70f577435",
        "Evaluation Time (s)":3004.56,
        "Leaderboard Average":null,
        "NPM (Average)":32.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"stabilityai\/stablelm-zephyr-3b",
        "Average":54.37,
        "ENEM":41.64,
        "BLUEX":36.02,
        "OAB Exams":33.03,
        "ASSIN2 RTE":87.57,
        "ASSIN2 STS":61.89,
        "FAQUAD NLI":67.1,
        "HateBR":67.08,
        "PT Hate Speech":54.25,
        "tweetSentBR":40.75,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"StableLmForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":2.8,
        "Hub":0,
        "Model sha":"015f44c1cdff647dbbd9e572661d05cef9da8ce1",
        "Evaluation Time (s)":8704.95,
        "Leaderboard Average":null,
        "NPM (Average)":32.21
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"xverse\/XVERSE-65B",
        "Average":53.71,
        "ENEM":34.5,
        "BLUEX":37.83,
        "OAB Exams":29.11,
        "ASSIN2 RTE":87.04,
        "ASSIN2 STS":73.27,
        "FAQUAD NLI":48.91,
        "HateBR":77.26,
        "PT Hate Speech":48.47,
        "tweetSentBR":47.0,
        "Type":"pretrained",
        "Architecture":"XverseForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":65.0,
        "Hub":40,
        "Model sha":"2f5c3c26594741b339d05b5bdf539d3a3583a6ba",
        "Evaluation Time (s)":31711.02,
        "Leaderboard Average":null,
        "NPM (Average)":30.4
    },
    {
        "T":"\ud83d\udcac",
        "Model":"recogna-nlp\/bode-7b-alpaca-pt-br",
        "Average":53.21,
        "ENEM":34.36,
        "BLUEX":28.93,
        "OAB Exams":30.84,
        "ASSIN2 RTE":79.83,
        "ASSIN2 STS":43.47,
        "FAQUAD NLI":67.45,
        "HateBR":85.06,
        "PT Hate Speech":65.73,
        "tweetSentBR":43.25,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.0,
        "Hub":31,
        "Model sha":"c1b0db933684edbfe29a06fa47eb19cc48025e93",
        "Evaluation Time (s)":7684.43,
        "Leaderboard Average":null,
        "NPM (Average)":33.03
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-13b",
        "Average":52.98,
        "ENEM":39.89,
        "BLUEX":32.82,
        "OAB Exams":35.26,
        "ASSIN2 RTE":79.72,
        "ASSIN2 STS":32.14,
        "FAQUAD NLI":54.88,
        "HateBR":82.27,
        "PT Hate Speech":63.01,
        "tweetSentBR":56.86,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":13.02,
        "Hub":129,
        "Model sha":"bf57045473f207bb1de1ed035ace226f4d9f9bba",
        "Evaluation Time (s)":5939.82,
        "Leaderboard Average":51.33,
        "NPM (Average)":32.2
    },
    {
        "T":"\ud83d\udcac",
        "Model":"recogna-nlp\/bode-13b-alpaca-pt-br",
        "Average":52.54,
        "ENEM":33.66,
        "BLUEX":38.25,
        "OAB Exams":36.04,
        "ASSIN2 RTE":71.22,
        "ASSIN2 STS":46.75,
        "FAQUAD NLI":51.68,
        "HateBR":82.21,
        "PT Hate Speech":65.54,
        "tweetSentBR":47.55,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":13.0,
        "Hub":12,
        "Model sha":"c2f3ec81aac798ae26dcc57799a994dfbf521496",
        "Evaluation Time (s)":9888.44,
        "Leaderboard Average":null,
        "NPM (Average)":30.3
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-4B",
        "Average":51.39,
        "ENEM":42.41,
        "BLUEX":36.16,
        "OAB Exams":31.16,
        "ASSIN2 RTE":85.33,
        "ASSIN2 STS":55.69,
        "FAQUAD NLI":52.75,
        "HateBR":56.74,
        "PT Hate Speech":57.28,
        "tweetSentBR":45.02,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":3.95,
        "Hub":0,
        "Model sha":"294dbdee5dacecc52c9cc6ba2dba4084addc7b2c",
        "Evaluation Time (s)":17162.98,
        "Leaderboard Average":null,
        "NPM (Average)":27.0
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicolasdec\/Cabra",
        "Average":50.41,
        "ENEM":33.24,
        "BLUEX":33.38,
        "OAB Exams":32.39,
        "ASSIN2 RTE":81.12,
        "ASSIN2 STS":29.38,
        "FAQUAD NLI":47.29,
        "HateBR":81.71,
        "PT Hate Speech":64.84,
        "tweetSentBR":50.33,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":0.0,
        "Hub":2,
        "Model sha":"b0b2da1071a298d31c2cabf43728ad064341baa6",
        "Evaluation Time (s)":3348.87,
        "Leaderboard Average":null,
        "NPM (Average)":28.58
    },
    {
        "T":"\ud83d\udcac",
        "Model":"google\/gemma-7b-it",
        "Average":49.64,
        "ENEM":36.46,
        "BLUEX":30.32,
        "OAB Exams":27.74,
        "ASSIN2 RTE":81.48,
        "ASSIN2 STS":60.45,
        "FAQUAD NLI":57.36,
        "HateBR":72.81,
        "PT Hate Speech":56.33,
        "tweetSentBR":23.77,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":8.54,
        "Hub":0,
        "Model sha":"cda5a5189d4606b969ca2b316298debf5fc2953d",
        "Evaluation Time (s)":5121.12,
        "Leaderboard Average":null,
        "NPM (Average)":25.3
    },
    {
        "T":"\ud83d\udcac",
        "Model":"internlm\/internlm2-chat-1_8b",
        "Average":49.21,
        "ENEM":32.05,
        "BLUEX":31.43,
        "OAB Exams":30.34,
        "ASSIN2 RTE":75.65,
        "ASSIN2 STS":52.54,
        "FAQUAD NLI":66.05,
        "HateBR":58.65,
        "PT Hate Speech":56.05,
        "tweetSentBR":40.16,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.89,
        "Hub":0,
        "Model sha":"75131b425ecc87fdbd10dd579531f93f5f81669a",
        "Evaluation Time (s)":10010.75,
        "Leaderboard Average":null,
        "NPM (Average)":24.34
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Average":48.9,
        "ENEM":31.91,
        "BLUEX":31.29,
        "OAB Exams":35.44,
        "ASSIN2 RTE":67.02,
        "ASSIN2 STS":31.1,
        "FAQUAD NLI":53.87,
        "HateBR":75.16,
        "PT Hate Speech":55.26,
        "tweetSentBR":59.06,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":6.74,
        "Hub":1193,
        "Model sha":"8cca527612d856d7d32bd94f8103728d614eb852",
        "Evaluation Time (s)":4781.25,
        "Leaderboard Average":50.97,
        "NPM (Average)":24.89
    },
    {
        "T":"\ud83d\udcac",
        "Model":"google\/gemma-7b-it",
        "Average":47.66,
        "ENEM":34.78,
        "BLUEX":29.35,
        "OAB Exams":27.2,
        "ASSIN2 RTE":80.5,
        "ASSIN2 STS":51.74,
        "FAQUAD NLI":54.21,
        "HateBR":77.0,
        "PT Hate Speech":53.91,
        "tweetSentBR":20.3,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":8.54,
        "Hub":0,
        "Model sha":"f6a08e4923398ccf3a68f69c774e266ab86006f2",
        "Evaluation Time (s)":3783.23,
        "Leaderboard Average":null,
        "NPM (Average)":22.86
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"dominguesm\/canarim-7b",
        "Average":47.36,
        "ENEM":25.96,
        "BLUEX":29.76,
        "OAB Exams":31.48,
        "ASSIN2 RTE":71.96,
        "ASSIN2 STS":13.34,
        "FAQUAD NLI":49.09,
        "HateBR":78.49,
        "PT Hate Speech":63.74,
        "tweetSentBR":62.38,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":7.0,
        "Hub":14,
        "Model sha":"18d34bd9ad2d9674675b2e0d88dee9324b52f2b5",
        "Evaluation Time (s)":4207.36,
        "Leaderboard Average":48.63,
        "NPM (Average)":24.5
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"internlm\/internlm-7b",
        "Average":47.27,
        "ENEM":40.87,
        "BLUEX":33.52,
        "OAB Exams":32.98,
        "ASSIN2 RTE":64.1,
        "ASSIN2 STS":32.69,
        "FAQUAD NLI":43.97,
        "HateBR":63.51,
        "PT Hate Speech":55.98,
        "tweetSentBR":57.8,
        "Type":"pretrained",
        "Architecture":"InternLMForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":7.0,
        "Hub":88,
        "Model sha":"154a736f18ae86c93339e345c145d65d03696156",
        "Evaluation Time (s)":4634.03,
        "Leaderboard Average":null,
        "NPM (Average)":20.95
    },
    {
        "T":"\ud83d\udcac",
        "Model":"dominguesm\/Canarim-7B-Instruct",
        "Average":47.21,
        "ENEM":27.5,
        "BLUEX":26.15,
        "OAB Exams":29.93,
        "ASSIN2 RTE":75.74,
        "ASSIN2 STS":12.08,
        "FAQUAD NLI":43.92,
        "HateBR":79.57,
        "PT Hate Speech":64.01,
        "tweetSentBR":66.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":7.0,
        "Hub":7,
        "Model sha":"863ba2a67fb9503b74b2e981b9d8255a722dfbd7",
        "Evaluation Time (s)":4330.53,
        "Leaderboard Average":null,
        "NPM (Average)":24.51
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"maritaca-ai\/sabia-7b",
        "Average":47.09,
        "ENEM":55.07,
        "BLUEX":47.71,
        "OAB Exams":41.41,
        "ASSIN2 RTE":46.68,
        "ASSIN2 STS":1.89,
        "FAQUAD NLI":58.34,
        "HateBR":61.93,
        "PT Hate Speech":64.13,
        "tweetSentBR":46.64,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":6.74,
        "Hub":65,
        "Model sha":"78ffc11554c73e4971a39e30ead7a7b0bb5b823d",
        "Evaluation Time (s)":5329.12,
        "Leaderboard Average":null,
        "NPM (Average)":21.39
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"PORTULAN\/gervasio-7b-portuguese-ptpt-decoder",
        "Average":46.84,
        "ENEM":17.0,
        "BLUEX":18.92,
        "OAB Exams":26.1,
        "ASSIN2 RTE":85.32,
        "ASSIN2 STS":79.1,
        "FAQUAD NLI":62.21,
        "HateBR":61.74,
        "PT Hate Speech":56.81,
        "tweetSentBR":14.38,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.0,
        "Hub":6,
        "Model sha":"0f3518ff23681fd6c48b0ccf46ad943f026210aa",
        "Evaluation Time (s)":14595.37,
        "Leaderboard Average":null,
        "NPM (Average)":20.73
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"allenai\/OLMo-7B-Twin-2T",
        "Average":45.03,
        "ENEM":19.17,
        "BLUEX":23.64,
        "OAB Exams":25.65,
        "ASSIN2 RTE":77.68,
        "ASSIN2 STS":31.06,
        "FAQUAD NLI":43.97,
        "HateBR":74.71,
        "PT Hate Speech":61.09,
        "tweetSentBR":48.33,
        "Type":"pretrained",
        "Architecture":"OLMoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":6.89,
        "Hub":0,
        "Model sha":"a77e93a129e708869d559146ab2211a428bb2856",
        "Evaluation Time (s)":5159.43,
        "Leaderboard Average":null,
        "NPM (Average)":20.29
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lrds-code\/boana-7b-instruct",
        "Average":44.57,
        "ENEM":21.62,
        "BLUEX":29.21,
        "OAB Exams":27.15,
        "ASSIN2 RTE":48.84,
        "ASSIN2 STS":37.56,
        "FAQUAD NLI":43.97,
        "HateBR":85.0,
        "PT Hate Speech":67.43,
        "tweetSentBR":40.38,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":6.74,
        "Hub":2,
        "Model sha":"96039b02ee677c99abdc0dc56824fcd69cc1c229",
        "Evaluation Time (s)":5064.94,
        "Leaderboard Average":null,
        "NPM (Average)":18.28
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"google\/gemma-2b",
        "Average":44.41,
        "ENEM":25.89,
        "BLUEX":28.93,
        "OAB Exams":28.29,
        "ASSIN2 RTE":64.94,
        "ASSIN2 STS":35.68,
        "FAQUAD NLI":44.87,
        "HateBR":78.1,
        "PT Hate Speech":37.83,
        "tweetSentBR":55.19,
        "Type":"pretrained",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":2.51,
        "Hub":0,
        "Model sha":"9d067f00def958594aaa16b39a65b07d69ca655b",
        "Evaluation Time (s)":1706.91,
        "Leaderboard Average":null,
        "NPM (Average)":17.16
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"xverse\/XVERSE-65B-2",
        "Average":44.37,
        "ENEM":40.52,
        "BLUEX":38.8,
        "OAB Exams":31.07,
        "ASSIN2 RTE":59.09,
        "ASSIN2 STS":74.56,
        "FAQUAD NLI":25.07,
        "HateBR":49.96,
        "PT Hate Speech":33.28,
        "tweetSentBR":46.96,
        "Type":"pretrained",
        "Architecture":"XverseForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":65.0,
        "Hub":9,
        "Model sha":"3f1c9ac7904404e18bf3aff5c139e51527074e8a",
        "Evaluation Time (s)":36141.88,
        "Leaderboard Average":null,
        "NPM (Average)":11.41
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"fernandosola\/bluearara-7B-instruct",
        "Average":43.23,
        "ENEM":21.41,
        "BLUEX":24.06,
        "OAB Exams":30.39,
        "ASSIN2 RTE":50.68,
        "ASSIN2 STS":17.17,
        "FAQUAD NLI":44.39,
        "HateBR":84.27,
        "PT Hate Speech":62.22,
        "tweetSentBR":54.48,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.24,
        "Hub":2,
        "Model sha":"a3c001b6c09d819b16e57977222aa7b2bc8a4ade",
        "Evaluation Time (s)":11150.58,
        "Leaderboard Average":null,
        "NPM (Average)":17.29
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-1.8B-Chat",
        "Average":43.22,
        "ENEM":32.96,
        "BLUEX":29.76,
        "OAB Exams":31.71,
        "ASSIN2 RTE":73.9,
        "ASSIN2 STS":25.83,
        "FAQUAD NLI":32.69,
        "HateBR":67.03,
        "PT Hate Speech":56.79,
        "tweetSentBR":38.28,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.84,
        "Hub":0,
        "Model sha":"c9a26c4b56507014e6c42a4d543de01c272ba165",
        "Evaluation Time (s)":1717.82,
        "Leaderboard Average":null,
        "NPM (Average)":15.97
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicolasdec\/CabraMistral7b-0.4",
        "Average":42.64,
        "ENEM":23.16,
        "BLUEX":22.39,
        "OAB Exams":24.83,
        "ASSIN2 RTE":69.54,
        "ASSIN2 STS":39.6,
        "FAQUAD NLI":43.97,
        "HateBR":78.45,
        "PT Hate Speech":41.4,
        "tweetSentBR":40.4,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"?",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"cc",
        "#Params (B)":7.24,
        "Hub":5,
        "Model sha":"3fc26e31e26d511e87db75bf64ef742596b81cc6",
        "Evaluation Time (s)":4442.12,
        "Leaderboard Average":null,
        "NPM (Average)":15.0
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"Unbabel\/TowerBase-7B-v0.1",
        "Average":41.44,
        "ENEM":36.81,
        "BLUEX":30.6,
        "OAB Exams":35.22,
        "ASSIN2 RTE":36.74,
        "ASSIN2 STS":20.68,
        "FAQUAD NLI":44.61,
        "HateBR":61.32,
        "PT Hate Speech":53.03,
        "tweetSentBR":53.99,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-nc-4.0",
        "#Params (B)":6.74,
        "Hub":44,
        "Model sha":"7512cb2c27e3b7f0b92c9271c2a845a1365048c8",
        "Evaluation Time (s)":3482.09,
        "Leaderboard Average":49.11,
        "NPM (Average)":11.27
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"fernandosola\/bluearara-7B",
        "Average":40.59,
        "ENEM":18.75,
        "BLUEX":22.95,
        "OAB Exams":26.2,
        "ASSIN2 RTE":71.62,
        "ASSIN2 STS":13.61,
        "FAQUAD NLI":43.97,
        "HateBR":62.27,
        "PT Hate Speech":57.49,
        "tweetSentBR":48.48,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.0,
        "Hub":0,
        "Model sha":"f93367f4891f4c081a00d36e19401c27a9dcef1f",
        "Evaluation Time (s)":13237.3,
        "Leaderboard Average":null,
        "NPM (Average)":13.41
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Average":39.79,
        "ENEM":31.63,
        "BLUEX":29.9,
        "OAB Exams":25.38,
        "ASSIN2 RTE":48.57,
        "ASSIN2 STS":16.16,
        "FAQUAD NLI":43.97,
        "HateBR":66.12,
        "PT Hate Speech":56.81,
        "tweetSentBR":39.57,
        "Type":"pretrained",
        "Architecture":"StableLMEpochForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"cc-by-sa-4.0",
        "#Params (B)":2.8,
        "Hub":302,
        "Model sha":"e3be657f4d1b78eb7520637ba922448a1ee456bd",
        "Evaluation Time (s)":3410.49,
        "Leaderboard Average":46.58,
        "NPM (Average)":10.48
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-30b",
        "Average":39.54,
        "ENEM":19.66,
        "BLUEX":21.84,
        "OAB Exams":25.19,
        "ASSIN2 RTE":66.07,
        "ASSIN2 STS":1.69,
        "FAQUAD NLI":43.97,
        "HateBR":69.53,
        "PT Hate Speech":54.65,
        "tweetSentBR":53.28,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":30.0,
        "Hub":133,
        "Model sha":"ceea0a90ac0f6fae7c2c34bcb40477438c152546",
        "Evaluation Time (s)":11041.68,
        "Leaderboard Average":42.0,
        "NPM (Average)":12.48
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"PORTULAN\/gervasio-7b-portuguese-ptbr-decoder",
        "Average":39.46,
        "ENEM":21.34,
        "BLUEX":21.0,
        "OAB Exams":26.29,
        "ASSIN2 RTE":83.15,
        "ASSIN2 STS":69.55,
        "FAQUAD NLI":18.59,
        "HateBR":53.8,
        "PT Hate Speech":47.24,
        "tweetSentBR":14.21,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":7.0,
        "Hub":6,
        "Model sha":"9c38686f160c3a6dcb34614c700779c495fcbcb1",
        "Evaluation Time (s)":15535.66,
        "Leaderboard Average":null,
        "NPM (Average)":7.37
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"fernandosola\/bluearara-7B",
        "Average":39.36,
        "ENEM":18.75,
        "BLUEX":22.95,
        "OAB Exams":26.01,
        "ASSIN2 RTE":71.05,
        "ASSIN2 STS":13.02,
        "FAQUAD NLI":43.97,
        "HateBR":57.45,
        "PT Hate Speech":54.26,
        "tweetSentBR":46.74,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":7.0,
        "Hub":0,
        "Model sha":"f93367f4891f4c081a00d36e19401c27a9dcef1f",
        "Evaluation Time (s)":14524.08,
        "Leaderboard Average":null,
        "NPM (Average)":11.15
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_7b_v2",
        "Average":39.21,
        "ENEM":20.78,
        "BLUEX":25.03,
        "OAB Exams":28.02,
        "ASSIN2 RTE":64.81,
        "ASSIN2 STS":3.82,
        "FAQUAD NLI":52.22,
        "HateBR":74.41,
        "PT Hate Speech":55.35,
        "tweetSentBR":28.4,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.0,
        "Hub":108,
        "Model sha":"e5961def23172a2384543940e773ab676033c963",
        "Evaluation Time (s)":8315.5,
        "Leaderboard Average":44.26,
        "NPM (Average)":12.27
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen-1_8B-Chat",
        "Average":37.65,
        "ENEM":18.12,
        "BLUEX":1.11,
        "OAB Exams":26.92,
        "ASSIN2 RTE":68.06,
        "ASSIN2 STS":24.28,
        "FAQUAD NLI":29.08,
        "HateBR":65.6,
        "PT Hate Speech":57.39,
        "tweetSentBR":48.31,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.84,
        "Hub":0,
        "Model sha":"1d0f68de57b88cfde81f3c3e537f24464d889081",
        "Evaluation Time (s)":10336.83,
        "Leaderboard Average":null,
        "NPM (Average)":8.35
    },
    {
        "T":"\ud83d\udd36",
        "Model":"internlm\/internlm2-1_8b",
        "Average":37.02,
        "ENEM":29.67,
        "BLUEX":26.84,
        "OAB Exams":30.48,
        "ASSIN2 RTE":67.04,
        "ASSIN2 STS":20.28,
        "FAQUAD NLI":56.59,
        "HateBR":33.33,
        "PT Hate Speech":23.17,
        "tweetSentBR":45.81,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"InternLM2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.89,
        "Hub":0,
        "Model sha":"454e4182b3dd9c7392db4a8425b0213560172698",
        "Evaluation Time (s)":2262.32,
        "Leaderboard Average":null,
        "NPM (Average)":4.24
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_13b",
        "Average":37.01,
        "ENEM":28.62,
        "BLUEX":24.76,
        "OAB Exams":27.29,
        "ASSIN2 RTE":50.83,
        "ASSIN2 STS":21.87,
        "FAQUAD NLI":44.71,
        "HateBR":46.46,
        "PT Hate Speech":58.03,
        "tweetSentBR":30.53,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":13.0,
        "Hub":451,
        "Model sha":"b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8",
        "Evaluation Time (s)":4726.48,
        "Leaderboard Average":47.26,
        "NPM (Average)":5.29
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"tiiuae\/falcon-7b",
        "Average":36.86,
        "ENEM":20.57,
        "BLUEX":21.97,
        "OAB Exams":22.82,
        "ASSIN2 RTE":45.54,
        "ASSIN2 STS":12.4,
        "FAQUAD NLI":43.97,
        "HateBR":54.31,
        "PT Hate Speech":62.31,
        "tweetSentBR":47.87,
        "Type":"pretrained",
        "Architecture":"FalconForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.0,
        "Hub":1012,
        "Model sha":"898df1396f35e447d5fe44e0a3ccaaaa69f30d36",
        "Evaluation Time (s)":4086.29,
        "Leaderboard Average":44.17,
        "NPM (Average)":6.26
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/phi-2",
        "Average":36.52,
        "ENEM":34.99,
        "BLUEX":26.98,
        "OAB Exams":28.29,
        "ASSIN2 RTE":38.38,
        "ASSIN2 STS":8.87,
        "FAQUAD NLI":43.92,
        "HateBR":59.63,
        "PT Hate Speech":51.23,
        "tweetSentBR":36.37,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":2.78,
        "Hub":2930,
        "Model sha":"b10c3eba545ad279e7208ee3a5d644566f001670",
        "Evaluation Time (s)":3965.88,
        "Leaderboard Average":61.33,
        "NPM (Average)":4.71
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen-1_8B",
        "Average":36.19,
        "ENEM":30.23,
        "BLUEX":26.15,
        "OAB Exams":27.2,
        "ASSIN2 RTE":64.83,
        "ASSIN2 STS":19.53,
        "FAQUAD NLI":43.97,
        "HateBR":33.33,
        "PT Hate Speech":41.23,
        "tweetSentBR":39.26,
        "Type":"pretrained",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":1.84,
        "Hub":50,
        "Model sha":"fa6e214ccbbc6a55235c26ef406355b6bfdf5eed",
        "Evaluation Time (s)":2005.22,
        "Leaderboard Average":null,
        "NPM (Average)":3.34
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"AI-Sweden-Models\/gpt-sw3-40b",
        "Average":35.41,
        "ENEM":23.58,
        "BLUEX":28.09,
        "OAB Exams":25.42,
        "ASSIN2 RTE":40.97,
        "ASSIN2 STS":17.31,
        "FAQUAD NLI":51.25,
        "HateBR":39.2,
        "PT Hate Speech":43.65,
        "tweetSentBR":49.17,
        "Type":"pretrained",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":39.93,
        "Hub":6,
        "Model sha":"910e5d769c3ebfcbb6577c7793578a7b4ea87680",
        "Evaluation Time (s)":13056.12,
        "Leaderboard Average":43.42,
        "NPM (Average)":1.84
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"Bruno\/Caramelinho",
        "Average":35.32,
        "ENEM":21.48,
        "BLUEX":22.11,
        "OAB Exams":25.15,
        "ASSIN2 RTE":48.97,
        "ASSIN2 STS":19.38,
        "FAQUAD NLI":43.92,
        "HateBR":33.97,
        "PT Hate Speech":46.57,
        "tweetSentBR":56.31,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"?",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":0.0,
        "Hub":2,
        "Model sha":"464ab3beee06456a9fae8e928b4fa8e724b2d416",
        "Evaluation Time (s)":5478.56,
        "Leaderboard Average":null,
        "NPM (Average)":1.79
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-66b",
        "Average":34.99,
        "ENEM":22.67,
        "BLUEX":25.59,
        "OAB Exams":25.92,
        "ASSIN2 RTE":55.53,
        "ASSIN2 STS":10.54,
        "FAQUAD NLI":44.61,
        "HateBR":62.16,
        "PT Hate Speech":29.29,
        "tweetSentBR":38.58,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":66.0,
        "Hub":173,
        "Model sha":"7259969061237fe940036d22bea0fd349e4485e9",
        "Evaluation Time (s)":21391.22,
        "Leaderboard Average":42.78,
        "NPM (Average)":2.84
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"allenai\/OLMo-7B",
        "Average":34.58,
        "ENEM":19.73,
        "BLUEX":21.0,
        "OAB Exams":25.24,
        "ASSIN2 RTE":33.97,
        "ASSIN2 STS":6.15,
        "FAQUAD NLI":43.97,
        "HateBR":72.62,
        "PT Hate Speech":40.93,
        "tweetSentBR":47.63,
        "Type":"pretrained",
        "Architecture":"OLMoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":6.89,
        "Hub":0,
        "Model sha":"09dd55d8d37c14aa0cbab5a4ac545140d2bd0a60",
        "Evaluation Time (s)":4006.97,
        "Leaderboard Average":null,
        "NPM (Average)":2.56
    },
    {
        "T":"\ud83d\udcac",
        "Model":"google\/gemma-2b-it",
        "Average":34.08,
        "ENEM":29.32,
        "BLUEX":25.73,
        "OAB Exams":28.29,
        "ASSIN2 RTE":57.48,
        "ASSIN2 STS":3.91,
        "FAQUAD NLI":55.82,
        "HateBR":44.16,
        "PT Hate Speech":23.22,
        "tweetSentBR":38.81,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":2.51,
        "Hub":0,
        "Model sha":"9642e777f24fde593d204a9b2471dce33334e64a",
        "Evaluation Time (s)":3956.5,
        "Leaderboard Average":null,
        "NPM (Average)":0.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-3b",
        "Average":33.54,
        "ENEM":19.38,
        "BLUEX":20.58,
        "OAB Exams":24.83,
        "ASSIN2 RTE":51.06,
        "ASSIN2 STS":6.27,
        "FAQUAD NLI":43.97,
        "HateBR":61.19,
        "PT Hate Speech":50.12,
        "tweetSentBR":24.5,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":3.0,
        "Hub":80,
        "Model sha":"52bc5b43010b4844513826b8be3f78c7344c37d7",
        "Evaluation Time (s)":2196.1,
        "Leaderboard Average":36.07,
        "NPM (Average)":1.8
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"huggyllama\/llama-7b",
        "Average":33.47,
        "ENEM":23.51,
        "BLUEX":23.92,
        "OAB Exams":25.65,
        "ASSIN2 RTE":38.62,
        "ASSIN2 STS":15.43,
        "FAQUAD NLI":52.43,
        "HateBR":38.07,
        "PT Hate Speech":24.11,
        "tweetSentBR":59.5,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":6.74,
        "Hub":248,
        "Model sha":"8416d3fefb0cb3ff5775a7b13c1692d10ff1aa16",
        "Evaluation Time (s)":4421.88,
        "Leaderboard Average":46.37,
        "NPM (Average)":-1.94
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"22h\/open-cabrita3b",
        "Average":33.04,
        "ENEM":17.98,
        "BLUEX":21.14,
        "OAB Exams":22.69,
        "ASSIN2 RTE":43.01,
        "ASSIN2 STS":8.92,
        "FAQUAD NLI":43.97,
        "HateBR":50.46,
        "PT Hate Speech":41.19,
        "tweetSentBR":47.96,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":3.0,
        "Hub":19,
        "Model sha":"fc2a2de94a3b31de54aaace695537c4d1c3e456d",
        "Evaluation Time (s)":2238.15,
        "Leaderboard Average":35.54,
        "NPM (Average)":-0.53
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"wandgibaut\/periquito-3B",
        "Average":33.04,
        "ENEM":17.98,
        "BLUEX":21.14,
        "OAB Exams":22.69,
        "ASSIN2 RTE":43.01,
        "ASSIN2 STS":8.92,
        "FAQUAD NLI":43.97,
        "HateBR":50.46,
        "PT Hate Speech":41.19,
        "tweetSentBR":47.96,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":3.0,
        "Hub":1,
        "Model sha":"58ca939e79821d863a95338d9e38f72e374ef114",
        "Evaluation Time (s)":4879.32,
        "Leaderboard Average":null,
        "NPM (Average)":-0.53
    },
    {
        "T":"?",
        "Model":"baseline",
        "Average":32.64,
        "ENEM":20.0,
        "BLUEX":22.5,
        "OAB Exams":25.0,
        "ASSIN2 RTE":50.0,
        "ASSIN2 STS":0.0,
        "FAQUAD NLI":45.6,
        "HateBR":50.0,
        "PT Hate Speech":47.9,
        "tweetSentBR":32.8,
        "Type":"",
        "Architecture":null,
        "Precision":"?",
        "Merged":false,
        "Hub License":"",
        "#Params (B)":0.0,
        "Hub":0,
        "Model sha":"N\/A",
        "Evaluation Time (s)":0.0,
        "Leaderboard Average":null,
        "NPM (Average)":0.0
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Average":32.28,
        "ENEM":22.25,
        "BLUEX":22.81,
        "OAB Exams":23.64,
        "ASSIN2 RTE":58.93,
        "ASSIN2 STS":13.57,
        "FAQUAD NLI":43.97,
        "HateBR":36.92,
        "PT Hate Speech":36.39,
        "tweetSentBR":32.0,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":1.1,
        "Hub":119,
        "Model sha":"036fa4651240b9a1487f709833b9e4b96b4c1574",
        "Evaluation Time (s)":3166.62,
        "Leaderboard Average":36.42,
        "NPM (Average)":-2.18
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"22h\/cabrita_7b_pt_850000",
        "Average":32.14,
        "ENEM":22.53,
        "BLUEX":23.09,
        "OAB Exams":29.2,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":12.65,
        "FAQUAD NLI":17.72,
        "HateBR":55.98,
        "PT Hate Speech":49.02,
        "tweetSentBR":45.75,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":7.0,
        "Hub":4,
        "Model sha":"1266df41f51fed9c1914f164152072acc5f89d6d",
        "Evaluation Time (s)":6740.16,
        "Leaderboard Average":null,
        "NPM (Average)":-3.23
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"stabilityai\/stablelm-2-1_6b",
        "Average":31.89,
        "ENEM":27.08,
        "BLUEX":24.48,
        "OAB Exams":26.29,
        "ASSIN2 RTE":33.42,
        "ASSIN2 STS":15.79,
        "FAQUAD NLI":43.97,
        "HateBR":33.97,
        "PT Hate Speech":41.23,
        "tweetSentBR":40.8,
        "Type":"pretrained",
        "Architecture":"StableLMEpochForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":1.64,
        "Hub":138,
        "Model sha":"64c3d6a37d3fb3d5a02c67b114da2451dc1c1c14",
        "Evaluation Time (s)":2138.12,
        "Leaderboard Average":45.25,
        "NPM (Average)":-4.47
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"Bruno\/Caramelo_7B",
        "Average":31.73,
        "ENEM":19.8,
        "BLUEX":24.48,
        "OAB Exams":25.28,
        "ASSIN2 RTE":54.27,
        "ASSIN2 STS":7.47,
        "FAQUAD NLI":43.97,
        "HateBR":33.65,
        "PT Hate Speech":41.23,
        "tweetSentBR":35.37,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"?",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":7.0,
        "Hub":1,
        "Model sha":"464ab3beee06456a9fae8e928b4fa8e724b2d416",
        "Evaluation Time (s)":4767.39,
        "Leaderboard Average":null,
        "NPM (Average)":-2.89
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_7b",
        "Average":30.92,
        "ENEM":21.2,
        "BLUEX":21.97,
        "OAB Exams":27.65,
        "ASSIN2 RTE":35.55,
        "ASSIN2 STS":16.4,
        "FAQUAD NLI":43.97,
        "HateBR":33.49,
        "PT Hate Speech":41.19,
        "tweetSentBR":36.8,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":7.0,
        "Hub":121,
        "Model sha":"6fb184ff23774c25bf84b3628e49c8b78372c7be",
        "Evaluation Time (s)":3481.21,
        "Leaderboard Average":42.31,
        "NPM (Average)":-5.67
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen-72B-Chat",
        "Average":30.8,
        "ENEM":0.07,
        "BLUEX":0.7,
        "OAB Exams":0.0,
        "ASSIN2 RTE":45.21,
        "ASSIN2 STS":0.0,
        "FAQUAD NLI":6.98,
        "HateBR":84.41,
        "PT Hate Speech":67.85,
        "tweetSentBR":71.99,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"QWenLMHeadModel",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":72.29,
        "Hub":0,
        "Model sha":"6eb5569e56644ea662b048e029de9d093e97d4b6",
        "Evaluation Time (s)":42462.16,
        "Leaderboard Average":null,
        "NPM (Average)":-0.17
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_3b_v2",
        "Average":30.64,
        "ENEM":18.82,
        "BLUEX":22.95,
        "OAB Exams":26.47,
        "ASSIN2 RTE":33.42,
        "ASSIN2 STS":6.3,
        "FAQUAD NLI":43.87,
        "HateBR":33.46,
        "PT Hate Speech":41.15,
        "tweetSentBR":49.34,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":3.0,
        "Hub":113,
        "Model sha":"bce5d60d3b0c68318862270ec4e794d83308d80a",
        "Evaluation Time (s)":6716.0,
        "Leaderboard Average":40.28,
        "NPM (Average)":-5.6
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"openlm-research\/open_llama_3b",
        "Average":30.19,
        "ENEM":19.66,
        "BLUEX":22.25,
        "OAB Exams":23.05,
        "ASSIN2 RTE":35.3,
        "ASSIN2 STS":5.53,
        "FAQUAD NLI":43.97,
        "HateBR":38.84,
        "PT Hate Speech":45.76,
        "tweetSentBR":37.32,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":3.0,
        "Hub":139,
        "Model sha":"141067009124b9c0aea62c76b3eb952174864057",
        "Evaluation Time (s)":6595.53,
        "Leaderboard Average":38.26,
        "NPM (Average)":-5.55
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-1.8B",
        "Average":30.14,
        "ENEM":27.71,
        "BLUEX":25.17,
        "OAB Exams":28.79,
        "ASSIN2 RTE":42.06,
        "ASSIN2 STS":32.2,
        "FAQUAD NLI":19.97,
        "HateBR":43.17,
        "PT Hate Speech":31.88,
        "tweetSentBR":20.27,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.84,
        "Hub":0,
        "Model sha":"921f88e4573192da5a10c809ed188603ea0f3937",
        "Evaluation Time (s)":10231.22,
        "Leaderboard Average":null,
        "NPM (Average)":-8.41
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"allenai\/OLMo-1B",
        "Average":29.71,
        "ENEM":20.29,
        "BLUEX":18.92,
        "OAB Exams":22.96,
        "ASSIN2 RTE":34.12,
        "ASSIN2 STS":9.28,
        "FAQUAD NLI":43.97,
        "HateBR":41.33,
        "PT Hate Speech":39.62,
        "tweetSentBR":36.92,
        "Type":"pretrained",
        "Architecture":"OLMoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":1.18,
        "Hub":0,
        "Model sha":"1e16c6e12e2f1850a1b7de91594d5b5eaedd28ef",
        "Evaluation Time (s)":1802.77,
        "Leaderboard Average":null,
        "NPM (Average)":-6.62
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-6.9b",
        "Average":29.04,
        "ENEM":19.45,
        "BLUEX":20.31,
        "OAB Exams":23.01,
        "ASSIN2 RTE":59.19,
        "ASSIN2 STS":0.26,
        "FAQUAD NLI":31.22,
        "HateBR":32.77,
        "PT Hate Speech":42.47,
        "tweetSentBR":32.67,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":6.9,
        "Hub":36,
        "Model sha":"f271943e880e60c0c715fd10e4dc74ec4e31eb44",
        "Evaluation Time (s)":4572.55,
        "Leaderboard Average":null,
        "NPM (Average)":-6.56
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-7b1",
        "Average":28.87,
        "ENEM":19.45,
        "BLUEX":23.64,
        "OAB Exams":25.42,
        "ASSIN2 RTE":34.84,
        "ASSIN2 STS":9.4,
        "FAQUAD NLI":45.18,
        "HateBR":49.3,
        "PT Hate Speech":23.75,
        "tweetSentBR":28.84,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":7.07,
        "Hub":172,
        "Model sha":"6232703e399354503377bf59dfbb8397fd569e4a",
        "Evaluation Time (s)":2715.25,
        "Leaderboard Average":39.18,
        "NPM (Average)":-8.22
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nicholasKluge\/TeenyTinyLlama-460m",
        "Average":28.86,
        "ENEM":20.15,
        "BLUEX":25.73,
        "OAB Exams":27.02,
        "ASSIN2 RTE":53.61,
        "ASSIN2 STS":13.0,
        "FAQUAD NLI":46.41,
        "HateBR":33.59,
        "PT Hate Speech":22.99,
        "tweetSentBR":17.28,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":0.47,
        "Hub":2,
        "Model sha":"d50ead046069983a1779a2f7fc6e70d182bafb3b",
        "Evaluation Time (s)":2562.84,
        "Leaderboard Average":null,
        "NPM (Average)":-8.33
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"facebook\/opt-6.7b",
        "Average":28.65,
        "ENEM":18.89,
        "BLUEX":19.05,
        "OAB Exams":22.96,
        "ASSIN2 RTE":39.13,
        "ASSIN2 STS":7.55,
        "FAQUAD NLI":43.97,
        "HateBR":36.63,
        "PT Hate Speech":53.48,
        "tweetSentBR":16.16,
        "Type":"pretrained",
        "Architecture":"OPTForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":6.7,
        "Hub":93,
        "Model sha":"a45aa65bbeb77c1558bc99bedc6779195462dab0",
        "Evaluation Time (s)":3788.3,
        "Leaderboard Average":39.08,
        "NPM (Average)":-7.39
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-1b7",
        "Average":28.56,
        "ENEM":18.96,
        "BLUEX":21.42,
        "OAB Exams":23.05,
        "ASSIN2 RTE":53.6,
        "ASSIN2 STS":4.81,
        "FAQUAD NLI":43.97,
        "HateBR":34.89,
        "PT Hate Speech":41.23,
        "tweetSentBR":15.07,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":1.72,
        "Hub":105,
        "Model sha":"cc72a88036c2fb937d65efeacc57a0c2ef5d6fe5",
        "Evaluation Time (s)":1919.79,
        "Leaderboard Average":33.98,
        "NPM (Average)":-7.3
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/phi-1_5",
        "Average":28.41,
        "ENEM":21.62,
        "BLUEX":23.5,
        "OAB Exams":23.92,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":13.02,
        "FAQUAD NLI":43.97,
        "HateBR":22.2,
        "PT Hate Speech":41.23,
        "tweetSentBR":32.88,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":0.0,
        "Hub":1233,
        "Model sha":"bffd3b29c4741576a3a97656bcb74956cffaeccf",
        "Evaluation Time (s)":3107.6,
        "Leaderboard Average":47.69,
        "NPM (Average)":-9.97
    },
    {
        "T":"\ud83d\udd36",
        "Model":"HuggingFaceTB\/cosmo-1b",
        "Average":28.36,
        "ENEM":20.78,
        "BLUEX":20.72,
        "OAB Exams":23.23,
        "ASSIN2 RTE":55.27,
        "ASSIN2 STS":7.33,
        "FAQUAD NLI":43.97,
        "HateBR":34.11,
        "PT Hate Speech":24.44,
        "tweetSentBR":25.34,
        "Type":"fine-tuned\/fp on domain-specific datasets",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":1.74,
        "Hub":92,
        "Model sha":"0d5e341cfe835dffc81b6186f9715c094889f8ce",
        "Evaluation Time (s)":2298.66,
        "Leaderboard Average":36.59,
        "NPM (Average)":-8.52
    },
    {
        "T":"\ud83d\udcac",
        "Model":"TinyLlama\/TinyLlama-1.1B-Chat-v1.0",
        "Average":28.22,
        "ENEM":17.07,
        "BLUEX":21.56,
        "OAB Exams":23.23,
        "ASSIN2 RTE":43.9,
        "ASSIN2 STS":0.52,
        "FAQUAD NLI":43.97,
        "HateBR":33.33,
        "PT Hate Speech":42.33,
        "tweetSentBR":28.04,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":1.1,
        "Hub":841,
        "Model sha":"77e23968eed12d195bd46c519aa679cc22a27ddc",
        "Evaluation Time (s)":3719.38,
        "Leaderboard Average":37.17,
        "NPM (Average)":-8.11
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nicholasKluge\/TeenyTinyLlama-160m",
        "Average":28.2,
        "ENEM":19.24,
        "BLUEX":23.09,
        "OAB Exams":22.37,
        "ASSIN2 RTE":53.97,
        "ASSIN2 STS":0.24,
        "FAQUAD NLI":43.97,
        "HateBR":36.92,
        "PT Hate Speech":42.63,
        "tweetSentBR":11.39,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":0.16,
        "Hub":4,
        "Model sha":"5a878fdaf9f180cdeeb0f716ffd7c1c562635451",
        "Evaluation Time (s)":4101.75,
        "Leaderboard Average":null,
        "NPM (Average)":-7.41
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"microsoft\/phi-1",
        "Average":27.54,
        "ENEM":18.33,
        "BLUEX":24.9,
        "OAB Exams":23.69,
        "ASSIN2 RTE":34.47,
        "ASSIN2 STS":2.12,
        "FAQUAD NLI":43.97,
        "HateBR":34.69,
        "PT Hate Speech":41.11,
        "tweetSentBR":24.55,
        "Type":"pretrained",
        "Architecture":"PhiForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":0.0,
        "Hub":182,
        "Model sha":"a1a59319a7de4307ed0a44f319e04b03b07f9988",
        "Evaluation Time (s)":3100.91,
        "Leaderboard Average":null,
        "NPM (Average)":-9.85
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"croissantllm\/CroissantLLMBase",
        "Average":27.52,
        "ENEM":20.01,
        "BLUEX":25.17,
        "OAB Exams":25.38,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":13.49,
        "FAQUAD NLI":43.97,
        "HateBR":33.49,
        "PT Hate Speech":37.8,
        "tweetSentBR":15.07,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":0.0,
        "Hub":24,
        "Model sha":"b22c20207a5a1b2b4bb3f2b511096c1f0cc95b81",
        "Evaluation Time (s)":2977.77,
        "Leaderboard Average":33.99,
        "NPM (Average)":-10.85
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"dynamofl\/dynamo-8B-v0.1",
        "Average":26.09,
        "ENEM":18.4,
        "BLUEX":20.72,
        "OAB Exams":13.21,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":22.4,
        "FAQUAD NLI":17.72,
        "HateBR":33.33,
        "PT Hate Speech":22.99,
        "tweetSentBR":52.68,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"MistralForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":8.27,
        "Hub":14,
        "Model sha":"14accdba043e9fff0ec02ad73250b9a6709e863b",
        "Evaluation Time (s)":11086.61,
        "Leaderboard Average":null,
        "NPM (Average)":-14.86
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"Qwen\/Qwen1.5-0.5B",
        "Average":25.74,
        "ENEM":19.24,
        "BLUEX":18.92,
        "OAB Exams":23.05,
        "ASSIN2 RTE":26.69,
        "ASSIN2 STS":15.33,
        "FAQUAD NLI":52.54,
        "HateBR":33.33,
        "PT Hate Speech":27.43,
        "tweetSentBR":15.15,
        "Type":"pretrained",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"other",
        "#Params (B)":0.62,
        "Hub":73,
        "Model sha":"fedce23ef6393499effdf4958f9b3256f299cc7d",
        "Evaluation Time (s)":11626.85,
        "Leaderboard Average":38.62,
        "NPM (Average)":-13.95
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"nicholasKluge\/TeenyTinyLlama-460m-Chat",
        "Average":25.49,
        "ENEM":20.29,
        "BLUEX":25.45,
        "OAB Exams":26.74,
        "ASSIN2 RTE":43.77,
        "ASSIN2 STS":4.52,
        "FAQUAD NLI":34.0,
        "HateBR":33.49,
        "PT Hate Speech":22.99,
        "tweetSentBR":18.13,
        "Type":"pretrained",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":0.47,
        "Hub":1,
        "Model sha":"fa05f58e7523d890c040a81172634d42a3f50f10",
        "Evaluation Time (s)":2401.98,
        "Leaderboard Average":null,
        "NPM (Average)":-13.94
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"bigscience\/bloom-560m",
        "Average":25.43,
        "ENEM":19.03,
        "BLUEX":18.92,
        "OAB Exams":23.05,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":8.48,
        "FAQUAD NLI":43.97,
        "HateBR":37.07,
        "PT Hate Speech":24.29,
        "tweetSentBR":20.74,
        "Type":"pretrained",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":0.56,
        "Hub":317,
        "Model sha":"ac2ae5fab2ce3f9f40dc79b5ca9f637430d24971",
        "Evaluation Time (s)":1520.0,
        "Leaderboard Average":30.13,
        "NPM (Average)":-13.93
    },
    {
        "T":"\ud83d\udcac",
        "Model":"Qwen\/Qwen1.5-0.5B-Chat",
        "Average":25.38,
        "ENEM":26.66,
        "BLUEX":25.45,
        "OAB Exams":27.11,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":6.88,
        "FAQUAD NLI":18.27,
        "HateBR":33.43,
        "PT Hate Speech":22.99,
        "tweetSentBR":34.34,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"Qwen2ForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":0.62,
        "Hub":0,
        "Model sha":"7f630fd18dccab574ab1b78411a8753f989a55ac",
        "Evaluation Time (s)":2443.54,
        "Leaderboard Average":null,
        "NPM (Average)":-15.6
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"EleutherAI\/pythia-1b",
        "Average":25.23,
        "ENEM":18.96,
        "BLUEX":19.19,
        "OAB Exams":24.15,
        "ASSIN2 RTE":46.5,
        "ASSIN2 STS":0.0,
        "FAQUAD NLI":43.97,
        "HateBR":33.33,
        "PT Hate Speech":22.99,
        "tweetSentBR":18.01,
        "Type":"pretrained",
        "Architecture":"GPTNeoXForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":1.08,
        "Hub":30,
        "Model sha":"f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2",
        "Evaluation Time (s)":1708.2,
        "Leaderboard Average":null,
        "NPM (Average)":-13.32
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"pierreguillou\/gpt2-small-portuguese",
        "Average":21.64,
        "ENEM":19.31,
        "BLUEX":21.42,
        "OAB Exams":3.14,
        "ASSIN2 RTE":33.59,
        "ASSIN2 STS":3.44,
        "FAQUAD NLI":43.97,
        "HateBR":33.33,
        "PT Hate Speech":22.99,
        "tweetSentBR":13.62,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"mit",
        "#Params (B)":0.0,
        "Hub":36,
        "Model sha":"89a916c041b54c8b925e1a3282a5a334684280cb",
        "Evaluation Time (s)":1033.62,
        "Leaderboard Average":null,
        "NPM (Average)":-19.28
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"HeyLucasLeao\/gpt-neo-small-portuguese",
        "Average":20.33,
        "ENEM":16.45,
        "BLUEX":3.89,
        "OAB Exams":2.32,
        "ASSIN2 RTE":35.29,
        "ASSIN2 STS":4.08,
        "FAQUAD NLI":43.97,
        "HateBR":33.33,
        "PT Hate Speech":28.55,
        "tweetSentBR":15.07,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"",
        "#Params (B)":0.0,
        "Hub":6,
        "Model sha":"6c55098b12753c7a0848203d33195f6fa07cd092",
        "Evaluation Time (s)":6401.17,
        "Leaderboard Average":null,
        "NPM (Average)":-20.43
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-portuguese-124M",
        "Average":20.27,
        "ENEM":20.36,
        "BLUEX":17.11,
        "OAB Exams":22.23,
        "ASSIN2 RTE":42.52,
        "ASSIN2 STS":2.92,
        "FAQUAD NLI":5.8,
        "HateBR":33.33,
        "PT Hate Speech":22.99,
        "tweetSentBR":15.21,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"apache-2.0",
        "#Params (B)":0.12,
        "Hub":2,
        "Model sha":"3e8a7225792db123fcba1062204bcf318bf128b5",
        "Evaluation Time (s)":1366.85,
        "Leaderboard Average":null,
        "NPM (Average)":-22.53
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"josu\/gpt-neo-pt-br",
        "Average":19.54,
        "ENEM":20.43,
        "BLUEX":17.66,
        "OAB Exams":22.32,
        "ASSIN2 RTE":14.28,
        "ASSIN2 STS":1.54,
        "FAQUAD NLI":25.54,
        "HateBR":22.09,
        "PT Hate Speech":41.23,
        "tweetSentBR":10.76,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":0.0,
        "Hub":4,
        "Model sha":"d165dd45ecfa43332bb00f77dfd20026d628d9ee",
        "Evaluation Time (s)":4472.3,
        "Leaderboard Average":null,
        "NPM (Average)":-24.16
    },
    {
        "T":"\ud83d\udcac",
        "Model":"lrds-code\/samba-1.1B",
        "Average":16.89,
        "ENEM":10.22,
        "BLUEX":8.07,
        "OAB Exams":15.03,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":1.3,
        "FAQUAD NLI":17.72,
        "HateBR":35.79,
        "PT Hate Speech":27.26,
        "tweetSentBR":3.27,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"LlamaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"llama2",
        "#Params (B)":1.1,
        "Hub":3,
        "Model sha":"4878a7614d32b8a051ed628c8986e29e9a8ee4a3",
        "Evaluation Time (s)":9901.11,
        "Leaderboard Average":null,
        "NPM (Average)":-26.6
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"pucpr\/gpt2-bio-pt",
        "Average":15.31,
        "ENEM":18.12,
        "BLUEX":12.93,
        "OAB Exams":22.05,
        "ASSIN2 RTE":11.32,
        "ASSIN2 STS":3.48,
        "FAQUAD NLI":19.57,
        "HateBR":24.74,
        "PT Hate Speech":15.33,
        "tweetSentBR":10.21,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"GPT2LMHeadModel",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":0.0,
        "Hub":7,
        "Model sha":"0ac35845ee873b296669458a7f392d3f31d0f9b0",
        "Evaluation Time (s)":4156.43,
        "Leaderboard Average":null,
        "NPM (Average)":-31.89
    },
    {
        "T":"\ud83d\udcac",
        "Model":"eduagarcia\/gemma-7b-it_singleturn_chat_template",
        "Average":14.27,
        "ENEM":0.0,
        "BLUEX":0.14,
        "OAB Exams":0.05,
        "ASSIN2 RTE":33.33,
        "ASSIN2 STS":0.0,
        "FAQUAD NLI":17.72,
        "HateBR":33.33,
        "PT Hate Speech":22.99,
        "tweetSentBR":20.85,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"GemmaForCausalLM",
        "Precision":"bfloat16",
        "Merged":false,
        "Hub License":"?",
        "#Params (B)":8.54,
        "Hub":0,
        "Model sha":"90efffa5e7506bb0a040c1fd12c21f47dcc1e829",
        "Evaluation Time (s)":4998.3,
        "Leaderboard Average":null,
        "NPM (Average)":-30.07
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"monilouise\/opt125M_portuguese",
        "Average":13.41,
        "ENEM":0.56,
        "BLUEX":0.7,
        "OAB Exams":10.66,
        "ASSIN2 RTE":24.43,
        "ASSIN2 STS":1.6,
        "FAQUAD NLI":27.88,
        "HateBR":23.0,
        "PT Hate Speech":12.96,
        "tweetSentBR":18.88,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"OPTForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":0.12,
        "Hub":2,
        "Model sha":"1630c0e2b763f11dc825c3530ae120f0b2fa4531",
        "Evaluation Time (s)":5016.76,
        "Leaderboard Average":null,
        "NPM (Average)":-32.83
    },
    {
        "T":"\ud83c\udd8e",
        "Model":"josu\/gpt-neo-pt-1.3B",
        "Average":11.25,
        "ENEM":19.31,
        "BLUEX":18.36,
        "OAB Exams":23.01,
        "ASSIN2 RTE":0.59,
        "ASSIN2 STS":3.78,
        "FAQUAD NLI":0.0,
        "HateBR":24.13,
        "PT Hate Speech":12.11,
        "tweetSentBR":0.0,
        "Type":"language adapted models (FP, FT, ...)",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":1.3,
        "Hub":0,
        "Model sha":"53e4511f9f6793718d613be0c8af157753bf2b66",
        "Evaluation Time (s)":11983.19,
        "Leaderboard Average":null,
        "NPM (Average)":-39.66
    },
    {
        "T":"\ud83d\udfe2",
        "Model":"NOVA-vision-language\/GlorIA-1.3B",
        "Average":4.1,
        "ENEM":1.89,
        "BLUEX":3.2,
        "OAB Exams":5.19,
        "ASSIN2 RTE":0.0,
        "ASSIN2 STS":2.32,
        "FAQUAD NLI":0.26,
        "HateBR":0.28,
        "PT Hate Speech":23.52,
        "tweetSentBR":0.19,
        "Type":"pretrained",
        "Architecture":"GPTNeoForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":null,
        "#Params (B)":1.42,
        "Hub":15,
        "Model sha":"a95ffb65726dda96fc05ce00de24feac1ad1df61",
        "Evaluation Time (s)":16167.89,
        "Leaderboard Average":null,
        "NPM (Average)":-49.97
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-portuguese-1B7",
        "Average":3.82,
        "ENEM":3.92,
        "BLUEX":0.28,
        "OAB Exams":7.56,
        "ASSIN2 RTE":2.53,
        "ASSIN2 STS":1.04,
        "FAQUAD NLI":1.99,
        "HateBR":16.98,
        "PT Hate Speech":0.11,
        "tweetSentBR":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":1.72,
        "Hub":2,
        "Model sha":"bfb868dd8666717715ee0f42dbe3cce33ca4808e",
        "Evaluation Time (s)":7241.43,
        "Leaderboard Average":null,
        "NPM (Average)":-50.3
    },
    {
        "T":"\ud83d\udcac",
        "Model":"nicholasKluge\/Aira-2-portuguese-560M",
        "Average":0.13,
        "ENEM":0.0,
        "BLUEX":0.0,
        "OAB Exams":0.0,
        "ASSIN2 RTE":0.0,
        "ASSIN2 STS":0.0,
        "FAQUAD NLI":0.0,
        "HateBR":1.2,
        "PT Hate Speech":0.0,
        "tweetSentBR":0.0,
        "Type":"chat models (RLHF, DPO, IFT, ...)",
        "Architecture":"BloomForCausalLM",
        "Precision":"float16",
        "Merged":false,
        "Hub License":"bigscience-bloom-rail-1.0",
        "#Params (B)":0.56,
        "Hub":2,
        "Model sha":"bb90268252bc87eddb97867f08f6b3449b21c35b",
        "Evaluation Time (s)":10135.39,
        "Leaderboard Average":null,
        "NPM (Average)":-56.62
    }
]