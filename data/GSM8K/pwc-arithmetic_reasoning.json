[
    {
        "table_id":17749,
        "row_id":104974,
        "rank":1,
        "method":"GPT-4 Code Interpreter (CSV, K=5)",
        "mlmodel":{

        },
        "Model":"GPT-4 Code Interpreter ",
        "method_details":"CSV, K=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-15",
        "metrics":{
            "Accuracy":"97.0",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":97.0,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1263883,
            "title":"Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification",
            "url":"\/paper\/solving-challenging-math-word-problems-using",
            "published":"2023-08-15T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":107566,
        "rank":2,
        "method":"GPT-4 (Model Selection, SC K=15)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"Model Selection, SC K=15",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "Accuracy":"96.8",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":96.8,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1214247,
            "title":"Automatic Model Selection with Large Language Models for Reasoning",
            "url":"\/paper\/automatic-model-selection-with-large-language",
            "published":"2023-05-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automatic-model-selection-with-large-language\/review\/?hl=107566"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":104254,
        "rank":3,
        "method":"GPT-4 (PHP, SC K=40)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"PHP, SC K=40",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-19",
        "metrics":{
            "Accuracy":"96.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":96.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1193695,
            "title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models",
            "url":"\/paper\/progressive-hint-prompting-improves-reasoning",
            "published":"2023-04-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/progressive-hint-prompting-improves-reasoning\/review\/?hl=104254"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":104531,
        "rank":4,
        "method":"GPT-4 (Model Selection, SC K=5)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"Model Selection, SC K=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-23",
        "metrics":{
            "Accuracy":"96.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":96.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1214247,
            "title":"Automatic Model Selection with Large Language Models for Reasoning",
            "url":"\/paper\/automatic-model-selection-with-large-language",
            "published":"2023-05-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/automatic-model-selection-with-large-language\/review\/?hl=104531"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":101477,
        "rank":5,
        "method":"GPT-4 (PHP)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"PHP",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-19",
        "metrics":{
            "Accuracy":"95.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":95.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1193695,
            "title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models",
            "url":"\/paper\/progressive-hint-prompting-improves-reasoning",
            "published":"2023-04-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/progressive-hint-prompting-improves-reasoning\/review\/?hl=101477"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":113524,
        "rank":6,
        "method":"Gemini Ultra (Maj1@32)",
        "mlmodel":{

        },
        "Model":"Gemini Ultra ",
        "method_details":"Maj1@32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-06",
        "metrics":{
            "Accuracy":"94.4",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":94.4,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336342,
            "title":"Gemini: A Family of Highly Capable Multimodal Models",
            "url":"\/paper\/gemini-a-family-of-highly-capable-multimodal",
            "published":"2023-12-06T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":114119,
        "rank":7,
        "method":"GPT-4 (Ask, Refine, Trust)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"Ask, Refine, Trust",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-14",
        "metrics":{
            "Accuracy":"94.08",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":94.08,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1320809,
            "title":"The ART of LLM Refinement: Ask, Refine, and Trust",
            "url":"\/paper\/the-art-of-llm-refinement-ask-refine-and",
            "published":"2023-11-14T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":103604,
        "rank":8,
        "method":"GPT-4 (Self-Refine, k=8, PaL)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"Self-Refine, k=8, PaL",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy":"93.1",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":93.1,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            },
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":103605,
        "rank":9,
        "method":"GPT-4 (PaL, k=8)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"PaL, k=8",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-18",
        "metrics":{
            "Accuracy":"92.9",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":92.9,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1114019,
            "title":"PAL: Program-aided Language Models",
            "url":"\/paper\/pal-program-aided-language-models",
            "published":"2022-11-18T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            },
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":99250,
        "rank":10,
        "method":"GPT-4 (few-shot, k=5, CoT)",
        "mlmodel":{

        },
        "Model":"GPT-4 ",
        "method_details":"few-shot, k=5, CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "Accuracy":"92",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":92.0,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=99250"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            },
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":102857,
        "rank":11,
        "method":"PaLM 2 (few-shot, k=8, SC)",
        "mlmodel":{

        },
        "Model":"PaLM 2 ",
        "method_details":"few-shot, k=8, SC",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"91.0",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":91.0,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210556,
            "title":"PaLM 2 Technical Report",
            "url":"\/paper\/palm-2-technical-report-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/palm-2-technical-report-1\/review\/?hl=102857"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110087,
        "rank":12,
        "method":"ToRA-70B (SC, k=50)",
        "mlmodel":{

        },
        "Model":"ToRA-70B ",
        "method_details":"SC, k=50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"88.3",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":88.3,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=110087"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97206,
        "rank":13,
        "method":"DeepMind 70B Model (SFT+ORM-RL, ORM reranking)",
        "mlmodel":{

        },
        "Model":"DeepMind 70B Model ",
        "method_details":"SFT+ORM-RL, ORM reranking",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-25",
        "metrics":{
            "Accuracy":"87.3",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":87.3,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1117491,
            "title":"Solving math word problems with process- and outcome-based feedback",
            "url":"\/paper\/solving-math-word-problems-with-process-and",
            "published":"2022-11-25T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":494,
                "name":"rerank",
                "color":"#27d3bf"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97208,
        "rank":14,
        "method":"DeepMind 70B Model (SFT+PRM-RL, PRM reranking)",
        "mlmodel":{

        },
        "Model":"DeepMind 70B Model ",
        "method_details":"SFT+PRM-RL, PRM reranking",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-25",
        "metrics":{
            "Accuracy":"87.1",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":87.1,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1117491,
            "title":"Solving math word problems with process- and outcome-based feedback",
            "url":"\/paper\/solving-math-word-problems-with-process-and",
            "published":"2022-11-25T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":494,
                "name":"rerank",
                "color":"#27d3bf"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":100625,
        "rank":15,
        "method":"GPT-4",
        "mlmodel":{

        },
        "Model":"GPT-4",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-22",
        "metrics":{
            "Accuracy":"87.1",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":87.1,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1178434,
            "title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4",
            "url":"\/paper\/sparks-of-artificial-general-intelligence",
            "published":"2023-03-22T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":113525,
        "rank":16,
        "method":"Gemini Pro (Maj1@32)",
        "mlmodel":{

        },
        "Model":"Gemini Pro ",
        "method_details":"Maj1@32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-06",
        "metrics":{
            "Accuracy":"86.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":86.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336342,
            "title":"Gemini: A Family of Highly Capable Multimodal Models",
            "url":"\/paper\/gemini-a-family-of-highly-capable-multimodal",
            "published":"2023-12-06T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":104119,
        "rank":17,
        "method":"Codex (Self-Evaluation Guided Decoding, PAL, multiple reasoning chains, 9-shot gen, 5-shot eval)",
        "mlmodel":{

        },
        "Model":"Codex ",
        "method_details":"Self-Evaluation Guided Decoding, PAL, multiple reasoning chains, 9-shot gen, 5-shot eval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy":"85.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":85.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110088,
        "rank":18,
        "method":"ToRA-Code-34B (SC, k=50)",
        "mlmodel":{

        },
        "Model":"ToRA-Code-34B ",
        "method_details":"SC, k=50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"85.1",
            "Parameters (Billion)":"34"
        },
        "raw_metrics":{
            "Accuracy":85.1,
            "Parameters (Billion)":34.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=110088"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112537,
        "rank":19,
        "method":"OVM-Mistral-7B (OVM planning, k=100)",
        "mlmodel":{

        },
        "Model":"OVM-Mistral-7B ",
        "method_details":"OVM planning, k=100",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-16",
        "metrics":{
            "Accuracy":"84.7",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":84.7,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1322273,
            "title":"Outcome-supervised Verifiers for Planning in Mathematical Reasoning",
            "url":"\/paper\/outcome-supervised-verifiers-for-planning-in",
            "published":"2023-11-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97328,
        "rank":20,
        "method":"Codex (LEVER, 8-shot)",
        "mlmodel":{

        },
        "Model":"Codex ",
        "method_details":"LEVER, 8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-16",
        "metrics":{
            "Accuracy":"84.5",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":84.5,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1158598,
            "title":"LEVER: Learning to Verify Language-to-Code Generation with Execution",
            "url":"\/paper\/lever-learning-to-verify-language-to-code",
            "published":"2023-02-16T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/lever-learning-to-verify-language-to-code\/review\/?hl=97328"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109549,
        "rank":21,
        "method":"ToRA 70B",
        "mlmodel":{

        },
        "Model":"ToRA 70B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"84.3",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":84.3,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=109549"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58539,
        "rank":22,
        "method":"DIVERSE 175B (8-shot)",
        "mlmodel":{

        },
        "Model":"DIVERSE 175B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-06",
        "metrics":{
            "Accuracy":"83.2",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":83.2,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1022171,
            "title":"Making Large Language Models Better Reasoners with Step-Aware Verifier",
            "url":"\/paper\/on-the-advance-of-making-language-models",
            "published":"2022-06-06T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/on-the-advance-of-making-language-models\/review\/?hl=58539"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112538,
        "rank":23,
        "method":"OVM-Mistral-7B (OVM planning, k=20)",
        "mlmodel":{

        },
        "Model":"OVM-Mistral-7B ",
        "method_details":"OVM planning, k=20",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-16",
        "metrics":{
            "Accuracy":"82.6",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":82.6,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1322273,
            "title":"Outcome-supervised Verifiers for Planning in Mathematical Reasoning",
            "url":"\/paper\/outcome-supervised-verifiers-for-planning-in",
            "published":"2023-11-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":114120,
        "rank":24,
        "method":"ChatGPT (Ask, Refine, Trust)",
        "mlmodel":{

        },
        "Model":"ChatGPT ",
        "method_details":"Ask, Refine, Trust",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-14",
        "metrics":{
            "Accuracy":"82.6",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":82.6,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1320809,
            "title":"The ART of LLM Refinement: Ask, Refine, and Trust",
            "url":"\/paper\/the-art-of-llm-refinement-ask-refine-and",
            "published":"2023-11-14T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109140,
        "rank":25,
        "method":"MetaMath 70B",
        "mlmodel":{

        },
        "Model":"MetaMath 70B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-21",
        "metrics":{
            "Accuracy":"82.3",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":82.3,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1284859,
            "title":"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
            "url":"\/paper\/metamath-bootstrap-your-own-mathematical",
            "published":"2023-09-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110828,
        "rank":26,
        "method":"MuggleMATH 70B",
        "mlmodel":{

        },
        "Model":"MuggleMATH 70B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-09",
        "metrics":{
            "Accuracy":"82.3",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":82.3,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1296546,
            "title":"Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization",
            "url":"\/paper\/query-and-response-augmentation-cannot-help",
            "published":"2023-10-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/query-and-response-augmentation-cannot-help\/review\/?hl=110828"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73274,
        "rank":27,
        "method":"PaLM 540B (Self Improvement, Self Consistency)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"Self Improvement, Self Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"82.1",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":82.1,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73274"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109550,
        "rank":28,
        "method":"ToRA-Code 34B",
        "mlmodel":{

        },
        "Model":"ToRA-Code 34B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"80.7",
            "Parameters (Billion)":"34"
        },
        "raw_metrics":{
            "Accuracy":80.7,
            "Parameters (Billion)":34.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=109550"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":102856,
        "rank":29,
        "method":"PaLM 2 (few-shot, k=8, CoT)",
        "mlmodel":{

        },
        "Model":"PaLM 2 ",
        "method_details":"few-shot, k=8, CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-17",
        "metrics":{
            "Accuracy":"80.7",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":80.7,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1210556,
            "title":"PaLM 2 Technical Report",
            "url":"\/paper\/palm-2-technical-report-1",
            "published":"2023-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/palm-2-technical-report-1\/review\/?hl=102856"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":104138,
        "rank":30,
        "method":"Self-Evaluation Guided Decoding (Codex, PAL, single reasoning chain, 9-shot gen, 5-shot eval)",
        "mlmodel":{

        },
        "Model":"Self-Evaluation Guided Decoding ",
        "method_details":"Codex, PAL, single reasoning chain, 9-shot gen, 5-shot eval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy":"80.2",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":80.2,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":69563,
        "rank":31,
        "method":"Minerva 540B-maj1@k (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 540B-maj1@k ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"78.5",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":78.5,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=69563"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110857,
        "rank":32,
        "method":"MetaMath-Mistral-7B",
        "mlmodel":{

        },
        "Model":"MetaMath-Mistral-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-21",
        "metrics":{
            "Accuracy":"77.7",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":77.7,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1284859,
            "title":"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
            "url":"\/paper\/metamath-bootstrap-your-own-mathematical",
            "published":"2023-09-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97207,
        "rank":33,
        "method":"DeepMind 70B Model (STaR, maj1@96)",
        "mlmodel":{

        },
        "Model":"DeepMind 70B Model ",
        "method_details":"STaR, maj1@96",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-25",
        "metrics":{
            "Accuracy":"76.5",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":76.5,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1117491,
            "title":"Solving math word problems with process- and outcome-based feedback",
            "url":"\/paper\/solving-math-word-problems-with-process-and",
            "published":"2022-11-25T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109551,
        "rank":34,
        "method":"ToRA-Code 13B",
        "mlmodel":{

        },
        "Model":"ToRA-Code 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"75.8",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":75.8,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=109551"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110633,
        "rank":35,
        "method":"Arithmo-Mistral-7B",
        "mlmodel":{

        },
        "Model":"Arithmo-Mistral-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-19",
        "metrics":{
            "Accuracy":"74.7",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":74.7,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58538,
        "rank":36,
        "method":"PaLM 540B maj1@40 (8-shot)",
        "mlmodel":{

        },
        "Model":"PaLM 540B maj1@40 ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-21",
        "metrics":{
            "Accuracy":"74.4",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":74.4,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":979919,
            "title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models",
            "url":"\/paper\/self-consistency-improves-chain-of-thought",
            "published":"2022-03-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-consistency-improves-chain-of-thought\/review\/?hl=58538"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            },
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73256,
        "rank":37,
        "method":"PaLM 540B (Self Consistency)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"Self Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"74.4",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":74.4,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73256"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":398,
                "name":"majority voting",
                "color":"#32d327"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110829,
        "rank":38,
        "method":"MuggleMATH 13B",
        "mlmodel":{

        },
        "Model":"MuggleMATH 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-09",
        "metrics":{
            "Accuracy":"74",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":74.0,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1296546,
            "title":"Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization",
            "url":"\/paper\/query-and-response-augmentation-cannot-help",
            "published":"2023-10-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/query-and-response-augmentation-cannot-help\/review\/?hl=110829"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":327,
                "name":"Finetuned",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":102951,
        "rank":39,
        "method":"CodeT5+",
        "mlmodel":{

        },
        "Model":"CodeT5+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-13",
        "metrics":{
            "Accuracy":"73.8",
            "Parameters (Billion)":"0.77"
        },
        "raw_metrics":{
            "Accuracy":73.8,
            "Parameters (Billion)":0.77
        },
        "uses_additional_data":false,
        "paper":{
            "id":1208032,
            "title":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation",
            "url":"\/paper\/codet5-open-code-large-language-models-for",
            "published":"2023-05-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/codet5-open-code-large-language-models-for\/review\/?hl=102951"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112539,
        "rank":40,
        "method":"OVM-Llama2-7B (OVM planning, k=100)",
        "mlmodel":{

        },
        "Model":"OVM-Llama2-7B ",
        "method_details":"OVM planning, k=100",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-16",
        "metrics":{
            "Accuracy":"73.7",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":73.7,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1322273,
            "title":"Outcome-supervised Verifiers for Planning in Mathematical Reasoning",
            "url":"\/paper\/outcome-supervised-verifiers-for-planning-in",
            "published":"2023-11-16T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73268,
        "rank":41,
        "method":"PaLM 540B (Self Improvement, CoT Prompting)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"Self Improvement, CoT Prompting",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"73.5",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":73.5,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73268"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110449,
        "rank":42,
        "method":"KwaiYiiMath 13B",
        "mlmodel":{

        },
        "Model":"KwaiYiiMath 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-11",
        "metrics":{
            "Accuracy":"73.3",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":73.3,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1298876,
            "title":"KwaiYiiMath: Technical Report",
            "url":"\/paper\/kwaiyiimath-technical-report",
            "published":"2023-10-11T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/kwaiyiimath-technical-report\/review\/?hl=110449"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109552,
        "rank":43,
        "method":"ToRA-Code 7B",
        "mlmodel":{

        },
        "Model":"ToRA-Code 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-29",
        "metrics":{
            "Accuracy":"72.6",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":72.6,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1291119,
            "title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
            "url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for",
            "published":"2023-09-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/tora-a-tool-integrated-reasoning-agent-for\/review\/?hl=109552"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":104139,
        "rank":44,
        "method":"Self-Evaluation Guided Decoding (Codex, CoT, single reasoning chain, 9-shot gen, 5-shot eval)",
        "mlmodel":{

        },
        "Model":"Self-Evaluation Guided Decoding ",
        "method_details":"Codex, CoT, single reasoning chain, 9-shot gen, 5-shot eval",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy":"71.9",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":71.9,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109141,
        "rank":45,
        "method":"MetaMath 13B",
        "mlmodel":{

        },
        "Model":"MetaMath 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-21",
        "metrics":{
            "Accuracy":"71.0",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":71.0,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1284859,
            "title":"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
            "url":"\/paper\/metamath-bootstrap-your-own-mathematical",
            "published":"2023-09-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97671,
        "rank":46,
        "method":"LLaMA 65B-maj1@k",
        "mlmodel":{

        },
        "Model":"LLaMA 65B-maj1@k",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"69.7",
            "Parameters (Billion)":"65"
        },
        "raw_metrics":{
            "Accuracy":69.7,
            "Parameters (Billion)":65.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97671"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58542,
        "rank":47,
        "method":"Minerva 62B-maj1@100 (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 62B-maj1@100 ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"68.5",
            "Parameters (Billion)":"62"
        },
        "raw_metrics":{
            "Accuracy":68.5,
            "Parameters (Billion)":62.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58542"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110830,
        "rank":48,
        "method":"MuggleMATH 7B",
        "mlmodel":{

        },
        "Model":"MuggleMATH 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-09",
        "metrics":{
            "Accuracy":"68.4",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":68.4,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1296546,
            "title":"Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization",
            "url":"\/paper\/query-and-response-augmentation-cannot-help",
            "published":"2023-10-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/query-and-response-augmentation-cannot-help\/review\/?hl=110830"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":327,
                "name":"Finetuned",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":98743,
        "rank":49,
        "method":"code-davinci-002 (Least-to-Most Prompting)",
        "mlmodel":{

        },
        "Model":"code-davinci-002 ",
        "method_details":"Least-to-Most Prompting",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-21",
        "metrics":{
            "Accuracy":"68.01",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":68.01,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1014054,
            "title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
            "url":"\/paper\/least-to-most-prompting-enables-complex",
            "published":"2022-05-21T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/least-to-most-prompting-enables-complex\/review\/?hl=98743"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":109142,
        "rank":50,
        "method":"MetaMath 7B",
        "mlmodel":{

        },
        "Model":"MetaMath 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-21",
        "metrics":{
            "Accuracy":"66.4",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":66.4,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1284859,
            "title":"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
            "url":"\/paper\/metamath-bootstrap-your-own-mathematical",
            "published":"2023-09-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110854,
        "rank":51,
        "method":"RFT 70B",
        "mlmodel":{

        },
        "Model":"RFT 70B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-13",
        "metrics":{
            "Accuracy":"64.8",
            "Parameters (Billion)":"79"
        },
        "raw_metrics":{
            "Accuracy":64.8,
            "Parameters (Billion)":79.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1257887,
            "title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models",
            "url":"\/paper\/scaling-relationship-on-learning-mathematical",
            "published":"2023-08-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-relationship-on-learning-mathematical\/review\/?hl=110854"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73803,
        "rank":52,
        "method":"GPT-J(CoRe)",
        "mlmodel":{

        },
        "Model":"GPT-J",
        "method_details":"CoRe",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-28",
        "metrics":{
            "Accuracy":"63.2",
            "Parameters (Billion)":"12"
        },
        "raw_metrics":{
            "Accuracy":63.2,
            "Parameters (Billion)":12.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1102179,
            "title":"Solving Math Word Problems via Cooperative Reasoning induced Language Models",
            "url":"\/paper\/solving-math-word-problem-via-cooperative",
            "published":"2022-10-28T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112811,
        "rank":53,
        "method":"Orca 2-13B",
        "mlmodel":{

        },
        "Model":"Orca 2-13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-18",
        "metrics":{
            "Accuracy":"59.14",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":59.14,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323875,
            "title":"Orca 2: Teaching Small Language Models How to Reason",
            "url":"\/paper\/orca-2-teaching-small-language-models-how-to",
            "published":"2023-11-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/orca-2-teaching-small-language-models-how-to\/review\/?hl=112811"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58540,
        "rank":54,
        "method":"Minerva 540B (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 540B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"58.8",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":58.8,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58540"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":72749,
        "rank":55,
        "method":"U-PaLM",
        "mlmodel":{

        },
        "Model":"U-PaLM",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"58.5",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":58.5,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097009,
            "title":"Transcending Scaling Laws with 0.1% Extra Compute",
            "url":"\/paper\/transcending-scaling-laws-with-0-1-extra",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/transcending-scaling-laws-with-0-1-extra\/review\/?hl=72749"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":318,
                "name":"chain-of-thought",
                "color":"#eea320"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55462,
        "rank":56,
        "method":"PaLM-540B (few-Shot-cot)",
        "mlmodel":{

        },
        "Model":"PaLM-540B ",
        "method_details":"few-Shot-cot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"58.1",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":58.1,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55462"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":99251,
        "rank":57,
        "method":"GPT-3.5 (few-shot, k=5)",
        "mlmodel":{

        },
        "Model":"GPT-3.5 ",
        "method_details":"few-shot, k=5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "Accuracy":"57.1",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":57.1,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1174373,
            "title":"GPT-4 Technical Report",
            "url":"\/paper\/gpt-4-technical-report-1",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/gpt-4-technical-report-1\/review\/?hl=99251"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":106290,
        "rank":58,
        "method":"LLaMA 2 70B (on-shot)",
        "mlmodel":{

        },
        "Model":"LLaMA 2 70B ",
        "method_details":"on-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-18",
        "metrics":{
            "Accuracy":"56.8",
            "Parameters (Billion)":"70"
        },
        "raw_metrics":{
            "Accuracy":56.8,
            "Parameters (Billion)":70.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1248363,
            "title":"Llama 2: Open Foundation and Fine-Tuned Chat Models",
            "url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat",
            "published":"2023-07-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-2-open-foundation-and-fine-tuned-chat\/review\/?hl=106290"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58541,
        "rank":59,
        "method":"PaLM 540B (8-shot)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"56.5",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":56.5,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58541"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73250,
        "rank":60,
        "method":"PaLM 540B (CoT Prompting)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"CoT Prompting",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"56.5",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":56.5,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73250"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110855,
        "rank":61,
        "method":"RFT 13B",
        "mlmodel":{

        },
        "Model":"RFT 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-13",
        "metrics":{
            "Accuracy":"55.3",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":55.3,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1257887,
            "title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models",
            "url":"\/paper\/scaling-relationship-on-learning-mathematical",
            "published":"2023-08-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-relationship-on-learning-mathematical\/review\/?hl=110855"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55460,
        "rank":62,
        "method":"Finetuned GPT-3 175B + verifier",
        "mlmodel":{

        },
        "Model":"Finetuned GPT-3 175B + verifier",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"55.0",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":55.0,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55460"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97669,
        "rank":63,
        "method":"LLaMA 33B-maj1@k",
        "mlmodel":{

        },
        "Model":"LLaMA 33B-maj1@k",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"53.1",
            "Parameters (Billion)":"33"
        },
        "raw_metrics":{
            "Accuracy":53.1,
            "Parameters (Billion)":33.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97669"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58543,
        "rank":64,
        "method":"Minerva 62B (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 62B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":" 52.4",
            "Parameters (Billion)":"62"
        },
        "raw_metrics":{
            "Accuracy":52.4,
            "Parameters (Billion)":62.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58543"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112818,
        "rank":65,
        "method":"Mistral 7B",
        "mlmodel":{

        },
        "Model":"Mistral 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-10",
        "metrics":{
            "Accuracy":"52.2",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":52.2,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1297015,
            "title":"Mistral 7B",
            "url":"\/paper\/mistral-7b",
            "published":"2023-10-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mistral-7b\/review\/?hl=112818"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55459,
        "rank":66,
        "method":"Text-davinci-002-175B (zero-plus-few-Shot-cot (8 samples))",
        "mlmodel":{

        },
        "Model":"Text-davinci-002-175B ",
        "method_details":"zero-plus-few-Shot-cot ",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"51.5",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":51.5,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55459"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            },
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":110856,
        "rank":67,
        "method":"RFT 7B",
        "mlmodel":{

        },
        "Model":"RFT 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-13",
        "metrics":{
            "Accuracy":"51.2",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":51.2,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1257887,
            "title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models",
            "url":"\/paper\/scaling-relationship-on-learning-mathematical",
            "published":"2023-08-03T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-relationship-on-learning-mathematical\/review\/?hl=110856"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97670,
        "rank":68,
        "method":"LLaMA 65B",
        "mlmodel":{

        },
        "Model":"LLaMA 65B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"50.9",
            "Parameters (Billion)":"65"
        },
        "raw_metrics":{
            "Accuracy":50.9,
            "Parameters (Billion)":65.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97670"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":112810,
        "rank":69,
        "method":"Orca 2-7B",
        "mlmodel":{

        },
        "Model":"Orca 2-7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-18",
        "metrics":{
            "Accuracy":"47.23",
            "Parameters (Billion)":null
        },
        "raw_metrics":{
            "Accuracy":47.23,
            "Parameters (Billion)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1323875,
            "title":"Orca 2: Teaching Small Language Models How to Reason",
            "url":"\/paper\/orca-2-teaching-small-language-models-how-to",
            "published":"2023-11-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/orca-2-teaching-small-language-models-how-to\/review\/?hl=112810"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55458,
        "rank":70,
        "method":"Text-davinci-002-175B (few-shot-cot (2 samples))",
        "mlmodel":{

        },
        "Model":"Text-davinci-002-175B ",
        "method_details":"few-shot-cot ",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"41.3",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":41.3,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55458"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55453,
        "rank":71,
        "method":"Text-davinci-002-175B (zero-shot-cot)",
        "mlmodel":{

        },
        "Model":"Text-davinci-002-175B ",
        "method_details":"zero-shot-cot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"40.7",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":40.7,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55453"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97668,
        "rank":72,
        "method":"LLaMA 33B",
        "mlmodel":{

        },
        "Model":"LLaMA 33B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"35.6",
            "Parameters (Billion)":"33"
        },
        "raw_metrics":{
            "Accuracy":35.6,
            "Parameters (Billion)":33.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97668"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58544,
        "rank":73,
        "method":"PaLM 62B (8-shot)",
        "mlmodel":{

        },
        "Model":"PaLM 62B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"33.0",
            "Parameters (Billion)":"62"
        },
        "raw_metrics":{
            "Accuracy":33.0,
            "Parameters (Billion)":62.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58544"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73262,
        "rank":74,
        "method":"PaLM 540B (Self Improvement, Standard-Prompting)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"Self Improvement, Standard-Prompting",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"32.2",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":32.2,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73262"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97667,
        "rank":75,
        "method":"LLaMA 13B-maj1@k",
        "mlmodel":{

        },
        "Model":"LLaMA 13B-maj1@k",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"29.3",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":29.3,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97667"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58545,
        "rank":76,
        "method":"Minerva 8B-maj1@k (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 8B-maj1@k ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":" 28.4",
            "Parameters (Billion)":"8"
        },
        "raw_metrics":{
            "Accuracy":28.4,
            "Parameters (Billion)":8.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58545"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":100089,
        "rank":77,
        "method":"GPT-Neo-2.7B + Self-Sampling",
        "mlmodel":{

        },
        "Model":"GPT-Neo-2.7B + Self-Sampling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-28",
        "metrics":{
            "Accuracy":"19.5",
            "Parameters (Billion)":"2.7"
        },
        "raw_metrics":{
            "Accuracy":19.5,
            "Parameters (Billion)":2.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1018119,
            "title":"Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions",
            "url":"\/paper\/learning-from-self-sampled-correct-and",
            "published":"2022-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-from-self-sampled-correct-and\/review\/?hl=100089"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97665,
        "rank":78,
        "method":"LLaMA 7B-maj1@k",
        "mlmodel":{

        },
        "Model":"LLaMA 7B-maj1@k",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"18.1",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":18.1,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97665"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55461,
        "rank":79,
        "method":"PaLM 540B (few-shot)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"few-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"17.9",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":17.9,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55461"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":73244,
        "rank":80,
        "method":"PaLM 540B (Standard-Prompting)",
        "mlmodel":{

        },
        "Model":"PaLM 540B ",
        "method_details":"Standard-Prompting",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-20",
        "metrics":{
            "Accuracy":"17.9",
            "Parameters (Billion)":"540"
        },
        "raw_metrics":{
            "Accuracy":17.9,
            "Parameters (Billion)":540.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1097944,
            "title":"Large Language Models Can Self-Improve",
            "url":"\/paper\/large-language-models-can-self-improve",
            "published":"2022-10-20T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/large-language-models-can-self-improve\/review\/?hl=73244"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97666,
        "rank":81,
        "method":"LLaMA 13B",
        "mlmodel":{

        },
        "Model":"LLaMA 13B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"17.8",
            "Parameters (Billion)":"13"
        },
        "raw_metrics":{
            "Accuracy":17.8,
            "Parameters (Billion)":13.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97666"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58546,
        "rank":82,
        "method":"Minerva 8B (8-shot)",
        "mlmodel":{

        },
        "Model":"Minerva 8B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"16.2",
            "Parameters (Billion)":"8"
        },
        "raw_metrics":{
            "Accuracy":16.2,
            "Parameters (Billion)":8.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58546"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":97664,
        "rank":83,
        "method":"LLaMA 7B",
        "mlmodel":{

        },
        "Model":"LLaMA 7B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-27",
        "metrics":{
            "Accuracy":"11.0",
            "Parameters (Billion)":"7"
        },
        "raw_metrics":{
            "Accuracy":11.0,
            "Parameters (Billion)":7.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1164350,
            "title":"LLaMA: Open and Efficient Foundation Language Models",
            "url":"\/paper\/llama-open-and-efficient-foundation-language-1",
            "published":"2023-02-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/llama-open-and-efficient-foundation-language-1\/review\/?hl=97664"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":55455,
        "rank":84,
        "method":"Text-davinci-002-175B (zero-shot)",
        "mlmodel":{

        },
        "Model":"Text-davinci-002-175B ",
        "method_details":"zero-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-24",
        "metrics":{
            "Accuracy":"10.4",
            "Parameters (Billion)":"175"
        },
        "raw_metrics":{
            "Accuracy":10.4,
            "Parameters (Billion)":175.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1015166,
            "title":"Large Language Models are Zero-Shot Reasoners",
            "url":"\/paper\/large-language-models-are-zero-shot-reasoners",
            "published":"2022-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-language-models-are-zero-shot-reasoners\/review\/?hl=55455"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":188,
                "name":"zero-shot",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":100090,
        "rank":85,
        "method":"GPT-Neo-125M + Self-Sampling",
        "mlmodel":{

        },
        "Model":"GPT-Neo-125M + Self-Sampling",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-28",
        "metrics":{
            "Accuracy":"7.5",
            "Parameters (Billion)":"0.1"
        },
        "raw_metrics":{
            "Accuracy":7.5,
            "Parameters (Billion)":0.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1018119,
            "title":"Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions",
            "url":"\/paper\/learning-from-self-sampled-correct-and",
            "published":"2022-05-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-from-self-sampled-correct-and\/review\/?hl=100090"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":184,
                "name":"fine-tuned",
                "color":"#e56666"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":17749,
        "row_id":58547,
        "rank":86,
        "method":"PaLM 8B (8-shot)",
        "mlmodel":{

        },
        "Model":"PaLM 8B ",
        "method_details":"8-shot",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-06-29",
        "metrics":{
            "Accuracy":"4.1",
            "Parameters (Billion)":"8"
        },
        "raw_metrics":{
            "Accuracy":4.1,
            "Parameters (Billion)":8.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1035722,
            "title":"Solving Quantitative Reasoning Problems with Language Models",
            "url":"\/paper\/solving-quantitative-reasoning-problems-with",
            "published":"2022-06-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-quantitative-reasoning-problems-with\/review\/?hl=58547"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":183,
                "name":"few-shot",
                "color":"#a1df95"
            }
        ],
        "reports":[

        ]
    }
]