[
    {
        "table_id":22010,
        "row_id":106328,
        "rank":1,
        "Model":"MSQNet",
        "mlmodel":{

        },
        "method_short":"MSQNet",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-07-20",
        "metrics":{
            "mAP":"35.59"
        },
        "raw_metrics":{
            "mAP":35.59
        },
        "uses_additional_data":false,
        "paper":{
            "id":1249627,
            "title":"Actor-agnostic Multi-label Action Recognition with Multi-modal Query",
            "url":"\/paper\/msqnet-actor-agnostic-action-recognition-with",
            "published":"2023-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/msqnet-actor-agnostic-action-recognition-with\/review\/?hl=106328"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22010,
        "row_id":87206,
        "rank":2,
        "Model":"VideoCoCa",
        "mlmodel":{

        },
        "method_short":"VideoCoCa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-09",
        "metrics":{
            "mAP":"25.8"
        },
        "raw_metrics":{
            "mAP":25.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":1126258,
            "title":"VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners",
            "url":"\/paper\/video-text-modeling-with-zero-shot-transfer",
            "published":"2022-12-09T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/video-text-modeling-with-zero-shot-transfer\/review\/?hl=87206"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22010,
        "row_id":107536,
        "rank":3,
        "Model":"MAXI",
        "mlmodel":{

        },
        "method_short":"MAXI",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-15",
        "metrics":{
            "mAP":"23.8"
        },
        "raw_metrics":{
            "mAP":23.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1175229,
            "title":"MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge",
            "url":"\/paper\/match-expand-and-improve-unsupervised",
            "published":"2023-03-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/match-expand-and-improve-unsupervised\/review\/?hl=107536"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22010,
        "row_id":87207,
        "rank":4,
        "Model":"CLIP-Hitchhiker (ViT-B\/16, 32 frames)",
        "mlmodel":{

        },
        "method_short":"CLIP-Hitchhiker ",
        "method_details":"ViT-B\/16, 32 frames",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-17",
        "metrics":{
            "mAP":"21.1"
        },
        "raw_metrics":{
            "mAP":21.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":1011401,
            "title":"A CLIP-Hitchhiker's Guide to Long Video Retrieval",
            "url":"\/paper\/a-clip-hitchhiker-s-guide-to-long-video",
            "published":"2022-05-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-clip-hitchhiker-s-guide-to-long-video\/review\/?hl=87207"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]