[
    {
        "Model":"bloom-7b1",
        "Language":"Vietnamese",
        "Code":"vi",
        "Average":38.7,
        "ARC (25-shot)":33.7,
        "HellaSwag (10-shot)\ufe0f":48.3,
        "MMLU (5-shot)":28.1,
        "TruthfulQA (0-shot)":44.7
    },
    {
        "Model":"llama-7B",
        "Language":"Vietnamese",
        "Code":"vi",
        "Average":31.7,
        "ARC (25-shot)":23.7,
        "HellaSwag (10-shot)\ufe0f":31.6,
        "MMLU (5-shot)":28.6,
        "TruthfulQA (0-shot)":43.0
    },
    {
        "Model":"llama-7B",
        "Language":"Ukrainian",
        "Code":"uk",
        "Average":37.0,
        "ARC (25-shot)":32.9,
        "HellaSwag (10-shot)\ufe0f":44.1,
        "MMLU (5-shot)":29.4,
        "TruthfulQA (0-shot)":41.4
    },
    {
        "Model":"bloom-7b1",
        "Language":"Ukrainian",
        "Code":"uk",
        "Average":32.7,
        "ARC (25-shot)":22.8,
        "HellaSwag (10-shot)\ufe0f":30.0,
        "MMLU (5-shot)":26.6,
        "TruthfulQA (0-shot)":51.4
    },
    {
        "Model":"llama-7B",
        "Language":"Telugu",
        "Code":"te",
        "Average":32.3,
        "ARC (25-shot)":25.2,
        "HellaSwag (10-shot)\ufe0f":28.9,
        "MMLU (5-shot)":26.9,
        "TruthfulQA (0-shot)":48.2
    },
    {
        "Model":"bloom-7b1",
        "Language":"Telugu",
        "Code":"te",
        "Average":31.5,
        "ARC (25-shot)":24.3,
        "HellaSwag (10-shot)\ufe0f":29.2,
        "MMLU (5-shot)":26.2,
        "TruthfulQA (0-shot)":46.1
    },
    {
        "Model":"llama-7B",
        "Language":"Tamil",
        "Code":"ta",
        "Average":33.5,
        "ARC (25-shot)":27.5,
        "HellaSwag (10-shot)\ufe0f":28.3,
        "MMLU (5-shot)":27.8,
        "TruthfulQA (0-shot)":50.3
    },
    {
        "Model":"bloom-7b1",
        "Language":"Tamil",
        "Code":"ta",
        "Average":32.1,
        "ARC (25-shot)":24.2,
        "HellaSwag (10-shot)\ufe0f":29.4,
        "MMLU (5-shot)":26.6,
        "TruthfulQA (0-shot)":48.3
    },
    {
        "Model":"llama-7B",
        "Language":"Swedish",
        "Code":"sv",
        "Average":38.8,
        "ARC (25-shot)":34.9,
        "HellaSwag (10-shot)\ufe0f":50.5,
        "MMLU (5-shot)":29.3,
        "TruthfulQA (0-shot)":40.5
    },
    {
        "Model":"bloom-7b1",
        "Language":"Swedish",
        "Code":"sv",
        "Average":32.1,
        "ARC (25-shot)":25.2,
        "HellaSwag (10-shot)\ufe0f":31.0,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":44.6
    },
    {
        "Model":"bloom-7b1",
        "Language":"Spanish",
        "Code":"es",
        "Average":41.0,
        "ARC (25-shot)":38.1,
        "HellaSwag (10-shot)\ufe0f":56.7,
        "MMLU (5-shot)":28.9,
        "TruthfulQA (0-shot)":40.4
    },
    {
        "Model":"llama-7B",
        "Language":"Spanish",
        "Code":"es",
        "Average":40.1,
        "ARC (25-shot)":36.8,
        "HellaSwag (10-shot)\ufe0f":56.4,
        "MMLU (5-shot)":30.3,
        "TruthfulQA (0-shot)":37.0
    },
    {
        "Model":"llama-7B",
        "Language":"Slovak",
        "Code":"sk",
        "Average":33.8,
        "ARC (25-shot)":29.0,
        "HellaSwag (10-shot)\ufe0f":35.9,
        "MMLU (5-shot)":29.4,
        "TruthfulQA (0-shot)":40.7
    },
    {
        "Model":"bloom-7b1",
        "Language":"Slovak",
        "Code":"sk",
        "Average":31.3,
        "ARC (25-shot)":24.9,
        "HellaSwag (10-shot)\ufe0f":29.8,
        "MMLU (5-shot)":26.7,
        "TruthfulQA (0-shot)":43.8
    },
    {
        "Model":"llama-7B",
        "Language":"Serbian",
        "Code":"sr",
        "Average":35.9,
        "ARC (25-shot)":30.8,
        "HellaSwag (10-shot)\ufe0f":41.1,
        "MMLU (5-shot)":29.2,
        "TruthfulQA (0-shot)":42.3
    },
    {
        "Model":"bloom-7b1",
        "Language":"Serbian",
        "Code":"sr",
        "Average":32.0,
        "ARC (25-shot)":25.1,
        "HellaSwag (10-shot)\ufe0f":29.9,
        "MMLU (5-shot)":27.2,
        "TruthfulQA (0-shot)":46.0
    },
    {
        "Model":"llama-7B",
        "Language":"Russian",
        "Code":"ru",
        "Average":37.2,
        "ARC (25-shot)":32.1,
        "HellaSwag (10-shot)\ufe0f":45.7,
        "MMLU (5-shot)":30.2,
        "TruthfulQA (0-shot)":40.9
    },
    {
        "Model":"bloom-7b1",
        "Language":"Russian",
        "Code":"ru",
        "Average":34.2,
        "ARC (25-shot)":27.5,
        "HellaSwag (10-shot)\ufe0f":32.5,
        "MMLU (5-shot)":27.0,
        "TruthfulQA (0-shot)":49.9
    },
    {
        "Model":"llama-7B",
        "Language":"Romanian",
        "Code":"ro",
        "Average":36.0,
        "ARC (25-shot)":32.4,
        "HellaSwag (10-shot)\ufe0f":44.9,
        "MMLU (5-shot)":29.7,
        "TruthfulQA (0-shot)":37.0
    },
    {
        "Model":"bloom-7b1",
        "Language":"Romanian",
        "Code":"ro",
        "Average":33.0,
        "ARC (25-shot)":26.9,
        "HellaSwag (10-shot)\ufe0f":31.8,
        "MMLU (5-shot)":27.4,
        "TruthfulQA (0-shot)":46.1
    },
    {
        "Model":"bloom-7b1",
        "Language":"Portuguese",
        "Code":"pt",
        "Average":40.7,
        "ARC (25-shot)":40.0,
        "HellaSwag (10-shot)\ufe0f":55.1,
        "MMLU (5-shot)":28.8,
        "TruthfulQA (0-shot)":38.9
    },
    {
        "Model":"llama-7B",
        "Language":"Portuguese",
        "Code":"pt",
        "Average":39.8,
        "ARC (25-shot)":37.8,
        "HellaSwag (10-shot)\ufe0f":53.2,
        "MMLU (5-shot)":30.1,
        "TruthfulQA (0-shot)":38.2
    },
    {
        "Model":"llama-7B",
        "Language":"Nepali",
        "Code":"ne",
        "Average":31.6,
        "ARC (25-shot)":24.3,
        "HellaSwag (10-shot)\ufe0f":28.2,
        "MMLU (5-shot)":27.7,
        "TruthfulQA (0-shot)":46.4
    },
    {
        "Model":"bloom-7b1",
        "Language":"Nepali",
        "Code":"ne",
        "Average":31.5,
        "ARC (25-shot)":22.3,
        "HellaSwag (10-shot)\ufe0f":30.9,
        "MMLU (5-shot)":26.6,
        "TruthfulQA (0-shot)":46.2
    },
    {
        "Model":"bloom-7b1",
        "Language":"Marathi",
        "Code":"mr",
        "Average":33.1,
        "ARC (25-shot)":27.3,
        "HellaSwag (10-shot)\ufe0f":31.0,
        "MMLU (5-shot)":26.3,
        "TruthfulQA (0-shot)":47.7
    },
    {
        "Model":"llama-7B",
        "Language":"Marathi",
        "Code":"mr",
        "Average":32.8,
        "ARC (25-shot)":25.5,
        "HellaSwag (10-shot)\ufe0f":28.8,
        "MMLU (5-shot)":27.8,
        "TruthfulQA (0-shot)":49.3
    },
    {
        "Model":"llama-7B",
        "Language":"Malayalam",
        "Code":"ml",
        "Average":33.6,
        "ARC (25-shot)":27.8,
        "HellaSwag (10-shot)\ufe0f":28.9,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":50.2
    },
    {
        "Model":"bloom-7b1",
        "Language":"Malayalam",
        "Code":"ml",
        "Average":32.4,
        "ARC (25-shot)":26.4,
        "HellaSwag (10-shot)\ufe0f":28.8,
        "MMLU (5-shot)":26.4,
        "TruthfulQA (0-shot)":48.0
    },
    {
        "Model":"bloom-7b1",
        "Language":"Kannada",
        "Code":"kn",
        "Average":32.7,
        "ARC (25-shot)":24.7,
        "HellaSwag (10-shot)\ufe0f":30.3,
        "MMLU (5-shot)":26.7,
        "TruthfulQA (0-shot)":49.1
    },
    {
        "Model":"llama-7B",
        "Language":"Kannada",
        "Code":"kn",
        "Average":31.8,
        "ARC (25-shot)":24.7,
        "HellaSwag (10-shot)\ufe0f":28.9,
        "MMLU (5-shot)":27.1,
        "TruthfulQA (0-shot)":46.4
    },
    {
        "Model":"llama-7B",
        "Language":"Italian",
        "Code":"it",
        "Average":39.3,
        "ARC (25-shot)":35.8,
        "HellaSwag (10-shot)\ufe0f":52.0,
        "MMLU (5-shot)":29.9,
        "TruthfulQA (0-shot)":39.6
    },
    {
        "Model":"bloom-7b1",
        "Language":"Italian",
        "Code":"it",
        "Average":35.3,
        "ARC (25-shot)":29.0,
        "HellaSwag (10-shot)\ufe0f":40.8,
        "MMLU (5-shot)":27.6,
        "TruthfulQA (0-shot)":43.7
    },
    {
        "Model":"bloom-7b1",
        "Language":"Indonesian",
        "Code":"id",
        "Average":38.5,
        "ARC (25-shot)":36.0,
        "HellaSwag (10-shot)\ufe0f":49.5,
        "MMLU (5-shot)":28.1,
        "TruthfulQA (0-shot)":40.3
    },
    {
        "Model":"llama-7B",
        "Language":"Indonesian",
        "Code":"id",
        "Average":32.5,
        "ARC (25-shot)":26.7,
        "HellaSwag (10-shot)\ufe0f":34.4,
        "MMLU (5-shot)":29.0,
        "TruthfulQA (0-shot)":39.8
    },
    {
        "Model":"llama-7B",
        "Language":"Hungarian",
        "Code":"hu",
        "Average":35.0,
        "ARC (25-shot)":29.8,
        "HellaSwag (10-shot)\ufe0f":37.9,
        "MMLU (5-shot)":29.0,
        "TruthfulQA (0-shot)":43.1
    },
    {
        "Model":"bloom-7b1",
        "Language":"Hungarian",
        "Code":"hu",
        "Average":33.2,
        "ARC (25-shot)":25.9,
        "HellaSwag (10-shot)\ufe0f":30.1,
        "MMLU (5-shot)":26.9,
        "TruthfulQA (0-shot)":50.0
    },
    {
        "Model":"bloom-7b1",
        "Language":"Hindi",
        "Code":"hi",
        "Average":34.4,
        "ARC (25-shot)":29.2,
        "HellaSwag (10-shot)\ufe0f":36.4,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":44.4
    },
    {
        "Model":"llama-7B",
        "Language":"Hindi",
        "Code":"hi",
        "Average":32.3,
        "ARC (25-shot)":25.0,
        "HellaSwag (10-shot)\ufe0f":29.2,
        "MMLU (5-shot)":27.9,
        "TruthfulQA (0-shot)":47.2
    },
    {
        "Model":"bloom-7b1",
        "Language":"Gujarati",
        "Code":"gu",
        "Average":31.5,
        "ARC (25-shot)":23.4,
        "HellaSwag (10-shot)\ufe0f":30.6,
        "MMLU (5-shot)":26.6,
        "TruthfulQA (0-shot)":45.5
    },
    {
        "Model":"llama-7B",
        "Language":"Gujarati",
        "Code":"gu",
        "Average":30.6,
        "ARC (25-shot)":23.2,
        "HellaSwag (10-shot)\ufe0f":28.9,
        "MMLU (5-shot)":27.4,
        "TruthfulQA (0-shot)":42.8
    },
    {
        "Model":"llama-7B",
        "Language":"German",
        "Code":"de",
        "Average":38.3,
        "ARC (25-shot)":35.1,
        "HellaSwag (10-shot)\ufe0f":49.9,
        "MMLU (5-shot)":29.9,
        "TruthfulQA (0-shot)":38.3
    },
    {
        "Model":"bloom-7b1",
        "Language":"German",
        "Code":"de",
        "Average":32.6,
        "ARC (25-shot)":26.3,
        "HellaSwag (10-shot)\ufe0f":32.4,
        "MMLU (5-shot)":28.1,
        "TruthfulQA (0-shot)":43.5
    },
    {
        "Model":"bloom-7b1",
        "Language":"French",
        "Code":"fr",
        "Average":41.0,
        "ARC (25-shot)":36.7,
        "HellaSwag (10-shot)\ufe0f":56.6,
        "MMLU (5-shot)":29.9,
        "TruthfulQA (0-shot)":40.9
    },
    {
        "Model":"llama-7B",
        "Language":"French",
        "Code":"fr",
        "Average":40.9,
        "ARC (25-shot)":37.3,
        "HellaSwag (10-shot)\ufe0f":55.7,
        "MMLU (5-shot)":30.5,
        "TruthfulQA (0-shot)":39.9
    },
    {
        "Model":"llama-7B",
        "Language":"Dutch",
        "Code":"nl",
        "Average":38.0,
        "ARC (25-shot)":33.6,
        "HellaSwag (10-shot)\ufe0f":48.7,
        "MMLU (5-shot)":29.8,
        "TruthfulQA (0-shot)":40.0
    },
    {
        "Model":"bloom-7b1",
        "Language":"Dutch",
        "Code":"nl",
        "Average":31.2,
        "ARC (25-shot)":23.1,
        "HellaSwag (10-shot)\ufe0f":31.7,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":42.7
    },
    {
        "Model":"llama-7B",
        "Language":"Danish",
        "Code":"da",
        "Average":37.8,
        "ARC (25-shot)":32.7,
        "HellaSwag (10-shot)\ufe0f":46.7,
        "MMLU (5-shot)":30.0,
        "TruthfulQA (0-shot)":41.6
    },
    {
        "Model":"bloom-7b1",
        "Language":"Danish",
        "Code":"da",
        "Average":31.7,
        "ARC (25-shot)":24.6,
        "HellaSwag (10-shot)\ufe0f":31.2,
        "MMLU (5-shot)":27.1,
        "TruthfulQA (0-shot)":43.8
    },
    {
        "Model":"llama-7B",
        "Language":"Croatian",
        "Code":"hr",
        "Average":36.3,
        "ARC (25-shot)":33.0,
        "HellaSwag (10-shot)\ufe0f":41.1,
        "MMLU (5-shot)":29.3,
        "TruthfulQA (0-shot)":41.7
    },
    {
        "Model":"bloom-7b1",
        "Language":"Croatian",
        "Code":"hr",
        "Average":32.1,
        "ARC (25-shot)":23.7,
        "HellaSwag (10-shot)\ufe0f":30.0,
        "MMLU (5-shot)":27.0,
        "TruthfulQA (0-shot)":47.9
    },
    {
        "Model":"bloom-7b1",
        "Language":"Chinese",
        "Code":"zh",
        "Average":39.1,
        "ARC (25-shot)":37.3,
        "HellaSwag (10-shot)\ufe0f":51.2,
        "MMLU (5-shot)":29.1,
        "TruthfulQA (0-shot)":38.8
    },
    {
        "Model":"llama-7B",
        "Language":"Chinese",
        "Code":"zh",
        "Average":35.4,
        "ARC (25-shot)":29.8,
        "HellaSwag (10-shot)\ufe0f":39.5,
        "MMLU (5-shot)":28.8,
        "TruthfulQA (0-shot)":43.6
    },
    {
        "Model":"bloom-7b1",
        "Language":"Catalan",
        "Code":"ca",
        "Average":38.7,
        "ARC (25-shot)":34.7,
        "HellaSwag (10-shot)\ufe0f":51.2,
        "MMLU (5-shot)":28.8,
        "TruthfulQA (0-shot)":40.1
    },
    {
        "Model":"llama-7B",
        "Language":"Catalan",
        "Code":"ca",
        "Average":38.5,
        "ARC (25-shot)":35.1,
        "HellaSwag (10-shot)\ufe0f":49.6,
        "MMLU (5-shot)":30.2,
        "TruthfulQA (0-shot)":38.9
    },
    {
        "Model":"bloom-7b1",
        "Language":"Bengali",
        "Code":"bn",
        "Average":33.9,
        "ARC (25-shot)":26.2,
        "HellaSwag (10-shot)\ufe0f":32.8,
        "MMLU (5-shot)":28.2,
        "TruthfulQA (0-shot)":48.4
    },
    {
        "Model":"llama-7B",
        "Language":"Bengali",
        "Code":"bn",
        "Average":33.5,
        "ARC (25-shot)":25.8,
        "HellaSwag (10-shot)\ufe0f":28.3,
        "MMLU (5-shot)":28.5,
        "TruthfulQA (0-shot)":51.2
    },
    {
        "Model":"bloom-7b1",
        "Language":"Basque",
        "Code":"eu",
        "Average":32.1,
        "ARC (25-shot)":25.2,
        "HellaSwag (10-shot)\ufe0f":31.2,
        "MMLU (5-shot)":27.4,
        "TruthfulQA (0-shot)":44.6
    },
    {
        "Model":"llama-7B",
        "Language":"Basque",
        "Code":"eu",
        "Average":30.4,
        "ARC (25-shot)":24.5,
        "HellaSwag (10-shot)\ufe0f":28.7,
        "MMLU (5-shot)":27.9,
        "TruthfulQA (0-shot)":40.7
    },
    {
        "Model":"llama-7B",
        "Language":"Armenian",
        "Code":"hy",
        "Average":32.2,
        "ARC (25-shot)":27.2,
        "HellaSwag (10-shot)\ufe0f":28.5,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":45.5
    },
    {
        "Model":"bloom-7b1",
        "Language":"Armenian",
        "Code":"hy",
        "Average":31.1,
        "ARC (25-shot)":26.2,
        "HellaSwag (10-shot)\ufe0f":27.6,
        "MMLU (5-shot)":25.7,
        "TruthfulQA (0-shot)":44.9
    },
    {
        "Model":"bloom-7b1",
        "Language":"Arabic",
        "Code":"ar",
        "Average":36.2,
        "ARC (25-shot)":31.4,
        "HellaSwag (10-shot)\ufe0f":43.3,
        "MMLU (5-shot)":27.5,
        "TruthfulQA (0-shot)":42.6
    },
    {
        "Model":"llama-7B",
        "Language":"Arabic",
        "Code":"ar",
        "Average":32.1,
        "ARC (25-shot)":24.6,
        "HellaSwag (10-shot)\ufe0f":30.9,
        "MMLU (5-shot)":28.0,
        "TruthfulQA (0-shot)":45.1
    }
]