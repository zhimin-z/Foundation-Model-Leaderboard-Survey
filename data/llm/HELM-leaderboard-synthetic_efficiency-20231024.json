[
  {
    "title": "Synthetic efficiency",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.52,
          "description": "min=13.6, mean=15.52, max=16, sum=77.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 29.939999999999998,
          "description": "min=21.7, mean=29.94, max=32, sum=149.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 58.739999999999995,
          "description": "min=37.7, mean=58.74, max=64, sum=293.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.92,
          "description": "min=7.6, mean=7.92, max=8, sum=39.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42000000000000004,
          "description": "min=0.2, mean=0.42, max=1, sum=2.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 563.42,
          "description": "min=1, mean=563.42, max=1024, sum=2817.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.86,
          "description": "min=15.3, mean=15.86, max=16, sum=79.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.98,
          "description": "min=1.9, mean=1.98, max=2, sum=9.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.72,
          "description": "min=30.6, mean=31.72, max=32, sum=158.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3.96,
          "description": "min=3.8, mean=3.96, max=4, sum=19.8 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 63.48,
          "description": "min=61.5, mean=63.48, max=64, sum=317.4 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.94,
          "description": "min=7.7, mean=7.94, max=8, sum=39.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.9,
          "description": "min=31.6, mean=31.9, max=32, sum=159.5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 63.98,
          "description": "min=63.9, mean=63.98, max=64, sum=319.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.959999999999999,
          "description": "min=7.8, mean=7.96, max=8, sum=39.8 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5200000000000001,
          "description": "min=0.2, mean=0.52, max=1, sum=2.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 357.62,
          "description": "min=1, mean=357.62, max=511.7, sum=1788.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6000000000000001,
          "description": "min=0.2, mean=0.6, max=1, sum=3.0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 359.4,
          "description": "min=5, mean=359.4, max=512.9, sum=1797 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.8,
          "description": "min=30, mean=30.8, max=31.5, sum=154 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 57.17999999999999,
          "description": "min=54.7, mean=57.18, max=60.2, sum=285.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9800000000000001,
          "description": "min=0.9, mean=0.98, max=1, sum=4.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.680000000000001,
          "description": "min=14.4, mean=15.68, max=16, sum=78.4 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.9600000000000002,
          "description": "min=1.8, mean=1.96, max=2, sum=9.8 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.080000000000002,
          "description": "min=28.8, mean=31.08, max=32, sum=155.4 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3.9200000000000004,
          "description": "min=3.6, mean=3.92, max=4, sum=19.6 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 61.8,
          "description": "min=57.6, mean=61.8, max=64, sum=309 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.840000000000001,
          "description": "min=7.2, mean=7.84, max=8, sum=39.2 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.86,
          "description": "min=15.5, mean=15.86, max=16, sum=79.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.76,
          "description": "min=28.1, mean=30.76, max=32, sum=153.8 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 58.17999999999999,
          "description": "min=43.6, mean=58.18, max=64, sum=290.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.66,
          "description": "min=14.7, mean=15.66, max=16, sum=78.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.26,
          "description": "min=25.9, mean=30.26, max=32, sum=151.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 57.58,
          "description": "min=40.9, mean=57.58, max=64, sum=287.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.98,
          "description": "min=15.9, mean=15.98, max=16, sum=79.9 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.340000000000003,
          "description": "min=30.3, mean=31.34, max=32, sum=156.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 59.0,
          "description": "min=50.9, mean=59, max=62.7, sum=295 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 62.739999999999995,
          "description": "min=57.7, mean=62.74, max=64, sum=313.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.8,
          "description": "min=1, mean=665.8, max=1536, sum=3329 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.62,
          "description": "min=1, mean=665.62, max=1535.6, sum=3328.1 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=80 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=10 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=160 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=20 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=320 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=50 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26000000000000006,
          "description": "min=0, mean=0.26, max=0.4, sum=1.3 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 665.5399999999998,
          "description": "min=1, mean=665.54, max=1535.6, sum=3327.7 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=40 (5)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=5 (5)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency.json"
      }
    ],
    "name": "synthetic_efficiency"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: ai21/j1",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:ai21_j1.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:ai21_j1.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:ai21_j1"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: ai21/j1",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:ai21_j1.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:ai21_j1.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:ai21_j1"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: ai21/j1",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:ai21_j1.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:ai21_j1.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:ai21_j1"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: ai21/j1",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:ai21_j1.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:ai21_j1.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:ai21_j1"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: ai21/j1",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Jumbo v1 (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j1-grande-v2-beta%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-jumbo%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-grande%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20ai21%2Fj1&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dai21_j2-large%2Ctokenizer%3Dai21_j1%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:ai21_j1.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:ai21_j1.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:ai21_j1"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: huggingface/gpt2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 13.6,
          "description": "min=13.6, mean=13.6, max=13.6, sum=13.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 21.7,
          "description": "min=21.7, mean=21.7, max=21.7, sum=21.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 37.7,
          "description": "min=37.7, mean=37.7, max=37.7, sum=37.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.6,
          "description": "min=7.6, mean=7.6, max=7.6, sum=7.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.2,
          "description": "min=31.2, mean=31.2, max=31.2, sum=31.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 59.4,
          "description": "min=59.4, mean=59.4, max=59.4, sum=59.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.6,
          "description": "min=30.6, mean=30.6, max=30.6, sum=30.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 59.4,
          "description": "min=59.4, mean=59.4, max=59.4, sum=59.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.5,
          "description": "min=15.5, mean=15.5, max=15.5, sum=15.5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.1,
          "description": "min=28.1, mean=28.1, max=28.1, sum=28.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 43.6,
          "description": "min=43.6, mean=43.6, max=43.6, sum=43.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 14.7,
          "description": "min=14.7, mean=14.7, max=14.7, sum=14.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 25.9,
          "description": "min=25.9, mean=25.9, max=25.9, sum=25.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 40.9,
          "description": "min=40.9, mean=40.9, max=40.9, sum=40.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.6,
          "description": "min=30.6, mean=30.6, max=30.6, sum=30.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 50.9,
          "description": "min=50.9, mean=50.9, max=50.9, sum=50.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 57.7,
          "description": "min=57.7, mean=57.7, max=57.7, sum=57.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: huggingface/gpt2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.3,
          "description": "min=30.3, mean=30.3, max=30.3, sum=30.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 55.9,
          "description": "min=55.9, mean=55.9, max=55.9, sum=55.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.9,
          "description": "min=15.9, mean=15.9, max=15.9, sum=15.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.3,
          "description": "min=30.3, mean=30.3, max=30.3, sum=30.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 59.1,
          "description": "min=59.1, mean=59.1, max=59.1, sum=59.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:huggingface_gpt2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:huggingface_gpt2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:huggingface_gpt2"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: huggingface/gpt2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.5,
          "description": "min=31.5, mean=31.5, max=31.5, sum=31.5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 60.2,
          "description": "min=60.2, mean=60.2, max=60.2, sum=60.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9,
          "description": "min=0.9, mean=0.9, max=0.9, sum=0.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 14.4,
          "description": "min=14.4, mean=14.4, max=14.4, sum=14.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.8,
          "description": "min=1.8, mean=1.8, max=1.8, sum=1.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.8,
          "description": "min=28.8, mean=28.8, max=28.8, sum=28.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3.6,
          "description": "min=3.6, mean=3.6, max=3.6, sum=3.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 57.6,
          "description": "min=57.6, mean=57.6, max=57.6, sum=57.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.2,
          "description": "min=7.2, mean=7.2, max=7.2, sum=7.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.6,
          "description": "min=15.6, mean=15.6, max=15.6, sum=15.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.0,
          "description": "min=30, mean=30, max=30, sum=30 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 58.8,
          "description": "min=58.8, mean=58.8, max=58.8, sum=58.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 62.7,
          "description": "min=62.7, mean=62.7, max=62.7, sum=62.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:huggingface_gpt2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:huggingface_gpt2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:huggingface_gpt2"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: huggingface/gpt2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.0,
          "description": "min=31, mean=31, max=31, sum=31 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 55.7,
          "description": "min=55.7, mean=55.7, max=55.7, sum=55.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.8,
          "description": "min=15.8, mean=15.8, max=15.8, sum=15.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.2,
          "description": "min=30.2, mean=30.2, max=30.2, sum=30.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 59.0,
          "description": "min=59, mean=59, max=59, sum=59 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.4,
          "description": "min=31.4, mean=31.4, max=31.4, sum=31.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 60.2,
          "description": "min=60.2, mean=60.2, max=60.2, sum=60.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 61.7,
          "description": "min=61.7, mean=61.7, max=61.7, sum=61.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: huggingface/gpt2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (530B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "davinci (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.0,
          "description": "min=30, mean=30, max=30, sum=30 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 54.7,
          "description": "min=54.7, mean=54.7, max=54.7, sum=54.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.5,
          "description": "min=31.5, mean=31.5, max=31.5, sum=31.5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 60.3,
          "description": "min=60.3, mean=60.3, max=60.3, sum=60.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.8,
          "description": "min=31.8, mean=31.8, max=31.8, sum=31.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 60.6,
          "description": "min=60.6, mean=60.6, max=60.6, sum=60.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-davinci-002 [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "code-cushman-001 (12B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:huggingface_gpt2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:huggingface_gpt2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:huggingface_gpt2"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: cohere/cohere",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:cohere_cohere.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:cohere_cohere.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:cohere_cohere"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: cohere/cohere",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.9,
          "description": "min=1.9, mean=1.9, max=1.9, sum=1.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 63.9,
          "description": "min=63.9, mean=63.9, max=63.9, sum=63.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:cohere_cohere.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:cohere_cohere.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:cohere_cohere"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: cohere/cohere",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 15.3,
          "description": "min=15.3, mean=15.3, max=15.3, sum=15.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 30.6,
          "description": "min=30.6, mean=30.6, max=30.6, sum=30.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3.8,
          "description": "min=3.8, mean=3.8, max=3.8, sum=3.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 61.5,
          "description": "min=61.5, mean=61.5, max=61.5, sum=61.5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.7,
          "description": "min=7.7, mean=7.7, max=7.7, sum=7.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.9,
          "description": "min=31.9, mean=31.9, max=31.9, sum=31.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 63.9,
          "description": "min=63.9, mean=63.9, max=63.9, sum=63.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:cohere_cohere.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:cohere_cohere.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:cohere_cohere"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: cohere/cohere",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:cohere_cohere.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:cohere_cohere.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:cohere_cohere"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: cohere/cohere",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20220609%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_large-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_small-20220720%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_xlarge-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_medium-20221108%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-medium-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 31.6,
          "description": "min=31.6, mean=31.6, max=31.6, sum=31.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20cohere%2Fcohere&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dcohere_command-xlarge-beta%2Ctokenizer%3Dcohere_cohere%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 7.8,
          "description": "min=7.8, mean=7.8, max=7.8, sum=7.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:cohere_cohere.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:cohere_cohere.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:cohere_cohere"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: bigscience/bloom",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_bloom.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_bloom.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_bloom"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: bigscience/bloom",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_bloom.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_bloom.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_bloom"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: bigscience/bloom",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_bloom.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_bloom.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_bloom"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: bigscience/bloom",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_bloom.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_bloom.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_bloom"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: bigscience/bloom",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "BLOOM (176B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "BLOOM (176B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Fbloom&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_bloom%2Ctokenizer%3Dbigscience_bloom%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_bloom.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_bloom.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_bloom"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: tsinghua/glm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:tsinghua_glm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:tsinghua_glm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:tsinghua_glm"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: tsinghua/glm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.6,
          "description": "min=1023.6, mean=1023.6, max=1023.6, sum=1023.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:tsinghua_glm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:tsinghua_glm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:tsinghua_glm"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: tsinghua/glm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:tsinghua_glm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:tsinghua_glm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:tsinghua_glm"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: tsinghua/glm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:tsinghua_glm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:tsinghua_glm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:tsinghua_glm"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: tsinghua/glm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GLM (130B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GLM (130B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20tsinghua%2Fglm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_glm%2Ctokenizer%3Dtsinghua_glm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.9,
          "description": "min=511.9, mean=511.9, max=511.9, sum=511.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:tsinghua_glm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:tsinghua_glm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:tsinghua_glm"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: eleutherai/gptj",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptj.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptj.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptj"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: eleutherai/gptj",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptj.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptj.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptj"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: eleutherai/gptj",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptj.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptj.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptj"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: eleutherai/gptj",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptj.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptj.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptj"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: eleutherai/gptj",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-J (6B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptj&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-j-6b%2Ctokenizer%3Deleutherai_gptj%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptj.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptj.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptj"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: eleutherai/gptneox",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptneox.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptneox.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:eleutherai_gptneox"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: eleutherai/gptneox",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptneox.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptneox.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:eleutherai_gptneox"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: eleutherai/gptneox",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptneox.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptneox.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:eleutherai_gptneox"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: eleutherai/gptneox",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptneox.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptneox.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:eleutherai_gptneox"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: eleutherai/gptneox",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20eleutherai%2Fgptneox&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_gpt-neox-20b%2Ctokenizer%3Deleutherai_gptneox%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptneox.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptneox.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:eleutherai_gptneox"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: meta/opt",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:meta_opt.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:meta_opt.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:meta_opt"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: meta/opt",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:meta_opt.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:meta_opt.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:meta_opt"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: meta/opt",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1536.0,
          "description": "min=1536, mean=1536, max=1536, sum=1536 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:meta_opt.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:meta_opt.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:meta_opt"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: meta/opt",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:meta_opt.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:meta_opt.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:meta_opt"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: meta/opt",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "OPT (175B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (175B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-175b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "OPT (66B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20meta%2Fopt&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_opt-66b%2Ctokenizer%3Dmeta_opt%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.0,
          "description": "min=512, mean=512, max=512, sum=512 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:meta_opt.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:meta_opt.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:meta_opt"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: bigscience/t0pp",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_t0pp.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_t0pp.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:bigscience_t0pp"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: bigscience/t0pp",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_t0pp.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_t0pp.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:bigscience_t0pp"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: bigscience/t0pp",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1024.0,
          "description": "min=1024, mean=1024, max=1024, sum=1024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_t0pp.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_t0pp.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:bigscience_t0pp"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: bigscience/t0pp",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_t0pp.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_t0pp.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:bigscience_t0pp"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: bigscience/t0pp",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T0pp (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T0pp (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20bigscience%2Ft0pp&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t0pp%2Ctokenizer%3Dbigscience_t0pp%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.1,
          "description": "min=512.1, mean=512.1, max=512.1, sum=512.1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_t0pp.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_t0pp.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:bigscience_t0pp"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: google/t5",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_t5.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_t5.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_t5"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: google/t5",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.6,
          "description": "min=509.6, mean=509.6, max=509.6, sum=509.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_t5.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_t5.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_t5"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: google/t5",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.8,
          "description": "min=509.8, mean=509.8, max=509.8, sum=509.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_t5.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_t5.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_t5"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: google/t5",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 256.0,
          "description": "min=256, mean=256, max=256, sum=256 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_t5.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_t5.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_t5"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: google/t5",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "T5 (11B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "T5 (11B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ft5&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_t5-11b%2Ctokenizer%3Dgoogle_t5%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%2Cstop%3Dhash%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.7,
          "description": "min=511.7, mean=511.7, max=511.7, sum=511.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_t5.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_t5.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_t5"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: google/ul2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5.0,
          "description": "min=5, mean=5, max=5, sum=5 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_ul2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_ul2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:google_ul2"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: google/ul2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.4,
          "description": "min=509.4, mean=509.4, max=509.4, sum=509.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_ul2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_ul2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:google_ul2"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: google/ul2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 509.7,
          "description": "min=509.7, mean=509.7, max=509.7, sum=509.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_ul2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_ul2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:google_ul2"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: google/ul2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 260.0,
          "description": "min=260, mean=260, max=260, sum=260 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_ul2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_ul2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:google_ul2"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: google/ul2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "UL2 (20B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "UL2 (20B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20google%2Ful2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_ul2%2Ctokenizer%3Dgoogle_ul2%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%2Cstop%3Dhash%2Cglobal_prefix%3Dnlg%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 512.9,
          "description": "min=512.9, mean=512.9, max=512.9, sum=512.9 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_ul2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_ul2.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:google_ul2"
  },
  {
    "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: yandex/yalm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:yandex_yalm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:yandex_yalm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:yandex_yalm"
  },
  {
    "title": "num_prompt_tokens: 1024, num_instances: 10, tokenizer: yandex/yalm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201024%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1024%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2,
          "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1023.8,
          "description": "min=1023.8, mean=1023.8, max=1023.8, sum=1023.8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:yandex_yalm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:yandex_yalm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1024,num_instances:10,tokenizer:yandex_yalm"
  },
  {
    "title": "num_prompt_tokens: 1536, num_instances: 10, tokenizer: yandex/yalm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201536%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D1536%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1535.6,
          "description": "min=1535.6, mean=1535.6, max=1535.6, sum=1535.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:yandex_yalm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:yandex_yalm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:1536,num_instances:10,tokenizer:yandex_yalm"
  },
  {
    "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: yandex/yalm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3,
          "description": "min=0.3, mean=0.3, max=0.3, sum=0.3 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 255.7,
          "description": "min=255.7, mean=255.7, max=255.7, sum=255.7 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:yandex_yalm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:yandex_yalm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:yandex_yalm"
  },
  {
    "title": "num_prompt_tokens: 512, num_instances: 10, tokenizer: yandex/yalm",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "# eval",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# train",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "truncated",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# output tokens",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "Synthetic efficiency"
        }
      },
      {
        "value": "# trials",
        "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "Synthetic efficiency"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "YaLM (100B) [max_tokens: 1]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D1%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 16]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D16%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 16.0,
          "description": "min=16, mean=16, max=16, sum=16 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 2]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D2%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2.0,
          "description": "min=2, mean=2, max=2, sum=2 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 32]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D32%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 32.0,
          "description": "min=32, mean=32, max=32, sum=32 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 4]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D4%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4.0,
          "description": "min=4, mean=4, max=4, sum=4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 64]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D64%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 64.0,
          "description": "min=64, mean=64, max=64, sum=64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "YaLM (100B) [max_tokens: 8]",
          "description": "",
          "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20512%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20yandex%2Fyalm&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dtogether_yalm%2Ctokenizer%3Dyandex_yalm%2Cnum_prompt_tokens%3D512%2Cnum_output_tokens%3D8%22%5D",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4,
          "description": "min=0.4, mean=0.4, max=0.4, sum=0.4 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 511.6,
          "description": "min=511.6, mean=511.6, max=511.6, sum=511.6 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 8.0,
          "description": "min=8, mean=8, max=8, sum=8 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:yandex_yalm.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:yandex_yalm.json"
      }
    ],
    "name": "synthetic_efficiency_num_prompt_tokens:512,num_instances:10,tokenizer:yandex_yalm"
  }
]