[
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.125,
        "E2E Throughput (tokens\/s)":18.39,
        "Prefill Latency (s)":69670,
        "E2E Latency (s)":165562.0,
        "Allocated Memory (MB)":54.5,
        "Reserved Memory (MB)":18.3,
        "Used Memory (MB)":69950,
        "Energy (tokens\/kWh)":71424
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.131,
        "E2E Throughput (tokens\/s)":18.36,
        "Prefill Latency (s)":69670,
        "E2E Latency (s)":165289.0,
        "Allocated Memory (MB)":54.6,
        "Reserved Memory (MB)":18.3,
        "Used Memory (MB)":69950,
        "Energy (tokens\/kWh)":71424
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.16,
        "E2E Throughput (tokens\/s)":19.48,
        "Prefill Latency (s)":20448,
        "E2E Latency (s)":208333.0,
        "Allocated Memory (MB)":51.5,
        "Reserved Memory (MB)":19.4,
        "Used Memory (MB)":20931,
        "Energy (tokens\/kWh)":22407
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.176,
        "E2E Throughput (tokens\/s)":15.52,
        "Prefill Latency (s)":25613,
        "E2E Latency (s)":195312.0,
        "Allocated Memory (MB)":64.6,
        "Reserved Memory (MB)":15.5,
        "Used Memory (MB)":31715,
        "Energy (tokens\/kWh)":33191
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.192,
        "E2E Throughput (tokens\/s)":15.9,
        "Prefill Latency (s)":21590,
        "E2E Latency (s)":168067.0,
        "Allocated Memory (MB)":63.1,
        "Reserved Memory (MB)":15.8,
        "Used Memory (MB)":21973,
        "Energy (tokens\/kWh)":23447
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"68.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.192,
        "E2E Throughput (tokens\/s)":15.57,
        "Prefill Latency (s)":21590,
        "E2E Latency (s)":162866.0,
        "Allocated Memory (MB)":64.4,
        "Reserved Memory (MB)":15.5,
        "Used Memory (MB)":21973,
        "Energy (tokens\/kWh)":23447
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0811,
        "E2E Throughput (tokens\/s)":18.11,
        "Prefill Latency (s)":43749,
        "E2E Latency (s)":167785.0,
        "Allocated Memory (MB)":55.3,
        "Reserved Memory (MB)":18.1,
        "Used Memory (MB)":46898,
        "Energy (tokens\/kWh)":48372
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0837,
        "E2E Throughput (tokens\/s)":18.21,
        "Prefill Latency (s)":43749,
        "E2E Latency (s)":167224.0,
        "Allocated Memory (MB)":55.0,
        "Reserved Memory (MB)":18.2,
        "Used Memory (MB)":46898,
        "Energy (tokens\/kWh)":48372
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.103,
        "E2E Throughput (tokens\/s)":17.21,
        "Prefill Latency (s)":15676,
        "E2E Latency (s)":202429.0,
        "Allocated Memory (MB)":58.2,
        "Reserved Memory (MB)":17.2,
        "Used Memory (MB)":18918,
        "Energy (tokens\/kWh)":20394
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.107,
        "E2E Throughput (tokens\/s)":17.04,
        "Prefill Latency (s)":16593,
        "E2E Latency (s)":206611.0,
        "Allocated Memory (MB)":58.8,
        "Reserved Memory (MB)":17.0,
        "Used Memory (MB)":19834,
        "Energy (tokens\/kWh)":21310
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.121,
        "E2E Throughput (tokens\/s)":14.29,
        "Prefill Latency (s)":16273,
        "E2E Latency (s)":162601.0,
        "Allocated Memory (MB)":70.1,
        "Reserved Memory (MB)":14.3,
        "Used Memory (MB)":18679,
        "Energy (tokens\/kWh)":20153
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"57.98*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.122,
        "E2E Throughput (tokens\/s)":14.15,
        "Prefill Latency (s)":16273,
        "E2E Latency (s)":165016.0,
        "Allocated Memory (MB)":70.8,
        "Reserved Memory (MB)":14.1,
        "Used Memory (MB)":18679,
        "Energy (tokens\/kWh)":20153
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Size":68.98,
        "Backend":"56.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.321,
        "E2E Throughput (tokens\/s)":12.58,
        "Prefill Latency (s)":38175,
        "E2E Latency (s)":116009.0,
        "Allocated Memory (MB)":79.8,
        "Reserved Memory (MB)":12.5,
        "Used Memory (MB)":38717,
        "Energy (tokens\/kWh)":40193
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Size":68.98,
        "Backend":"56.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.324,
        "E2E Throughput (tokens\/s)":13.21,
        "Prefill Latency (s)":40080,
        "E2E Latency (s)":141643.0,
        "Allocated Memory (MB)":76.0,
        "Reserved Memory (MB)":13.2,
        "Used Memory (MB)":40621,
        "Energy (tokens\/kWh)":42097
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Size":68.98,
        "Backend":"56.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.382,
        "E2E Throughput (tokens\/s)":10.81,
        "Prefill Latency (s)":40602,
        "E2E Latency (s)":94339.0,
        "Allocated Memory (MB)":92.9,
        "Reserved Memory (MB)":10.8,
        "Used Memory (MB)":41219,
        "Energy (tokens\/kWh)":42693
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"54.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.303,
        "E2E Throughput (tokens\/s)":12.77,
        "Prefill Latency (s)":41896,
        "E2E Latency (s)":119474.0,
        "Allocated Memory (MB)":78.6,
        "Reserved Memory (MB)":12.7,
        "Used Memory (MB)":53676,
        "Energy (tokens\/kWh)":55152
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"54.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.31,
        "E2E Throughput (tokens\/s)":13.93,
        "Prefill Latency (s)":43362,
        "E2E Latency (s)":150375.0,
        "Allocated Memory (MB)":72.1,
        "Reserved Memory (MB)":13.9,
        "Used Memory (MB)":55144,
        "Energy (tokens\/kWh)":56620
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"54.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.364,
        "E2E Throughput (tokens\/s)":11.52,
        "Prefill Latency (s)":44280,
        "E2E Latency (s)":107066.0,
        "Allocated Memory (MB)":87.2,
        "Reserved Memory (MB)":11.5,
        "Used Memory (MB)":53389,
        "Energy (tokens\/kWh)":54863
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"53.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.308,
        "E2E Throughput (tokens\/s)":12.69,
        "Prefill Latency (s)":41896,
        "E2E Latency (s)":117647.0,
        "Allocated Memory (MB)":79.1,
        "Reserved Memory (MB)":12.6,
        "Used Memory (MB)":53676,
        "Energy (tokens\/kWh)":55152
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"53.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.309,
        "E2E Throughput (tokens\/s)":13.93,
        "Prefill Latency (s)":43362,
        "E2E Latency (s)":149700.0,
        "Allocated Memory (MB)":72.1,
        "Reserved Memory (MB)":13.9,
        "Used Memory (MB)":55144,
        "Energy (tokens\/kWh)":56620
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Size":65.29,
        "Backend":"53.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.362,
        "E2E Throughput (tokens\/s)":11.32,
        "Prefill Latency (s)":44280,
        "E2E Latency (s)":109051.0,
        "Allocated Memory (MB)":88.7,
        "Reserved Memory (MB)":11.3,
        "Used Memory (MB)":53389,
        "Energy (tokens\/kWh)":54863
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0286,
        "E2E Throughput (tokens\/s)":39.26,
        "Prefill Latency (s)":12433,
        "E2E Latency (s)":450450.0,
        "Allocated Memory (MB)":25.5,
        "Reserved Memory (MB)":39.2,
        "Used Memory (MB)":12593,
        "Energy (tokens\/kWh)":14067
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0345,
        "E2E Throughput (tokens\/s)":31.88,
        "Prefill Latency (s)":13608,
        "E2E Latency (s)":373134.0,
        "Allocated Memory (MB)":31.4,
        "Reserved Memory (MB)":31.8,
        "Used Memory (MB)":13650,
        "Energy (tokens\/kWh)":15124
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0359,
        "E2E Throughput (tokens\/s)":35.38,
        "Prefill Latency (s)":4384,
        "E2E Latency (s)":462962.0,
        "Allocated Memory (MB)":28.3,
        "Reserved Memory (MB)":35.3,
        "Used Memory (MB)":4546,
        "Energy (tokens\/kWh)":6022
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0447,
        "E2E Throughput (tokens\/s)":29.89,
        "Prefill Latency (s)":6284,
        "E2E Latency (s)":404858.0,
        "Allocated Memory (MB)":33.5,
        "Reserved Memory (MB)":29.9,
        "Used Memory (MB)":6335,
        "Energy (tokens\/kWh)":7811
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0453,
        "E2E Throughput (tokens\/s)":29.36,
        "Prefill Latency (s)":4506,
        "E2E Latency (s)":401606.0,
        "Allocated Memory (MB)":34.1,
        "Reserved Memory (MB)":29.3,
        "Used Memory (MB)":4668,
        "Energy (tokens\/kWh)":6142
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"53.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0467,
        "E2E Throughput (tokens\/s)":28.94,
        "Prefill Latency (s)":4506,
        "E2E Latency (s)":398406.0,
        "Allocated Memory (MB)":34.6,
        "Reserved Memory (MB)":28.9,
        "Used Memory (MB)":4668,
        "Energy (tokens\/kWh)":6142
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Size":13.0,
        "Backend":"52.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0871,
        "E2E Throughput (tokens\/s)":13.57,
        "Prefill Latency (s)":28858,
        "E2E Latency (s)":156250.0,
        "Allocated Memory (MB)":73.8,
        "Reserved Memory (MB)":13.6,
        "Used Memory (MB)":30647,
        "Energy (tokens\/kWh)":32121
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Size":13.0,
        "Backend":"52.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0877,
        "E2E Throughput (tokens\/s)":12.82,
        "Prefill Latency (s)":28858,
        "E2E Latency (s)":149925.0,
        "Allocated Memory (MB)":78.1,
        "Reserved Memory (MB)":12.8,
        "Used Memory (MB)":30664,
        "Energy (tokens\/kWh)":32138
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Size":13.0,
        "Backend":"52.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.089,
        "E2E Throughput (tokens\/s)":12.87,
        "Prefill Latency (s)":28858,
        "E2E Latency (s)":151515.0,
        "Allocated Memory (MB)":77.8,
        "Reserved Memory (MB)":12.9,
        "Used Memory (MB)":30664,
        "Energy (tokens\/kWh)":32138
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0364,
        "E2E Throughput (tokens\/s)":34.65,
        "Prefill Latency (s)":15381,
        "E2E Latency (s)":383141.0,
        "Allocated Memory (MB)":28.9,
        "Reserved Memory (MB)":34.6,
        "Used Memory (MB)":15651,
        "Energy (tokens\/kWh)":17124
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0373,
        "E2E Throughput (tokens\/s)":35.13,
        "Prefill Latency (s)":15381,
        "E2E Latency (s)":380228.0,
        "Allocated Memory (MB)":28.5,
        "Reserved Memory (MB)":35.1,
        "Used Memory (MB)":15651,
        "Energy (tokens\/kWh)":17124
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0453,
        "E2E Throughput (tokens\/s)":33.27,
        "Prefill Latency (s)":5176,
        "E2E Latency (s)":413223.0,
        "Allocated Memory (MB)":30.1,
        "Reserved Memory (MB)":33.2,
        "Used Memory (MB)":5391,
        "Energy (tokens\/kWh)":6867
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0454,
        "E2E Throughput (tokens\/s)":32.94,
        "Prefill Latency (s)":6120,
        "E2E Latency (s)":436681.0,
        "Allocated Memory (MB)":30.4,
        "Reserved Memory (MB)":32.9,
        "Used Memory (MB)":6337,
        "Energy (tokens\/kWh)":7813
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0519,
        "E2E Throughput (tokens\/s)":26.92,
        "Prefill Latency (s)":5370,
        "E2E Latency (s)":358422.0,
        "Allocated Memory (MB)":37.2,
        "Reserved Memory (MB)":26.9,
        "Used Memory (MB)":5559,
        "Energy (tokens\/kWh)":7033
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"50.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0532,
        "E2E Throughput (tokens\/s)":27.07,
        "Prefill Latency (s)":5370,
        "E2E Latency (s)":331125.0,
        "Allocated Memory (MB)":37.0,
        "Reserved Memory (MB)":27.0,
        "Used Memory (MB)":5559,
        "Energy (tokens\/kWh)":7033
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.126,
        "E2E Throughput (tokens\/s)":17.77,
        "Prefill Latency (s)":69241,
        "E2E Latency (s)":161030.0,
        "Allocated Memory (MB)":56.4,
        "Reserved Memory (MB)":17.7,
        "Used Memory (MB)":73417,
        "Energy (tokens\/kWh)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.127,
        "E2E Throughput (tokens\/s)":17.52,
        "Prefill Latency (s)":69241,
        "E2E Latency (s)":157977.0,
        "Allocated Memory (MB)":57.2,
        "Reserved Memory (MB)":17.5,
        "Used Memory (MB)":73417,
        "Energy (tokens\/kWh)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.13,
        "E2E Throughput (tokens\/s)":17.49,
        "Prefill Latency (s)":69241,
        "E2E Latency (s)":157728.0,
        "Allocated Memory (MB)":57.3,
        "Reserved Memory (MB)":17.5,
        "Used Memory (MB)":73417,
        "Energy (tokens\/kWh)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.16,
        "E2E Throughput (tokens\/s)":18.75,
        "Prefill Latency (s)":22110,
        "E2E Latency (s)":190839.0,
        "Allocated Memory (MB)":53.5,
        "Reserved Memory (MB)":18.7,
        "Used Memory (MB)":26128,
        "Energy (tokens\/kWh)":27604
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.164,
        "E2E Throughput (tokens\/s)":19.0,
        "Prefill Latency (s)":23298,
        "E2E Latency (s)":218340.0,
        "Allocated Memory (MB)":52.8,
        "Reserved Memory (MB)":18.9,
        "Used Memory (MB)":27315,
        "Energy (tokens\/kWh)":28791
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Size":32.53,
        "Backend":"49.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.185,
        "E2E Throughput (tokens\/s)":15.57,
        "Prefill Latency (s)":23006,
        "E2E Latency (s)":167785.0,
        "Allocated Memory (MB)":64.4,
        "Reserved Memory (MB)":15.5,
        "Used Memory (MB)":26357,
        "Energy (tokens\/kWh)":27830
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0514,
        "E2E Throughput (tokens\/s)":33.62,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":300300.0,
        "Allocated Memory (MB)":29.8,
        "Reserved Memory (MB)":33.6,
        "Used Memory (MB)":30104,
        "Energy (tokens\/kWh)":31578
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0539,
        "E2E Throughput (tokens\/s)":29.99,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":277008.0,
        "Allocated Memory (MB)":33.4,
        "Reserved Memory (MB)":29.9,
        "Used Memory (MB)":30148,
        "Energy (tokens\/kWh)":31622
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0558,
        "E2E Throughput (tokens\/s)":29.72,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":280112.0,
        "Allocated Memory (MB)":33.7,
        "Reserved Memory (MB)":29.7,
        "Used Memory (MB)":30148,
        "Energy (tokens\/kWh)":31622
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0692,
        "E2E Throughput (tokens\/s)":28.14,
        "Prefill Latency (s)":9637,
        "E2E Latency (s)":323624.0,
        "Allocated Memory (MB)":35.6,
        "Reserved Memory (MB)":28.1,
        "Used Memory (MB)":11544,
        "Energy (tokens\/kWh)":13020
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0702,
        "E2E Throughput (tokens\/s)":27.01,
        "Prefill Latency (s)":10550,
        "E2E Latency (s)":344827.0,
        "Allocated Memory (MB)":37.1,
        "Reserved Memory (MB)":27.0,
        "Used Memory (MB)":12457,
        "Energy (tokens\/kWh)":13932
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"46.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0793,
        "E2E Throughput (tokens\/s)":23.08,
        "Prefill Latency (s)":9996,
        "E2E Latency (s)":284090.0,
        "Allocated Memory (MB)":43.4,
        "Reserved Memory (MB)":23.0,
        "Used Memory (MB)":11542,
        "Energy (tokens\/kWh)":13016
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0508,
        "E2E Throughput (tokens\/s)":33.17,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":297619.0,
        "Allocated Memory (MB)":30.2,
        "Reserved Memory (MB)":33.1,
        "Used Memory (MB)":30104,
        "Energy (tokens\/kWh)":31578
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0524,
        "E2E Throughput (tokens\/s)":29.11,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":289017.0,
        "Allocated Memory (MB)":34.4,
        "Reserved Memory (MB)":29.1,
        "Used Memory (MB)":30148,
        "Energy (tokens\/kWh)":31622
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0539,
        "E2E Throughput (tokens\/s)":29.55,
        "Prefill Latency (s)":28305,
        "E2E Latency (s)":276243.0,
        "Allocated Memory (MB)":33.9,
        "Reserved Memory (MB)":29.5,
        "Used Memory (MB)":30148,
        "Energy (tokens\/kWh)":31622
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0693,
        "E2E Throughput (tokens\/s)":28.14,
        "Prefill Latency (s)":9637,
        "E2E Latency (s)":322580.0,
        "Allocated Memory (MB)":35.6,
        "Reserved Memory (MB)":28.1,
        "Used Memory (MB)":11544,
        "Energy (tokens\/kWh)":13020
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0702,
        "E2E Throughput (tokens\/s)":28.88,
        "Prefill Latency (s)":10550,
        "E2E Latency (s)":355871.0,
        "Allocated Memory (MB)":34.7,
        "Reserved Memory (MB)":28.8,
        "Used Memory (MB)":12457,
        "Energy (tokens\/kWh)":13932
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"46.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0795,
        "E2E Throughput (tokens\/s)":23.46,
        "Prefill Latency (s)":9996,
        "E2E Latency (s)":290697.0,
        "Allocated Memory (MB)":42.7,
        "Reserved Memory (MB)":23.4,
        "Used Memory (MB)":11542,
        "Energy (tokens\/kWh)":13016
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0326,
        "E2E Throughput (tokens\/s)":42.43,
        "Prefill Latency (s)":15456,
        "E2E Latency (s)":440528.0,
        "Allocated Memory (MB)":23.6,
        "Reserved Memory (MB)":42.4,
        "Used Memory (MB)":15497,
        "Energy (tokens\/kWh)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0344,
        "E2E Throughput (tokens\/s)":38.22,
        "Prefill Latency (s)":15456,
        "E2E Latency (s)":411522.0,
        "Allocated Memory (MB)":26.2,
        "Reserved Memory (MB)":38.2,
        "Used Memory (MB)":15497,
        "Energy (tokens\/kWh)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0349,
        "E2E Throughput (tokens\/s)":38.37,
        "Prefill Latency (s)":15456,
        "E2E Latency (s)":396825.0,
        "Allocated Memory (MB)":26.1,
        "Reserved Memory (MB)":38.3,
        "Used Memory (MB)":15497,
        "Energy (tokens\/kWh)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0435,
        "E2E Throughput (tokens\/s)":34.3,
        "Prefill Latency (s)":6017,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":29.2,
        "Reserved Memory (MB)":34.2,
        "Used Memory (MB)":6327,
        "Energy (tokens\/kWh)":7802
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0444,
        "E2E Throughput (tokens\/s)":35.27,
        "Prefill Latency (s)":6743,
        "E2E Latency (s)":454545.0,
        "Allocated Memory (MB)":28.4,
        "Reserved Memory (MB)":35.2,
        "Used Memory (MB)":7054,
        "Energy (tokens\/kWh)":8530
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0484,
        "E2E Throughput (tokens\/s)":28.45,
        "Prefill Latency (s)":6178,
        "E2E Latency (s)":354609.0,
        "Allocated Memory (MB)":35.2,
        "Reserved Memory (MB)":28.4,
        "Used Memory (MB)":6327,
        "Energy (tokens\/kWh)":7800
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Size":6.76,
        "Backend":"45.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0485,
        "E2E Throughput (tokens\/s)":28.61,
        "Prefill Latency (s)":6178,
        "E2E Latency (s)":383141.0,
        "Allocated Memory (MB)":35.0,
        "Reserved Memory (MB)":28.6,
        "Used Memory (MB)":6327,
        "Energy (tokens\/kWh)":7800
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0512,
        "E2E Throughput (tokens\/s)":32.63,
        "Prefill Latency (s)":28263,
        "E2E Latency (s)":300300.0,
        "Allocated Memory (MB)":30.7,
        "Reserved Memory (MB)":32.6,
        "Used Memory (MB)":30062,
        "Energy (tokens\/kWh)":31536
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0534,
        "E2E Throughput (tokens\/s)":30.35,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":282485.0,
        "Allocated Memory (MB)":33.0,
        "Reserved Memory (MB)":30.3,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.054,
        "E2E Throughput (tokens\/s)":30.35,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":289017.0,
        "Allocated Memory (MB)":33.0,
        "Reserved Memory (MB)":30.3,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0694,
        "E2E Throughput (tokens\/s)":26.79,
        "Prefill Latency (s)":9595,
        "E2E Latency (s)":324675.0,
        "Allocated Memory (MB)":37.4,
        "Reserved Memory (MB)":26.7,
        "Used Memory (MB)":11502,
        "Energy (tokens\/kWh)":12978
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0699,
        "E2E Throughput (tokens\/s)":28.47,
        "Prefill Latency (s)":10508,
        "E2E Latency (s)":353356.0,
        "Allocated Memory (MB)":35.2,
        "Reserved Memory (MB)":28.4,
        "Used Memory (MB)":12415,
        "Energy (tokens\/kWh)":13891
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0791,
        "E2E Throughput (tokens\/s)":22.98,
        "Prefill Latency (s)":9954,
        "E2E Latency (s)":287356.0,
        "Allocated Memory (MB)":43.6,
        "Reserved Memory (MB)":22.9,
        "Used Memory (MB)":11500,
        "Energy (tokens\/kWh)":12974
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.83*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0807,
        "E2E Throughput (tokens\/s)":22.93,
        "Prefill Latency (s)":9954,
        "E2E Latency (s)":271002.0,
        "Allocated Memory (MB)":43.7,
        "Reserved Memory (MB)":22.9,
        "Used Memory (MB)":11500,
        "Energy (tokens\/kWh)":12974
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.051,
        "E2E Throughput (tokens\/s)":32.95,
        "Prefill Latency (s)":28263,
        "E2E Latency (s)":306748.0,
        "Allocated Memory (MB)":30.4,
        "Reserved Memory (MB)":32.9,
        "Used Memory (MB)":30062,
        "Energy (tokens\/kWh)":31536
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0532,
        "E2E Throughput (tokens\/s)":30.17,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":279329.0,
        "Allocated Memory (MB)":33.2,
        "Reserved Memory (MB)":30.1,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.054,
        "E2E Throughput (tokens\/s)":30.63,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":279329.0,
        "Allocated Memory (MB)":32.7,
        "Reserved Memory (MB)":30.6,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0706,
        "E2E Throughput (tokens\/s)":28.23,
        "Prefill Latency (s)":9595,
        "E2E Latency (s)":324675.0,
        "Allocated Memory (MB)":35.5,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":11502,
        "Energy (tokens\/kWh)":12978
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0715,
        "E2E Throughput (tokens\/s)":27.76,
        "Prefill Latency (s)":10508,
        "E2E Latency (s)":352112.0,
        "Allocated Memory (MB)":36.1,
        "Reserved Memory (MB)":27.7,
        "Used Memory (MB)":12415,
        "Energy (tokens\/kWh)":13891
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"44.81*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.079,
        "E2E Throughput (tokens\/s)":23.08,
        "Prefill Latency (s)":9954,
        "E2E Latency (s)":288184.0,
        "Allocated Memory (MB)":43.4,
        "Reserved Memory (MB)":23.0,
        "Used Memory (MB)":11500,
        "Energy (tokens\/kWh)":12974
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.032,
        "E2E Throughput (tokens\/s)":42.25,
        "Prefill Latency (s)":14895,
        "E2E Latency (s)":444444.0,
        "Allocated Memory (MB)":23.7,
        "Reserved Memory (MB)":42.2,
        "Used Memory (MB)":14942,
        "Energy (tokens\/kWh)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0332,
        "E2E Throughput (tokens\/s)":37.64,
        "Prefill Latency (s)":14895,
        "E2E Latency (s)":423728.0,
        "Allocated Memory (MB)":26.6,
        "Reserved Memory (MB)":37.6,
        "Used Memory (MB)":14942,
        "Energy (tokens\/kWh)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.034,
        "E2E Throughput (tokens\/s)":38.66,
        "Prefill Latency (s)":14895,
        "E2E Latency (s)":395256.0,
        "Allocated Memory (MB)":25.9,
        "Reserved Memory (MB)":38.6,
        "Used Memory (MB)":14942,
        "Energy (tokens\/kWh)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.042,
        "E2E Throughput (tokens\/s)":35.14,
        "Prefill Latency (s)":5455,
        "E2E Latency (s)":421940.0,
        "Allocated Memory (MB)":28.5,
        "Reserved Memory (MB)":35.1,
        "Used Memory (MB)":5750,
        "Energy (tokens\/kWh)":7226
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0433,
        "E2E Throughput (tokens\/s)":35.27,
        "Prefill Latency (s)":6180,
        "E2E Latency (s)":462962.0,
        "Allocated Memory (MB)":28.4,
        "Reserved Memory (MB)":35.2,
        "Used Memory (MB)":6478,
        "Energy (tokens\/kWh)":7953
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0456,
        "E2E Throughput (tokens\/s)":31.59,
        "Prefill Latency (s)":5615,
        "E2E Latency (s)":401606.0,
        "Allocated Memory (MB)":31.7,
        "Reserved Memory (MB)":31.5,
        "Used Memory (MB)":5748,
        "Energy (tokens\/kWh)":7222
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.047,
        "E2E Throughput (tokens\/s)":28.77,
        "Prefill Latency (s)":5615,
        "E2E Latency (s)":387596.0,
        "Allocated Memory (MB)":34.8,
        "Reserved Memory (MB)":28.7,
        "Used Memory (MB)":5760,
        "Energy (tokens\/kWh)":7234
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"43.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0482,
        "E2E Throughput (tokens\/s)":29.03,
        "Prefill Latency (s)":5615,
        "E2E Latency (s)":369003.0,
        "Allocated Memory (MB)":34.5,
        "Reserved Memory (MB)":29.0,
        "Used Memory (MB)":5760,
        "Energy (tokens\/kWh)":7234
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"41.60 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0255,
        "E2E Throughput (tokens\/s)":38.8,
        "Prefill Latency (s)":3329,
        "E2E Latency (s)":581395.0,
        "Allocated Memory (MB)":25.8,
        "Reserved Memory (MB)":38.8,
        "Used Memory (MB)":3399,
        "Energy (tokens\/kWh)":4873
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"41.60 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0264,
        "E2E Throughput (tokens\/s)":37.77,
        "Prefill Latency (s)":3329,
        "E2E Latency (s)":552486.0,
        "Allocated Memory (MB)":26.5,
        "Reserved Memory (MB)":37.7,
        "Used Memory (MB)":3399,
        "Energy (tokens\/kWh)":4873
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"41.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0352,
        "E2E Throughput (tokens\/s)":33.6,
        "Prefill Latency (s)":1600,
        "E2E Latency (s)":515463.0,
        "Allocated Memory (MB)":29.8,
        "Reserved Memory (MB)":33.6,
        "Used Memory (MB)":1656,
        "Energy (tokens\/kWh)":3130
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"41.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0354,
        "E2E Throughput (tokens\/s)":33.37,
        "Prefill Latency (s)":1600,
        "E2E Latency (s)":518134.0,
        "Allocated Memory (MB)":30.0,
        "Reserved Memory (MB)":33.3,
        "Used Memory (MB)":1656,
        "Energy (tokens\/kWh)":3130
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0524,
        "E2E Throughput (tokens\/s)":33.62,
        "Prefill Latency (s)":28263,
        "E2E Latency (s)":298507.0,
        "Allocated Memory (MB)":29.8,
        "Reserved Memory (MB)":33.6,
        "Used Memory (MB)":30062,
        "Energy (tokens\/kWh)":31536
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0529,
        "E2E Throughput (tokens\/s)":29.9,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":287356.0,
        "Allocated Memory (MB)":33.5,
        "Reserved Memory (MB)":29.9,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0546,
        "E2E Throughput (tokens\/s)":29.46,
        "Prefill Latency (s)":28264,
        "E2E Latency (s)":278551.0,
        "Allocated Memory (MB)":34.0,
        "Reserved Memory (MB)":29.4,
        "Used Memory (MB)":30106,
        "Energy (tokens\/kWh)":31580
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0695,
        "E2E Throughput (tokens\/s)":28.07,
        "Prefill Latency (s)":9595,
        "E2E Latency (s)":327868.0,
        "Allocated Memory (MB)":35.7,
        "Reserved Memory (MB)":28.0,
        "Used Memory (MB)":11502,
        "Energy (tokens\/kWh)":12978
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0713,
        "E2E Throughput (tokens\/s)":28.23,
        "Prefill Latency (s)":10508,
        "E2E Latency (s)":358422.0,
        "Allocated Memory (MB)":35.5,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":12415,
        "Energy (tokens\/kWh)":13891
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0775,
        "E2E Throughput (tokens\/s)":25.3,
        "Prefill Latency (s)":9953,
        "E2E Latency (s)":295857.0,
        "Allocated Memory (MB)":39.6,
        "Reserved Memory (MB)":25.3,
        "Used Memory (MB)":11452,
        "Energy (tokens\/kWh)":12926
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0794,
        "E2E Throughput (tokens\/s)":22.82,
        "Prefill Latency (s)":9954,
        "E2E Latency (s)":281690.0,
        "Allocated Memory (MB)":43.9,
        "Reserved Memory (MB)":22.8,
        "Used Memory (MB)":11500,
        "Energy (tokens\/kWh)":12974
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Size":12.85,
        "Backend":"41.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0807,
        "E2E Throughput (tokens\/s)":22.77,
        "Prefill Latency (s)":9954,
        "E2E Latency (s)":268817.0,
        "Allocated Memory (MB)":44.0,
        "Reserved Memory (MB)":22.7,
        "Used Memory (MB)":11500,
        "Energy (tokens\/kWh)":12974
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0228,
        "E2E Throughput (tokens\/s)":42.78,
        "Prefill Latency (s)":6458,
        "E2E Latency (s)":543478.0,
        "Allocated Memory (MB)":23.4,
        "Reserved Memory (MB)":42.7,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0232,
        "E2E Throughput (tokens\/s)":42.24,
        "Prefill Latency (s)":6458,
        "E2E Latency (s)":555555.0,
        "Allocated Memory (MB)":23.7,
        "Reserved Memory (MB)":42.2,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0271,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":3172,
        "E2E Latency (s)":558659.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":3336,
        "Energy (tokens\/kWh)":4812
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0273,
        "E2E Throughput (tokens\/s)":40.37,
        "Prefill Latency (s)":2716,
        "E2E Latency (s)":549450.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":2879,
        "Energy (tokens\/kWh)":4355
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0427,
        "E2E Throughput (tokens\/s)":32.3,
        "Prefill Latency (s)":2627,
        "E2E Latency (s)":442477.0,
        "Allocated Memory (MB)":31.0,
        "Reserved Memory (MB)":32.3,
        "Used Memory (MB)":2755,
        "Energy (tokens\/kWh)":4229
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"40.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0441,
        "E2E Throughput (tokens\/s)":31.89,
        "Prefill Latency (s)":2627,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":31.4,
        "Reserved Memory (MB)":31.8,
        "Used Memory (MB)":2755,
        "Energy (tokens\/kWh)":4229
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Size":6.89,
        "Backend":"40.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0302,
        "E2E Throughput (tokens\/s)":42.79,
        "Prefill Latency (s)":15178,
        "E2E Latency (s)":442477.0,
        "Allocated Memory (MB)":23.4,
        "Reserved Memory (MB)":42.7,
        "Used Memory (MB)":15210,
        "Energy (tokens\/kWh)":16684
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Size":6.89,
        "Backend":"40.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0316,
        "E2E Throughput (tokens\/s)":43.54,
        "Prefill Latency (s)":15178,
        "E2E Latency (s)":429184.0,
        "Allocated Memory (MB)":23.0,
        "Reserved Memory (MB)":43.5,
        "Used Memory (MB)":15210,
        "Energy (tokens\/kWh)":16684
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Size":6.89,
        "Backend":"40.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0434,
        "E2E Throughput (tokens\/s)":34.65,
        "Prefill Latency (s)":5869,
        "E2E Latency (s)":446428.0,
        "Allocated Memory (MB)":28.9,
        "Reserved Memory (MB)":34.6,
        "Used Memory (MB)":6069,
        "Energy (tokens\/kWh)":7542
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Size":6.89,
        "Backend":"40.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0442,
        "E2E Throughput (tokens\/s)":35.9,
        "Prefill Latency (s)":5869,
        "E2E Latency (s)":432900.0,
        "Allocated Memory (MB)":27.9,
        "Reserved Memory (MB)":35.8,
        "Used Memory (MB)":6069,
        "Energy (tokens\/kWh)":7542
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.032,
        "E2E Throughput (tokens\/s)":42.07,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":436681.0,
        "Allocated Memory (MB)":23.8,
        "Reserved Memory (MB)":42.0,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0334,
        "E2E Throughput (tokens\/s)":37.93,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":432900.0,
        "Allocated Memory (MB)":26.4,
        "Reserved Memory (MB)":37.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.034,
        "E2E Throughput (tokens\/s)":38.66,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":404858.0,
        "Allocated Memory (MB)":25.9,
        "Reserved Memory (MB)":38.6,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0428,
        "E2E Throughput (tokens\/s)":35.9,
        "Prefill Latency (s)":5421,
        "E2E Latency (s)":444444.0,
        "Allocated Memory (MB)":27.9,
        "Reserved Memory (MB)":35.8,
        "Used Memory (MB)":5716,
        "Energy (tokens\/kWh)":7192
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0434,
        "E2E Throughput (tokens\/s)":34.53,
        "Prefill Latency (s)":6147,
        "E2E Latency (s)":442477.0,
        "Allocated Memory (MB)":29.0,
        "Reserved Memory (MB)":34.5,
        "Used Memory (MB)":6444,
        "Energy (tokens\/kWh)":7920
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0459,
        "E2E Throughput (tokens\/s)":30.81,
        "Prefill Latency (s)":5582,
        "E2E Latency (s)":395256.0,
        "Allocated Memory (MB)":32.5,
        "Reserved Memory (MB)":30.8,
        "Used Memory (MB)":5714,
        "Energy (tokens\/kWh)":7188
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.047,
        "E2E Throughput (tokens\/s)":29.11,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":386100.0,
        "Allocated Memory (MB)":34.4,
        "Reserved Memory (MB)":29.1,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"39.93*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0479,
        "E2E Throughput (tokens\/s)":28.53,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":370370.0,
        "Allocated Memory (MB)":35.1,
        "Reserved Memory (MB)":28.5,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0319,
        "E2E Throughput (tokens\/s)":42.98,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":462962.0,
        "Allocated Memory (MB)":23.3,
        "Reserved Memory (MB)":42.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0331,
        "E2E Throughput (tokens\/s)":38.07,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":429184.0,
        "Allocated Memory (MB)":26.3,
        "Reserved Memory (MB)":38.0,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0339,
        "E2E Throughput (tokens\/s)":38.81,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":414937.0,
        "Allocated Memory (MB)":25.8,
        "Reserved Memory (MB)":38.8,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0426,
        "E2E Throughput (tokens\/s)":34.65,
        "Prefill Latency (s)":6147,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":28.9,
        "Reserved Memory (MB)":34.6,
        "Used Memory (MB)":6444,
        "Energy (tokens\/kWh)":7920
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0428,
        "E2E Throughput (tokens\/s)":34.77,
        "Prefill Latency (s)":5421,
        "E2E Latency (s)":429184.0,
        "Allocated Memory (MB)":28.8,
        "Reserved Memory (MB)":34.7,
        "Used Memory (MB)":5716,
        "Energy (tokens\/kWh)":7192
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0458,
        "E2E Throughput (tokens\/s)":30.91,
        "Prefill Latency (s)":5582,
        "E2E Latency (s)":392156.0,
        "Allocated Memory (MB)":32.4,
        "Reserved Memory (MB)":30.9,
        "Used Memory (MB)":5714,
        "Energy (tokens\/kWh)":7188
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0474,
        "E2E Throughput (tokens\/s)":28.45,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":371747.0,
        "Allocated Memory (MB)":35.2,
        "Reserved Memory (MB)":28.4,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"39.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0476,
        "E2E Throughput (tokens\/s)":28.29,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":373134.0,
        "Allocated Memory (MB)":35.4,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Size":6.65,
        "Backend":"38.74 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0277,
        "E2E Throughput (tokens\/s)":61.83,
        "Prefill Latency (s)":14649,
        "E2E Latency (s)":568181.0,
        "Allocated Memory (MB)":16.2,
        "Reserved Memory (MB)":61.7,
        "Used Memory (MB)":14669,
        "Energy (tokens\/kWh)":16143
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Size":6.65,
        "Backend":"38.74 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0279,
        "E2E Throughput (tokens\/s)":61.08,
        "Prefill Latency (s)":14649,
        "E2E Latency (s)":540540.0,
        "Allocated Memory (MB)":16.4,
        "Reserved Memory (MB)":61.0,
        "Used Memory (MB)":14669,
        "Energy (tokens\/kWh)":16143
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Size":6.65,
        "Backend":"38.74*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0402,
        "E2E Throughput (tokens\/s)":47.94,
        "Prefill Latency (s)":5395,
        "E2E Latency (s)":564971.0,
        "Allocated Memory (MB)":20.9,
        "Reserved Memory (MB)":47.8,
        "Used Memory (MB)":5481,
        "Energy (tokens\/kWh)":6955
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Size":6.65,
        "Backend":"38.74*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0405,
        "E2E Throughput (tokens\/s)":48.88,
        "Prefill Latency (s)":5395,
        "E2E Latency (s)":552486.0,
        "Allocated Memory (MB)":20.5,
        "Reserved Memory (MB)":48.8,
        "Used Memory (MB)":5481,
        "Energy (tokens\/kWh)":6955
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.032,
        "E2E Throughput (tokens\/s)":42.98,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":460829.0,
        "Allocated Memory (MB)":23.3,
        "Reserved Memory (MB)":42.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0341,
        "E2E Throughput (tokens\/s)":37.93,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":418410.0,
        "Allocated Memory (MB)":26.4,
        "Reserved Memory (MB)":37.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0349,
        "E2E Throughput (tokens\/s)":38.96,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":414937.0,
        "Allocated Memory (MB)":25.7,
        "Reserved Memory (MB)":38.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0419,
        "E2E Throughput (tokens\/s)":35.02,
        "Prefill Latency (s)":5421,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":28.6,
        "Reserved Memory (MB)":35.0,
        "Used Memory (MB)":5716,
        "Energy (tokens\/kWh)":7192
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0424,
        "E2E Throughput (tokens\/s)":34.41,
        "Prefill Latency (s)":6147,
        "E2E Latency (s)":460829.0,
        "Allocated Memory (MB)":29.1,
        "Reserved Memory (MB)":34.4,
        "Used Memory (MB)":6444,
        "Energy (tokens\/kWh)":7920
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0459,
        "E2E Throughput (tokens\/s)":31.29,
        "Prefill Latency (s)":5582,
        "E2E Latency (s)":392156.0,
        "Allocated Memory (MB)":32.0,
        "Reserved Memory (MB)":31.2,
        "Used Memory (MB)":5714,
        "Energy (tokens\/kWh)":7188
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0471,
        "E2E Throughput (tokens\/s)":28.69,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":378787.0,
        "Allocated Memory (MB)":34.9,
        "Reserved Memory (MB)":28.7,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"38.72*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0473,
        "E2E Throughput (tokens\/s)":28.94,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":370370.0,
        "Allocated Memory (MB)":34.6,
        "Reserved Memory (MB)":28.9,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"38.27 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0348,
        "E2E Throughput (tokens\/s)":39.9,
        "Prefill Latency (s)":13945,
        "E2E Latency (s)":448430.0,
        "Allocated Memory (MB)":25.1,
        "Reserved Memory (MB)":39.8,
        "Used Memory (MB)":14088,
        "Energy (tokens\/kWh)":15562
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"38.27 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.035,
        "E2E Throughput (tokens\/s)":39.58,
        "Prefill Latency (s)":13945,
        "E2E Latency (s)":429184.0,
        "Allocated Memory (MB)":25.3,
        "Reserved Memory (MB)":39.5,
        "Used Memory (MB)":14088,
        "Energy (tokens\/kWh)":15562
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"38.27*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0519,
        "E2E Throughput (tokens\/s)":36.97,
        "Prefill Latency (s)":4558,
        "E2E Latency (s)":456621.0,
        "Allocated Memory (MB)":27.1,
        "Reserved Memory (MB)":36.9,
        "Used Memory (MB)":4655,
        "Energy (tokens\/kWh)":6129
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"38.27*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0521,
        "E2E Throughput (tokens\/s)":36.84,
        "Prefill Latency (s)":4558,
        "E2E Latency (s)":469483.0,
        "Allocated Memory (MB)":27.2,
        "Reserved Memory (MB)":36.8,
        "Used Memory (MB)":4655,
        "Energy (tokens\/kWh)":6129
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0507,
        "E2E Throughput (tokens\/s)":32.21,
        "Prefill Latency (s)":28557,
        "E2E Latency (s)":298507.0,
        "Allocated Memory (MB)":31.1,
        "Reserved Memory (MB)":32.2,
        "Used Memory (MB)":30356,
        "Energy (tokens\/kWh)":31830
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0533,
        "E2E Throughput (tokens\/s)":29.72,
        "Prefill Latency (s)":28557,
        "E2E Latency (s)":287356.0,
        "Allocated Memory (MB)":33.7,
        "Reserved Memory (MB)":29.7,
        "Used Memory (MB)":30400,
        "Energy (tokens\/kWh)":31874
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0546,
        "E2E Throughput (tokens\/s)":28.95,
        "Prefill Latency (s)":28557,
        "E2E Latency (s)":274725.0,
        "Allocated Memory (MB)":34.6,
        "Reserved Memory (MB)":28.9,
        "Used Memory (MB)":30400,
        "Energy (tokens\/kWh)":31874
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0707,
        "E2E Throughput (tokens\/s)":28.63,
        "Prefill Latency (s)":9889,
        "E2E Latency (s)":330033.0,
        "Allocated Memory (MB)":35.0,
        "Reserved Memory (MB)":28.6,
        "Used Memory (MB)":11771,
        "Energy (tokens\/kWh)":13247
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0716,
        "E2E Throughput (tokens\/s)":27.99,
        "Prefill Latency (s)":10802,
        "E2E Latency (s)":348432.0,
        "Allocated Memory (MB)":35.8,
        "Reserved Memory (MB)":27.9,
        "Used Memory (MB)":12683,
        "Energy (tokens\/kWh)":14159
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0776,
        "E2E Throughput (tokens\/s)":25.17,
        "Prefill Latency (s)":10251,
        "E2E Latency (s)":301204.0,
        "Allocated Memory (MB)":39.8,
        "Reserved Memory (MB)":25.1,
        "Used Memory (MB)":11794,
        "Energy (tokens\/kWh)":13268
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0796,
        "E2E Throughput (tokens\/s)":22.72,
        "Prefill Latency (s)":10251,
        "E2E Latency (s)":280112.0,
        "Allocated Memory (MB)":44.1,
        "Reserved Memory (MB)":22.7,
        "Used Memory (MB)":11794,
        "Energy (tokens\/kWh)":13268
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Size":13.02,
        "Backend":"37.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0808,
        "E2E Throughput (tokens\/s)":23.52,
        "Prefill Latency (s)":10251,
        "E2E Latency (s)":268817.0,
        "Allocated Memory (MB)":42.6,
        "Reserved Memory (MB)":23.5,
        "Used Memory (MB)":11794,
        "Energy (tokens\/kWh)":13268
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"37.74 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0582,
        "E2E Throughput (tokens\/s)":23.4,
        "Prefill Latency (s)":28350,
        "E2E Latency (s)":241545.0,
        "Allocated Memory (MB)":42.8,
        "Reserved Memory (MB)":23.4,
        "Used Memory (MB)":28393,
        "Energy (tokens\/kWh)":29867
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"37.74 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.059,
        "E2E Throughput (tokens\/s)":23.9,
        "Prefill Latency (s)":28350,
        "E2E Latency (s)":249376.0,
        "Allocated Memory (MB)":41.9,
        "Reserved Memory (MB)":23.9,
        "Used Memory (MB)":28393,
        "Energy (tokens\/kWh)":29867
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"37.74*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.088,
        "E2E Throughput (tokens\/s)":17.6,
        "Prefill Latency (s)":8714,
        "E2E Latency (s)":228310.0,
        "Allocated Memory (MB)":56.9,
        "Reserved Memory (MB)":17.6,
        "Used Memory (MB)":9024,
        "Energy (tokens\/kWh)":10497
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"37.74*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0893,
        "E2E Throughput (tokens\/s)":17.24,
        "Prefill Latency (s)":8714,
        "E2E Latency (s)":206185.0,
        "Allocated Memory (MB)":58.1,
        "Reserved Memory (MB)":17.2,
        "Used Memory (MB)":9024,
        "Energy (tokens\/kWh)":10497
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Size":65.72,
        "Backend":"37.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.278,
        "E2E Throughput (tokens\/s)":22.46,
        "Prefill Latency (s)":43999,
        "E2E Latency (s)":207468.0,
        "Allocated Memory (MB)":44.8,
        "Reserved Memory (MB)":22.3,
        "Used Memory (MB)":63464,
        "Energy (tokens\/kWh)":64939
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Size":65.72,
        "Backend":"37.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.284,
        "E2E Throughput (tokens\/s)":14.0,
        "Prefill Latency (s)":41562,
        "E2E Latency (s)":131233.0,
        "Allocated Memory (MB)":71.7,
        "Reserved Memory (MB)":13.9,
        "Used Memory (MB)":61022,
        "Energy (tokens\/kWh)":62498
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Size":65.72,
        "Backend":"37.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.339,
        "E2E Throughput (tokens\/s)":14.82,
        "Prefill Latency (s)":43600,
        "E2E Latency (s)":133689.0,
        "Allocated Memory (MB)":67.8,
        "Reserved Memory (MB)":14.7,
        "Used Memory (MB)":58466,
        "Energy (tokens\/kWh)":59938
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Size":65.72,
        "Backend":"37.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.348,
        "E2E Throughput (tokens\/s)":13.08,
        "Prefill Latency (s)":43601,
        "E2E Latency (s)":119331.0,
        "Allocated Memory (MB)":76.8,
        "Reserved Memory (MB)":13.0,
        "Used Memory (MB)":58466,
        "Energy (tokens\/kWh)":59940
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Size":65.72,
        "Backend":"37.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.358,
        "E2E Throughput (tokens\/s)":12.83,
        "Prefill Latency (s)":43601,
        "E2E Latency (s)":112994.0,
        "Allocated Memory (MB)":78.3,
        "Reserved Memory (MB)":12.8,
        "Used Memory (MB)":58466,
        "Energy (tokens\/kWh)":59940
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0612,
        "E2E Throughput (tokens\/s)":27.07,
        "Prefill Latency (s)":34377,
        "E2E Latency (s)":246305.0,
        "Allocated Memory (MB)":37.0,
        "Reserved Memory (MB)":27.0,
        "Used Memory (MB)":36962,
        "Energy (tokens\/kWh)":38436
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0634,
        "E2E Throughput (tokens\/s)":25.62,
        "Prefill Latency (s)":34361,
        "E2E Latency (s)":240963.0,
        "Allocated Memory (MB)":39.1,
        "Reserved Memory (MB)":25.6,
        "Used Memory (MB)":36951,
        "Energy (tokens\/kWh)":38425
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0648,
        "E2E Throughput (tokens\/s)":25.17,
        "Prefill Latency (s)":34361,
        "E2E Latency (s)":231481.0,
        "Allocated Memory (MB)":39.8,
        "Reserved Memory (MB)":25.1,
        "Used Memory (MB)":36951,
        "Energy (tokens\/kWh)":38425
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0814,
        "E2E Throughput (tokens\/s)":25.3,
        "Prefill Latency (s)":11871,
        "E2E Latency (s)":293255.0,
        "Allocated Memory (MB)":39.6,
        "Reserved Memory (MB)":25.3,
        "Used Memory (MB)":14487,
        "Energy (tokens\/kWh)":15962
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0821,
        "E2E Throughput (tokens\/s)":25.63,
        "Prefill Latency (s)":13487,
        "E2E Latency (s)":323624.0,
        "Allocated Memory (MB)":39.1,
        "Reserved Memory (MB)":25.6,
        "Used Memory (MB)":16106,
        "Energy (tokens\/kWh)":17581
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0936,
        "E2E Throughput (tokens\/s)":24.21,
        "Prefill Latency (s)":12250,
        "E2E Latency (s)":270270.0,
        "Allocated Memory (MB)":41.4,
        "Reserved Memory (MB)":24.2,
        "Used Memory (MB)":13929,
        "Energy (tokens\/kWh)":15403
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Size":15.72,
        "Backend":"37.22*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0978,
        "E2E Throughput (tokens\/s)":22.93,
        "Prefill Latency (s)":12235,
        "E2E Latency (s)":263157.0,
        "Allocated Memory (MB)":43.7,
        "Reserved Memory (MB)":22.9,
        "Used Memory (MB)":13885,
        "Energy (tokens\/kWh)":15358
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0322,
        "E2E Throughput (tokens\/s)":40.21,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":24.9,
        "Reserved Memory (MB)":40.2,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0334,
        "E2E Throughput (tokens\/s)":38.51,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":26.0,
        "Reserved Memory (MB)":38.5,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0338,
        "E2E Throughput (tokens\/s)":37.93,
        "Prefill Latency (s)":14861,
        "E2E Latency (s)":411522.0,
        "Allocated Memory (MB)":26.4,
        "Reserved Memory (MB)":37.9,
        "Used Memory (MB)":14908,
        "Energy (tokens\/kWh)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0419,
        "E2E Throughput (tokens\/s)":35.64,
        "Prefill Latency (s)":5421,
        "E2E Latency (s)":454545.0,
        "Allocated Memory (MB)":28.1,
        "Reserved Memory (MB)":35.6,
        "Used Memory (MB)":5716,
        "Energy (tokens\/kWh)":7192
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0427,
        "E2E Throughput (tokens\/s)":34.77,
        "Prefill Latency (s)":6147,
        "E2E Latency (s)":480769.0,
        "Allocated Memory (MB)":28.8,
        "Reserved Memory (MB)":34.7,
        "Used Memory (MB)":6444,
        "Energy (tokens\/kWh)":7920
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0458,
        "E2E Throughput (tokens\/s)":31.69,
        "Prefill Latency (s)":5582,
        "E2E Latency (s)":396825.0,
        "Allocated Memory (MB)":31.6,
        "Reserved Memory (MB)":31.6,
        "Used Memory (MB)":5714,
        "Energy (tokens\/kWh)":7188
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Size":6.61,
        "Backend":"37.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0474,
        "E2E Throughput (tokens\/s)":29.03,
        "Prefill Latency (s)":5581,
        "E2E Latency (s)":373134.0,
        "Allocated Memory (MB)":34.5,
        "Reserved Memory (MB)":29.0,
        "Used Memory (MB)":5727,
        "Energy (tokens\/kWh)":7201
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0577,
        "E2E Throughput (tokens\/s)":27.9,
        "Prefill Latency (s)":43419,
        "E2E Latency (s)":289855.0,
        "Allocated Memory (MB)":35.9,
        "Reserved Memory (MB)":27.9,
        "Used Memory (MB)":46948,
        "Energy (tokens\/kWh)":48420
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0594,
        "E2E Throughput (tokens\/s)":26.08,
        "Prefill Latency (s)":43420,
        "E2E Latency (s)":277008.0,
        "Allocated Memory (MB)":38.4,
        "Reserved Memory (MB)":26.0,
        "Used Memory (MB)":46925,
        "Energy (tokens\/kWh)":48399
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0712,
        "E2E Throughput (tokens\/s)":25.82,
        "Prefill Latency (s)":43420,
        "E2E Latency (s)":234192.0,
        "Allocated Memory (MB)":38.8,
        "Reserved Memory (MB)":25.8,
        "Used Memory (MB)":46925,
        "Energy (tokens\/kWh)":48399
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0718,
        "E2E Throughput (tokens\/s)":27.99,
        "Prefill Latency (s)":43419,
        "E2E Latency (s)":256410.0,
        "Allocated Memory (MB)":35.8,
        "Reserved Memory (MB)":27.9,
        "Used Memory (MB)":46948,
        "Energy (tokens\/kWh)":48420
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0718,
        "E2E Throughput (tokens\/s)":26.09,
        "Prefill Latency (s)":43420,
        "E2E Latency (s)":239234.0,
        "Allocated Memory (MB)":38.4,
        "Reserved Memory (MB)":26.0,
        "Used Memory (MB)":46925,
        "Energy (tokens\/kWh)":48399
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0957,
        "E2E Throughput (tokens\/s)":33.33,
        "Prefill Latency (s)":14228,
        "E2E Latency (s)":346020.0,
        "Allocated Memory (MB)":30.1,
        "Reserved Memory (MB)":33.2,
        "Used Memory (MB)":17758,
        "Energy (tokens\/kWh)":19234
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Size":20.26,
        "Backend":"36.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0973,
        "E2E Throughput (tokens\/s)":40.81,
        "Prefill Latency (s)":15846,
        "E2E Latency (s)":450450.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":19379,
        "Energy (tokens\/kWh)":20855
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.108,
        "E2E Throughput (tokens\/s)":21.33,
        "Prefill Latency (s)":63508,
        "E2E Latency (s)":196850.0,
        "Allocated Memory (MB)":47.0,
        "Reserved Memory (MB)":21.3,
        "Used Memory (MB)":68209,
        "Energy (tokens\/kWh)":69681
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.115,
        "E2E Throughput (tokens\/s)":19.69,
        "Prefill Latency (s)":63498,
        "E2E Latency (s)":181488.0,
        "Allocated Memory (MB)":50.9,
        "Reserved Memory (MB)":19.6,
        "Used Memory (MB)":68010,
        "Energy (tokens\/kWh)":69484
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.12,
        "E2E Throughput (tokens\/s)":19.54,
        "Prefill Latency (s)":63498,
        "E2E Latency (s)":179856.0,
        "Allocated Memory (MB)":51.3,
        "Reserved Memory (MB)":19.5,
        "Used Memory (MB)":68010,
        "Energy (tokens\/kWh)":69484
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.144,
        "E2E Throughput (tokens\/s)":35.14,
        "Prefill Latency (s)":22002,
        "E2E Latency (s)":364963.0,
        "Allocated Memory (MB)":28.6,
        "Reserved Memory (MB)":35.0,
        "Used Memory (MB)":26925,
        "Energy (tokens\/kWh)":28401
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.144,
        "E2E Throughput (tokens\/s)":25.28,
        "Prefill Latency (s)":20110,
        "E2E Latency (s)":250626.0,
        "Allocated Memory (MB)":39.7,
        "Reserved Memory (MB)":25.2,
        "Used Memory (MB)":25052,
        "Energy (tokens\/kWh)":26528
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.17,
        "E2E Throughput (tokens\/s)":27.91,
        "Prefill Latency (s)":20948,
        "E2E Latency (s)":242130.0,
        "Allocated Memory (MB)":36.0,
        "Reserved Memory (MB)":27.8,
        "Used Memory (MB)":24519,
        "Energy (tokens\/kWh)":25993
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Size":29.98,
        "Backend":"36.57*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.178,
        "E2E Throughput (tokens\/s)":22.51,
        "Prefill Latency (s)":20948,
        "E2E Latency (s)":213219.0,
        "Allocated Memory (MB)":44.6,
        "Reserved Memory (MB)":22.4,
        "Used Memory (MB)":24519,
        "Energy (tokens\/kWh)":25993
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0182,
        "E2E Throughput (tokens\/s)":55.61,
        "Prefill Latency (s)":6840,
        "E2E Latency (s)":689655.0,
        "Allocated Memory (MB)":18.0,
        "Reserved Memory (MB)":55.6,
        "Used Memory (MB)":7119,
        "Energy (tokens\/kWh)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0201,
        "E2E Throughput (tokens\/s)":49.31,
        "Prefill Latency (s)":6840,
        "E2E Latency (s)":609756.0,
        "Allocated Memory (MB)":20.3,
        "Reserved Memory (MB)":49.3,
        "Used Memory (MB)":7119,
        "Energy (tokens\/kWh)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0206,
        "E2E Throughput (tokens\/s)":48.59,
        "Prefill Latency (s)":6840,
        "E2E Latency (s)":632911.0,
        "Allocated Memory (MB)":20.6,
        "Reserved Memory (MB)":48.5,
        "Used Memory (MB)":7119,
        "Energy (tokens\/kWh)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0231,
        "E2E Throughput (tokens\/s)":46.56,
        "Prefill Latency (s)":3410,
        "E2E Latency (s)":662251.0,
        "Allocated Memory (MB)":21.5,
        "Reserved Memory (MB)":46.5,
        "Used Memory (MB)":3743,
        "Energy (tokens\/kWh)":5219
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0235,
        "E2E Throughput (tokens\/s)":46.13,
        "Prefill Latency (s)":2870,
        "E2E Latency (s)":632911.0,
        "Allocated Memory (MB)":21.7,
        "Reserved Memory (MB)":46.1,
        "Used Memory (MB)":3200,
        "Energy (tokens\/kWh)":4676
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0329,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":561797.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":3229,
        "Energy (tokens\/kWh)":4703
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Size":3.0,
        "Backend":"36.20*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0353,
        "E2E Throughput (tokens\/s)":37.79,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":518134.0,
        "Allocated Memory (MB)":26.5,
        "Reserved Memory (MB)":37.7,
        "Used Memory (MB)":3219,
        "Energy (tokens\/kWh)":4692
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0292,
        "E2E Throughput (tokens\/s)":45.72,
        "Prefill Latency (s)":15233,
        "E2E Latency (s)":473933.0,
        "Allocated Memory (MB)":21.9,
        "Reserved Memory (MB)":45.7,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16738
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0298,
        "E2E Throughput (tokens\/s)":46.36,
        "Prefill Latency (s)":15233,
        "E2E Latency (s)":476190.0,
        "Allocated Memory (MB)":21.6,
        "Reserved Memory (MB)":46.3,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16738
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0312,
        "E2E Throughput (tokens\/s)":40.05,
        "Prefill Latency (s)":15234,
        "E2E Latency (s)":436681.0,
        "Allocated Memory (MB)":25.0,
        "Reserved Memory (MB)":40.0,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0315,
        "E2E Throughput (tokens\/s)":39.89,
        "Prefill Latency (s)":15234,
        "E2E Latency (s)":432900.0,
        "Allocated Memory (MB)":25.1,
        "Reserved Memory (MB)":39.8,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0318,
        "E2E Throughput (tokens\/s)":39.42,
        "Prefill Latency (s)":15234,
        "E2E Latency (s)":423728.0,
        "Allocated Memory (MB)":25.4,
        "Reserved Memory (MB)":39.4,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0321,
        "E2E Throughput (tokens\/s)":38.51,
        "Prefill Latency (s)":15234,
        "E2E Latency (s)":423728.0,
        "Allocated Memory (MB)":26.0,
        "Reserved Memory (MB)":38.5,
        "Used Memory (MB)":15267,
        "Energy (tokens\/kWh)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0399,
        "E2E Throughput (tokens\/s)":41.91,
        "Prefill Latency (s)":5832,
        "E2E Latency (s)":523560.0,
        "Allocated Memory (MB)":23.9,
        "Reserved Memory (MB)":41.8,
        "Used Memory (MB)":5848,
        "Energy (tokens\/kWh)":7324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0409,
        "E2E Throughput (tokens\/s)":41.56,
        "Prefill Latency (s)":5832,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":24.1,
        "Reserved Memory (MB)":41.5,
        "Used Memory (MB)":5848,
        "Energy (tokens\/kWh)":7324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.041,
        "E2E Throughput (tokens\/s)":41.39,
        "Prefill Latency (s)":6910,
        "E2E Latency (s)":543478.0,
        "Allocated Memory (MB)":24.2,
        "Reserved Memory (MB)":41.3,
        "Used Memory (MB)":6928,
        "Energy (tokens\/kWh)":8404
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0419,
        "E2E Throughput (tokens\/s)":41.74,
        "Prefill Latency (s)":6910,
        "E2E Latency (s)":561797.0,
        "Allocated Memory (MB)":24.0,
        "Reserved Memory (MB)":41.7,
        "Used Memory (MB)":6928,
        "Energy (tokens\/kWh)":8404
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0466,
        "E2E Throughput (tokens\/s)":37.1,
        "Prefill Latency (s)":5999,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":27.0,
        "Reserved Memory (MB)":37.0,
        "Used Memory (MB)":6062,
        "Energy (tokens\/kWh)":7534
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0466,
        "E2E Throughput (tokens\/s)":36.96,
        "Prefill Latency (s)":5999,
        "E2E Latency (s)":450450.0,
        "Allocated Memory (MB)":27.1,
        "Reserved Memory (MB)":36.9,
        "Used Memory (MB)":6062,
        "Energy (tokens\/kWh)":7534
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0489,
        "E2E Throughput (tokens\/s)":33.28,
        "Prefill Latency (s)":5998,
        "E2E Latency (s)":413223.0,
        "Allocated Memory (MB)":30.1,
        "Reserved Memory (MB)":33.2,
        "Used Memory (MB)":6041,
        "Energy (tokens\/kWh)":7515
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"36.09*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.049,
        "E2E Throughput (tokens\/s)":33.61,
        "Prefill Latency (s)":5998,
        "E2E Latency (s)":418410.0,
        "Allocated Memory (MB)":29.8,
        "Reserved Memory (MB)":33.6,
        "Used Memory (MB)":6041,
        "Energy (tokens\/kWh)":7515
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0825,
        "E2E Throughput (tokens\/s)":24.38,
        "Prefill Latency (s)":44027,
        "E2E Latency (s)":218818.0,
        "Allocated Memory (MB)":41.1,
        "Reserved Memory (MB)":24.3,
        "Used Memory (MB)":47603,
        "Energy (tokens\/kWh)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0828,
        "E2E Throughput (tokens\/s)":23.91,
        "Prefill Latency (s)":44027,
        "E2E Latency (s)":214592.0,
        "Allocated Memory (MB)":41.9,
        "Reserved Memory (MB)":23.9,
        "Used Memory (MB)":47603,
        "Energy (tokens\/kWh)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0833,
        "E2E Throughput (tokens\/s)":23.8,
        "Prefill Latency (s)":44027,
        "E2E Latency (s)":214132.0,
        "Allocated Memory (MB)":42.1,
        "Reserved Memory (MB)":23.8,
        "Used Memory (MB)":47603,
        "Energy (tokens\/kWh)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.104,
        "E2E Throughput (tokens\/s)":26.96,
        "Prefill Latency (s)":14830,
        "E2E Latency (s)":293255.0,
        "Allocated Memory (MB)":37.2,
        "Reserved Memory (MB)":26.9,
        "Used Memory (MB)":18433,
        "Energy (tokens\/kWh)":19909
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.105,
        "E2E Throughput (tokens\/s)":26.6,
        "Prefill Latency (s)":16448,
        "E2E Latency (s)":322580.0,
        "Allocated Memory (MB)":37.7,
        "Reserved Memory (MB)":26.5,
        "Used Memory (MB)":20055,
        "Energy (tokens\/kWh)":21530
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.122,
        "E2E Throughput (tokens\/s)":23.27,
        "Prefill Latency (s)":15392,
        "E2E Latency (s)":253164.0,
        "Allocated Memory (MB)":43.1,
        "Reserved Memory (MB)":23.2,
        "Used Memory (MB)":17318,
        "Energy (tokens\/kWh)":18792
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Size":20.74,
        "Backend":"36.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.123,
        "E2E Throughput (tokens\/s)":22.23,
        "Prefill Latency (s)":15392,
        "E2E Latency (s)":242130.0,
        "Allocated Memory (MB)":45.1,
        "Reserved Memory (MB)":22.2,
        "Used Memory (MB)":17341,
        "Energy (tokens\/kWh)":18815
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0303,
        "E2E Throughput (tokens\/s)":13.34,
        "Prefill Latency (s)":14150,
        "E2E Latency (s)":123915.0,
        "Allocated Memory (MB)":75.0,
        "Reserved Memory (MB)":13.3,
        "Used Memory (MB)":21544,
        "Energy (tokens\/kWh)":23017
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0327,
        "E2E Throughput (tokens\/s)":10.96,
        "Prefill Latency (s)":14309,
        "E2E Latency (s)":102774.0,
        "Allocated Memory (MB)":91.3,
        "Reserved Memory (MB)":11.0,
        "Used Memory (MB)":21544,
        "Energy (tokens\/kWh)":23017
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.033,
        "E2E Throughput (tokens\/s)":10.8,
        "Prefill Latency (s)":14309,
        "E2E Latency (s)":100603.0,
        "Allocated Memory (MB)":92.6,
        "Reserved Memory (MB)":10.8,
        "Used Memory (MB)":21544,
        "Energy (tokens\/kWh)":23017
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0412,
        "E2E Throughput (tokens\/s)":10.35,
        "Prefill Latency (s)":4909,
        "E2E Latency (s)":96153.0,
        "Allocated Memory (MB)":96.7,
        "Reserved Memory (MB)":10.3,
        "Used Memory (MB)":12146,
        "Energy (tokens\/kWh)":13622
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0421,
        "E2E Throughput (tokens\/s)":10.28,
        "Prefill Latency (s)":5987,
        "E2E Latency (s)":95238.0,
        "Allocated Memory (MB)":97.3,
        "Reserved Memory (MB)":10.3,
        "Used Memory (MB)":13226,
        "Energy (tokens\/kWh)":14702
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0479,
        "E2E Throughput (tokens\/s)":11.91,
        "Prefill Latency (s)":5025,
        "E2E Latency (s)":110132.0,
        "Allocated Memory (MB)":84.0,
        "Reserved Memory (MB)":11.9,
        "Used Memory (MB)":5182,
        "Energy (tokens\/kWh)":6655
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"35.46*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0503,
        "E2E Throughput (tokens\/s)":9.91,
        "Prefill Latency (s)":5081,
        "E2E Latency (s)":91743.0,
        "Allocated Memory (MB)":101.0,
        "Reserved Memory (MB)":9.9,
        "Used Memory (MB)":5316,
        "Energy (tokens\/kWh)":6790
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"35.26 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0222,
        "E2E Throughput (tokens\/s)":45.71,
        "Prefill Latency (s)":7770,
        "E2E Latency (s)":561797.0,
        "Allocated Memory (MB)":21.9,
        "Reserved Memory (MB)":45.7,
        "Used Memory (MB)":8155,
        "Energy (tokens\/kWh)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"35.26 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0226,
        "E2E Throughput (tokens\/s)":47.22,
        "Prefill Latency (s)":7779,
        "E2E Latency (s)":588235.0,
        "Allocated Memory (MB)":21.2,
        "Reserved Memory (MB)":47.2,
        "Used Memory (MB)":8172,
        "Energy (tokens\/kWh)":9646
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"35.26 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0226,
        "E2E Throughput (tokens\/s)":45.5,
        "Prefill Latency (s)":7770,
        "E2E Latency (s)":574712.0,
        "Allocated Memory (MB)":22.0,
        "Reserved Memory (MB)":45.5,
        "Used Memory (MB)":8155,
        "Energy (tokens\/kWh)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"35.26*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0383,
        "E2E Throughput (tokens\/s)":34.53,
        "Prefill Latency (s)":3114,
        "E2E Latency (s)":465116.0,
        "Allocated Memory (MB)":29.0,
        "Reserved Memory (MB)":34.5,
        "Used Memory (MB)":3422,
        "Energy (tokens\/kWh)":4896
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"35.26*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0388,
        "E2E Throughput (tokens\/s)":35.38,
        "Prefill Latency (s)":3122,
        "E2E Latency (s)":487804.0,
        "Allocated Memory (MB)":28.3,
        "Reserved Memory (MB)":35.3,
        "Used Memory (MB)":3458,
        "Energy (tokens\/kWh)":4931
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0451,
        "E2E Throughput (tokens\/s)":43.19,
        "Prefill Latency (s)":27772,
        "E2E Latency (s)":393700.0,
        "Allocated Memory (MB)":23.2,
        "Reserved Memory (MB)":43.1,
        "Used Memory (MB)":29855,
        "Energy (tokens\/kWh)":31326
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0496,
        "E2E Throughput (tokens\/s)":35.91,
        "Prefill Latency (s)":27772,
        "E2E Latency (s)":324675.0,
        "Allocated Memory (MB)":27.9,
        "Reserved Memory (MB)":35.8,
        "Used Memory (MB)":29582,
        "Energy (tokens\/kWh)":31056
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0502,
        "E2E Throughput (tokens\/s)":35.65,
        "Prefill Latency (s)":27772,
        "E2E Latency (s)":324675.0,
        "Allocated Memory (MB)":28.1,
        "Reserved Memory (MB)":35.6,
        "Used Memory (MB)":29582,
        "Energy (tokens\/kWh)":31056
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0643,
        "E2E Throughput (tokens\/s)":40.76,
        "Prefill Latency (s)":9360,
        "E2E Latency (s)":438596.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":11444,
        "Energy (tokens\/kWh)":12920
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0664,
        "E2E Throughput (tokens\/s)":43.8,
        "Prefill Latency (s)":10709,
        "E2E Latency (s)":515463.0,
        "Allocated Memory (MB)":22.9,
        "Reserved Memory (MB)":43.7,
        "Used Memory (MB)":12794,
        "Energy (tokens\/kWh)":14270
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0726,
        "E2E Throughput (tokens\/s)":35.3,
        "Prefill Latency (s)":9685,
        "E2E Latency (s)":377358.0,
        "Allocated Memory (MB)":28.4,
        "Reserved Memory (MB)":35.2,
        "Used Memory (MB)":11150,
        "Energy (tokens\/kWh)":12622
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Size":12.85,
        "Backend":"34.99*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0786,
        "E2E Throughput (tokens\/s)":30.56,
        "Prefill Latency (s)":9686,
        "E2E Latency (s)":344827.0,
        "Allocated Memory (MB)":32.8,
        "Reserved Memory (MB)":30.5,
        "Used Memory (MB)":11177,
        "Energy (tokens\/kWh)":12651
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0343,
        "E2E Throughput (tokens\/s)":28.85,
        "Prefill Latency (s)":15707,
        "E2E Latency (s)":332225.0,
        "Allocated Memory (MB)":34.7,
        "Reserved Memory (MB)":28.8,
        "Used Memory (MB)":15762,
        "Energy (tokens\/kWh)":17235
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0383,
        "E2E Throughput (tokens\/s)":26.55,
        "Prefill Latency (s)":15697,
        "E2E Latency (s)":317460.0,
        "Allocated Memory (MB)":37.7,
        "Reserved Memory (MB)":26.5,
        "Used Memory (MB)":15741,
        "Energy (tokens\/kWh)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0384,
        "E2E Throughput (tokens\/s)":26.69,
        "Prefill Latency (s)":15697,
        "E2E Latency (s)":320512.0,
        "Allocated Memory (MB)":37.5,
        "Reserved Memory (MB)":26.7,
        "Used Memory (MB)":15741,
        "Energy (tokens\/kWh)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0456,
        "E2E Throughput (tokens\/s)":26.35,
        "Prefill Latency (s)":6000,
        "E2E Latency (s)":350877.0,
        "Allocated Memory (MB)":38.0,
        "Reserved Memory (MB)":26.3,
        "Used Memory (MB)":6039,
        "Energy (tokens\/kWh)":7515
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0478,
        "E2E Throughput (tokens\/s)":26.56,
        "Prefill Latency (s)":7077,
        "E2E Latency (s)":375939.0,
        "Allocated Memory (MB)":37.7,
        "Reserved Memory (MB)":26.5,
        "Used Memory (MB)":7119,
        "Energy (tokens\/kWh)":8595
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0499,
        "E2E Throughput (tokens\/s)":25.54,
        "Prefill Latency (s)":6188,
        "E2E Latency (s)":338983.0,
        "Allocated Memory (MB)":39.2,
        "Reserved Memory (MB)":25.5,
        "Used Memory (MB)":6285,
        "Energy (tokens\/kWh)":7758
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"34.92*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0541,
        "E2E Throughput (tokens\/s)":23.78,
        "Prefill Latency (s)":6176,
        "E2E Latency (s)":321543.0,
        "Allocated Memory (MB)":42.1,
        "Reserved Memory (MB)":23.8,
        "Used Memory (MB)":6243,
        "Energy (tokens\/kWh)":7716
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0305,
        "E2E Throughput (tokens\/s)":33.15,
        "Prefill Latency (s)":13448,
        "E2E Latency (s)":392156.0,
        "Allocated Memory (MB)":30.2,
        "Reserved Memory (MB)":33.1,
        "Used Memory (MB)":13503,
        "Energy (tokens\/kWh)":14977
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0333,
        "E2E Throughput (tokens\/s)":31.48,
        "Prefill Latency (s)":13438,
        "E2E Latency (s)":370370.0,
        "Allocated Memory (MB)":31.8,
        "Reserved Memory (MB)":31.4,
        "Used Memory (MB)":13482,
        "Energy (tokens\/kWh)":14956
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0338,
        "E2E Throughput (tokens\/s)":31.38,
        "Prefill Latency (s)":13438,
        "E2E Latency (s)":371747.0,
        "Allocated Memory (MB)":31.9,
        "Reserved Memory (MB)":31.3,
        "Used Memory (MB)":13482,
        "Energy (tokens\/kWh)":14956
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0401,
        "E2E Throughput (tokens\/s)":30.71,
        "Prefill Latency (s)":5231,
        "E2E Latency (s)":413223.0,
        "Allocated Memory (MB)":32.6,
        "Reserved Memory (MB)":30.7,
        "Used Memory (MB)":5385,
        "Energy (tokens\/kWh)":6861
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0409,
        "E2E Throughput (tokens\/s)":30.62,
        "Prefill Latency (s)":6309,
        "E2E Latency (s)":432900.0,
        "Allocated Memory (MB)":32.7,
        "Reserved Memory (MB)":30.6,
        "Used Memory (MB)":6465,
        "Energy (tokens\/kWh)":7941
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0443,
        "E2E Throughput (tokens\/s)":27.89,
        "Prefill Latency (s)":5341,
        "E2E Latency (s)":367647.0,
        "Allocated Memory (MB)":35.9,
        "Reserved Memory (MB)":27.9,
        "Used Memory (MB)":5429,
        "Energy (tokens\/kWh)":6903
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Size":5.84,
        "Backend":"34.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0486,
        "E2E Throughput (tokens\/s)":26.42,
        "Prefill Latency (s)":5331,
        "E2E Latency (s)":347222.0,
        "Allocated Memory (MB)":37.9,
        "Reserved Memory (MB)":26.4,
        "Used Memory (MB)":5387,
        "Energy (tokens\/kWh)":6861
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"34.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0583,
        "E2E Throughput (tokens\/s)":23.4,
        "Prefill Latency (s)":28350,
        "E2E Latency (s)":236406.0,
        "Allocated Memory (MB)":42.8,
        "Reserved Memory (MB)":23.4,
        "Used Memory (MB)":28393,
        "Energy (tokens\/kWh)":29867
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"34.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0583,
        "E2E Throughput (tokens\/s)":23.13,
        "Prefill Latency (s)":28350,
        "E2E Latency (s)":242130.0,
        "Allocated Memory (MB)":43.3,
        "Reserved Memory (MB)":23.1,
        "Used Memory (MB)":28393,
        "Energy (tokens\/kWh)":29867
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Size":13.89,
        "Backend":"34.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0879,
        "E2E Throughput (tokens\/s)":17.6,
        "Prefill Latency (s)":8714,
        "E2E Latency (s)":226244.0,
        "Allocated Memory (MB)":56.9,
        "Reserved Memory (MB)":17.6,
        "Used Memory (MB)":9024,
        "Energy (tokens\/kWh)":10497
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.032,
        "E2E Throughput (tokens\/s)":42.07,
        "Prefill Latency (s)":15095,
        "E2E Latency (s)":444444.0,
        "Allocated Memory (MB)":23.8,
        "Reserved Memory (MB)":42.0,
        "Used Memory (MB)":15109,
        "Energy (tokens\/kWh)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0336,
        "E2E Throughput (tokens\/s)":38.36,
        "Prefill Latency (s)":15095,
        "E2E Latency (s)":421940.0,
        "Allocated Memory (MB)":26.1,
        "Reserved Memory (MB)":38.3,
        "Used Memory (MB)":15109,
        "Energy (tokens\/kWh)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0343,
        "E2E Throughput (tokens\/s)":38.66,
        "Prefill Latency (s)":15095,
        "E2E Latency (s)":396825.0,
        "Allocated Memory (MB)":25.9,
        "Reserved Memory (MB)":38.6,
        "Used Memory (MB)":15109,
        "Energy (tokens\/kWh)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0414,
        "E2E Throughput (tokens\/s)":34.18,
        "Prefill Latency (s)":5657,
        "E2E Latency (s)":460829.0,
        "Allocated Memory (MB)":29.3,
        "Reserved Memory (MB)":34.1,
        "Used Memory (MB)":5708,
        "Energy (tokens\/kWh)":7184
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0427,
        "E2E Throughput (tokens\/s)":34.65,
        "Prefill Latency (s)":6382,
        "E2E Latency (s)":476190.0,
        "Allocated Memory (MB)":28.9,
        "Reserved Memory (MB)":34.6,
        "Used Memory (MB)":6436,
        "Energy (tokens\/kWh)":7912
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0454,
        "E2E Throughput (tokens\/s)":31.0,
        "Prefill Latency (s)":5821,
        "E2E Latency (s)":399999.0,
        "Allocated Memory (MB)":32.3,
        "Reserved Memory (MB)":31.0,
        "Used Memory (MB)":5939,
        "Energy (tokens\/kWh)":7412
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Size":6.74,
        "Backend":"34.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0474,
        "E2E Throughput (tokens\/s)":28.45,
        "Prefill Latency (s)":5822,
        "E2E Latency (s)":380228.0,
        "Allocated Memory (MB)":35.2,
        "Reserved Memory (MB)":28.4,
        "Used Memory (MB)":5939,
        "Energy (tokens\/kWh)":7412
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.046,
        "E2E Throughput (tokens\/s)":38.09,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":342465.0,
        "Allocated Memory (MB)":26.3,
        "Reserved Memory (MB)":38.0,
        "Used Memory (MB)":27856,
        "Energy (tokens\/kWh)":29328
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0479,
        "E2E Throughput (tokens\/s)":35.02,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":325732.0,
        "Allocated Memory (MB)":28.6,
        "Reserved Memory (MB)":35.0,
        "Used Memory (MB)":27812,
        "Energy (tokens\/kWh)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0481,
        "E2E Throughput (tokens\/s)":32.73,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":317460.0,
        "Allocated Memory (MB)":30.6,
        "Reserved Memory (MB)":32.7,
        "Used Memory (MB)":27812,
        "Energy (tokens\/kWh)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.062,
        "E2E Throughput (tokens\/s)":36.05,
        "Prefill Latency (s)":10548,
        "E2E Latency (s)":454545.0,
        "Allocated Memory (MB)":27.8,
        "Reserved Memory (MB)":36.0,
        "Used Memory (MB)":12637,
        "Energy (tokens\/kWh)":14113
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0711,
        "E2E Throughput (tokens\/s)":32.86,
        "Prefill Latency (s)":9441,
        "E2E Latency (s)":373134.0,
        "Allocated Memory (MB)":30.5,
        "Reserved Memory (MB)":32.8,
        "Used Memory (MB)":10557,
        "Energy (tokens\/kWh)":12028
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"34.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0738,
        "E2E Throughput (tokens\/s)":29.83,
        "Prefill Latency (s)":9441,
        "E2E Latency (s)":348432.0,
        "Allocated Memory (MB)":33.6,
        "Reserved Memory (MB)":29.8,
        "Used Memory (MB)":10529,
        "Energy (tokens\/kWh)":12003
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0289,
        "E2E Throughput (tokens\/s)":45.93,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":467289.0,
        "Allocated Memory (MB)":21.8,
        "Reserved Memory (MB)":45.9,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16713
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0314,
        "E2E Throughput (tokens\/s)":40.37,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0315,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":425531.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0392,
        "E2E Throughput (tokens\/s)":41.73,
        "Prefill Latency (s)":5807,
        "E2E Latency (s)":520833.0,
        "Allocated Memory (MB)":24.0,
        "Reserved Memory (MB)":41.7,
        "Used Memory (MB)":5825,
        "Energy (tokens\/kWh)":7301
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0404,
        "E2E Throughput (tokens\/s)":40.88,
        "Prefill Latency (s)":6884,
        "E2E Latency (s)":555555.0,
        "Allocated Memory (MB)":24.5,
        "Reserved Memory (MB)":40.8,
        "Used Memory (MB)":6905,
        "Energy (tokens\/kWh)":8381
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0453,
        "E2E Throughput (tokens\/s)":36.83,
        "Prefill Latency (s)":5974,
        "E2E Latency (s)":454545.0,
        "Allocated Memory (MB)":27.2,
        "Reserved Memory (MB)":36.8,
        "Used Memory (MB)":6037,
        "Energy (tokens\/kWh)":7509
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"34.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0478,
        "E2E Throughput (tokens\/s)":33.5,
        "Prefill Latency (s)":5973,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":29.9,
        "Reserved Memory (MB)":33.4,
        "Used Memory (MB)":6037,
        "Energy (tokens\/kWh)":7511
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0282,
        "E2E Throughput (tokens\/s)":65.48,
        "Prefill Latency (s)":14668,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":15.3,
        "Reserved Memory (MB)":65.4,
        "Used Memory (MB)":14692,
        "Energy (tokens\/kWh)":16164
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0307,
        "E2E Throughput (tokens\/s)":51.1,
        "Prefill Latency (s)":14668,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":19.6,
        "Reserved Memory (MB)":51.0,
        "Used Memory (MB)":14692,
        "Energy (tokens\/kWh)":16166
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.031,
        "E2E Throughput (tokens\/s)":53.0,
        "Prefill Latency (s)":14668,
        "E2E Latency (s)":495049.0,
        "Allocated Memory (MB)":18.9,
        "Reserved Memory (MB)":52.9,
        "Used Memory (MB)":14692,
        "Energy (tokens\/kWh)":16166
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0384,
        "E2E Throughput (tokens\/s)":55.37,
        "Prefill Latency (s)":5268,
        "E2E Latency (s)":653594.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":5561,
        "Energy (tokens\/kWh)":7037
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0393,
        "E2E Throughput (tokens\/s)":54.76,
        "Prefill Latency (s)":6347,
        "E2E Latency (s)":699300.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":6641,
        "Energy (tokens\/kWh)":8117
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0417,
        "E2E Throughput (tokens\/s)":44.33,
        "Prefill Latency (s)":5403,
        "E2E Latency (s)":515463.0,
        "Allocated Memory (MB)":22.6,
        "Reserved Memory (MB)":44.2,
        "Used Memory (MB)":5463,
        "Energy (tokens\/kWh)":6934
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Size":6.66,
        "Backend":"34.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0476,
        "E2E Throughput (tokens\/s)":37.8,
        "Prefill Latency (s)":5402,
        "E2E Latency (s)":471698.0,
        "Allocated Memory (MB)":26.5,
        "Reserved Memory (MB)":37.7,
        "Used Memory (MB)":5454,
        "Energy (tokens\/kWh)":6928
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0285,
        "E2E Throughput (tokens\/s)":54.43,
        "Prefill Latency (s)":15404,
        "E2E Latency (s)":507614.0,
        "Allocated Memory (MB)":18.4,
        "Reserved Memory (MB)":54.3,
        "Used Memory (MB)":15424,
        "Energy (tokens\/kWh)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.03,
        "E2E Throughput (tokens\/s)":52.44,
        "Prefill Latency (s)":15404,
        "E2E Latency (s)":495049.0,
        "Allocated Memory (MB)":19.1,
        "Reserved Memory (MB)":52.4,
        "Used Memory (MB)":15424,
        "Energy (tokens\/kWh)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0302,
        "E2E Throughput (tokens\/s)":52.17,
        "Prefill Latency (s)":15404,
        "E2E Latency (s)":502512.0,
        "Allocated Memory (MB)":19.2,
        "Reserved Memory (MB)":52.1,
        "Used Memory (MB)":15424,
        "Energy (tokens\/kWh)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0356,
        "E2E Throughput (tokens\/s)":54.16,
        "Prefill Latency (s)":6599,
        "E2E Latency (s)":632911.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":6704,
        "Energy (tokens\/kWh)":8180
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0364,
        "E2E Throughput (tokens\/s)":53.58,
        "Prefill Latency (s)":7677,
        "E2E Latency (s)":666666.0,
        "Allocated Memory (MB)":18.7,
        "Reserved Memory (MB)":53.5,
        "Used Memory (MB)":7782,
        "Energy (tokens\/kWh)":9258
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0403,
        "E2E Throughput (tokens\/s)":43.55,
        "Prefill Latency (s)":6730,
        "E2E Latency (s)":510204.0,
        "Allocated Memory (MB)":23.0,
        "Reserved Memory (MB)":43.5,
        "Used Memory (MB)":6836,
        "Energy (tokens\/kWh)":8310
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Size":7.07,
        "Backend":"34.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0413,
        "E2E Throughput (tokens\/s)":42.27,
        "Prefill Latency (s)":6731,
        "E2E Latency (s)":502512.0,
        "Allocated Memory (MB)":23.7,
        "Reserved Memory (MB)":42.2,
        "Used Memory (MB)":6836,
        "Energy (tokens\/kWh)":8310
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0459,
        "E2E Throughput (tokens\/s)":38.09,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":341296.0,
        "Allocated Memory (MB)":26.3,
        "Reserved Memory (MB)":38.0,
        "Used Memory (MB)":27856,
        "Energy (tokens\/kWh)":29328
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0479,
        "E2E Throughput (tokens\/s)":35.4,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":325732.0,
        "Allocated Memory (MB)":28.3,
        "Reserved Memory (MB)":35.3,
        "Used Memory (MB)":27812,
        "Energy (tokens\/kWh)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0492,
        "E2E Throughput (tokens\/s)":35.15,
        "Prefill Latency (s)":25714,
        "E2E Latency (s)":324675.0,
        "Allocated Memory (MB)":28.5,
        "Reserved Memory (MB)":35.1,
        "Used Memory (MB)":27812,
        "Energy (tokens\/kWh)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0606,
        "E2E Throughput (tokens\/s)":36.31,
        "Prefill Latency (s)":9201,
        "E2E Latency (s)":429184.0,
        "Allocated Memory (MB)":27.6,
        "Reserved Memory (MB)":36.2,
        "Used Memory (MB)":11286,
        "Energy (tokens\/kWh)":12762
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.063,
        "E2E Throughput (tokens\/s)":36.05,
        "Prefill Latency (s)":10548,
        "E2E Latency (s)":465116.0,
        "Allocated Memory (MB)":27.8,
        "Reserved Memory (MB)":36.0,
        "Used Memory (MB)":12637,
        "Energy (tokens\/kWh)":14113
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0716,
        "E2E Throughput (tokens\/s)":30.84,
        "Prefill Latency (s)":9441,
        "E2E Latency (s)":366300.0,
        "Allocated Memory (MB)":32.5,
        "Reserved Memory (MB)":30.8,
        "Used Memory (MB)":10557,
        "Energy (tokens\/kWh)":12028
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Size":11.59,
        "Backend":"33.91*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0735,
        "E2E Throughput (tokens\/s)":29.3,
        "Prefill Latency (s)":9441,
        "E2E Latency (s)":347222.0,
        "Allocated Memory (MB)":34.2,
        "Reserved Memory (MB)":29.2,
        "Used Memory (MB)":10529,
        "Energy (tokens\/kWh)":12003
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Size":7.49,
        "Backend":"33.84 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0331,
        "E2E Throughput (tokens\/s)":50.33,
        "Prefill Latency (s)":16352,
        "E2E Latency (s)":497512.0,
        "Allocated Memory (MB)":19.9,
        "Reserved Memory (MB)":50.3,
        "Used Memory (MB)":16399,
        "Energy (tokens\/kWh)":17873
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Size":7.49,
        "Backend":"33.84 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0333,
        "E2E Throughput (tokens\/s)":50.59,
        "Prefill Latency (s)":16352,
        "E2E Latency (s)":492610.0,
        "Allocated Memory (MB)":19.8,
        "Reserved Memory (MB)":50.5,
        "Used Memory (MB)":16399,
        "Energy (tokens\/kWh)":17873
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Size":7.49,
        "Backend":"33.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0402,
        "E2E Throughput (tokens\/s)":53.31,
        "Prefill Latency (s)":6952,
        "E2E Latency (s)":617283.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":7247,
        "Energy (tokens\/kWh)":8723
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Size":7.49,
        "Backend":"33.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0421,
        "E2E Throughput (tokens\/s)":51.13,
        "Prefill Latency (s)":8031,
        "E2E Latency (s)":625000.0,
        "Allocated Memory (MB)":19.6,
        "Reserved Memory (MB)":51.0,
        "Used Memory (MB)":8327,
        "Energy (tokens\/kWh)":9803
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Size":7.49,
        "Backend":"33.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0505,
        "E2E Throughput (tokens\/s)":37.11,
        "Prefill Latency (s)":7089,
        "E2E Latency (s)":442477.0,
        "Allocated Memory (MB)":27.0,
        "Reserved Memory (MB)":37.0,
        "Used Memory (MB)":7140,
        "Energy (tokens\/kWh)":8614
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0427,
        "E2E Throughput (tokens\/s)":40.23,
        "Prefill Latency (s)":23434,
        "E2E Latency (s)":361010.0,
        "Allocated Memory (MB)":24.9,
        "Reserved Memory (MB)":40.2,
        "Used Memory (MB)":24184,
        "Energy (tokens\/kWh)":25656
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0456,
        "E2E Throughput (tokens\/s)":35.77,
        "Prefill Latency (s)":23434,
        "E2E Latency (s)":340136.0,
        "Allocated Memory (MB)":28.0,
        "Reserved Memory (MB)":35.7,
        "Used Memory (MB)":24184,
        "Energy (tokens\/kWh)":25658
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0564,
        "E2E Throughput (tokens\/s)":37.53,
        "Prefill Latency (s)":8544,
        "E2E Latency (s)":446428.0,
        "Allocated Memory (MB)":26.7,
        "Reserved Memory (MB)":37.5,
        "Used Memory (MB)":9177,
        "Energy (tokens\/kWh)":10652
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0591,
        "E2E Throughput (tokens\/s)":36.18,
        "Prefill Latency (s)":9824,
        "E2E Latency (s)":450450.0,
        "Allocated Memory (MB)":27.7,
        "Reserved Memory (MB)":36.1,
        "Used Memory (MB)":10458,
        "Energy (tokens\/kWh)":11934
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0667,
        "E2E Throughput (tokens\/s)":30.27,
        "Prefill Latency (s)":8714,
        "E2E Latency (s)":363636.0,
        "Allocated Memory (MB)":33.1,
        "Reserved Memory (MB)":30.2,
        "Used Memory (MB)":9147,
        "Energy (tokens\/kWh)":10619
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Size":10.47,
        "Backend":"33.76*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0688,
        "E2E Throughput (tokens\/s)":29.73,
        "Prefill Latency (s)":8714,
        "E2E Latency (s)":354609.0,
        "Allocated Memory (MB)":33.7,
        "Reserved Memory (MB)":29.7,
        "Used Memory (MB)":9147,
        "Energy (tokens\/kWh)":10621
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0211,
        "E2E Throughput (tokens\/s)":44.89,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":591715.0,
        "Allocated Memory (MB)":22.3,
        "Reserved Memory (MB)":44.8,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0252,
        "E2E Throughput (tokens\/s)":40.36,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0253,
        "E2E Throughput (tokens\/s)":39.41,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":520833.0,
        "Allocated Memory (MB)":25.4,
        "Reserved Memory (MB)":39.4,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0262,
        "E2E Throughput (tokens\/s)":41.37,
        "Prefill Latency (s)":2874,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":24.2,
        "Reserved Memory (MB)":41.3,
        "Used Memory (MB)":3099,
        "Energy (tokens\/kWh)":4575
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0262,
        "E2E Throughput (tokens\/s)":41.03,
        "Prefill Latency (s)":3548,
        "E2E Latency (s)":571428.0,
        "Allocated Memory (MB)":24.4,
        "Reserved Memory (MB)":41.0,
        "Used Memory (MB)":3776,
        "Energy (tokens\/kWh)":5252
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0328,
        "E2E Throughput (tokens\/s)":36.41,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":27.5,
        "Reserved Memory (MB)":36.4,
        "Used Memory (MB)":3042,
        "Energy (tokens\/kWh)":4516
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"33.73*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0377,
        "E2E Throughput (tokens\/s)":33.38,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":467289.0,
        "Allocated Memory (MB)":30.0,
        "Reserved Memory (MB)":33.3,
        "Used Memory (MB)":3042,
        "Energy (tokens\/kWh)":4516
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0312,
        "E2E Throughput (tokens\/s)":30.7,
        "Prefill Latency (s)":9381,
        "E2E Latency (s)":403225.0,
        "Allocated Memory (MB)":32.6,
        "Reserved Memory (MB)":30.7,
        "Used Memory (MB)":9684,
        "Energy (tokens\/kWh)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0366,
        "E2E Throughput (tokens\/s)":27.2,
        "Prefill Latency (s)":9382,
        "E2E Latency (s)":358422.0,
        "Allocated Memory (MB)":36.8,
        "Reserved Memory (MB)":27.2,
        "Used Memory (MB)":9684,
        "Energy (tokens\/kWh)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0374,
        "E2E Throughput (tokens\/s)":28.77,
        "Prefill Latency (s)":3951,
        "E2E Latency (s)":406504.0,
        "Allocated Memory (MB)":34.8,
        "Reserved Memory (MB)":28.7,
        "Used Memory (MB)":4265,
        "Energy (tokens\/kWh)":5741
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0375,
        "E2E Throughput (tokens\/s)":27.43,
        "Prefill Latency (s)":9382,
        "E2E Latency (s)":362318.0,
        "Allocated Memory (MB)":36.5,
        "Reserved Memory (MB)":27.4,
        "Used Memory (MB)":9684,
        "Energy (tokens\/kWh)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0387,
        "E2E Throughput (tokens\/s)":27.73,
        "Prefill Latency (s)":4626,
        "E2E Latency (s)":386100.0,
        "Allocated Memory (MB)":36.1,
        "Reserved Memory (MB)":27.7,
        "Used Memory (MB)":4942,
        "Energy (tokens\/kWh)":6418
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0488,
        "E2E Throughput (tokens\/s)":24.97,
        "Prefill Latency (s)":4062,
        "E2E Latency (s)":343642.0,
        "Allocated Memory (MB)":40.1,
        "Reserved Memory (MB)":24.9,
        "Used Memory (MB)":4198,
        "Energy (tokens\/kWh)":5672
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Size":3.83,
        "Backend":"33.54*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0544,
        "E2E Throughput (tokens\/s)":23.12,
        "Prefill Latency (s)":4062,
        "E2E Latency (s)":320512.0,
        "Allocated Memory (MB)":43.3,
        "Reserved Memory (MB)":23.1,
        "Used Memory (MB)":4198,
        "Energy (tokens\/kWh)":5672
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"33.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0221,
        "E2E Throughput (tokens\/s)":45.71,
        "Prefill Latency (s)":7770,
        "E2E Latency (s)":578034.0,
        "Allocated Memory (MB)":21.9,
        "Reserved Memory (MB)":45.7,
        "Used Memory (MB)":8155,
        "Energy (tokens\/kWh)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"33.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0221,
        "E2E Throughput (tokens\/s)":44.49,
        "Prefill Latency (s)":7770,
        "E2E Latency (s)":555555.0,
        "Allocated Memory (MB)":22.5,
        "Reserved Memory (MB)":44.4,
        "Used Memory (MB)":8155,
        "Energy (tokens\/kWh)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"33.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0228,
        "E2E Throughput (tokens\/s)":47.0,
        "Prefill Latency (s)":7779,
        "E2E Latency (s)":595238.0,
        "Allocated Memory (MB)":21.3,
        "Reserved Memory (MB)":46.9,
        "Used Memory (MB)":8172,
        "Energy (tokens\/kWh)":9646
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"33.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0382,
        "E2E Throughput (tokens\/s)":35.01,
        "Prefill Latency (s)":3114,
        "E2E Latency (s)":476190.0,
        "Allocated Memory (MB)":28.6,
        "Reserved Memory (MB)":35.0,
        "Used Memory (MB)":3422,
        "Energy (tokens\/kWh)":4896
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Size":3.32,
        "Backend":"33.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0389,
        "E2E Throughput (tokens\/s)":35.76,
        "Prefill Latency (s)":3122,
        "E2E Latency (s)":492610.0,
        "Allocated Memory (MB)":28.0,
        "Reserved Memory (MB)":35.7,
        "Used Memory (MB)":3458,
        "Energy (tokens\/kWh)":4931
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0292,
        "E2E Throughput (tokens\/s)":46.79,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":478468.0,
        "Allocated Memory (MB)":21.4,
        "Reserved Memory (MB)":46.7,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16713
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0312,
        "E2E Throughput (tokens\/s)":40.54,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":434782.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0319,
        "E2E Throughput (tokens\/s)":40.05,
        "Prefill Latency (s)":15208,
        "E2E Latency (s)":418410.0,
        "Allocated Memory (MB)":25.0,
        "Reserved Memory (MB)":40.0,
        "Used Memory (MB)":15242,
        "Energy (tokens\/kWh)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0391,
        "E2E Throughput (tokens\/s)":42.62,
        "Prefill Latency (s)":5807,
        "E2E Latency (s)":540540.0,
        "Allocated Memory (MB)":23.5,
        "Reserved Memory (MB)":42.6,
        "Used Memory (MB)":5825,
        "Energy (tokens\/kWh)":7301
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0415,
        "E2E Throughput (tokens\/s)":40.72,
        "Prefill Latency (s)":6884,
        "E2E Latency (s)":526315.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":6905,
        "Energy (tokens\/kWh)":8381
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0454,
        "E2E Throughput (tokens\/s)":36.16,
        "Prefill Latency (s)":5974,
        "E2E Latency (s)":456621.0,
        "Allocated Memory (MB)":27.7,
        "Reserved Memory (MB)":36.1,
        "Used Memory (MB)":6037,
        "Energy (tokens\/kWh)":7509
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Size":6.65,
        "Backend":"33.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0479,
        "E2E Throughput (tokens\/s)":32.52,
        "Prefill Latency (s)":5973,
        "E2E Latency (s)":416666.0,
        "Allocated Memory (MB)":30.8,
        "Reserved Memory (MB)":32.5,
        "Used Memory (MB)":6037,
        "Energy (tokens\/kWh)":7511
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"rwkv",
        "Size":7.19,
        "Backend":"33.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0359,
        "E2E Throughput (tokens\/s)":29.71,
        "Prefill Latency (s)":14829,
        "E2E Latency (s)":352112.0,
        "Allocated Memory (MB)":33.7,
        "Reserved Memory (MB)":29.7,
        "Used Memory (MB)":14881,
        "Energy (tokens\/kWh)":16355
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"rwkv",
        "Size":7.19,
        "Backend":"33.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0581,
        "E2E Throughput (tokens\/s)":22.2,
        "Prefill Latency (s)":4799,
        "E2E Latency (s)":295857.0,
        "Allocated Memory (MB)":45.1,
        "Reserved Memory (MB)":22.2,
        "Used Memory (MB)":5012,
        "Energy (tokens\/kWh)":6485
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0809,
        "E2E Throughput (tokens\/s)":26.44,
        "Prefill Latency (s)":46447,
        "E2E Latency (s)":239234.0,
        "Allocated Memory (MB)":37.9,
        "Reserved Memory (MB)":26.4,
        "Used Memory (MB)":49234,
        "Energy (tokens\/kWh)":50708
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0826,
        "E2E Throughput (tokens\/s)":26.1,
        "Prefill Latency (s)":46448,
        "E2E Latency (s)":234741.0,
        "Allocated Memory (MB)":38.4,
        "Reserved Memory (MB)":26.0,
        "Used Memory (MB)":49234,
        "Energy (tokens\/kWh)":50708
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.105,
        "E2E Throughput (tokens\/s)":29.07,
        "Prefill Latency (s)":15106,
        "E2E Latency (s)":309597.0,
        "Allocated Memory (MB)":34.5,
        "Reserved Memory (MB)":29.0,
        "Used Memory (MB)":17788,
        "Energy (tokens\/kWh)":19263
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.11,
        "E2E Throughput (tokens\/s)":28.34,
        "Prefill Latency (s)":16290,
        "E2E Latency (s)":322580.0,
        "Allocated Memory (MB)":35.4,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":18970,
        "Energy (tokens\/kWh)":20446
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.122,
        "E2E Throughput (tokens\/s)":24.77,
        "Prefill Latency (s)":15625,
        "E2E Latency (s)":233100.0,
        "Allocated Memory (MB)":40.5,
        "Reserved Memory (MB)":24.7,
        "Used Memory (MB)":17802,
        "Energy (tokens\/kWh)":19276
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Size":21.83,
        "Backend":"32.80*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.125,
        "E2E Throughput (tokens\/s)":23.32,
        "Prefill Latency (s)":15625,
        "E2E Latency (s)":240384.0,
        "Allocated Memory (MB)":43.0,
        "Reserved Memory (MB)":23.3,
        "Used Memory (MB)":17714,
        "Energy (tokens\/kWh)":19188
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0395,
        "E2E Throughput (tokens\/s)":37.79,
        "Prefill Latency (s)":27939,
        "E2E Latency (s)":393700.0,
        "Allocated Memory (MB)":26.5,
        "Reserved Memory (MB)":37.7,
        "Used Memory (MB)":30282,
        "Energy (tokens\/kWh)":31754
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0442,
        "E2E Throughput (tokens\/s)":35.27,
        "Prefill Latency (s)":27939,
        "E2E Latency (s)":387596.0,
        "Allocated Memory (MB)":28.4,
        "Reserved Memory (MB)":35.2,
        "Used Memory (MB)":30282,
        "Energy (tokens\/kWh)":31756
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0501,
        "E2E Throughput (tokens\/s)":38.68,
        "Prefill Latency (s)":27939,
        "E2E Latency (s)":348432.0,
        "Allocated Memory (MB)":25.9,
        "Reserved Memory (MB)":38.6,
        "Used Memory (MB)":30282,
        "Energy (tokens\/kWh)":31754
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0501,
        "E2E Throughput (tokens\/s)":35.52,
        "Prefill Latency (s)":27939,
        "E2E Latency (s)":320512.0,
        "Allocated Memory (MB)":28.2,
        "Reserved Memory (MB)":35.5,
        "Used Memory (MB)":30282,
        "Energy (tokens\/kWh)":31756
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0661,
        "E2E Throughput (tokens\/s)":42.86,
        "Prefill Latency (s)":9568,
        "E2E Latency (s)":462962.0,
        "Allocated Memory (MB)":23.4,
        "Reserved Memory (MB)":42.7,
        "Used Memory (MB)":11867,
        "Energy (tokens\/kWh)":13343
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Size":12.85,
        "Backend":"32.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0668,
        "E2E Throughput (tokens\/s)":40.43,
        "Prefill Latency (s)":10916,
        "E2E Latency (s)":352112.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":13218,
        "Energy (tokens\/kWh)":14694
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"32.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0154,
        "E2E Throughput (tokens\/s)":66.29,
        "Prefill Latency (s)":3135,
        "E2E Latency (s)":869565.0,
        "Allocated Memory (MB)":15.1,
        "Reserved Memory (MB)":66.2,
        "Used Memory (MB)":3214,
        "Energy (tokens\/kWh)":4688
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0158,
        "E2E Throughput (tokens\/s)":67.64,
        "Prefill Latency (s)":1382,
        "E2E Latency (s)":943396.0,
        "Allocated Memory (MB)":14.8,
        "Reserved Memory (MB)":67.6,
        "Used Memory (MB)":1457,
        "Energy (tokens\/kWh)":2933
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"32.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0163,
        "E2E Throughput (tokens\/s)":65.43,
        "Prefill Latency (s)":3135,
        "E2E Latency (s)":869565.0,
        "Allocated Memory (MB)":15.3,
        "Reserved Memory (MB)":65.4,
        "Used Memory (MB)":3214,
        "Energy (tokens\/kWh)":4688
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0192,
        "E2E Throughput (tokens\/s)":60.68,
        "Prefill Latency (s)":1920,
        "E2E Latency (s)":869565.0,
        "Allocated Memory (MB)":16.5,
        "Reserved Memory (MB)":60.6,
        "Used Memory (MB)":1977,
        "Energy (tokens\/kWh)":3453
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0212,
        "E2E Throughput (tokens\/s)":44.49,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":22.5,
        "Reserved Memory (MB)":44.4,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0236,
        "E2E Throughput (tokens\/s)":52.98,
        "Prefill Latency (s)":1397,
        "E2E Latency (s)":740740.0,
        "Allocated Memory (MB)":18.9,
        "Reserved Memory (MB)":52.9,
        "Used Memory (MB)":1455,
        "Energy (tokens\/kWh)":2929
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0254,
        "E2E Throughput (tokens\/s)":40.36,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":531914.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.026,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":523560.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0262,
        "E2E Throughput (tokens\/s)":41.03,
        "Prefill Latency (s)":2858,
        "E2E Latency (s)":578034.0,
        "Allocated Memory (MB)":24.4,
        "Reserved Memory (MB)":41.0,
        "Used Memory (MB)":3080,
        "Energy (tokens\/kWh)":4556
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0274,
        "E2E Throughput (tokens\/s)":40.37,
        "Prefill Latency (s)":3532,
        "E2E Latency (s)":552486.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":3755,
        "Energy (tokens\/kWh)":5231
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0326,
        "E2E Throughput (tokens\/s)":36.81,
        "Prefill Latency (s)":2918,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":27.2,
        "Reserved Memory (MB)":36.8,
        "Used Memory (MB)":3032,
        "Energy (tokens\/kWh)":4506
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0372,
        "E2E Throughput (tokens\/s)":33.37,
        "Prefill Latency (s)":2918,
        "E2E Latency (s)":469483.0,
        "Allocated Memory (MB)":30.0,
        "Reserved Memory (MB)":33.3,
        "Used Memory (MB)":3032,
        "Energy (tokens\/kWh)":4506
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.022,
        "E2E Throughput (tokens\/s)":26.19,
        "Prefill Latency (s)":5990,
        "E2E Latency (s)":240384.0,
        "Allocated Memory (MB)":38.2,
        "Reserved Memory (MB)":26.2,
        "Used Memory (MB)":13482,
        "Energy (tokens\/kWh)":14956
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.026,
        "E2E Throughput (tokens\/s)":18.12,
        "Prefill Latency (s)":6117,
        "E2E Latency (s)":168918.0,
        "Allocated Memory (MB)":55.2,
        "Reserved Memory (MB)":18.1,
        "Used Memory (MB)":13482,
        "Energy (tokens\/kWh)":14956
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0261,
        "E2E Throughput (tokens\/s)":18.26,
        "Prefill Latency (s)":6117,
        "E2E Latency (s)":169491.0,
        "Allocated Memory (MB)":54.8,
        "Reserved Memory (MB)":18.2,
        "Used Memory (MB)":13482,
        "Energy (tokens\/kWh)":14956
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.027,
        "E2E Throughput (tokens\/s)":16.87,
        "Prefill Latency (s)":3110,
        "E2E Latency (s)":155038.0,
        "Allocated Memory (MB)":59.3,
        "Reserved Memory (MB)":16.9,
        "Used Memory (MB)":10468,
        "Energy (tokens\/kWh)":11944
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0271,
        "E2E Throughput (tokens\/s)":17.34,
        "Prefill Latency (s)":2437,
        "E2E Latency (s)":159744.0,
        "Allocated Memory (MB)":57.7,
        "Reserved Memory (MB)":17.3,
        "Used Memory (MB)":9793,
        "Energy (tokens\/kWh)":11269
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0338,
        "E2E Throughput (tokens\/s)":22.49,
        "Prefill Latency (s)":2370,
        "E2E Latency (s)":209643.0,
        "Allocated Memory (MB)":44.5,
        "Reserved Memory (MB)":22.5,
        "Used Memory (MB)":8862,
        "Energy (tokens\/kWh)":10336
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"32.37*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0381,
        "E2E Throughput (tokens\/s)":16.38,
        "Prefill Latency (s)":2497,
        "E2E Latency (s)":152439.0,
        "Allocated Memory (MB)":61.1,
        "Reserved Memory (MB)":16.4,
        "Used Memory (MB)":8862,
        "Energy (tokens\/kWh)":10336
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0156,
        "E2E Throughput (tokens\/s)":62.56,
        "Prefill Latency (s)":6135,
        "E2E Latency (s)":763358.0,
        "Allocated Memory (MB)":16.0,
        "Reserved Memory (MB)":62.5,
        "Used Memory (MB)":6438,
        "Energy (tokens\/kWh)":7909
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0196,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":6135,
        "E2E Latency (s)":675675.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":6438,
        "Energy (tokens\/kWh)":7912
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0198,
        "E2E Throughput (tokens\/s)":53.82,
        "Prefill Latency (s)":6135,
        "E2E Latency (s)":662251.0,
        "Allocated Memory (MB)":18.6,
        "Reserved Memory (MB)":53.8,
        "Used Memory (MB)":6438,
        "Energy (tokens\/kWh)":7912
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0225,
        "E2E Throughput (tokens\/s)":53.83,
        "Prefill Latency (s)":2464,
        "E2E Latency (s)":675675.0,
        "Allocated Memory (MB)":18.6,
        "Reserved Memory (MB)":53.8,
        "Used Memory (MB)":2684,
        "Energy (tokens\/kWh)":4160
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0255,
        "E2E Throughput (tokens\/s)":45.93,
        "Prefill Latency (s)":3138,
        "E2E Latency (s)":636942.0,
        "Allocated Memory (MB)":21.8,
        "Reserved Memory (MB)":45.9,
        "Used Memory (MB)":3359,
        "Energy (tokens\/kWh)":4835
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0325,
        "E2E Throughput (tokens\/s)":41.72,
        "Prefill Latency (s)":2517,
        "E2E Latency (s)":571428.0,
        "Allocated Memory (MB)":24.0,
        "Reserved Memory (MB)":41.7,
        "Used Memory (MB)":2629,
        "Energy (tokens\/kWh)":4103
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Size":2.65,
        "Backend":"32.17*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0378,
        "E2E Throughput (tokens\/s)":36.95,
        "Prefill Latency (s)":2518,
        "E2E Latency (s)":505050.0,
        "Allocated Memory (MB)":27.1,
        "Reserved Memory (MB)":36.9,
        "Used Memory (MB)":2634,
        "Energy (tokens\/kWh)":4107
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0209,
        "E2E Throughput (tokens\/s)":45.09,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":578034.0,
        "Allocated Memory (MB)":22.2,
        "Reserved Memory (MB)":45.0,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0252,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":526315.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0252,
        "E2E Throughput (tokens\/s)":40.36,
        "Prefill Latency (s)":6539,
        "E2E Latency (s)":537634.0,
        "Allocated Memory (MB)":24.8,
        "Reserved Memory (MB)":40.3,
        "Used Memory (MB)":6750,
        "Energy (tokens\/kWh)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0261,
        "E2E Throughput (tokens\/s)":40.69,
        "Prefill Latency (s)":2858,
        "E2E Latency (s)":555555.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":3080,
        "Energy (tokens\/kWh)":4556
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0272,
        "E2E Throughput (tokens\/s)":37.21,
        "Prefill Latency (s)":3532,
        "E2E Latency (s)":561797.0,
        "Allocated Memory (MB)":26.9,
        "Reserved Memory (MB)":37.2,
        "Used Memory (MB)":3755,
        "Energy (tokens\/kWh)":5231
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0329,
        "E2E Throughput (tokens\/s)":36.54,
        "Prefill Latency (s)":2918,
        "E2E Latency (s)":500000.0,
        "Allocated Memory (MB)":27.4,
        "Reserved Memory (MB)":36.5,
        "Used Memory (MB)":3032,
        "Energy (tokens\/kWh)":4506
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Size":2.91,
        "Backend":"32.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0379,
        "E2E Throughput (tokens\/s)":33.94,
        "Prefill Latency (s)":2918,
        "E2E Latency (s)":462962.0,
        "Allocated Memory (MB)":29.5,
        "Reserved Memory (MB)":33.9,
        "Used Memory (MB)":3032,
        "Energy (tokens\/kWh)":4506
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0231,
        "E2E Throughput (tokens\/s)":62.59,
        "Prefill Latency (s)":14803,
        "E2E Latency (s)":689655.0,
        "Allocated Memory (MB)":16.0,
        "Reserved Memory (MB)":62.5,
        "Used Memory (MB)":14858,
        "Energy (tokens\/kWh)":16329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0259,
        "E2E Throughput (tokens\/s)":53.55,
        "Prefill Latency (s)":14803,
        "E2E Latency (s)":606060.0,
        "Allocated Memory (MB)":18.7,
        "Reserved Memory (MB)":53.5,
        "Used Memory (MB)":14858,
        "Energy (tokens\/kWh)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0274,
        "E2E Throughput (tokens\/s)":62.61,
        "Prefill Latency (s)":14803,
        "E2E Latency (s)":568181.0,
        "Allocated Memory (MB)":16.0,
        "Reserved Memory (MB)":62.5,
        "Used Memory (MB)":14858,
        "Energy (tokens\/kWh)":16329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0284,
        "E2E Throughput (tokens\/s)":53.85,
        "Prefill Latency (s)":14803,
        "E2E Latency (s)":531914.0,
        "Allocated Memory (MB)":18.6,
        "Reserved Memory (MB)":53.8,
        "Used Memory (MB)":14858,
        "Energy (tokens\/kWh)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0288,
        "E2E Throughput (tokens\/s)":53.56,
        "Prefill Latency (s)":14803,
        "E2E Latency (s)":507614.0,
        "Allocated Memory (MB)":18.7,
        "Reserved Memory (MB)":53.5,
        "Used Memory (MB)":14858,
        "Energy (tokens\/kWh)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0378,
        "E2E Throughput (tokens\/s)":56.94,
        "Prefill Latency (s)":5401,
        "E2E Latency (s)":641025.0,
        "Allocated Memory (MB)":17.6,
        "Reserved Memory (MB)":56.8,
        "Used Memory (MB)":5419,
        "Energy (tokens\/kWh)":6894
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Size":6.66,
        "Backend":"31.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0392,
        "E2E Throughput (tokens\/s)":55.99,
        "Prefill Latency (s)":6478,
        "E2E Latency (s)":694444.0,
        "Allocated Memory (MB)":17.9,
        "Reserved Memory (MB)":55.9,
        "Used Memory (MB)":6499,
        "Energy (tokens\/kWh)":7974
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0217,
        "E2E Throughput (tokens\/s)":44.49,
        "Prefill Latency (s)":6269,
        "E2E Latency (s)":574712.0,
        "Allocated Memory (MB)":22.5,
        "Reserved Memory (MB)":44.4,
        "Used Memory (MB)":6631,
        "Energy (tokens\/kWh)":8104
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0225,
        "E2E Throughput (tokens\/s)":45.09,
        "Prefill Latency (s)":6281,
        "E2E Latency (s)":568181.0,
        "Allocated Memory (MB)":22.2,
        "Reserved Memory (MB)":45.0,
        "Used Memory (MB)":6727,
        "Energy (tokens\/kWh)":8201
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0227,
        "E2E Throughput (tokens\/s)":43.33,
        "Prefill Latency (s)":6281,
        "E2E Latency (s)":578034.0,
        "Allocated Memory (MB)":23.1,
        "Reserved Memory (MB)":43.3,
        "Used Memory (MB)":6727,
        "Energy (tokens\/kWh)":8201
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0258,
        "E2E Throughput (tokens\/s)":43.91,
        "Prefill Latency (s)":2624,
        "E2E Latency (s)":574712.0,
        "Allocated Memory (MB)":22.8,
        "Reserved Memory (MB)":43.9,
        "Used Memory (MB)":2908,
        "Energy (tokens\/kWh)":4384
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0269,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":3298,
        "E2E Latency (s)":581395.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":3571,
        "Energy (tokens\/kWh)":5047
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0354,
        "E2E Throughput (tokens\/s)":38.66,
        "Prefill Latency (s)":2674,
        "E2E Latency (s)":537634.0,
        "Allocated Memory (MB)":25.9,
        "Reserved Memory (MB)":38.6,
        "Used Memory (MB)":2797,
        "Energy (tokens\/kWh)":4271
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Size":2.72,
        "Backend":"31.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0396,
        "E2E Throughput (tokens\/s)":34.53,
        "Prefill Latency (s)":2686,
        "E2E Latency (s)":476190.0,
        "Allocated Memory (MB)":29.0,
        "Reserved Memory (MB)":34.5,
        "Used Memory (MB)":2900,
        "Energy (tokens\/kWh)":4374
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0213,
        "E2E Throughput (tokens\/s)":44.89,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":22.3,
        "Reserved Memory (MB)":44.8,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0251,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":540540.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0253,
        "E2E Throughput (tokens\/s)":40.69,
        "Prefill Latency (s)":6555,
        "E2E Latency (s)":523560.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":6769,
        "Energy (tokens\/kWh)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0264,
        "E2E Throughput (tokens\/s)":39.41,
        "Prefill Latency (s)":3548,
        "E2E Latency (s)":568181.0,
        "Allocated Memory (MB)":25.4,
        "Reserved Memory (MB)":39.4,
        "Used Memory (MB)":3776,
        "Energy (tokens\/kWh)":5252
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.027,
        "E2E Throughput (tokens\/s)":41.71,
        "Prefill Latency (s)":2874,
        "E2E Latency (s)":552486.0,
        "Allocated Memory (MB)":24.0,
        "Reserved Memory (MB)":41.7,
        "Used Memory (MB)":3099,
        "Energy (tokens\/kWh)":4575
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0337,
        "E2E Throughput (tokens\/s)":37.08,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":512820.0,
        "Allocated Memory (MB)":27.0,
        "Reserved Memory (MB)":37.0,
        "Used Memory (MB)":3042,
        "Energy (tokens\/kWh)":4516
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Size":2.65,
        "Backend":"31.56*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0371,
        "E2E Throughput (tokens\/s)":33.49,
        "Prefill Latency (s)":2933,
        "E2E Latency (s)":467289.0,
        "Allocated Memory (MB)":29.9,
        "Reserved Memory (MB)":33.4,
        "Used Memory (MB)":3042,
        "Energy (tokens\/kWh)":4516
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.017,
        "E2E Throughput (tokens\/s)":55.3,
        "Prefill Latency (s)":6802,
        "E2E Latency (s)":680272.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":6937,
        "Energy (tokens\/kWh)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0196,
        "E2E Throughput (tokens\/s)":52.96,
        "Prefill Latency (s)":6803,
        "E2E Latency (s)":662251.0,
        "Allocated Memory (MB)":18.9,
        "Reserved Memory (MB)":52.9,
        "Used Memory (MB)":6937,
        "Energy (tokens\/kWh)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0204,
        "E2E Throughput (tokens\/s)":54.71,
        "Prefill Latency (s)":4021,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":4250,
        "Energy (tokens\/kWh)":5726
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0204,
        "E2E Throughput (tokens\/s)":51.87,
        "Prefill Latency (s)":6803,
        "E2E Latency (s)":649350.0,
        "Allocated Memory (MB)":19.3,
        "Reserved Memory (MB)":51.8,
        "Used Memory (MB)":6937,
        "Energy (tokens\/kWh)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0209,
        "E2E Throughput (tokens\/s)":51.34,
        "Prefill Latency (s)":3348,
        "E2E Latency (s)":680272.0,
        "Allocated Memory (MB)":19.5,
        "Reserved Memory (MB)":51.3,
        "Used Memory (MB)":3554,
        "Energy (tokens\/kWh)":5030
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0284,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":3408,
        "E2E Latency (s)":598802.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":3491,
        "Energy (tokens\/kWh)":4965
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Size":3.0,
        "Backend":"31.50*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0311,
        "E2E Throughput (tokens\/s)":42.43,
        "Prefill Latency (s)":3407,
        "E2E Latency (s)":558659.0,
        "Allocated Memory (MB)":23.6,
        "Reserved Memory (MB)":42.4,
        "Used Memory (MB)":3495,
        "Energy (tokens\/kWh)":4969
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Size":5.08,
        "Backend":"31.05 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0316,
        "E2E Throughput (tokens\/s)":35.75,
        "Prefill Latency (s)":10128,
        "E2E Latency (s)":421940.0,
        "Allocated Memory (MB)":28.0,
        "Reserved Memory (MB)":35.7,
        "Used Memory (MB)":10695,
        "Energy (tokens\/kWh)":12169
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Size":5.08,
        "Backend":"31.05 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.032,
        "E2E Throughput (tokens\/s)":35.38,
        "Prefill Latency (s)":10128,
        "E2E Latency (s)":431034.0,
        "Allocated Memory (MB)":28.3,
        "Reserved Memory (MB)":35.3,
        "Used Memory (MB)":10695,
        "Energy (tokens\/kWh)":12169
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Size":5.08,
        "Backend":"31.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0373,
        "E2E Throughput (tokens\/s)":35.51,
        "Prefill Latency (s)":4238,
        "E2E Latency (s)":465116.0,
        "Allocated Memory (MB)":28.2,
        "Reserved Memory (MB)":35.5,
        "Used Memory (MB)":4397,
        "Energy (tokens\/kWh)":5873
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Size":5.08,
        "Backend":"31.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0376,
        "E2E Throughput (tokens\/s)":36.41,
        "Prefill Latency (s)":5317,
        "E2E Latency (s)":483091.0,
        "Allocated Memory (MB)":27.5,
        "Reserved Memory (MB)":36.4,
        "Used Memory (MB)":5479,
        "Energy (tokens\/kWh)":6955
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Size":5.08,
        "Backend":"31.05*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0646,
        "E2E Throughput (tokens\/s)":25.23,
        "Prefill Latency (s)":4338,
        "E2E Latency (s)":337837.0,
        "Allocated Memory (MB)":39.7,
        "Reserved Memory (MB)":25.2,
        "Used Memory (MB)":4471,
        "Energy (tokens\/kWh)":5944
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0276,
        "E2E Throughput (tokens\/s)":68.62,
        "Prefill Latency (s)":17012,
        "E2E Latency (s)":625000.0,
        "Allocated Memory (MB)":14.6,
        "Reserved Memory (MB)":68.5,
        "Used Memory (MB)":18324,
        "Energy (tokens\/kWh)":19796
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0277,
        "E2E Throughput (tokens\/s)":65.48,
        "Prefill Latency (s)":17012,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":15.3,
        "Reserved Memory (MB)":65.4,
        "Used Memory (MB)":18278,
        "Energy (tokens\/kWh)":19752
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0359,
        "E2E Throughput (tokens\/s)":63.04,
        "Prefill Latency (s)":6586,
        "E2E Latency (s)":540540.0,
        "Allocated Memory (MB)":15.9,
        "Reserved Memory (MB)":62.9,
        "Used Memory (MB)":7897,
        "Energy (tokens\/kWh)":9373
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0371,
        "E2E Throughput (tokens\/s)":80.24,
        "Prefill Latency (s)":8200,
        "E2E Latency (s)":900900.0,
        "Allocated Memory (MB)":12.5,
        "Reserved Memory (MB)":80.0,
        "Used Memory (MB)":9512,
        "Energy (tokens\/kWh)":10988
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0422,
        "E2E Throughput (tokens\/s)":70.63,
        "Prefill Latency (s)":6593,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":14.2,
        "Reserved Memory (MB)":70.4,
        "Used Memory (MB)":6989,
        "Energy (tokens\/kWh)":8461
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Size":7.56,
        "Backend":"31.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0438,
        "E2E Throughput (tokens\/s)":62.67,
        "Prefill Latency (s)":6593,
        "E2E Latency (s)":671140.0,
        "Allocated Memory (MB)":16.0,
        "Reserved Memory (MB)":62.5,
        "Used Memory (MB)":6949,
        "Energy (tokens\/kWh)":8423
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Size":2.86,
        "Backend":"31.00 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.034,
        "E2E Throughput (tokens\/s)":29.1,
        "Prefill Latency (s)":6007,
        "E2E Latency (s)":411522.0,
        "Allocated Memory (MB)":34.4,
        "Reserved Memory (MB)":29.1,
        "Used Memory (MB)":6272,
        "Energy (tokens\/kWh)":7746
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Size":2.86,
        "Backend":"31.00 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":2.07,
        "E2E Throughput (tokens\/s)":29.3,
        "Prefill Latency (s)":6007,
        "E2E Latency (s)":390625.0,
        "Allocated Memory (MB)":36.2,
        "Reserved Memory (MB)":27.6,
        "Used Memory (MB)":6272,
        "Energy (tokens\/kWh)":7746
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Size":2.86,
        "Backend":"31.00*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":2.23,
        "E2E Throughput (tokens\/s)":21.85,
        "Prefill Latency (s)":2082,
        "E2E Latency (s)":306748.0,
        "Allocated Memory (MB)":48.0,
        "Reserved Memory (MB)":20.8,
        "Used Memory (MB)":2170,
        "Energy (tokens\/kWh)":3644
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0183,
        "E2E Throughput (tokens\/s)":82.77,
        "Prefill Latency (s)":11212,
        "E2E Latency (s)":900900.0,
        "Allocated Memory (MB)":12.1,
        "Reserved Memory (MB)":82.6,
        "Used Memory (MB)":11257,
        "Energy (tokens\/kWh)":12729
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.02,
        "E2E Throughput (tokens\/s)":71.53,
        "Prefill Latency (s)":11211,
        "E2E Latency (s)":813008.0,
        "Allocated Memory (MB)":14.0,
        "Reserved Memory (MB)":71.4,
        "Used Memory (MB)":11236,
        "Energy (tokens\/kWh)":12710
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0204,
        "E2E Throughput (tokens\/s)":82.78,
        "Prefill Latency (s)":11212,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":12.1,
        "Reserved Memory (MB)":82.6,
        "Used Memory (MB)":11257,
        "Energy (tokens\/kWh)":12729
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0217,
        "E2E Throughput (tokens\/s)":71.54,
        "Prefill Latency (s)":11212,
        "E2E Latency (s)":709219.0,
        "Allocated Memory (MB)":14.0,
        "Reserved Memory (MB)":71.4,
        "Used Memory (MB)":11257,
        "Energy (tokens\/kWh)":12731
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0219,
        "E2E Throughput (tokens\/s)":72.06,
        "Prefill Latency (s)":11212,
        "E2E Latency (s)":675675.0,
        "Allocated Memory (MB)":13.9,
        "Reserved Memory (MB)":71.9,
        "Used Memory (MB)":11257,
        "Energy (tokens\/kWh)":12731
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0292,
        "E2E Throughput (tokens\/s)":70.07,
        "Prefill Latency (s)":4194,
        "E2E Latency (s)":813008.0,
        "Allocated Memory (MB)":14.3,
        "Reserved Memory (MB)":69.9,
        "Used Memory (MB)":4227,
        "Energy (tokens\/kWh)":5703
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Size":5.05,
        "Backend":"30.84*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0297,
        "E2E Throughput (tokens\/s)":74.24,
        "Prefill Latency (s)":5270,
        "E2E Latency (s)":917431.0,
        "Allocated Memory (MB)":13.5,
        "Reserved Memory (MB)":74.1,
        "Used Memory (MB)":5307,
        "Energy (tokens\/kWh)":6783
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0157,
        "E2E Throughput (tokens\/s)":61.79,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":854700.0,
        "Allocated Memory (MB)":16.2,
        "Reserved Memory (MB)":61.7,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4988
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0189,
        "E2E Throughput (tokens\/s)":52.96,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":18.9,
        "Reserved Memory (MB)":52.9,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.019,
        "E2E Throughput (tokens\/s)":53.25,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0195,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":2232,
        "E2E Latency (s)":775193.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":2298,
        "Energy (tokens\/kWh)":3774
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0203,
        "E2E Throughput (tokens\/s)":53.82,
        "Prefill Latency (s)":1694,
        "E2E Latency (s)":735294.0,
        "Allocated Memory (MB)":18.6,
        "Reserved Memory (MB)":53.8,
        "Used Memory (MB)":1757,
        "Energy (tokens\/kWh)":3233
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0247,
        "E2E Throughput (tokens\/s)":50.06,
        "Prefill Latency (s)":1710,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":20.0,
        "Reserved Memory (MB)":50.0,
        "Used Memory (MB)":1786,
        "Energy (tokens\/kWh)":3258
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.62*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0276,
        "E2E Throughput (tokens\/s)":44.3,
        "Prefill Latency (s)":1710,
        "E2E Latency (s)":641025.0,
        "Allocated Memory (MB)":22.6,
        "Reserved Memory (MB)":44.2,
        "Used Memory (MB)":1786,
        "Energy (tokens\/kWh)":3260
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.016,
        "E2E Throughput (tokens\/s)":61.04,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":840336.0,
        "Allocated Memory (MB)":16.4,
        "Reserved Memory (MB)":61.0,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4988
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":53.24,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":53.24,
        "Prefill Latency (s)":3450,
        "E2E Latency (s)":735294.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":3516,
        "Energy (tokens\/kWh)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0194,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":2232,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":2298,
        "Energy (tokens\/kWh)":3774
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.02,
        "E2E Throughput (tokens\/s)":54.7,
        "Prefill Latency (s)":1694,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":1757,
        "Energy (tokens\/kWh)":3233
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0247,
        "E2E Throughput (tokens\/s)":49.32,
        "Prefill Latency (s)":1710,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":20.3,
        "Reserved Memory (MB)":49.3,
        "Used Memory (MB)":1786,
        "Energy (tokens\/kWh)":3258
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Size":1.31,
        "Backend":"30.11*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0273,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":1710,
        "E2E Latency (s)":649350.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":1786,
        "Energy (tokens\/kWh)":3260
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0302,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":16864,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":16886,
        "Energy (tokens\/kWh)":18357
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0323,
        "E2E Throughput (tokens\/s)":39.58,
        "Prefill Latency (s)":16864,
        "E2E Latency (s)":438596.0,
        "Allocated Memory (MB)":25.3,
        "Reserved Memory (MB)":39.5,
        "Used Memory (MB)":16886,
        "Energy (tokens\/kWh)":18359
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0329,
        "E2E Throughput (tokens\/s)":39.89,
        "Prefill Latency (s)":16864,
        "E2E Latency (s)":414937.0,
        "Allocated Memory (MB)":25.1,
        "Reserved Memory (MB)":39.8,
        "Used Memory (MB)":16886,
        "Energy (tokens\/kWh)":18360
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0418,
        "E2E Throughput (tokens\/s)":40.72,
        "Prefill Latency (s)":8541,
        "E2E Latency (s)":515463.0,
        "Allocated Memory (MB)":24.6,
        "Reserved Memory (MB)":40.7,
        "Used Memory (MB)":8589,
        "Energy (tokens\/kWh)":10065
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0438,
        "E2E Throughput (tokens\/s)":34.9,
        "Prefill Latency (s)":7464,
        "E2E Latency (s)":384615.0,
        "Allocated Memory (MB)":28.7,
        "Reserved Memory (MB)":34.8,
        "Used Memory (MB)":7509,
        "Energy (tokens\/kWh)":8985
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0467,
        "E2E Throughput (tokens\/s)":36.56,
        "Prefill Latency (s)":7630,
        "E2E Latency (s)":452488.0,
        "Allocated Memory (MB)":27.4,
        "Reserved Memory (MB)":36.5,
        "Used Memory (MB)":7673,
        "Energy (tokens\/kWh)":9145
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Size":7.06,
        "Backend":"30.07*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.05,
        "E2E Throughput (tokens\/s)":32.84,
        "Prefill Latency (s)":7631,
        "E2E Latency (s)":404858.0,
        "Allocated Memory (MB)":30.5,
        "Reserved Memory (MB)":32.8,
        "Used Memory (MB)":7715,
        "Energy (tokens\/kWh)":9189
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0181,
        "E2E Throughput (tokens\/s)":53.24,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":775193.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0198,
        "E2E Throughput (tokens\/s)":51.33,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":19.5,
        "Reserved Memory (MB)":51.3,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0201,
        "E2E Throughput (tokens\/s)":50.56,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":19.8,
        "Reserved Memory (MB)":50.5,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0229,
        "E2E Throughput (tokens\/s)":46.56,
        "Prefill Latency (s)":1258,
        "E2E Latency (s)":675675.0,
        "Allocated Memory (MB)":21.5,
        "Reserved Memory (MB)":46.5,
        "Used Memory (MB)":1348,
        "Energy (tokens\/kWh)":2824
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0282,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":887,
        "E2E Latency (s)":613496.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":977,
        "Energy (tokens\/kWh)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0317,
        "E2E Throughput (tokens\/s)":40.87,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":621118.0,
        "Allocated Memory (MB)":24.5,
        "Reserved Memory (MB)":40.8,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Size":1.03,
        "Backend":"30.06*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0341,
        "E2E Throughput (tokens\/s)":39.58,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":584795.0,
        "Allocated Memory (MB)":25.3,
        "Reserved Memory (MB)":39.5,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0507,
        "E2E Throughput (tokens\/s)":34.07,
        "Prefill Latency (s)":28041,
        "E2E Latency (s)":305810.0,
        "Allocated Memory (MB)":29.4,
        "Reserved Memory (MB)":34.0,
        "Used Memory (MB)":30410,
        "Energy (tokens\/kWh)":31882
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0526,
        "E2E Throughput (tokens\/s)":31.7,
        "Prefill Latency (s)":28041,
        "E2E Latency (s)":304878.0,
        "Allocated Memory (MB)":31.6,
        "Reserved Memory (MB)":31.6,
        "Used Memory (MB)":30410,
        "Energy (tokens\/kWh)":31884
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0688,
        "E2E Throughput (tokens\/s)":32.43,
        "Prefill Latency (s)":11018,
        "E2E Latency (s)":393700.0,
        "Allocated Memory (MB)":30.9,
        "Reserved Memory (MB)":32.4,
        "Used Memory (MB)":13373,
        "Energy (tokens\/kWh)":14849
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0689,
        "E2E Throughput (tokens\/s)":32.54,
        "Prefill Latency (s)":9670,
        "E2E Latency (s)":366300.0,
        "Allocated Memory (MB)":30.8,
        "Reserved Memory (MB)":32.5,
        "Used Memory (MB)":12002,
        "Energy (tokens\/kWh)":13477
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.079,
        "E2E Throughput (tokens\/s)":29.83,
        "Prefill Latency (s)":9966,
        "E2E Latency (s)":335570.0,
        "Allocated Memory (MB)":33.6,
        "Reserved Memory (MB)":29.8,
        "Used Memory (MB)":11234,
        "Energy (tokens\/kWh)":12706
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Size":13.06,
        "Backend":"29.86*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0825,
        "E2E Throughput (tokens\/s)":27.09,
        "Prefill Latency (s)":9966,
        "E2E Latency (s)":307692.0,
        "Allocated Memory (MB)":37.0,
        "Reserved Memory (MB)":27.0,
        "Used Memory (MB)":11261,
        "Energy (tokens\/kWh)":12735
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0183,
        "E2E Throughput (tokens\/s)":54.4,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":18.4,
        "Reserved Memory (MB)":54.3,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.02,
        "E2E Throughput (tokens\/s)":51.6,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":19.4,
        "Reserved Memory (MB)":51.5,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0215,
        "E2E Throughput (tokens\/s)":48.59,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":20.6,
        "Reserved Memory (MB)":48.5,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0228,
        "E2E Throughput (tokens\/s)":46.78,
        "Prefill Latency (s)":1258,
        "E2E Latency (s)":675675.0,
        "Allocated Memory (MB)":21.4,
        "Reserved Memory (MB)":46.7,
        "Used Memory (MB)":1348,
        "Energy (tokens\/kWh)":2824
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0245,
        "E2E Throughput (tokens\/s)":47.22,
        "Prefill Latency (s)":887,
        "E2E Latency (s)":645161.0,
        "Allocated Memory (MB)":21.2,
        "Reserved Memory (MB)":47.2,
        "Used Memory (MB)":977,
        "Energy (tokens\/kWh)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0313,
        "E2E Throughput (tokens\/s)":41.38,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":621118.0,
        "Allocated Memory (MB)":24.2,
        "Reserved Memory (MB)":41.3,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"29.52*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0336,
        "E2E Throughput (tokens\/s)":39.27,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":588235.0,
        "Allocated Memory (MB)":25.5,
        "Reserved Memory (MB)":39.2,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0162,
        "E2E Throughput (tokens\/s)":58.88,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":819672.0,
        "Allocated Memory (MB)":17.0,
        "Reserved Memory (MB)":58.8,
        "Used Memory (MB)":3437,
        "Energy (tokens\/kWh)":4911
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0165,
        "E2E Throughput (tokens\/s)":61.04,
        "Prefill Latency (s)":3254,
        "E2E Latency (s)":826446.0,
        "Allocated Memory (MB)":16.4,
        "Reserved Memory (MB)":61.0,
        "Used Memory (MB)":3437,
        "Energy (tokens\/kWh)":4910
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0168,
        "E2E Throughput (tokens\/s)":59.94,
        "Prefill Latency (s)":3254,
        "E2E Latency (s)":806451.0,
        "Allocated Memory (MB)":16.7,
        "Reserved Memory (MB)":59.9,
        "Used Memory (MB)":3437,
        "Energy (tokens\/kWh)":4911
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":56.56,
        "Prefill Latency (s)":2040,
        "E2E Latency (s)":806451.0,
        "Allocated Memory (MB)":17.7,
        "Reserved Memory (MB)":56.5,
        "Used Memory (MB)":2132,
        "Energy (tokens\/kWh)":3608
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0191,
        "E2E Throughput (tokens\/s)":56.24,
        "Prefill Latency (s)":1501,
        "E2E Latency (s)":799999.0,
        "Allocated Memory (MB)":17.8,
        "Reserved Memory (MB)":56.2,
        "Used Memory (MB)":1591,
        "Energy (tokens\/kWh)":3067
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0294,
        "E2E Throughput (tokens\/s)":47.01,
        "Prefill Latency (s)":1507,
        "E2E Latency (s)":666666.0,
        "Allocated Memory (MB)":21.3,
        "Reserved Memory (MB)":46.9,
        "Used Memory (MB)":1606,
        "Energy (tokens\/kWh)":3080
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Size":1.37,
        "Backend":"29.44*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0316,
        "E2E Throughput (tokens\/s)":45.31,
        "Prefill Latency (s)":1517,
        "E2E Latency (s)":636942.0,
        "Allocated Memory (MB)":22.1,
        "Reserved Memory (MB)":45.2,
        "Used Memory (MB)":1606,
        "Energy (tokens\/kWh)":3080
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Size":1.41,
        "Backend":"29.24 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0248,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":3066,
        "E2E Latency (s)":591715.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":3344,
        "Energy (tokens\/kWh)":4818
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Size":1.41,
        "Backend":"29.24*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":1.6,
        "E2E Throughput (tokens\/s)":29.5,
        "Prefill Latency (s)":1181,
        "E2E Latency (s)":418410.0,
        "Allocated Memory (MB)":35.5,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":1207,
        "Energy (tokens\/kWh)":2681
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Size":1.41,
        "Backend":"29.24 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":1.65,
        "E2E Throughput (tokens\/s)":40.24,
        "Prefill Latency (s)":3066,
        "E2E Latency (s)":534759.0,
        "Allocated Memory (MB)":26.5,
        "Reserved Memory (MB)":37.7,
        "Used Memory (MB)":3344,
        "Energy (tokens\/kWh)":4818
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0153,
        "E2E Throughput (tokens\/s)":62.95,
        "Prefill Latency (s)":6286,
        "E2E Latency (s)":833333.0,
        "Allocated Memory (MB)":15.9,
        "Reserved Memory (MB)":62.9,
        "Used Memory (MB)":6496,
        "Energy (tokens\/kWh)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0158,
        "E2E Throughput (tokens\/s)":62.96,
        "Prefill Latency (s)":6286,
        "E2E Latency (s)":787401.0,
        "Allocated Memory (MB)":15.9,
        "Reserved Memory (MB)":62.9,
        "Used Memory (MB)":6496,
        "Energy (tokens\/kWh)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":55.61,
        "Prefill Latency (s)":6286,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":18.0,
        "Reserved Memory (MB)":55.6,
        "Used Memory (MB)":6496,
        "Energy (tokens\/kWh)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":55.31,
        "Prefill Latency (s)":6286,
        "E2E Latency (s)":709219.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":6496,
        "Energy (tokens\/kWh)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0193,
        "E2E Throughput (tokens\/s)":54.7,
        "Prefill Latency (s)":6286,
        "E2E Latency (s)":684931.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":6496,
        "Energy (tokens\/kWh)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0229,
        "E2E Throughput (tokens\/s)":56.25,
        "Prefill Latency (s)":3279,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":17.8,
        "Reserved Memory (MB)":56.2,
        "Used Memory (MB)":3481,
        "Energy (tokens\/kWh)":4957
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Size":2.65,
        "Backend":"29.16*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0236,
        "E2E Throughput (tokens\/s)":55.63,
        "Prefill Latency (s)":2605,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":18.0,
        "Reserved Memory (MB)":55.6,
        "Used Memory (MB)":2805,
        "Energy (tokens\/kWh)":4281
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0512,
        "E2E Throughput (tokens\/s)":37.95,
        "Prefill Latency (s)":28578,
        "E2E Latency (s)":338983.0,
        "Allocated Memory (MB)":26.4,
        "Reserved Memory (MB)":37.9,
        "Used Memory (MB)":30945,
        "Energy (tokens\/kWh)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0522,
        "E2E Throughput (tokens\/s)":38.99,
        "Prefill Latency (s)":28579,
        "E2E Latency (s)":349650.0,
        "Allocated Memory (MB)":25.7,
        "Reserved Memory (MB)":38.9,
        "Used Memory (MB)":30945,
        "Energy (tokens\/kWh)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0529,
        "E2E Throughput (tokens\/s)":38.25,
        "Prefill Latency (s)":28579,
        "E2E Latency (s)":337837.0,
        "Allocated Memory (MB)":26.2,
        "Reserved Memory (MB)":38.2,
        "Used Memory (MB)":30945,
        "Energy (tokens\/kWh)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.066,
        "E2E Throughput (tokens\/s)":40.93,
        "Prefill Latency (s)":10194,
        "E2E Latency (s)":421940.0,
        "Allocated Memory (MB)":24.5,
        "Reserved Memory (MB)":40.8,
        "Used Memory (MB)":12561,
        "Energy (tokens\/kWh)":14037
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0671,
        "E2E Throughput (tokens\/s)":40.6,
        "Prefill Latency (s)":11542,
        "E2E Latency (s)":473933.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":13912,
        "Energy (tokens\/kWh)":15388
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0761,
        "E2E Throughput (tokens\/s)":33.31,
        "Prefill Latency (s)":10490,
        "E2E Latency (s)":359712.0,
        "Allocated Memory (MB)":30.1,
        "Reserved Memory (MB)":33.2,
        "Used Memory (MB)":11769,
        "Energy (tokens\/kWh)":13242
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Size":13.26,
        "Backend":"29.08*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.079,
        "E2E Throughput (tokens\/s)":32.13,
        "Prefill Latency (s)":10491,
        "E2E Latency (s)":349650.0,
        "Allocated Memory (MB)":31.2,
        "Reserved Memory (MB)":32.1,
        "Used Memory (MB)":11769,
        "Energy (tokens\/kWh)":13242
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0108,
        "E2E Throughput (tokens\/s)":90.18,
        "Prefill Latency (s)":2443,
        "E2E Latency (s)":1226993.0,
        "Allocated Memory (MB)":11.1,
        "Reserved Memory (MB)":90.1,
        "Used Memory (MB)":2497,
        "Energy (tokens\/kWh)":3969
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0126,
        "E2E Throughput (tokens\/s)":79.44,
        "Prefill Latency (s)":2443,
        "E2E Latency (s)":1119820.0,
        "Allocated Memory (MB)":12.6,
        "Reserved Memory (MB)":79.4,
        "Used Memory (MB)":2499,
        "Energy (tokens\/kWh)":3973
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0127,
        "E2E Throughput (tokens\/s)":78.82,
        "Prefill Latency (s)":2443,
        "E2E Latency (s)":1101321.0,
        "Allocated Memory (MB)":12.7,
        "Reserved Memory (MB)":78.7,
        "Used Memory (MB)":2499,
        "Energy (tokens\/kWh)":3973
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0132,
        "E2E Throughput (tokens\/s)":80.73,
        "Prefill Latency (s)":1824,
        "E2E Latency (s)":1104972.0,
        "Allocated Memory (MB)":12.4,
        "Reserved Memory (MB)":80.6,
        "Used Memory (MB)":1885,
        "Energy (tokens\/kWh)":3361
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0134,
        "E2E Throughput (tokens\/s)":78.21,
        "Prefill Latency (s)":1286,
        "E2E Latency (s)":1077586.0,
        "Allocated Memory (MB)":12.8,
        "Reserved Memory (MB)":78.1,
        "Used Memory (MB)":1344,
        "Energy (tokens\/kWh)":2820
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0165,
        "E2E Throughput (tokens\/s)":74.16,
        "Prefill Latency (s)":1284,
        "E2E Latency (s)":1070663.0,
        "Allocated Memory (MB)":13.5,
        "Reserved Memory (MB)":74.1,
        "Used Memory (MB)":1342,
        "Energy (tokens\/kWh)":2813
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Size":1.08,
        "Backend":"28.77*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0188,
        "E2E Throughput (tokens\/s)":64.18,
        "Prefill Latency (s)":1284,
        "E2E Latency (s)":943396.0,
        "Allocated Memory (MB)":15.6,
        "Reserved Memory (MB)":64.1,
        "Used Memory (MB)":1344,
        "Energy (tokens\/kWh)":2818
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0341,
        "E2E Throughput (tokens\/s)":28.93,
        "Prefill Latency (s)":15707,
        "E2E Latency (s)":331125.0,
        "Allocated Memory (MB)":34.6,
        "Reserved Memory (MB)":28.9,
        "Used Memory (MB)":15762,
        "Energy (tokens\/kWh)":17235
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0383,
        "E2E Throughput (tokens\/s)":26.91,
        "Prefill Latency (s)":15697,
        "E2E Latency (s)":330033.0,
        "Allocated Memory (MB)":37.2,
        "Reserved Memory (MB)":26.9,
        "Used Memory (MB)":15741,
        "Energy (tokens\/kWh)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.039,
        "E2E Throughput (tokens\/s)":26.84,
        "Prefill Latency (s)":15697,
        "E2E Latency (s)":316455.0,
        "Allocated Memory (MB)":37.3,
        "Reserved Memory (MB)":26.8,
        "Used Memory (MB)":15741,
        "Energy (tokens\/kWh)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0468,
        "E2E Throughput (tokens\/s)":26.42,
        "Prefill Latency (s)":7077,
        "E2E Latency (s)":353356.0,
        "Allocated Memory (MB)":37.9,
        "Reserved Memory (MB)":26.4,
        "Used Memory (MB)":7119,
        "Energy (tokens\/kWh)":8595
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0481,
        "E2E Throughput (tokens\/s)":26.7,
        "Prefill Latency (s)":6000,
        "E2E Latency (s)":343642.0,
        "Allocated Memory (MB)":37.5,
        "Reserved Memory (MB)":26.7,
        "Used Memory (MB)":6039,
        "Energy (tokens\/kWh)":7515
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0502,
        "E2E Throughput (tokens\/s)":25.09,
        "Prefill Latency (s)":6188,
        "E2E Latency (s)":343642.0,
        "Allocated Memory (MB)":39.9,
        "Reserved Memory (MB)":25.1,
        "Used Memory (MB)":6285,
        "Energy (tokens\/kWh)":7758
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Size":6.85,
        "Backend":"28.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0542,
        "E2E Throughput (tokens\/s)":23.62,
        "Prefill Latency (s)":6176,
        "E2E Latency (s)":319488.0,
        "Allocated Memory (MB)":42.4,
        "Reserved Memory (MB)":23.6,
        "Used Memory (MB)":6243,
        "Energy (tokens\/kWh)":7716
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0294,
        "E2E Throughput (tokens\/s)":37.35,
        "Prefill Latency (s)":12576,
        "E2E Latency (s)":444444.0,
        "Allocated Memory (MB)":26.8,
        "Reserved Memory (MB)":37.3,
        "Used Memory (MB)":12792,
        "Energy (tokens\/kWh)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0306,
        "E2E Throughput (tokens\/s)":34.52,
        "Prefill Latency (s)":12576,
        "E2E Latency (s)":416666.0,
        "Allocated Memory (MB)":29.0,
        "Reserved Memory (MB)":34.5,
        "Used Memory (MB)":12792,
        "Energy (tokens\/kWh)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0333,
        "E2E Throughput (tokens\/s)":33.94,
        "Prefill Latency (s)":12576,
        "E2E Latency (s)":395256.0,
        "Allocated Memory (MB)":29.5,
        "Reserved Memory (MB)":33.9,
        "Used Memory (MB)":12792,
        "Energy (tokens\/kWh)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0385,
        "E2E Throughput (tokens\/s)":32.72,
        "Prefill Latency (s)":4331,
        "E2E Latency (s)":413223.0,
        "Allocated Memory (MB)":30.6,
        "Reserved Memory (MB)":32.7,
        "Used Memory (MB)":4494,
        "Energy (tokens\/kWh)":5970
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.04,
        "E2E Throughput (tokens\/s)":32.4,
        "Prefill Latency (s)":5057,
        "E2E Latency (s)":432900.0,
        "Allocated Memory (MB)":30.9,
        "Reserved Memory (MB)":32.4,
        "Used Memory (MB)":5221,
        "Energy (tokens\/kWh)":6697
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.046,
        "E2E Throughput (tokens\/s)":29.02,
        "Prefill Latency (s)":4453,
        "E2E Latency (s)":371747.0,
        "Allocated Memory (MB)":34.5,
        "Reserved Memory (MB)":29.0,
        "Used Memory (MB)":4643,
        "Energy (tokens\/kWh)":6116
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Size":5.87,
        "Backend":"28.23*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0494,
        "E2E Throughput (tokens\/s)":27.21,
        "Prefill Latency (s)":4453,
        "E2E Latency (s)":346020.0,
        "Allocated Memory (MB)":36.8,
        "Reserved Memory (MB)":27.2,
        "Used Memory (MB)":4643,
        "Energy (tokens\/kWh)":6116
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0149,
        "E2E Throughput (tokens\/s)":88.61,
        "Prefill Latency (s)":8232,
        "E2E Latency (s)":934579.0,
        "Allocated Memory (MB)":11.3,
        "Reserved Memory (MB)":88.5,
        "Used Memory (MB)":8252,
        "Energy (tokens\/kWh)":9723
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0159,
        "E2E Throughput (tokens\/s)":79.47,
        "Prefill Latency (s)":8232,
        "E2E Latency (s)":877192.0,
        "Allocated Memory (MB)":12.6,
        "Reserved Memory (MB)":79.4,
        "Used Memory (MB)":8273,
        "Energy (tokens\/kWh)":9746
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0162,
        "E2E Throughput (tokens\/s)":76.43,
        "Prefill Latency (s)":8232,
        "E2E Latency (s)":826446.0,
        "Allocated Memory (MB)":13.1,
        "Reserved Memory (MB)":76.3,
        "Used Memory (MB)":8273,
        "Energy (tokens\/kWh)":9747
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0179,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0198,
        "E2E Throughput (tokens\/s)":51.33,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":19.5,
        "Reserved Memory (MB)":51.3,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0199,
        "E2E Throughput (tokens\/s)":51.87,
        "Prefill Latency (s)":2289,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":19.3,
        "Reserved Memory (MB)":51.8,
        "Used Memory (MB)":2443,
        "Energy (tokens\/kWh)":3916
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0206,
        "E2E Throughput (tokens\/s)":81.44,
        "Prefill Latency (s)":3598,
        "E2E Latency (s)":961538.0,
        "Allocated Memory (MB)":12.3,
        "Reserved Memory (MB)":81.3,
        "Used Memory (MB)":3674,
        "Energy (tokens\/kWh)":5150
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0206,
        "E2E Throughput (tokens\/s)":77.64,
        "Prefill Latency (s)":4674,
        "E2E Latency (s)":990099.0,
        "Allocated Memory (MB)":12.9,
        "Reserved Memory (MB)":77.5,
        "Used Memory (MB)":4752,
        "Energy (tokens\/kWh)":6228
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0228,
        "E2E Throughput (tokens\/s)":73.65,
        "Prefill Latency (s)":3607,
        "E2E Latency (s)":900900.0,
        "Allocated Memory (MB)":13.6,
        "Reserved Memory (MB)":73.5,
        "Used Memory (MB)":3682,
        "Energy (tokens\/kWh)":5154
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0231,
        "E2E Throughput (tokens\/s)":47.45,
        "Prefill Latency (s)":887,
        "E2E Latency (s)":641025.0,
        "Allocated Memory (MB)":21.1,
        "Reserved Memory (MB)":47.4,
        "Used Memory (MB)":977,
        "Energy (tokens\/kWh)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0231,
        "E2E Throughput (tokens\/s)":46.56,
        "Prefill Latency (s)":1258,
        "E2E Latency (s)":657894.0,
        "Allocated Memory (MB)":21.5,
        "Reserved Memory (MB)":46.5,
        "Used Memory (MB)":1348,
        "Energy (tokens\/kWh)":2824
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Size":3.43,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0245,
        "E2E Throughput (tokens\/s)":65.04,
        "Prefill Latency (s)":3607,
        "E2E Latency (s)":813008.0,
        "Allocated Memory (MB)":15.4,
        "Reserved Memory (MB)":64.9,
        "Used Memory (MB)":3682,
        "Energy (tokens\/kWh)":5156
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.031,
        "E2E Throughput (tokens\/s)":41.72,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":625000.0,
        "Allocated Memory (MB)":24.0,
        "Reserved Memory (MB)":41.7,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Size":1.1,
        "Backend":"27.87*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0333,
        "E2E Throughput (tokens\/s)":39.42,
        "Prefill Latency (s)":898,
        "E2E Latency (s)":588235.0,
        "Allocated Memory (MB)":25.4,
        "Reserved Memory (MB)":39.4,
        "Used Memory (MB)":1010,
        "Energy (tokens\/kWh)":2484
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0159,
        "E2E Throughput (tokens\/s)":59.58,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":934579.0,
        "Allocated Memory (MB)":16.8,
        "Reserved Memory (MB)":59.5,
        "Used Memory (MB)":1310,
        "Energy (tokens\/kWh)":2784
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0185,
        "E2E Throughput (tokens\/s)":54.7,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":847457.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":1312,
        "Energy (tokens\/kWh)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0187,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":826446.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":1312,
        "Energy (tokens\/kWh)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0196,
        "E2E Throughput (tokens\/s)":55.31,
        "Prefill Latency (s)":1017,
        "E2E Latency (s)":793650.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":1147,
        "Energy (tokens\/kWh)":2623
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0196,
        "E2E Throughput (tokens\/s)":55.0,
        "Prefill Latency (s)":748,
        "E2E Latency (s)":781250.0,
        "Allocated Memory (MB)":18.2,
        "Reserved Memory (MB)":54.9,
        "Used Memory (MB)":889,
        "Energy (tokens\/kWh)":2365
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0244,
        "E2E Throughput (tokens\/s)":48.6,
        "Prefill Latency (s)":754,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":20.6,
        "Reserved Memory (MB)":48.5,
        "Used Memory (MB)":901,
        "Energy (tokens\/kWh)":2375
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.68*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0284,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":754,
        "E2E Latency (s)":684931.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":901,
        "Energy (tokens\/kWh)":2375
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0248,
        "E2E Throughput (tokens\/s)":40.53,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":505050.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10944
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0278,
        "E2E Throughput (tokens\/s)":36.53,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":485436.0,
        "Allocated Memory (MB)":27.4,
        "Reserved Memory (MB)":36.5,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0287,
        "E2E Throughput (tokens\/s)":35.25,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":450450.0,
        "Allocated Memory (MB)":28.4,
        "Reserved Memory (MB)":35.2,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.03,
        "E2E Throughput (tokens\/s)":35.88,
        "Prefill Latency (s)":3901,
        "E2E Latency (s)":478468.0,
        "Allocated Memory (MB)":27.9,
        "Reserved Memory (MB)":35.8,
        "Used Memory (MB)":4399,
        "Energy (tokens\/kWh)":5875
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0303,
        "E2E Throughput (tokens\/s)":36.4,
        "Prefill Latency (s)":4642,
        "E2E Latency (s)":490196.0,
        "Allocated Memory (MB)":27.5,
        "Reserved Memory (MB)":36.4,
        "Used Memory (MB)":5142,
        "Energy (tokens\/kWh)":6618
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0371,
        "E2E Throughput (tokens\/s)":34.29,
        "Prefill Latency (s)":3892,
        "E2E Latency (s)":456621.0,
        "Allocated Memory (MB)":29.2,
        "Reserved Memory (MB)":34.2,
        "Used Memory (MB)":4330,
        "Energy (tokens\/kWh)":5802
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.67*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0412,
        "E2E Throughput (tokens\/s)":30.07,
        "Prefill Latency (s)":3892,
        "E2E Latency (s)":403225.0,
        "Allocated Memory (MB)":33.3,
        "Reserved Memory (MB)":30.0,
        "Used Memory (MB)":4351,
        "Energy (tokens\/kWh)":5825
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0237,
        "E2E Throughput (tokens\/s)":40.52,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":510204.0,
        "Allocated Memory (MB)":24.7,
        "Reserved Memory (MB)":40.5,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10944
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0275,
        "E2E Throughput (tokens\/s)":36.94,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":480769.0,
        "Allocated Memory (MB)":27.1,
        "Reserved Memory (MB)":36.9,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0278,
        "E2E Throughput (tokens\/s)":36.14,
        "Prefill Latency (s)":8864,
        "E2E Latency (s)":458715.0,
        "Allocated Memory (MB)":27.7,
        "Reserved Memory (MB)":36.1,
        "Used Memory (MB)":9472,
        "Energy (tokens\/kWh)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.03,
        "E2E Throughput (tokens\/s)":35.0,
        "Prefill Latency (s)":3901,
        "E2E Latency (s)":465116.0,
        "Allocated Memory (MB)":28.6,
        "Reserved Memory (MB)":35.0,
        "Used Memory (MB)":4399,
        "Energy (tokens\/kWh)":5875
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0303,
        "E2E Throughput (tokens\/s)":37.08,
        "Prefill Latency (s)":4642,
        "E2E Latency (s)":507614.0,
        "Allocated Memory (MB)":27.0,
        "Reserved Memory (MB)":37.0,
        "Used Memory (MB)":5142,
        "Energy (tokens\/kWh)":6618
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0372,
        "E2E Throughput (tokens\/s)":33.26,
        "Prefill Latency (s)":3892,
        "E2E Latency (s)":448430.0,
        "Allocated Memory (MB)":30.1,
        "Reserved Memory (MB)":33.2,
        "Used Memory (MB)":4330,
        "Energy (tokens\/kWh)":5802
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Size":3.95,
        "Backend":"27.58*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0413,
        "E2E Throughput (tokens\/s)":30.16,
        "Prefill Latency (s)":3892,
        "E2E Latency (s)":408163.0,
        "Allocated Memory (MB)":33.2,
        "Reserved Memory (MB)":30.1,
        "Used Memory (MB)":4351,
        "Energy (tokens\/kWh)":5825
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.016,
        "E2E Throughput (tokens\/s)":59.58,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":925925.0,
        "Allocated Memory (MB)":16.8,
        "Reserved Memory (MB)":59.5,
        "Used Memory (MB)":1310,
        "Energy (tokens\/kWh)":2784
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0185,
        "E2E Throughput (tokens\/s)":55.31,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":833333.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":1312,
        "Energy (tokens\/kWh)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0185,
        "E2E Throughput (tokens\/s)":54.7,
        "Prefill Latency (s)":1175,
        "E2E Latency (s)":847457.0,
        "Allocated Memory (MB)":18.3,
        "Reserved Memory (MB)":54.6,
        "Used Memory (MB)":1312,
        "Energy (tokens\/kWh)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0194,
        "E2E Throughput (tokens\/s)":53.82,
        "Prefill Latency (s)":748,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":18.6,
        "Reserved Memory (MB)":53.8,
        "Used Memory (MB)":889,
        "Energy (tokens\/kWh)":2365
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0196,
        "E2E Throughput (tokens\/s)":51.33,
        "Prefill Latency (s)":1017,
        "E2E Latency (s)":799999.0,
        "Allocated Memory (MB)":19.5,
        "Reserved Memory (MB)":51.3,
        "Used Memory (MB)":1147,
        "Energy (tokens\/kWh)":2623
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0243,
        "E2E Throughput (tokens\/s)":48.84,
        "Prefill Latency (s)":754,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":20.5,
        "Reserved Memory (MB)":48.8,
        "Used Memory (MB)":901,
        "Energy (tokens\/kWh)":2375
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Size":0.51,
        "Backend":"27.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0273,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":754,
        "E2E Latency (s)":684931.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":901,
        "Energy (tokens\/kWh)":2375
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0113,
        "E2E Throughput (tokens\/s)":84.83,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":1148105.0,
        "Allocated Memory (MB)":11.8,
        "Reserved Memory (MB)":84.7,
        "Used Memory (MB)":3277,
        "Energy (tokens\/kWh)":4749
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0116,
        "E2E Throughput (tokens\/s)":85.55,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":1194743.0,
        "Allocated Memory (MB)":11.7,
        "Reserved Memory (MB)":85.5,
        "Used Memory (MB)":3277,
        "Energy (tokens\/kWh)":4749
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0143,
        "E2E Throughput (tokens\/s)":72.02,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":990099.0,
        "Allocated Memory (MB)":13.9,
        "Reserved Memory (MB)":71.9,
        "Used Memory (MB)":3277,
        "Energy (tokens\/kWh)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0143,
        "E2E Throughput (tokens\/s)":71.5,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":990099.0,
        "Allocated Memory (MB)":14.0,
        "Reserved Memory (MB)":71.4,
        "Used Memory (MB)":3277,
        "Energy (tokens\/kWh)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0144,
        "E2E Throughput (tokens\/s)":70.99,
        "Prefill Latency (s)":3244,
        "E2E Latency (s)":943396.0,
        "Allocated Memory (MB)":14.1,
        "Reserved Memory (MB)":70.9,
        "Used Memory (MB)":3277,
        "Energy (tokens\/kWh)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0151,
        "E2E Throughput (tokens\/s)":74.16,
        "Prefill Latency (s)":1490,
        "E2E Latency (s)":990099.0,
        "Allocated Memory (MB)":13.5,
        "Reserved Memory (MB)":74.1,
        "Used Memory (MB)":1520,
        "Energy (tokens\/kWh)":2996
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Size":1.32,
        "Backend":"27.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0151,
        "E2E Throughput (tokens\/s)":73.61,
        "Prefill Latency (s)":2028,
        "E2E Latency (s)":1019367.0,
        "Allocated Memory (MB)":13.6,
        "Reserved Memory (MB)":73.5,
        "Used Memory (MB)":2061,
        "Energy (tokens\/kWh)":3537
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Size":0.38,
        "Backend":"26.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0247,
        "E2E Throughput (tokens\/s)":39.56,
        "Prefill Latency (s)":895,
        "E2E Latency (s)":625000.0,
        "Allocated Memory (MB)":25.3,
        "Reserved Memory (MB)":39.5,
        "Used Memory (MB)":918,
        "Energy (tokens\/kWh)":2392
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Size":0.38,
        "Backend":"26.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":1.58,
        "E2E Throughput (tokens\/s)":40.62,
        "Prefill Latency (s)":895,
        "E2E Latency (s)":602409.0,
        "Allocated Memory (MB)":26.2,
        "Reserved Memory (MB)":38.2,
        "Used Memory (MB)":914,
        "Energy (tokens\/kWh)":2388
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Size":0.38,
        "Backend":"26.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":1.58,
        "E2E Throughput (tokens\/s)":29.48,
        "Prefill Latency (s)":419,
        "E2E Latency (s)":440528.0,
        "Allocated Memory (MB)":35.5,
        "Reserved Memory (MB)":28.2,
        "Used Memory (MB)":452,
        "Energy (tokens\/kWh)":1926
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.02,
        "E2E Throughput (tokens\/s)":49.31,
        "Prefill Latency (s)":1020,
        "E2E Latency (s)":775193.0,
        "Allocated Memory (MB)":20.3,
        "Reserved Memory (MB)":49.3,
        "Used Memory (MB)":1126,
        "Energy (tokens\/kWh)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0215,
        "E2E Throughput (tokens\/s)":47.44,
        "Prefill Latency (s)":1020,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":21.1,
        "Reserved Memory (MB)":47.4,
        "Used Memory (MB)":1126,
        "Energy (tokens\/kWh)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0215,
        "E2E Throughput (tokens\/s)":47.22,
        "Prefill Latency (s)":1020,
        "E2E Latency (s)":729927.0,
        "Allocated Memory (MB)":21.2,
        "Reserved Memory (MB)":47.2,
        "Used Memory (MB)":1126,
        "Energy (tokens\/kWh)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0249,
        "E2E Throughput (tokens\/s)":42.96,
        "Prefill Latency (s)":768,
        "E2E Latency (s)":636942.0,
        "Allocated Memory (MB)":23.3,
        "Reserved Memory (MB)":42.9,
        "Used Memory (MB)":843,
        "Energy (tokens\/kWh)":2318
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0252,
        "E2E Throughput (tokens\/s)":42.78,
        "Prefill Latency (s)":499,
        "E2E Latency (s)":621118.0,
        "Allocated Memory (MB)":23.4,
        "Reserved Memory (MB)":42.7,
        "Used Memory (MB)":562,
        "Energy (tokens\/kWh)":2037
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0344,
        "E2E Throughput (tokens\/s)":38.22,
        "Prefill Latency (s)":504,
        "E2E Latency (s)":595238.0,
        "Allocated Memory (MB)":26.2,
        "Reserved Memory (MB)":38.2,
        "Used Memory (MB)":578,
        "Energy (tokens\/kWh)":2052
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Size":0.41,
        "Backend":"26.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0374,
        "E2E Throughput (tokens\/s)":35.76,
        "Prefill Latency (s)":504,
        "E2E Latency (s)":543478.0,
        "Allocated Memory (MB)":28.0,
        "Reserved Memory (MB)":35.7,
        "Used Memory (MB)":578,
        "Energy (tokens\/kWh)":2052
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0124,
        "E2E Throughput (tokens\/s)":86.3,
        "Prefill Latency (s)":924,
        "E2E Latency (s)":1291989.0,
        "Allocated Memory (MB)":11.6,
        "Reserved Memory (MB)":86.2,
        "Used Memory (MB)":1048,
        "Energy (tokens\/kWh)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.015,
        "E2E Throughput (tokens\/s)":75.27,
        "Prefill Latency (s)":924,
        "E2E Latency (s)":1168224.0,
        "Allocated Memory (MB)":13.3,
        "Reserved Memory (MB)":75.2,
        "Used Memory (MB)":1048,
        "Energy (tokens\/kWh)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0154,
        "E2E Throughput (tokens\/s)":74.71,
        "Prefill Latency (s)":924,
        "E2E Latency (s)":1119820.0,
        "Allocated Memory (MB)":13.4,
        "Reserved Memory (MB)":74.6,
        "Used Memory (MB)":1048,
        "Energy (tokens\/kWh)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0158,
        "E2E Throughput (tokens\/s)":72.55,
        "Prefill Latency (s)":755,
        "E2E Latency (s)":1028806.0,
        "Allocated Memory (MB)":13.8,
        "Reserved Memory (MB)":72.5,
        "Used Memory (MB)":901,
        "Energy (tokens\/kWh)":2377
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0166,
        "E2E Throughput (tokens\/s)":70.5,
        "Prefill Latency (s)":486,
        "E2E Latency (s)":1000000.0,
        "Allocated Memory (MB)":14.2,
        "Reserved Memory (MB)":70.4,
        "Used Memory (MB)":620,
        "Energy (tokens\/kWh)":2096
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0257,
        "E2E Throughput (tokens\/s)":54.13,
        "Prefill Latency (s)":488,
        "E2E Latency (s)":840336.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":612,
        "Energy (tokens\/kWh)":2086
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Size":0.33,
        "Backend":"26.32*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0282,
        "E2E Throughput (tokens\/s)":49.82,
        "Prefill Latency (s)":488,
        "E2E Latency (s)":757575.0,
        "Allocated Memory (MB)":20.1,
        "Reserved Memory (MB)":49.8,
        "Used Memory (MB)":612,
        "Energy (tokens\/kWh)":2086
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Size":0.56,
        "Backend":"26.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0154,
        "E2E Throughput (tokens\/s)":74.71,
        "Prefill Latency (s)":1392,
        "E2E Latency (s)":1050420.0,
        "Allocated Memory (MB)":13.4,
        "Reserved Memory (MB)":74.6,
        "Used Memory (MB)":1543,
        "Energy (tokens\/kWh)":3017
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Size":0.56,
        "Backend":"26.19 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0156,
        "E2E Throughput (tokens\/s)":74.16,
        "Prefill Latency (s)":1392,
        "E2E Latency (s)":1083423.0,
        "Allocated Memory (MB)":13.5,
        "Reserved Memory (MB)":74.1,
        "Used Memory (MB)":1543,
        "Energy (tokens\/kWh)":3017
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Size":0.56,
        "Backend":"26.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0162,
        "E2E Throughput (tokens\/s)":72.55,
        "Prefill Latency (s)":1223,
        "E2E Latency (s)":1001001.0,
        "Allocated Memory (MB)":13.8,
        "Reserved Memory (MB)":72.5,
        "Used Memory (MB)":1375,
        "Energy (tokens\/kWh)":2851
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Size":0.56,
        "Backend":"26.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0169,
        "E2E Throughput (tokens\/s)":68.11,
        "Prefill Latency (s)":954,
        "E2E Latency (s)":980392.0,
        "Allocated Memory (MB)":14.7,
        "Reserved Memory (MB)":68.0,
        "Used Memory (MB)":1094,
        "Energy (tokens\/kWh)":2570
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Size":0.56,
        "Backend":"26.19*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0287,
        "E2E Throughput (tokens\/s)":50.84,
        "Prefill Latency (s)":958,
        "E2E Latency (s)":746268.0,
        "Allocated Memory (MB)":19.7,
        "Reserved Memory (MB)":50.8,
        "Used Memory (MB)":1107,
        "Energy (tokens\/kWh)":2581
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0129,
        "E2E Throughput (tokens\/s)":68.55,
        "Prefill Latency (s)":2143,
        "E2E Latency (s)":1029866.0,
        "Allocated Memory (MB)":14.6,
        "Reserved Memory (MB)":68.5,
        "Used Memory (MB)":2357,
        "Energy (tokens\/kWh)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0149,
        "E2E Throughput (tokens\/s)":68.56,
        "Prefill Latency (s)":2143,
        "E2E Latency (s)":980392.0,
        "Allocated Memory (MB)":14.6,
        "Reserved Memory (MB)":68.5,
        "Used Memory (MB)":2357,
        "Energy (tokens\/kWh)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.015,
        "E2E Throughput (tokens\/s)":67.64,
        "Prefill Latency (s)":2143,
        "E2E Latency (s)":980392.0,
        "Allocated Memory (MB)":14.8,
        "Reserved Memory (MB)":67.6,
        "Used Memory (MB)":2357,
        "Energy (tokens\/kWh)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0156,
        "E2E Throughput (tokens\/s)":70.01,
        "Prefill Latency (s)":1170,
        "E2E Latency (s)":934579.0,
        "Allocated Memory (MB)":14.3,
        "Reserved Memory (MB)":69.9,
        "Used Memory (MB)":1342,
        "Energy (tokens\/kWh)":2818
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0157,
        "E2E Throughput (tokens\/s)":67.64,
        "Prefill Latency (s)":1574,
        "E2E Latency (s)":943396.0,
        "Allocated Memory (MB)":14.8,
        "Reserved Memory (MB)":67.6,
        "Used Memory (MB)":1749,
        "Energy (tokens\/kWh)":3224
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0213,
        "E2E Throughput (tokens\/s)":56.89,
        "Prefill Latency (s)":1166,
        "E2E Latency (s)":840336.0,
        "Allocated Memory (MB)":17.6,
        "Reserved Memory (MB)":56.8,
        "Used Memory (MB)":1344,
        "Energy (tokens\/kWh)":2818
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Size":0.88,
        "Backend":"25.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.024,
        "E2E Throughput (tokens\/s)":53.54,
        "Prefill Latency (s)":1166,
        "E2E Latency (s)":787401.0,
        "Allocated Memory (MB)":18.7,
        "Reserved Memory (MB)":53.5,
        "Used Memory (MB)":1344,
        "Energy (tokens\/kWh)":2818
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00818,
        "E2E Throughput (tokens\/s)":116.39,
        "Prefill Latency (s)":408,
        "E2E Latency (s)":1862197.0,
        "Allocated Memory (MB)":8.6,
        "Reserved Memory (MB)":116.0,
        "Used Memory (MB)":499,
        "Energy (tokens\/kWh)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00839,
        "E2E Throughput (tokens\/s)":118.74,
        "Prefill Latency (s)":411,
        "E2E Latency (s)":1872659.0,
        "Allocated Memory (MB)":8.43,
        "Reserved Memory (MB)":119.0,
        "Used Memory (MB)":499,
        "Energy (tokens\/kWh)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00848,
        "E2E Throughput (tokens\/s)":117.63,
        "Prefill Latency (s)":411,
        "E2E Latency (s)":1814882.0,
        "Allocated Memory (MB)":8.51,
        "Reserved Memory (MB)":118.0,
        "Used Memory (MB)":499,
        "Energy (tokens\/kWh)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00929,
        "E2E Throughput (tokens\/s)":114.15,
        "Prefill Latency (s)":489,
        "E2E Latency (s)":1642036.0,
        "Allocated Memory (MB)":8.77,
        "Reserved Memory (MB)":114.0,
        "Used Memory (MB)":572,
        "Energy (tokens\/kWh)":2048
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00958,
        "E2E Throughput (tokens\/s)":112.99,
        "Prefill Latency (s)":286,
        "E2E Latency (s)":1584786.0,
        "Allocated Memory (MB)":8.86,
        "Reserved Memory (MB)":113.0,
        "Used Memory (MB)":364,
        "Energy (tokens\/kWh)":1840
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0144,
        "E2E Throughput (tokens\/s)":87.07,
        "Prefill Latency (s)":287,
        "E2E Latency (s)":1388888.0,
        "Allocated Memory (MB)":11.5,
        "Reserved Memory (MB)":87.0,
        "Used Memory (MB)":369,
        "Energy (tokens\/kWh)":1842
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Size":0.15,
        "Backend":"25.79*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.015,
        "E2E Throughput (tokens\/s)":87.07,
        "Prefill Latency (s)":291,
        "E2E Latency (s)":1347708.0,
        "Allocated Memory (MB)":11.5,
        "Reserved Memory (MB)":87.0,
        "Used Memory (MB)":367,
        "Energy (tokens\/kWh)":1840
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0162,
        "E2E Throughput (tokens\/s)":82.76,
        "Prefill Latency (s)":7714,
        "E2E Latency (s)":877192.0,
        "Allocated Memory (MB)":12.1,
        "Reserved Memory (MB)":82.6,
        "Used Memory (MB)":7761,
        "Energy (tokens\/kWh)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0168,
        "E2E Throughput (tokens\/s)":74.72,
        "Prefill Latency (s)":7714,
        "E2E Latency (s)":854700.0,
        "Allocated Memory (MB)":13.4,
        "Reserved Memory (MB)":74.6,
        "Used Memory (MB)":7761,
        "Energy (tokens\/kWh)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0181,
        "E2E Throughput (tokens\/s)":75.29,
        "Prefill Latency (s)":7714,
        "E2E Latency (s)":819672.0,
        "Allocated Memory (MB)":13.3,
        "Reserved Memory (MB)":75.2,
        "Used Memory (MB)":7761,
        "Energy (tokens\/kWh)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0215,
        "E2E Throughput (tokens\/s)":66.76,
        "Prefill Latency (s)":3039,
        "E2E Latency (s)":847457.0,
        "Allocated Memory (MB)":15.0,
        "Reserved Memory (MB)":66.7,
        "Used Memory (MB)":3200,
        "Energy (tokens\/kWh)":4676
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0233,
        "E2E Throughput (tokens\/s)":61.44,
        "Prefill Latency (s)":3072,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":16.3,
        "Reserved Memory (MB)":61.3,
        "Used Memory (MB)":3164,
        "Energy (tokens\/kWh)":4638
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Size":3.37,
        "Backend":"25.69*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0241,
        "E2E Throughput (tokens\/s)":57.88,
        "Prefill Latency (s)":3073,
        "E2E Latency (s)":719424.0,
        "Allocated Memory (MB)":17.3,
        "Reserved Memory (MB)":57.8,
        "Used Memory (MB)":3170,
        "Energy (tokens\/kWh)":4644
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00803,
        "E2E Throughput (tokens\/s)":114.0,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1824817.0,
        "Allocated Memory (MB)":8.78,
        "Reserved Memory (MB)":114.0,
        "Used Memory (MB)":574,
        "Energy (tokens\/kWh)":2048
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0094,
        "E2E Throughput (tokens\/s)":106.26,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1675041.0,
        "Allocated Memory (MB)":9.42,
        "Reserved Memory (MB)":106.0,
        "Used Memory (MB)":576,
        "Energy (tokens\/kWh)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0098,
        "E2E Throughput (tokens\/s)":105.15,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1663893.0,
        "Allocated Memory (MB)":9.52,
        "Reserved Memory (MB)":105.0,
        "Used Memory (MB)":576,
        "Energy (tokens\/kWh)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00991,
        "E2E Throughput (tokens\/s)":104.49,
        "Prefill Latency (s)":358,
        "E2E Latency (s)":1477104.0,
        "Allocated Memory (MB)":9.58,
        "Reserved Memory (MB)":104.0,
        "Used Memory (MB)":444,
        "Energy (tokens\/kWh)":1920
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0125,
        "E2E Throughput (tokens\/s)":94.45,
        "Prefill Latency (s)":362,
        "E2E Latency (s)":1464128.0,
        "Allocated Memory (MB)":10.6,
        "Reserved Memory (MB)":94.3,
        "Used Memory (MB)":448,
        "Energy (tokens\/kWh)":1922
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.66*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.014,
        "E2E Throughput (tokens\/s)":86.31,
        "Prefill Latency (s)":362,
        "E2E Latency (s)":1338688.0,
        "Allocated Memory (MB)":11.6,
        "Reserved Memory (MB)":86.2,
        "Used Memory (MB)":448,
        "Energy (tokens\/kWh)":1922
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Size":0.26,
        "Backend":"25.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00673,
        "E2E Throughput (tokens\/s)":129.82,
        "Prefill Latency (s)":737,
        "E2E Latency (s)":2079002.0,
        "Allocated Memory (MB)":7.71,
        "Reserved Memory (MB)":130.0,
        "Used Memory (MB)":853,
        "Energy (tokens\/kWh)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Size":0.26,
        "Backend":"25.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00675,
        "E2E Throughput (tokens\/s)":130.66,
        "Prefill Latency (s)":737,
        "E2E Latency (s)":1980198.0,
        "Allocated Memory (MB)":7.66,
        "Reserved Memory (MB)":131.0,
        "Used Memory (MB)":853,
        "Energy (tokens\/kWh)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Size":0.26,
        "Backend":"25.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00843,
        "E2E Throughput (tokens\/s)":117.49,
        "Prefill Latency (s)":737,
        "E2E Latency (s)":1757469.0,
        "Allocated Memory (MB)":8.52,
        "Reserved Memory (MB)":117.0,
        "Used Memory (MB)":853,
        "Energy (tokens\/kWh)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Size":0.26,
        "Backend":"25.65*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00845,
        "E2E Throughput (tokens\/s)":114.66,
        "Prefill Latency (s)":737,
        "E2E Latency (s)":1792114.0,
        "Allocated Memory (MB)":8.73,
        "Reserved Memory (MB)":115.0,
        "Used Memory (MB)":853,
        "Energy (tokens\/kWh)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Size":0.26,
        "Backend":"25.65 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00848,
        "E2E Throughput (tokens\/s)":115.85,
        "Prefill Latency (s)":737,
        "E2E Latency (s)":1754385.0,
        "Allocated Memory (MB)":8.64,
        "Reserved Memory (MB)":116.0,
        "Used Memory (MB)":853,
        "Energy (tokens\/kWh)":2327
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0162,
        "E2E Throughput (tokens\/s)":65.0,
        "Prefill Latency (s)":2391,
        "E2E Latency (s)":934579.0,
        "Allocated Memory (MB)":15.4,
        "Reserved Memory (MB)":64.9,
        "Used Memory (MB)":2541,
        "Energy (tokens\/kWh)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0164,
        "E2E Throughput (tokens\/s)":64.58,
        "Prefill Latency (s)":2391,
        "E2E Latency (s)":925925.0,
        "Allocated Memory (MB)":15.5,
        "Reserved Memory (MB)":64.5,
        "Used Memory (MB)":2541,
        "Energy (tokens\/kWh)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0166,
        "E2E Throughput (tokens\/s)":63.76,
        "Prefill Latency (s)":2391,
        "E2E Latency (s)":900900.0,
        "Allocated Memory (MB)":15.7,
        "Reserved Memory (MB)":63.7,
        "Used Memory (MB)":2541,
        "Energy (tokens\/kWh)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0187,
        "E2E Throughput (tokens\/s)":59.59,
        "Prefill Latency (s)":1407,
        "E2E Latency (s)":877192.0,
        "Allocated Memory (MB)":16.8,
        "Reserved Memory (MB)":59.5,
        "Used Memory (MB)":1476,
        "Energy (tokens\/kWh)":2952
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.02,
        "E2E Throughput (tokens\/s)":58.89,
        "Prefill Latency (s)":1020,
        "E2E Latency (s)":819672.0,
        "Allocated Memory (MB)":17.0,
        "Reserved Memory (MB)":58.8,
        "Used Memory (MB)":1086,
        "Energy (tokens\/kWh)":2562
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0284,
        "E2E Throughput (tokens\/s)":48.85,
        "Prefill Latency (s)":1031,
        "E2E Latency (s)":709219.0,
        "Allocated Memory (MB)":20.5,
        "Reserved Memory (MB)":48.8,
        "Used Memory (MB)":1111,
        "Energy (tokens\/kWh)":2585
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Size":1.11,
        "Backend":"25.60*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0285,
        "E2E Throughput (tokens\/s)":48.85,
        "Prefill Latency (s)":1031,
        "E2E Latency (s)":724637.0,
        "Allocated Memory (MB)":20.5,
        "Reserved Memory (MB)":48.8,
        "Used Memory (MB)":1111,
        "Energy (tokens\/kWh)":2585
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00613,
        "E2E Throughput (tokens\/s)":166.01,
        "Prefill Latency (s)":360,
        "E2E Latency (s)":2570694.0,
        "Allocated Memory (MB)":6.03,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":455,
        "Energy (tokens\/kWh)":1928
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00756,
        "E2E Throughput (tokens\/s)":144.88,
        "Prefill Latency (s)":360,
        "E2E Latency (s)":2217294.0,
        "Allocated Memory (MB)":6.91,
        "Reserved Memory (MB)":145.0,
        "Used Memory (MB)":455,
        "Energy (tokens\/kWh)":1928
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00759,
        "E2E Throughput (tokens\/s)":141.59,
        "Prefill Latency (s)":360,
        "E2E Latency (s)":2123142.0,
        "Allocated Memory (MB)":7.07,
        "Reserved Memory (MB)":141.0,
        "Used Memory (MB)":455,
        "Energy (tokens\/kWh)":1928
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00805,
        "E2E Throughput (tokens\/s)":139.82,
        "Prefill Latency (s)":433,
        "E2E Latency (s)":2016129.0,
        "Allocated Memory (MB)":7.16,
        "Reserved Memory (MB)":140.0,
        "Used Memory (MB)":532,
        "Energy (tokens\/kWh)":2008
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00814,
        "E2E Throughput (tokens\/s)":136.39,
        "Prefill Latency (s)":232,
        "E2E Latency (s)":1908396.0,
        "Allocated Memory (MB)":7.34,
        "Reserved Memory (MB)":136.0,
        "Used Memory (MB)":322,
        "Energy (tokens\/kWh)":1798
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0129,
        "E2E Throughput (tokens\/s)":107.1,
        "Prefill Latency (s)":232,
        "E2E Latency (s)":1686340.0,
        "Allocated Memory (MB)":9.35,
        "Reserved Memory (MB)":107.0,
        "Used Memory (MB)":325,
        "Energy (tokens\/kWh)":1798
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Size":0.12,
        "Backend":"25.47*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0157,
        "E2E Throughput (tokens\/s)":92.73,
        "Prefill Latency (s)":232,
        "E2E Latency (s)":1490312.0,
        "Allocated Memory (MB)":10.8,
        "Reserved Memory (MB)":92.6,
        "Used Memory (MB)":325,
        "Energy (tokens\/kWh)":1798
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00755,
        "E2E Throughput (tokens\/s)":119.3,
        "Prefill Latency (s)":446,
        "E2E Latency (s)":1923076.0,
        "Allocated Memory (MB)":8.39,
        "Reserved Memory (MB)":119.0,
        "Used Memory (MB)":471,
        "Energy (tokens\/kWh)":1943
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00936,
        "E2E Throughput (tokens\/s)":103.41,
        "Prefill Latency (s)":446,
        "E2E Latency (s)":1626016.0,
        "Allocated Memory (MB)":9.68,
        "Reserved Memory (MB)":103.0,
        "Used Memory (MB)":471,
        "Energy (tokens\/kWh)":1945
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00977,
        "E2E Throughput (tokens\/s)":101.62,
        "Prefill Latency (s)":446,
        "E2E Latency (s)":1615508.0,
        "Allocated Memory (MB)":9.85,
        "Reserved Memory (MB)":102.0,
        "Used Memory (MB)":471,
        "Energy (tokens\/kWh)":1945
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00995,
        "E2E Throughput (tokens\/s)":100.91,
        "Prefill Latency (s)":470,
        "E2E Latency (s)":1533742.0,
        "Allocated Memory (MB)":9.92,
        "Reserved Memory (MB)":101.0,
        "Used Memory (MB)":505,
        "Energy (tokens\/kWh)":1981
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00999,
        "E2E Throughput (tokens\/s)":99.11,
        "Prefill Latency (s)":269,
        "E2E Latency (s)":1447178.0,
        "Allocated Memory (MB)":10.1,
        "Reserved Memory (MB)":99.0,
        "Used Memory (MB)":297,
        "Energy (tokens\/kWh)":1773
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0157,
        "E2E Throughput (tokens\/s)":86.32,
        "Prefill Latency (s)":269,
        "E2E Latency (s)":1322751.0,
        "Allocated Memory (MB)":11.6,
        "Reserved Memory (MB)":86.2,
        "Used Memory (MB)":301,
        "Energy (tokens\/kWh)":1773
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Size":0.16,
        "Backend":"25.43*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.017,
        "E2E Throughput (tokens\/s)":73.08,
        "Prefill Latency (s)":269,
        "E2E Latency (s)":1164144.0,
        "Allocated Memory (MB)":13.7,
        "Reserved Memory (MB)":73.0,
        "Used Memory (MB)":301,
        "Energy (tokens\/kWh)":1775
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00797,
        "E2E Throughput (tokens\/s)":114.13,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1872659.0,
        "Allocated Memory (MB)":8.77,
        "Reserved Memory (MB)":114.0,
        "Used Memory (MB)":574,
        "Energy (tokens\/kWh)":2048
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00948,
        "E2E Throughput (tokens\/s)":104.82,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1652892.0,
        "Allocated Memory (MB)":9.55,
        "Reserved Memory (MB)":105.0,
        "Used Memory (MB)":576,
        "Energy (tokens\/kWh)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00956,
        "E2E Throughput (tokens\/s)":105.93,
        "Prefill Latency (s)":483,
        "E2E Latency (s)":1652892.0,
        "Allocated Memory (MB)":9.45,
        "Reserved Memory (MB)":106.0,
        "Used Memory (MB)":576,
        "Energy (tokens\/kWh)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00965,
        "E2E Throughput (tokens\/s)":106.27,
        "Prefill Latency (s)":561,
        "E2E Latency (s)":1599999.0,
        "Allocated Memory (MB)":9.42,
        "Reserved Memory (MB)":106.0,
        "Used Memory (MB)":652,
        "Energy (tokens\/kWh)":2128
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0101,
        "E2E Throughput (tokens\/s)":104.39,
        "Prefill Latency (s)":358,
        "E2E Latency (s)":1483679.0,
        "Allocated Memory (MB)":9.59,
        "Reserved Memory (MB)":104.0,
        "Used Memory (MB)":444,
        "Energy (tokens\/kWh)":1920
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0127,
        "E2E Throughput (tokens\/s)":95.35,
        "Prefill Latency (s)":362,
        "E2E Latency (s)":1503759.0,
        "Allocated Memory (MB)":10.5,
        "Reserved Memory (MB)":95.2,
        "Used Memory (MB)":448,
        "Energy (tokens\/kWh)":1922
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Size":0.21,
        "Backend":"25.36*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0139,
        "E2E Throughput (tokens\/s)":86.31,
        "Prefill Latency (s)":362,
        "E2E Latency (s)":1360544.0,
        "Allocated Memory (MB)":11.6,
        "Reserved Memory (MB)":86.2,
        "Used Memory (MB)":448,
        "Energy (tokens\/kWh)":1922
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00418,
        "E2E Throughput (tokens\/s)":219.5,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3436426.0,
        "Allocated Memory (MB)":4.56,
        "Reserved Memory (MB)":219.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00478,
        "E2E Throughput (tokens\/s)":203.04,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3225806.0,
        "Allocated Memory (MB)":4.93,
        "Reserved Memory (MB)":203.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0049,
        "E2E Throughput (tokens\/s)":201.81,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3215434.0,
        "Allocated Memory (MB)":4.96,
        "Reserved Memory (MB)":202.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00511,
        "E2E Throughput (tokens\/s)":197.05,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":2881844.0,
        "Allocated Memory (MB)":5.08,
        "Reserved Memory (MB)":197.0,
        "Used Memory (MB)":234,
        "Energy (tokens\/kWh)":1710
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00513,
        "E2E Throughput (tokens\/s)":193.24,
        "Prefill Latency (s)":321,
        "E2E Latency (s)":3030303.0,
        "Allocated Memory (MB)":5.18,
        "Reserved Memory (MB)":193.0,
        "Used Memory (MB)":373,
        "Energy (tokens\/kWh)":1849
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0063,
        "E2E Throughput (tokens\/s)":173.2,
        "Prefill Latency (s)":185,
        "E2E Latency (s)":2688172.0,
        "Allocated Memory (MB)":5.78,
        "Reserved Memory (MB)":173.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1689
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"25.28*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00721,
        "E2E Throughput (tokens\/s)":164.4,
        "Prefill Latency (s)":185,
        "E2E Latency (s)":2583979.0,
        "Allocated Memory (MB)":6.09,
        "Reserved Memory (MB)":164.0,
        "Used Memory (MB)":213,
        "Energy (tokens\/kWh)":1687
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.016,
        "E2E Throughput (tokens\/s)":57.86,
        "Prefill Latency (s)":2193,
        "E2E Latency (s)":884955.0,
        "Allocated Memory (MB)":17.3,
        "Reserved Memory (MB)":57.8,
        "Used Memory (MB)":2384,
        "Energy (tokens\/kWh)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0192,
        "E2E Throughput (tokens\/s)":51.07,
        "Prefill Latency (s)":2193,
        "E2E Latency (s)":787401.0,
        "Allocated Memory (MB)":19.6,
        "Reserved Memory (MB)":51.0,
        "Used Memory (MB)":2384,
        "Energy (tokens\/kWh)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0194,
        "E2E Throughput (tokens\/s)":55.31,
        "Prefill Latency (s)":1602,
        "E2E Latency (s)":819672.0,
        "Allocated Memory (MB)":18.1,
        "Reserved Memory (MB)":55.2,
        "Used Memory (MB)":1753,
        "Energy (tokens\/kWh)":3229
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0195,
        "E2E Throughput (tokens\/s)":53.25,
        "Prefill Latency (s)":2193,
        "E2E Latency (s)":769230.0,
        "Allocated Memory (MB)":18.8,
        "Reserved Memory (MB)":53.2,
        "Used Memory (MB)":2384,
        "Energy (tokens\/kWh)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0198,
        "E2E Throughput (tokens\/s)":54.11,
        "Prefill Latency (s)":1198,
        "E2E Latency (s)":757575.0,
        "Allocated Memory (MB)":18.5,
        "Reserved Memory (MB)":54.1,
        "Used Memory (MB)":1346,
        "Energy (tokens\/kWh)":2822
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0245,
        "E2E Throughput (tokens\/s)":48.84,
        "Prefill Latency (s)":1216,
        "E2E Latency (s)":751879.0,
        "Allocated Memory (MB)":20.5,
        "Reserved Memory (MB)":48.8,
        "Used Memory (MB)":1377,
        "Energy (tokens\/kWh)":2851
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Size":0.76,
        "Backend":"25.24*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0278,
        "E2E Throughput (tokens\/s)":44.7,
        "Prefill Latency (s)":1216,
        "E2E Latency (s)":662251.0,
        "Allocated Memory (MB)":22.4,
        "Reserved Memory (MB)":44.6,
        "Used Memory (MB)":1377,
        "Energy (tokens\/kWh)":2851
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00413,
        "E2E Throughput (tokens\/s)":219.02,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3610108.0,
        "Allocated Memory (MB)":4.57,
        "Reserved Memory (MB)":219.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00476,
        "E2E Throughput (tokens\/s)":208.54,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3378378.0,
        "Allocated Memory (MB)":4.8,
        "Reserved Memory (MB)":208.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00483,
        "E2E Throughput (tokens\/s)":204.28,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3215434.0,
        "Allocated Memory (MB)":4.9,
        "Reserved Memory (MB)":204.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00496,
        "E2E Throughput (tokens\/s)":197.82,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3067484.0,
        "Allocated Memory (MB)":5.06,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00499,
        "E2E Throughput (tokens\/s)":199.8,
        "Prefill Latency (s)":119,
        "E2E Latency (s)":2762430.0,
        "Allocated Memory (MB)":5.01,
        "Reserved Memory (MB)":200.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00632,
        "E2E Throughput (tokens\/s)":177.5,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2702702.0,
        "Allocated Memory (MB)":5.64,
        "Reserved Memory (MB)":177.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"25.21*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00714,
        "E2E Throughput (tokens\/s)":163.86,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2544529.0,
        "Allocated Memory (MB)":6.11,
        "Reserved Memory (MB)":164.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00466,
        "E2E Throughput (tokens\/s)":282.86,
        "Prefill Latency (s)":2328,
        "E2E Latency (s)":3154574.0,
        "Allocated Memory (MB)":3.54,
        "Reserved Memory (MB)":282.0,
        "Used Memory (MB)":2355,
        "Energy (tokens\/kWh)":3828
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00483,
        "E2E Throughput (tokens\/s)":256.73,
        "Prefill Latency (s)":2328,
        "E2E Latency (s)":2967359.0,
        "Allocated Memory (MB)":3.9,
        "Reserved Memory (MB)":256.0,
        "Used Memory (MB)":2355,
        "Energy (tokens\/kWh)":3828
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00486,
        "E2E Throughput (tokens\/s)":258.72,
        "Prefill Latency (s)":2328,
        "E2E Latency (s)":2898550.0,
        "Allocated Memory (MB)":3.87,
        "Reserved Memory (MB)":258.0,
        "Used Memory (MB)":2355,
        "Energy (tokens\/kWh)":3828
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00589,
        "E2E Throughput (tokens\/s)":245.45,
        "Prefill Latency (s)":1227,
        "E2E Latency (s)":3225806.0,
        "Allocated Memory (MB)":4.08,
        "Reserved Memory (MB)":245.0,
        "Used Memory (MB)":1287,
        "Energy (tokens\/kWh)":2763
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.006,
        "E2E Throughput (tokens\/s)":236.74,
        "Prefill Latency (s)":1949,
        "E2E Latency (s)":3333333.0,
        "Allocated Memory (MB)":4.23,
        "Reserved Memory (MB)":236.0,
        "Used Memory (MB)":2011,
        "Energy (tokens\/kWh)":3487
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00653,
        "E2E Throughput (tokens\/s)":216.76,
        "Prefill Latency (s)":1166,
        "E2E Latency (s)":2840909.0,
        "Allocated Memory (MB)":4.62,
        "Reserved Memory (MB)":216.0,
        "Used Memory (MB)":1220,
        "Energy (tokens\/kWh)":2694
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Size":0.94,
        "Backend":"25.12*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0068,
        "E2E Throughput (tokens\/s)":201.08,
        "Prefill Latency (s)":1166,
        "E2E Latency (s)":2652519.0,
        "Allocated Memory (MB)":4.98,
        "Reserved Memory (MB)":201.0,
        "Used Memory (MB)":1233,
        "Energy (tokens\/kWh)":2706
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Size":0.13,
        "Backend":"25.07 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0128,
        "E2E Throughput (tokens\/s)":77.0,
        "Prefill Latency (s)":381,
        "E2E Latency (s)":1162790.0,
        "Allocated Memory (MB)":13.0,
        "Reserved Memory (MB)":76.9,
        "Used Memory (MB)":400,
        "Energy (tokens\/kWh)":1874
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Size":0.13,
        "Backend":"25.07 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.777,
        "E2E Throughput (tokens\/s)":77.98,
        "Prefill Latency (s)":381,
        "E2E Latency (s)":1168224.0,
        "Allocated Memory (MB)":13.6,
        "Reserved Memory (MB)":73.5,
        "Used Memory (MB)":398,
        "Energy (tokens\/kWh)":1872
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Size":0.13,
        "Backend":"25.07*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.818,
        "E2E Throughput (tokens\/s)":58.2,
        "Prefill Latency (s)":241,
        "E2E Latency (s)":877192.0,
        "Allocated Memory (MB)":18.0,
        "Reserved Memory (MB)":55.6,
        "Used Memory (MB)":274,
        "Energy (tokens\/kWh)":1748
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00484,
        "E2E Throughput (tokens\/s)":186.74,
        "Prefill Latency (s)":180,
        "E2E Latency (s)":3058103.0,
        "Allocated Memory (MB)":5.36,
        "Reserved Memory (MB)":187.0,
        "Used Memory (MB)":224,
        "Energy (tokens\/kWh)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0054,
        "E2E Throughput (tokens\/s)":176.53,
        "Prefill Latency (s)":180,
        "E2E Latency (s)":2857142.0,
        "Allocated Memory (MB)":5.67,
        "Reserved Memory (MB)":176.0,
        "Used Memory (MB)":224,
        "Energy (tokens\/kWh)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00567,
        "E2E Throughput (tokens\/s)":174.08,
        "Prefill Latency (s)":180,
        "E2E Latency (s)":2717391.0,
        "Allocated Memory (MB)":5.75,
        "Reserved Memory (MB)":174.0,
        "Used Memory (MB)":224,
        "Energy (tokens\/kWh)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00613,
        "E2E Throughput (tokens\/s)":168.81,
        "Prefill Latency (s)":279,
        "E2E Latency (s)":2544529.0,
        "Allocated Memory (MB)":5.93,
        "Reserved Memory (MB)":169.0,
        "Used Memory (MB)":320,
        "Energy (tokens\/kWh)":1796
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00618,
        "E2E Throughput (tokens\/s)":166.28,
        "Prefill Latency (s)":145,
        "E2E Latency (s)":2624671.0,
        "Allocated Memory (MB)":6.02,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":182,
        "Energy (tokens\/kWh)":1658
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00845,
        "E2E Throughput (tokens\/s)":150.79,
        "Prefill Latency (s)":144,
        "E2E Latency (s)":2341920.0,
        "Allocated Memory (MB)":6.64,
        "Reserved Memory (MB)":151.0,
        "Used Memory (MB)":182,
        "Energy (tokens\/kWh)":1656
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Size":0.06,
        "Backend":"25.03*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00908,
        "E2E Throughput (tokens\/s)":140.83,
        "Prefill Latency (s)":144,
        "E2E Latency (s)":2232142.0,
        "Allocated Memory (MB)":7.11,
        "Reserved Memory (MB)":141.0,
        "Used Memory (MB)":182,
        "Energy (tokens\/kWh)":1656
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Size":0.0,
        "Backend":"25.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00545,
        "E2E Throughput (tokens\/s)":177.79,
        "Prefill Latency (s)":77,
        "E2E Latency (s)":2941176.0,
        "Allocated Memory (MB)":5.63,
        "Reserved Memory (MB)":178.0,
        "Used Memory (MB)":98,
        "Energy (tokens\/kWh)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Size":0.0,
        "Backend":"25.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00567,
        "E2E Throughput (tokens\/s)":168.23,
        "Prefill Latency (s)":77,
        "E2E Latency (s)":2652519.0,
        "Allocated Memory (MB)":5.95,
        "Reserved Memory (MB)":168.0,
        "Used Memory (MB)":98,
        "Energy (tokens\/kWh)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Size":0.0,
        "Backend":"25.02 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00591,
        "E2E Throughput (tokens\/s)":163.56,
        "Prefill Latency (s)":77,
        "E2E Latency (s)":2754820.0,
        "Allocated Memory (MB)":6.12,
        "Reserved Memory (MB)":163.0,
        "Used Memory (MB)":100,
        "Energy (tokens\/kWh)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Size":0.0,
        "Backend":"25.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0103,
        "E2E Throughput (tokens\/s)":125.48,
        "Prefill Latency (s)":75,
        "E2E Latency (s)":2100840.0,
        "Allocated Memory (MB)":7.98,
        "Reserved Memory (MB)":125.0,
        "Used Memory (MB)":98,
        "Energy (tokens\/kWh)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Size":0.0,
        "Backend":"25.02*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0103,
        "E2E Throughput (tokens\/s)":122.25,
        "Prefill Latency (s)":75,
        "E2E Latency (s)":2004008.0,
        "Allocated Memory (MB)":8.19,
        "Reserved Memory (MB)":122.0,
        "Used Memory (MB)":98,
        "Energy (tokens\/kWh)":1572
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Size":6.53,
        "Backend":"25.00 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0305,
        "E2E Throughput (tokens\/s)":34.05,
        "Prefill Latency (s)":13112,
        "E2E Latency (s)":399999.0,
        "Allocated Memory (MB)":29.4,
        "Reserved Memory (MB)":34.0,
        "Used Memory (MB)":13165,
        "Energy (tokens\/kWh)":14639
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Size":6.53,
        "Backend":"25.00*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0496,
        "E2E Throughput (tokens\/s)":25.16,
        "Prefill Latency (s)":4352,
        "E2E Latency (s)":343642.0,
        "Allocated Memory (MB)":39.8,
        "Reserved Memory (MB)":25.1,
        "Used Memory (MB)":4548,
        "Energy (tokens\/kWh)":6022
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Size":6.53,
        "Backend":"25.00 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":1.89,
        "E2E Throughput (tokens\/s)":34.23,
        "Prefill Latency (s)":13112,
        "E2E Latency (s)":380228.0,
        "Allocated Memory (MB)":31.1,
        "Reserved Memory (MB)":32.2,
        "Used Memory (MB)":13165,
        "Energy (tokens\/kWh)":14639
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00886,
        "E2E Throughput (tokens\/s)":107.75,
        "Prefill Latency (s)":2329,
        "E2E Latency (s)":1418439.0,
        "Allocated Memory (MB)":9.29,
        "Reserved Memory (MB)":108.0,
        "Used Memory (MB)":2426,
        "Energy (tokens\/kWh)":3898
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0117,
        "E2E Throughput (tokens\/s)":82.72,
        "Prefill Latency (s)":2329,
        "E2E Latency (s)":1152073.0,
        "Allocated Memory (MB)":12.1,
        "Reserved Memory (MB)":82.6,
        "Used Memory (MB)":2426,
        "Energy (tokens\/kWh)":3900
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0121,
        "E2E Throughput (tokens\/s)":85.56,
        "Prefill Latency (s)":1395,
        "E2E Latency (s)":1256281.0,
        "Allocated Memory (MB)":11.7,
        "Reserved Memory (MB)":85.5,
        "Used Memory (MB)":1451,
        "Energy (tokens\/kWh)":2927
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0122,
        "E2E Throughput (tokens\/s)":82.73,
        "Prefill Latency (s)":2329,
        "E2E Latency (s)":1122334.0,
        "Allocated Memory (MB)":12.1,
        "Reserved Memory (MB)":82.6,
        "Used Memory (MB)":2426,
        "Energy (tokens\/kWh)":3900
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0135,
        "E2E Throughput (tokens\/s)":82.06,
        "Prefill Latency (s)":856,
        "E2E Latency (s)":1156069.0,
        "Allocated Memory (MB)":12.2,
        "Reserved Memory (MB)":82.0,
        "Used Memory (MB)":912,
        "Energy (tokens\/kWh)":2388
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0175,
        "E2E Throughput (tokens\/s)":74.72,
        "Prefill Latency (s)":901,
        "E2E Latency (s)":1072961.0,
        "Allocated Memory (MB)":13.4,
        "Reserved Memory (MB)":74.6,
        "Used Memory (MB)":952,
        "Energy (tokens\/kWh)":2423
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Size":1.12,
        "Backend":"24.95*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0204,
        "E2E Throughput (tokens\/s)":62.97,
        "Prefill Latency (s)":901,
        "E2E Latency (s)":909090.0,
        "Allocated Memory (MB)":15.9,
        "Reserved Memory (MB)":62.9,
        "Used Memory (MB)":954,
        "Energy (tokens\/kWh)":2427
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00406,
        "E2E Throughput (tokens\/s)":229.05,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3649635.0,
        "Allocated Memory (MB)":4.37,
        "Reserved Memory (MB)":229.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00477,
        "E2E Throughput (tokens\/s)":207.67,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3278688.0,
        "Allocated Memory (MB)":4.82,
        "Reserved Memory (MB)":207.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0048,
        "E2E Throughput (tokens\/s)":206.39,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3246753.0,
        "Allocated Memory (MB)":4.85,
        "Reserved Memory (MB)":206.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00505,
        "E2E Throughput (tokens\/s)":198.22,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3012048.0,
        "Allocated Memory (MB)":5.05,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00506,
        "E2E Throughput (tokens\/s)":198.61,
        "Prefill Latency (s)":119,
        "E2E Latency (s)":2958579.0,
        "Allocated Memory (MB)":5.04,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00639,
        "E2E Throughput (tokens\/s)":180.06,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2915451.0,
        "Allocated Memory (MB)":5.56,
        "Reserved Memory (MB)":180.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.89*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00709,
        "E2E Throughput (tokens\/s)":166.31,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2617801.0,
        "Allocated Memory (MB)":6.02,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00414,
        "E2E Throughput (tokens\/s)":220.47,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3584229.0,
        "Allocated Memory (MB)":4.54,
        "Reserved Memory (MB)":220.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00479,
        "E2E Throughput (tokens\/s)":206.39,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3300330.0,
        "Allocated Memory (MB)":4.85,
        "Reserved Memory (MB)":206.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0048,
        "E2E Throughput (tokens\/s)":205.54,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3311258.0,
        "Allocated Memory (MB)":4.87,
        "Reserved Memory (MB)":205.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.005,
        "E2E Throughput (tokens\/s)":198.61,
        "Prefill Latency (s)":119,
        "E2E Latency (s)":2923976.0,
        "Allocated Memory (MB)":5.04,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00501,
        "E2E Throughput (tokens\/s)":197.82,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3048780.0,
        "Allocated Memory (MB)":5.06,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0063,
        "E2E Throughput (tokens\/s)":178.77,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2890173.0,
        "Allocated Memory (MB)":5.6,
        "Reserved Memory (MB)":179.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.85*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00701,
        "E2E Throughput (tokens\/s)":165.48,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2583979.0,
        "Allocated Memory (MB)":6.05,
        "Reserved Memory (MB)":165.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00419,
        "E2E Throughput (tokens\/s)":216.18,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3623188.0,
        "Allocated Memory (MB)":4.63,
        "Reserved Memory (MB)":216.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00484,
        "E2E Throughput (tokens\/s)":203.87,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3115264.0,
        "Allocated Memory (MB)":4.91,
        "Reserved Memory (MB)":204.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00491,
        "E2E Throughput (tokens\/s)":199.8,
        "Prefill Latency (s)":216,
        "E2E Latency (s)":3134796.0,
        "Allocated Memory (MB)":5.01,
        "Reserved Memory (MB)":200.0,
        "Used Memory (MB)":251,
        "Energy (tokens\/kWh)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00499,
        "E2E Throughput (tokens\/s)":199.8,
        "Prefill Latency (s)":321,
        "E2E Latency (s)":3012048.0,
        "Allocated Memory (MB)":5.01,
        "Reserved Memory (MB)":200.0,
        "Used Memory (MB)":373,
        "Energy (tokens\/kWh)":1849
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00502,
        "E2E Throughput (tokens\/s)":199.01,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":2857142.0,
        "Allocated Memory (MB)":5.03,
        "Reserved Memory (MB)":199.0,
        "Used Memory (MB)":234,
        "Energy (tokens\/kWh)":1710
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00635,
        "E2E Throughput (tokens\/s)":174.11,
        "Prefill Latency (s)":185,
        "E2E Latency (s)":2824858.0,
        "Allocated Memory (MB)":5.75,
        "Reserved Memory (MB)":174.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1689
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Size":0.1,
        "Backend":"24.71*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00719,
        "E2E Throughput (tokens\/s)":162.26,
        "Prefill Latency (s)":185,
        "E2E Latency (s)":2544529.0,
        "Allocated Memory (MB)":6.17,
        "Reserved Memory (MB)":162.0,
        "Used Memory (MB)":213,
        "Energy (tokens\/kWh)":1687
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00413,
        "E2E Throughput (tokens\/s)":223.42,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3676470.0,
        "Allocated Memory (MB)":4.48,
        "Reserved Memory (MB)":223.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00495,
        "E2E Throughput (tokens\/s)":205.55,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3289473.0,
        "Allocated Memory (MB)":4.87,
        "Reserved Memory (MB)":205.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00495,
        "E2E Throughput (tokens\/s)":199.0,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3174603.0,
        "Allocated Memory (MB)":5.03,
        "Reserved Memory (MB)":199.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00503,
        "E2E Throughput (tokens\/s)":197.83,
        "Prefill Latency (s)":119,
        "E2E Latency (s)":2923976.0,
        "Allocated Memory (MB)":5.06,
        "Reserved Memory (MB)":198.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00503,
        "E2E Throughput (tokens\/s)":197.05,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3021148.0,
        "Allocated Memory (MB)":5.08,
        "Reserved Memory (MB)":197.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00634,
        "E2E Throughput (tokens\/s)":180.06,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2857142.0,
        "Allocated Memory (MB)":5.56,
        "Reserved Memory (MB)":180.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.70*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.007,
        "E2E Throughput (tokens\/s)":168.27,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2617801.0,
        "Allocated Memory (MB)":5.95,
        "Reserved Memory (MB)":168.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00415,
        "E2E Throughput (tokens\/s)":220.95,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3610108.0,
        "Allocated Memory (MB)":4.53,
        "Reserved Memory (MB)":221.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00478,
        "E2E Throughput (tokens\/s)":205.12,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3378378.0,
        "Allocated Memory (MB)":4.88,
        "Reserved Memory (MB)":205.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00489,
        "E2E Throughput (tokens\/s)":203.87,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3115264.0,
        "Allocated Memory (MB)":4.91,
        "Reserved Memory (MB)":204.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00504,
        "E2E Throughput (tokens\/s)":200.2,
        "Prefill Latency (s)":119,
        "E2E Latency (s)":2967359.0,
        "Allocated Memory (MB)":5.0,
        "Reserved Memory (MB)":200.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00508,
        "E2E Throughput (tokens\/s)":195.51,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3039513.0,
        "Allocated Memory (MB)":5.12,
        "Reserved Memory (MB)":195.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00631,
        "E2E Throughput (tokens\/s)":179.09,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2898550.0,
        "Allocated Memory (MB)":5.59,
        "Reserved Memory (MB)":179.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.63*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00702,
        "E2E Throughput (tokens\/s)":166.58,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2577319.0,
        "Allocated Memory (MB)":6.01,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00544,
        "E2E Throughput (tokens\/s)":171.69,
        "Prefill Latency (s)":191,
        "E2E Latency (s)":2680965.0,
        "Allocated Memory (MB)":5.83,
        "Reserved Memory (MB)":172.0,
        "Used Memory (MB)":241,
        "Energy (tokens\/kWh)":1714
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00569,
        "E2E Throughput (tokens\/s)":176.23,
        "Prefill Latency (s)":192,
        "E2E Latency (s)":2762430.0,
        "Allocated Memory (MB)":5.68,
        "Reserved Memory (MB)":176.0,
        "Used Memory (MB)":262,
        "Energy (tokens\/kWh)":1735
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00578,
        "E2E Throughput (tokens\/s)":170.24,
        "Prefill Latency (s)":192,
        "E2E Latency (s)":2624671.0,
        "Allocated Memory (MB)":5.88,
        "Reserved Memory (MB)":170.0,
        "Used Memory (MB)":262,
        "Energy (tokens\/kWh)":1735
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00634,
        "E2E Throughput (tokens\/s)":166.29,
        "Prefill Latency (s)":157,
        "E2E Latency (s)":2403846.0,
        "Allocated Memory (MB)":6.02,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":218,
        "Energy (tokens\/kWh)":1693
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00636,
        "E2E Throughput (tokens\/s)":165.74,
        "Prefill Latency (s)":293,
        "E2E Latency (s)":2415458.0,
        "Allocated Memory (MB)":6.04,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":354,
        "Energy (tokens\/kWh)":1830
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00941,
        "E2E Throughput (tokens\/s)":134.76,
        "Prefill Latency (s)":154,
        "E2E Latency (s)":2164502.0,
        "Allocated Memory (MB)":7.43,
        "Reserved Memory (MB)":135.0,
        "Used Memory (MB)":218,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Size":0.05,
        "Backend":"24.39*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.01,
        "E2E Throughput (tokens\/s)":127.06,
        "Prefill Latency (s)":157,
        "E2E Latency (s)":2024291.0,
        "Allocated Memory (MB)":7.88,
        "Reserved Memory (MB)":127.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1689
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00312,
        "E2E Throughput (tokens\/s)":301.49,
        "Prefill Latency (s)":197,
        "E2E Latency (s)":4784688.0,
        "Allocated Memory (MB)":3.32,
        "Reserved Memory (MB)":301.0,
        "Used Memory (MB)":234,
        "Energy (tokens\/kWh)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00324,
        "E2E Throughput (tokens\/s)":306.11,
        "Prefill Latency (s)":200,
        "E2E Latency (s)":4739336.0,
        "Allocated Memory (MB)":3.27,
        "Reserved Memory (MB)":306.0,
        "Used Memory (MB)":234,
        "Energy (tokens\/kWh)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00337,
        "E2E Throughput (tokens\/s)":304.26,
        "Prefill Latency (s)":200,
        "E2E Latency (s)":4761904.0,
        "Allocated Memory (MB)":3.29,
        "Reserved Memory (MB)":304.0,
        "Used Memory (MB)":234,
        "Energy (tokens\/kWh)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0037,
        "E2E Throughput (tokens\/s)":291.86,
        "Prefill Latency (s)":362,
        "E2E Latency (s)":4405286.0,
        "Allocated Memory (MB)":3.43,
        "Reserved Memory (MB)":292.0,
        "Used Memory (MB)":402,
        "Energy (tokens\/kWh)":1878
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00371,
        "E2E Throughput (tokens\/s)":294.44,
        "Prefill Latency (s)":162,
        "E2E Latency (s)":4201680.0,
        "Allocated Memory (MB)":3.4,
        "Reserved Memory (MB)":294.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00503,
        "E2E Throughput (tokens\/s)":248.45,
        "Prefill Latency (s)":157,
        "E2E Latency (s)":3952569.0,
        "Allocated Memory (MB)":4.03,
        "Reserved Memory (MB)":248.0,
        "Used Memory (MB)":197,
        "Energy (tokens\/kWh)":1670
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Size":0.07,
        "Backend":"24.38*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00539,
        "E2E Throughput (tokens\/s)":228.07,
        "Prefill Latency (s)":161,
        "E2E Latency (s)":3649635.0,
        "Allocated Memory (MB)":4.39,
        "Reserved Memory (MB)":228.0,
        "Used Memory (MB)":197,
        "Energy (tokens\/kWh)":1670
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00409,
        "E2E Throughput (tokens\/s)":225.43,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3663003.0,
        "Allocated Memory (MB)":4.44,
        "Reserved Memory (MB)":225.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00487,
        "E2E Throughput (tokens\/s)":205.54,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3300330.0,
        "Allocated Memory (MB)":4.87,
        "Reserved Memory (MB)":205.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00503,
        "E2E Throughput (tokens\/s)":195.89,
        "Prefill Latency (s)":126,
        "E2E Latency (s)":3144654.0,
        "Allocated Memory (MB)":5.11,
        "Reserved Memory (MB)":196.0,
        "Used Memory (MB)":155,
        "Energy (tokens\/kWh)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00507,
        "E2E Throughput (tokens\/s)":202.23,
        "Prefill Latency (s)":186,
        "E2E Latency (s)":3125000.0,
        "Allocated Memory (MB)":4.95,
        "Reserved Memory (MB)":202.0,
        "Used Memory (MB)":216,
        "Energy (tokens\/kWh)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00624,
        "E2E Throughput (tokens\/s)":179.41,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2865329.0,
        "Allocated Memory (MB)":5.58,
        "Reserved Memory (MB)":179.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Size":0.03,
        "Backend":"24.35*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00704,
        "E2E Throughput (tokens\/s)":165.76,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2617801.0,
        "Allocated Memory (MB)":6.04,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":146,
        "Energy (tokens\/kWh)":1620
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00555,
        "E2E Throughput (tokens\/s)":172.28,
        "Prefill Latency (s)":112,
        "E2E Latency (s)":2873563.0,
        "Allocated Memory (MB)":5.81,
        "Reserved Memory (MB)":172.0,
        "Used Memory (MB)":157,
        "Energy (tokens\/kWh)":1631
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00567,
        "E2E Throughput (tokens\/s)":177.48,
        "Prefill Latency (s)":112,
        "E2E Latency (s)":2898550.0,
        "Allocated Memory (MB)":5.64,
        "Reserved Memory (MB)":177.0,
        "Used Memory (MB)":157,
        "Energy (tokens\/kWh)":1631
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00581,
        "E2E Throughput (tokens\/s)":174.39,
        "Prefill Latency (s)":112,
        "E2E Latency (s)":2793296.0,
        "Allocated Memory (MB)":5.74,
        "Reserved Memory (MB)":174.0,
        "Used Memory (MB)":157,
        "Energy (tokens\/kWh)":1630
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0063,
        "E2E Throughput (tokens\/s)":165.19,
        "Prefill Latency (s)":170,
        "E2E Latency (s)":2557544.0,
        "Allocated Memory (MB)":6.06,
        "Reserved Memory (MB)":165.0,
        "Used Memory (MB)":218,
        "Energy (tokens\/kWh)":1693
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00636,
        "E2E Throughput (tokens\/s)":167.12,
        "Prefill Latency (s)":103,
        "E2E Latency (s)":2531645.0,
        "Allocated Memory (MB)":5.99,
        "Reserved Memory (MB)":167.0,
        "Used Memory (MB)":148,
        "Energy (tokens\/kWh)":1624
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00944,
        "E2E Throughput (tokens\/s)":135.86,
        "Prefill Latency (s)":102,
        "E2E Latency (s)":2169197.0,
        "Allocated Memory (MB)":7.37,
        "Reserved Memory (MB)":136.0,
        "Used Memory (MB)":148,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Size":0.02,
        "Backend":"24.31*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0101,
        "E2E Throughput (tokens\/s)":129.54,
        "Prefill Latency (s)":102,
        "E2E Latency (s)":2020202.0,
        "Allocated Memory (MB)":7.73,
        "Reserved Memory (MB)":129.0,
        "Used Memory (MB)":148,
        "Energy (tokens\/kWh)":1622
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00667,
        "E2E Throughput (tokens\/s)":138.25,
        "Prefill Latency (s)":480,
        "E2E Latency (s)":2118644.0,
        "Allocated Memory (MB)":7.24,
        "Reserved Memory (MB)":138.0,
        "Used Memory (MB)":555,
        "Energy (tokens\/kWh)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00762,
        "E2E Throughput (tokens\/s)":132.94,
        "Prefill Latency (s)":480,
        "E2E Latency (s)":2000000.0,
        "Allocated Memory (MB)":7.53,
        "Reserved Memory (MB)":133.0,
        "Used Memory (MB)":555,
        "Energy (tokens\/kWh)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00764,
        "E2E Throughput (tokens\/s)":132.06,
        "Prefill Latency (s)":480,
        "E2E Latency (s)":2000000.0,
        "Allocated Memory (MB)":7.58,
        "Reserved Memory (MB)":132.0,
        "Used Memory (MB)":555,
        "Energy (tokens\/kWh)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00804,
        "E2E Throughput (tokens\/s)":130.34,
        "Prefill Latency (s)":555,
        "E2E Latency (s)":1923076.0,
        "Allocated Memory (MB)":7.68,
        "Reserved Memory (MB)":130.0,
        "Used Memory (MB)":652,
        "Energy (tokens\/kWh)":2128
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00807,
        "E2E Throughput (tokens\/s)":133.66,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":1897533.0,
        "Allocated Memory (MB)":7.49,
        "Reserved Memory (MB)":134.0,
        "Used Memory (MB)":444,
        "Energy (tokens\/kWh)":1920
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.011,
        "E2E Throughput (tokens\/s)":107.54,
        "Prefill Latency (s)":353,
        "E2E Latency (s)":1658374.0,
        "Allocated Memory (MB)":9.31,
        "Reserved Memory (MB)":107.0,
        "Used Memory (MB)":427,
        "Energy (tokens\/kWh)":1901
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Size":0.19,
        "Backend":"24.25*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.012,
        "E2E Throughput (tokens\/s)":104.41,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":1582278.0,
        "Allocated Memory (MB)":9.59,
        "Reserved Memory (MB)":104.0,
        "Used Memory (MB)":427,
        "Energy (tokens\/kWh)":1901
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00557,
        "E2E Throughput (tokens\/s)":171.1,
        "Prefill Latency (s)":87,
        "E2E Latency (s)":2832861.0,
        "Allocated Memory (MB)":5.85,
        "Reserved Memory (MB)":171.0,
        "Used Memory (MB)":123,
        "Energy (tokens\/kWh)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00563,
        "E2E Throughput (tokens\/s)":178.43,
        "Prefill Latency (s)":87,
        "E2E Latency (s)":2923976.0,
        "Allocated Memory (MB)":5.61,
        "Reserved Memory (MB)":178.0,
        "Used Memory (MB)":123,
        "Energy (tokens\/kWh)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00588,
        "E2E Throughput (tokens\/s)":174.09,
        "Prefill Latency (s)":87,
        "E2E Latency (s)":2777777.0,
        "Allocated Memory (MB)":5.75,
        "Reserved Memory (MB)":174.0,
        "Used Memory (MB)":123,
        "Energy (tokens\/kWh)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00621,
        "E2E Throughput (tokens\/s)":168.24,
        "Prefill Latency (s)":118,
        "E2E Latency (s)":2590673.0,
        "Allocated Memory (MB)":5.95,
        "Reserved Memory (MB)":168.0,
        "Used Memory (MB)":157,
        "Energy (tokens\/kWh)":1633
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00642,
        "E2E Throughput (tokens\/s)":165.74,
        "Prefill Latency (s)":84,
        "E2E Latency (s)":2347417.0,
        "Allocated Memory (MB)":6.04,
        "Reserved Memory (MB)":166.0,
        "Used Memory (MB)":121,
        "Energy (tokens\/kWh)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00928,
        "E2E Throughput (tokens\/s)":137.73,
        "Prefill Latency (s)":84,
        "E2E Latency (s)":2197802.0,
        "Allocated Memory (MB)":7.27,
        "Reserved Memory (MB)":138.0,
        "Used Memory (MB)":121,
        "Energy (tokens\/kWh)":1595
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Size":0.01,
        "Backend":"24.18*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0102,
        "E2E Throughput (tokens\/s)":129.87,
        "Prefill Latency (s)":84,
        "E2E Latency (s)":2024291.0,
        "Allocated Memory (MB)":7.71,
        "Reserved Memory (MB)":130.0,
        "Used Memory (MB)":121,
        "Energy (tokens\/kWh)":1595
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00475,
        "E2E Throughput (tokens\/s)":184.66,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":2941176.0,
        "Allocated Memory (MB)":5.42,
        "Reserved Memory (MB)":185.0,
        "Used Memory (MB)":427,
        "Energy (tokens\/kWh)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00494,
        "E2E Throughput (tokens\/s)":180.67,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":2865329.0,
        "Allocated Memory (MB)":5.54,
        "Reserved Memory (MB)":181.0,
        "Used Memory (MB)":427,
        "Energy (tokens\/kWh)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00602,
        "E2E Throughput (tokens\/s)":160.67,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":2409638.0,
        "Allocated Memory (MB)":6.23,
        "Reserved Memory (MB)":161.0,
        "Used Memory (MB)":425,
        "Energy (tokens\/kWh)":1899
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.00604,
        "E2E Throughput (tokens\/s)":160.41,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":2487562.0,
        "Allocated Memory (MB)":6.24,
        "Reserved Memory (MB)":160.0,
        "Used Memory (MB)":425,
        "Energy (tokens\/kWh)":1899
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.00608,
        "E2E Throughput (tokens\/s)":163.56,
        "Prefill Latency (s)":354,
        "E2E Latency (s)":2531645.0,
        "Allocated Memory (MB)":6.12,
        "Reserved Memory (MB)":163.0,
        "Used Memory (MB)":427,
        "Energy (tokens\/kWh)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.00621,
        "E2E Throughput (tokens\/s)":168.53,
        "Prefill Latency (s)":453,
        "E2E Latency (s)":2518891.0,
        "Allocated Memory (MB)":5.94,
        "Reserved Memory (MB)":168.0,
        "Used Memory (MB)":520,
        "Energy (tokens\/kWh)":1995
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Size":0.11,
        "Backend":"24.10*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.00628,
        "E2E Throughput (tokens\/s)":168.81,
        "Prefill Latency (s)":251,
        "E2E Latency (s)":2409638.0,
        "Allocated Memory (MB)":5.93,
        "Reserved Memory (MB)":169.0,
        "Used Memory (MB)":331,
        "Energy (tokens\/kWh)":1807
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0118,
        "E2E Throughput (tokens\/s)":79.44,
        "Prefill Latency (s)":3144,
        "E2E Latency (s)":1070663.0,
        "Allocated Memory (MB)":12.6,
        "Reserved Memory (MB)":79.4,
        "Used Memory (MB)":3416,
        "Energy (tokens\/kWh)":4890
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0147,
        "E2E Throughput (tokens\/s)":70.0,
        "Prefill Latency (s)":3144,
        "E2E Latency (s)":943396.0,
        "Allocated Memory (MB)":14.3,
        "Reserved Memory (MB)":69.9,
        "Used Memory (MB)":3416,
        "Energy (tokens\/kWh)":4889
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0149,
        "E2E Throughput (tokens\/s)":71.5,
        "Prefill Latency (s)":3144,
        "E2E Latency (s)":917431.0,
        "Allocated Memory (MB)":14.0,
        "Reserved Memory (MB)":71.4,
        "Used Memory (MB)":3416,
        "Energy (tokens\/kWh)":4890
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV1",
        "Decode Throughput (tokens\/s)":0.0164,
        "E2E Throughput (tokens\/s)":72.55,
        "Prefill Latency (s)":1390,
        "E2E Latency (s)":990099.0,
        "Allocated Memory (MB)":13.8,
        "Reserved Memory (MB)":72.5,
        "Used Memory (MB)":1486,
        "Energy (tokens\/kWh)":2962
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"GPTQ.4bit+ExllamaV2",
        "Decode Throughput (tokens\/s)":0.0167,
        "E2E Throughput (tokens\/s)":71.01,
        "Prefill Latency (s)":1929,
        "E2E Latency (s)":1017293.0,
        "Allocated Memory (MB)":14.1,
        "Reserved Memory (MB)":70.9,
        "Used Memory (MB)":2027,
        "Energy (tokens\/kWh)":3503
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"BetterTransformer",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0254,
        "E2E Throughput (tokens\/s)":56.26,
        "Prefill Latency (s)":1407,
        "E2E Latency (s)":787401.0,
        "Allocated Memory (MB)":17.8,
        "Reserved Memory (MB)":56.2,
        "Used Memory (MB)":1497,
        "Energy (tokens\/kWh)":2971
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Size":1.32,
        "Backend":"19.40*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0292,
        "E2E Throughput (tokens\/s)":50.07,
        "Prefill Latency (s)":1408,
        "E2E Latency (s)":704225.0,
        "Allocated Memory (MB)":20.0,
        "Reserved Memory (MB)":50.0,
        "Used Memory (MB)":1497,
        "Energy (tokens\/kWh)":2971
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Size":1.31,
        "Backend":"17.88 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0115,
        "E2E Throughput (tokens\/s)":88.59,
        "Prefill Latency (s)":3135,
        "E2E Latency (s)":1127395.0,
        "Allocated Memory (MB)":11.3,
        "Reserved Memory (MB)":88.5,
        "Used Memory (MB)":3212,
        "Energy (tokens\/kWh)":4686
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Size":1.31,
        "Backend":"17.88 ",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"FlashAttentionV2",
        "Avg Score (%)":"None",
        "Decode Throughput (tokens\/s)":0.0116,
        "E2E Throughput (tokens\/s)":87.04,
        "Prefill Latency (s)":3135,
        "E2E Latency (s)":1140250.0,
        "Allocated Memory (MB)":11.5,
        "Reserved Memory (MB)":87.0,
        "Used Memory (MB)":3212,
        "Energy (tokens\/kWh)":4686
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Size":1.31,
        "Backend":"17.88*",
        "Dtype":"pytorch",
        "Optimizations":"float16",
        "Quantization":"None",
        "Avg Score (%)":"BnB.4bit",
        "Decode Throughput (tokens\/s)":0.0201,
        "E2E Throughput (tokens\/s)":63.78,
        "Prefill Latency (s)":1398,
        "E2E Latency (s)":892857.0,
        "Allocated Memory (MB)":15.7,
        "Reserved Memory (MB)":63.7,
        "Used Memory (MB)":1453,
        "Energy (tokens\/kWh)":2927
    }
]