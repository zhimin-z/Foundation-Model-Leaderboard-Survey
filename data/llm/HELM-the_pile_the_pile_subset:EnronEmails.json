{
  "title": "subset: Enron Emails",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "BPB",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "BPB",
        "run_group": "The Pile"
      }
    },
    {
      "value": "Denoised inference time (s)",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Denoised inference time (s)",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# eval",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# train",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "The Pile"
      }
    },
    {
      "value": "truncated",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# output tokens",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# trials",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "The Pile"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "J1-Jumbo v1 (178B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-jumbo%22%5D",
        "markdown": false
      },
      {
        "value": 0.5586372781430737,
        "description": "min=0.559, mean=0.559, max=0.559, sum=0.559 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.4218728966346155,
        "description": "min=0.422, mean=0.422, max=0.422, sum=0.422 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Large v1 (7.5B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-large%22%5D",
        "markdown": false
      },
      {
        "value": 0.7673018540199894,
        "description": "min=0.767, mean=0.767, max=0.767, sum=0.767 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.35003825495793284,
        "description": "min=0.35, mean=0.35, max=0.35, sum=0.35 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Grande v1 (17B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-grande%22%5D",
        "markdown": false
      },
      {
        "value": 0.6901915547980926,
        "description": "min=0.69, mean=0.69, max=0.69, sum=0.69 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.42614610877403847,
        "description": "min=0.426, mean=0.426, max=0.426, sum=0.426 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Grande v2 beta (17B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
        "markdown": false
      },
      {
        "value": 0.7436628178994338,
        "description": "min=0.744, mean=0.744, max=0.744, sum=0.744 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Jumbo (178B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-jumbo%22%5D",
        "markdown": false
      },
      {
        "value": 0.6834391925190553,
        "description": "min=0.683, mean=0.683, max=0.683, sum=0.683 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 352.62745098039215,
        "description": "min=352.627, mean=352.627, max=352.627, sum=352.627 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Grande (17B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-grande%22%5D",
        "markdown": false
      },
      {
        "value": 0.7353955287785678,
        "description": "min=0.735, mean=0.735, max=0.735, sum=0.735 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Large (7.5B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-large%22%5D",
        "markdown": false
      },
      {
        "value": 0.8099813134177772,
        "description": "min=0.81, mean=0.81, max=0.81, sum=0.81 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 361.5673076923077,
        "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B)\u2620",
        "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
        "markdown": false
      },
      {
        "value": 0.8738712360692764,
        "description": "min=0.874, mean=0.874, max=0.874, sum=0.874 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.7712531403186277,
        "description": "min=0.771, mean=0.771, max=0.771, sum=0.771 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 426.79411764705884,
        "description": "min=426.794, mean=426.794, max=426.794, sum=426.794 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 3.9607843137254903,
        "description": "min=3.961, mean=3.961, max=3.961, sum=3.961 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "BLOOM (176B)\u2620",
        "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_bloom%22%5D",
        "markdown": false
      },
      {
        "value": 0.8275444757820553,
        "description": "min=0.828, mean=0.828, max=0.828, sum=0.828 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.6277824397318257,
        "description": "min=0.628, mean=0.628, max=0.628, sum=0.628 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 378.6923076923077,
        "description": "min=378.692, mean=378.692, max=378.692, sum=378.692 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "Cohere xlarge v20220609 (52.4B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_xlarge-20220609%22%5D",
        "markdown": false
      },
      {
        "value": 0.9363645608160398,
        "description": "min=0.936, mean=0.936, max=0.936, sum=0.936 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.4710873883928569,
        "description": "min=0.471, mean=0.471, max=0.471, sum=0.471 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere large v20220720 (13.1B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_large-20220720%22%5D",
        "markdown": false
      },
      {
        "value": 0.9836258840801502,
        "description": "min=0.984, mean=0.984, max=0.984, sum=0.984 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.30965760788690466,
        "description": "min=0.31, mean=0.31, max=0.31, sum=0.31 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere medium v20220720 (6.1B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_medium-20220720%22%5D",
        "markdown": false
      },
      {
        "value": 1.0169704296539641,
        "description": "min=1.017, mean=1.017, max=1.017, sum=1.017 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.26816454613095225,
        "description": "min=0.268, mean=0.268, max=0.268, sum=0.268 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere small v20220720 (410M)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_small-20220720%22%5D",
        "markdown": false
      },
      {
        "value": 1.1824377664200978,
        "description": "min=1.182, mean=1.182, max=1.182, sum=1.182 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.2831417968749999,
        "description": "min=0.283, mean=0.283, max=0.283, sum=0.283 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere xlarge v20221108 (52.4B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_xlarge-20221108%22%5D",
        "markdown": false
      },
      {
        "value": 0.9323164837336272,
        "description": "min=0.932, mean=0.932, max=0.932, sum=0.932 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere medium v20221108 (6.1B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_medium-20221108%22%5D",
        "markdown": false
      },
      {
        "value": 1.0492286807383089,
        "description": "min=1.049, mean=1.049, max=1.049, sum=1.049 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 446.84761904761905,
        "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere Command beta (6.1B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_command-medium-beta%22%5D",
        "markdown": false
      },
      {
        "value": 1.0527257306688016,
        "description": "min=1.053, mean=1.053, max=1.053, sum=1.053 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 445.51428571428573,
        "description": "min=445.514, mean=445.514, max=445.514, sum=445.514 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere Command beta (52.4B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_command-xlarge-beta%22%5D",
        "markdown": false
      },
      {
        "value": 0.9608436655343752,
        "description": "min=0.961, mean=0.961, max=0.961, sum=0.961 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 445.51428571428573,
        "description": "min=445.514, mean=445.514, max=445.514, sum=445.514 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "GPT-J (6B)\u2620",
        "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
        "markdown": false
      },
      {
        "value": 0.4719483919683847,
        "description": "min=0.472, mean=0.472, max=0.472, sum=0.472 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.45039792106265086,
        "description": "min=0.45, mean=0.45, max=0.45, sum=0.45 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "GPT-NeoX (20B)\u2620",
        "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
        "markdown": false
      },
      {
        "value": 0.415984556470918,
        "description": "min=0.416, mean=0.416, max=0.416, sum=0.416 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray",
          "font-weight": "bold"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.8498413511193715,
        "description": "min=0.85, mean=0.85, max=0.85, sum=0.85 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 408.86538461538464,
        "description": "min=408.865, mean=408.865, max=408.865, sum=408.865 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "OPT (175B)\u2620",
        "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_opt-175b%22%5D",
        "markdown": false
      },
      {
        "value": 0.6103518190290984,
        "description": "min=0.61, mean=0.61, max=0.61, sum=0.61 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.7509441199797202,
        "description": "min=0.751, mean=0.751, max=0.751, sum=0.751 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "OPT (66B)\u2620",
        "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_opt-66b%22%5D",
        "markdown": false
      },
      {
        "value": 0.6516029874902458,
        "description": "min=0.652, mean=0.652, max=0.652, sum=0.652 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.7818579669532142,
        "description": "min=0.782, mean=0.782, max=0.782, sum=0.782 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "TNLG v2 (530B)\u2620",
        "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
        "markdown": false
      },
      {
        "value": 0.8719475521068547,
        "description": "min=0.872, mean=0.872, max=0.872, sum=0.872 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 438.9047619047619,
        "description": "min=438.905, mean=438.905, max=438.905, sum=438.905 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B)\u2620",
        "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
        "markdown": false
      },
      {
        "value": 0.9812304149641637,
        "description": "min=0.981, mean=0.981, max=0.981, sum=0.981 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 438.9047619047619,
        "description": "min=438.905, mean=438.905, max=438.905, sum=438.905 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "davinci (175B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_davinci%22%5D",
        "markdown": false
      },
      {
        "value": 0.9790026759479636,
        "description": "min=0.979, mean=0.979, max=0.979, sum=0.979 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.20530081845238102,
        "description": "min=0.205, mean=0.205, max=0.205, sum=0.205 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_curie%22%5D",
        "markdown": false
      },
      {
        "value": 1.0541406102414068,
        "description": "min=1.054, mean=1.054, max=1.054, sum=1.054 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.09134916914682542,
        "description": "min=0.091, mean=0.091, max=0.091, sum=0.091 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_babbage%22%5D",
        "markdown": false
      },
      {
        "value": 1.123187940160497,
        "description": "min=1.123, mean=1.123, max=1.123, sum=1.123 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.11765336061507939,
        "description": "min=0.118, mean=0.118, max=0.118, sum=0.118 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M)",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_ada%22%5D",
        "markdown": false
      },
      {
        "value": 1.2122512727979304,
        "description": "min=1.212, mean=1.212, max=1.212, sum=1.212 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.13967581845238097,
        "description": "min=0.14, mean=0.14, max=0.14, sum=0.14 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-davinci-003%22%5D",
        "markdown": false
      },
      {
        "value": 0.8633977697757586,
        "description": "min=0.863, mean=0.863, max=0.863, sum=0.863 (1)",
        "style": {},
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 447.97087378640776,
        "description": "min=447.971, mean=447.971, max=447.971, sum=447.971 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-davinci-002%22%5D",
        "markdown": false
      },
      {
        "value": 0.8269553503052298,
        "description": "min=0.827, mean=0.827, max=0.827, sum=0.827 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.18883556457322007,
        "description": "min=0.189, mean=0.189, max=0.189, sum=0.189 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 447.97087378640776,
        "description": "min=447.971, mean=447.971, max=447.971, sum=447.971 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-curie-001%22%5D",
        "markdown": false
      },
      {
        "value": 1.2749034435651114,
        "description": "min=1.275, mean=1.275, max=1.275, sum=1.275 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.13262703373015872,
        "description": "min=0.133, mean=0.133, max=0.133, sum=0.133 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-babbage-001%22%5D",
        "markdown": false
      },
      {
        "value": 1.4354041718632282,
        "description": "min=1.435, mean=1.435, max=1.435, sum=1.435 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.13237560763888895,
        "description": "min=0.132, mean=0.132, max=0.132, sum=0.132 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001",
        "description": "",
        "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-ada-001%22%5D",
        "markdown": false
      },
      {
        "value": 2.0025518558810145,
        "description": "min=2.003, mean=2.003, max=2.003, sum=2.003 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.08688396577380951,
        "description": "min=0.087, mean=0.087, max=0.087, sum=0.087 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 102.0,
        "description": "min=102, mean=102, max=102, sum=102 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 438.95238095238096,
        "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:EnronEmails.tex"
    },
    {
      "text": "JSON",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:EnronEmails.json"
    }
  ],
  "name": "the_pile_subset:EnronEmails"
}