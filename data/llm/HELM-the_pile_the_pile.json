{
  "title": "The Pile",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "BPB",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "BPB",
        "run_group": "The Pile"
      }
    },
    {
      "value": "Denoised inference time (s)",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Denoised inference time (s)",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# eval",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# train",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "The Pile"
      }
    },
    {
      "value": "truncated",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# output tokens",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "The Pile"
      }
    },
    {
      "value": "# trials",
      "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "The Pile"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "J1-Jumbo v1 (178B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5446759805962651,
        "description": "min=0.28, mean=0.545, max=0.745, sum=3.268 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.8475487923672765,
        "description": "min=0.422, mean=0.848, max=1.13, sum=5.085 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Large v1 (7.5B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.6450688489525521,
        "description": "min=0.358, mean=0.645, max=0.833, sum=3.87 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.6419919242598767,
        "description": "min=0.35, mean=0.642, max=0.835, sum=3.852 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Grande v1 (17B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.6004897010269956,
        "description": "min=0.314, mean=0.6, max=0.792, sum=3.603 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.753306670563767,
        "description": "min=0.426, mean=0.753, max=0.969, sum=4.52 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "J1-Grande v2 beta (17B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.6017824615646595,
        "description": "min=0.333, mean=0.602, max=0.767, sum=3.611 (6)",
        "style": {},
        "markdown": false
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Jumbo (178B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5329256754326485,
        "description": "min=0.241, mean=0.533, max=0.715, sum=3.198 (6)",
        "style": {},
        "markdown": false
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 3256.851718945114,
        "description": "min=352.627, mean=3256.852, max=5999.966, sum=19541.11 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Grande (17B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5925241942233298,
        "description": "min=0.322, mean=0.593, max=0.762, sum=3.555 (6)",
        "style": {},
        "markdown": false
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Jurassic-2 Large (7.5B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.6387153068049641,
        "description": "min=0.343, mean=0.639, max=0.81, sum=3.832 (6)",
        "style": {},
        "markdown": false
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1374.2057250112794,
        "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B)\u2620",
        "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "markdown": false
      },
      {
        "value": 0.5972066883968664,
        "description": "min=0.336, mean=0.597, max=0.874, sum=3.583 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 2.9107060307669976,
        "description": "min=0.771, mean=2.911, max=9.758, sum=17.464 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 4398.179624638534,
        "description": "min=426.794, mean=4398.18, max=8191.98, sum=26389.078 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 24.407303790787452,
        "description": "min=0.011, mean=24.407, max=128.85, sum=146.444 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "BLOOM (176B)\u2620",
        "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "markdown": false
      },
      {
        "value": 0.5705008762275305,
        "description": "min=0.269, mean=0.571, max=0.828, sum=3.423 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.9687673335811681,
        "description": "min=0.628, mean=0.969, max=1.172, sum=5.813 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1376.4098097975045,
        "description": "min=378.692, mean=1376.41, max=2048.999, sum=8258.459 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "Cohere xlarge v20220609 (52.4B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.7568403374591455,
        "description": "min=0.565, mean=0.757, max=0.936, sum=2.271 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.6536378630351761,
        "description": "min=0.471, mean=0.654, max=0.944, sum=1.961 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere large v20220720 (13.1B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.8105335374648689,
        "description": "min=0.64, mean=0.811, max=0.984, sum=2.432 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.45567770648827927,
        "description": "min=0.31, mean=0.456, max=0.69, sum=1.367 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere medium v20220720 (6.1B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.8445509042661411,
        "description": "min=0.68, mean=0.845, max=1.017, sum=2.534 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.3698902792855998,
        "description": "min=0.268, mean=0.37, max=0.533, sum=1.11 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere small v20220720 (410M)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.9956816345252987,
        "description": "min=0.837, mean=0.996, max=1.182, sum=2.987 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.39354988136346974,
        "description": "min=0.283, mean=0.394, max=0.572, sum=1.181 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere xlarge v20221108 (52.4B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.741373702319429,
        "description": "min=0.544, mean=0.741, max=0.932, sum=2.224 (3)",
        "style": {},
        "markdown": false
      },
      {
        "description": "3 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere medium v20221108 (6.1B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.8579217585101606,
        "description": "min=0.711, mean=0.858, max=1.049, sum=2.574 (3)",
        "style": {},
        "markdown": false
      },
      {
        "description": "3 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1058.016029755685,
        "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere Command beta (6.1B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.8749858012544512,
        "description": "min=0.735, mean=0.875, max=1.053, sum=2.625 (3)",
        "style": {},
        "markdown": false
      },
      {
        "description": "3 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1049.3075368121931,
        "description": "min=445.514, mean=1049.308, max=2012.12, sum=3147.923 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0006386520853068,
        "description": "min=0.998, mean=1.001, max=1.004, sum=3.002 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Cohere Command beta (52.4B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.7814220850110823,
        "description": "min=0.611, mean=0.781, max=0.961, sum=2.344 (3)",
        "style": {},
        "markdown": false
      },
      {
        "description": "3 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 376.6666666666667,
        "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1049.3075368121931,
        "description": "min=445.514, mean=1049.308, max=2012.12, sum=3147.923 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0006386520853068,
        "description": "min=0.998, mean=1.001, max=1.004, sum=3.002 (3)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=3 (3)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "GPT-J (6B)\u2620",
        "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "markdown": false
      },
      {
        "value": 0.4903116839910649,
        "description": "min=0.234, mean=0.49, max=0.701, sum=2.942 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.4545487957788817,
        "description": "min=0.45, mean=0.455, max=0.458, sum=2.727 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "GPT-NeoX (20B)\u2620",
        "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "markdown": false
      },
      {
        "value": 0.4659283446665785,
        "description": "min=0.212, mean=0.466, max=0.677, sum=2.796 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray",
          "font-weight": "bold"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.9020064701332329,
        "description": "min=0.85, mean=0.902, max=0.94, sum=5.412 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1407.5179849310268,
        "description": "min=408.865, mean=1407.518, max=2048.969, sum=8445.108 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "OPT (175B)\u2620",
        "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "markdown": false
      },
      {
        "value": 0.5923991536514844,
        "description": "min=0.443, mean=0.592, max=0.73, sum=3.554 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.8291283641986077,
        "description": "min=0.751, mean=0.829, max=0.884, sum=4.975 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1442.1907989529147,
        "description": "min=438.952, mean=1442.191, max=2048.976, sum=8653.145 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "OPT (66B)\u2620",
        "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "markdown": false
      },
      {
        "value": 0.617650458554565,
        "description": "min=0.468, mean=0.618, max=0.756, sum=3.706 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.4954892173905541,
        "description": "min=0.323, mean=0.495, max=0.782, sum=2.973 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1442.1907989529147,
        "description": "min=438.952, mean=1442.191, max=2048.976, sum=8653.145 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "TNLG v2 (530B)\u2620",
        "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "markdown": false
      },
      {
        "value": 0.6102107496083775,
        "description": "min=0.319, mean=0.61, max=0.872, sum=3.661 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1441.579879002146,
        "description": "min=438.905, mean=1441.58, max=2047.976, sum=8649.479 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.007348234199533665,
        "description": "min=0, mean=0.007, max=0.02, sum=0.044 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B)\u2620",
        "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "markdown": false
      },
      {
        "value": 0.7043563640119105,
        "description": "min=0.418, mean=0.704, max=0.981, sum=4.226 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1441.579879002146,
        "description": "min=438.905, mean=1441.58, max=2047.976, sum=8649.479 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 0.007348234199533665,
        "description": "min=0, mean=0.007, max=0.02, sum=0.044 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
        "style": {
          "color": "lightgray"
        },
        "markdown": false,
        "contamination_level": "strong"
      }
    ],
    [
      {
        "value": "davinci (175B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.7130778918416715,
        "description": "min=0.515, mean=0.713, max=0.979, sum=4.278 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.22648630444649456,
        "description": "min=0.205, mean=0.226, max=0.239, sum=1.359 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.789139881233082,
        "description": "min=0.587, mean=0.789, max=1.054, sum=4.735 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.10946915104340038,
        "description": "min=0.091, mean=0.109, max=0.12, sum=0.657 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.8657412068723543,
        "description": "min=0.687, mean=0.866, max=1.123, sum=5.194 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.12766683943867405,
        "description": "min=0.118, mean=0.128, max=0.134, sum=0.766 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.9604306414992282,
        "description": "min=0.823, mean=0.96, max=1.212, sum=5.763 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.1423994499242065,
        "description": "min=0.14, mean=0.142, max=0.144, sum=0.854 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5757934583803997,
        "description": "min=0.205, mean=0.576, max=0.863, sum=3.455 (6)",
        "style": {},
        "markdown": false
      },
      {
        "description": "6 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2476.021535372013,
        "description": "min=447.971, mean=2476.022, max=4000.966, sum=14856.129 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5776114680706049,
        "description": "min=0.214, mean=0.578, max=0.827, sum=3.466 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.27909842959569836,
        "description": "min=0.189, mean=0.279, max=0.347, sum=1.675 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2476.021535372013,
        "description": "min=447.971, mean=2476.022, max=4000.966, sum=14856.129 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.9685573509261866,
        "description": "min=0.677, mean=0.969, max=1.275, sum=5.811 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.14748904771651317,
        "description": "min=0.133, mean=0.147, max=0.156, sum=0.885 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001",
        "description": "",
        "markdown": false
      },
      {
        "value": 1.103368716007582,
        "description": "min=0.814, mean=1.103, max=1.435, sum=6.62 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.15499952592827024,
        "description": "min=0.132, mean=0.155, max=0.169, sum=0.93 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001",
        "description": "",
        "markdown": false
      },
      {
        "value": 1.610207406363304,
        "description": "min=1.156, mean=1.61, max=2.003, sum=9.661 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.10754665397556828,
        "description": "min=0.087, mean=0.108, max=0.12, sum=0.645 (6)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 492.0,
        "description": "min=28, mean=492, max=1000, sum=2952 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1442.1915224110446,
        "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (6)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=6 (6)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile.tex"
    },
    {
      "text": "JSON",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile.json"
    }
  ],
  "name": "the_pile"
}