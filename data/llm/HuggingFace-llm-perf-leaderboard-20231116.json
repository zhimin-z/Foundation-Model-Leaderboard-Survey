[
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"68.68**",
        "Decode Throughput (tokens\/s)":15.52,
        "E2E Throughput (tokens\/s)":15.5,
        "Prefill Latency (s)":0.176,
        "E2E Latency (s)":64.6,
        "Allocated Memory (MB)":25613,
        "Reserved Memory (MB)":31715,
        "Used Memory (MB)":33191,
        "Energy (tokens\/kWh)":195312.0
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"68.68**",
        "Decode Throughput (tokens\/s)":15.57,
        "E2E Throughput (tokens\/s)":15.5,
        "Prefill Latency (s)":0.192,
        "E2E Latency (s)":64.4,
        "Allocated Memory (MB)":21590,
        "Reserved Memory (MB)":21973,
        "Used Memory (MB)":23447,
        "Energy (tokens\/kWh)":162866.0
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"68.68**",
        "Decode Throughput (tokens\/s)":15.9,
        "E2E Throughput (tokens\/s)":15.8,
        "Prefill Latency (s)":0.192,
        "E2E Latency (s)":63.1,
        "Allocated Memory (MB)":21590,
        "Reserved Memory (MB)":21973,
        "Used Memory (MB)":23447,
        "Energy (tokens\/kWh)":168067.0
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":68.68,
        "Decode Throughput (tokens\/s)":18.39,
        "E2E Throughput (tokens\/s)":18.3,
        "Prefill Latency (s)":0.125,
        "E2E Latency (s)":54.5,
        "Allocated Memory (MB)":69670,
        "Reserved Memory (MB)":69950,
        "Used Memory (MB)":71424,
        "Energy (tokens\/kWh)":165562.0
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":68.68,
        "Decode Throughput (tokens\/s)":18.36,
        "E2E Throughput (tokens\/s)":18.3,
        "Prefill Latency (s)":0.131,
        "E2E Latency (s)":54.6,
        "Allocated Memory (MB)":69670,
        "Reserved Memory (MB)":69950,
        "Used Memory (MB)":71424,
        "Energy (tokens\/kWh)":165289.0
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"Yi",
        "Size":34.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"68.68**",
        "Decode Throughput (tokens\/s)":19.48,
        "E2E Throughput (tokens\/s)":19.4,
        "Prefill Latency (s)":0.16,
        "E2E Latency (s)":51.5,
        "Allocated Memory (MB)":20448,
        "Reserved Memory (MB)":20931,
        "Used Memory (MB)":22407,
        "Energy (tokens\/kWh)":208333.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"57.98**",
        "Decode Throughput (tokens\/s)":14.15,
        "E2E Throughput (tokens\/s)":14.1,
        "Prefill Latency (s)":0.122,
        "E2E Latency (s)":70.8,
        "Allocated Memory (MB)":16273,
        "Reserved Memory (MB)":18679,
        "Used Memory (MB)":20153,
        "Energy (tokens\/kWh)":165016.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"57.98**",
        "Decode Throughput (tokens\/s)":14.29,
        "E2E Throughput (tokens\/s)":14.3,
        "Prefill Latency (s)":0.121,
        "E2E Latency (s)":70.1,
        "Allocated Memory (MB)":16273,
        "Reserved Memory (MB)":18679,
        "Used Memory (MB)":20153,
        "Energy (tokens\/kWh)":162601.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"57.98**",
        "Decode Throughput (tokens\/s)":17.04,
        "E2E Throughput (tokens\/s)":17.0,
        "Prefill Latency (s)":0.107,
        "E2E Latency (s)":58.8,
        "Allocated Memory (MB)":16593,
        "Reserved Memory (MB)":19834,
        "Used Memory (MB)":21310,
        "Energy (tokens\/kWh)":206611.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"57.98**",
        "Decode Throughput (tokens\/s)":17.21,
        "E2E Throughput (tokens\/s)":17.2,
        "Prefill Latency (s)":0.103,
        "E2E Latency (s)":58.2,
        "Allocated Memory (MB)":15676,
        "Reserved Memory (MB)":18918,
        "Used Memory (MB)":20394,
        "Energy (tokens\/kWh)":202429.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":57.98,
        "Decode Throughput (tokens\/s)":18.11,
        "E2E Throughput (tokens\/s)":18.1,
        "Prefill Latency (s)":0.0811,
        "E2E Latency (s)":55.3,
        "Allocated Memory (MB)":43749,
        "Reserved Memory (MB)":46898,
        "Used Memory (MB)":48372,
        "Energy (tokens\/kWh)":167785.0
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Size":20.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":57.98,
        "Decode Throughput (tokens\/s)":18.21,
        "E2E Throughput (tokens\/s)":18.2,
        "Prefill Latency (s)":0.0837,
        "E2E Latency (s)":55.0,
        "Allocated Memory (MB)":43749,
        "Reserved Memory (MB)":46898,
        "Used Memory (MB)":48372,
        "Energy (tokens\/kWh)":167224.0
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":68.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"56.25**",
        "Decode Throughput (tokens\/s)":10.81,
        "E2E Throughput (tokens\/s)":10.8,
        "Prefill Latency (s)":0.382,
        "E2E Latency (s)":92.9,
        "Allocated Memory (MB)":40602,
        "Reserved Memory (MB)":41219,
        "Used Memory (MB)":42693,
        "Energy (tokens\/kWh)":94339.0
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":68.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"56.25**",
        "Decode Throughput (tokens\/s)":12.58,
        "E2E Throughput (tokens\/s)":12.5,
        "Prefill Latency (s)":0.321,
        "E2E Latency (s)":79.8,
        "Allocated Memory (MB)":38175,
        "Reserved Memory (MB)":38717,
        "Used Memory (MB)":40193,
        "Energy (tokens\/kWh)":116009.0
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":68.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"56.25**",
        "Decode Throughput (tokens\/s)":13.21,
        "E2E Throughput (tokens\/s)":13.2,
        "Prefill Latency (s)":0.324,
        "E2E Latency (s)":76.0,
        "Allocated Memory (MB)":40080,
        "Reserved Memory (MB)":40621,
        "Used Memory (MB)":42097,
        "Energy (tokens\/kWh)":141643.0
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"54.62**",
        "Decode Throughput (tokens\/s)":11.52,
        "E2E Throughput (tokens\/s)":11.5,
        "Prefill Latency (s)":0.364,
        "E2E Latency (s)":87.2,
        "Allocated Memory (MB)":44280,
        "Reserved Memory (MB)":53389,
        "Used Memory (MB)":54863,
        "Energy (tokens\/kWh)":107066.0
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"54.62**",
        "Decode Throughput (tokens\/s)":12.77,
        "E2E Throughput (tokens\/s)":12.7,
        "Prefill Latency (s)":0.303,
        "E2E Latency (s)":78.6,
        "Allocated Memory (MB)":41896,
        "Reserved Memory (MB)":53676,
        "Used Memory (MB)":55152,
        "Energy (tokens\/kWh)":119474.0
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"54.62**",
        "Decode Throughput (tokens\/s)":13.93,
        "E2E Throughput (tokens\/s)":13.9,
        "Prefill Latency (s)":0.31,
        "E2E Latency (s)":72.1,
        "Allocated Memory (MB)":43362,
        "Reserved Memory (MB)":55144,
        "Used Memory (MB)":56620,
        "Energy (tokens\/kWh)":150375.0
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"53.31**",
        "Decode Throughput (tokens\/s)":11.32,
        "E2E Throughput (tokens\/s)":11.3,
        "Prefill Latency (s)":0.362,
        "E2E Latency (s)":88.7,
        "Allocated Memory (MB)":44280,
        "Reserved Memory (MB)":53389,
        "Used Memory (MB)":54863,
        "Energy (tokens\/kWh)":109051.0
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"53.31**",
        "Decode Throughput (tokens\/s)":12.69,
        "E2E Throughput (tokens\/s)":12.6,
        "Prefill Latency (s)":0.308,
        "E2E Latency (s)":79.1,
        "Allocated Memory (MB)":41896,
        "Reserved Memory (MB)":53676,
        "Used Memory (MB)":55152,
        "Energy (tokens\/kWh)":117647.0
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":65.29,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"53.31**",
        "Decode Throughput (tokens\/s)":13.93,
        "E2E Throughput (tokens\/s)":13.9,
        "Prefill Latency (s)":0.309,
        "E2E Latency (s)":72.1,
        "Allocated Memory (MB)":43362,
        "Reserved Memory (MB)":55144,
        "Used Memory (MB)":56620,
        "Energy (tokens\/kWh)":149700.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"53.06**",
        "Decode Throughput (tokens\/s)":28.94,
        "E2E Throughput (tokens\/s)":28.9,
        "Prefill Latency (s)":0.0467,
        "E2E Latency (s)":34.6,
        "Allocated Memory (MB)":4506,
        "Reserved Memory (MB)":4668,
        "Used Memory (MB)":6142,
        "Energy (tokens\/kWh)":398406.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"53.06**",
        "Decode Throughput (tokens\/s)":29.36,
        "E2E Throughput (tokens\/s)":29.3,
        "Prefill Latency (s)":0.0453,
        "E2E Latency (s)":34.1,
        "Allocated Memory (MB)":4506,
        "Reserved Memory (MB)":4668,
        "Used Memory (MB)":6142,
        "Energy (tokens\/kWh)":401606.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"53.06**",
        "Decode Throughput (tokens\/s)":29.89,
        "E2E Throughput (tokens\/s)":29.9,
        "Prefill Latency (s)":0.0447,
        "E2E Latency (s)":33.5,
        "Allocated Memory (MB)":6284,
        "Reserved Memory (MB)":6335,
        "Used Memory (MB)":7811,
        "Energy (tokens\/kWh)":404858.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":53.06,
        "Decode Throughput (tokens\/s)":31.88,
        "E2E Throughput (tokens\/s)":31.8,
        "Prefill Latency (s)":0.0345,
        "E2E Latency (s)":31.4,
        "Allocated Memory (MB)":13608,
        "Reserved Memory (MB)":13650,
        "Used Memory (MB)":15124,
        "Energy (tokens\/kWh)":373134.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"53.06**",
        "Decode Throughput (tokens\/s)":35.38,
        "E2E Throughput (tokens\/s)":35.3,
        "Prefill Latency (s)":0.0359,
        "E2E Latency (s)":28.3,
        "Allocated Memory (MB)":4384,
        "Reserved Memory (MB)":4546,
        "Used Memory (MB)":6022,
        "Energy (tokens\/kWh)":462962.0
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"Yi",
        "Size":6.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":53.06,
        "Decode Throughput (tokens\/s)":39.26,
        "E2E Throughput (tokens\/s)":39.2,
        "Prefill Latency (s)":0.0286,
        "E2E Latency (s)":25.5,
        "Allocated Memory (MB)":12433,
        "Reserved Memory (MB)":12593,
        "Used Memory (MB)":14067,
        "Energy (tokens\/kWh)":450450.0
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":52.11,
        "Decode Throughput (tokens\/s)":12.82,
        "E2E Throughput (tokens\/s)":12.8,
        "Prefill Latency (s)":0.0877,
        "E2E Latency (s)":78.1,
        "Allocated Memory (MB)":28858,
        "Reserved Memory (MB)":30664,
        "Used Memory (MB)":32138,
        "Energy (tokens\/kWh)":149925.0
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":52.11,
        "Decode Throughput (tokens\/s)":12.87,
        "E2E Throughput (tokens\/s)":12.9,
        "Prefill Latency (s)":0.089,
        "E2E Latency (s)":77.8,
        "Allocated Memory (MB)":28858,
        "Reserved Memory (MB)":30664,
        "Used Memory (MB)":32138,
        "Energy (tokens\/kWh)":151515.0
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":52.11,
        "Decode Throughput (tokens\/s)":13.57,
        "E2E Throughput (tokens\/s)":13.6,
        "Prefill Latency (s)":0.0871,
        "E2E Latency (s)":73.8,
        "Allocated Memory (MB)":28858,
        "Reserved Memory (MB)":30647,
        "Used Memory (MB)":32121,
        "Energy (tokens\/kWh)":156250.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"50.32**",
        "Decode Throughput (tokens\/s)":26.92,
        "E2E Throughput (tokens\/s)":26.9,
        "Prefill Latency (s)":0.0519,
        "E2E Latency (s)":37.2,
        "Allocated Memory (MB)":5370,
        "Reserved Memory (MB)":5559,
        "Used Memory (MB)":7033,
        "Energy (tokens\/kWh)":358422.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"50.32**",
        "Decode Throughput (tokens\/s)":27.07,
        "E2E Throughput (tokens\/s)":27.0,
        "Prefill Latency (s)":0.0532,
        "E2E Latency (s)":37.0,
        "Allocated Memory (MB)":5370,
        "Reserved Memory (MB)":5559,
        "Used Memory (MB)":7033,
        "Energy (tokens\/kWh)":331125.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"50.32**",
        "Decode Throughput (tokens\/s)":32.94,
        "E2E Throughput (tokens\/s)":32.9,
        "Prefill Latency (s)":0.0454,
        "E2E Latency (s)":30.4,
        "Allocated Memory (MB)":6120,
        "Reserved Memory (MB)":6337,
        "Used Memory (MB)":7813,
        "Energy (tokens\/kWh)":436681.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"50.32**",
        "Decode Throughput (tokens\/s)":33.27,
        "E2E Throughput (tokens\/s)":33.2,
        "Prefill Latency (s)":0.0453,
        "E2E Latency (s)":30.1,
        "Allocated Memory (MB)":5176,
        "Reserved Memory (MB)":5391,
        "Used Memory (MB)":6867,
        "Energy (tokens\/kWh)":413223.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":50.32,
        "Decode Throughput (tokens\/s)":34.65,
        "E2E Throughput (tokens\/s)":34.6,
        "Prefill Latency (s)":0.0364,
        "E2E Latency (s)":28.9,
        "Allocated Memory (MB)":15381,
        "Reserved Memory (MB)":15651,
        "Used Memory (MB)":17124,
        "Energy (tokens\/kWh)":383141.0
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Size":7.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":50.32,
        "Decode Throughput (tokens\/s)":35.13,
        "E2E Throughput (tokens\/s)":35.1,
        "Prefill Latency (s)":0.0373,
        "E2E Latency (s)":28.5,
        "Allocated Memory (MB)":15381,
        "Reserved Memory (MB)":15651,
        "Used Memory (MB)":17124,
        "Energy (tokens\/kWh)":380228.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"49.71**",
        "Decode Throughput (tokens\/s)":15.57,
        "E2E Throughput (tokens\/s)":15.5,
        "Prefill Latency (s)":0.185,
        "E2E Latency (s)":64.4,
        "Allocated Memory (MB)":23006,
        "Reserved Memory (MB)":26357,
        "Used Memory (MB)":27830,
        "Energy (tokens\/kWh)":167785.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":49.71,
        "Decode Throughput (tokens\/s)":17.52,
        "E2E Throughput (tokens\/s)":17.5,
        "Prefill Latency (s)":0.127,
        "E2E Latency (s)":57.2,
        "Allocated Memory (MB)":69241,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890,
        "Energy (tokens\/kWh)":157977.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":49.71,
        "Decode Throughput (tokens\/s)":17.49,
        "E2E Throughput (tokens\/s)":17.5,
        "Prefill Latency (s)":0.13,
        "E2E Latency (s)":57.3,
        "Allocated Memory (MB)":69241,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890,
        "Energy (tokens\/kWh)":157728.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":49.71,
        "Decode Throughput (tokens\/s)":17.77,
        "E2E Throughput (tokens\/s)":17.7,
        "Prefill Latency (s)":0.126,
        "E2E Latency (s)":56.4,
        "Allocated Memory (MB)":69241,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890,
        "Energy (tokens\/kWh)":161030.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"49.71**",
        "Decode Throughput (tokens\/s)":18.75,
        "E2E Throughput (tokens\/s)":18.7,
        "Prefill Latency (s)":0.16,
        "E2E Latency (s)":53.5,
        "Allocated Memory (MB)":22110,
        "Reserved Memory (MB)":26128,
        "Used Memory (MB)":27604,
        "Energy (tokens\/kWh)":190839.0
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":32.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"49.71**",
        "Decode Throughput (tokens\/s)":19.0,
        "E2E Throughput (tokens\/s)":18.9,
        "Prefill Latency (s)":0.164,
        "E2E Latency (s)":52.8,
        "Allocated Memory (MB)":23298,
        "Reserved Memory (MB)":27315,
        "Used Memory (MB)":28791,
        "Energy (tokens\/kWh)":218340.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"46.89**",
        "Decode Throughput (tokens\/s)":23.08,
        "E2E Throughput (tokens\/s)":23.0,
        "Prefill Latency (s)":0.0793,
        "E2E Latency (s)":43.4,
        "Allocated Memory (MB)":9996,
        "Reserved Memory (MB)":11542,
        "Used Memory (MB)":13016,
        "Energy (tokens\/kWh)":284090.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"46.89**",
        "Decode Throughput (tokens\/s)":27.01,
        "E2E Throughput (tokens\/s)":27.0,
        "Prefill Latency (s)":0.0702,
        "E2E Latency (s)":37.1,
        "Allocated Memory (MB)":10550,
        "Reserved Memory (MB)":12457,
        "Used Memory (MB)":13932,
        "Energy (tokens\/kWh)":344827.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"46.89**",
        "Decode Throughput (tokens\/s)":28.14,
        "E2E Throughput (tokens\/s)":28.1,
        "Prefill Latency (s)":0.0692,
        "E2E Latency (s)":35.6,
        "Allocated Memory (MB)":9637,
        "Reserved Memory (MB)":11544,
        "Used Memory (MB)":13020,
        "Energy (tokens\/kWh)":323624.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":46.89,
        "Decode Throughput (tokens\/s)":29.72,
        "E2E Throughput (tokens\/s)":29.7,
        "Prefill Latency (s)":0.0558,
        "E2E Latency (s)":33.7,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622,
        "Energy (tokens\/kWh)":280112.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":46.89,
        "Decode Throughput (tokens\/s)":29.99,
        "E2E Throughput (tokens\/s)":29.9,
        "Prefill Latency (s)":0.0539,
        "E2E Latency (s)":33.4,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622,
        "Energy (tokens\/kWh)":277008.0
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":46.89,
        "Decode Throughput (tokens\/s)":33.62,
        "E2E Throughput (tokens\/s)":33.6,
        "Prefill Latency (s)":0.0514,
        "E2E Latency (s)":29.8,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30104,
        "Used Memory (MB)":31578,
        "Energy (tokens\/kWh)":300300.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"46.87**",
        "Decode Throughput (tokens\/s)":23.46,
        "E2E Throughput (tokens\/s)":23.4,
        "Prefill Latency (s)":0.0795,
        "E2E Latency (s)":42.7,
        "Allocated Memory (MB)":9996,
        "Reserved Memory (MB)":11542,
        "Used Memory (MB)":13016,
        "Energy (tokens\/kWh)":290697.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"46.87**",
        "Decode Throughput (tokens\/s)":28.14,
        "E2E Throughput (tokens\/s)":28.1,
        "Prefill Latency (s)":0.0693,
        "E2E Latency (s)":35.6,
        "Allocated Memory (MB)":9637,
        "Reserved Memory (MB)":11544,
        "Used Memory (MB)":13020,
        "Energy (tokens\/kWh)":322580.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"46.87**",
        "Decode Throughput (tokens\/s)":28.88,
        "E2E Throughput (tokens\/s)":28.8,
        "Prefill Latency (s)":0.0702,
        "E2E Latency (s)":34.7,
        "Allocated Memory (MB)":10550,
        "Reserved Memory (MB)":12457,
        "Used Memory (MB)":13932,
        "Energy (tokens\/kWh)":355871.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":46.87,
        "Decode Throughput (tokens\/s)":29.11,
        "E2E Throughput (tokens\/s)":29.1,
        "Prefill Latency (s)":0.0524,
        "E2E Latency (s)":34.4,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622,
        "Energy (tokens\/kWh)":289017.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":46.87,
        "Decode Throughput (tokens\/s)":29.55,
        "E2E Throughput (tokens\/s)":29.5,
        "Prefill Latency (s)":0.0539,
        "E2E Latency (s)":33.9,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622,
        "Energy (tokens\/kWh)":276243.0
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":46.87,
        "Decode Throughput (tokens\/s)":33.17,
        "E2E Throughput (tokens\/s)":33.1,
        "Prefill Latency (s)":0.0508,
        "E2E Latency (s)":30.2,
        "Allocated Memory (MB)":28305,
        "Reserved Memory (MB)":30104,
        "Used Memory (MB)":31578,
        "Energy (tokens\/kWh)":297619.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"45.1**",
        "Decode Throughput (tokens\/s)":28.45,
        "E2E Throughput (tokens\/s)":28.4,
        "Prefill Latency (s)":0.0484,
        "E2E Latency (s)":35.2,
        "Allocated Memory (MB)":6178,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7800,
        "Energy (tokens\/kWh)":354609.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"45.1**",
        "Decode Throughput (tokens\/s)":28.61,
        "E2E Throughput (tokens\/s)":28.6,
        "Prefill Latency (s)":0.0485,
        "E2E Latency (s)":35.0,
        "Allocated Memory (MB)":6178,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7800,
        "Energy (tokens\/kWh)":383141.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"45.1**",
        "Decode Throughput (tokens\/s)":34.3,
        "E2E Throughput (tokens\/s)":34.2,
        "Prefill Latency (s)":0.0435,
        "E2E Latency (s)":29.2,
        "Allocated Memory (MB)":6017,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7802,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"45.1**",
        "Decode Throughput (tokens\/s)":35.27,
        "E2E Throughput (tokens\/s)":35.2,
        "Prefill Latency (s)":0.0444,
        "E2E Latency (s)":28.4,
        "Allocated Memory (MB)":6743,
        "Reserved Memory (MB)":7054,
        "Used Memory (MB)":8530,
        "Energy (tokens\/kWh)":454545.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":45.1,
        "Decode Throughput (tokens\/s)":38.22,
        "E2E Throughput (tokens\/s)":38.2,
        "Prefill Latency (s)":0.0344,
        "E2E Latency (s)":26.2,
        "Allocated Memory (MB)":15456,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971,
        "Energy (tokens\/kWh)":411522.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":45.1,
        "Decode Throughput (tokens\/s)":38.37,
        "E2E Throughput (tokens\/s)":38.3,
        "Prefill Latency (s)":0.0349,
        "E2E Latency (s)":26.1,
        "Allocated Memory (MB)":15456,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971,
        "Energy (tokens\/kWh)":396825.0
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":45.1,
        "Decode Throughput (tokens\/s)":42.43,
        "E2E Throughput (tokens\/s)":42.4,
        "Prefill Latency (s)":0.0326,
        "E2E Latency (s)":23.6,
        "Allocated Memory (MB)":15456,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971,
        "Energy (tokens\/kWh)":440528.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"44.83**",
        "Decode Throughput (tokens\/s)":22.98,
        "E2E Throughput (tokens\/s)":22.9,
        "Prefill Latency (s)":0.0791,
        "E2E Latency (s)":43.6,
        "Allocated Memory (MB)":9954,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974,
        "Energy (tokens\/kWh)":287356.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"44.83**",
        "Decode Throughput (tokens\/s)":22.93,
        "E2E Throughput (tokens\/s)":22.9,
        "Prefill Latency (s)":0.0807,
        "E2E Latency (s)":43.7,
        "Allocated Memory (MB)":9954,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974,
        "Energy (tokens\/kWh)":271002.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"44.83**",
        "Decode Throughput (tokens\/s)":26.79,
        "E2E Throughput (tokens\/s)":26.7,
        "Prefill Latency (s)":0.0694,
        "E2E Latency (s)":37.4,
        "Allocated Memory (MB)":9595,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978,
        "Energy (tokens\/kWh)":324675.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"44.83**",
        "Decode Throughput (tokens\/s)":28.47,
        "E2E Throughput (tokens\/s)":28.4,
        "Prefill Latency (s)":0.0699,
        "E2E Latency (s)":35.2,
        "Allocated Memory (MB)":10508,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891,
        "Energy (tokens\/kWh)":353356.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":44.83,
        "Decode Throughput (tokens\/s)":30.35,
        "E2E Throughput (tokens\/s)":30.3,
        "Prefill Latency (s)":0.054,
        "E2E Latency (s)":33.0,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":289017.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":44.83,
        "Decode Throughput (tokens\/s)":30.35,
        "E2E Throughput (tokens\/s)":30.3,
        "Prefill Latency (s)":0.0534,
        "E2E Latency (s)":33.0,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":282485.0
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":44.83,
        "Decode Throughput (tokens\/s)":32.63,
        "E2E Throughput (tokens\/s)":32.6,
        "Prefill Latency (s)":0.0512,
        "E2E Latency (s)":30.7,
        "Allocated Memory (MB)":28263,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536,
        "Energy (tokens\/kWh)":300300.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"44.81**",
        "Decode Throughput (tokens\/s)":23.08,
        "E2E Throughput (tokens\/s)":23.0,
        "Prefill Latency (s)":0.079,
        "E2E Latency (s)":43.4,
        "Allocated Memory (MB)":9954,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974,
        "Energy (tokens\/kWh)":288184.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"44.81**",
        "Decode Throughput (tokens\/s)":27.76,
        "E2E Throughput (tokens\/s)":27.7,
        "Prefill Latency (s)":0.0715,
        "E2E Latency (s)":36.1,
        "Allocated Memory (MB)":10508,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891,
        "Energy (tokens\/kWh)":352112.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"44.81**",
        "Decode Throughput (tokens\/s)":28.23,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":0.0706,
        "E2E Latency (s)":35.5,
        "Allocated Memory (MB)":9595,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978,
        "Energy (tokens\/kWh)":324675.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":44.81,
        "Decode Throughput (tokens\/s)":30.17,
        "E2E Throughput (tokens\/s)":30.1,
        "Prefill Latency (s)":0.0532,
        "E2E Latency (s)":33.2,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":279329.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":44.81,
        "Decode Throughput (tokens\/s)":30.63,
        "E2E Throughput (tokens\/s)":30.6,
        "Prefill Latency (s)":0.054,
        "E2E Latency (s)":32.7,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":279329.0
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":44.81,
        "Decode Throughput (tokens\/s)":32.95,
        "E2E Throughput (tokens\/s)":32.9,
        "Prefill Latency (s)":0.051,
        "E2E Latency (s)":30.4,
        "Allocated Memory (MB)":28263,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536,
        "Energy (tokens\/kWh)":306748.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"43.43**",
        "Decode Throughput (tokens\/s)":28.77,
        "E2E Throughput (tokens\/s)":28.7,
        "Prefill Latency (s)":0.047,
        "E2E Latency (s)":34.8,
        "Allocated Memory (MB)":5615,
        "Reserved Memory (MB)":5760,
        "Used Memory (MB)":7234,
        "Energy (tokens\/kWh)":387596.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"43.43**",
        "Decode Throughput (tokens\/s)":29.03,
        "E2E Throughput (tokens\/s)":29.0,
        "Prefill Latency (s)":0.0482,
        "E2E Latency (s)":34.5,
        "Allocated Memory (MB)":5615,
        "Reserved Memory (MB)":5760,
        "Used Memory (MB)":7234,
        "Energy (tokens\/kWh)":369003.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"43.43**",
        "Decode Throughput (tokens\/s)":31.59,
        "E2E Throughput (tokens\/s)":31.5,
        "Prefill Latency (s)":0.0456,
        "E2E Latency (s)":31.7,
        "Allocated Memory (MB)":5615,
        "Reserved Memory (MB)":5748,
        "Used Memory (MB)":7222,
        "Energy (tokens\/kWh)":401606.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"43.43**",
        "Decode Throughput (tokens\/s)":35.14,
        "E2E Throughput (tokens\/s)":35.1,
        "Prefill Latency (s)":0.042,
        "E2E Latency (s)":28.5,
        "Allocated Memory (MB)":5455,
        "Reserved Memory (MB)":5750,
        "Used Memory (MB)":7226,
        "Energy (tokens\/kWh)":421940.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"43.43**",
        "Decode Throughput (tokens\/s)":35.27,
        "E2E Throughput (tokens\/s)":35.2,
        "Prefill Latency (s)":0.0433,
        "E2E Latency (s)":28.4,
        "Allocated Memory (MB)":6180,
        "Reserved Memory (MB)":6478,
        "Used Memory (MB)":7953,
        "Energy (tokens\/kWh)":462962.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":43.43,
        "Decode Throughput (tokens\/s)":37.64,
        "E2E Throughput (tokens\/s)":37.6,
        "Prefill Latency (s)":0.0332,
        "E2E Latency (s)":26.6,
        "Allocated Memory (MB)":14895,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415,
        "Energy (tokens\/kWh)":423728.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":43.43,
        "Decode Throughput (tokens\/s)":38.66,
        "E2E Throughput (tokens\/s)":38.6,
        "Prefill Latency (s)":0.034,
        "E2E Latency (s)":25.9,
        "Allocated Memory (MB)":14895,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415,
        "Energy (tokens\/kWh)":395256.0
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":43.43,
        "Decode Throughput (tokens\/s)":42.25,
        "E2E Throughput (tokens\/s)":42.2,
        "Prefill Latency (s)":0.032,
        "E2E Latency (s)":23.7,
        "Allocated Memory (MB)":14895,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415,
        "Energy (tokens\/kWh)":444444.0
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"41.6**",
        "Decode Throughput (tokens\/s)":33.37,
        "E2E Throughput (tokens\/s)":33.3,
        "Prefill Latency (s)":0.0354,
        "E2E Latency (s)":30.0,
        "Allocated Memory (MB)":1600,
        "Reserved Memory (MB)":1656,
        "Used Memory (MB)":3130,
        "Energy (tokens\/kWh)":518134.0
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"41.6**",
        "Decode Throughput (tokens\/s)":33.6,
        "E2E Throughput (tokens\/s)":33.6,
        "Prefill Latency (s)":0.0352,
        "E2E Latency (s)":29.8,
        "Allocated Memory (MB)":1600,
        "Reserved Memory (MB)":1656,
        "Used Memory (MB)":3130,
        "Energy (tokens\/kWh)":515463.0
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":41.6,
        "Decode Throughput (tokens\/s)":37.77,
        "E2E Throughput (tokens\/s)":37.7,
        "Prefill Latency (s)":0.0264,
        "E2E Latency (s)":26.5,
        "Allocated Memory (MB)":3329,
        "Reserved Memory (MB)":3399,
        "Used Memory (MB)":4873,
        "Energy (tokens\/kWh)":552486.0
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"mixformer-sequential",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":41.6,
        "Decode Throughput (tokens\/s)":38.8,
        "E2E Throughput (tokens\/s)":38.8,
        "Prefill Latency (s)":0.0255,
        "E2E Latency (s)":25.8,
        "Allocated Memory (MB)":3329,
        "Reserved Memory (MB)":3399,
        "Used Memory (MB)":4873,
        "Energy (tokens\/kWh)":581395.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"41.37**",
        "Decode Throughput (tokens\/s)":22.77,
        "E2E Throughput (tokens\/s)":22.7,
        "Prefill Latency (s)":0.0807,
        "E2E Latency (s)":44.0,
        "Allocated Memory (MB)":9954,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974,
        "Energy (tokens\/kWh)":268817.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"41.37**",
        "Decode Throughput (tokens\/s)":22.82,
        "E2E Throughput (tokens\/s)":22.8,
        "Prefill Latency (s)":0.0794,
        "E2E Latency (s)":43.9,
        "Allocated Memory (MB)":9954,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974,
        "Energy (tokens\/kWh)":281690.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"41.37**",
        "Decode Throughput (tokens\/s)":25.3,
        "E2E Throughput (tokens\/s)":25.3,
        "Prefill Latency (s)":0.0775,
        "E2E Latency (s)":39.6,
        "Allocated Memory (MB)":9953,
        "Reserved Memory (MB)":11452,
        "Used Memory (MB)":12926,
        "Energy (tokens\/kWh)":295857.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"41.37**",
        "Decode Throughput (tokens\/s)":28.07,
        "E2E Throughput (tokens\/s)":28.0,
        "Prefill Latency (s)":0.0695,
        "E2E Latency (s)":35.7,
        "Allocated Memory (MB)":9595,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978,
        "Energy (tokens\/kWh)":327868.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"41.37**",
        "Decode Throughput (tokens\/s)":28.23,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":0.0713,
        "E2E Latency (s)":35.5,
        "Allocated Memory (MB)":10508,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891,
        "Energy (tokens\/kWh)":358422.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":41.37,
        "Decode Throughput (tokens\/s)":29.46,
        "E2E Throughput (tokens\/s)":29.4,
        "Prefill Latency (s)":0.0546,
        "E2E Latency (s)":34.0,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":278551.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":41.37,
        "Decode Throughput (tokens\/s)":29.9,
        "E2E Throughput (tokens\/s)":29.9,
        "Prefill Latency (s)":0.0529,
        "E2E Latency (s)":33.5,
        "Allocated Memory (MB)":28264,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580,
        "Energy (tokens\/kWh)":287356.0
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":41.37,
        "Decode Throughput (tokens\/s)":33.62,
        "E2E Throughput (tokens\/s)":33.6,
        "Prefill Latency (s)":0.0524,
        "E2E Latency (s)":29.8,
        "Allocated Memory (MB)":28263,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536,
        "Energy (tokens\/kWh)":298507.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"40.69**",
        "Decode Throughput (tokens\/s)":31.89,
        "E2E Throughput (tokens\/s)":31.8,
        "Prefill Latency (s)":0.0441,
        "E2E Latency (s)":31.4,
        "Allocated Memory (MB)":2627,
        "Reserved Memory (MB)":2755,
        "Used Memory (MB)":4229,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"40.69**",
        "Decode Throughput (tokens\/s)":32.3,
        "E2E Throughput (tokens\/s)":32.3,
        "Prefill Latency (s)":0.0427,
        "E2E Latency (s)":31.0,
        "Allocated Memory (MB)":2627,
        "Reserved Memory (MB)":2755,
        "Used Memory (MB)":4229,
        "Energy (tokens\/kWh)":442477.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"40.69**",
        "Decode Throughput (tokens\/s)":40.37,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0273,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":2716,
        "Reserved Memory (MB)":2879,
        "Used Memory (MB)":4355,
        "Energy (tokens\/kWh)":549450.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"40.69**",
        "Decode Throughput (tokens\/s)":40.7,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0271,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":3172,
        "Reserved Memory (MB)":3336,
        "Used Memory (MB)":4812,
        "Energy (tokens\/kWh)":558659.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":40.69,
        "Decode Throughput (tokens\/s)":42.24,
        "E2E Throughput (tokens\/s)":42.2,
        "Prefill Latency (s)":0.0232,
        "E2E Latency (s)":23.7,
        "Allocated Memory (MB)":6458,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":555555.0
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Size":2.8,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":40.69,
        "Decode Throughput (tokens\/s)":42.78,
        "E2E Throughput (tokens\/s)":42.7,
        "Prefill Latency (s)":0.0228,
        "E2E Latency (s)":23.4,
        "Allocated Memory (MB)":6458,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":543478.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"StableLM-Alpha",
        "Size":6.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"40.31**",
        "Decode Throughput (tokens\/s)":34.65,
        "E2E Throughput (tokens\/s)":34.6,
        "Prefill Latency (s)":0.0434,
        "E2E Latency (s)":28.9,
        "Allocated Memory (MB)":5869,
        "Reserved Memory (MB)":6069,
        "Used Memory (MB)":7542,
        "Energy (tokens\/kWh)":446428.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"StableLM-Alpha",
        "Size":6.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"40.31**",
        "Decode Throughput (tokens\/s)":35.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Prefill Latency (s)":0.0442,
        "E2E Latency (s)":27.9,
        "Allocated Memory (MB)":5869,
        "Reserved Memory (MB)":6069,
        "Used Memory (MB)":7542,
        "Energy (tokens\/kWh)":432900.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"StableLM-Alpha",
        "Size":6.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":40.31,
        "Decode Throughput (tokens\/s)":42.79,
        "E2E Throughput (tokens\/s)":42.7,
        "Prefill Latency (s)":0.0302,
        "E2E Latency (s)":23.4,
        "Allocated Memory (MB)":15178,
        "Reserved Memory (MB)":15210,
        "Used Memory (MB)":16684,
        "Energy (tokens\/kWh)":442477.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"StableLM-Alpha",
        "Size":6.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":40.31,
        "Decode Throughput (tokens\/s)":43.54,
        "E2E Throughput (tokens\/s)":43.5,
        "Prefill Latency (s)":0.0316,
        "E2E Latency (s)":23.0,
        "Allocated Memory (MB)":15178,
        "Reserved Memory (MB)":15210,
        "Used Memory (MB)":16684,
        "Energy (tokens\/kWh)":429184.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.93**",
        "Decode Throughput (tokens\/s)":28.53,
        "E2E Throughput (tokens\/s)":28.5,
        "Prefill Latency (s)":0.0479,
        "E2E Latency (s)":35.1,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":370370.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.93**",
        "Decode Throughput (tokens\/s)":29.11,
        "E2E Throughput (tokens\/s)":29.1,
        "Prefill Latency (s)":0.047,
        "E2E Latency (s)":34.4,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":386100.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.93**",
        "Decode Throughput (tokens\/s)":30.81,
        "E2E Throughput (tokens\/s)":30.8,
        "Prefill Latency (s)":0.0459,
        "E2E Latency (s)":32.5,
        "Allocated Memory (MB)":5582,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188,
        "Energy (tokens\/kWh)":395256.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"39.93**",
        "Decode Throughput (tokens\/s)":34.53,
        "E2E Throughput (tokens\/s)":34.5,
        "Prefill Latency (s)":0.0434,
        "E2E Latency (s)":29.0,
        "Allocated Memory (MB)":6147,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920,
        "Energy (tokens\/kWh)":442477.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"39.93**",
        "Decode Throughput (tokens\/s)":35.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Prefill Latency (s)":0.0428,
        "E2E Latency (s)":27.9,
        "Allocated Memory (MB)":5421,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192,
        "Energy (tokens\/kWh)":444444.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":39.93,
        "Decode Throughput (tokens\/s)":37.93,
        "E2E Throughput (tokens\/s)":37.9,
        "Prefill Latency (s)":0.0334,
        "E2E Latency (s)":26.4,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":432900.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":39.93,
        "Decode Throughput (tokens\/s)":38.66,
        "E2E Throughput (tokens\/s)":38.6,
        "Prefill Latency (s)":0.034,
        "E2E Latency (s)":25.9,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":404858.0
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":39.93,
        "Decode Throughput (tokens\/s)":42.07,
        "E2E Throughput (tokens\/s)":42.0,
        "Prefill Latency (s)":0.032,
        "E2E Latency (s)":23.8,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":436681.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.91**",
        "Decode Throughput (tokens\/s)":28.29,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":0.0476,
        "E2E Latency (s)":35.4,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":373134.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.91**",
        "Decode Throughput (tokens\/s)":28.45,
        "E2E Throughput (tokens\/s)":28.4,
        "Prefill Latency (s)":0.0474,
        "E2E Latency (s)":35.2,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":371747.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"39.91**",
        "Decode Throughput (tokens\/s)":30.91,
        "E2E Throughput (tokens\/s)":30.9,
        "Prefill Latency (s)":0.0458,
        "E2E Latency (s)":32.4,
        "Allocated Memory (MB)":5582,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188,
        "Energy (tokens\/kWh)":392156.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"39.91**",
        "Decode Throughput (tokens\/s)":34.65,
        "E2E Throughput (tokens\/s)":34.6,
        "Prefill Latency (s)":0.0426,
        "E2E Latency (s)":28.9,
        "Allocated Memory (MB)":6147,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"39.91**",
        "Decode Throughput (tokens\/s)":34.77,
        "E2E Throughput (tokens\/s)":34.7,
        "Prefill Latency (s)":0.0428,
        "E2E Latency (s)":28.8,
        "Allocated Memory (MB)":5421,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192,
        "Energy (tokens\/kWh)":429184.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":39.91,
        "Decode Throughput (tokens\/s)":38.07,
        "E2E Throughput (tokens\/s)":38.0,
        "Prefill Latency (s)":0.0331,
        "E2E Latency (s)":26.3,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":429184.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":39.91,
        "Decode Throughput (tokens\/s)":38.81,
        "E2E Throughput (tokens\/s)":38.8,
        "Prefill Latency (s)":0.0339,
        "E2E Latency (s)":25.8,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":414937.0
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":39.91,
        "Decode Throughput (tokens\/s)":42.98,
        "E2E Throughput (tokens\/s)":42.9,
        "Prefill Latency (s)":0.0319,
        "E2E Latency (s)":23.3,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":462962.0
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"MPT",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.74**",
        "Decode Throughput (tokens\/s)":47.94,
        "E2E Throughput (tokens\/s)":47.8,
        "Prefill Latency (s)":0.0402,
        "E2E Latency (s)":20.9,
        "Allocated Memory (MB)":5395,
        "Reserved Memory (MB)":5481,
        "Used Memory (MB)":6955,
        "Energy (tokens\/kWh)":564971.0
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"MPT",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.74**",
        "Decode Throughput (tokens\/s)":48.88,
        "E2E Throughput (tokens\/s)":48.8,
        "Prefill Latency (s)":0.0405,
        "E2E Latency (s)":20.5,
        "Allocated Memory (MB)":5395,
        "Reserved Memory (MB)":5481,
        "Used Memory (MB)":6955,
        "Energy (tokens\/kWh)":552486.0
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"MPT",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":38.74,
        "Decode Throughput (tokens\/s)":61.08,
        "E2E Throughput (tokens\/s)":61.0,
        "Prefill Latency (s)":0.0279,
        "E2E Latency (s)":16.4,
        "Allocated Memory (MB)":14649,
        "Reserved Memory (MB)":14669,
        "Used Memory (MB)":16143,
        "Energy (tokens\/kWh)":540540.0
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"MPT",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":38.74,
        "Decode Throughput (tokens\/s)":61.83,
        "E2E Throughput (tokens\/s)":61.7,
        "Prefill Latency (s)":0.0277,
        "E2E Latency (s)":16.2,
        "Allocated Memory (MB)":14649,
        "Reserved Memory (MB)":14669,
        "Used Memory (MB)":16143,
        "Energy (tokens\/kWh)":568181.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.72**",
        "Decode Throughput (tokens\/s)":28.69,
        "E2E Throughput (tokens\/s)":28.7,
        "Prefill Latency (s)":0.0471,
        "E2E Latency (s)":34.9,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":378787.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.72**",
        "Decode Throughput (tokens\/s)":28.94,
        "E2E Throughput (tokens\/s)":28.9,
        "Prefill Latency (s)":0.0473,
        "E2E Latency (s)":34.6,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":370370.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.72**",
        "Decode Throughput (tokens\/s)":31.29,
        "E2E Throughput (tokens\/s)":31.2,
        "Prefill Latency (s)":0.0459,
        "E2E Latency (s)":32.0,
        "Allocated Memory (MB)":5582,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188,
        "Energy (tokens\/kWh)":392156.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"38.72**",
        "Decode Throughput (tokens\/s)":34.41,
        "E2E Throughput (tokens\/s)":34.4,
        "Prefill Latency (s)":0.0424,
        "E2E Latency (s)":29.1,
        "Allocated Memory (MB)":6147,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920,
        "Energy (tokens\/kWh)":460829.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"38.72**",
        "Decode Throughput (tokens\/s)":35.02,
        "E2E Throughput (tokens\/s)":35.0,
        "Prefill Latency (s)":0.0419,
        "E2E Latency (s)":28.6,
        "Allocated Memory (MB)":5421,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":38.72,
        "Decode Throughput (tokens\/s)":37.93,
        "E2E Throughput (tokens\/s)":37.9,
        "Prefill Latency (s)":0.0341,
        "E2E Latency (s)":26.4,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":418410.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":38.72,
        "Decode Throughput (tokens\/s)":38.96,
        "E2E Throughput (tokens\/s)":38.9,
        "Prefill Latency (s)":0.0349,
        "E2E Latency (s)":25.7,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":414937.0
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":38.72,
        "Decode Throughput (tokens\/s)":42.98,
        "E2E Throughput (tokens\/s)":42.9,
        "Prefill Latency (s)":0.032,
        "E2E Latency (s)":23.3,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":460829.0
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.27**",
        "Decode Throughput (tokens\/s)":36.84,
        "E2E Throughput (tokens\/s)":36.8,
        "Prefill Latency (s)":0.0521,
        "E2E Latency (s)":27.2,
        "Allocated Memory (MB)":4558,
        "Reserved Memory (MB)":4655,
        "Used Memory (MB)":6129,
        "Energy (tokens\/kWh)":469483.0
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"38.27**",
        "Decode Throughput (tokens\/s)":36.97,
        "E2E Throughput (tokens\/s)":36.9,
        "Prefill Latency (s)":0.0519,
        "E2E Latency (s)":27.1,
        "Allocated Memory (MB)":4558,
        "Reserved Memory (MB)":4655,
        "Used Memory (MB)":6129,
        "Energy (tokens\/kWh)":456621.0
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":38.27,
        "Decode Throughput (tokens\/s)":39.58,
        "E2E Throughput (tokens\/s)":39.5,
        "Prefill Latency (s)":0.035,
        "E2E Latency (s)":25.3,
        "Allocated Memory (MB)":13945,
        "Reserved Memory (MB)":14088,
        "Used Memory (MB)":15562,
        "Energy (tokens\/kWh)":429184.0
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Size":6.92,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":38.27,
        "Decode Throughput (tokens\/s)":39.9,
        "E2E Throughput (tokens\/s)":39.8,
        "Prefill Latency (s)":0.0348,
        "E2E Latency (s)":25.1,
        "Allocated Memory (MB)":13945,
        "Reserved Memory (MB)":14088,
        "Used Memory (MB)":15562,
        "Energy (tokens\/kWh)":448430.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.91**",
        "Decode Throughput (tokens\/s)":22.72,
        "E2E Throughput (tokens\/s)":22.7,
        "Prefill Latency (s)":0.0796,
        "E2E Latency (s)":44.1,
        "Allocated Memory (MB)":10251,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268,
        "Energy (tokens\/kWh)":280112.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.91**",
        "Decode Throughput (tokens\/s)":23.52,
        "E2E Throughput (tokens\/s)":23.5,
        "Prefill Latency (s)":0.0808,
        "E2E Latency (s)":42.6,
        "Allocated Memory (MB)":10251,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268,
        "Energy (tokens\/kWh)":268817.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.91**",
        "Decode Throughput (tokens\/s)":25.17,
        "E2E Throughput (tokens\/s)":25.1,
        "Prefill Latency (s)":0.0776,
        "E2E Latency (s)":39.8,
        "Allocated Memory (MB)":10251,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268,
        "Energy (tokens\/kWh)":301204.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.91**",
        "Decode Throughput (tokens\/s)":27.99,
        "E2E Throughput (tokens\/s)":27.9,
        "Prefill Latency (s)":0.0716,
        "E2E Latency (s)":35.8,
        "Allocated Memory (MB)":10802,
        "Reserved Memory (MB)":12683,
        "Used Memory (MB)":14159,
        "Energy (tokens\/kWh)":348432.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.91**",
        "Decode Throughput (tokens\/s)":28.63,
        "E2E Throughput (tokens\/s)":28.6,
        "Prefill Latency (s)":0.0707,
        "E2E Latency (s)":35.0,
        "Allocated Memory (MB)":9889,
        "Reserved Memory (MB)":11771,
        "Used Memory (MB)":13247,
        "Energy (tokens\/kWh)":330033.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":37.91,
        "Decode Throughput (tokens\/s)":28.95,
        "E2E Throughput (tokens\/s)":28.9,
        "Prefill Latency (s)":0.0546,
        "E2E Latency (s)":34.6,
        "Allocated Memory (MB)":28557,
        "Reserved Memory (MB)":30400,
        "Used Memory (MB)":31874,
        "Energy (tokens\/kWh)":274725.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":37.91,
        "Decode Throughput (tokens\/s)":29.72,
        "E2E Throughput (tokens\/s)":29.7,
        "Prefill Latency (s)":0.0533,
        "E2E Latency (s)":33.7,
        "Allocated Memory (MB)":28557,
        "Reserved Memory (MB)":30400,
        "Used Memory (MB)":31874,
        "Energy (tokens\/kWh)":287356.0
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":13.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":37.91,
        "Decode Throughput (tokens\/s)":32.21,
        "E2E Throughput (tokens\/s)":32.2,
        "Prefill Latency (s)":0.0507,
        "E2E Latency (s)":31.1,
        "Allocated Memory (MB)":28557,
        "Reserved Memory (MB)":30356,
        "Used Memory (MB)":31830,
        "Energy (tokens\/kWh)":298507.0
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.74**",
        "Decode Throughput (tokens\/s)":17.24,
        "E2E Throughput (tokens\/s)":17.2,
        "Prefill Latency (s)":0.0893,
        "E2E Latency (s)":58.1,
        "Allocated Memory (MB)":8714,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497,
        "Energy (tokens\/kWh)":206185.0
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.74**",
        "Decode Throughput (tokens\/s)":17.6,
        "E2E Throughput (tokens\/s)":17.6,
        "Prefill Latency (s)":0.088,
        "E2E Latency (s)":56.9,
        "Allocated Memory (MB)":8714,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497,
        "Energy (tokens\/kWh)":228310.0
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":37.74,
        "Decode Throughput (tokens\/s)":23.4,
        "E2E Throughput (tokens\/s)":23.4,
        "Prefill Latency (s)":0.0582,
        "E2E Latency (s)":42.8,
        "Allocated Memory (MB)":28350,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867,
        "Energy (tokens\/kWh)":241545.0
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":37.74,
        "Decode Throughput (tokens\/s)":23.9,
        "E2E Throughput (tokens\/s)":23.9,
        "Prefill Latency (s)":0.059,
        "E2E Latency (s)":41.9,
        "Allocated Memory (MB)":28350,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867,
        "Energy (tokens\/kWh)":249376.0
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"OPT",
        "Size":65.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.31**",
        "Decode Throughput (tokens\/s)":12.83,
        "E2E Throughput (tokens\/s)":12.8,
        "Prefill Latency (s)":0.358,
        "E2E Latency (s)":78.3,
        "Allocated Memory (MB)":43601,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59940,
        "Energy (tokens\/kWh)":112994.0
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"OPT",
        "Size":65.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.31**",
        "Decode Throughput (tokens\/s)":13.08,
        "E2E Throughput (tokens\/s)":13.0,
        "Prefill Latency (s)":0.348,
        "E2E Latency (s)":76.8,
        "Allocated Memory (MB)":43601,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59940,
        "Energy (tokens\/kWh)":119331.0
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"OPT",
        "Size":65.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.31**",
        "Decode Throughput (tokens\/s)":14.0,
        "E2E Throughput (tokens\/s)":13.9,
        "Prefill Latency (s)":0.284,
        "E2E Latency (s)":71.7,
        "Allocated Memory (MB)":41562,
        "Reserved Memory (MB)":61022,
        "Used Memory (MB)":62498,
        "Energy (tokens\/kWh)":131233.0
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"OPT",
        "Size":65.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.31**",
        "Decode Throughput (tokens\/s)":14.82,
        "E2E Throughput (tokens\/s)":14.7,
        "Prefill Latency (s)":0.339,
        "E2E Latency (s)":67.8,
        "Allocated Memory (MB)":43600,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59938,
        "Energy (tokens\/kWh)":133689.0
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"OPT",
        "Size":65.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.31**",
        "Decode Throughput (tokens\/s)":22.46,
        "E2E Throughput (tokens\/s)":22.3,
        "Prefill Latency (s)":0.278,
        "E2E Latency (s)":44.8,
        "Allocated Memory (MB)":43999,
        "Reserved Memory (MB)":63464,
        "Used Memory (MB)":64939,
        "Energy (tokens\/kWh)":207468.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.22**",
        "Decode Throughput (tokens\/s)":22.93,
        "E2E Throughput (tokens\/s)":22.9,
        "Prefill Latency (s)":0.0978,
        "E2E Latency (s)":43.7,
        "Allocated Memory (MB)":12235,
        "Reserved Memory (MB)":13885,
        "Used Memory (MB)":15358,
        "Energy (tokens\/kWh)":263157.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.22**",
        "Decode Throughput (tokens\/s)":24.21,
        "E2E Throughput (tokens\/s)":24.2,
        "Prefill Latency (s)":0.0936,
        "E2E Latency (s)":41.4,
        "Allocated Memory (MB)":12250,
        "Reserved Memory (MB)":13929,
        "Used Memory (MB)":15403,
        "Energy (tokens\/kWh)":270270.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":37.22,
        "Decode Throughput (tokens\/s)":25.17,
        "E2E Throughput (tokens\/s)":25.1,
        "Prefill Latency (s)":0.0648,
        "E2E Latency (s)":39.8,
        "Allocated Memory (MB)":34361,
        "Reserved Memory (MB)":36951,
        "Used Memory (MB)":38425,
        "Energy (tokens\/kWh)":231481.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.22**",
        "Decode Throughput (tokens\/s)":25.3,
        "E2E Throughput (tokens\/s)":25.3,
        "Prefill Latency (s)":0.0814,
        "E2E Latency (s)":39.6,
        "Allocated Memory (MB)":11871,
        "Reserved Memory (MB)":14487,
        "Used Memory (MB)":15962,
        "Energy (tokens\/kWh)":293255.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.22**",
        "Decode Throughput (tokens\/s)":25.63,
        "E2E Throughput (tokens\/s)":25.6,
        "Prefill Latency (s)":0.0821,
        "E2E Latency (s)":39.1,
        "Allocated Memory (MB)":13487,
        "Reserved Memory (MB)":16106,
        "Used Memory (MB)":17581,
        "Energy (tokens\/kWh)":323624.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":37.22,
        "Decode Throughput (tokens\/s)":25.62,
        "E2E Throughput (tokens\/s)":25.6,
        "Prefill Latency (s)":0.0634,
        "E2E Latency (s)":39.1,
        "Allocated Memory (MB)":34361,
        "Reserved Memory (MB)":36951,
        "Used Memory (MB)":38425,
        "Energy (tokens\/kWh)":240963.0
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"CodeGen",
        "Size":15.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":37.22,
        "Decode Throughput (tokens\/s)":27.07,
        "E2E Throughput (tokens\/s)":27.0,
        "Prefill Latency (s)":0.0612,
        "E2E Latency (s)":37.0,
        "Allocated Memory (MB)":34377,
        "Reserved Memory (MB)":36962,
        "Used Memory (MB)":38436,
        "Energy (tokens\/kWh)":246305.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.05**",
        "Decode Throughput (tokens\/s)":29.03,
        "E2E Throughput (tokens\/s)":29.0,
        "Prefill Latency (s)":0.0474,
        "E2E Latency (s)":34.5,
        "Allocated Memory (MB)":5581,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201,
        "Energy (tokens\/kWh)":373134.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"37.05**",
        "Decode Throughput (tokens\/s)":31.69,
        "E2E Throughput (tokens\/s)":31.6,
        "Prefill Latency (s)":0.0458,
        "E2E Latency (s)":31.6,
        "Allocated Memory (MB)":5582,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188,
        "Energy (tokens\/kWh)":396825.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.05**",
        "Decode Throughput (tokens\/s)":34.77,
        "E2E Throughput (tokens\/s)":34.7,
        "Prefill Latency (s)":0.0427,
        "E2E Latency (s)":28.8,
        "Allocated Memory (MB)":6147,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920,
        "Energy (tokens\/kWh)":480769.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"37.05**",
        "Decode Throughput (tokens\/s)":35.64,
        "E2E Throughput (tokens\/s)":35.6,
        "Prefill Latency (s)":0.0419,
        "E2E Latency (s)":28.1,
        "Allocated Memory (MB)":5421,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192,
        "Energy (tokens\/kWh)":454545.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":37.05,
        "Decode Throughput (tokens\/s)":37.93,
        "E2E Throughput (tokens\/s)":37.9,
        "Prefill Latency (s)":0.0338,
        "E2E Latency (s)":26.4,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":411522.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":37.05,
        "Decode Throughput (tokens\/s)":38.51,
        "E2E Throughput (tokens\/s)":38.5,
        "Prefill Latency (s)":0.0334,
        "E2E Latency (s)":26.0,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.61,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":37.05,
        "Decode Throughput (tokens\/s)":40.21,
        "E2E Throughput (tokens\/s)":40.2,
        "Prefill Latency (s)":0.0322,
        "E2E Latency (s)":24.9,
        "Allocated Memory (MB)":14861,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.8,
        "Decode Throughput (tokens\/s)":25.82,
        "E2E Throughput (tokens\/s)":25.8,
        "Prefill Latency (s)":0.0712,
        "E2E Latency (s)":38.8,
        "Allocated Memory (MB)":43420,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399,
        "Energy (tokens\/kWh)":234192.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.8**",
        "Decode Throughput (tokens\/s)":26.08,
        "E2E Throughput (tokens\/s)":26.0,
        "Prefill Latency (s)":0.0594,
        "E2E Latency (s)":38.4,
        "Allocated Memory (MB)":43420,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399,
        "Energy (tokens\/kWh)":277008.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.8,
        "Decode Throughput (tokens\/s)":26.09,
        "E2E Throughput (tokens\/s)":26.0,
        "Prefill Latency (s)":0.0718,
        "E2E Latency (s)":38.4,
        "Allocated Memory (MB)":43420,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399,
        "Energy (tokens\/kWh)":239234.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.8**",
        "Decode Throughput (tokens\/s)":27.9,
        "E2E Throughput (tokens\/s)":27.9,
        "Prefill Latency (s)":0.0577,
        "E2E Latency (s)":35.9,
        "Allocated Memory (MB)":43419,
        "Reserved Memory (MB)":46948,
        "Used Memory (MB)":48420,
        "Energy (tokens\/kWh)":289855.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.8,
        "Decode Throughput (tokens\/s)":27.99,
        "E2E Throughput (tokens\/s)":27.9,
        "Prefill Latency (s)":0.0718,
        "E2E Latency (s)":35.8,
        "Allocated Memory (MB)":43419,
        "Reserved Memory (MB)":46948,
        "Used Memory (MB)":48420,
        "Energy (tokens\/kWh)":256410.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.8**",
        "Decode Throughput (tokens\/s)":33.33,
        "E2E Throughput (tokens\/s)":33.2,
        "Prefill Latency (s)":0.0957,
        "E2E Latency (s)":30.1,
        "Allocated Memory (MB)":14228,
        "Reserved Memory (MB)":17758,
        "Used Memory (MB)":19234,
        "Energy (tokens\/kWh)":346020.0
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Size":20.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.8**",
        "Decode Throughput (tokens\/s)":40.81,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0973,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":15846,
        "Reserved Memory (MB)":19379,
        "Used Memory (MB)":20855,
        "Energy (tokens\/kWh)":450450.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.57,
        "Decode Throughput (tokens\/s)":19.54,
        "E2E Throughput (tokens\/s)":19.5,
        "Prefill Latency (s)":0.12,
        "E2E Latency (s)":51.3,
        "Allocated Memory (MB)":63498,
        "Reserved Memory (MB)":68010,
        "Used Memory (MB)":69484,
        "Energy (tokens\/kWh)":179856.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.57,
        "Decode Throughput (tokens\/s)":19.69,
        "E2E Throughput (tokens\/s)":19.6,
        "Prefill Latency (s)":0.115,
        "E2E Latency (s)":50.9,
        "Allocated Memory (MB)":63498,
        "Reserved Memory (MB)":68010,
        "Used Memory (MB)":69484,
        "Energy (tokens\/kWh)":181488.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.57,
        "Decode Throughput (tokens\/s)":21.33,
        "E2E Throughput (tokens\/s)":21.3,
        "Prefill Latency (s)":0.108,
        "E2E Latency (s)":47.0,
        "Allocated Memory (MB)":63508,
        "Reserved Memory (MB)":68209,
        "Used Memory (MB)":69681,
        "Energy (tokens\/kWh)":196850.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.57**",
        "Decode Throughput (tokens\/s)":22.51,
        "E2E Throughput (tokens\/s)":22.4,
        "Prefill Latency (s)":0.178,
        "E2E Latency (s)":44.6,
        "Allocated Memory (MB)":20948,
        "Reserved Memory (MB)":24519,
        "Used Memory (MB)":25993,
        "Energy (tokens\/kWh)":213219.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.57**",
        "Decode Throughput (tokens\/s)":25.28,
        "E2E Throughput (tokens\/s)":25.2,
        "Prefill Latency (s)":0.144,
        "E2E Latency (s)":39.7,
        "Allocated Memory (MB)":20110,
        "Reserved Memory (MB)":25052,
        "Used Memory (MB)":26528,
        "Energy (tokens\/kWh)":250626.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.57**",
        "Decode Throughput (tokens\/s)":27.91,
        "E2E Throughput (tokens\/s)":27.8,
        "Prefill Latency (s)":0.17,
        "E2E Latency (s)":36.0,
        "Allocated Memory (MB)":20948,
        "Reserved Memory (MB)":24519,
        "Used Memory (MB)":25993,
        "Energy (tokens\/kWh)":242130.0
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"OPT",
        "Size":29.98,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.57**",
        "Decode Throughput (tokens\/s)":35.14,
        "E2E Throughput (tokens\/s)":35.0,
        "Prefill Latency (s)":0.144,
        "E2E Latency (s)":28.6,
        "Allocated Memory (MB)":22002,
        "Reserved Memory (MB)":26925,
        "Used Memory (MB)":28401,
        "Energy (tokens\/kWh)":364963.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.2**",
        "Decode Throughput (tokens\/s)":37.79,
        "E2E Throughput (tokens\/s)":37.7,
        "Prefill Latency (s)":0.0353,
        "E2E Latency (s)":26.5,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3219,
        "Used Memory (MB)":4692,
        "Energy (tokens\/kWh)":518134.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.2**",
        "Decode Throughput (tokens\/s)":40.7,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0329,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3229,
        "Used Memory (MB)":4703,
        "Energy (tokens\/kWh)":561797.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.2**",
        "Decode Throughput (tokens\/s)":46.13,
        "E2E Throughput (tokens\/s)":46.1,
        "Prefill Latency (s)":0.0235,
        "E2E Latency (s)":21.7,
        "Allocated Memory (MB)":2870,
        "Reserved Memory (MB)":3200,
        "Used Memory (MB)":4676,
        "Energy (tokens\/kWh)":632911.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.2**",
        "Decode Throughput (tokens\/s)":46.56,
        "E2E Throughput (tokens\/s)":46.5,
        "Prefill Latency (s)":0.0231,
        "E2E Latency (s)":21.5,
        "Allocated Memory (MB)":3410,
        "Reserved Memory (MB)":3743,
        "Used Memory (MB)":5219,
        "Energy (tokens\/kWh)":662251.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.2,
        "Decode Throughput (tokens\/s)":48.59,
        "E2E Throughput (tokens\/s)":48.5,
        "Prefill Latency (s)":0.0206,
        "E2E Latency (s)":20.6,
        "Allocated Memory (MB)":6840,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593,
        "Energy (tokens\/kWh)":632911.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.2,
        "Decode Throughput (tokens\/s)":49.31,
        "E2E Throughput (tokens\/s)":49.3,
        "Prefill Latency (s)":0.0201,
        "E2E Latency (s)":20.3,
        "Allocated Memory (MB)":6840,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593,
        "Energy (tokens\/kWh)":609756.0
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.2,
        "Decode Throughput (tokens\/s)":55.61,
        "E2E Throughput (tokens\/s)":55.6,
        "Prefill Latency (s)":0.0182,
        "E2E Latency (s)":18.0,
        "Allocated Memory (MB)":6840,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593,
        "Energy (tokens\/kWh)":689655.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":33.28,
        "E2E Throughput (tokens\/s)":33.2,
        "Prefill Latency (s)":0.0489,
        "E2E Latency (s)":30.1,
        "Allocated Memory (MB)":5998,
        "Reserved Memory (MB)":6041,
        "Used Memory (MB)":7515,
        "Energy (tokens\/kWh)":413223.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":33.61,
        "E2E Throughput (tokens\/s)":33.6,
        "Prefill Latency (s)":0.049,
        "E2E Latency (s)":29.8,
        "Allocated Memory (MB)":5998,
        "Reserved Memory (MB)":6041,
        "Used Memory (MB)":7515,
        "Energy (tokens\/kWh)":418410.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":36.96,
        "E2E Throughput (tokens\/s)":36.9,
        "Prefill Latency (s)":0.0466,
        "E2E Latency (s)":27.1,
        "Allocated Memory (MB)":5999,
        "Reserved Memory (MB)":6062,
        "Used Memory (MB)":7534,
        "Energy (tokens\/kWh)":450450.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":37.1,
        "E2E Throughput (tokens\/s)":37.0,
        "Prefill Latency (s)":0.0466,
        "E2E Latency (s)":27.0,
        "Allocated Memory (MB)":5999,
        "Reserved Memory (MB)":6062,
        "Used Memory (MB)":7534,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":38.51,
        "E2E Throughput (tokens\/s)":38.5,
        "Prefill Latency (s)":0.0321,
        "E2E Latency (s)":26.0,
        "Allocated Memory (MB)":15234,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741,
        "Energy (tokens\/kWh)":423728.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":39.42,
        "E2E Throughput (tokens\/s)":39.4,
        "Prefill Latency (s)":0.0318,
        "E2E Latency (s)":25.4,
        "Allocated Memory (MB)":15234,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741,
        "Energy (tokens\/kWh)":423728.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":39.89,
        "E2E Throughput (tokens\/s)":39.8,
        "Prefill Latency (s)":0.0315,
        "E2E Latency (s)":25.1,
        "Allocated Memory (MB)":15234,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741,
        "Energy (tokens\/kWh)":432900.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":40.05,
        "E2E Throughput (tokens\/s)":40.0,
        "Prefill Latency (s)":0.0312,
        "E2E Latency (s)":25.0,
        "Allocated Memory (MB)":15234,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741,
        "Energy (tokens\/kWh)":436681.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":41.39,
        "E2E Throughput (tokens\/s)":41.3,
        "Prefill Latency (s)":0.041,
        "E2E Latency (s)":24.2,
        "Allocated Memory (MB)":6910,
        "Reserved Memory (MB)":6928,
        "Used Memory (MB)":8404,
        "Energy (tokens\/kWh)":543478.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":41.56,
        "E2E Throughput (tokens\/s)":41.5,
        "Prefill Latency (s)":0.0409,
        "E2E Latency (s)":24.1,
        "Allocated Memory (MB)":5832,
        "Reserved Memory (MB)":5848,
        "Used Memory (MB)":7324,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":41.74,
        "E2E Throughput (tokens\/s)":41.7,
        "Prefill Latency (s)":0.0419,
        "E2E Latency (s)":24.0,
        "Allocated Memory (MB)":6910,
        "Reserved Memory (MB)":6928,
        "Used Memory (MB)":8404,
        "Energy (tokens\/kWh)":561797.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.09**",
        "Decode Throughput (tokens\/s)":41.91,
        "E2E Throughput (tokens\/s)":41.8,
        "Prefill Latency (s)":0.0399,
        "E2E Latency (s)":23.9,
        "Allocated Memory (MB)":5832,
        "Reserved Memory (MB)":5848,
        "Used Memory (MB)":7324,
        "Energy (tokens\/kWh)":523560.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":45.72,
        "E2E Throughput (tokens\/s)":45.7,
        "Prefill Latency (s)":0.0292,
        "E2E Latency (s)":21.9,
        "Allocated Memory (MB)":15233,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16738,
        "Energy (tokens\/kWh)":473933.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.09,
        "Decode Throughput (tokens\/s)":46.36,
        "E2E Throughput (tokens\/s)":46.3,
        "Prefill Latency (s)":0.0298,
        "E2E Latency (s)":21.6,
        "Allocated Memory (MB)":15233,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16738,
        "Energy (tokens\/kWh)":476190.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.02**",
        "Decode Throughput (tokens\/s)":22.23,
        "E2E Throughput (tokens\/s)":22.2,
        "Prefill Latency (s)":0.123,
        "E2E Latency (s)":45.1,
        "Allocated Memory (MB)":15392,
        "Reserved Memory (MB)":17341,
        "Used Memory (MB)":18815,
        "Energy (tokens\/kWh)":242130.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"36.02**",
        "Decode Throughput (tokens\/s)":23.27,
        "E2E Throughput (tokens\/s)":23.2,
        "Prefill Latency (s)":0.122,
        "E2E Latency (s)":43.1,
        "Allocated Memory (MB)":15392,
        "Reserved Memory (MB)":17318,
        "Used Memory (MB)":18792,
        "Energy (tokens\/kWh)":253164.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":36.02,
        "Decode Throughput (tokens\/s)":23.8,
        "E2E Throughput (tokens\/s)":23.8,
        "Prefill Latency (s)":0.0833,
        "E2E Latency (s)":42.1,
        "Allocated Memory (MB)":44027,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077,
        "Energy (tokens\/kWh)":214132.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":36.02,
        "Decode Throughput (tokens\/s)":23.91,
        "E2E Throughput (tokens\/s)":23.9,
        "Prefill Latency (s)":0.0828,
        "E2E Latency (s)":41.9,
        "Allocated Memory (MB)":44027,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077,
        "Energy (tokens\/kWh)":214592.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":36.02,
        "Decode Throughput (tokens\/s)":24.38,
        "E2E Throughput (tokens\/s)":24.3,
        "Prefill Latency (s)":0.0825,
        "E2E Latency (s)":41.1,
        "Allocated Memory (MB)":44027,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077,
        "Energy (tokens\/kWh)":218818.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.02**",
        "Decode Throughput (tokens\/s)":26.6,
        "E2E Throughput (tokens\/s)":26.5,
        "Prefill Latency (s)":0.105,
        "E2E Latency (s)":37.7,
        "Allocated Memory (MB)":16448,
        "Reserved Memory (MB)":20055,
        "Used Memory (MB)":21530,
        "Energy (tokens\/kWh)":322580.0
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Size":20.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"36.02**",
        "Decode Throughput (tokens\/s)":26.96,
        "E2E Throughput (tokens\/s)":26.9,
        "Prefill Latency (s)":0.104,
        "E2E Latency (s)":37.2,
        "Allocated Memory (MB)":14830,
        "Reserved Memory (MB)":18433,
        "Used Memory (MB)":19909,
        "Energy (tokens\/kWh)":293255.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"35.46**",
        "Decode Throughput (tokens\/s)":9.91,
        "E2E Throughput (tokens\/s)":9.9,
        "Prefill Latency (s)":0.0503,
        "E2E Latency (s)":101.0,
        "Allocated Memory (MB)":5081,
        "Reserved Memory (MB)":5316,
        "Used Memory (MB)":6790,
        "Energy (tokens\/kWh)":91743.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"35.46**",
        "Decode Throughput (tokens\/s)":10.35,
        "E2E Throughput (tokens\/s)":10.3,
        "Prefill Latency (s)":0.0412,
        "E2E Latency (s)":96.7,
        "Allocated Memory (MB)":4909,
        "Reserved Memory (MB)":12146,
        "Used Memory (MB)":13622,
        "Energy (tokens\/kWh)":96153.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"35.46**",
        "Decode Throughput (tokens\/s)":10.28,
        "E2E Throughput (tokens\/s)":10.3,
        "Prefill Latency (s)":0.0421,
        "E2E Latency (s)":97.3,
        "Allocated Memory (MB)":5987,
        "Reserved Memory (MB)":13226,
        "Used Memory (MB)":14702,
        "Energy (tokens\/kWh)":95238.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":35.46,
        "Decode Throughput (tokens\/s)":10.8,
        "E2E Throughput (tokens\/s)":10.8,
        "Prefill Latency (s)":0.033,
        "E2E Latency (s)":92.6,
        "Allocated Memory (MB)":14309,
        "Reserved Memory (MB)":21544,
        "Used Memory (MB)":23017,
        "Energy (tokens\/kWh)":100603.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":35.46,
        "Decode Throughput (tokens\/s)":10.96,
        "E2E Throughput (tokens\/s)":11.0,
        "Prefill Latency (s)":0.0327,
        "E2E Latency (s)":91.3,
        "Allocated Memory (MB)":14309,
        "Reserved Memory (MB)":21544,
        "Used Memory (MB)":23017,
        "Energy (tokens\/kWh)":102774.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"35.46**",
        "Decode Throughput (tokens\/s)":11.91,
        "E2E Throughput (tokens\/s)":11.9,
        "Prefill Latency (s)":0.0479,
        "E2E Latency (s)":84.0,
        "Allocated Memory (MB)":5025,
        "Reserved Memory (MB)":5182,
        "Used Memory (MB)":6655,
        "Energy (tokens\/kWh)":110132.0
    },
    {
        "Model":"Rallio67\/7B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":35.46,
        "Decode Throughput (tokens\/s)":13.34,
        "E2E Throughput (tokens\/s)":13.3,
        "Prefill Latency (s)":0.0303,
        "E2E Latency (s)":75.0,
        "Allocated Memory (MB)":14150,
        "Reserved Memory (MB)":21544,
        "Used Memory (MB)":23017,
        "Energy (tokens\/kWh)":123915.0
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"35.26**",
        "Decode Throughput (tokens\/s)":34.53,
        "E2E Throughput (tokens\/s)":34.5,
        "Prefill Latency (s)":0.0383,
        "E2E Latency (s)":29.0,
        "Allocated Memory (MB)":3114,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4896,
        "Energy (tokens\/kWh)":465116.0
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"35.26**",
        "Decode Throughput (tokens\/s)":35.38,
        "E2E Throughput (tokens\/s)":35.3,
        "Prefill Latency (s)":0.0388,
        "E2E Latency (s)":28.3,
        "Allocated Memory (MB)":3122,
        "Reserved Memory (MB)":3458,
        "Used Memory (MB)":4931,
        "Energy (tokens\/kWh)":487804.0
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":35.26,
        "Decode Throughput (tokens\/s)":45.5,
        "E2E Throughput (tokens\/s)":45.5,
        "Prefill Latency (s)":0.0226,
        "E2E Latency (s)":22.0,
        "Allocated Memory (MB)":7770,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629,
        "Energy (tokens\/kWh)":574712.0
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":35.26,
        "Decode Throughput (tokens\/s)":45.71,
        "E2E Throughput (tokens\/s)":45.7,
        "Prefill Latency (s)":0.0222,
        "E2E Latency (s)":21.9,
        "Allocated Memory (MB)":7770,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629,
        "Energy (tokens\/kWh)":561797.0
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":35.26,
        "Decode Throughput (tokens\/s)":47.22,
        "E2E Throughput (tokens\/s)":47.2,
        "Prefill Latency (s)":0.0226,
        "E2E Latency (s)":21.2,
        "Allocated Memory (MB)":7779,
        "Reserved Memory (MB)":8172,
        "Used Memory (MB)":9646,
        "Energy (tokens\/kWh)":588235.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.99**",
        "Decode Throughput (tokens\/s)":30.56,
        "E2E Throughput (tokens\/s)":30.5,
        "Prefill Latency (s)":0.0786,
        "E2E Latency (s)":32.8,
        "Allocated Memory (MB)":9686,
        "Reserved Memory (MB)":11177,
        "Used Memory (MB)":12651,
        "Energy (tokens\/kWh)":344827.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.99**",
        "Decode Throughput (tokens\/s)":35.3,
        "E2E Throughput (tokens\/s)":35.2,
        "Prefill Latency (s)":0.0726,
        "E2E Latency (s)":28.4,
        "Allocated Memory (MB)":9685,
        "Reserved Memory (MB)":11150,
        "Used Memory (MB)":12622,
        "Energy (tokens\/kWh)":377358.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.99,
        "Decode Throughput (tokens\/s)":35.65,
        "E2E Throughput (tokens\/s)":35.6,
        "Prefill Latency (s)":0.0502,
        "E2E Latency (s)":28.1,
        "Allocated Memory (MB)":27772,
        "Reserved Memory (MB)":29582,
        "Used Memory (MB)":31056,
        "Energy (tokens\/kWh)":324675.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.99,
        "Decode Throughput (tokens\/s)":35.91,
        "E2E Throughput (tokens\/s)":35.8,
        "Prefill Latency (s)":0.0496,
        "E2E Latency (s)":27.9,
        "Allocated Memory (MB)":27772,
        "Reserved Memory (MB)":29582,
        "Used Memory (MB)":31056,
        "Energy (tokens\/kWh)":324675.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.99**",
        "Decode Throughput (tokens\/s)":40.76,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0643,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":9360,
        "Reserved Memory (MB)":11444,
        "Used Memory (MB)":12920,
        "Energy (tokens\/kWh)":438596.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.99,
        "Decode Throughput (tokens\/s)":43.19,
        "E2E Throughput (tokens\/s)":43.1,
        "Prefill Latency (s)":0.0451,
        "E2E Latency (s)":23.2,
        "Allocated Memory (MB)":27772,
        "Reserved Memory (MB)":29855,
        "Used Memory (MB)":31326,
        "Energy (tokens\/kWh)":393700.0
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"OPT",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.99**",
        "Decode Throughput (tokens\/s)":43.8,
        "E2E Throughput (tokens\/s)":43.7,
        "Prefill Latency (s)":0.0664,
        "E2E Latency (s)":22.9,
        "Allocated Memory (MB)":10709,
        "Reserved Memory (MB)":12794,
        "Used Memory (MB)":14270,
        "Energy (tokens\/kWh)":515463.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.92**",
        "Decode Throughput (tokens\/s)":23.78,
        "E2E Throughput (tokens\/s)":23.8,
        "Prefill Latency (s)":0.0541,
        "E2E Latency (s)":42.1,
        "Allocated Memory (MB)":6176,
        "Reserved Memory (MB)":6243,
        "Used Memory (MB)":7716,
        "Energy (tokens\/kWh)":321543.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.92**",
        "Decode Throughput (tokens\/s)":25.54,
        "E2E Throughput (tokens\/s)":25.5,
        "Prefill Latency (s)":0.0499,
        "E2E Latency (s)":39.2,
        "Allocated Memory (MB)":6188,
        "Reserved Memory (MB)":6285,
        "Used Memory (MB)":7758,
        "Energy (tokens\/kWh)":338983.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.92**",
        "Decode Throughput (tokens\/s)":26.35,
        "E2E Throughput (tokens\/s)":26.3,
        "Prefill Latency (s)":0.0456,
        "E2E Latency (s)":38.0,
        "Allocated Memory (MB)":6000,
        "Reserved Memory (MB)":6039,
        "Used Memory (MB)":7515,
        "Energy (tokens\/kWh)":350877.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.92**",
        "Decode Throughput (tokens\/s)":26.56,
        "E2E Throughput (tokens\/s)":26.5,
        "Prefill Latency (s)":0.0478,
        "E2E Latency (s)":37.7,
        "Allocated Memory (MB)":7077,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8595,
        "Energy (tokens\/kWh)":375939.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.92,
        "Decode Throughput (tokens\/s)":26.55,
        "E2E Throughput (tokens\/s)":26.5,
        "Prefill Latency (s)":0.0383,
        "E2E Latency (s)":37.7,
        "Allocated Memory (MB)":15697,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214,
        "Energy (tokens\/kWh)":317460.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.92,
        "Decode Throughput (tokens\/s)":26.69,
        "E2E Throughput (tokens\/s)":26.7,
        "Prefill Latency (s)":0.0384,
        "E2E Latency (s)":37.5,
        "Allocated Memory (MB)":15697,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214,
        "Energy (tokens\/kWh)":320512.0
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.92,
        "Decode Throughput (tokens\/s)":28.85,
        "E2E Throughput (tokens\/s)":28.8,
        "Prefill Latency (s)":0.0343,
        "E2E Latency (s)":34.7,
        "Allocated Memory (MB)":15707,
        "Reserved Memory (MB)":15762,
        "Used Memory (MB)":17235,
        "Energy (tokens\/kWh)":332225.0
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.87**",
        "Decode Throughput (tokens\/s)":17.6,
        "E2E Throughput (tokens\/s)":17.6,
        "Prefill Latency (s)":0.0879,
        "E2E Latency (s)":56.9,
        "Allocated Memory (MB)":8714,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497,
        "Energy (tokens\/kWh)":226244.0
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.87,
        "Decode Throughput (tokens\/s)":23.13,
        "E2E Throughput (tokens\/s)":23.1,
        "Prefill Latency (s)":0.0583,
        "E2E Latency (s)":43.3,
        "Allocated Memory (MB)":28350,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867,
        "Energy (tokens\/kWh)":242130.0
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"RWKV",
        "Size":13.89,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.87,
        "Decode Throughput (tokens\/s)":23.4,
        "E2E Throughput (tokens\/s)":23.4,
        "Prefill Latency (s)":0.0583,
        "E2E Latency (s)":42.8,
        "Allocated Memory (MB)":28350,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867,
        "Energy (tokens\/kWh)":236406.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.87**",
        "Decode Throughput (tokens\/s)":26.42,
        "E2E Throughput (tokens\/s)":26.4,
        "Prefill Latency (s)":0.0486,
        "E2E Latency (s)":37.9,
        "Allocated Memory (MB)":5331,
        "Reserved Memory (MB)":5387,
        "Used Memory (MB)":6861,
        "Energy (tokens\/kWh)":347222.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.87**",
        "Decode Throughput (tokens\/s)":27.89,
        "E2E Throughput (tokens\/s)":27.9,
        "Prefill Latency (s)":0.0443,
        "E2E Latency (s)":35.9,
        "Allocated Memory (MB)":5341,
        "Reserved Memory (MB)":5429,
        "Used Memory (MB)":6903,
        "Energy (tokens\/kWh)":367647.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.87**",
        "Decode Throughput (tokens\/s)":30.62,
        "E2E Throughput (tokens\/s)":30.6,
        "Prefill Latency (s)":0.0409,
        "E2E Latency (s)":32.7,
        "Allocated Memory (MB)":6309,
        "Reserved Memory (MB)":6465,
        "Used Memory (MB)":7941,
        "Energy (tokens\/kWh)":432900.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.87**",
        "Decode Throughput (tokens\/s)":30.71,
        "E2E Throughput (tokens\/s)":30.7,
        "Prefill Latency (s)":0.0401,
        "E2E Latency (s)":32.6,
        "Allocated Memory (MB)":5231,
        "Reserved Memory (MB)":5385,
        "Used Memory (MB)":6861,
        "Energy (tokens\/kWh)":413223.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.87,
        "Decode Throughput (tokens\/s)":31.38,
        "E2E Throughput (tokens\/s)":31.3,
        "Prefill Latency (s)":0.0338,
        "E2E Latency (s)":31.9,
        "Allocated Memory (MB)":13438,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956,
        "Energy (tokens\/kWh)":371747.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.87,
        "Decode Throughput (tokens\/s)":31.48,
        "E2E Throughput (tokens\/s)":31.4,
        "Prefill Latency (s)":0.0333,
        "E2E Latency (s)":31.8,
        "Allocated Memory (MB)":13438,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956,
        "Energy (tokens\/kWh)":370370.0
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Size":5.84,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.87,
        "Decode Throughput (tokens\/s)":33.15,
        "E2E Throughput (tokens\/s)":33.1,
        "Prefill Latency (s)":0.0305,
        "E2E Latency (s)":30.2,
        "Allocated Memory (MB)":13448,
        "Reserved Memory (MB)":13503,
        "Used Memory (MB)":14977,
        "Energy (tokens\/kWh)":392156.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.85**",
        "Decode Throughput (tokens\/s)":28.45,
        "E2E Throughput (tokens\/s)":28.4,
        "Prefill Latency (s)":0.0474,
        "E2E Latency (s)":35.2,
        "Allocated Memory (MB)":5822,
        "Reserved Memory (MB)":5939,
        "Used Memory (MB)":7412,
        "Energy (tokens\/kWh)":380228.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.85**",
        "Decode Throughput (tokens\/s)":31.0,
        "E2E Throughput (tokens\/s)":31.0,
        "Prefill Latency (s)":0.0454,
        "E2E Latency (s)":32.3,
        "Allocated Memory (MB)":5821,
        "Reserved Memory (MB)":5939,
        "Used Memory (MB)":7412,
        "Energy (tokens\/kWh)":399999.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.85**",
        "Decode Throughput (tokens\/s)":34.18,
        "E2E Throughput (tokens\/s)":34.1,
        "Prefill Latency (s)":0.0414,
        "E2E Latency (s)":29.3,
        "Allocated Memory (MB)":5657,
        "Reserved Memory (MB)":5708,
        "Used Memory (MB)":7184,
        "Energy (tokens\/kWh)":460829.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.85**",
        "Decode Throughput (tokens\/s)":34.65,
        "E2E Throughput (tokens\/s)":34.6,
        "Prefill Latency (s)":0.0427,
        "E2E Latency (s)":28.9,
        "Allocated Memory (MB)":6382,
        "Reserved Memory (MB)":6436,
        "Used Memory (MB)":7912,
        "Energy (tokens\/kWh)":476190.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.85,
        "Decode Throughput (tokens\/s)":38.36,
        "E2E Throughput (tokens\/s)":38.3,
        "Prefill Latency (s)":0.0336,
        "E2E Latency (s)":26.1,
        "Allocated Memory (MB)":15095,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583,
        "Energy (tokens\/kWh)":421940.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.85,
        "Decode Throughput (tokens\/s)":38.66,
        "E2E Throughput (tokens\/s)":38.6,
        "Prefill Latency (s)":0.0343,
        "E2E Latency (s)":25.9,
        "Allocated Memory (MB)":15095,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583,
        "Energy (tokens\/kWh)":396825.0
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":6.74,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.85,
        "Decode Throughput (tokens\/s)":42.07,
        "E2E Throughput (tokens\/s)":42.0,
        "Prefill Latency (s)":0.032,
        "E2E Latency (s)":23.8,
        "Allocated Memory (MB)":15095,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583,
        "Energy (tokens\/kWh)":444444.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.67**",
        "Decode Throughput (tokens\/s)":29.83,
        "E2E Throughput (tokens\/s)":29.8,
        "Prefill Latency (s)":0.0738,
        "E2E Latency (s)":33.6,
        "Allocated Memory (MB)":9441,
        "Reserved Memory (MB)":10529,
        "Used Memory (MB)":12003,
        "Energy (tokens\/kWh)":348432.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.67,
        "Decode Throughput (tokens\/s)":32.73,
        "E2E Throughput (tokens\/s)":32.7,
        "Prefill Latency (s)":0.0481,
        "E2E Latency (s)":30.6,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286,
        "Energy (tokens\/kWh)":317460.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.67**",
        "Decode Throughput (tokens\/s)":32.86,
        "E2E Throughput (tokens\/s)":32.8,
        "Prefill Latency (s)":0.0711,
        "E2E Latency (s)":30.5,
        "Allocated Memory (MB)":9441,
        "Reserved Memory (MB)":10557,
        "Used Memory (MB)":12028,
        "Energy (tokens\/kWh)":373134.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.67,
        "Decode Throughput (tokens\/s)":35.02,
        "E2E Throughput (tokens\/s)":35.0,
        "Prefill Latency (s)":0.0479,
        "E2E Latency (s)":28.6,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286,
        "Energy (tokens\/kWh)":325732.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.67**",
        "Decode Throughput (tokens\/s)":36.05,
        "E2E Throughput (tokens\/s)":36.0,
        "Prefill Latency (s)":0.062,
        "E2E Latency (s)":27.8,
        "Allocated Memory (MB)":10548,
        "Reserved Memory (MB)":12637,
        "Used Memory (MB)":14113,
        "Energy (tokens\/kWh)":454545.0
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.67,
        "Decode Throughput (tokens\/s)":38.09,
        "E2E Throughput (tokens\/s)":38.0,
        "Prefill Latency (s)":0.046,
        "E2E Latency (s)":26.3,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27856,
        "Used Memory (MB)":29328,
        "Energy (tokens\/kWh)":342465.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.32**",
        "Decode Throughput (tokens\/s)":33.5,
        "E2E Throughput (tokens\/s)":33.4,
        "Prefill Latency (s)":0.0478,
        "E2E Latency (s)":29.9,
        "Allocated Memory (MB)":5973,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7511,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.32**",
        "Decode Throughput (tokens\/s)":36.83,
        "E2E Throughput (tokens\/s)":36.8,
        "Prefill Latency (s)":0.0453,
        "E2E Latency (s)":27.2,
        "Allocated Memory (MB)":5974,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7509,
        "Energy (tokens\/kWh)":454545.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.32,
        "Decode Throughput (tokens\/s)":40.37,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0314,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.32,
        "Decode Throughput (tokens\/s)":40.7,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0315,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715,
        "Energy (tokens\/kWh)":425531.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.32**",
        "Decode Throughput (tokens\/s)":40.88,
        "E2E Throughput (tokens\/s)":40.8,
        "Prefill Latency (s)":0.0404,
        "E2E Latency (s)":24.5,
        "Allocated Memory (MB)":6884,
        "Reserved Memory (MB)":6905,
        "Used Memory (MB)":8381,
        "Energy (tokens\/kWh)":555555.0
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.32,
        "Decode Throughput (tokens\/s)":45.93,
        "E2E Throughput (tokens\/s)":45.9,
        "Prefill Latency (s)":0.0289,
        "E2E Latency (s)":21.8,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16713,
        "Energy (tokens\/kWh)":467289.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.19**",
        "Decode Throughput (tokens\/s)":37.8,
        "E2E Throughput (tokens\/s)":37.7,
        "Prefill Latency (s)":0.0476,
        "E2E Latency (s)":26.5,
        "Allocated Memory (MB)":5402,
        "Reserved Memory (MB)":5454,
        "Used Memory (MB)":6928,
        "Energy (tokens\/kWh)":471698.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.19**",
        "Decode Throughput (tokens\/s)":44.33,
        "E2E Throughput (tokens\/s)":44.2,
        "Prefill Latency (s)":0.0417,
        "E2E Latency (s)":22.6,
        "Allocated Memory (MB)":5403,
        "Reserved Memory (MB)":5463,
        "Used Memory (MB)":6934,
        "Energy (tokens\/kWh)":515463.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.19,
        "Decode Throughput (tokens\/s)":51.1,
        "E2E Throughput (tokens\/s)":51.0,
        "Prefill Latency (s)":0.0307,
        "E2E Latency (s)":19.6,
        "Allocated Memory (MB)":14668,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16166,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.19,
        "Decode Throughput (tokens\/s)":53.0,
        "E2E Throughput (tokens\/s)":52.9,
        "Prefill Latency (s)":0.031,
        "E2E Latency (s)":18.9,
        "Allocated Memory (MB)":14668,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16166,
        "Energy (tokens\/kWh)":495049.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.19**",
        "Decode Throughput (tokens\/s)":54.76,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.0393,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":6347,
        "Reserved Memory (MB)":6641,
        "Used Memory (MB)":8117,
        "Energy (tokens\/kWh)":699300.0
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"OPT",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.19,
        "Decode Throughput (tokens\/s)":65.48,
        "E2E Throughput (tokens\/s)":65.4,
        "Prefill Latency (s)":0.0282,
        "E2E Latency (s)":15.3,
        "Allocated Memory (MB)":14668,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16164,
        "Energy (tokens\/kWh)":584795.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.18**",
        "Decode Throughput (tokens\/s)":42.27,
        "E2E Throughput (tokens\/s)":42.2,
        "Prefill Latency (s)":0.0413,
        "E2E Latency (s)":23.7,
        "Allocated Memory (MB)":6731,
        "Reserved Memory (MB)":6836,
        "Used Memory (MB)":8310,
        "Energy (tokens\/kWh)":502512.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"34.18**",
        "Decode Throughput (tokens\/s)":43.55,
        "E2E Throughput (tokens\/s)":43.5,
        "Prefill Latency (s)":0.0403,
        "E2E Latency (s)":23.0,
        "Allocated Memory (MB)":6730,
        "Reserved Memory (MB)":6836,
        "Used Memory (MB)":8310,
        "Energy (tokens\/kWh)":510204.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":34.18,
        "Decode Throughput (tokens\/s)":52.17,
        "E2E Throughput (tokens\/s)":52.1,
        "Prefill Latency (s)":0.0302,
        "E2E Latency (s)":19.2,
        "Allocated Memory (MB)":15404,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898,
        "Energy (tokens\/kWh)":502512.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":34.18,
        "Decode Throughput (tokens\/s)":52.44,
        "E2E Throughput (tokens\/s)":52.4,
        "Prefill Latency (s)":0.03,
        "E2E Latency (s)":19.1,
        "Allocated Memory (MB)":15404,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898,
        "Energy (tokens\/kWh)":495049.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"34.18**",
        "Decode Throughput (tokens\/s)":53.58,
        "E2E Throughput (tokens\/s)":53.5,
        "Prefill Latency (s)":0.0364,
        "E2E Latency (s)":18.7,
        "Allocated Memory (MB)":7677,
        "Reserved Memory (MB)":7782,
        "Used Memory (MB)":9258,
        "Energy (tokens\/kWh)":666666.0
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"Bloom \ud83c\udf38",
        "Size":7.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":34.18,
        "Decode Throughput (tokens\/s)":54.43,
        "E2E Throughput (tokens\/s)":54.3,
        "Prefill Latency (s)":0.0285,
        "E2E Latency (s)":18.4,
        "Allocated Memory (MB)":15404,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898,
        "Energy (tokens\/kWh)":507614.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.91**",
        "Decode Throughput (tokens\/s)":29.3,
        "E2E Throughput (tokens\/s)":29.2,
        "Prefill Latency (s)":0.0735,
        "E2E Latency (s)":34.2,
        "Allocated Memory (MB)":9441,
        "Reserved Memory (MB)":10529,
        "Used Memory (MB)":12003,
        "Energy (tokens\/kWh)":347222.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.91**",
        "Decode Throughput (tokens\/s)":30.84,
        "E2E Throughput (tokens\/s)":30.8,
        "Prefill Latency (s)":0.0716,
        "E2E Latency (s)":32.5,
        "Allocated Memory (MB)":9441,
        "Reserved Memory (MB)":10557,
        "Used Memory (MB)":12028,
        "Energy (tokens\/kWh)":366300.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.91,
        "Decode Throughput (tokens\/s)":35.15,
        "E2E Throughput (tokens\/s)":35.1,
        "Prefill Latency (s)":0.0492,
        "E2E Latency (s)":28.5,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286,
        "Energy (tokens\/kWh)":324675.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.91,
        "Decode Throughput (tokens\/s)":35.4,
        "E2E Throughput (tokens\/s)":35.3,
        "Prefill Latency (s)":0.0479,
        "E2E Latency (s)":28.3,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286,
        "Energy (tokens\/kWh)":325732.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.91**",
        "Decode Throughput (tokens\/s)":36.05,
        "E2E Throughput (tokens\/s)":36.0,
        "Prefill Latency (s)":0.063,
        "E2E Latency (s)":27.8,
        "Allocated Memory (MB)":10548,
        "Reserved Memory (MB)":12637,
        "Used Memory (MB)":14113,
        "Energy (tokens\/kWh)":465116.0
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Size":11.59,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.91,
        "Decode Throughput (tokens\/s)":38.09,
        "E2E Throughput (tokens\/s)":38.0,
        "Prefill Latency (s)":0.0459,
        "E2E Latency (s)":26.3,
        "Allocated Memory (MB)":25714,
        "Reserved Memory (MB)":27856,
        "Used Memory (MB)":29328,
        "Energy (tokens\/kWh)":341296.0
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Size":7.49,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.84**",
        "Decode Throughput (tokens\/s)":37.11,
        "E2E Throughput (tokens\/s)":37.0,
        "Prefill Latency (s)":0.0505,
        "E2E Latency (s)":27.0,
        "Allocated Memory (MB)":7089,
        "Reserved Memory (MB)":7140,
        "Used Memory (MB)":8614,
        "Energy (tokens\/kWh)":442477.0
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Size":7.49,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.84,
        "Decode Throughput (tokens\/s)":50.33,
        "E2E Throughput (tokens\/s)":50.3,
        "Prefill Latency (s)":0.0331,
        "E2E Latency (s)":19.9,
        "Allocated Memory (MB)":16352,
        "Reserved Memory (MB)":16399,
        "Used Memory (MB)":17873,
        "Energy (tokens\/kWh)":497512.0
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Size":7.49,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.84,
        "Decode Throughput (tokens\/s)":50.59,
        "E2E Throughput (tokens\/s)":50.5,
        "Prefill Latency (s)":0.0333,
        "E2E Latency (s)":19.8,
        "Allocated Memory (MB)":16352,
        "Reserved Memory (MB)":16399,
        "Used Memory (MB)":17873,
        "Energy (tokens\/kWh)":492610.0
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Size":7.49,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.84**",
        "Decode Throughput (tokens\/s)":51.13,
        "E2E Throughput (tokens\/s)":51.0,
        "Prefill Latency (s)":0.0421,
        "E2E Latency (s)":19.6,
        "Allocated Memory (MB)":8031,
        "Reserved Memory (MB)":8327,
        "Used Memory (MB)":9803,
        "Energy (tokens\/kWh)":625000.0
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Size":10.47,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.76**",
        "Decode Throughput (tokens\/s)":29.73,
        "E2E Throughput (tokens\/s)":29.7,
        "Prefill Latency (s)":0.0688,
        "E2E Latency (s)":33.7,
        "Allocated Memory (MB)":8714,
        "Reserved Memory (MB)":9147,
        "Used Memory (MB)":10621,
        "Energy (tokens\/kWh)":354609.0
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Size":10.47,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.76**",
        "Decode Throughput (tokens\/s)":30.27,
        "E2E Throughput (tokens\/s)":30.2,
        "Prefill Latency (s)":0.0667,
        "E2E Latency (s)":33.1,
        "Allocated Memory (MB)":8714,
        "Reserved Memory (MB)":9147,
        "Used Memory (MB)":10619,
        "Energy (tokens\/kWh)":363636.0
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Size":10.47,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.76,
        "Decode Throughput (tokens\/s)":35.77,
        "E2E Throughput (tokens\/s)":35.7,
        "Prefill Latency (s)":0.0456,
        "E2E Latency (s)":28.0,
        "Allocated Memory (MB)":23434,
        "Reserved Memory (MB)":24184,
        "Used Memory (MB)":25658,
        "Energy (tokens\/kWh)":340136.0
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Size":10.47,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.76**",
        "Decode Throughput (tokens\/s)":36.18,
        "E2E Throughput (tokens\/s)":36.1,
        "Prefill Latency (s)":0.0591,
        "E2E Latency (s)":27.7,
        "Allocated Memory (MB)":9824,
        "Reserved Memory (MB)":10458,
        "Used Memory (MB)":11934,
        "Energy (tokens\/kWh)":450450.0
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Size":10.47,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.76,
        "Decode Throughput (tokens\/s)":40.23,
        "E2E Throughput (tokens\/s)":40.2,
        "Prefill Latency (s)":0.0427,
        "E2E Latency (s)":24.9,
        "Allocated Memory (MB)":23434,
        "Reserved Memory (MB)":24184,
        "Used Memory (MB)":25656,
        "Energy (tokens\/kWh)":361010.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.73**",
        "Decode Throughput (tokens\/s)":33.38,
        "E2E Throughput (tokens\/s)":33.3,
        "Prefill Latency (s)":0.0377,
        "E2E Latency (s)":30.0,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516,
        "Energy (tokens\/kWh)":467289.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.73**",
        "Decode Throughput (tokens\/s)":36.41,
        "E2E Throughput (tokens\/s)":36.4,
        "Prefill Latency (s)":0.0328,
        "E2E Latency (s)":27.5,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.73,
        "Decode Throughput (tokens\/s)":39.41,
        "E2E Throughput (tokens\/s)":39.4,
        "Prefill Latency (s)":0.0253,
        "E2E Latency (s)":25.4,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":520833.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.73,
        "Decode Throughput (tokens\/s)":40.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0252,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.73**",
        "Decode Throughput (tokens\/s)":41.03,
        "E2E Throughput (tokens\/s)":41.0,
        "Prefill Latency (s)":0.0262,
        "E2E Latency (s)":24.4,
        "Allocated Memory (MB)":3548,
        "Reserved Memory (MB)":3776,
        "Used Memory (MB)":5252,
        "Energy (tokens\/kWh)":571428.0
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.73,
        "Decode Throughput (tokens\/s)":44.89,
        "E2E Throughput (tokens\/s)":44.8,
        "Prefill Latency (s)":0.0211,
        "E2E Latency (s)":22.3,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":591715.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.54**",
        "Decode Throughput (tokens\/s)":23.12,
        "E2E Throughput (tokens\/s)":23.1,
        "Prefill Latency (s)":0.0544,
        "E2E Latency (s)":43.3,
        "Allocated Memory (MB)":4062,
        "Reserved Memory (MB)":4198,
        "Used Memory (MB)":5672,
        "Energy (tokens\/kWh)":320512.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.54**",
        "Decode Throughput (tokens\/s)":24.97,
        "E2E Throughput (tokens\/s)":24.9,
        "Prefill Latency (s)":0.0488,
        "E2E Latency (s)":40.1,
        "Allocated Memory (MB)":4062,
        "Reserved Memory (MB)":4198,
        "Used Memory (MB)":5672,
        "Energy (tokens\/kWh)":343642.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.54,
        "Decode Throughput (tokens\/s)":27.2,
        "E2E Throughput (tokens\/s)":27.2,
        "Prefill Latency (s)":0.0366,
        "E2E Latency (s)":36.8,
        "Allocated Memory (MB)":9382,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158,
        "Energy (tokens\/kWh)":358422.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.54,
        "Decode Throughput (tokens\/s)":27.43,
        "E2E Throughput (tokens\/s)":27.4,
        "Prefill Latency (s)":0.0375,
        "E2E Latency (s)":36.5,
        "Allocated Memory (MB)":9382,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158,
        "Energy (tokens\/kWh)":362318.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.54**",
        "Decode Throughput (tokens\/s)":27.73,
        "E2E Throughput (tokens\/s)":27.7,
        "Prefill Latency (s)":0.0387,
        "E2E Latency (s)":36.1,
        "Allocated Memory (MB)":4626,
        "Reserved Memory (MB)":4942,
        "Used Memory (MB)":6418,
        "Energy (tokens\/kWh)":386100.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Size":3.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.54,
        "Decode Throughput (tokens\/s)":30.7,
        "E2E Throughput (tokens\/s)":30.7,
        "Prefill Latency (s)":0.0312,
        "E2E Latency (s)":32.6,
        "Allocated Memory (MB)":9381,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158,
        "Energy (tokens\/kWh)":403225.0
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.52**",
        "Decode Throughput (tokens\/s)":35.01,
        "E2E Throughput (tokens\/s)":35.0,
        "Prefill Latency (s)":0.0382,
        "E2E Latency (s)":28.6,
        "Allocated Memory (MB)":3114,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4896,
        "Energy (tokens\/kWh)":476190.0
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.52**",
        "Decode Throughput (tokens\/s)":35.76,
        "E2E Throughput (tokens\/s)":35.7,
        "Prefill Latency (s)":0.0389,
        "E2E Latency (s)":28.0,
        "Allocated Memory (MB)":3122,
        "Reserved Memory (MB)":3458,
        "Used Memory (MB)":4931,
        "Energy (tokens\/kWh)":492610.0
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.52,
        "Decode Throughput (tokens\/s)":44.49,
        "E2E Throughput (tokens\/s)":44.4,
        "Prefill Latency (s)":0.0221,
        "E2E Latency (s)":22.5,
        "Allocated Memory (MB)":7770,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629,
        "Energy (tokens\/kWh)":555555.0
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.52,
        "Decode Throughput (tokens\/s)":45.71,
        "E2E Throughput (tokens\/s)":45.7,
        "Prefill Latency (s)":0.0221,
        "E2E Latency (s)":21.9,
        "Allocated Memory (MB)":7770,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629,
        "Energy (tokens\/kWh)":578034.0
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.52,
        "Decode Throughput (tokens\/s)":47.0,
        "E2E Throughput (tokens\/s)":46.9,
        "Prefill Latency (s)":0.0228,
        "E2E Latency (s)":21.3,
        "Allocated Memory (MB)":7779,
        "Reserved Memory (MB)":8172,
        "Used Memory (MB)":9646,
        "Energy (tokens\/kWh)":595238.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.31**",
        "Decode Throughput (tokens\/s)":32.52,
        "E2E Throughput (tokens\/s)":32.5,
        "Prefill Latency (s)":0.0479,
        "E2E Latency (s)":30.8,
        "Allocated Memory (MB)":5973,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7511,
        "Energy (tokens\/kWh)":416666.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.31**",
        "Decode Throughput (tokens\/s)":36.16,
        "E2E Throughput (tokens\/s)":36.1,
        "Prefill Latency (s)":0.0454,
        "E2E Latency (s)":27.7,
        "Allocated Memory (MB)":5974,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7509,
        "Energy (tokens\/kWh)":456621.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":33.31,
        "Decode Throughput (tokens\/s)":40.05,
        "E2E Throughput (tokens\/s)":40.0,
        "Prefill Latency (s)":0.0319,
        "E2E Latency (s)":25.0,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715,
        "Energy (tokens\/kWh)":418410.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.31,
        "Decode Throughput (tokens\/s)":40.54,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0312,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715,
        "Energy (tokens\/kWh)":434782.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"33.31**",
        "Decode Throughput (tokens\/s)":40.72,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0415,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":6884,
        "Reserved Memory (MB)":6905,
        "Used Memory (MB)":8381,
        "Energy (tokens\/kWh)":526315.0
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Size":6.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":33.31,
        "Decode Throughput (tokens\/s)":46.79,
        "E2E Throughput (tokens\/s)":46.7,
        "Prefill Latency (s)":0.0292,
        "E2E Latency (s)":21.4,
        "Allocated Memory (MB)":15208,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16713,
        "Energy (tokens\/kWh)":478468.0
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"RWKV",
        "Size":7.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"33.19**",
        "Decode Throughput (tokens\/s)":22.2,
        "E2E Throughput (tokens\/s)":22.2,
        "Prefill Latency (s)":0.0581,
        "E2E Latency (s)":45.1,
        "Allocated Memory (MB)":4799,
        "Reserved Memory (MB)":5012,
        "Used Memory (MB)":6485,
        "Energy (tokens\/kWh)":295857.0
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"RWKV",
        "Size":7.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":33.19,
        "Decode Throughput (tokens\/s)":29.71,
        "E2E Throughput (tokens\/s)":29.7,
        "Prefill Latency (s)":0.0359,
        "E2E Latency (s)":33.7,
        "Allocated Memory (MB)":14829,
        "Reserved Memory (MB)":14881,
        "Used Memory (MB)":16355,
        "Energy (tokens\/kWh)":352112.0
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":21.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.8**",
        "Decode Throughput (tokens\/s)":23.32,
        "E2E Throughput (tokens\/s)":23.3,
        "Prefill Latency (s)":0.125,
        "E2E Latency (s)":43.0,
        "Allocated Memory (MB)":15625,
        "Reserved Memory (MB)":17714,
        "Used Memory (MB)":19188,
        "Energy (tokens\/kWh)":240384.0
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":21.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.8**",
        "Decode Throughput (tokens\/s)":24.77,
        "E2E Throughput (tokens\/s)":24.7,
        "Prefill Latency (s)":0.122,
        "E2E Latency (s)":40.5,
        "Allocated Memory (MB)":15625,
        "Reserved Memory (MB)":17802,
        "Used Memory (MB)":19276,
        "Energy (tokens\/kWh)":233100.0
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":21.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.8,
        "Decode Throughput (tokens\/s)":26.1,
        "E2E Throughput (tokens\/s)":26.0,
        "Prefill Latency (s)":0.0826,
        "E2E Latency (s)":38.4,
        "Allocated Memory (MB)":46448,
        "Reserved Memory (MB)":49234,
        "Used Memory (MB)":50708,
        "Energy (tokens\/kWh)":234741.0
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":21.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.8,
        "Decode Throughput (tokens\/s)":26.44,
        "E2E Throughput (tokens\/s)":26.4,
        "Prefill Latency (s)":0.0809,
        "E2E Latency (s)":37.9,
        "Allocated Memory (MB)":46447,
        "Reserved Memory (MB)":49234,
        "Used Memory (MB)":50708,
        "Energy (tokens\/kWh)":239234.0
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":21.83,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.8**",
        "Decode Throughput (tokens\/s)":28.34,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":0.11,
        "E2E Latency (s)":35.4,
        "Allocated Memory (MB)":16290,
        "Reserved Memory (MB)":18970,
        "Used Memory (MB)":20446,
        "Energy (tokens\/kWh)":322580.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.68**",
        "Decode Throughput (tokens\/s)":35.27,
        "E2E Throughput (tokens\/s)":35.2,
        "Prefill Latency (s)":0.0442,
        "E2E Latency (s)":28.4,
        "Allocated Memory (MB)":27939,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31756,
        "Energy (tokens\/kWh)":387596.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.68,
        "Decode Throughput (tokens\/s)":35.52,
        "E2E Throughput (tokens\/s)":35.5,
        "Prefill Latency (s)":0.0501,
        "E2E Latency (s)":28.2,
        "Allocated Memory (MB)":27939,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31756,
        "Energy (tokens\/kWh)":320512.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.68**",
        "Decode Throughput (tokens\/s)":37.79,
        "E2E Throughput (tokens\/s)":37.7,
        "Prefill Latency (s)":0.0395,
        "E2E Latency (s)":26.5,
        "Allocated Memory (MB)":27939,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31754,
        "Energy (tokens\/kWh)":393700.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.68,
        "Decode Throughput (tokens\/s)":38.68,
        "E2E Throughput (tokens\/s)":38.6,
        "Prefill Latency (s)":0.0501,
        "E2E Latency (s)":25.9,
        "Allocated Memory (MB)":27939,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31754,
        "Energy (tokens\/kWh)":348432.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.68**",
        "Decode Throughput (tokens\/s)":40.43,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0668,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":10916,
        "Reserved Memory (MB)":13218,
        "Used Memory (MB)":14694,
        "Energy (tokens\/kWh)":352112.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Size":12.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.68**",
        "Decode Throughput (tokens\/s)":42.86,
        "E2E Throughput (tokens\/s)":42.7,
        "Prefill Latency (s)":0.0661,
        "E2E Latency (s)":23.4,
        "Allocated Memory (MB)":9568,
        "Reserved Memory (MB)":11867,
        "Used Memory (MB)":13343,
        "Energy (tokens\/kWh)":462962.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":33.37,
        "E2E Throughput (tokens\/s)":33.3,
        "Prefill Latency (s)":0.0372,
        "E2E Latency (s)":30.0,
        "Allocated Memory (MB)":2918,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506,
        "Energy (tokens\/kWh)":469483.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":36.81,
        "E2E Throughput (tokens\/s)":36.8,
        "Prefill Latency (s)":0.0326,
        "E2E Latency (s)":27.2,
        "Allocated Memory (MB)":2918,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":40.37,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0274,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":3532,
        "Reserved Memory (MB)":3755,
        "Used Memory (MB)":5231,
        "Energy (tokens\/kWh)":552486.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.44,
        "Decode Throughput (tokens\/s)":40.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0254,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":531914.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":32.44,
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.026,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":523560.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":41.03,
        "E2E Throughput (tokens\/s)":41.0,
        "Prefill Latency (s)":0.0262,
        "E2E Latency (s)":24.4,
        "Allocated Memory (MB)":2858,
        "Reserved Memory (MB)":3080,
        "Used Memory (MB)":4556,
        "Energy (tokens\/kWh)":578034.0
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.44,
        "Decode Throughput (tokens\/s)":44.49,
        "E2E Throughput (tokens\/s)":44.4,
        "Prefill Latency (s)":0.0212,
        "E2E Latency (s)":22.5,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":584795.0
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":52.98,
        "E2E Throughput (tokens\/s)":52.9,
        "Prefill Latency (s)":0.0236,
        "E2E Latency (s)":18.9,
        "Allocated Memory (MB)":1397,
        "Reserved Memory (MB)":1455,
        "Used Memory (MB)":2929,
        "Energy (tokens\/kWh)":740740.0
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":60.68,
        "E2E Throughput (tokens\/s)":60.6,
        "Prefill Latency (s)":0.0192,
        "E2E Latency (s)":16.5,
        "Allocated Memory (MB)":1920,
        "Reserved Memory (MB)":1977,
        "Used Memory (MB)":3453,
        "Energy (tokens\/kWh)":869565.0
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":32.44,
        "Decode Throughput (tokens\/s)":65.43,
        "E2E Throughput (tokens\/s)":65.4,
        "Prefill Latency (s)":0.0163,
        "E2E Latency (s)":15.3,
        "Allocated Memory (MB)":3135,
        "Reserved Memory (MB)":3214,
        "Used Memory (MB)":4688,
        "Energy (tokens\/kWh)":869565.0
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.44,
        "Decode Throughput (tokens\/s)":66.29,
        "E2E Throughput (tokens\/s)":66.2,
        "Prefill Latency (s)":0.0154,
        "E2E Latency (s)":15.1,
        "Allocated Memory (MB)":3135,
        "Reserved Memory (MB)":3214,
        "Used Memory (MB)":4688,
        "Energy (tokens\/kWh)":869565.0
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.44**",
        "Decode Throughput (tokens\/s)":67.64,
        "E2E Throughput (tokens\/s)":67.6,
        "Prefill Latency (s)":0.0158,
        "E2E Latency (s)":14.8,
        "Allocated Memory (MB)":1382,
        "Reserved Memory (MB)":1457,
        "Used Memory (MB)":2933,
        "Energy (tokens\/kWh)":943396.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.37**",
        "Decode Throughput (tokens\/s)":16.38,
        "E2E Throughput (tokens\/s)":16.4,
        "Prefill Latency (s)":0.0381,
        "E2E Latency (s)":61.1,
        "Allocated Memory (MB)":2497,
        "Reserved Memory (MB)":8862,
        "Used Memory (MB)":10336,
        "Energy (tokens\/kWh)":152439.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.37**",
        "Decode Throughput (tokens\/s)":16.87,
        "E2E Throughput (tokens\/s)":16.9,
        "Prefill Latency (s)":0.027,
        "E2E Latency (s)":59.3,
        "Allocated Memory (MB)":3110,
        "Reserved Memory (MB)":10468,
        "Used Memory (MB)":11944,
        "Energy (tokens\/kWh)":155038.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.37**",
        "Decode Throughput (tokens\/s)":17.34,
        "E2E Throughput (tokens\/s)":17.3,
        "Prefill Latency (s)":0.0271,
        "E2E Latency (s)":57.7,
        "Allocated Memory (MB)":2437,
        "Reserved Memory (MB)":9793,
        "Used Memory (MB)":11269,
        "Energy (tokens\/kWh)":159744.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":32.37,
        "Decode Throughput (tokens\/s)":18.12,
        "E2E Throughput (tokens\/s)":18.1,
        "Prefill Latency (s)":0.026,
        "E2E Latency (s)":55.2,
        "Allocated Memory (MB)":6117,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956,
        "Energy (tokens\/kWh)":168918.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.37,
        "Decode Throughput (tokens\/s)":18.26,
        "E2E Throughput (tokens\/s)":18.2,
        "Prefill Latency (s)":0.0261,
        "E2E Latency (s)":54.8,
        "Allocated Memory (MB)":6117,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956,
        "Energy (tokens\/kWh)":169491.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.37**",
        "Decode Throughput (tokens\/s)":22.49,
        "E2E Throughput (tokens\/s)":22.5,
        "Prefill Latency (s)":0.0338,
        "E2E Latency (s)":44.5,
        "Allocated Memory (MB)":2370,
        "Reserved Memory (MB)":8862,
        "Used Memory (MB)":10336,
        "Energy (tokens\/kWh)":209643.0
    },
    {
        "Model":"Rallio67\/3B-redpajama-conditional-alpha",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.37,
        "Decode Throughput (tokens\/s)":26.19,
        "E2E Throughput (tokens\/s)":26.2,
        "Prefill Latency (s)":0.022,
        "E2E Latency (s)":38.2,
        "Allocated Memory (MB)":5990,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956,
        "Energy (tokens\/kWh)":240384.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.17**",
        "Decode Throughput (tokens\/s)":36.95,
        "E2E Throughput (tokens\/s)":36.9,
        "Prefill Latency (s)":0.0378,
        "E2E Latency (s)":27.1,
        "Allocated Memory (MB)":2518,
        "Reserved Memory (MB)":2634,
        "Used Memory (MB)":4107,
        "Energy (tokens\/kWh)":505050.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.17**",
        "Decode Throughput (tokens\/s)":41.72,
        "E2E Throughput (tokens\/s)":41.7,
        "Prefill Latency (s)":0.0325,
        "E2E Latency (s)":24.0,
        "Allocated Memory (MB)":2517,
        "Reserved Memory (MB)":2629,
        "Used Memory (MB)":4103,
        "Energy (tokens\/kWh)":571428.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.17**",
        "Decode Throughput (tokens\/s)":45.93,
        "E2E Throughput (tokens\/s)":45.9,
        "Prefill Latency (s)":0.0255,
        "E2E Latency (s)":21.8,
        "Allocated Memory (MB)":3138,
        "Reserved Memory (MB)":3359,
        "Used Memory (MB)":4835,
        "Energy (tokens\/kWh)":636942.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.17**",
        "Decode Throughput (tokens\/s)":53.83,
        "E2E Throughput (tokens\/s)":53.8,
        "Prefill Latency (s)":0.0225,
        "E2E Latency (s)":18.6,
        "Allocated Memory (MB)":2464,
        "Reserved Memory (MB)":2684,
        "Used Memory (MB)":4160,
        "Energy (tokens\/kWh)":675675.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":32.17,
        "Decode Throughput (tokens\/s)":53.82,
        "E2E Throughput (tokens\/s)":53.8,
        "Prefill Latency (s)":0.0198,
        "E2E Latency (s)":18.6,
        "Allocated Memory (MB)":6135,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7912,
        "Energy (tokens\/kWh)":662251.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.17,
        "Decode Throughput (tokens\/s)":54.11,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0196,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":6135,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7912,
        "Energy (tokens\/kWh)":675675.0
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"OPT",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.17,
        "Decode Throughput (tokens\/s)":62.56,
        "E2E Throughput (tokens\/s)":62.5,
        "Prefill Latency (s)":0.0156,
        "E2E Latency (s)":16.0,
        "Allocated Memory (MB)":6135,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7909,
        "Energy (tokens\/kWh)":763358.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.11**",
        "Decode Throughput (tokens\/s)":33.94,
        "E2E Throughput (tokens\/s)":33.9,
        "Prefill Latency (s)":0.0379,
        "E2E Latency (s)":29.5,
        "Allocated Memory (MB)":2918,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506,
        "Energy (tokens\/kWh)":462962.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"32.11**",
        "Decode Throughput (tokens\/s)":36.54,
        "E2E Throughput (tokens\/s)":36.5,
        "Prefill Latency (s)":0.0329,
        "E2E Latency (s)":27.4,
        "Allocated Memory (MB)":2918,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506,
        "Energy (tokens\/kWh)":500000.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.11**",
        "Decode Throughput (tokens\/s)":37.21,
        "E2E Throughput (tokens\/s)":37.2,
        "Prefill Latency (s)":0.0272,
        "E2E Latency (s)":26.9,
        "Allocated Memory (MB)":3532,
        "Reserved Memory (MB)":3755,
        "Used Memory (MB)":5231,
        "Energy (tokens\/kWh)":561797.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":32.11,
        "Decode Throughput (tokens\/s)":40.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Prefill Latency (s)":0.0252,
        "E2E Latency (s)":24.8,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":537634.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":32.11,
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0252,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":526315.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"32.11**",
        "Decode Throughput (tokens\/s)":40.69,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0261,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":2858,
        "Reserved Memory (MB)":3080,
        "Used Memory (MB)":4556,
        "Energy (tokens\/kWh)":555555.0
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Size":2.91,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":32.11,
        "Decode Throughput (tokens\/s)":45.09,
        "E2E Throughput (tokens\/s)":45.0,
        "Prefill Latency (s)":0.0209,
        "E2E Latency (s)":22.2,
        "Allocated Memory (MB)":6539,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224,
        "Energy (tokens\/kWh)":578034.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.77,
        "Decode Throughput (tokens\/s)":53.56,
        "E2E Throughput (tokens\/s)":53.5,
        "Prefill Latency (s)":0.0288,
        "E2E Latency (s)":18.7,
        "Allocated Memory (MB)":14803,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332,
        "Energy (tokens\/kWh)":507614.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.77**",
        "Decode Throughput (tokens\/s)":53.55,
        "E2E Throughput (tokens\/s)":53.5,
        "Prefill Latency (s)":0.0259,
        "E2E Latency (s)":18.7,
        "Allocated Memory (MB)":14803,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332,
        "Energy (tokens\/kWh)":606060.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.77,
        "Decode Throughput (tokens\/s)":53.85,
        "E2E Throughput (tokens\/s)":53.8,
        "Prefill Latency (s)":0.0284,
        "E2E Latency (s)":18.6,
        "Allocated Memory (MB)":14803,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332,
        "Energy (tokens\/kWh)":531914.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.77**",
        "Decode Throughput (tokens\/s)":55.99,
        "E2E Throughput (tokens\/s)":55.9,
        "Prefill Latency (s)":0.0392,
        "E2E Latency (s)":17.9,
        "Allocated Memory (MB)":6478,
        "Reserved Memory (MB)":6499,
        "Used Memory (MB)":7974,
        "Energy (tokens\/kWh)":694444.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.77**",
        "Decode Throughput (tokens\/s)":56.94,
        "E2E Throughput (tokens\/s)":56.8,
        "Prefill Latency (s)":0.0378,
        "E2E Latency (s)":17.6,
        "Allocated Memory (MB)":5401,
        "Reserved Memory (MB)":5419,
        "Used Memory (MB)":6894,
        "Energy (tokens\/kWh)":641025.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.77**",
        "Decode Throughput (tokens\/s)":62.59,
        "E2E Throughput (tokens\/s)":62.5,
        "Prefill Latency (s)":0.0231,
        "E2E Latency (s)":16.0,
        "Allocated Memory (MB)":14803,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16329,
        "Energy (tokens\/kWh)":689655.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Size":6.66,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":31.77,
        "Decode Throughput (tokens\/s)":62.61,
        "E2E Throughput (tokens\/s)":62.5,
        "Prefill Latency (s)":0.0274,
        "E2E Latency (s)":16.0,
        "Allocated Memory (MB)":14803,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16329,
        "Energy (tokens\/kWh)":568181.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.71**",
        "Decode Throughput (tokens\/s)":34.53,
        "E2E Throughput (tokens\/s)":34.5,
        "Prefill Latency (s)":0.0396,
        "E2E Latency (s)":29.0,
        "Allocated Memory (MB)":2686,
        "Reserved Memory (MB)":2900,
        "Used Memory (MB)":4374,
        "Energy (tokens\/kWh)":476190.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.71**",
        "Decode Throughput (tokens\/s)":38.66,
        "E2E Throughput (tokens\/s)":38.6,
        "Prefill Latency (s)":0.0354,
        "E2E Latency (s)":25.9,
        "Allocated Memory (MB)":2674,
        "Reserved Memory (MB)":2797,
        "Used Memory (MB)":4271,
        "Energy (tokens\/kWh)":537634.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.71,
        "Decode Throughput (tokens\/s)":43.33,
        "E2E Throughput (tokens\/s)":43.3,
        "Prefill Latency (s)":0.0227,
        "E2E Latency (s)":23.1,
        "Allocated Memory (MB)":6281,
        "Reserved Memory (MB)":6727,
        "Used Memory (MB)":8201,
        "Energy (tokens\/kWh)":578034.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.71**",
        "Decode Throughput (tokens\/s)":43.91,
        "E2E Throughput (tokens\/s)":43.9,
        "Prefill Latency (s)":0.0258,
        "E2E Latency (s)":22.8,
        "Allocated Memory (MB)":2624,
        "Reserved Memory (MB)":2908,
        "Used Memory (MB)":4384,
        "Energy (tokens\/kWh)":574712.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":31.71,
        "Decode Throughput (tokens\/s)":44.49,
        "E2E Throughput (tokens\/s)":44.4,
        "Prefill Latency (s)":0.0217,
        "E2E Latency (s)":22.5,
        "Allocated Memory (MB)":6269,
        "Reserved Memory (MB)":6631,
        "Used Memory (MB)":8104,
        "Energy (tokens\/kWh)":574712.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.71**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0269,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":3298,
        "Reserved Memory (MB)":3571,
        "Used Memory (MB)":5047,
        "Energy (tokens\/kWh)":581395.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Size":2.72,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.71,
        "Decode Throughput (tokens\/s)":45.09,
        "E2E Throughput (tokens\/s)":45.0,
        "Prefill Latency (s)":0.0225,
        "E2E Latency (s)":22.2,
        "Allocated Memory (MB)":6281,
        "Reserved Memory (MB)":6727,
        "Used Memory (MB)":8201,
        "Energy (tokens\/kWh)":568181.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.56**",
        "Decode Throughput (tokens\/s)":33.49,
        "E2E Throughput (tokens\/s)":33.4,
        "Prefill Latency (s)":0.0371,
        "E2E Latency (s)":29.9,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516,
        "Energy (tokens\/kWh)":467289.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.56**",
        "Decode Throughput (tokens\/s)":37.08,
        "E2E Throughput (tokens\/s)":37.0,
        "Prefill Latency (s)":0.0337,
        "E2E Latency (s)":27.0,
        "Allocated Memory (MB)":2933,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516,
        "Energy (tokens\/kWh)":512820.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.56**",
        "Decode Throughput (tokens\/s)":39.41,
        "E2E Throughput (tokens\/s)":39.4,
        "Prefill Latency (s)":0.0264,
        "E2E Latency (s)":25.4,
        "Allocated Memory (MB)":3548,
        "Reserved Memory (MB)":3776,
        "Used Memory (MB)":5252,
        "Energy (tokens\/kWh)":568181.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.56,
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0251,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":540540.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.56,
        "Decode Throughput (tokens\/s)":40.69,
        "E2E Throughput (tokens\/s)":40.7,
        "Prefill Latency (s)":0.0253,
        "E2E Latency (s)":24.6,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":523560.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.56**",
        "Decode Throughput (tokens\/s)":41.71,
        "E2E Throughput (tokens\/s)":41.7,
        "Prefill Latency (s)":0.027,
        "E2E Latency (s)":24.0,
        "Allocated Memory (MB)":2874,
        "Reserved Memory (MB)":3099,
        "Used Memory (MB)":4575,
        "Energy (tokens\/kWh)":552486.0
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":31.56,
        "Decode Throughput (tokens\/s)":44.89,
        "E2E Throughput (tokens\/s)":44.8,
        "Prefill Latency (s)":0.0213,
        "E2E Latency (s)":22.3,
        "Allocated Memory (MB)":6555,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243,
        "Energy (tokens\/kWh)":584795.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.5**",
        "Decode Throughput (tokens\/s)":42.43,
        "E2E Throughput (tokens\/s)":42.4,
        "Prefill Latency (s)":0.0311,
        "E2E Latency (s)":23.6,
        "Allocated Memory (MB)":3407,
        "Reserved Memory (MB)":3495,
        "Used Memory (MB)":4969,
        "Energy (tokens\/kWh)":558659.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.5**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0284,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":3408,
        "Reserved Memory (MB)":3491,
        "Used Memory (MB)":4965,
        "Energy (tokens\/kWh)":598802.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.5**",
        "Decode Throughput (tokens\/s)":51.34,
        "E2E Throughput (tokens\/s)":51.3,
        "Prefill Latency (s)":0.0209,
        "E2E Latency (s)":19.5,
        "Allocated Memory (MB)":3348,
        "Reserved Memory (MB)":3554,
        "Used Memory (MB)":5030,
        "Energy (tokens\/kWh)":680272.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.5,
        "Decode Throughput (tokens\/s)":51.87,
        "E2E Throughput (tokens\/s)":51.8,
        "Prefill Latency (s)":0.0204,
        "E2E Latency (s)":19.3,
        "Allocated Memory (MB)":6803,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411,
        "Energy (tokens\/kWh)":649350.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.5,
        "Decode Throughput (tokens\/s)":52.96,
        "E2E Throughput (tokens\/s)":52.9,
        "Prefill Latency (s)":0.0196,
        "E2E Latency (s)":18.9,
        "Allocated Memory (MB)":6803,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411,
        "Energy (tokens\/kWh)":662251.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.5**",
        "Decode Throughput (tokens\/s)":54.71,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.0204,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":4021,
        "Reserved Memory (MB)":4250,
        "Used Memory (MB)":5726,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"Bloom \ud83c\udf38",
        "Size":3.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":31.5,
        "Decode Throughput (tokens\/s)":55.3,
        "E2E Throughput (tokens\/s)":55.2,
        "Prefill Latency (s)":0.017,
        "E2E Latency (s)":18.1,
        "Allocated Memory (MB)":6802,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411,
        "Energy (tokens\/kWh)":680272.0
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Size":5.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.05**",
        "Decode Throughput (tokens\/s)":25.23,
        "E2E Throughput (tokens\/s)":25.2,
        "Prefill Latency (s)":0.0646,
        "E2E Latency (s)":39.7,
        "Allocated Memory (MB)":4338,
        "Reserved Memory (MB)":4471,
        "Used Memory (MB)":5944,
        "Energy (tokens\/kWh)":337837.0
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Size":5.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.05,
        "Decode Throughput (tokens\/s)":35.38,
        "E2E Throughput (tokens\/s)":35.3,
        "Prefill Latency (s)":0.032,
        "E2E Latency (s)":28.3,
        "Allocated Memory (MB)":10128,
        "Reserved Memory (MB)":10695,
        "Used Memory (MB)":12169,
        "Energy (tokens\/kWh)":431034.0
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Size":5.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.05**",
        "Decode Throughput (tokens\/s)":35.51,
        "E2E Throughput (tokens\/s)":35.5,
        "Prefill Latency (s)":0.0373,
        "E2E Latency (s)":28.2,
        "Allocated Memory (MB)":4238,
        "Reserved Memory (MB)":4397,
        "Used Memory (MB)":5873,
        "Energy (tokens\/kWh)":465116.0
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Size":5.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.05,
        "Decode Throughput (tokens\/s)":35.75,
        "E2E Throughput (tokens\/s)":35.7,
        "Prefill Latency (s)":0.0316,
        "E2E Latency (s)":28.0,
        "Allocated Memory (MB)":10128,
        "Reserved Memory (MB)":10695,
        "Used Memory (MB)":12169,
        "Energy (tokens\/kWh)":421940.0
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Size":5.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.05**",
        "Decode Throughput (tokens\/s)":36.41,
        "E2E Throughput (tokens\/s)":36.4,
        "Prefill Latency (s)":0.0376,
        "E2E Latency (s)":27.5,
        "Allocated Memory (MB)":5317,
        "Reserved Memory (MB)":5479,
        "Used Memory (MB)":6955,
        "Energy (tokens\/kWh)":483091.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.02**",
        "Decode Throughput (tokens\/s)":62.67,
        "E2E Throughput (tokens\/s)":62.5,
        "Prefill Latency (s)":0.0438,
        "E2E Latency (s)":16.0,
        "Allocated Memory (MB)":6593,
        "Reserved Memory (MB)":6949,
        "Used Memory (MB)":8423,
        "Energy (tokens\/kWh)":671140.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.02**",
        "Decode Throughput (tokens\/s)":63.04,
        "E2E Throughput (tokens\/s)":62.9,
        "Prefill Latency (s)":0.0359,
        "E2E Latency (s)":15.9,
        "Allocated Memory (MB)":6586,
        "Reserved Memory (MB)":7897,
        "Used Memory (MB)":9373,
        "Energy (tokens\/kWh)":540540.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.02,
        "Decode Throughput (tokens\/s)":65.48,
        "E2E Throughput (tokens\/s)":65.4,
        "Prefill Latency (s)":0.0277,
        "E2E Latency (s)":15.3,
        "Allocated Memory (MB)":17012,
        "Reserved Memory (MB)":18278,
        "Used Memory (MB)":19752,
        "Energy (tokens\/kWh)":584795.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":31.02,
        "Decode Throughput (tokens\/s)":68.62,
        "E2E Throughput (tokens\/s)":68.5,
        "Prefill Latency (s)":0.0276,
        "E2E Latency (s)":14.6,
        "Allocated Memory (MB)":17012,
        "Reserved Memory (MB)":18324,
        "Used Memory (MB)":19796,
        "Energy (tokens\/kWh)":625000.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.02**",
        "Decode Throughput (tokens\/s)":70.63,
        "E2E Throughput (tokens\/s)":70.4,
        "Prefill Latency (s)":0.0422,
        "E2E Latency (s)":14.2,
        "Allocated Memory (MB)":6593,
        "Reserved Memory (MB)":6989,
        "Used Memory (MB)":8461,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Size":7.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"31.02**",
        "Decode Throughput (tokens\/s)":80.24,
        "E2E Throughput (tokens\/s)":80.0,
        "Prefill Latency (s)":0.0371,
        "E2E Latency (s)":12.5,
        "Allocated Memory (MB)":8200,
        "Reserved Memory (MB)":9512,
        "Used Memory (MB)":10988,
        "Energy (tokens\/kWh)":900900.0
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"RWKV",
        "Size":2.86,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"31.0**",
        "Decode Throughput (tokens\/s)":21.85,
        "E2E Throughput (tokens\/s)":20.8,
        "Prefill Latency (s)":2.23,
        "E2E Latency (s)":48.0,
        "Allocated Memory (MB)":2082,
        "Reserved Memory (MB)":2170,
        "Used Memory (MB)":3644,
        "Energy (tokens\/kWh)":306748.0
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"RWKV",
        "Size":2.86,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":31.0,
        "Decode Throughput (tokens\/s)":29.3,
        "E2E Throughput (tokens\/s)":27.6,
        "Prefill Latency (s)":2.07,
        "E2E Latency (s)":36.2,
        "Allocated Memory (MB)":6007,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7746,
        "Energy (tokens\/kWh)":390625.0
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"RWKV",
        "Size":2.86,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":31.0,
        "Decode Throughput (tokens\/s)":29.1,
        "E2E Throughput (tokens\/s)":29.1,
        "Prefill Latency (s)":0.034,
        "E2E Latency (s)":34.4,
        "Allocated Memory (MB)":6007,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7746,
        "Energy (tokens\/kWh)":411522.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.84**",
        "Decode Throughput (tokens\/s)":70.07,
        "E2E Throughput (tokens\/s)":69.9,
        "Prefill Latency (s)":0.0292,
        "E2E Latency (s)":14.3,
        "Allocated Memory (MB)":4194,
        "Reserved Memory (MB)":4227,
        "Used Memory (MB)":5703,
        "Energy (tokens\/kWh)":813008.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.84**",
        "Decode Throughput (tokens\/s)":71.53,
        "E2E Throughput (tokens\/s)":71.4,
        "Prefill Latency (s)":0.02,
        "E2E Latency (s)":14.0,
        "Allocated Memory (MB)":11211,
        "Reserved Memory (MB)":11236,
        "Used Memory (MB)":12710,
        "Energy (tokens\/kWh)":813008.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":30.84,
        "Decode Throughput (tokens\/s)":71.54,
        "E2E Throughput (tokens\/s)":71.4,
        "Prefill Latency (s)":0.0217,
        "E2E Latency (s)":14.0,
        "Allocated Memory (MB)":11212,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12731,
        "Energy (tokens\/kWh)":709219.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":30.84,
        "Decode Throughput (tokens\/s)":72.06,
        "E2E Throughput (tokens\/s)":71.9,
        "Prefill Latency (s)":0.0219,
        "E2E Latency (s)":13.9,
        "Allocated Memory (MB)":11212,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12731,
        "Energy (tokens\/kWh)":675675.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.84**",
        "Decode Throughput (tokens\/s)":74.24,
        "E2E Throughput (tokens\/s)":74.1,
        "Prefill Latency (s)":0.0297,
        "E2E Latency (s)":13.5,
        "Allocated Memory (MB)":5270,
        "Reserved Memory (MB)":5307,
        "Used Memory (MB)":6783,
        "Energy (tokens\/kWh)":917431.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.84**",
        "Decode Throughput (tokens\/s)":82.77,
        "E2E Throughput (tokens\/s)":82.6,
        "Prefill Latency (s)":0.0183,
        "E2E Latency (s)":12.1,
        "Allocated Memory (MB)":11212,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12729,
        "Energy (tokens\/kWh)":900900.0
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Size":5.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":30.84,
        "Decode Throughput (tokens\/s)":82.78,
        "E2E Throughput (tokens\/s)":82.6,
        "Prefill Latency (s)":0.0204,
        "E2E Latency (s)":12.1,
        "Allocated Memory (MB)":11212,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12729,
        "Energy (tokens\/kWh)":751879.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.62**",
        "Decode Throughput (tokens\/s)":44.3,
        "E2E Throughput (tokens\/s)":44.2,
        "Prefill Latency (s)":0.0276,
        "E2E Latency (s)":22.6,
        "Allocated Memory (MB)":1710,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3260,
        "Energy (tokens\/kWh)":641025.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.62**",
        "Decode Throughput (tokens\/s)":50.06,
        "E2E Throughput (tokens\/s)":50.0,
        "Prefill Latency (s)":0.0247,
        "E2E Latency (s)":20.0,
        "Allocated Memory (MB)":1710,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3258,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":30.62,
        "Decode Throughput (tokens\/s)":52.96,
        "E2E Throughput (tokens\/s)":52.9,
        "Prefill Latency (s)":0.0189,
        "E2E Latency (s)":18.9,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":30.62,
        "Decode Throughput (tokens\/s)":53.25,
        "E2E Throughput (tokens\/s)":53.2,
        "Prefill Latency (s)":0.019,
        "E2E Latency (s)":18.8,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.62**",
        "Decode Throughput (tokens\/s)":53.82,
        "E2E Throughput (tokens\/s)":53.8,
        "Prefill Latency (s)":0.0203,
        "E2E Latency (s)":18.6,
        "Allocated Memory (MB)":1694,
        "Reserved Memory (MB)":1757,
        "Used Memory (MB)":3233,
        "Energy (tokens\/kWh)":735294.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.62**",
        "Decode Throughput (tokens\/s)":54.11,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0195,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":2232,
        "Reserved Memory (MB)":2298,
        "Used Memory (MB)":3774,
        "Energy (tokens\/kWh)":775193.0
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":30.62,
        "Decode Throughput (tokens\/s)":61.79,
        "E2E Throughput (tokens\/s)":61.7,
        "Prefill Latency (s)":0.0157,
        "E2E Latency (s)":16.2,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4988,
        "Energy (tokens\/kWh)":854700.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.11**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0273,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":1710,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3260,
        "Energy (tokens\/kWh)":649350.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.11**",
        "Decode Throughput (tokens\/s)":49.32,
        "E2E Throughput (tokens\/s)":49.3,
        "Prefill Latency (s)":0.0247,
        "E2E Latency (s)":20.3,
        "Allocated Memory (MB)":1710,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3258,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":30.11,
        "Decode Throughput (tokens\/s)":53.24,
        "E2E Throughput (tokens\/s)":53.2,
        "Prefill Latency (s)":0.0188,
        "E2E Latency (s)":18.8,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990,
        "Energy (tokens\/kWh)":751879.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":30.11,
        "Decode Throughput (tokens\/s)":53.24,
        "E2E Throughput (tokens\/s)":53.2,
        "Prefill Latency (s)":0.0188,
        "E2E Latency (s)":18.8,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990,
        "Energy (tokens\/kWh)":735294.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.11**",
        "Decode Throughput (tokens\/s)":54.11,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0194,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":2232,
        "Reserved Memory (MB)":2298,
        "Used Memory (MB)":3774,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.11**",
        "Decode Throughput (tokens\/s)":54.7,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.02,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":1694,
        "Reserved Memory (MB)":1757,
        "Used Memory (MB)":3233,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":30.11,
        "Decode Throughput (tokens\/s)":61.04,
        "E2E Throughput (tokens\/s)":61.0,
        "Prefill Latency (s)":0.016,
        "E2E Latency (s)":16.4,
        "Allocated Memory (MB)":3450,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4988,
        "Energy (tokens\/kWh)":840336.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.07**",
        "Decode Throughput (tokens\/s)":32.84,
        "E2E Throughput (tokens\/s)":32.8,
        "Prefill Latency (s)":0.05,
        "E2E Latency (s)":30.5,
        "Allocated Memory (MB)":7631,
        "Reserved Memory (MB)":7715,
        "Used Memory (MB)":9189,
        "Energy (tokens\/kWh)":404858.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.07**",
        "Decode Throughput (tokens\/s)":34.9,
        "E2E Throughput (tokens\/s)":34.8,
        "Prefill Latency (s)":0.0438,
        "E2E Latency (s)":28.7,
        "Allocated Memory (MB)":7464,
        "Reserved Memory (MB)":7509,
        "Used Memory (MB)":8985,
        "Energy (tokens\/kWh)":384615.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.07**",
        "Decode Throughput (tokens\/s)":36.56,
        "E2E Throughput (tokens\/s)":36.5,
        "Prefill Latency (s)":0.0467,
        "E2E Latency (s)":27.4,
        "Allocated Memory (MB)":7630,
        "Reserved Memory (MB)":7673,
        "Used Memory (MB)":9145,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":30.07,
        "Decode Throughput (tokens\/s)":39.58,
        "E2E Throughput (tokens\/s)":39.5,
        "Prefill Latency (s)":0.0323,
        "E2E Latency (s)":25.3,
        "Allocated Memory (MB)":16864,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18359,
        "Energy (tokens\/kWh)":438596.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":30.07,
        "Decode Throughput (tokens\/s)":39.89,
        "E2E Throughput (tokens\/s)":39.8,
        "Prefill Latency (s)":0.0329,
        "E2E Latency (s)":25.1,
        "Allocated Memory (MB)":16864,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18360,
        "Energy (tokens\/kWh)":414937.0
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Size":7.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":30.07,
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0302,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":16864,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18357,
        "Energy (tokens\/kWh)":452488.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.06**",
        "Decode Throughput (tokens\/s)":39.58,
        "E2E Throughput (tokens\/s)":39.5,
        "Prefill Latency (s)":0.0341,
        "E2E Latency (s)":25.3,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":584795.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"30.06**",
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0282,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":887,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453,
        "Energy (tokens\/kWh)":613496.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"30.06**",
        "Decode Throughput (tokens\/s)":40.87,
        "E2E Throughput (tokens\/s)":40.8,
        "Prefill Latency (s)":0.0317,
        "E2E Latency (s)":24.5,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":621118.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":30.06,
        "Decode Throughput (tokens\/s)":50.56,
        "E2E Throughput (tokens\/s)":50.5,
        "Prefill Latency (s)":0.0201,
        "E2E Latency (s)":19.8,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":30.06,
        "Decode Throughput (tokens\/s)":51.33,
        "E2E Throughput (tokens\/s)":51.3,
        "Prefill Latency (s)":0.0198,
        "E2E Latency (s)":19.5,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":30.06,
        "Decode Throughput (tokens\/s)":53.24,
        "E2E Throughput (tokens\/s)":53.2,
        "Prefill Latency (s)":0.0181,
        "E2E Latency (s)":18.8,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":775193.0
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Size":13.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.86**",
        "Decode Throughput (tokens\/s)":27.09,
        "E2E Throughput (tokens\/s)":27.0,
        "Prefill Latency (s)":0.0825,
        "E2E Latency (s)":37.0,
        "Allocated Memory (MB)":9966,
        "Reserved Memory (MB)":11261,
        "Used Memory (MB)":12735,
        "Energy (tokens\/kWh)":307692.0
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Size":13.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.86**",
        "Decode Throughput (tokens\/s)":29.83,
        "E2E Throughput (tokens\/s)":29.8,
        "Prefill Latency (s)":0.079,
        "E2E Latency (s)":33.6,
        "Allocated Memory (MB)":9966,
        "Reserved Memory (MB)":11234,
        "Used Memory (MB)":12706,
        "Energy (tokens\/kWh)":335570.0
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Size":13.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.86,
        "Decode Throughput (tokens\/s)":31.7,
        "E2E Throughput (tokens\/s)":31.6,
        "Prefill Latency (s)":0.0526,
        "E2E Latency (s)":31.6,
        "Allocated Memory (MB)":28041,
        "Reserved Memory (MB)":30410,
        "Used Memory (MB)":31884,
        "Energy (tokens\/kWh)":304878.0
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Size":13.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"29.86**",
        "Decode Throughput (tokens\/s)":32.54,
        "E2E Throughput (tokens\/s)":32.5,
        "Prefill Latency (s)":0.0689,
        "E2E Latency (s)":30.8,
        "Allocated Memory (MB)":9670,
        "Reserved Memory (MB)":12002,
        "Used Memory (MB)":13477,
        "Energy (tokens\/kWh)":366300.0
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Size":13.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":29.86,
        "Decode Throughput (tokens\/s)":34.07,
        "E2E Throughput (tokens\/s)":34.0,
        "Prefill Latency (s)":0.0507,
        "E2E Latency (s)":29.4,
        "Allocated Memory (MB)":28041,
        "Reserved Memory (MB)":30410,
        "Used Memory (MB)":31882,
        "Energy (tokens\/kWh)":305810.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.52**",
        "Decode Throughput (tokens\/s)":39.27,
        "E2E Throughput (tokens\/s)":39.2,
        "Prefill Latency (s)":0.0336,
        "E2E Latency (s)":25.5,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":588235.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.52**",
        "Decode Throughput (tokens\/s)":41.38,
        "E2E Throughput (tokens\/s)":41.3,
        "Prefill Latency (s)":0.0313,
        "E2E Latency (s)":24.2,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":621118.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"29.52**",
        "Decode Throughput (tokens\/s)":47.22,
        "E2E Throughput (tokens\/s)":47.2,
        "Prefill Latency (s)":0.0245,
        "E2E Latency (s)":21.2,
        "Allocated Memory (MB)":887,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453,
        "Energy (tokens\/kWh)":645161.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":29.52,
        "Decode Throughput (tokens\/s)":48.59,
        "E2E Throughput (tokens\/s)":48.5,
        "Prefill Latency (s)":0.0215,
        "E2E Latency (s)":20.6,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.52,
        "Decode Throughput (tokens\/s)":51.6,
        "E2E Throughput (tokens\/s)":51.5,
        "Prefill Latency (s)":0.02,
        "E2E Latency (s)":19.4,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":29.52,
        "Decode Throughput (tokens\/s)":54.4,
        "E2E Throughput (tokens\/s)":54.3,
        "Prefill Latency (s)":0.0183,
        "E2E Latency (s)":18.4,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.44**",
        "Decode Throughput (tokens\/s)":45.31,
        "E2E Throughput (tokens\/s)":45.2,
        "Prefill Latency (s)":0.0316,
        "E2E Latency (s)":22.1,
        "Allocated Memory (MB)":1517,
        "Reserved Memory (MB)":1606,
        "Used Memory (MB)":3080,
        "Energy (tokens\/kWh)":636942.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.44**",
        "Decode Throughput (tokens\/s)":47.01,
        "E2E Throughput (tokens\/s)":46.9,
        "Prefill Latency (s)":0.0294,
        "E2E Latency (s)":21.3,
        "Allocated Memory (MB)":1507,
        "Reserved Memory (MB)":1606,
        "Used Memory (MB)":3080,
        "Energy (tokens\/kWh)":666666.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"29.44**",
        "Decode Throughput (tokens\/s)":56.24,
        "E2E Throughput (tokens\/s)":56.2,
        "Prefill Latency (s)":0.0191,
        "E2E Latency (s)":17.8,
        "Allocated Memory (MB)":1501,
        "Reserved Memory (MB)":1591,
        "Used Memory (MB)":3067,
        "Energy (tokens\/kWh)":799999.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":29.44,
        "Decode Throughput (tokens\/s)":58.88,
        "E2E Throughput (tokens\/s)":58.8,
        "Prefill Latency (s)":0.0162,
        "E2E Latency (s)":17.0,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4911,
        "Energy (tokens\/kWh)":819672.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":29.44,
        "Decode Throughput (tokens\/s)":59.94,
        "E2E Throughput (tokens\/s)":59.9,
        "Prefill Latency (s)":0.0168,
        "E2E Latency (s)":16.7,
        "Allocated Memory (MB)":3254,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4911,
        "Energy (tokens\/kWh)":806451.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Size":1.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.44,
        "Decode Throughput (tokens\/s)":61.04,
        "E2E Throughput (tokens\/s)":61.0,
        "Prefill Latency (s)":0.0165,
        "E2E Latency (s)":16.4,
        "Allocated Memory (MB)":3254,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4910,
        "Energy (tokens\/kWh)":826446.0
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"RWKV",
        "Size":1.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.24**",
        "Decode Throughput (tokens\/s)":29.5,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":1.6,
        "E2E Latency (s)":35.5,
        "Allocated Memory (MB)":1181,
        "Reserved Memory (MB)":1207,
        "Used Memory (MB)":2681,
        "Energy (tokens\/kWh)":418410.0
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"RWKV",
        "Size":1.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":29.24,
        "Decode Throughput (tokens\/s)":40.24,
        "E2E Throughput (tokens\/s)":37.7,
        "Prefill Latency (s)":1.65,
        "E2E Latency (s)":26.5,
        "Allocated Memory (MB)":3066,
        "Reserved Memory (MB)":3344,
        "Used Memory (MB)":4818,
        "Energy (tokens\/kWh)":534759.0
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"RWKV",
        "Size":1.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.24,
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0248,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":3066,
        "Reserved Memory (MB)":3344,
        "Used Memory (MB)":4818,
        "Energy (tokens\/kWh)":591715.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":29.16,
        "Decode Throughput (tokens\/s)":54.7,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.0193,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":6286,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970,
        "Energy (tokens\/kWh)":684931.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.16,
        "Decode Throughput (tokens\/s)":55.31,
        "E2E Throughput (tokens\/s)":55.2,
        "Prefill Latency (s)":0.0188,
        "E2E Latency (s)":18.1,
        "Allocated Memory (MB)":6286,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970,
        "Energy (tokens\/kWh)":709219.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"29.16**",
        "Decode Throughput (tokens\/s)":55.63,
        "E2E Throughput (tokens\/s)":55.6,
        "Prefill Latency (s)":0.0236,
        "E2E Latency (s)":18.0,
        "Allocated Memory (MB)":2605,
        "Reserved Memory (MB)":2805,
        "Used Memory (MB)":4281,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.16**",
        "Decode Throughput (tokens\/s)":55.61,
        "E2E Throughput (tokens\/s)":55.6,
        "Prefill Latency (s)":0.0188,
        "E2E Latency (s)":18.0,
        "Allocated Memory (MB)":6286,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.16**",
        "Decode Throughput (tokens\/s)":62.95,
        "E2E Throughput (tokens\/s)":62.9,
        "Prefill Latency (s)":0.0153,
        "E2E Latency (s)":15.9,
        "Allocated Memory (MB)":6286,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970,
        "Energy (tokens\/kWh)":833333.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Size":2.65,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":29.16,
        "Decode Throughput (tokens\/s)":62.96,
        "E2E Throughput (tokens\/s)":62.9,
        "Prefill Latency (s)":0.0158,
        "E2E Latency (s)":15.9,
        "Allocated Memory (MB)":6286,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970,
        "Energy (tokens\/kWh)":787401.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.08**",
        "Decode Throughput (tokens\/s)":32.13,
        "E2E Throughput (tokens\/s)":32.1,
        "Prefill Latency (s)":0.079,
        "E2E Latency (s)":31.2,
        "Allocated Memory (MB)":10491,
        "Reserved Memory (MB)":11769,
        "Used Memory (MB)":13242,
        "Energy (tokens\/kWh)":349650.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"29.08**",
        "Decode Throughput (tokens\/s)":33.31,
        "E2E Throughput (tokens\/s)":33.2,
        "Prefill Latency (s)":0.0761,
        "E2E Latency (s)":30.1,
        "Allocated Memory (MB)":10490,
        "Reserved Memory (MB)":11769,
        "Used Memory (MB)":13242,
        "Energy (tokens\/kWh)":359712.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":29.08,
        "Decode Throughput (tokens\/s)":37.95,
        "E2E Throughput (tokens\/s)":37.9,
        "Prefill Latency (s)":0.0512,
        "E2E Latency (s)":26.4,
        "Allocated Memory (MB)":28578,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419,
        "Energy (tokens\/kWh)":338983.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":29.08,
        "Decode Throughput (tokens\/s)":38.25,
        "E2E Throughput (tokens\/s)":38.2,
        "Prefill Latency (s)":0.0529,
        "E2E Latency (s)":26.2,
        "Allocated Memory (MB)":28579,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419,
        "Energy (tokens\/kWh)":337837.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":29.08,
        "Decode Throughput (tokens\/s)":38.99,
        "E2E Throughput (tokens\/s)":38.9,
        "Prefill Latency (s)":0.0522,
        "E2E Latency (s)":25.7,
        "Allocated Memory (MB)":28579,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419,
        "Energy (tokens\/kWh)":349650.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"Bloom \ud83c\udf38",
        "Size":13.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"29.08**",
        "Decode Throughput (tokens\/s)":40.93,
        "E2E Throughput (tokens\/s)":40.8,
        "Prefill Latency (s)":0.066,
        "E2E Latency (s)":24.5,
        "Allocated Memory (MB)":10194,
        "Reserved Memory (MB)":12561,
        "Used Memory (MB)":14037,
        "Energy (tokens\/kWh)":421940.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.77**",
        "Decode Throughput (tokens\/s)":64.18,
        "E2E Throughput (tokens\/s)":64.1,
        "Prefill Latency (s)":0.0188,
        "E2E Latency (s)":15.6,
        "Allocated Memory (MB)":1284,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818,
        "Energy (tokens\/kWh)":943396.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.77**",
        "Decode Throughput (tokens\/s)":74.16,
        "E2E Throughput (tokens\/s)":74.1,
        "Prefill Latency (s)":0.0165,
        "E2E Latency (s)":13.5,
        "Allocated Memory (MB)":1284,
        "Reserved Memory (MB)":1342,
        "Used Memory (MB)":2813,
        "Energy (tokens\/kWh)":1070663.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"28.77**",
        "Decode Throughput (tokens\/s)":78.21,
        "E2E Throughput (tokens\/s)":78.1,
        "Prefill Latency (s)":0.0134,
        "E2E Latency (s)":12.8,
        "Allocated Memory (MB)":1286,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2820,
        "Energy (tokens\/kWh)":1077586.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":28.77,
        "Decode Throughput (tokens\/s)":78.82,
        "E2E Throughput (tokens\/s)":78.7,
        "Prefill Latency (s)":0.0127,
        "E2E Latency (s)":12.7,
        "Allocated Memory (MB)":2443,
        "Reserved Memory (MB)":2499,
        "Used Memory (MB)":3973,
        "Energy (tokens\/kWh)":1101321.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":28.77,
        "Decode Throughput (tokens\/s)":79.44,
        "E2E Throughput (tokens\/s)":79.4,
        "Prefill Latency (s)":0.0126,
        "E2E Latency (s)":12.6,
        "Allocated Memory (MB)":2443,
        "Reserved Memory (MB)":2499,
        "Used Memory (MB)":3973,
        "Energy (tokens\/kWh)":1119820.0
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Size":1.08,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":28.77,
        "Decode Throughput (tokens\/s)":90.18,
        "E2E Throughput (tokens\/s)":90.1,
        "Prefill Latency (s)":0.0108,
        "E2E Latency (s)":11.1,
        "Allocated Memory (MB)":2443,
        "Reserved Memory (MB)":2497,
        "Used Memory (MB)":3969,
        "Energy (tokens\/kWh)":1226993.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.38**",
        "Decode Throughput (tokens\/s)":23.62,
        "E2E Throughput (tokens\/s)":23.6,
        "Prefill Latency (s)":0.0542,
        "E2E Latency (s)":42.4,
        "Allocated Memory (MB)":6176,
        "Reserved Memory (MB)":6243,
        "Used Memory (MB)":7716,
        "Energy (tokens\/kWh)":319488.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.38**",
        "Decode Throughput (tokens\/s)":25.09,
        "E2E Throughput (tokens\/s)":25.1,
        "Prefill Latency (s)":0.0502,
        "E2E Latency (s)":39.9,
        "Allocated Memory (MB)":6188,
        "Reserved Memory (MB)":6285,
        "Used Memory (MB)":7758,
        "Energy (tokens\/kWh)":343642.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"28.38**",
        "Decode Throughput (tokens\/s)":26.7,
        "E2E Throughput (tokens\/s)":26.7,
        "Prefill Latency (s)":0.0481,
        "E2E Latency (s)":37.5,
        "Allocated Memory (MB)":6000,
        "Reserved Memory (MB)":6039,
        "Used Memory (MB)":7515,
        "Energy (tokens\/kWh)":343642.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":28.38,
        "Decode Throughput (tokens\/s)":26.84,
        "E2E Throughput (tokens\/s)":26.8,
        "Prefill Latency (s)":0.039,
        "E2E Latency (s)":37.3,
        "Allocated Memory (MB)":15697,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214,
        "Energy (tokens\/kWh)":316455.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":28.38,
        "Decode Throughput (tokens\/s)":26.91,
        "E2E Throughput (tokens\/s)":26.9,
        "Prefill Latency (s)":0.0383,
        "E2E Latency (s)":37.2,
        "Allocated Memory (MB)":15697,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214,
        "Energy (tokens\/kWh)":330033.0
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"CodeGen",
        "Size":6.85,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":28.38,
        "Decode Throughput (tokens\/s)":28.93,
        "E2E Throughput (tokens\/s)":28.9,
        "Prefill Latency (s)":0.0341,
        "E2E Latency (s)":34.6,
        "Allocated Memory (MB)":15707,
        "Reserved Memory (MB)":15762,
        "Used Memory (MB)":17235,
        "Energy (tokens\/kWh)":331125.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.23**",
        "Decode Throughput (tokens\/s)":27.21,
        "E2E Throughput (tokens\/s)":27.2,
        "Prefill Latency (s)":0.0494,
        "E2E Latency (s)":36.8,
        "Allocated Memory (MB)":4453,
        "Reserved Memory (MB)":4643,
        "Used Memory (MB)":6116,
        "Energy (tokens\/kWh)":346020.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"28.23**",
        "Decode Throughput (tokens\/s)":29.02,
        "E2E Throughput (tokens\/s)":29.0,
        "Prefill Latency (s)":0.046,
        "E2E Latency (s)":34.5,
        "Allocated Memory (MB)":4453,
        "Reserved Memory (MB)":4643,
        "Used Memory (MB)":6116,
        "Energy (tokens\/kWh)":371747.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"28.23**",
        "Decode Throughput (tokens\/s)":32.72,
        "E2E Throughput (tokens\/s)":32.7,
        "Prefill Latency (s)":0.0385,
        "E2E Latency (s)":30.6,
        "Allocated Memory (MB)":4331,
        "Reserved Memory (MB)":4494,
        "Used Memory (MB)":5970,
        "Energy (tokens\/kWh)":413223.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":28.23,
        "Decode Throughput (tokens\/s)":33.94,
        "E2E Throughput (tokens\/s)":33.9,
        "Prefill Latency (s)":0.0333,
        "E2E Latency (s)":29.5,
        "Allocated Memory (MB)":12576,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266,
        "Energy (tokens\/kWh)":395256.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":28.23,
        "Decode Throughput (tokens\/s)":34.52,
        "E2E Throughput (tokens\/s)":34.5,
        "Prefill Latency (s)":0.0306,
        "E2E Latency (s)":29.0,
        "Allocated Memory (MB)":12576,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266,
        "Energy (tokens\/kWh)":416666.0
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":5.87,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":28.23,
        "Decode Throughput (tokens\/s)":37.35,
        "E2E Throughput (tokens\/s)":37.3,
        "Prefill Latency (s)":0.0294,
        "E2E Latency (s)":26.8,
        "Allocated Memory (MB)":12576,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266,
        "Energy (tokens\/kWh)":444444.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":39.42,
        "E2E Throughput (tokens\/s)":39.4,
        "Prefill Latency (s)":0.0333,
        "E2E Latency (s)":25.4,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":588235.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":41.72,
        "E2E Throughput (tokens\/s)":41.7,
        "Prefill Latency (s)":0.031,
        "E2E Latency (s)":24.0,
        "Allocated Memory (MB)":898,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484,
        "Energy (tokens\/kWh)":625000.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":47.45,
        "E2E Throughput (tokens\/s)":47.4,
        "Prefill Latency (s)":0.0231,
        "E2E Latency (s)":21.1,
        "Allocated Memory (MB)":887,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453,
        "Energy (tokens\/kWh)":641025.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":51.33,
        "E2E Throughput (tokens\/s)":51.3,
        "Prefill Latency (s)":0.0198,
        "E2E Latency (s)":19.5,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":751879.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":51.87,
        "E2E Throughput (tokens\/s)":51.8,
        "Prefill Latency (s)":0.0199,
        "E2E Latency (s)":19.3,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":54.11,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0179,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":2289,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":65.04,
        "E2E Throughput (tokens\/s)":64.9,
        "Prefill Latency (s)":0.0245,
        "E2E Latency (s)":15.4,
        "Allocated Memory (MB)":3607,
        "Reserved Memory (MB)":3682,
        "Used Memory (MB)":5156,
        "Energy (tokens\/kWh)":813008.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":73.65,
        "E2E Throughput (tokens\/s)":73.5,
        "Prefill Latency (s)":0.0228,
        "E2E Latency (s)":13.6,
        "Allocated Memory (MB)":3607,
        "Reserved Memory (MB)":3682,
        "Used Memory (MB)":5154,
        "Energy (tokens\/kWh)":900900.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":76.43,
        "E2E Throughput (tokens\/s)":76.3,
        "Prefill Latency (s)":0.0162,
        "E2E Latency (s)":13.1,
        "Allocated Memory (MB)":8232,
        "Reserved Memory (MB)":8273,
        "Used Memory (MB)":9747,
        "Energy (tokens\/kWh)":826446.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":79.47,
        "E2E Throughput (tokens\/s)":79.4,
        "Prefill Latency (s)":0.0159,
        "E2E Latency (s)":12.6,
        "Allocated Memory (MB)":8232,
        "Reserved Memory (MB)":8273,
        "Used Memory (MB)":9746,
        "Energy (tokens\/kWh)":877192.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"GPTQ.4bit",
        "Avg Score (%)":"27.87**",
        "Decode Throughput (tokens\/s)":81.44,
        "E2E Throughput (tokens\/s)":81.3,
        "Prefill Latency (s)":0.0206,
        "E2E Latency (s)":12.3,
        "Allocated Memory (MB)":3598,
        "Reserved Memory (MB)":3674,
        "Used Memory (MB)":5150,
        "Energy (tokens\/kWh)":961538.0
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Size":3.43,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.87,
        "Decode Throughput (tokens\/s)":88.61,
        "E2E Throughput (tokens\/s)":88.5,
        "Prefill Latency (s)":0.0149,
        "E2E Latency (s)":11.3,
        "Allocated Memory (MB)":8232,
        "Reserved Memory (MB)":8252,
        "Used Memory (MB)":9723,
        "Energy (tokens\/kWh)":934579.0
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.68**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0284,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":754,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375,
        "Energy (tokens\/kWh)":684931.0
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.68**",
        "Decode Throughput (tokens\/s)":48.6,
        "E2E Throughput (tokens\/s)":48.5,
        "Prefill Latency (s)":0.0244,
        "E2E Latency (s)":20.6,
        "Allocated Memory (MB)":754,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375,
        "Energy (tokens\/kWh)":751879.0
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.68,
        "Decode Throughput (tokens\/s)":54.11,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0187,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786,
        "Energy (tokens\/kWh)":826446.0
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.68,
        "Decode Throughput (tokens\/s)":54.7,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.0185,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786,
        "Energy (tokens\/kWh)":847457.0
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.68,
        "Decode Throughput (tokens\/s)":59.58,
        "E2E Throughput (tokens\/s)":59.5,
        "Prefill Latency (s)":0.0159,
        "E2E Latency (s)":16.8,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1310,
        "Used Memory (MB)":2784,
        "Energy (tokens\/kWh)":934579.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.67**",
        "Decode Throughput (tokens\/s)":30.07,
        "E2E Throughput (tokens\/s)":30.0,
        "Prefill Latency (s)":0.0412,
        "E2E Latency (s)":33.3,
        "Allocated Memory (MB)":3892,
        "Reserved Memory (MB)":4351,
        "Used Memory (MB)":5825,
        "Energy (tokens\/kWh)":403225.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.67**",
        "Decode Throughput (tokens\/s)":34.29,
        "E2E Throughput (tokens\/s)":34.2,
        "Prefill Latency (s)":0.0371,
        "E2E Latency (s)":29.2,
        "Allocated Memory (MB)":3892,
        "Reserved Memory (MB)":4330,
        "Used Memory (MB)":5802,
        "Energy (tokens\/kWh)":456621.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.67,
        "Decode Throughput (tokens\/s)":35.25,
        "E2E Throughput (tokens\/s)":35.2,
        "Prefill Latency (s)":0.0287,
        "E2E Latency (s)":28.4,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946,
        "Energy (tokens\/kWh)":450450.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.67,
        "Decode Throughput (tokens\/s)":36.53,
        "E2E Throughput (tokens\/s)":36.5,
        "Prefill Latency (s)":0.0278,
        "E2E Latency (s)":27.4,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946,
        "Energy (tokens\/kWh)":485436.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.67,
        "Decode Throughput (tokens\/s)":40.53,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0248,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10944,
        "Energy (tokens\/kWh)":505050.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.58**",
        "Decode Throughput (tokens\/s)":30.16,
        "E2E Throughput (tokens\/s)":30.1,
        "Prefill Latency (s)":0.0413,
        "E2E Latency (s)":33.2,
        "Allocated Memory (MB)":3892,
        "Reserved Memory (MB)":4351,
        "Used Memory (MB)":5825,
        "Energy (tokens\/kWh)":408163.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.58**",
        "Decode Throughput (tokens\/s)":33.26,
        "E2E Throughput (tokens\/s)":33.2,
        "Prefill Latency (s)":0.0372,
        "E2E Latency (s)":30.1,
        "Allocated Memory (MB)":3892,
        "Reserved Memory (MB)":4330,
        "Used Memory (MB)":5802,
        "Energy (tokens\/kWh)":448430.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.58,
        "Decode Throughput (tokens\/s)":36.14,
        "E2E Throughput (tokens\/s)":36.1,
        "Prefill Latency (s)":0.0278,
        "E2E Latency (s)":27.7,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946,
        "Energy (tokens\/kWh)":458715.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.58,
        "Decode Throughput (tokens\/s)":36.94,
        "E2E Throughput (tokens\/s)":36.9,
        "Prefill Latency (s)":0.0275,
        "E2E Latency (s)":27.1,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946,
        "Energy (tokens\/kWh)":480769.0
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Size":3.95,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.58,
        "Decode Throughput (tokens\/s)":40.52,
        "E2E Throughput (tokens\/s)":40.5,
        "Prefill Latency (s)":0.0237,
        "E2E Latency (s)":24.7,
        "Allocated Memory (MB)":8864,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10944,
        "Energy (tokens\/kWh)":510204.0
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.43**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0273,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":754,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375,
        "Energy (tokens\/kWh)":684931.0
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.43**",
        "Decode Throughput (tokens\/s)":48.84,
        "E2E Throughput (tokens\/s)":48.8,
        "Prefill Latency (s)":0.0243,
        "E2E Latency (s)":20.5,
        "Allocated Memory (MB)":754,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.43,
        "Decode Throughput (tokens\/s)":54.7,
        "E2E Throughput (tokens\/s)":54.6,
        "Prefill Latency (s)":0.0185,
        "E2E Latency (s)":18.3,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786,
        "Energy (tokens\/kWh)":847457.0
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.43,
        "Decode Throughput (tokens\/s)":55.31,
        "E2E Throughput (tokens\/s)":55.2,
        "Prefill Latency (s)":0.0185,
        "E2E Latency (s)":18.1,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786,
        "Energy (tokens\/kWh)":833333.0
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.51,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.43,
        "Decode Throughput (tokens\/s)":59.58,
        "E2E Throughput (tokens\/s)":59.5,
        "Prefill Latency (s)":0.016,
        "E2E Latency (s)":16.8,
        "Allocated Memory (MB)":1175,
        "Reserved Memory (MB)":1310,
        "Used Memory (MB)":2784,
        "Energy (tokens\/kWh)":925925.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":27.35,
        "Decode Throughput (tokens\/s)":70.99,
        "E2E Throughput (tokens\/s)":70.9,
        "Prefill Latency (s)":0.0144,
        "E2E Latency (s)":14.1,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751,
        "Energy (tokens\/kWh)":943396.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.35**",
        "Decode Throughput (tokens\/s)":71.5,
        "E2E Throughput (tokens\/s)":71.4,
        "Prefill Latency (s)":0.0143,
        "E2E Latency (s)":14.0,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751,
        "Energy (tokens\/kWh)":990099.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":27.35,
        "Decode Throughput (tokens\/s)":72.02,
        "E2E Throughput (tokens\/s)":71.9,
        "Prefill Latency (s)":0.0143,
        "E2E Latency (s)":13.9,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751,
        "Energy (tokens\/kWh)":990099.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":27.35,
        "Decode Throughput (tokens\/s)":84.83,
        "E2E Throughput (tokens\/s)":84.7,
        "Prefill Latency (s)":0.0113,
        "E2E Latency (s)":11.8,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4749,
        "Energy (tokens\/kWh)":1148105.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"27.35**",
        "Decode Throughput (tokens\/s)":85.55,
        "E2E Throughput (tokens\/s)":85.5,
        "Prefill Latency (s)":0.0116,
        "E2E Latency (s)":11.7,
        "Allocated Memory (MB)":3244,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4749,
        "Energy (tokens\/kWh)":1194743.0
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"RWKV",
        "Size":0.38,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.89**",
        "Decode Throughput (tokens\/s)":29.48,
        "E2E Throughput (tokens\/s)":28.2,
        "Prefill Latency (s)":1.58,
        "E2E Latency (s)":35.5,
        "Allocated Memory (MB)":419,
        "Reserved Memory (MB)":452,
        "Used Memory (MB)":1926,
        "Energy (tokens\/kWh)":440528.0
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"RWKV",
        "Size":0.38,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":26.89,
        "Decode Throughput (tokens\/s)":40.62,
        "E2E Throughput (tokens\/s)":38.2,
        "Prefill Latency (s)":1.58,
        "E2E Latency (s)":26.2,
        "Allocated Memory (MB)":895,
        "Reserved Memory (MB)":914,
        "Used Memory (MB)":2388,
        "Energy (tokens\/kWh)":602409.0
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"RWKV",
        "Size":0.38,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":26.89,
        "Decode Throughput (tokens\/s)":39.56,
        "E2E Throughput (tokens\/s)":39.5,
        "Prefill Latency (s)":0.0247,
        "E2E Latency (s)":25.3,
        "Allocated Memory (MB)":895,
        "Reserved Memory (MB)":918,
        "Used Memory (MB)":2392,
        "Energy (tokens\/kWh)":625000.0
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.65**",
        "Decode Throughput (tokens\/s)":35.76,
        "E2E Throughput (tokens\/s)":35.7,
        "Prefill Latency (s)":0.0374,
        "E2E Latency (s)":28.0,
        "Allocated Memory (MB)":504,
        "Reserved Memory (MB)":578,
        "Used Memory (MB)":2052,
        "Energy (tokens\/kWh)":543478.0
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.65**",
        "Decode Throughput (tokens\/s)":38.22,
        "E2E Throughput (tokens\/s)":38.2,
        "Prefill Latency (s)":0.0344,
        "E2E Latency (s)":26.2,
        "Allocated Memory (MB)":504,
        "Reserved Memory (MB)":578,
        "Used Memory (MB)":2052,
        "Energy (tokens\/kWh)":595238.0
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":26.65,
        "Decode Throughput (tokens\/s)":47.22,
        "E2E Throughput (tokens\/s)":47.2,
        "Prefill Latency (s)":0.0215,
        "E2E Latency (s)":21.2,
        "Allocated Memory (MB)":1020,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599,
        "Energy (tokens\/kWh)":729927.0
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":26.65,
        "Decode Throughput (tokens\/s)":47.44,
        "E2E Throughput (tokens\/s)":47.4,
        "Prefill Latency (s)":0.0215,
        "E2E Latency (s)":21.1,
        "Allocated Memory (MB)":1020,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.41,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":26.65,
        "Decode Throughput (tokens\/s)":49.31,
        "E2E Throughput (tokens\/s)":49.3,
        "Prefill Latency (s)":0.02,
        "E2E Latency (s)":20.3,
        "Allocated Memory (MB)":1020,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599,
        "Energy (tokens\/kWh)":775193.0
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"OPT",
        "Size":0.33,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.32**",
        "Decode Throughput (tokens\/s)":49.82,
        "E2E Throughput (tokens\/s)":49.8,
        "Prefill Latency (s)":0.0282,
        "E2E Latency (s)":20.1,
        "Allocated Memory (MB)":488,
        "Reserved Memory (MB)":612,
        "Used Memory (MB)":2086,
        "Energy (tokens\/kWh)":757575.0
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"OPT",
        "Size":0.33,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.32**",
        "Decode Throughput (tokens\/s)":54.13,
        "E2E Throughput (tokens\/s)":54.1,
        "Prefill Latency (s)":0.0257,
        "E2E Latency (s)":18.5,
        "Allocated Memory (MB)":488,
        "Reserved Memory (MB)":612,
        "Used Memory (MB)":2086,
        "Energy (tokens\/kWh)":840336.0
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"OPT",
        "Size":0.33,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":26.32,
        "Decode Throughput (tokens\/s)":74.71,
        "E2E Throughput (tokens\/s)":74.6,
        "Prefill Latency (s)":0.0154,
        "E2E Latency (s)":13.4,
        "Allocated Memory (MB)":924,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522,
        "Energy (tokens\/kWh)":1119820.0
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"OPT",
        "Size":0.33,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":26.32,
        "Decode Throughput (tokens\/s)":75.27,
        "E2E Throughput (tokens\/s)":75.2,
        "Prefill Latency (s)":0.015,
        "E2E Latency (s)":13.3,
        "Allocated Memory (MB)":924,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522,
        "Energy (tokens\/kWh)":1168224.0
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"OPT",
        "Size":0.33,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":26.32,
        "Decode Throughput (tokens\/s)":86.3,
        "E2E Throughput (tokens\/s)":86.2,
        "Prefill Latency (s)":0.0124,
        "E2E Latency (s)":11.6,
        "Allocated Memory (MB)":924,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522,
        "Energy (tokens\/kWh)":1291989.0
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Size":0.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"26.19**",
        "Decode Throughput (tokens\/s)":50.84,
        "E2E Throughput (tokens\/s)":50.8,
        "Prefill Latency (s)":0.0287,
        "E2E Latency (s)":19.7,
        "Allocated Memory (MB)":958,
        "Reserved Memory (MB)":1107,
        "Used Memory (MB)":2581,
        "Energy (tokens\/kWh)":746268.0
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Size":0.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":26.19,
        "Decode Throughput (tokens\/s)":74.16,
        "E2E Throughput (tokens\/s)":74.1,
        "Prefill Latency (s)":0.0156,
        "E2E Latency (s)":13.5,
        "Allocated Memory (MB)":1392,
        "Reserved Memory (MB)":1543,
        "Used Memory (MB)":3017,
        "Energy (tokens\/kWh)":1083423.0
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Size":0.56,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":26.19,
        "Decode Throughput (tokens\/s)":74.71,
        "E2E Throughput (tokens\/s)":74.6,
        "Prefill Latency (s)":0.0154,
        "E2E Latency (s)":13.4,
        "Allocated Memory (MB)":1392,
        "Reserved Memory (MB)":1543,
        "Used Memory (MB)":3017,
        "Energy (tokens\/kWh)":1050420.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.88,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.95**",
        "Decode Throughput (tokens\/s)":53.54,
        "E2E Throughput (tokens\/s)":53.5,
        "Prefill Latency (s)":0.024,
        "E2E Latency (s)":18.7,
        "Allocated Memory (MB)":1166,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818,
        "Energy (tokens\/kWh)":787401.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.88,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.95**",
        "Decode Throughput (tokens\/s)":56.89,
        "E2E Throughput (tokens\/s)":56.8,
        "Prefill Latency (s)":0.0213,
        "E2E Latency (s)":17.6,
        "Allocated Memory (MB)":1166,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818,
        "Energy (tokens\/kWh)":840336.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.88,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.95,
        "Decode Throughput (tokens\/s)":67.64,
        "E2E Throughput (tokens\/s)":67.6,
        "Prefill Latency (s)":0.015,
        "E2E Latency (s)":14.8,
        "Allocated Memory (MB)":2143,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830,
        "Energy (tokens\/kWh)":980392.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.88,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.95,
        "Decode Throughput (tokens\/s)":68.56,
        "E2E Throughput (tokens\/s)":68.5,
        "Prefill Latency (s)":0.0149,
        "E2E Latency (s)":14.6,
        "Allocated Memory (MB)":2143,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830,
        "Energy (tokens\/kWh)":980392.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.88,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.95,
        "Decode Throughput (tokens\/s)":68.55,
        "E2E Throughput (tokens\/s)":68.5,
        "Prefill Latency (s)":0.0129,
        "E2E Latency (s)":14.6,
        "Allocated Memory (MB)":2143,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830,
        "Energy (tokens\/kWh)":1029866.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Size":0.15,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.79**",
        "Decode Throughput (tokens\/s)":87.07,
        "E2E Throughput (tokens\/s)":87.0,
        "Prefill Latency (s)":0.0144,
        "E2E Latency (s)":11.5,
        "Allocated Memory (MB)":287,
        "Reserved Memory (MB)":369,
        "Used Memory (MB)":1842,
        "Energy (tokens\/kWh)":1388888.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Size":0.15,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.79**",
        "Decode Throughput (tokens\/s)":87.07,
        "E2E Throughput (tokens\/s)":87.0,
        "Prefill Latency (s)":0.015,
        "E2E Latency (s)":11.5,
        "Allocated Memory (MB)":291,
        "Reserved Memory (MB)":367,
        "Used Memory (MB)":1840,
        "Energy (tokens\/kWh)":1347708.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Size":0.15,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.79,
        "Decode Throughput (tokens\/s)":116.39,
        "E2E Throughput (tokens\/s)":116.0,
        "Prefill Latency (s)":0.00818,
        "E2E Latency (s)":8.6,
        "Allocated Memory (MB)":408,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972,
        "Energy (tokens\/kWh)":1862197.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Size":0.15,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.79,
        "Decode Throughput (tokens\/s)":117.63,
        "E2E Throughput (tokens\/s)":118.0,
        "Prefill Latency (s)":0.00848,
        "E2E Latency (s)":8.51,
        "Allocated Memory (MB)":411,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972,
        "Energy (tokens\/kWh)":1814882.0
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Size":0.15,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.79,
        "Decode Throughput (tokens\/s)":118.74,
        "E2E Throughput (tokens\/s)":119.0,
        "Prefill Latency (s)":0.00839,
        "E2E Latency (s)":8.43,
        "Allocated Memory (MB)":411,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972,
        "Energy (tokens\/kWh)":1872659.0
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.69**",
        "Decode Throughput (tokens\/s)":57.88,
        "E2E Throughput (tokens\/s)":57.8,
        "Prefill Latency (s)":0.0241,
        "E2E Latency (s)":17.3,
        "Allocated Memory (MB)":3073,
        "Reserved Memory (MB)":3170,
        "Used Memory (MB)":4644,
        "Energy (tokens\/kWh)":719424.0
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.69**",
        "Decode Throughput (tokens\/s)":61.44,
        "E2E Throughput (tokens\/s)":61.3,
        "Prefill Latency (s)":0.0233,
        "E2E Latency (s)":16.3,
        "Allocated Memory (MB)":3072,
        "Reserved Memory (MB)":3164,
        "Used Memory (MB)":4638,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.69,
        "Decode Throughput (tokens\/s)":74.72,
        "E2E Throughput (tokens\/s)":74.6,
        "Prefill Latency (s)":0.0168,
        "E2E Latency (s)":13.4,
        "Allocated Memory (MB)":7714,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235,
        "Energy (tokens\/kWh)":854700.0
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.69,
        "Decode Throughput (tokens\/s)":75.29,
        "E2E Throughput (tokens\/s)":75.2,
        "Prefill Latency (s)":0.0181,
        "E2E Latency (s)":13.3,
        "Allocated Memory (MB)":7714,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235,
        "Energy (tokens\/kWh)":819672.0
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":3.37,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.69,
        "Decode Throughput (tokens\/s)":82.76,
        "E2E Throughput (tokens\/s)":82.6,
        "Prefill Latency (s)":0.0162,
        "E2E Latency (s)":12.1,
        "Allocated Memory (MB)":7714,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235,
        "Energy (tokens\/kWh)":877192.0
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.66**",
        "Decode Throughput (tokens\/s)":86.31,
        "E2E Throughput (tokens\/s)":86.2,
        "Prefill Latency (s)":0.014,
        "E2E Latency (s)":11.6,
        "Allocated Memory (MB)":362,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922,
        "Energy (tokens\/kWh)":1338688.0
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.66**",
        "Decode Throughput (tokens\/s)":94.45,
        "E2E Throughput (tokens\/s)":94.3,
        "Prefill Latency (s)":0.0125,
        "E2E Latency (s)":10.6,
        "Allocated Memory (MB)":362,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922,
        "Energy (tokens\/kWh)":1464128.0
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.66,
        "Decode Throughput (tokens\/s)":105.15,
        "E2E Throughput (tokens\/s)":105.0,
        "Prefill Latency (s)":0.0098,
        "E2E Latency (s)":9.52,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050,
        "Energy (tokens\/kWh)":1663893.0
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.66,
        "Decode Throughput (tokens\/s)":106.26,
        "E2E Throughput (tokens\/s)":106.0,
        "Prefill Latency (s)":0.0094,
        "E2E Latency (s)":9.42,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050,
        "Energy (tokens\/kWh)":1675041.0
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.66,
        "Decode Throughput (tokens\/s)":114.0,
        "E2E Throughput (tokens\/s)":114.0,
        "Prefill Latency (s)":0.00803,
        "E2E Latency (s)":8.78,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":574,
        "Used Memory (MB)":2048,
        "Energy (tokens\/kWh)":1824817.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Size":0.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.65**",
        "Decode Throughput (tokens\/s)":114.66,
        "E2E Throughput (tokens\/s)":115.0,
        "Prefill Latency (s)":0.00845,
        "E2E Latency (s)":8.73,
        "Allocated Memory (MB)":737,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327,
        "Energy (tokens\/kWh)":1792114.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Size":0.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.65,
        "Decode Throughput (tokens\/s)":115.85,
        "E2E Throughput (tokens\/s)":116.0,
        "Prefill Latency (s)":0.00848,
        "E2E Latency (s)":8.64,
        "Allocated Memory (MB)":737,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327,
        "Energy (tokens\/kWh)":1754385.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Size":0.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.65,
        "Decode Throughput (tokens\/s)":117.49,
        "E2E Throughput (tokens\/s)":117.0,
        "Prefill Latency (s)":0.00843,
        "E2E Latency (s)":8.52,
        "Allocated Memory (MB)":737,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327,
        "Energy (tokens\/kWh)":1757469.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Size":0.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.65**",
        "Decode Throughput (tokens\/s)":129.82,
        "E2E Throughput (tokens\/s)":130.0,
        "Prefill Latency (s)":0.00673,
        "E2E Latency (s)":7.71,
        "Allocated Memory (MB)":737,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327,
        "Energy (tokens\/kWh)":2079002.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Size":0.26,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.65,
        "Decode Throughput (tokens\/s)":130.66,
        "E2E Throughput (tokens\/s)":131.0,
        "Prefill Latency (s)":0.00675,
        "E2E Latency (s)":7.66,
        "Allocated Memory (MB)":737,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327,
        "Energy (tokens\/kWh)":1980198.0
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.6**",
        "Decode Throughput (tokens\/s)":48.85,
        "E2E Throughput (tokens\/s)":48.8,
        "Prefill Latency (s)":0.0285,
        "E2E Latency (s)":20.5,
        "Allocated Memory (MB)":1031,
        "Reserved Memory (MB)":1111,
        "Used Memory (MB)":2585,
        "Energy (tokens\/kWh)":724637.0
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.6**",
        "Decode Throughput (tokens\/s)":48.85,
        "E2E Throughput (tokens\/s)":48.8,
        "Prefill Latency (s)":0.0284,
        "E2E Latency (s)":20.5,
        "Allocated Memory (MB)":1031,
        "Reserved Memory (MB)":1111,
        "Used Memory (MB)":2585,
        "Energy (tokens\/kWh)":709219.0
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.6,
        "Decode Throughput (tokens\/s)":63.76,
        "E2E Throughput (tokens\/s)":63.7,
        "Prefill Latency (s)":0.0166,
        "E2E Latency (s)":15.7,
        "Allocated Memory (MB)":2391,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015,
        "Energy (tokens\/kWh)":900900.0
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.6,
        "Decode Throughput (tokens\/s)":64.58,
        "E2E Throughput (tokens\/s)":64.5,
        "Prefill Latency (s)":0.0164,
        "E2E Latency (s)":15.5,
        "Allocated Memory (MB)":2391,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015,
        "Energy (tokens\/kWh)":925925.0
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":1.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.6,
        "Decode Throughput (tokens\/s)":65.0,
        "E2E Throughput (tokens\/s)":64.9,
        "Prefill Latency (s)":0.0162,
        "E2E Latency (s)":15.4,
        "Allocated Memory (MB)":2391,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015,
        "Energy (tokens\/kWh)":934579.0
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"OPT",
        "Size":0.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.47**",
        "Decode Throughput (tokens\/s)":92.73,
        "E2E Throughput (tokens\/s)":92.6,
        "Prefill Latency (s)":0.0157,
        "E2E Latency (s)":10.8,
        "Allocated Memory (MB)":232,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1798,
        "Energy (tokens\/kWh)":1490312.0
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"OPT",
        "Size":0.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.47**",
        "Decode Throughput (tokens\/s)":107.1,
        "E2E Throughput (tokens\/s)":107.0,
        "Prefill Latency (s)":0.0129,
        "E2E Latency (s)":9.35,
        "Allocated Memory (MB)":232,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1798,
        "Energy (tokens\/kWh)":1686340.0
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"OPT",
        "Size":0.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.47,
        "Decode Throughput (tokens\/s)":141.59,
        "E2E Throughput (tokens\/s)":141.0,
        "Prefill Latency (s)":0.00759,
        "E2E Latency (s)":7.07,
        "Allocated Memory (MB)":360,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928,
        "Energy (tokens\/kWh)":2123142.0
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"OPT",
        "Size":0.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.47,
        "Decode Throughput (tokens\/s)":144.88,
        "E2E Throughput (tokens\/s)":145.0,
        "Prefill Latency (s)":0.00756,
        "E2E Latency (s)":6.91,
        "Allocated Memory (MB)":360,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928,
        "Energy (tokens\/kWh)":2217294.0
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"OPT",
        "Size":0.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.47,
        "Decode Throughput (tokens\/s)":166.01,
        "E2E Throughput (tokens\/s)":166.0,
        "Prefill Latency (s)":0.00613,
        "E2E Latency (s)":6.03,
        "Allocated Memory (MB)":360,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928,
        "Energy (tokens\/kWh)":2570694.0
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":0.16,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.43**",
        "Decode Throughput (tokens\/s)":73.08,
        "E2E Throughput (tokens\/s)":73.0,
        "Prefill Latency (s)":0.017,
        "E2E Latency (s)":13.7,
        "Allocated Memory (MB)":269,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1775,
        "Energy (tokens\/kWh)":1164144.0
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":0.16,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.43**",
        "Decode Throughput (tokens\/s)":86.32,
        "E2E Throughput (tokens\/s)":86.2,
        "Prefill Latency (s)":0.0157,
        "E2E Latency (s)":11.6,
        "Allocated Memory (MB)":269,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1773,
        "Energy (tokens\/kWh)":1322751.0
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":0.16,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.43,
        "Decode Throughput (tokens\/s)":101.62,
        "E2E Throughput (tokens\/s)":102.0,
        "Prefill Latency (s)":0.00977,
        "E2E Latency (s)":9.85,
        "Allocated Memory (MB)":446,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1945,
        "Energy (tokens\/kWh)":1615508.0
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":0.16,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.43,
        "Decode Throughput (tokens\/s)":103.41,
        "E2E Throughput (tokens\/s)":103.0,
        "Prefill Latency (s)":0.00936,
        "E2E Latency (s)":9.68,
        "Allocated Memory (MB)":446,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1945,
        "Energy (tokens\/kWh)":1626016.0
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":0.16,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.43,
        "Decode Throughput (tokens\/s)":119.3,
        "E2E Throughput (tokens\/s)":119.0,
        "Prefill Latency (s)":0.00755,
        "E2E Latency (s)":8.39,
        "Allocated Memory (MB)":446,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1943,
        "Energy (tokens\/kWh)":1923076.0
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.36**",
        "Decode Throughput (tokens\/s)":86.31,
        "E2E Throughput (tokens\/s)":86.2,
        "Prefill Latency (s)":0.0139,
        "E2E Latency (s)":11.6,
        "Allocated Memory (MB)":362,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922,
        "Energy (tokens\/kWh)":1360544.0
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.36**",
        "Decode Throughput (tokens\/s)":95.35,
        "E2E Throughput (tokens\/s)":95.2,
        "Prefill Latency (s)":0.0127,
        "E2E Latency (s)":10.5,
        "Allocated Memory (MB)":362,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922,
        "Energy (tokens\/kWh)":1503759.0
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.36,
        "Decode Throughput (tokens\/s)":104.82,
        "E2E Throughput (tokens\/s)":105.0,
        "Prefill Latency (s)":0.00948,
        "E2E Latency (s)":9.55,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050,
        "Energy (tokens\/kWh)":1652892.0
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.36,
        "Decode Throughput (tokens\/s)":105.93,
        "E2E Throughput (tokens\/s)":106.0,
        "Prefill Latency (s)":0.00956,
        "E2E Latency (s)":9.45,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050,
        "Energy (tokens\/kWh)":1652892.0
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Size":0.21,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.36,
        "Decode Throughput (tokens\/s)":114.13,
        "E2E Throughput (tokens\/s)":114.0,
        "Prefill Latency (s)":0.00797,
        "E2E Latency (s)":8.77,
        "Allocated Memory (MB)":483,
        "Reserved Memory (MB)":574,
        "Used Memory (MB)":2048,
        "Energy (tokens\/kWh)":1872659.0
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.28**",
        "Decode Throughput (tokens\/s)":164.4,
        "E2E Throughput (tokens\/s)":164.0,
        "Prefill Latency (s)":0.00721,
        "E2E Latency (s)":6.09,
        "Allocated Memory (MB)":185,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1687,
        "Energy (tokens\/kWh)":2583979.0
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.28**",
        "Decode Throughput (tokens\/s)":173.2,
        "E2E Throughput (tokens\/s)":173.0,
        "Prefill Latency (s)":0.0063,
        "E2E Latency (s)":5.78,
        "Allocated Memory (MB)":185,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689,
        "Energy (tokens\/kWh)":2688172.0
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.28,
        "Decode Throughput (tokens\/s)":201.81,
        "E2E Throughput (tokens\/s)":202.0,
        "Prefill Latency (s)":0.0049,
        "E2E Latency (s)":4.96,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3215434.0
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.28,
        "Decode Throughput (tokens\/s)":203.04,
        "E2E Throughput (tokens\/s)":203.0,
        "Prefill Latency (s)":0.00478,
        "E2E Latency (s)":4.93,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3225806.0
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.28,
        "Decode Throughput (tokens\/s)":219.5,
        "E2E Throughput (tokens\/s)":219.0,
        "Prefill Latency (s)":0.00418,
        "E2E Latency (s)":4.56,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3436426.0
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Size":0.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.24**",
        "Decode Throughput (tokens\/s)":44.7,
        "E2E Throughput (tokens\/s)":44.6,
        "Prefill Latency (s)":0.0278,
        "E2E Latency (s)":22.4,
        "Allocated Memory (MB)":1216,
        "Reserved Memory (MB)":1377,
        "Used Memory (MB)":2851,
        "Energy (tokens\/kWh)":662251.0
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Size":0.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.24**",
        "Decode Throughput (tokens\/s)":48.84,
        "E2E Throughput (tokens\/s)":48.8,
        "Prefill Latency (s)":0.0245,
        "E2E Latency (s)":20.5,
        "Allocated Memory (MB)":1216,
        "Reserved Memory (MB)":1377,
        "Used Memory (MB)":2851,
        "Energy (tokens\/kWh)":751879.0
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Size":0.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.24,
        "Decode Throughput (tokens\/s)":51.07,
        "E2E Throughput (tokens\/s)":51.0,
        "Prefill Latency (s)":0.0192,
        "E2E Latency (s)":19.6,
        "Allocated Memory (MB)":2193,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858,
        "Energy (tokens\/kWh)":787401.0
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Size":0.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.24,
        "Decode Throughput (tokens\/s)":53.25,
        "E2E Throughput (tokens\/s)":53.2,
        "Prefill Latency (s)":0.0195,
        "E2E Latency (s)":18.8,
        "Allocated Memory (MB)":2193,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858,
        "Energy (tokens\/kWh)":769230.0
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Size":0.76,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.24,
        "Decode Throughput (tokens\/s)":57.86,
        "E2E Throughput (tokens\/s)":57.8,
        "Prefill Latency (s)":0.016,
        "E2E Latency (s)":17.3,
        "Allocated Memory (MB)":2193,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858,
        "Energy (tokens\/kWh)":884955.0
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.21**",
        "Decode Throughput (tokens\/s)":163.86,
        "E2E Throughput (tokens\/s)":164.0,
        "Prefill Latency (s)":0.00714,
        "E2E Latency (s)":6.11,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2544529.0
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.21**",
        "Decode Throughput (tokens\/s)":177.5,
        "E2E Throughput (tokens\/s)":177.0,
        "Prefill Latency (s)":0.00632,
        "E2E Latency (s)":5.64,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2702702.0
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.21,
        "Decode Throughput (tokens\/s)":204.28,
        "E2E Throughput (tokens\/s)":204.0,
        "Prefill Latency (s)":0.00483,
        "E2E Latency (s)":4.9,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3215434.0
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.21,
        "Decode Throughput (tokens\/s)":208.54,
        "E2E Throughput (tokens\/s)":208.0,
        "Prefill Latency (s)":0.00476,
        "E2E Latency (s)":4.8,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3378378.0
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.21,
        "Decode Throughput (tokens\/s)":219.02,
        "E2E Throughput (tokens\/s)":219.0,
        "Prefill Latency (s)":0.00413,
        "E2E Latency (s)":4.57,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3610108.0
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.94,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.12**",
        "Decode Throughput (tokens\/s)":201.08,
        "E2E Throughput (tokens\/s)":201.0,
        "Prefill Latency (s)":0.0068,
        "E2E Latency (s)":4.98,
        "Allocated Memory (MB)":1166,
        "Reserved Memory (MB)":1233,
        "Used Memory (MB)":2706,
        "Energy (tokens\/kWh)":2652519.0
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.94,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.12**",
        "Decode Throughput (tokens\/s)":216.76,
        "E2E Throughput (tokens\/s)":216.0,
        "Prefill Latency (s)":0.00653,
        "E2E Latency (s)":4.62,
        "Allocated Memory (MB)":1166,
        "Reserved Memory (MB)":1220,
        "Used Memory (MB)":2694,
        "Energy (tokens\/kWh)":2840909.0
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.94,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.12,
        "Decode Throughput (tokens\/s)":256.73,
        "E2E Throughput (tokens\/s)":256.0,
        "Prefill Latency (s)":0.00483,
        "E2E Latency (s)":3.9,
        "Allocated Memory (MB)":2328,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828,
        "Energy (tokens\/kWh)":2967359.0
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.94,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.12,
        "Decode Throughput (tokens\/s)":258.72,
        "E2E Throughput (tokens\/s)":258.0,
        "Prefill Latency (s)":0.00486,
        "E2E Latency (s)":3.87,
        "Allocated Memory (MB)":2328,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828,
        "Energy (tokens\/kWh)":2898550.0
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.94,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.12,
        "Decode Throughput (tokens\/s)":282.86,
        "E2E Throughput (tokens\/s)":282.0,
        "Prefill Latency (s)":0.00466,
        "E2E Latency (s)":3.54,
        "Allocated Memory (MB)":2328,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828,
        "Energy (tokens\/kWh)":3154574.0
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"RWKV",
        "Size":0.13,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.07**",
        "Decode Throughput (tokens\/s)":58.2,
        "E2E Throughput (tokens\/s)":55.6,
        "Prefill Latency (s)":0.818,
        "E2E Latency (s)":18.0,
        "Allocated Memory (MB)":241,
        "Reserved Memory (MB)":274,
        "Used Memory (MB)":1748,
        "Energy (tokens\/kWh)":877192.0
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"RWKV",
        "Size":0.13,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.07,
        "Decode Throughput (tokens\/s)":77.98,
        "E2E Throughput (tokens\/s)":73.5,
        "Prefill Latency (s)":0.777,
        "E2E Latency (s)":13.6,
        "Allocated Memory (MB)":381,
        "Reserved Memory (MB)":398,
        "Used Memory (MB)":1872,
        "Energy (tokens\/kWh)":1168224.0
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"RWKV",
        "Size":0.13,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.07,
        "Decode Throughput (tokens\/s)":77.0,
        "E2E Throughput (tokens\/s)":76.9,
        "Prefill Latency (s)":0.0128,
        "E2E Latency (s)":13.0,
        "Allocated Memory (MB)":381,
        "Reserved Memory (MB)":400,
        "Used Memory (MB)":1874,
        "Energy (tokens\/kWh)":1162790.0
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.03**",
        "Decode Throughput (tokens\/s)":140.83,
        "E2E Throughput (tokens\/s)":141.0,
        "Prefill Latency (s)":0.00908,
        "E2E Latency (s)":7.11,
        "Allocated Memory (MB)":144,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1656,
        "Energy (tokens\/kWh)":2232142.0
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.03**",
        "Decode Throughput (tokens\/s)":150.79,
        "E2E Throughput (tokens\/s)":151.0,
        "Prefill Latency (s)":0.00845,
        "E2E Latency (s)":6.64,
        "Allocated Memory (MB)":144,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1656,
        "Energy (tokens\/kWh)":2341920.0
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.03,
        "Decode Throughput (tokens\/s)":174.08,
        "E2E Throughput (tokens\/s)":174.0,
        "Prefill Latency (s)":0.00567,
        "E2E Latency (s)":5.75,
        "Allocated Memory (MB)":180,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698,
        "Energy (tokens\/kWh)":2717391.0
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.03,
        "Decode Throughput (tokens\/s)":176.53,
        "E2E Throughput (tokens\/s)":176.0,
        "Prefill Latency (s)":0.0054,
        "E2E Latency (s)":5.67,
        "Allocated Memory (MB)":180,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698,
        "Energy (tokens\/kWh)":2857142.0
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"LLaMA \ud83e\udd99",
        "Size":0.06,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.03,
        "Decode Throughput (tokens\/s)":186.74,
        "E2E Throughput (tokens\/s)":187.0,
        "Prefill Latency (s)":0.00484,
        "E2E Latency (s)":5.36,
        "Allocated Memory (MB)":180,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698,
        "Energy (tokens\/kWh)":3058103.0
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.02**",
        "Decode Throughput (tokens\/s)":122.25,
        "E2E Throughput (tokens\/s)":122.0,
        "Prefill Latency (s)":0.0103,
        "E2E Latency (s)":8.19,
        "Allocated Memory (MB)":75,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572,
        "Energy (tokens\/kWh)":2004008.0
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.02**",
        "Decode Throughput (tokens\/s)":125.48,
        "E2E Throughput (tokens\/s)":125.0,
        "Prefill Latency (s)":0.0103,
        "E2E Latency (s)":7.98,
        "Allocated Memory (MB)":75,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572,
        "Energy (tokens\/kWh)":2100840.0
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.02,
        "Decode Throughput (tokens\/s)":163.56,
        "E2E Throughput (tokens\/s)":163.0,
        "Prefill Latency (s)":0.00591,
        "E2E Latency (s)":6.12,
        "Allocated Memory (MB)":77,
        "Reserved Memory (MB)":100,
        "Used Memory (MB)":1574,
        "Energy (tokens\/kWh)":2754820.0
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.02,
        "Decode Throughput (tokens\/s)":168.23,
        "E2E Throughput (tokens\/s)":168.0,
        "Prefill Latency (s)":0.00567,
        "E2E Latency (s)":5.95,
        "Allocated Memory (MB)":77,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572,
        "Energy (tokens\/kWh)":2652519.0
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Size":0.0,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":25.02,
        "Decode Throughput (tokens\/s)":177.79,
        "E2E Throughput (tokens\/s)":178.0,
        "Prefill Latency (s)":0.00545,
        "E2E Latency (s)":5.63,
        "Allocated Memory (MB)":77,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572,
        "Energy (tokens\/kWh)":2941176.0
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"RWKV",
        "Size":6.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"25.0**",
        "Decode Throughput (tokens\/s)":25.16,
        "E2E Throughput (tokens\/s)":25.1,
        "Prefill Latency (s)":0.0496,
        "E2E Latency (s)":39.8,
        "Allocated Memory (MB)":4352,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6022,
        "Energy (tokens\/kWh)":343642.0
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"RWKV",
        "Size":6.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":25.0,
        "Decode Throughput (tokens\/s)":34.23,
        "E2E Throughput (tokens\/s)":32.2,
        "Prefill Latency (s)":1.89,
        "E2E Latency (s)":31.1,
        "Allocated Memory (MB)":13112,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14639,
        "Energy (tokens\/kWh)":380228.0
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"RWKV",
        "Size":6.53,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":25.0,
        "Decode Throughput (tokens\/s)":34.05,
        "E2E Throughput (tokens\/s)":34.0,
        "Prefill Latency (s)":0.0305,
        "E2E Latency (s)":29.4,
        "Allocated Memory (MB)":13112,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14639,
        "Energy (tokens\/kWh)":399999.0
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":1.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.95**",
        "Decode Throughput (tokens\/s)":62.97,
        "E2E Throughput (tokens\/s)":62.9,
        "Prefill Latency (s)":0.0204,
        "E2E Latency (s)":15.9,
        "Allocated Memory (MB)":901,
        "Reserved Memory (MB)":954,
        "Used Memory (MB)":2427,
        "Energy (tokens\/kWh)":909090.0
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":1.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.95**",
        "Decode Throughput (tokens\/s)":74.72,
        "E2E Throughput (tokens\/s)":74.6,
        "Prefill Latency (s)":0.0175,
        "E2E Latency (s)":13.4,
        "Allocated Memory (MB)":901,
        "Reserved Memory (MB)":952,
        "Used Memory (MB)":2423,
        "Energy (tokens\/kWh)":1072961.0
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":1.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.95,
        "Decode Throughput (tokens\/s)":82.73,
        "E2E Throughput (tokens\/s)":82.6,
        "Prefill Latency (s)":0.0122,
        "E2E Latency (s)":12.1,
        "Allocated Memory (MB)":2329,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3900,
        "Energy (tokens\/kWh)":1122334.0
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":1.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.95,
        "Decode Throughput (tokens\/s)":82.72,
        "E2E Throughput (tokens\/s)":82.6,
        "Prefill Latency (s)":0.0117,
        "E2E Latency (s)":12.1,
        "Allocated Memory (MB)":2329,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3900,
        "Energy (tokens\/kWh)":1152073.0
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"GPT-BigCode \ud83c\udf38",
        "Size":1.12,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.95,
        "Decode Throughput (tokens\/s)":107.75,
        "E2E Throughput (tokens\/s)":108.0,
        "Prefill Latency (s)":0.00886,
        "E2E Latency (s)":9.29,
        "Allocated Memory (MB)":2329,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3898,
        "Energy (tokens\/kWh)":1418439.0
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.89**",
        "Decode Throughput (tokens\/s)":166.31,
        "E2E Throughput (tokens\/s)":166.0,
        "Prefill Latency (s)":0.00709,
        "E2E Latency (s)":6.02,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2617801.0
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.89**",
        "Decode Throughput (tokens\/s)":180.06,
        "E2E Throughput (tokens\/s)":180.0,
        "Prefill Latency (s)":0.00639,
        "E2E Latency (s)":5.56,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2915451.0
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.89,
        "Decode Throughput (tokens\/s)":206.39,
        "E2E Throughput (tokens\/s)":206.0,
        "Prefill Latency (s)":0.0048,
        "E2E Latency (s)":4.85,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3246753.0
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.89,
        "Decode Throughput (tokens\/s)":207.67,
        "E2E Throughput (tokens\/s)":207.0,
        "Prefill Latency (s)":0.00477,
        "E2E Latency (s)":4.82,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3278688.0
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.89,
        "Decode Throughput (tokens\/s)":229.05,
        "E2E Throughput (tokens\/s)":229.0,
        "Prefill Latency (s)":0.00406,
        "E2E Latency (s)":4.37,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3649635.0
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.85**",
        "Decode Throughput (tokens\/s)":165.48,
        "E2E Throughput (tokens\/s)":165.0,
        "Prefill Latency (s)":0.00701,
        "E2E Latency (s)":6.05,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2583979.0
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.85**",
        "Decode Throughput (tokens\/s)":178.77,
        "E2E Throughput (tokens\/s)":179.0,
        "Prefill Latency (s)":0.0063,
        "E2E Latency (s)":5.6,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2890173.0
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.85,
        "Decode Throughput (tokens\/s)":205.54,
        "E2E Throughput (tokens\/s)":205.0,
        "Prefill Latency (s)":0.0048,
        "E2E Latency (s)":4.87,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3311258.0
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.85,
        "Decode Throughput (tokens\/s)":206.39,
        "E2E Throughput (tokens\/s)":206.0,
        "Prefill Latency (s)":0.00479,
        "E2E Latency (s)":4.85,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3300330.0
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.85,
        "Decode Throughput (tokens\/s)":220.47,
        "E2E Throughput (tokens\/s)":220.0,
        "Prefill Latency (s)":0.00414,
        "E2E Latency (s)":4.54,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3584229.0
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.71**",
        "Decode Throughput (tokens\/s)":162.26,
        "E2E Throughput (tokens\/s)":162.0,
        "Prefill Latency (s)":0.00719,
        "E2E Latency (s)":6.17,
        "Allocated Memory (MB)":185,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1687,
        "Energy (tokens\/kWh)":2544529.0
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.71**",
        "Decode Throughput (tokens\/s)":174.11,
        "E2E Throughput (tokens\/s)":174.0,
        "Prefill Latency (s)":0.00635,
        "E2E Latency (s)":5.75,
        "Allocated Memory (MB)":185,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689,
        "Energy (tokens\/kWh)":2824858.0
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.71,
        "Decode Throughput (tokens\/s)":199.8,
        "E2E Throughput (tokens\/s)":200.0,
        "Prefill Latency (s)":0.00491,
        "E2E Latency (s)":5.01,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3134796.0
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.71,
        "Decode Throughput (tokens\/s)":203.87,
        "E2E Throughput (tokens\/s)":204.0,
        "Prefill Latency (s)":0.00484,
        "E2E Latency (s)":4.91,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3115264.0
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Size":0.1,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.71,
        "Decode Throughput (tokens\/s)":216.18,
        "E2E Throughput (tokens\/s)":216.0,
        "Prefill Latency (s)":0.00419,
        "E2E Latency (s)":4.63,
        "Allocated Memory (MB)":216,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725,
        "Energy (tokens\/kWh)":3623188.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.7**",
        "Decode Throughput (tokens\/s)":168.27,
        "E2E Throughput (tokens\/s)":168.0,
        "Prefill Latency (s)":0.007,
        "E2E Latency (s)":5.95,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2617801.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.7**",
        "Decode Throughput (tokens\/s)":180.06,
        "E2E Throughput (tokens\/s)":180.0,
        "Prefill Latency (s)":0.00634,
        "E2E Latency (s)":5.56,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2857142.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.7,
        "Decode Throughput (tokens\/s)":199.0,
        "E2E Throughput (tokens\/s)":199.0,
        "Prefill Latency (s)":0.00495,
        "E2E Latency (s)":5.03,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3174603.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.7,
        "Decode Throughput (tokens\/s)":205.55,
        "E2E Throughput (tokens\/s)":205.0,
        "Prefill Latency (s)":0.00495,
        "E2E Latency (s)":4.87,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3289473.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.7,
        "Decode Throughput (tokens\/s)":223.42,
        "E2E Throughput (tokens\/s)":223.0,
        "Prefill Latency (s)":0.00413,
        "E2E Latency (s)":4.48,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3676470.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.63**",
        "Decode Throughput (tokens\/s)":166.58,
        "E2E Throughput (tokens\/s)":166.0,
        "Prefill Latency (s)":0.00702,
        "E2E Latency (s)":6.01,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2577319.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.63**",
        "Decode Throughput (tokens\/s)":179.09,
        "E2E Throughput (tokens\/s)":179.0,
        "Prefill Latency (s)":0.00631,
        "E2E Latency (s)":5.59,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2898550.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.63,
        "Decode Throughput (tokens\/s)":203.87,
        "E2E Throughput (tokens\/s)":204.0,
        "Prefill Latency (s)":0.00489,
        "E2E Latency (s)":4.91,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3115264.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.63,
        "Decode Throughput (tokens\/s)":205.12,
        "E2E Throughput (tokens\/s)":205.0,
        "Prefill Latency (s)":0.00478,
        "E2E Latency (s)":4.88,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3378378.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.63,
        "Decode Throughput (tokens\/s)":220.95,
        "E2E Throughput (tokens\/s)":221.0,
        "Prefill Latency (s)":0.00415,
        "E2E Latency (s)":4.53,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3610108.0
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Size":0.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.39**",
        "Decode Throughput (tokens\/s)":127.06,
        "E2E Throughput (tokens\/s)":127.0,
        "Prefill Latency (s)":0.01,
        "E2E Latency (s)":7.88,
        "Allocated Memory (MB)":157,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689,
        "Energy (tokens\/kWh)":2024291.0
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Size":0.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.39**",
        "Decode Throughput (tokens\/s)":134.76,
        "E2E Throughput (tokens\/s)":135.0,
        "Prefill Latency (s)":0.00941,
        "E2E Latency (s)":7.43,
        "Allocated Memory (MB)":154,
        "Reserved Memory (MB)":218,
        "Used Memory (MB)":1691,
        "Energy (tokens\/kWh)":2164502.0
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Size":0.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.39,
        "Decode Throughput (tokens\/s)":170.24,
        "E2E Throughput (tokens\/s)":170.0,
        "Prefill Latency (s)":0.00578,
        "E2E Latency (s)":5.88,
        "Allocated Memory (MB)":192,
        "Reserved Memory (MB)":262,
        "Used Memory (MB)":1735,
        "Energy (tokens\/kWh)":2624671.0
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Size":0.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.39,
        "Decode Throughput (tokens\/s)":171.69,
        "E2E Throughput (tokens\/s)":172.0,
        "Prefill Latency (s)":0.00544,
        "E2E Latency (s)":5.83,
        "Allocated Memory (MB)":191,
        "Reserved Memory (MB)":241,
        "Used Memory (MB)":1714,
        "Energy (tokens\/kWh)":2680965.0
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Size":0.05,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.39,
        "Decode Throughput (tokens\/s)":176.23,
        "E2E Throughput (tokens\/s)":176.0,
        "Prefill Latency (s)":0.00569,
        "E2E Latency (s)":5.68,
        "Allocated Memory (MB)":192,
        "Reserved Memory (MB)":262,
        "Used Memory (MB)":1735,
        "Energy (tokens\/kWh)":2762430.0
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Size":0.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.38**",
        "Decode Throughput (tokens\/s)":228.07,
        "E2E Throughput (tokens\/s)":228.0,
        "Prefill Latency (s)":0.00539,
        "E2E Latency (s)":4.39,
        "Allocated Memory (MB)":161,
        "Reserved Memory (MB)":197,
        "Used Memory (MB)":1670,
        "Energy (tokens\/kWh)":3649635.0
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Size":0.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.38**",
        "Decode Throughput (tokens\/s)":248.45,
        "E2E Throughput (tokens\/s)":248.0,
        "Prefill Latency (s)":0.00503,
        "E2E Latency (s)":4.03,
        "Allocated Memory (MB)":157,
        "Reserved Memory (MB)":197,
        "Used Memory (MB)":1670,
        "Energy (tokens\/kWh)":3952569.0
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Size":0.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.38,
        "Decode Throughput (tokens\/s)":301.49,
        "E2E Throughput (tokens\/s)":301.0,
        "Prefill Latency (s)":0.00312,
        "E2E Latency (s)":3.32,
        "Allocated Memory (MB)":197,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708,
        "Energy (tokens\/kWh)":4784688.0
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Size":0.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.38,
        "Decode Throughput (tokens\/s)":304.26,
        "E2E Throughput (tokens\/s)":304.0,
        "Prefill Latency (s)":0.00337,
        "E2E Latency (s)":3.29,
        "Allocated Memory (MB)":200,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708,
        "Energy (tokens\/kWh)":4761904.0
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Size":0.07,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.38,
        "Decode Throughput (tokens\/s)":306.11,
        "E2E Throughput (tokens\/s)":306.0,
        "Prefill Latency (s)":0.00324,
        "E2E Latency (s)":3.27,
        "Allocated Memory (MB)":200,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708,
        "Energy (tokens\/kWh)":4739336.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.35**",
        "Decode Throughput (tokens\/s)":165.76,
        "E2E Throughput (tokens\/s)":166.0,
        "Prefill Latency (s)":0.00704,
        "E2E Latency (s)":6.04,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2617801.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.35**",
        "Decode Throughput (tokens\/s)":179.41,
        "E2E Throughput (tokens\/s)":179.0,
        "Prefill Latency (s)":0.00624,
        "E2E Latency (s)":5.58,
        "Allocated Memory (MB)":118,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620,
        "Energy (tokens\/kWh)":2865329.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.35,
        "Decode Throughput (tokens\/s)":195.89,
        "E2E Throughput (tokens\/s)":196.0,
        "Prefill Latency (s)":0.00503,
        "E2E Latency (s)":5.11,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3144654.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.35,
        "Decode Throughput (tokens\/s)":205.54,
        "E2E Throughput (tokens\/s)":205.0,
        "Prefill Latency (s)":0.00487,
        "E2E Latency (s)":4.87,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3300330.0
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Size":0.03,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.35,
        "Decode Throughput (tokens\/s)":225.43,
        "E2E Throughput (tokens\/s)":225.0,
        "Prefill Latency (s)":0.00409,
        "E2E Latency (s)":4.44,
        "Allocated Memory (MB)":126,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628,
        "Energy (tokens\/kWh)":3663003.0
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Size":0.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.31**",
        "Decode Throughput (tokens\/s)":129.54,
        "E2E Throughput (tokens\/s)":129.0,
        "Prefill Latency (s)":0.0101,
        "E2E Latency (s)":7.73,
        "Allocated Memory (MB)":102,
        "Reserved Memory (MB)":148,
        "Used Memory (MB)":1622,
        "Energy (tokens\/kWh)":2020202.0
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Size":0.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.31**",
        "Decode Throughput (tokens\/s)":135.86,
        "E2E Throughput (tokens\/s)":136.0,
        "Prefill Latency (s)":0.00944,
        "E2E Latency (s)":7.37,
        "Allocated Memory (MB)":102,
        "Reserved Memory (MB)":148,
        "Used Memory (MB)":1622,
        "Energy (tokens\/kWh)":2169197.0
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Size":0.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.31,
        "Decode Throughput (tokens\/s)":172.28,
        "E2E Throughput (tokens\/s)":172.0,
        "Prefill Latency (s)":0.00555,
        "E2E Latency (s)":5.81,
        "Allocated Memory (MB)":112,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1631,
        "Energy (tokens\/kWh)":2873563.0
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Size":0.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.31,
        "Decode Throughput (tokens\/s)":174.39,
        "E2E Throughput (tokens\/s)":174.0,
        "Prefill Latency (s)":0.00581,
        "E2E Latency (s)":5.74,
        "Allocated Memory (MB)":112,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1630,
        "Energy (tokens\/kWh)":2793296.0
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Size":0.02,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.31,
        "Decode Throughput (tokens\/s)":177.48,
        "E2E Throughput (tokens\/s)":177.0,
        "Prefill Latency (s)":0.00567,
        "E2E Latency (s)":5.64,
        "Allocated Memory (MB)":112,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1631,
        "Energy (tokens\/kWh)":2898550.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.25**",
        "Decode Throughput (tokens\/s)":104.41,
        "E2E Throughput (tokens\/s)":104.0,
        "Prefill Latency (s)":0.012,
        "E2E Latency (s)":9.59,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901,
        "Energy (tokens\/kWh)":1582278.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.25**",
        "Decode Throughput (tokens\/s)":107.54,
        "E2E Throughput (tokens\/s)":107.0,
        "Prefill Latency (s)":0.011,
        "E2E Latency (s)":9.31,
        "Allocated Memory (MB)":353,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901,
        "Energy (tokens\/kWh)":1658374.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.25,
        "Decode Throughput (tokens\/s)":132.06,
        "E2E Throughput (tokens\/s)":132.0,
        "Prefill Latency (s)":0.00764,
        "E2E Latency (s)":7.58,
        "Allocated Memory (MB)":480,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029,
        "Energy (tokens\/kWh)":2000000.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.25,
        "Decode Throughput (tokens\/s)":132.94,
        "E2E Throughput (tokens\/s)":133.0,
        "Prefill Latency (s)":0.00762,
        "E2E Latency (s)":7.53,
        "Allocated Memory (MB)":480,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029,
        "Energy (tokens\/kWh)":2000000.0
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"Bloom \ud83c\udf38",
        "Size":0.19,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.25,
        "Decode Throughput (tokens\/s)":138.25,
        "E2E Throughput (tokens\/s)":138.0,
        "Prefill Latency (s)":0.00667,
        "E2E Latency (s)":7.24,
        "Allocated Memory (MB)":480,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029,
        "Energy (tokens\/kWh)":2118644.0
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Size":0.01,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.18**",
        "Decode Throughput (tokens\/s)":129.87,
        "E2E Throughput (tokens\/s)":130.0,
        "Prefill Latency (s)":0.0102,
        "E2E Latency (s)":7.71,
        "Allocated Memory (MB)":84,
        "Reserved Memory (MB)":121,
        "Used Memory (MB)":1595,
        "Energy (tokens\/kWh)":2024291.0
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Size":0.01,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.18**",
        "Decode Throughput (tokens\/s)":137.73,
        "E2E Throughput (tokens\/s)":138.0,
        "Prefill Latency (s)":0.00928,
        "E2E Latency (s)":7.27,
        "Allocated Memory (MB)":84,
        "Reserved Memory (MB)":121,
        "Used Memory (MB)":1595,
        "Energy (tokens\/kWh)":2197802.0
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Size":0.01,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.18,
        "Decode Throughput (tokens\/s)":171.1,
        "E2E Throughput (tokens\/s)":171.0,
        "Prefill Latency (s)":0.00557,
        "E2E Latency (s)":5.85,
        "Allocated Memory (MB)":87,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597,
        "Energy (tokens\/kWh)":2832861.0
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Size":0.01,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.18,
        "Decode Throughput (tokens\/s)":174.09,
        "E2E Throughput (tokens\/s)":174.0,
        "Prefill Latency (s)":0.00588,
        "E2E Latency (s)":5.75,
        "Allocated Memory (MB)":87,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597,
        "Energy (tokens\/kWh)":2777777.0
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Size":0.01,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.18,
        "Decode Throughput (tokens\/s)":178.43,
        "E2E Throughput (tokens\/s)":178.0,
        "Prefill Latency (s)":0.00563,
        "E2E Latency (s)":5.61,
        "Allocated Memory (MB)":87,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597,
        "Energy (tokens\/kWh)":2923976.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Size":0.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":24.1,
        "Decode Throughput (tokens\/s)":160.41,
        "E2E Throughput (tokens\/s)":160.0,
        "Prefill Latency (s)":0.00604,
        "E2E Latency (s)":6.24,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1899,
        "Energy (tokens\/kWh)":2487562.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Size":0.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":24.1,
        "Decode Throughput (tokens\/s)":160.67,
        "E2E Throughput (tokens\/s)":161.0,
        "Prefill Latency (s)":0.00602,
        "E2E Latency (s)":6.23,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1899,
        "Energy (tokens\/kWh)":2409638.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Size":0.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.1**",
        "Decode Throughput (tokens\/s)":163.56,
        "E2E Throughput (tokens\/s)":163.0,
        "Prefill Latency (s)":0.00608,
        "E2E Latency (s)":6.12,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901,
        "Energy (tokens\/kWh)":2531645.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Size":0.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":24.1,
        "Decode Throughput (tokens\/s)":180.67,
        "E2E Throughput (tokens\/s)":181.0,
        "Prefill Latency (s)":0.00494,
        "E2E Latency (s)":5.54,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901,
        "Energy (tokens\/kWh)":2865329.0
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Size":0.11,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"24.1**",
        "Decode Throughput (tokens\/s)":184.66,
        "E2E Throughput (tokens\/s)":185.0,
        "Prefill Latency (s)":0.00475,
        "E2E Latency (s)":5.42,
        "Allocated Memory (MB)":354,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901,
        "Energy (tokens\/kWh)":2941176.0
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"OPT",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"19.4**",
        "Decode Throughput (tokens\/s)":50.07,
        "E2E Throughput (tokens\/s)":50.0,
        "Prefill Latency (s)":0.0292,
        "E2E Latency (s)":20.0,
        "Allocated Memory (MB)":1408,
        "Reserved Memory (MB)":1497,
        "Used Memory (MB)":2971,
        "Energy (tokens\/kWh)":704225.0
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"OPT",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"19.4**",
        "Decode Throughput (tokens\/s)":56.26,
        "E2E Throughput (tokens\/s)":56.2,
        "Prefill Latency (s)":0.0254,
        "E2E Latency (s)":17.8,
        "Allocated Memory (MB)":1407,
        "Reserved Memory (MB)":1497,
        "Used Memory (MB)":2971,
        "Energy (tokens\/kWh)":787401.0
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"OPT",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":19.4,
        "Decode Throughput (tokens\/s)":70.0,
        "E2E Throughput (tokens\/s)":69.9,
        "Prefill Latency (s)":0.0147,
        "E2E Latency (s)":14.3,
        "Allocated Memory (MB)":3144,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4889,
        "Energy (tokens\/kWh)":943396.0
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"OPT",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":19.4,
        "Decode Throughput (tokens\/s)":71.5,
        "E2E Throughput (tokens\/s)":71.4,
        "Prefill Latency (s)":0.0149,
        "E2E Latency (s)":14.0,
        "Allocated Memory (MB)":3144,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4890,
        "Energy (tokens\/kWh)":917431.0
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"OPT",
        "Size":1.32,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"BetterTransformer",
        "Quantization":"None",
        "Avg Score (%)":19.4,
        "Decode Throughput (tokens\/s)":79.44,
        "E2E Throughput (tokens\/s)":79.4,
        "Prefill Latency (s)":0.0118,
        "E2E Latency (s)":12.6,
        "Allocated Memory (MB)":3144,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4890,
        "Energy (tokens\/kWh)":1070663.0
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"MPT",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"BnB.4bit",
        "Avg Score (%)":"17.88**",
        "Decode Throughput (tokens\/s)":63.78,
        "E2E Throughput (tokens\/s)":63.7,
        "Prefill Latency (s)":0.0201,
        "E2E Latency (s)":15.7,
        "Allocated Memory (MB)":1398,
        "Reserved Memory (MB)":1453,
        "Used Memory (MB)":2927,
        "Energy (tokens\/kWh)":892857.0
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"MPT",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"FlashAttentionV2",
        "Quantization":"None",
        "Avg Score (%)":17.88,
        "Decode Throughput (tokens\/s)":87.04,
        "E2E Throughput (tokens\/s)":87.0,
        "Prefill Latency (s)":0.0116,
        "E2E Latency (s)":11.5,
        "Allocated Memory (MB)":3135,
        "Reserved Memory (MB)":3212,
        "Used Memory (MB)":4686,
        "Energy (tokens\/kWh)":1140250.0
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"MPT",
        "Size":1.31,
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimizations":"None",
        "Quantization":"None",
        "Avg Score (%)":17.88,
        "Decode Throughput (tokens\/s)":88.59,
        "E2E Throughput (tokens\/s)":88.5,
        "Prefill Latency (s)":0.0115,
        "E2E Latency (s)":11.3,
        "Allocated Memory (MB)":3135,
        "Reserved Memory (MB)":3212,
        "Used Memory (MB)":4686,
        "Energy (tokens\/kWh)":1127395.0
    }
]