{
  "title": "num_prompt_tokens: 1, num_instances: 10, tokenizer: huggingface/gpt2",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "# eval",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# train",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "truncated",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# output tokens",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# trials",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "Synthetic efficiency"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 13.6,
        "description": "min=13.6, mean=13.6, max=13.6, sum=13.6 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 21.7,
        "description": "min=21.7, mean=21.7, max=21.7, sum=21.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 37.7,
        "description": "min=37.7, mean=37.7, max=37.7, sum=37.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 7.6,
        "description": "min=7.6, mean=7.6, max=7.6, sum=7.6 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 31.2,
        "description": "min=31.2, mean=31.2, max=31.2, sum=31.2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 59.4,
        "description": "min=59.4, mean=59.4, max=59.4, sum=59.4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 30.6,
        "description": "min=30.6, mean=30.6, max=30.6, sum=30.6 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 59.4,
        "description": "min=59.4, mean=59.4, max=59.4, sum=59.4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 15.5,
        "description": "min=15.5, mean=15.5, max=15.5, sum=15.5 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 28.1,
        "description": "min=28.1, mean=28.1, max=28.1, sum=28.1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 43.6,
        "description": "min=43.6, mean=43.6, max=43.6, sum=43.6 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 14.7,
        "description": "min=14.7, mean=14.7, max=14.7, sum=14.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 25.9,
        "description": "min=25.9, mean=25.9, max=25.9, sum=25.9 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 40.9,
        "description": "min=40.9, mean=40.9, max=40.9, sum=40.9 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 30.6,
        "description": "min=30.6, mean=30.6, max=30.6, sum=30.6 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 50.9,
        "description": "min=50.9, mean=50.9, max=50.9, sum=50.9 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 57.7,
        "description": "min=57.7, mean=57.7, max=57.7, sum=57.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%201%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D1%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2.tex"
    },
    {
      "text": "JSON",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2.json"
    }
  ],
  "name": "synthetic_efficiency_num_prompt_tokens:1,num_instances:10,tokenizer:huggingface_gpt2"
}